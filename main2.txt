/home/miguelvilla/anaconda3/envs/doom/lib/python3.12/site-packages/vizdoom/gymnasium_wrapper/base_gymnasium_env.py:84: UserWarning: Detected screen format CRCGCB. Only RGB24 and GRAY8 are supported in the Gymnasium wrapper. Forcing RGB24.
  warnings.warn(
Using cuda device
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.075   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 4        |
|    fps              | 2490     |
|    time_elapsed     | 0        |
|    total_timesteps  | 76       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.072   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 8        |
|    fps              | 2590     |
|    time_elapsed     | 0        |
|    total_timesteps  | 146      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.179    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 12       |
|    fps              | 2636     |
|    time_elapsed     | 0        |
|    total_timesteps  | 216      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.113    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 16       |
|    fps              | 2595     |
|    time_elapsed     | 0        |
|    total_timesteps  | 301      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0759   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 20       |
|    fps              | 2549     |
|    time_elapsed     | 0        |
|    total_timesteps  | 376      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.136    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 24       |
|    fps              | 2575     |
|    time_elapsed     | 0        |
|    total_timesteps  | 439      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.144    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 28       |
|    fps              | 2577     |
|    time_elapsed     | 0        |
|    total_timesteps  | 499      |
----------------------------------
Eval num_timesteps=500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 500      |
---------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.118    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 32       |
|    fps              | 114      |
|    time_elapsed     | 4        |
|    total_timesteps  | 568      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.125    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 36       |
|    fps              | 127      |
|    time_elapsed     | 4        |
|    total_timesteps  | 633      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.131    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 40       |
|    fps              | 140      |
|    time_elapsed     | 4        |
|    total_timesteps  | 703      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.113    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 44       |
|    fps              | 153      |
|    time_elapsed     | 5        |
|    total_timesteps  | 773      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0979   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 48       |
|    fps              | 166      |
|    time_elapsed     | 5        |
|    total_timesteps  | 838      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0851   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 52       |
|    fps              | 179      |
|    time_elapsed     | 5        |
|    total_timesteps  | 908      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0741   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 56       |
|    fps              | 191      |
|    time_elapsed     | 5        |
|    total_timesteps  | 977      |
----------------------------------
Eval num_timesteps=1000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 1000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0647   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 60       |
|    fps              | 109      |
|    time_elapsed     | 9        |
|    total_timesteps  | 1045     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.072    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 64       |
|    fps              | 116      |
|    time_elapsed     | 9        |
|    total_timesteps  | 1115     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0634   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 68       |
|    fps              | 124      |
|    time_elapsed     | 9        |
|    total_timesteps  | 1190     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0548   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 72       |
|    fps              | 133      |
|    time_elapsed     | 9        |
|    total_timesteps  | 1283     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0472   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 76       |
|    fps              | 142      |
|    time_elapsed     | 9        |
|    total_timesteps  | 1373     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0411   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 80       |
|    fps              | 149      |
|    time_elapsed     | 9        |
|    total_timesteps  | 1450     |
----------------------------------
Eval num_timesteps=1500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 1500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0349   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 84       |
|    fps              | 111      |
|    time_elapsed     | 13       |
|    total_timesteps  | 1540     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 88       |
|    fps              | 115      |
|    time_elapsed     | 13       |
|    total_timesteps  | 1605     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0374   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 92       |
|    fps              | 119      |
|    time_elapsed     | 13       |
|    total_timesteps  | 1664     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0434   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 96       |
|    fps              | 124      |
|    time_elapsed     | 13       |
|    total_timesteps  | 1735     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0387   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 100      |
|    fps              | 129      |
|    time_elapsed     | 13       |
|    total_timesteps  | 1809     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0385   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 104      |
|    fps              | 135      |
|    time_elapsed     | 13       |
|    total_timesteps  | 1890     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 108      |
|    fps              | 141      |
|    time_elapsed     | 14       |
|    total_timesteps  | 1979     |
----------------------------------
Eval num_timesteps=2000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 2000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00796  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 112      |
|    fps              | 110      |
|    time_elapsed     | 18       |
|    total_timesteps  | 2043     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00848  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 116      |
|    fps              | 114      |
|    time_elapsed     | 18       |
|    total_timesteps  | 2115     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 120      |
|    fps              | 118      |
|    time_elapsed     | 18       |
|    total_timesteps  | 2193     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00823  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 124      |
|    fps              | 121      |
|    time_elapsed     | 18       |
|    total_timesteps  | 2260     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00775  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 128      |
|    fps              | 125      |
|    time_elapsed     | 18       |
|    total_timesteps  | 2332     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00731  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 132      |
|    fps              | 129      |
|    time_elapsed     | 18       |
|    total_timesteps  | 2412     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00283 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 136      |
|    fps              | 133      |
|    time_elapsed     | 18       |
|    total_timesteps  | 2480     |
----------------------------------
Eval num_timesteps=2500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 2500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 140      |
|    fps              | 111      |
|    time_elapsed     | 22       |
|    total_timesteps  | 2550     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 144      |
|    fps              | 114      |
|    time_elapsed     | 22       |
|    total_timesteps  | 2630     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 148      |
|    fps              | 117      |
|    time_elapsed     | 22       |
|    total_timesteps  | 2699     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00313 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 152      |
|    fps              | 120      |
|    time_elapsed     | 22       |
|    total_timesteps  | 2763     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00357 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 156      |
|    fps              | 123      |
|    time_elapsed     | 23       |
|    total_timesteps  | 2843     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00361 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 160      |
|    fps              | 126      |
|    time_elapsed     | 23       |
|    total_timesteps  | 2912     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 164      |
|    fps              | 130      |
|    time_elapsed     | 23       |
|    total_timesteps  | 2998     |
----------------------------------
Eval num_timesteps=3000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 3000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00492 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 168      |
|    fps              | 113      |
|    time_elapsed     | 27       |
|    total_timesteps  | 3090     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00408 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 172      |
|    fps              | 115      |
|    time_elapsed     | 27       |
|    total_timesteps  | 3162     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00348 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 176      |
|    fps              | 118      |
|    time_elapsed     | 27       |
|    total_timesteps  | 3237     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00707  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 180      |
|    fps              | 120      |
|    time_elapsed     | 27       |
|    total_timesteps  | 3300     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 184      |
|    fps              | 122      |
|    time_elapsed     | 27       |
|    total_timesteps  | 3366     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 188      |
|    fps              | 124      |
|    time_elapsed     | 27       |
|    total_timesteps  | 3435     |
----------------------------------
Eval num_timesteps=3500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 3500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0073   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 192      |
|    fps              | 110      |
|    time_elapsed     | 31       |
|    total_timesteps  | 3508     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00759  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 196      |
|    fps              | 111      |
|    time_elapsed     | 31       |
|    total_timesteps  | 3571     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00755  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 200      |
|    fps              | 114      |
|    time_elapsed     | 31       |
|    total_timesteps  | 3646     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 204      |
|    fps              | 116      |
|    time_elapsed     | 31       |
|    total_timesteps  | 3722     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 208      |
|    fps              | 119      |
|    time_elapsed     | 31       |
|    total_timesteps  | 3812     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0165   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 212      |
|    fps              | 122      |
|    time_elapsed     | 32       |
|    total_timesteps  | 3906     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 216      |
|    fps              | 123      |
|    time_elapsed     | 32       |
|    total_timesteps  | 3971     |
----------------------------------
Eval num_timesteps=4000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 4000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00715  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 220      |
|    fps              | 111      |
|    time_elapsed     | 36       |
|    total_timesteps  | 4040     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00286 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 224      |
|    fps              | 112      |
|    time_elapsed     | 36       |
|    total_timesteps  | 4107     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 228      |
|    fps              | 114      |
|    time_elapsed     | 36       |
|    total_timesteps  | 4186     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 232      |
|    fps              | 116      |
|    time_elapsed     | 36       |
|    total_timesteps  | 4256     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 236      |
|    fps              | 118      |
|    time_elapsed     | 36       |
|    total_timesteps  | 4320     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 240      |
|    fps              | 120      |
|    time_elapsed     | 36       |
|    total_timesteps  | 4392     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 244      |
|    fps              | 121      |
|    time_elapsed     | 36       |
|    total_timesteps  | 4454     |
----------------------------------
Eval num_timesteps=4500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 4500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 248      |
|    fps              | 110      |
|    time_elapsed     | 41       |
|    total_timesteps  | 4533     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 252      |
|    fps              | 112      |
|    time_elapsed     | 41       |
|    total_timesteps  | 4603     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0223  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 256      |
|    fps              | 113      |
|    time_elapsed     | 41       |
|    total_timesteps  | 4675     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 260      |
|    fps              | 115      |
|    time_elapsed     | 41       |
|    total_timesteps  | 4757     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.022   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 264      |
|    fps              | 117      |
|    time_elapsed     | 41       |
|    total_timesteps  | 4822     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0318  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 268      |
|    fps              | 119      |
|    time_elapsed     | 41       |
|    total_timesteps  | 4910     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0316  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 272      |
|    fps              | 120      |
|    time_elapsed     | 41       |
|    total_timesteps  | 4976     |
----------------------------------
Eval num_timesteps=5000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 5000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0215  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 276      |
|    fps              | 110      |
|    time_elapsed     | 45       |
|    total_timesteps  | 5050     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0318  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 280      |
|    fps              | 112      |
|    time_elapsed     | 45       |
|    total_timesteps  | 5119     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0423  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 284      |
|    fps              | 113      |
|    time_elapsed     | 45       |
|    total_timesteps  | 5199     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0424  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 288      |
|    fps              | 115      |
|    time_elapsed     | 45       |
|    total_timesteps  | 5271     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0321  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 292      |
|    fps              | 116      |
|    time_elapsed     | 45       |
|    total_timesteps  | 5336     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0422  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 296      |
|    fps              | 118      |
|    time_elapsed     | 45       |
|    total_timesteps  | 5402     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0422  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 300      |
|    fps              | 119      |
|    time_elapsed     | 45       |
|    total_timesteps  | 5476     |
----------------------------------
Eval num_timesteps=5500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 5500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0417  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 304      |
|    fps              | 110      |
|    time_elapsed     | 50       |
|    total_timesteps  | 5541     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.041   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 308      |
|    fps              | 112      |
|    time_elapsed     | 50       |
|    total_timesteps  | 5614     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0295  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 312      |
|    fps              | 113      |
|    time_elapsed     | 50       |
|    total_timesteps  | 5670     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00956 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 316      |
|    fps              | 114      |
|    time_elapsed     | 50       |
|    total_timesteps  | 5737     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00988 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 320      |
|    fps              | 115      |
|    time_elapsed     | 50       |
|    total_timesteps  | 5814     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00996 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 324      |
|    fps              | 117      |
|    time_elapsed     | 50       |
|    total_timesteps  | 5883     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00984 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 328      |
|    fps              | 118      |
|    time_elapsed     | 50       |
|    total_timesteps  | 5959     |
----------------------------------
Eval num_timesteps=6000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 6000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.01    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 332      |
|    fps              | 110      |
|    time_elapsed     | 54       |
|    total_timesteps  | 6033     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0106  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 336      |
|    fps              | 111      |
|    time_elapsed     | 54       |
|    total_timesteps  | 6111     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 340      |
|    fps              | 113      |
|    time_elapsed     | 54       |
|    total_timesteps  | 6201     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 344      |
|    fps              | 114      |
|    time_elapsed     | 54       |
|    total_timesteps  | 6273     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 348      |
|    fps              | 115      |
|    time_elapsed     | 54       |
|    total_timesteps  | 6340     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 352      |
|    fps              | 117      |
|    time_elapsed     | 54       |
|    total_timesteps  | 6423     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 356      |
|    fps              | 118      |
|    time_elapsed     | 54       |
|    total_timesteps  | 6487     |
----------------------------------
Eval num_timesteps=6500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 6500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00067 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 360      |
|    fps              | 110      |
|    time_elapsed     | 59       |
|    total_timesteps  | 6551     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 364      |
|    fps              | 111      |
|    time_elapsed     | 59       |
|    total_timesteps  | 6614     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 368      |
|    fps              | 112      |
|    time_elapsed     | 59       |
|    total_timesteps  | 6688     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0198   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 372      |
|    fps              | 113      |
|    time_elapsed     | 59       |
|    total_timesteps  | 6759     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00953  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 376      |
|    fps              | 115      |
|    time_elapsed     | 59       |
|    total_timesteps  | 6839     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00945  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 380      |
|    fps              | 116      |
|    time_elapsed     | 59       |
|    total_timesteps  | 6910     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00977  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 384      |
|    fps              | 117      |
|    time_elapsed     | 59       |
|    total_timesteps  | 6982     |
----------------------------------
Eval num_timesteps=7000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 7000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00953  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 388      |
|    fps              | 110      |
|    time_elapsed     | 63       |
|    total_timesteps  | 7060     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00931  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 392      |
|    fps              | 111      |
|    time_elapsed     | 63       |
|    total_timesteps  | 7131     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00911  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 396      |
|    fps              | 113      |
|    time_elapsed     | 63       |
|    total_timesteps  | 7202     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00895  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 400      |
|    fps              | 114      |
|    time_elapsed     | 63       |
|    total_timesteps  | 7280     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00219 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 404      |
|    fps              | 115      |
|    time_elapsed     | 63       |
|    total_timesteps  | 7373     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00187 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 408      |
|    fps              | 116      |
|    time_elapsed     | 63       |
|    total_timesteps  | 7438     |
----------------------------------
Eval num_timesteps=7500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 7500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00214 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 412      |
|    fps              | 109      |
|    time_elapsed     | 68       |
|    total_timesteps  | 7500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0125  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 416      |
|    fps              | 110      |
|    time_elapsed     | 68       |
|    total_timesteps  | 7576     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 420      |
|    fps              | 111      |
|    time_elapsed     | 68       |
|    total_timesteps  | 7651     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00252 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 424      |
|    fps              | 112      |
|    time_elapsed     | 68       |
|    total_timesteps  | 7722     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00268 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 428      |
|    fps              | 113      |
|    time_elapsed     | 68       |
|    total_timesteps  | 7802     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00736  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 432      |
|    fps              | 114      |
|    time_elapsed     | 68       |
|    total_timesteps  | 7875     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00756  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 436      |
|    fps              | 115      |
|    time_elapsed     | 68       |
|    total_timesteps  | 7948     |
----------------------------------
Eval num_timesteps=8000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 8000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00864  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 440      |
|    fps              | 110      |
|    time_elapsed     | 72       |
|    total_timesteps  | 8011     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00828  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 444      |
|    fps              | 111      |
|    time_elapsed     | 72       |
|    total_timesteps  | 8092     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 448      |
|    fps              | 112      |
|    time_elapsed     | 72       |
|    total_timesteps  | 8164     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 452      |
|    fps              | 113      |
|    time_elapsed     | 72       |
|    total_timesteps  | 8244     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 456      |
|    fps              | 113      |
|    time_elapsed     | 72       |
|    total_timesteps  | 8314     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00752  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 460      |
|    fps              | 114      |
|    time_elapsed     | 72       |
|    total_timesteps  | 8389     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00349 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 464      |
|    fps              | 116      |
|    time_elapsed     | 72       |
|    total_timesteps  | 8477     |
----------------------------------
Eval num_timesteps=8500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 8500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00704  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 468      |
|    fps              | 109      |
|    time_elapsed     | 77       |
|    total_timesteps  | 8538     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0164   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 472      |
|    fps              | 110      |
|    time_elapsed     | 77       |
|    total_timesteps  | 8625     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 476      |
|    fps              | 111      |
|    time_elapsed     | 77       |
|    total_timesteps  | 8707     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 480      |
|    fps              | 112      |
|    time_elapsed     | 77       |
|    total_timesteps  | 8782     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 484      |
|    fps              | 113      |
|    time_elapsed     | 77       |
|    total_timesteps  | 8853     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 488      |
|    fps              | 114      |
|    time_elapsed     | 77       |
|    total_timesteps  | 8928     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0065   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 492      |
|    fps              | 115      |
|    time_elapsed     | 77       |
|    total_timesteps  | 8994     |
----------------------------------
Eval num_timesteps=9000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 9000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00666  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 496      |
|    fps              | 109      |
|    time_elapsed     | 82       |
|    total_timesteps  | 9061     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 500      |
|    fps              | 110      |
|    time_elapsed     | 82       |
|    total_timesteps  | 9123     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 504      |
|    fps              | 111      |
|    time_elapsed     | 82       |
|    total_timesteps  | 9200     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 508      |
|    fps              | 112      |
|    time_elapsed     | 82       |
|    total_timesteps  | 9263     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00734  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 512      |
|    fps              | 113      |
|    time_elapsed     | 82       |
|    total_timesteps  | 9342     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00239 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 516      |
|    fps              | 113      |
|    time_elapsed     | 82       |
|    total_timesteps  | 9411     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00814  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 520      |
|    fps              | 114      |
|    time_elapsed     | 82       |
|    total_timesteps  | 9473     |
----------------------------------
Eval num_timesteps=9500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 9500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00166 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 524      |
|    fps              | 109      |
|    time_elapsed     | 86       |
|    total_timesteps  | 9539     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00899  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 528      |
|    fps              | 110      |
|    time_elapsed     | 86       |
|    total_timesteps  | 9603     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00061 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 532      |
|    fps              | 111      |
|    time_elapsed     | 86       |
|    total_timesteps  | 9666     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00077 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 536      |
|    fps              | 112      |
|    time_elapsed     | 86       |
|    total_timesteps  | 9743     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00938  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 540      |
|    fps              | 112      |
|    time_elapsed     | 86       |
|    total_timesteps  | 9802     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 544      |
|    fps              | 113      |
|    time_elapsed     | 86       |
|    total_timesteps  | 9864     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 9e-05    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 548      |
|    fps              | 114      |
|    time_elapsed     | 86       |
|    total_timesteps  | 9937     |
----------------------------------
Eval num_timesteps=10000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 10000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00025  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 552      |
|    fps              | 109      |
|    time_elapsed     | 91       |
|    total_timesteps  | 10013    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 556      |
|    fps              | 110      |
|    time_elapsed     | 91       |
|    total_timesteps  | 10088    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 560      |
|    fps              | 111      |
|    time_elapsed     | 91       |
|    total_timesteps  | 10157    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0215   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 564      |
|    fps              | 111      |
|    time_elapsed     | 91       |
|    total_timesteps  | 10215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0112   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 568      |
|    fps              | 112      |
|    time_elapsed     | 91       |
|    total_timesteps  | 10283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.012    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 572      |
|    fps              | 113      |
|    time_elapsed     | 91       |
|    total_timesteps  | 10352    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0326   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 576      |
|    fps              | 113      |
|    time_elapsed     | 91       |
|    total_timesteps  | 10417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0328   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 580      |
|    fps              | 114      |
|    time_elapsed     | 91       |
|    total_timesteps  | 10487    |
----------------------------------
Eval num_timesteps=10500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 10500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0323   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 584      |
|    fps              | 110      |
|    time_elapsed     | 95       |
|    total_timesteps  | 10571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0323   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 588      |
|    fps              | 111      |
|    time_elapsed     | 95       |
|    total_timesteps  | 10647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0322   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 592      |
|    fps              | 111      |
|    time_elapsed     | 95       |
|    total_timesteps  | 10715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0316   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 596      |
|    fps              | 112      |
|    time_elapsed     | 95       |
|    total_timesteps  | 10797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0214   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 600      |
|    fps              | 113      |
|    time_elapsed     | 95       |
|    total_timesteps  | 10863    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0319   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 604      |
|    fps              | 113      |
|    time_elapsed     | 95       |
|    total_timesteps  | 10928    |
----------------------------------
Eval num_timesteps=11000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 11000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0314   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 608      |
|    fps              | 109      |
|    time_elapsed     | 100      |
|    total_timesteps  | 11003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0319   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 612      |
|    fps              | 110      |
|    time_elapsed     | 100      |
|    total_timesteps  | 11071    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0318   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 616      |
|    fps              | 111      |
|    time_elapsed     | 100      |
|    total_timesteps  | 11143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 620      |
|    fps              | 111      |
|    time_elapsed     | 100      |
|    total_timesteps  | 11228    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 624      |
|    fps              | 112      |
|    time_elapsed     | 100      |
|    total_timesteps  | 11299    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 628      |
|    fps              | 113      |
|    time_elapsed     | 100      |
|    total_timesteps  | 11366    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 632      |
|    fps              | 113      |
|    time_elapsed     | 100      |
|    total_timesteps  | 11438    |
----------------------------------
Eval num_timesteps=11500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 11500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 636      |
|    fps              | 109      |
|    time_elapsed     | 105      |
|    total_timesteps  | 11507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00042 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 640      |
|    fps              | 110      |
|    time_elapsed     | 105      |
|    total_timesteps  | 11588    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00078 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 644      |
|    fps              | 110      |
|    time_elapsed     | 105      |
|    total_timesteps  | 11659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00066 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 648      |
|    fps              | 111      |
|    time_elapsed     | 105      |
|    total_timesteps  | 11729    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00018 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 652      |
|    fps              | 112      |
|    time_elapsed     | 105      |
|    total_timesteps  | 11793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 656      |
|    fps              | 112      |
|    time_elapsed     | 105      |
|    total_timesteps  | 11868    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 660      |
|    fps              | 113      |
|    time_elapsed     | 105      |
|    total_timesteps  | 11943    |
----------------------------------
Eval num_timesteps=12000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 12000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 664      |
|    fps              | 109      |
|    time_elapsed     | 109      |
|    total_timesteps  | 12014    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0209  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 668      |
|    fps              | 110      |
|    time_elapsed     | 109      |
|    total_timesteps  | 12080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0316  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 672      |
|    fps              | 110      |
|    time_elapsed     | 109      |
|    total_timesteps  | 12167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.052   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 676      |
|    fps              | 111      |
|    time_elapsed     | 109      |
|    total_timesteps  | 12243    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0521  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 680      |
|    fps              | 112      |
|    time_elapsed     | 109      |
|    total_timesteps  | 12314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0518  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 684      |
|    fps              | 112      |
|    time_elapsed     | 109      |
|    total_timesteps  | 12391    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0515  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 688      |
|    fps              | 113      |
|    time_elapsed     | 109      |
|    total_timesteps  | 12460    |
----------------------------------
Eval num_timesteps=12500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 12500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0514  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 692      |
|    fps              | 109      |
|    time_elapsed     | 114      |
|    total_timesteps  | 12526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0508  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 696      |
|    fps              | 110      |
|    time_elapsed     | 114      |
|    total_timesteps  | 12593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0514  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 700      |
|    fps              | 111      |
|    time_elapsed     | 114      |
|    total_timesteps  | 12674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0614  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 704      |
|    fps              | 111      |
|    time_elapsed     | 114      |
|    total_timesteps  | 12737    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0611  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 708      |
|    fps              | 112      |
|    time_elapsed     | 114      |
|    total_timesteps  | 12806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0614  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 712      |
|    fps              | 112      |
|    time_elapsed     | 114      |
|    total_timesteps  | 12880    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0615  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 716      |
|    fps              | 113      |
|    time_elapsed     | 114      |
|    total_timesteps  | 12955    |
----------------------------------
Eval num_timesteps=13000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 13000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0608  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 720      |
|    fps              | 109      |
|    time_elapsed     | 118      |
|    total_timesteps  | 13022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0606  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 724      |
|    fps              | 110      |
|    time_elapsed     | 118      |
|    total_timesteps  | 13088    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0504  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 728      |
|    fps              | 110      |
|    time_elapsed     | 118      |
|    total_timesteps  | 13151    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0501  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 732      |
|    fps              | 111      |
|    time_elapsed     | 118      |
|    total_timesteps  | 13215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0506  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 736      |
|    fps              | 111      |
|    time_elapsed     | 118      |
|    total_timesteps  | 13298    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0502  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 740      |
|    fps              | 112      |
|    time_elapsed     | 118      |
|    total_timesteps  | 13367    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0405  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 744      |
|    fps              | 113      |
|    time_elapsed     | 118      |
|    total_timesteps  | 13446    |
----------------------------------
Eval num_timesteps=13500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 13500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0407  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 748      |
|    fps              | 109      |
|    time_elapsed     | 123      |
|    total_timesteps  | 13521    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0311  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 752      |
|    fps              | 110      |
|    time_elapsed     | 123      |
|    total_timesteps  | 13595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0307  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 756      |
|    fps              | 110      |
|    time_elapsed     | 123      |
|    total_timesteps  | 13661    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 760      |
|    fps              | 111      |
|    time_elapsed     | 123      |
|    total_timesteps  | 13731    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0308  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 764      |
|    fps              | 111      |
|    time_elapsed     | 123      |
|    total_timesteps  | 13810    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0309  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 768      |
|    fps              | 112      |
|    time_elapsed     | 123      |
|    total_timesteps  | 13878    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 772      |
|    fps              | 112      |
|    time_elapsed     | 123      |
|    total_timesteps  | 13958    |
----------------------------------
Eval num_timesteps=14000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 14000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0304  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 776      |
|    fps              | 109      |
|    time_elapsed     | 127      |
|    total_timesteps  | 14028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0303  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 780      |
|    fps              | 110      |
|    time_elapsed     | 127      |
|    total_timesteps  | 14096    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.03    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 784      |
|    fps              | 110      |
|    time_elapsed     | 127      |
|    total_timesteps  | 14166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.03    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 788      |
|    fps              | 111      |
|    time_elapsed     | 127      |
|    total_timesteps  | 14236    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0299  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 792      |
|    fps              | 111      |
|    time_elapsed     | 127      |
|    total_timesteps  | 14298    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.03    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 796      |
|    fps              | 112      |
|    time_elapsed     | 127      |
|    total_timesteps  | 14369    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.03    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 800      |
|    fps              | 112      |
|    time_elapsed     | 128      |
|    total_timesteps  | 14449    |
----------------------------------
Eval num_timesteps=14500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 14500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 804      |
|    fps              | 109      |
|    time_elapsed     | 132      |
|    total_timesteps  | 14528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 808      |
|    fps              | 110      |
|    time_elapsed     | 132      |
|    total_timesteps  | 14610    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 812      |
|    fps              | 110      |
|    time_elapsed     | 132      |
|    total_timesteps  | 14688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 816      |
|    fps              | 111      |
|    time_elapsed     | 132      |
|    total_timesteps  | 14764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 820      |
|    fps              | 111      |
|    time_elapsed     | 132      |
|    total_timesteps  | 14834    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 824      |
|    fps              | 112      |
|    time_elapsed     | 132      |
|    total_timesteps  | 14902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 828      |
|    fps              | 112      |
|    time_elapsed     | 132      |
|    total_timesteps  | 14967    |
----------------------------------
Eval num_timesteps=15000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 15000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0016  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 832      |
|    fps              | 109      |
|    time_elapsed     | 136      |
|    total_timesteps  | 15031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00128 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 836      |
|    fps              | 110      |
|    time_elapsed     | 136      |
|    total_timesteps  | 15106    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00128 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 840      |
|    fps              | 110      |
|    time_elapsed     | 136      |
|    total_timesteps  | 15175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.011   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 844      |
|    fps              | 111      |
|    time_elapsed     | 136      |
|    total_timesteps  | 15248    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 848      |
|    fps              | 111      |
|    time_elapsed     | 136      |
|    total_timesteps  | 15328    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0215  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 852      |
|    fps              | 112      |
|    time_elapsed     | 136      |
|    total_timesteps  | 15409    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.022   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 856      |
|    fps              | 113      |
|    time_elapsed     | 136      |
|    total_timesteps  | 15486    |
----------------------------------
Eval num_timesteps=15500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 15500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0318  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 860      |
|    fps              | 110      |
|    time_elapsed     | 141      |
|    total_timesteps  | 15551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0311  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 864      |
|    fps              | 110      |
|    time_elapsed     | 141      |
|    total_timesteps  | 15614    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0208  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 868      |
|    fps              | 110      |
|    time_elapsed     | 141      |
|    total_timesteps  | 15675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -2e-05   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 872      |
|    fps              | 111      |
|    time_elapsed     | 141      |
|    total_timesteps  | 15735    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -2e-05   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 876      |
|    fps              | 111      |
|    time_elapsed     | 141      |
|    total_timesteps  | 15805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0005  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 880      |
|    fps              | 112      |
|    time_elapsed     | 141      |
|    total_timesteps  | 15885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00942  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 884      |
|    fps              | 112      |
|    time_elapsed     | 141      |
|    total_timesteps  | 15957    |
----------------------------------
Eval num_timesteps=16000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 16000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00962  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 888      |
|    fps              | 109      |
|    time_elapsed     | 145      |
|    total_timesteps  | 16022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00938  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 892      |
|    fps              | 110      |
|    time_elapsed     | 146      |
|    total_timesteps  | 16090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00914  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 896      |
|    fps              | 110      |
|    time_elapsed     | 146      |
|    total_timesteps  | 16167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00938  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 900      |
|    fps              | 111      |
|    time_elapsed     | 146      |
|    total_timesteps  | 16241    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00035 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 904      |
|    fps              | 111      |
|    time_elapsed     | 146      |
|    total_timesteps  | 16313    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00017  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 908      |
|    fps              | 112      |
|    time_elapsed     | 146      |
|    total_timesteps  | 16382    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00041  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 912      |
|    fps              | 112      |
|    time_elapsed     | 146      |
|    total_timesteps  | 16454    |
----------------------------------
Eval num_timesteps=16500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 16500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00915 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 916      |
|    fps              | 109      |
|    time_elapsed     | 150      |
|    total_timesteps  | 16519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 920      |
|    fps              | 110      |
|    time_elapsed     | 150      |
|    total_timesteps  | 16587    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0112   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 924      |
|    fps              | 110      |
|    time_elapsed     | 150      |
|    total_timesteps  | 16649    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00104  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 928      |
|    fps              | 110      |
|    time_elapsed     | 150      |
|    total_timesteps  | 16717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 7e-05    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 932      |
|    fps              | 111      |
|    time_elapsed     | 150      |
|    total_timesteps  | 16805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00015  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 936      |
|    fps              | 111      |
|    time_elapsed     | 150      |
|    total_timesteps  | 16878    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00033 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 940      |
|    fps              | 112      |
|    time_elapsed     | 150      |
|    total_timesteps  | 16959    |
----------------------------------
Eval num_timesteps=17000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 17000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00021 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 944      |
|    fps              | 109      |
|    time_elapsed     | 155      |
|    total_timesteps  | 17029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 948      |
|    fps              | 109      |
|    time_elapsed     | 155      |
|    total_timesteps  | 17090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 952      |
|    fps              | 110      |
|    time_elapsed     | 155      |
|    total_timesteps  | 17193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 956      |
|    fps              | 111      |
|    time_elapsed     | 155      |
|    total_timesteps  | 17271    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 960      |
|    fps              | 111      |
|    time_elapsed     | 155      |
|    total_timesteps  | 17347    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 964      |
|    fps              | 112      |
|    time_elapsed     | 155      |
|    total_timesteps  | 17428    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 968      |
|    fps              | 112      |
|    time_elapsed     | 155      |
|    total_timesteps  | 17496    |
----------------------------------
Eval num_timesteps=17500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 17500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00803  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 972      |
|    fps              | 109      |
|    time_elapsed     | 159      |
|    total_timesteps  | 17561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00835  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 976      |
|    fps              | 110      |
|    time_elapsed     | 159      |
|    total_timesteps  | 17623    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00867  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 980      |
|    fps              | 110      |
|    time_elapsed     | 159      |
|    total_timesteps  | 17695    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00879  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 984      |
|    fps              | 111      |
|    time_elapsed     | 159      |
|    total_timesteps  | 17764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00867  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 988      |
|    fps              | 111      |
|    time_elapsed     | 160      |
|    total_timesteps  | 17832    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00819  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 992      |
|    fps              | 111      |
|    time_elapsed     | 160      |
|    total_timesteps  | 17912    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00835  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 996      |
|    fps              | 112      |
|    time_elapsed     | 160      |
|    total_timesteps  | 17985    |
----------------------------------
Eval num_timesteps=18000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 18000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00859  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1000     |
|    fps              | 109      |
|    time_elapsed     | 164      |
|    total_timesteps  | 18053    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00859  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1004     |
|    fps              | 110      |
|    time_elapsed     | 164      |
|    total_timesteps  | 18125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00863  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1008     |
|    fps              | 110      |
|    time_elapsed     | 164      |
|    total_timesteps  | 18193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00883  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1012     |
|    fps              | 111      |
|    time_elapsed     | 164      |
|    total_timesteps  | 18260    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00843  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1016     |
|    fps              | 111      |
|    time_elapsed     | 164      |
|    total_timesteps  | 18335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00889  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1020     |
|    fps              | 111      |
|    time_elapsed     | 164      |
|    total_timesteps  | 18392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00861  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1024     |
|    fps              | 112      |
|    time_elapsed     | 164      |
|    total_timesteps  | 18461    |
----------------------------------
Eval num_timesteps=18500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 18500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00869  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1028     |
|    fps              | 109      |
|    time_elapsed     | 168      |
|    total_timesteps  | 18527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00043 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1032     |
|    fps              | 110      |
|    time_elapsed     | 168      |
|    total_timesteps  | 18593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00055 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1036     |
|    fps              | 110      |
|    time_elapsed     | 168      |
|    total_timesteps  | 18669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00051 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1040     |
|    fps              | 111      |
|    time_elapsed     | 168      |
|    total_timesteps  | 18749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00087 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1044     |
|    fps              | 111      |
|    time_elapsed     | 168      |
|    total_timesteps  | 18828    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1048     |
|    fps              | 112      |
|    time_elapsed     | 168      |
|    total_timesteps  | 18902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00976 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1052     |
|    fps              | 112      |
|    time_elapsed     | 168      |
|    total_timesteps  | 18963    |
----------------------------------
Eval num_timesteps=19000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 19000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0094  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1056     |
|    fps              | 109      |
|    time_elapsed     | 173      |
|    total_timesteps  | 19032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1060     |
|    fps              | 110      |
|    time_elapsed     | 173      |
|    total_timesteps  | 19129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1064     |
|    fps              | 110      |
|    time_elapsed     | 173      |
|    total_timesteps  | 19196    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0198  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1068     |
|    fps              | 111      |
|    time_elapsed     | 173      |
|    total_timesteps  | 19266    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0299  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1072     |
|    fps              | 111      |
|    time_elapsed     | 173      |
|    total_timesteps  | 19334    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0305  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1076     |
|    fps              | 111      |
|    time_elapsed     | 173      |
|    total_timesteps  | 19412    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1080     |
|    fps              | 112      |
|    time_elapsed     | 173      |
|    total_timesteps  | 19483    |
----------------------------------
Eval num_timesteps=19500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 19500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.031   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1084     |
|    fps              | 109      |
|    time_elapsed     | 177      |
|    total_timesteps  | 19564    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0315  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1088     |
|    fps              | 110      |
|    time_elapsed     | 177      |
|    total_timesteps  | 19646    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0314  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1092     |
|    fps              | 110      |
|    time_elapsed     | 177      |
|    total_timesteps  | 19722    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0315  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1096     |
|    fps              | 111      |
|    time_elapsed     | 177      |
|    total_timesteps  | 19798    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1100     |
|    fps              | 111      |
|    time_elapsed     | 177      |
|    total_timesteps  | 19864    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1104     |
|    fps              | 112      |
|    time_elapsed     | 178      |
|    total_timesteps  | 19939    |
----------------------------------
Eval num_timesteps=20000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 20000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1108     |
|    fps              | 109      |
|    time_elapsed     | 182      |
|    total_timesteps  | 20015    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00157 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1112     |
|    fps              | 109      |
|    time_elapsed     | 182      |
|    total_timesteps  | 20075    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00141 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1116     |
|    fps              | 110      |
|    time_elapsed     | 182      |
|    total_timesteps  | 20146    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0216  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1120     |
|    fps              | 110      |
|    time_elapsed     | 182      |
|    total_timesteps  | 20208    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1124     |
|    fps              | 110      |
|    time_elapsed     | 182      |
|    total_timesteps  | 20270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1128     |
|    fps              | 111      |
|    time_elapsed     | 182      |
|    total_timesteps  | 20342    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1132     |
|    fps              | 111      |
|    time_elapsed     | 182      |
|    total_timesteps  | 20404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00101 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1136     |
|    fps              | 111      |
|    time_elapsed     | 182      |
|    total_timesteps  | 20470    |
----------------------------------
Eval num_timesteps=20500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 20500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00109 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1140     |
|    fps              | 109      |
|    time_elapsed     | 187      |
|    total_timesteps  | 20552    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00976  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1144     |
|    fps              | 109      |
|    time_elapsed     | 187      |
|    total_timesteps  | 20610    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1148     |
|    fps              | 110      |
|    time_elapsed     | 187      |
|    total_timesteps  | 20686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00945  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1152     |
|    fps              | 110      |
|    time_elapsed     | 187      |
|    total_timesteps  | 20753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00929  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1156     |
|    fps              | 110      |
|    time_elapsed     | 187      |
|    total_timesteps  | 20826    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00989  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1160     |
|    fps              | 111      |
|    time_elapsed     | 187      |
|    total_timesteps  | 20908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1164     |
|    fps              | 111      |
|    time_elapsed     | 187      |
|    total_timesteps  | 20969    |
----------------------------------
Eval num_timesteps=21000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 21000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0198   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1168     |
|    fps              | 109      |
|    time_elapsed     | 192      |
|    total_timesteps  | 21047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1172     |
|    fps              | 109      |
|    time_elapsed     | 192      |
|    total_timesteps  | 21125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1176     |
|    fps              | 110      |
|    time_elapsed     | 192      |
|    total_timesteps  | 21197    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0193   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1180     |
|    fps              | 110      |
|    time_elapsed     | 192      |
|    total_timesteps  | 21275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0199   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1184     |
|    fps              | 110      |
|    time_elapsed     | 192      |
|    total_timesteps  | 21343    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0198   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1188     |
|    fps              | 111      |
|    time_elapsed     | 192      |
|    total_timesteps  | 21426    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1192     |
|    fps              | 111      |
|    time_elapsed     | 192      |
|    total_timesteps  | 21493    |
----------------------------------
Eval num_timesteps=21500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 21500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1196     |
|    fps              | 109      |
|    time_elapsed     | 197      |
|    total_timesteps  | 21570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0199   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1200     |
|    fps              | 109      |
|    time_elapsed     | 197      |
|    total_timesteps  | 21642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00991  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1204     |
|    fps              | 110      |
|    time_elapsed     | 197      |
|    total_timesteps  | 21717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00987  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1208     |
|    fps              | 110      |
|    time_elapsed     | 197      |
|    total_timesteps  | 21794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00944  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1212     |
|    fps              | 110      |
|    time_elapsed     | 197      |
|    total_timesteps  | 21865    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0295   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1216     |
|    fps              | 111      |
|    time_elapsed     | 197      |
|    total_timesteps  | 21935    |
----------------------------------
Eval num_timesteps=22000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 22000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1220     |
|    fps              | 109      |
|    time_elapsed     | 202      |
|    total_timesteps  | 22024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1224     |
|    fps              | 109      |
|    time_elapsed     | 202      |
|    total_timesteps  | 22091    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1228     |
|    fps              | 109      |
|    time_elapsed     | 202      |
|    total_timesteps  | 22167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1232     |
|    fps              | 110      |
|    time_elapsed     | 202      |
|    total_timesteps  | 22240    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1236     |
|    fps              | 110      |
|    time_elapsed     | 202      |
|    total_timesteps  | 22310    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1240     |
|    fps              | 110      |
|    time_elapsed     | 202      |
|    total_timesteps  | 22386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1244     |
|    fps              | 111      |
|    time_elapsed     | 202      |
|    total_timesteps  | 22459    |
----------------------------------
Eval num_timesteps=22500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 22500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0071   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1248     |
|    fps              | 108      |
|    time_elapsed     | 207      |
|    total_timesteps  | 22534    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1252     |
|    fps              | 109      |
|    time_elapsed     | 207      |
|    total_timesteps  | 22604    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1256     |
|    fps              | 109      |
|    time_elapsed     | 207      |
|    total_timesteps  | 22668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1260     |
|    fps              | 109      |
|    time_elapsed     | 207      |
|    total_timesteps  | 22738    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1264     |
|    fps              | 110      |
|    time_elapsed     | 207      |
|    total_timesteps  | 22809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1268     |
|    fps              | 110      |
|    time_elapsed     | 207      |
|    total_timesteps  | 22881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1272     |
|    fps              | 110      |
|    time_elapsed     | 207      |
|    total_timesteps  | 22957    |
----------------------------------
Eval num_timesteps=23000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 23000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1276     |
|    fps              | 108      |
|    time_elapsed     | 212      |
|    total_timesteps  | 23044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1280     |
|    fps              | 108      |
|    time_elapsed     | 212      |
|    total_timesteps  | 23118    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1284     |
|    fps              | 109      |
|    time_elapsed     | 212      |
|    total_timesteps  | 23183    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1288     |
|    fps              | 109      |
|    time_elapsed     | 212      |
|    total_timesteps  | 23247    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1292     |
|    fps              | 109      |
|    time_elapsed     | 212      |
|    total_timesteps  | 23313    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1296     |
|    fps              | 110      |
|    time_elapsed     | 212      |
|    total_timesteps  | 23376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00881  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1300     |
|    fps              | 110      |
|    time_elapsed     | 212      |
|    total_timesteps  | 23448    |
----------------------------------
Eval num_timesteps=23500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 23500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1304     |
|    fps              | 108      |
|    time_elapsed     | 216      |
|    total_timesteps  | 23526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0286   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1308     |
|    fps              | 108      |
|    time_elapsed     | 216      |
|    total_timesteps  | 23605    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1312     |
|    fps              | 109      |
|    time_elapsed     | 216      |
|    total_timesteps  | 23674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00876  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1316     |
|    fps              | 109      |
|    time_elapsed     | 216      |
|    total_timesteps  | 23743    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00959  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1320     |
|    fps              | 109      |
|    time_elapsed     | 216      |
|    total_timesteps  | 23812    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0299   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1324     |
|    fps              | 110      |
|    time_elapsed     | 216      |
|    total_timesteps  | 23871    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0193   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1328     |
|    fps              | 110      |
|    time_elapsed     | 216      |
|    total_timesteps  | 23961    |
----------------------------------
Eval num_timesteps=24000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 24000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1332     |
|    fps              | 108      |
|    time_elapsed     | 221      |
|    total_timesteps  | 24027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1336     |
|    fps              | 108      |
|    time_elapsed     | 221      |
|    total_timesteps  | 24097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0299   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1340     |
|    fps              | 109      |
|    time_elapsed     | 221      |
|    total_timesteps  | 24167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1344     |
|    fps              | 109      |
|    time_elapsed     | 221      |
|    total_timesteps  | 24236    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1348     |
|    fps              | 109      |
|    time_elapsed     | 221      |
|    total_timesteps  | 24300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1352     |
|    fps              | 109      |
|    time_elapsed     | 221      |
|    total_timesteps  | 24369    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0402   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1356     |
|    fps              | 110      |
|    time_elapsed     | 221      |
|    total_timesteps  | 24441    |
----------------------------------
Eval num_timesteps=24500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 24500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0406   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1360     |
|    fps              | 108      |
|    time_elapsed     | 226      |
|    total_timesteps  | 24502    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0408   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1364     |
|    fps              | 108      |
|    time_elapsed     | 226      |
|    total_timesteps  | 24567    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0408   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1368     |
|    fps              | 108      |
|    time_elapsed     | 226      |
|    total_timesteps  | 24639    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0313   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1372     |
|    fps              | 109      |
|    time_elapsed     | 226      |
|    total_timesteps  | 24701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0323   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1376     |
|    fps              | 109      |
|    time_elapsed     | 226      |
|    total_timesteps  | 24764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0419   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1380     |
|    fps              | 109      |
|    time_elapsed     | 226      |
|    total_timesteps  | 24847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0621   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1384     |
|    fps              | 109      |
|    time_elapsed     | 226      |
|    total_timesteps  | 24908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0616   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1388     |
|    fps              | 110      |
|    time_elapsed     | 226      |
|    total_timesteps  | 24984    |
----------------------------------
Eval num_timesteps=25000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 25000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0608   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1392     |
|    fps              | 108      |
|    time_elapsed     | 231      |
|    total_timesteps  | 25070    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0605   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1396     |
|    fps              | 108      |
|    time_elapsed     | 231      |
|    total_timesteps  | 25140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0706   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1400     |
|    fps              | 109      |
|    time_elapsed     | 231      |
|    total_timesteps  | 25209    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0505   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1404     |
|    fps              | 109      |
|    time_elapsed     | 231      |
|    total_timesteps  | 25289    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0612   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1408     |
|    fps              | 109      |
|    time_elapsed     | 231      |
|    total_timesteps  | 25352    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0607   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1412     |
|    fps              | 110      |
|    time_elapsed     | 231      |
|    total_timesteps  | 25432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0609   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1416     |
|    fps              | 110      |
|    time_elapsed     | 231      |
|    total_timesteps  | 25497    |
----------------------------------
Eval num_timesteps=25500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 25500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0509   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1420     |
|    fps              | 108      |
|    time_elapsed     | 235      |
|    total_timesteps  | 25565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0306   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1424     |
|    fps              | 108      |
|    time_elapsed     | 235      |
|    total_timesteps  | 25633    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0308   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1428     |
|    fps              | 108      |
|    time_elapsed     | 235      |
|    total_timesteps  | 25718    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0408   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1432     |
|    fps              | 109      |
|    time_elapsed     | 235      |
|    total_timesteps  | 25782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.051    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1436     |
|    fps              | 109      |
|    time_elapsed     | 236      |
|    total_timesteps  | 25848    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0413   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1440     |
|    fps              | 109      |
|    time_elapsed     | 236      |
|    total_timesteps  | 25911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0415   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1444     |
|    fps              | 110      |
|    time_elapsed     | 236      |
|    total_timesteps  | 25975    |
----------------------------------
Eval num_timesteps=26000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 26000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0414   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1448     |
|    fps              | 108      |
|    time_elapsed     | 240      |
|    total_timesteps  | 26041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0413   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1452     |
|    fps              | 108      |
|    time_elapsed     | 240      |
|    total_timesteps  | 26113    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0517   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1456     |
|    fps              | 108      |
|    time_elapsed     | 240      |
|    total_timesteps  | 26174    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0516   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1460     |
|    fps              | 108      |
|    time_elapsed     | 240      |
|    total_timesteps  | 26238    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0506   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1464     |
|    fps              | 109      |
|    time_elapsed     | 240      |
|    total_timesteps  | 26327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0507   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1468     |
|    fps              | 109      |
|    time_elapsed     | 240      |
|    total_timesteps  | 26398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0604   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1472     |
|    fps              | 109      |
|    time_elapsed     | 240      |
|    total_timesteps  | 26466    |
----------------------------------
Eval num_timesteps=26500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 26500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0603   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1476     |
|    fps              | 108      |
|    time_elapsed     | 245      |
|    total_timesteps  | 26532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0504   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1480     |
|    fps              | 108      |
|    time_elapsed     | 245      |
|    total_timesteps  | 26613    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0302   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1484     |
|    fps              | 108      |
|    time_elapsed     | 245      |
|    total_timesteps  | 26678    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0306   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1488     |
|    fps              | 108      |
|    time_elapsed     | 245      |
|    total_timesteps  | 26746    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.031    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1492     |
|    fps              | 109      |
|    time_elapsed     | 245      |
|    total_timesteps  | 26822    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0309   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1496     |
|    fps              | 109      |
|    time_elapsed     | 245      |
|    total_timesteps  | 26894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0302   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1500     |
|    fps              | 109      |
|    time_elapsed     | 245      |
|    total_timesteps  | 26979    |
----------------------------------
Eval num_timesteps=27000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 27000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1504     |
|    fps              | 108      |
|    time_elapsed     | 250      |
|    total_timesteps  | 27052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1508     |
|    fps              | 108      |
|    time_elapsed     | 250      |
|    total_timesteps  | 27138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1512     |
|    fps              | 108      |
|    time_elapsed     | 250      |
|    total_timesteps  | 27207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1516     |
|    fps              | 108      |
|    time_elapsed     | 250      |
|    total_timesteps  | 27280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1520     |
|    fps              | 109      |
|    time_elapsed     | 250      |
|    total_timesteps  | 27378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1524     |
|    fps              | 109      |
|    time_elapsed     | 250      |
|    total_timesteps  | 27447    |
----------------------------------
Eval num_timesteps=27500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 27500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1528     |
|    fps              | 107      |
|    time_elapsed     | 255      |
|    total_timesteps  | 27523    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00831  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1532     |
|    fps              | 108      |
|    time_elapsed     | 255      |
|    total_timesteps  | 27599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00196 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1536     |
|    fps              | 108      |
|    time_elapsed     | 255      |
|    total_timesteps  | 27672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0024  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1540     |
|    fps              | 108      |
|    time_elapsed     | 255      |
|    total_timesteps  | 27746    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00312 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1544     |
|    fps              | 108      |
|    time_elapsed     | 255      |
|    total_timesteps  | 27828    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00601  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1548     |
|    fps              | 109      |
|    time_elapsed     | 255      |
|    total_timesteps  | 27916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00372 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1552     |
|    fps              | 109      |
|    time_elapsed     | 255      |
|    total_timesteps  | 27981    |
----------------------------------
Eval num_timesteps=28000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 28000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1556     |
|    fps              | 107      |
|    time_elapsed     | 260      |
|    total_timesteps  | 28050    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1560     |
|    fps              | 108      |
|    time_elapsed     | 260      |
|    total_timesteps  | 28122    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1564     |
|    fps              | 108      |
|    time_elapsed     | 260      |
|    total_timesteps  | 28190    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0336  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1568     |
|    fps              | 108      |
|    time_elapsed     | 260      |
|    total_timesteps  | 28262    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0447  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1572     |
|    fps              | 108      |
|    time_elapsed     | 260      |
|    total_timesteps  | 28359    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1576     |
|    fps              | 109      |
|    time_elapsed     | 260      |
|    total_timesteps  | 28416    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0339  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1580     |
|    fps              | 109      |
|    time_elapsed     | 260      |
|    total_timesteps  | 28485    |
----------------------------------
Eval num_timesteps=28500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 28500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0348  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1584     |
|    fps              | 107      |
|    time_elapsed     | 265      |
|    total_timesteps  | 28573    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0349  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1588     |
|    fps              | 108      |
|    time_elapsed     | 265      |
|    total_timesteps  | 28643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0346  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1592     |
|    fps              | 108      |
|    time_elapsed     | 265      |
|    total_timesteps  | 28713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0343  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1596     |
|    fps              | 108      |
|    time_elapsed     | 265      |
|    total_timesteps  | 28777    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0438  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1600     |
|    fps              | 108      |
|    time_elapsed     | 265      |
|    total_timesteps  | 28848    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0336  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1604     |
|    fps              | 109      |
|    time_elapsed     | 265      |
|    total_timesteps  | 28917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0428  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1608     |
|    fps              | 109      |
|    time_elapsed     | 265      |
|    total_timesteps  | 28984    |
----------------------------------
Eval num_timesteps=29000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 29000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0427  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1612     |
|    fps              | 107      |
|    time_elapsed     | 269      |
|    total_timesteps  | 29051    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0424  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1616     |
|    fps              | 107      |
|    time_elapsed     | 270      |
|    total_timesteps  | 29115    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0419  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1620     |
|    fps              | 108      |
|    time_elapsed     | 270      |
|    total_timesteps  | 29202    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0423  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1624     |
|    fps              | 108      |
|    time_elapsed     | 270      |
|    total_timesteps  | 29280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0419  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1628     |
|    fps              | 108      |
|    time_elapsed     | 270      |
|    total_timesteps  | 29345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0415  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1632     |
|    fps              | 108      |
|    time_elapsed     | 270      |
|    total_timesteps  | 29413    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0415  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1636     |
|    fps              | 109      |
|    time_elapsed     | 270      |
|    total_timesteps  | 29485    |
----------------------------------
Eval num_timesteps=29500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 29500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0411  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1640     |
|    fps              | 107      |
|    time_elapsed     | 275      |
|    total_timesteps  | 29550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.041   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1644     |
|    fps              | 107      |
|    time_elapsed     | 275      |
|    total_timesteps  | 29628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0407  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1648     |
|    fps              | 107      |
|    time_elapsed     | 275      |
|    total_timesteps  | 29708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1652     |
|    fps              | 108      |
|    time_elapsed     | 275      |
|    total_timesteps  | 29772    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1656     |
|    fps              | 108      |
|    time_elapsed     | 275      |
|    total_timesteps  | 29836    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0209  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1660     |
|    fps              | 108      |
|    time_elapsed     | 275      |
|    total_timesteps  | 29920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1664     |
|    fps              | 108      |
|    time_elapsed     | 275      |
|    total_timesteps  | 29997    |
----------------------------------
Eval num_timesteps=30000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 30000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1668     |
|    fps              | 107      |
|    time_elapsed     | 279      |
|    total_timesteps  | 30065    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1672     |
|    fps              | 107      |
|    time_elapsed     | 279      |
|    total_timesteps  | 30138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1676     |
|    fps              | 107      |
|    time_elapsed     | 279      |
|    total_timesteps  | 30207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1680     |
|    fps              | 108      |
|    time_elapsed     | 279      |
|    total_timesteps  | 30285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0203  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1684     |
|    fps              | 108      |
|    time_elapsed     | 280      |
|    total_timesteps  | 30356    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0209  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1688     |
|    fps              | 108      |
|    time_elapsed     | 280      |
|    total_timesteps  | 30442    |
----------------------------------
Eval num_timesteps=30500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 30500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0111  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1692     |
|    fps              | 107      |
|    time_elapsed     | 284      |
|    total_timesteps  | 30517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00143 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1696     |
|    fps              | 107      |
|    time_elapsed     | 284      |
|    total_timesteps  | 30588    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00147 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1700     |
|    fps              | 107      |
|    time_elapsed     | 284      |
|    total_timesteps  | 30660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1704     |
|    fps              | 107      |
|    time_elapsed     | 284      |
|    total_timesteps  | 30723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1708     |
|    fps              | 108      |
|    time_elapsed     | 284      |
|    total_timesteps  | 30789    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1712     |
|    fps              | 108      |
|    time_elapsed     | 284      |
|    total_timesteps  | 30857    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1716     |
|    fps              | 108      |
|    time_elapsed     | 284      |
|    total_timesteps  | 30938    |
----------------------------------
Eval num_timesteps=31000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 31000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00133 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1720     |
|    fps              | 107      |
|    time_elapsed     | 289      |
|    total_timesteps  | 31010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00911  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1724     |
|    fps              | 107      |
|    time_elapsed     | 289      |
|    total_timesteps  | 31077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00895  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1728     |
|    fps              | 107      |
|    time_elapsed     | 289      |
|    total_timesteps  | 31146    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00907  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1732     |
|    fps              | 107      |
|    time_elapsed     | 289      |
|    total_timesteps  | 31211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00915  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1736     |
|    fps              | 107      |
|    time_elapsed     | 289      |
|    total_timesteps  | 31281    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00895  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1740     |
|    fps              | 108      |
|    time_elapsed     | 289      |
|    total_timesteps  | 31351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0295   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1744     |
|    fps              | 108      |
|    time_elapsed     | 289      |
|    total_timesteps  | 31417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1748     |
|    fps              | 108      |
|    time_elapsed     | 289      |
|    total_timesteps  | 31485    |
----------------------------------
Eval num_timesteps=31500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 31500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1752     |
|    fps              | 107      |
|    time_elapsed     | 294      |
|    total_timesteps  | 31552    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1756     |
|    fps              | 107      |
|    time_elapsed     | 294      |
|    total_timesteps  | 31622    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0404   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1760     |
|    fps              | 107      |
|    time_elapsed     | 294      |
|    total_timesteps  | 31686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0502   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1764     |
|    fps              | 107      |
|    time_elapsed     | 294      |
|    total_timesteps  | 31769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0502   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1768     |
|    fps              | 108      |
|    time_elapsed     | 294      |
|    total_timesteps  | 31837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1772     |
|    fps              | 108      |
|    time_elapsed     | 294      |
|    total_timesteps  | 31913    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0401   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1776     |
|    fps              | 108      |
|    time_elapsed     | 294      |
|    total_timesteps  | 31980    |
----------------------------------
Eval num_timesteps=32000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 32000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0402   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1780     |
|    fps              | 107      |
|    time_elapsed     | 299      |
|    total_timesteps  | 32055    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0402   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1784     |
|    fps              | 107      |
|    time_elapsed     | 299      |
|    total_timesteps  | 32128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0512   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1788     |
|    fps              | 107      |
|    time_elapsed     | 299      |
|    total_timesteps  | 32189    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0516   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1792     |
|    fps              | 107      |
|    time_elapsed     | 299      |
|    total_timesteps  | 32252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0417   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1796     |
|    fps              | 107      |
|    time_elapsed     | 299      |
|    total_timesteps  | 32321    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0419   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1800     |
|    fps              | 108      |
|    time_elapsed     | 299      |
|    total_timesteps  | 32388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0417   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1804     |
|    fps              | 108      |
|    time_elapsed     | 299      |
|    total_timesteps  | 32457    |
----------------------------------
Eval num_timesteps=32500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 32500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0408   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1808     |
|    fps              | 106      |
|    time_elapsed     | 304      |
|    total_timesteps  | 32544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0404   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1812     |
|    fps              | 107      |
|    time_elapsed     | 304      |
|    total_timesteps  | 32623    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0509   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1816     |
|    fps              | 107      |
|    time_elapsed     | 304      |
|    total_timesteps  | 32691    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0412   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1820     |
|    fps              | 107      |
|    time_elapsed     | 304      |
|    total_timesteps  | 32757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0308   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1824     |
|    fps              | 107      |
|    time_elapsed     | 304      |
|    total_timesteps  | 32832    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.031    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1828     |
|    fps              | 108      |
|    time_elapsed     | 304      |
|    total_timesteps  | 32897    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0309   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1832     |
|    fps              | 108      |
|    time_elapsed     | 304      |
|    total_timesteps  | 32964    |
----------------------------------
Eval num_timesteps=33000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 33000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0412   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1836     |
|    fps              | 106      |
|    time_elapsed     | 309      |
|    total_timesteps  | 33027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0408   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1840     |
|    fps              | 106      |
|    time_elapsed     | 309      |
|    total_timesteps  | 33107    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1844     |
|    fps              | 107      |
|    time_elapsed     | 309      |
|    total_timesteps  | 33179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00052  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1848     |
|    fps              | 107      |
|    time_elapsed     | 309      |
|    total_timesteps  | 33248    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0004   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1852     |
|    fps              | 107      |
|    time_elapsed     | 309      |
|    total_timesteps  | 33318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0104   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1856     |
|    fps              | 107      |
|    time_elapsed     | 309      |
|    total_timesteps  | 33389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00024  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1860     |
|    fps              | 108      |
|    time_elapsed     | 309      |
|    total_timesteps  | 33456    |
----------------------------------
Eval num_timesteps=33500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 33500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00936 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1864     |
|    fps              | 106      |
|    time_elapsed     | 314      |
|    total_timesteps  | 33529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00936 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1868     |
|    fps              | 106      |
|    time_elapsed     | 314      |
|    total_timesteps  | 33597    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0013   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1872     |
|    fps              | 107      |
|    time_elapsed     | 314      |
|    total_timesteps  | 33657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00138  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1876     |
|    fps              | 107      |
|    time_elapsed     | 314      |
|    total_timesteps  | 33722    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00178  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1880     |
|    fps              | 107      |
|    time_elapsed     | 314      |
|    total_timesteps  | 33787    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00174  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1884     |
|    fps              | 107      |
|    time_elapsed     | 314      |
|    total_timesteps  | 33861    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00911 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1888     |
|    fps              | 107      |
|    time_elapsed     | 314      |
|    total_timesteps  | 33943    |
----------------------------------
Eval num_timesteps=34000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 34000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00904 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1892     |
|    fps              | 106      |
|    time_elapsed     | 319      |
|    total_timesteps  | 34004    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00085  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1896     |
|    fps              | 106      |
|    time_elapsed     | 319      |
|    total_timesteps  | 34076    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00089  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1900     |
|    fps              | 106      |
|    time_elapsed     | 319      |
|    total_timesteps  | 34142    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00089  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1904     |
|    fps              | 107      |
|    time_elapsed     | 319      |
|    total_timesteps  | 34211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0118   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1908     |
|    fps              | 107      |
|    time_elapsed     | 319      |
|    total_timesteps  | 34275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0122   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1912     |
|    fps              | 107      |
|    time_elapsed     | 319      |
|    total_timesteps  | 34345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00225  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1916     |
|    fps              | 107      |
|    time_elapsed     | 319      |
|    total_timesteps  | 34411    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00161  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1920     |
|    fps              | 108      |
|    time_elapsed     | 319      |
|    total_timesteps  | 34493    |
----------------------------------
Eval num_timesteps=34500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 34500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.012    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1924     |
|    fps              | 106      |
|    time_elapsed     | 324      |
|    total_timesteps  | 34559    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1928     |
|    fps              | 106      |
|    time_elapsed     | 324      |
|    total_timesteps  | 34635    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0216   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1932     |
|    fps              | 106      |
|    time_elapsed     | 324      |
|    total_timesteps  | 34701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0213   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1936     |
|    fps              | 107      |
|    time_elapsed     | 324      |
|    total_timesteps  | 34770    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0214   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1940     |
|    fps              | 107      |
|    time_elapsed     | 324      |
|    total_timesteps  | 34848    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0214   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1944     |
|    fps              | 107      |
|    time_elapsed     | 324      |
|    total_timesteps  | 34920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0315   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1948     |
|    fps              | 107      |
|    time_elapsed     | 324      |
|    total_timesteps  | 34986    |
----------------------------------
Eval num_timesteps=35000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 35000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0212   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1952     |
|    fps              | 106      |
|    time_elapsed     | 329      |
|    total_timesteps  | 35065    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0114   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1956     |
|    fps              | 106      |
|    time_elapsed     | 329      |
|    total_timesteps  | 35129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0104   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1960     |
|    fps              | 106      |
|    time_elapsed     | 329      |
|    total_timesteps  | 35221    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00958  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1964     |
|    fps              | 107      |
|    time_elapsed     | 329      |
|    total_timesteps  | 35315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00946  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1968     |
|    fps              | 107      |
|    time_elapsed     | 329      |
|    total_timesteps  | 35386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00084 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1972     |
|    fps              | 107      |
|    time_elapsed     | 329      |
|    total_timesteps  | 35453    |
----------------------------------
Eval num_timesteps=35500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 35500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00104 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1976     |
|    fps              | 106      |
|    time_elapsed     | 334      |
|    total_timesteps  | 35523    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0089   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1980     |
|    fps              | 106      |
|    time_elapsed     | 334      |
|    total_timesteps  | 35590    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00866  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1984     |
|    fps              | 106      |
|    time_elapsed     | 334      |
|    total_timesteps  | 35670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1988     |
|    fps              | 106      |
|    time_elapsed     | 334      |
|    total_timesteps  | 35748    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1992     |
|    fps              | 107      |
|    time_elapsed     | 334      |
|    total_timesteps  | 35815    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1996     |
|    fps              | 107      |
|    time_elapsed     | 334      |
|    total_timesteps  | 35885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2000     |
|    fps              | 107      |
|    time_elapsed     | 334      |
|    total_timesteps  | 35964    |
----------------------------------
Eval num_timesteps=36000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 36000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0387   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2004     |
|    fps              | 106      |
|    time_elapsed     | 338      |
|    total_timesteps  | 36018    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2008     |
|    fps              | 106      |
|    time_elapsed     | 338      |
|    total_timesteps  | 36088    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2012     |
|    fps              | 106      |
|    time_elapsed     | 338      |
|    total_timesteps  | 36159    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2016     |
|    fps              | 106      |
|    time_elapsed     | 338      |
|    total_timesteps  | 36242    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2020     |
|    fps              | 107      |
|    time_elapsed     | 338      |
|    total_timesteps  | 36322    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2024     |
|    fps              | 107      |
|    time_elapsed     | 338      |
|    total_timesteps  | 36392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2028     |
|    fps              | 107      |
|    time_elapsed     | 339      |
|    total_timesteps  | 36466    |
----------------------------------
Eval num_timesteps=36500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 36500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00764  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2032     |
|    fps              | 106      |
|    time_elapsed     | 343      |
|    total_timesteps  | 36536    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00216 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2036     |
|    fps              | 106      |
|    time_elapsed     | 343      |
|    total_timesteps  | 36600    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2040     |
|    fps              | 106      |
|    time_elapsed     | 343      |
|    total_timesteps  | 36667    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2044     |
|    fps              | 106      |
|    time_elapsed     | 343      |
|    total_timesteps  | 36743    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2048     |
|    fps              | 107      |
|    time_elapsed     | 343      |
|    total_timesteps  | 36806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2052     |
|    fps              | 107      |
|    time_elapsed     | 343      |
|    total_timesteps  | 36888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2056     |
|    fps              | 107      |
|    time_elapsed     | 344      |
|    total_timesteps  | 36958    |
----------------------------------
Eval num_timesteps=37000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 37000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2060     |
|    fps              | 106      |
|    time_elapsed     | 348      |
|    total_timesteps  | 37029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2064     |
|    fps              | 106      |
|    time_elapsed     | 348      |
|    total_timesteps  | 37103    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2068     |
|    fps              | 106      |
|    time_elapsed     | 348      |
|    total_timesteps  | 37174    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0498   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2072     |
|    fps              | 106      |
|    time_elapsed     | 348      |
|    total_timesteps  | 37235    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0494   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2076     |
|    fps              | 106      |
|    time_elapsed     | 348      |
|    total_timesteps  | 37314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0394   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2080     |
|    fps              | 107      |
|    time_elapsed     | 348      |
|    total_timesteps  | 37380    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0388   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2084     |
|    fps              | 107      |
|    time_elapsed     | 348      |
|    total_timesteps  | 37477    |
----------------------------------
Eval num_timesteps=37500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 37500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0491   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2088     |
|    fps              | 106      |
|    time_elapsed     | 353      |
|    total_timesteps  | 37546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2092     |
|    fps              | 106      |
|    time_elapsed     | 353      |
|    total_timesteps  | 37610    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0393   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2096     |
|    fps              | 106      |
|    time_elapsed     | 353      |
|    total_timesteps  | 37678    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2100     |
|    fps              | 106      |
|    time_elapsed     | 353      |
|    total_timesteps  | 37751    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2104     |
|    fps              | 106      |
|    time_elapsed     | 353      |
|    total_timesteps  | 37833    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2108     |
|    fps              | 107      |
|    time_elapsed     | 353      |
|    total_timesteps  | 37903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2112     |
|    fps              | 107      |
|    time_elapsed     | 353      |
|    total_timesteps  | 37973    |
----------------------------------
Eval num_timesteps=38000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 38000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2116     |
|    fps              | 106      |
|    time_elapsed     | 358      |
|    total_timesteps  | 38039    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2120     |
|    fps              | 106      |
|    time_elapsed     | 358      |
|    total_timesteps  | 38109    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2124     |
|    fps              | 106      |
|    time_elapsed     | 358      |
|    total_timesteps  | 38185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2128     |
|    fps              | 106      |
|    time_elapsed     | 358      |
|    total_timesteps  | 38250    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2132     |
|    fps              | 106      |
|    time_elapsed     | 358      |
|    total_timesteps  | 38335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2136     |
|    fps              | 107      |
|    time_elapsed     | 358      |
|    total_timesteps  | 38400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2140     |
|    fps              | 107      |
|    time_elapsed     | 358      |
|    total_timesteps  | 38474    |
----------------------------------
Eval num_timesteps=38500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 38500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2144     |
|    fps              | 106      |
|    time_elapsed     | 363      |
|    total_timesteps  | 38558    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00815  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2148     |
|    fps              | 106      |
|    time_elapsed     | 363      |
|    total_timesteps  | 38629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00827  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2152     |
|    fps              | 106      |
|    time_elapsed     | 363      |
|    total_timesteps  | 38708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00839  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2156     |
|    fps              | 106      |
|    time_elapsed     | 363      |
|    total_timesteps  | 38775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2160     |
|    fps              | 106      |
|    time_elapsed     | 363      |
|    total_timesteps  | 38843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00852  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2164     |
|    fps              | 107      |
|    time_elapsed     | 363      |
|    total_timesteps  | 38916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2168     |
|    fps              | 107      |
|    time_elapsed     | 363      |
|    total_timesteps  | 38981    |
----------------------------------
Eval num_timesteps=39000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 39000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2172     |
|    fps              | 106      |
|    time_elapsed     | 368      |
|    total_timesteps  | 39041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2176     |
|    fps              | 106      |
|    time_elapsed     | 368      |
|    total_timesteps  | 39121    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2180     |
|    fps              | 106      |
|    time_elapsed     | 368      |
|    total_timesteps  | 39197    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2184     |
|    fps              | 106      |
|    time_elapsed     | 368      |
|    total_timesteps  | 39270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00917  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2188     |
|    fps              | 106      |
|    time_elapsed     | 368      |
|    total_timesteps  | 39342    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00858  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2192     |
|    fps              | 107      |
|    time_elapsed     | 368      |
|    total_timesteps  | 39421    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00862  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2196     |
|    fps              | 107      |
|    time_elapsed     | 368      |
|    total_timesteps  | 39488    |
----------------------------------
Eval num_timesteps=39500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 39500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2200     |
|    fps              | 106      |
|    time_elapsed     | 373      |
|    total_timesteps  | 39549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2204     |
|    fps              | 106      |
|    time_elapsed     | 373      |
|    total_timesteps  | 39619    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2208     |
|    fps              | 106      |
|    time_elapsed     | 373      |
|    total_timesteps  | 39701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2212     |
|    fps              | 106      |
|    time_elapsed     | 373      |
|    total_timesteps  | 39765    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0189   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2216     |
|    fps              | 106      |
|    time_elapsed     | 373      |
|    total_timesteps  | 39843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2220     |
|    fps              | 106      |
|    time_elapsed     | 373      |
|    total_timesteps  | 39921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0289   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2224     |
|    fps              | 107      |
|    time_elapsed     | 373      |
|    total_timesteps  | 39989    |
----------------------------------
Eval num_timesteps=40000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 40000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0289   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2228     |
|    fps              | 105      |
|    time_elapsed     | 378      |
|    total_timesteps  | 40052    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000155 |
|    n_updates        | 12       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2232     |
|    fps              | 106      |
|    time_elapsed     | 378      |
|    total_timesteps  | 40117    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.43e-05 |
|    n_updates        | 29       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2236     |
|    fps              | 106      |
|    time_elapsed     | 378      |
|    total_timesteps  | 40188    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.71e-05 |
|    n_updates        | 46       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2240     |
|    fps              | 106      |
|    time_elapsed     | 378      |
|    total_timesteps  | 40256    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00715  |
|    n_updates        | 63       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0402   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2244     |
|    fps              | 106      |
|    time_elapsed     | 378      |
|    total_timesteps  | 40328    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000149 |
|    n_updates        | 81       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0501   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2248     |
|    fps              | 106      |
|    time_elapsed     | 378      |
|    total_timesteps  | 40402    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.85e-05 |
|    n_updates        | 100      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0502   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2252     |
|    fps              | 106      |
|    time_elapsed     | 378      |
|    total_timesteps  | 40479    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0078   |
|    n_updates        | 119      |
----------------------------------
Eval num_timesteps=40500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 40500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.21e-05 |
|    n_updates        | 124      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0501   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2256     |
|    fps              | 105      |
|    time_elapsed     | 383      |
|    total_timesteps  | 40547    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.34e-05 |
|    n_updates        | 136      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2260     |
|    fps              | 105      |
|    time_elapsed     | 383      |
|    total_timesteps  | 40628    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.97e-05 |
|    n_updates        | 156      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0499   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2264     |
|    fps              | 106      |
|    time_elapsed     | 383      |
|    total_timesteps  | 40693    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00713  |
|    n_updates        | 173      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0702   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2268     |
|    fps              | 106      |
|    time_elapsed     | 383      |
|    total_timesteps  | 40751    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.09e-05 |
|    n_updates        | 187      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0699   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2272     |
|    fps              | 106      |
|    time_elapsed     | 383      |
|    total_timesteps  | 40819    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.73e-05 |
|    n_updates        | 204      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0796   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2276     |
|    fps              | 106      |
|    time_elapsed     | 383      |
|    total_timesteps  | 40906    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000132 |
|    n_updates        | 226      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0899   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2280     |
|    fps              | 106      |
|    time_elapsed     | 383      |
|    total_timesteps  | 40975    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.15e-05 |
|    n_updates        | 243      |
----------------------------------
Eval num_timesteps=41000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 41000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0144   |
|    n_updates        | 249      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2284     |
|    fps              | 105      |
|    time_elapsed     | 389      |
|    total_timesteps  | 41046    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000126 |
|    n_updates        | 261      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0802   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2288     |
|    fps              | 105      |
|    time_elapsed     | 389      |
|    total_timesteps  | 41113    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000101 |
|    n_updates        | 278      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0802   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2292     |
|    fps              | 105      |
|    time_elapsed     | 389      |
|    total_timesteps  | 41191    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.98e-05 |
|    n_updates        | 297      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0898   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2296     |
|    fps              | 105      |
|    time_elapsed     | 389      |
|    total_timesteps  | 41267    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.92e-05 |
|    n_updates        | 316      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0793   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2300     |
|    fps              | 106      |
|    time_elapsed     | 389      |
|    total_timesteps  | 41342    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.92e-05 |
|    n_updates        | 335      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0893   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2304     |
|    fps              | 106      |
|    time_elapsed     | 389      |
|    total_timesteps  | 41410    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0143   |
|    n_updates        | 352      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2308     |
|    fps              | 106      |
|    time_elapsed     | 389      |
|    total_timesteps  | 41468    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00719  |
|    n_updates        | 366      |
----------------------------------
Eval num_timesteps=41500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 41500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000105 |
|    n_updates        | 374      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0895   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2312     |
|    fps              | 105      |
|    time_elapsed     | 394      |
|    total_timesteps  | 41552    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00717  |
|    n_updates        | 387      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2316     |
|    fps              | 105      |
|    time_elapsed     | 394      |
|    total_timesteps  | 41617    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0143   |
|    n_updates        | 404      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2320     |
|    fps              | 105      |
|    time_elapsed     | 394      |
|    total_timesteps  | 41690    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.89e-05 |
|    n_updates        | 422      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2324     |
|    fps              | 105      |
|    time_elapsed     | 394      |
|    total_timesteps  | 41760    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.34e-05 |
|    n_updates        | 439      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0997   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2328     |
|    fps              | 105      |
|    time_elapsed     | 395      |
|    total_timesteps  | 41833    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.69e-05 |
|    n_updates        | 458      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2332     |
|    fps              | 106      |
|    time_elapsed     | 395      |
|    total_timesteps  | 41901    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00722  |
|    n_updates        | 475      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2336     |
|    fps              | 106      |
|    time_elapsed     | 395      |
|    total_timesteps  | 41970    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.83e-05 |
|    n_updates        | 492      |
----------------------------------
Eval num_timesteps=42000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.999    |
| time/               |          |
|    total_timesteps  | 42000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00717  |
|    n_updates        | 499      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.119    |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2340     |
|    fps              | 105      |
|    time_elapsed     | 400      |
|    total_timesteps  | 42048    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.43e-05 |
|    n_updates        | 511      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2344     |
|    fps              | 105      |
|    time_elapsed     | 400      |
|    total_timesteps  | 42112    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.27e-05 |
|    n_updates        | 527      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2348     |
|    fps              | 105      |
|    time_elapsed     | 400      |
|    total_timesteps  | 42180    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.01e-05 |
|    n_updates        | 544      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2352     |
|    fps              | 105      |
|    time_elapsed     | 400      |
|    total_timesteps  | 42252    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000105 |
|    n_updates        | 562      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2356     |
|    fps              | 105      |
|    time_elapsed     | 400      |
|    total_timesteps  | 42317    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000116 |
|    n_updates        | 579      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.121    |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2360     |
|    fps              | 105      |
|    time_elapsed     | 400      |
|    total_timesteps  | 42381    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.44e-05 |
|    n_updates        | 595      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.111    |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2364     |
|    fps              | 105      |
|    time_elapsed     | 400      |
|    total_timesteps  | 42453    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.45e-05 |
|    n_updates        | 613      |
----------------------------------
Eval num_timesteps=42500, episode_reward=-0.26 +/- 0.18
Episode length: 70.10 +/- 16.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.1     |
|    mean_reward      | -0.26    |
| rollout/            |          |
|    exploration_rate | 0.999    |
| time/               |          |
|    total_timesteps  | 42500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00712  |
|    n_updates        | 624      |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2368     |
|    fps              | 104      |
|    time_elapsed     | 405      |
|    total_timesteps  | 42527    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00723  |
|    n_updates        | 631      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0701   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2372     |
|    fps              | 105      |
|    time_elapsed     | 405      |
|    total_timesteps  | 42592    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000173 |
|    n_updates        | 647      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0602   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2376     |
|    fps              | 105      |
|    time_elapsed     | 405      |
|    total_timesteps  | 42676    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00712  |
|    n_updates        | 668      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0502   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2380     |
|    fps              | 105      |
|    time_elapsed     | 405      |
|    total_timesteps  | 42745    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.31e-05 |
|    n_updates        | 686      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0702   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2384     |
|    fps              | 105      |
|    time_elapsed     | 405      |
|    total_timesteps  | 42815    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.72e-05 |
|    n_updates        | 703      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0703   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2388     |
|    fps              | 105      |
|    time_elapsed     | 405      |
|    total_timesteps  | 42882    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.9e-05  |
|    n_updates        | 720      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0606   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2392     |
|    fps              | 105      |
|    time_elapsed     | 405      |
|    total_timesteps  | 42951    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.49e-05 |
|    n_updates        | 737      |
----------------------------------
Eval num_timesteps=43000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.999    |
| time/               |          |
|    total_timesteps  | 43000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.99e-05 |
|    n_updates        | 749      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0505   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2396     |
|    fps              | 104      |
|    time_elapsed     | 410      |
|    total_timesteps  | 43029    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.13e-05 |
|    n_updates        | 757      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0605   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2400     |
|    fps              | 104      |
|    time_elapsed     | 410      |
|    total_timesteps  | 43105    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00706  |
|    n_updates        | 776      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0506   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2404     |
|    fps              | 105      |
|    time_elapsed     | 410      |
|    total_timesteps  | 43171    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00702  |
|    n_updates        | 792      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0402   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2408     |
|    fps              | 105      |
|    time_elapsed     | 410      |
|    total_timesteps  | 43238    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00686  |
|    n_updates        | 809      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0407   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2412     |
|    fps              | 105      |
|    time_elapsed     | 411      |
|    total_timesteps  | 43310    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.85e-05 |
|    n_updates        | 827      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.051    |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2416     |
|    fps              | 105      |
|    time_elapsed     | 411      |
|    total_timesteps  | 43368    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.9e-05  |
|    n_updates        | 841      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0405   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2420     |
|    fps              | 105      |
|    time_elapsed     | 411      |
|    total_timesteps  | 43454    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.43e-05 |
|    n_updates        | 863      |
----------------------------------
Eval num_timesteps=43500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.999    |
| time/               |          |
|    total_timesteps  | 43500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.31e-05 |
|    n_updates        | 874      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0406   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2424     |
|    fps              | 104      |
|    time_elapsed     | 416      |
|    total_timesteps  | 43522    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.51e-05 |
|    n_updates        | 880      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0411   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2428     |
|    fps              | 104      |
|    time_elapsed     | 416      |
|    total_timesteps  | 43581    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.03e-05 |
|    n_updates        | 895      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.021    |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2432     |
|    fps              | 104      |
|    time_elapsed     | 416      |
|    total_timesteps  | 43651    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.46e-05 |
|    n_updates        | 912      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0311   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2436     |
|    fps              | 105      |
|    time_elapsed     | 416      |
|    total_timesteps  | 43720    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.4e-05  |
|    n_updates        | 929      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0314   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2440     |
|    fps              | 105      |
|    time_elapsed     | 416      |
|    total_timesteps  | 43790    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00694  |
|    n_updates        | 947      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2444     |
|    fps              | 105      |
|    time_elapsed     | 416      |
|    total_timesteps  | 43860    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0138   |
|    n_updates        | 964      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2448     |
|    fps              | 105      |
|    time_elapsed     | 416      |
|    total_timesteps  | 43937    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.1e-05  |
|    n_updates        | 984      |
----------------------------------
Eval num_timesteps=44000, episode_reward=0.08 +/- 0.35
Episode length: 14.52 +/- 1.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.0831   |
| rollout/            |          |
|    exploration_rate | 0.999    |
| time/               |          |
|    total_timesteps  | 44000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000118 |
|    n_updates        | 999      |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2452     |
|    fps              | 105      |
|    time_elapsed     | 417      |
|    total_timesteps  | 44014    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.09e-05 |
|    n_updates        | 1003     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2456     |
|    fps              | 105      |
|    time_elapsed     | 417      |
|    total_timesteps  | 44092    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00714  |
|    n_updates        | 1022     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0498   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2460     |
|    fps              | 105      |
|    time_elapsed     | 417      |
|    total_timesteps  | 44161    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0138   |
|    n_updates        | 1040     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0495   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2464     |
|    fps              | 105      |
|    time_elapsed     | 417      |
|    total_timesteps  | 44242    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.86e-05 |
|    n_updates        | 1060     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0495   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2468     |
|    fps              | 106      |
|    time_elapsed     | 418      |
|    total_timesteps  | 44315    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00714  |
|    n_updates        | 1078     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0589   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2472     |
|    fps              | 106      |
|    time_elapsed     | 418      |
|    total_timesteps  | 44396    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00708  |
|    n_updates        | 1098     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0591   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2476     |
|    fps              | 106      |
|    time_elapsed     | 418      |
|    total_timesteps  | 44475    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.58e-05 |
|    n_updates        | 1118     |
----------------------------------
Eval num_timesteps=44500, episode_reward=-0.27 +/- 0.18
Episode length: 72.62 +/- 11.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.6     |
|    mean_reward      | -0.27    |
| rollout/            |          |
|    exploration_rate | 0.998    |
| time/               |          |
|    total_timesteps  | 44500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00723  |
|    n_updates        | 1124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0694   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2480     |
|    fps              | 105      |
|    time_elapsed     | 422      |
|    total_timesteps  | 44535    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00682  |
|    n_updates        | 1133     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0491   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2484     |
|    fps              | 105      |
|    time_elapsed     | 422      |
|    total_timesteps  | 44613    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0144   |
|    n_updates        | 1153     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0491   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2488     |
|    fps              | 105      |
|    time_elapsed     | 423      |
|    total_timesteps  | 44680    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000157 |
|    n_updates        | 1169     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.049    |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2492     |
|    fps              | 105      |
|    time_elapsed     | 423      |
|    total_timesteps  | 44751    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.04e-05 |
|    n_updates        | 1187     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0588   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2496     |
|    fps              | 105      |
|    time_elapsed     | 423      |
|    total_timesteps  | 44834    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00719  |
|    n_updates        | 1208     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0594   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2500     |
|    fps              | 106      |
|    time_elapsed     | 423      |
|    total_timesteps  | 44896    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000101 |
|    n_updates        | 1223     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0692   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2504     |
|    fps              | 106      |
|    time_elapsed     | 423      |
|    total_timesteps  | 44967    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.27e-05 |
|    n_updates        | 1241     |
----------------------------------
Eval num_timesteps=45000, episode_reward=-0.14 +/- 0.25
Episode length: 44.88 +/- 30.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | -0.139   |
| rollout/            |          |
|    exploration_rate | 0.998    |
| time/               |          |
|    total_timesteps  | 45000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.13e-05 |
|    n_updates        | 1249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0791   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2508     |
|    fps              | 105      |
|    time_elapsed     | 426      |
|    total_timesteps  | 45036    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000116 |
|    n_updates        | 1258     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0788   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2512     |
|    fps              | 105      |
|    time_elapsed     | 426      |
|    total_timesteps  | 45117    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000104 |
|    n_updates        | 1279     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0683   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2516     |
|    fps              | 105      |
|    time_elapsed     | 426      |
|    total_timesteps  | 45187    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.64e-05 |
|    n_updates        | 1296     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0689   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2520     |
|    fps              | 106      |
|    time_elapsed     | 426      |
|    total_timesteps  | 45257    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.63e-05 |
|    n_updates        | 1314     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.069    |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2524     |
|    fps              | 106      |
|    time_elapsed     | 426      |
|    total_timesteps  | 45323    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000143 |
|    n_updates        | 1330     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0678   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2528     |
|    fps              | 106      |
|    time_elapsed     | 426      |
|    total_timesteps  | 45411    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.43e-05 |
|    n_updates        | 1352     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0678   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2532     |
|    fps              | 106      |
|    time_elapsed     | 427      |
|    total_timesteps  | 45483    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000191 |
|    n_updates        | 1370     |
----------------------------------
Eval num_timesteps=45500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.998    |
| time/               |          |
|    total_timesteps  | 45500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00714  |
|    n_updates        | 1374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0475   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2536     |
|    fps              | 105      |
|    time_elapsed     | 431      |
|    total_timesteps  | 45558    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.98e-05 |
|    n_updates        | 1389     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0577   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2540     |
|    fps              | 105      |
|    time_elapsed     | 431      |
|    total_timesteps  | 45623    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.56e-05 |
|    n_updates        | 1405     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0574   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2544     |
|    fps              | 105      |
|    time_elapsed     | 431      |
|    total_timesteps  | 45700    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.65e-05 |
|    n_updates        | 1424     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0679   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2548     |
|    fps              | 105      |
|    time_elapsed     | 432      |
|    total_timesteps  | 45765    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000106 |
|    n_updates        | 1441     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0781   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2552     |
|    fps              | 106      |
|    time_elapsed     | 432      |
|    total_timesteps  | 45836    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000118 |
|    n_updates        | 1458     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0685   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2556     |
|    fps              | 106      |
|    time_elapsed     | 432      |
|    total_timesteps  | 45905    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6e-05    |
|    n_updates        | 1476     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.048    |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2560     |
|    fps              | 106      |
|    time_elapsed     | 432      |
|    total_timesteps  | 45986    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.12e-05 |
|    n_updates        | 1496     |
----------------------------------
Eval num_timesteps=46000, episode_reward=-0.13 +/- 0.23
Episode length: 42.88 +/- 28.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | -0.131   |
| rollout/            |          |
|    exploration_rate | 0.997    |
| time/               |          |
|    total_timesteps  | 46000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00661  |
|    n_updates        | 1499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2564     |
|    fps              | 105      |
|    time_elapsed     | 435      |
|    total_timesteps  | 46052    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00775  |
|    n_updates        | 1512     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0479   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2568     |
|    fps              | 105      |
|    time_elapsed     | 435      |
|    total_timesteps  | 46144    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00785  |
|    n_updates        | 1535     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0482   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2572     |
|    fps              | 106      |
|    time_elapsed     | 435      |
|    total_timesteps  | 46217    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.82e-05 |
|    n_updates        | 1554     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2576     |
|    fps              | 106      |
|    time_elapsed     | 435      |
|    total_timesteps  | 46286    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00722  |
|    n_updates        | 1571     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0481   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2580     |
|    fps              | 106      |
|    time_elapsed     | 435      |
|    total_timesteps  | 46360    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000137 |
|    n_updates        | 1589     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2584     |
|    fps              | 106      |
|    time_elapsed     | 435      |
|    total_timesteps  | 46421    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000112 |
|    n_updates        | 1605     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0684   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2588     |
|    fps              | 106      |
|    time_elapsed     | 435      |
|    total_timesteps  | 46495    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000136 |
|    n_updates        | 1623     |
----------------------------------
Eval num_timesteps=46500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.997    |
| time/               |          |
|    total_timesteps  | 46500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.06e-05 |
|    n_updates        | 1624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0679   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2592     |
|    fps              | 105      |
|    time_elapsed     | 440      |
|    total_timesteps  | 46579    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7e-05    |
|    n_updates        | 1644     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0587   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2596     |
|    fps              | 105      |
|    time_elapsed     | 440      |
|    total_timesteps  | 46644    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.27e-05 |
|    n_updates        | 1660     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0484   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2600     |
|    fps              | 105      |
|    time_elapsed     | 440      |
|    total_timesteps  | 46713    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00718  |
|    n_updates        | 1678     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2604     |
|    fps              | 106      |
|    time_elapsed     | 441      |
|    total_timesteps  | 46784    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0072   |
|    n_updates        | 1695     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2608     |
|    fps              | 106      |
|    time_elapsed     | 441      |
|    total_timesteps  | 46852    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0071   |
|    n_updates        | 1712     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0386   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2612     |
|    fps              | 106      |
|    time_elapsed     | 441      |
|    total_timesteps  | 46928    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000125 |
|    n_updates        | 1731     |
----------------------------------
Eval num_timesteps=47000, episode_reward=0.12 +/- 0.39
Episode length: 16.14 +/- 1.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | 0.116    |
| rollout/            |          |
|    exploration_rate | 0.997    |
| time/               |          |
|    total_timesteps  | 47000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00691  |
|    n_updates        | 1749     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0385   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2616     |
|    fps              | 106      |
|    time_elapsed     | 442      |
|    total_timesteps  | 47000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0385   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2620     |
|    fps              | 106      |
|    time_elapsed     | 442      |
|    total_timesteps  | 47069    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.38e-05 |
|    n_updates        | 1767     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2624     |
|    fps              | 106      |
|    time_elapsed     | 442      |
|    total_timesteps  | 47144    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0079   |
|    n_updates        | 1785     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2628     |
|    fps              | 106      |
|    time_elapsed     | 442      |
|    total_timesteps  | 47210    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000121 |
|    n_updates        | 1802     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0487   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2632     |
|    fps              | 106      |
|    time_elapsed     | 442      |
|    total_timesteps  | 47291    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.92e-05 |
|    n_updates        | 1822     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2636     |
|    fps              | 106      |
|    time_elapsed     | 442      |
|    total_timesteps  | 47368    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.92e-05 |
|    n_updates        | 1841     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.059    |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2640     |
|    fps              | 107      |
|    time_elapsed     | 442      |
|    total_timesteps  | 47424    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.9e-05  |
|    n_updates        | 1855     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0592   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2644     |
|    fps              | 107      |
|    time_elapsed     | 442      |
|    total_timesteps  | 47496    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0143   |
|    n_updates        | 1873     |
----------------------------------
Eval num_timesteps=47500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.996    |
| time/               |          |
|    total_timesteps  | 47500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.36e-05 |
|    n_updates        | 1874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0589   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2648     |
|    fps              | 106      |
|    time_elapsed     | 447      |
|    total_timesteps  | 47568    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000136 |
|    n_updates        | 1891     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.059    |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2652     |
|    fps              | 106      |
|    time_elapsed     | 447      |
|    total_timesteps  | 47637    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00758  |
|    n_updates        | 1909     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2656     |
|    fps              | 106      |
|    time_elapsed     | 447      |
|    total_timesteps  | 47715    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.007    |
|    n_updates        | 1928     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0491   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2660     |
|    fps              | 106      |
|    time_elapsed     | 448      |
|    total_timesteps  | 47783    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00706  |
|    n_updates        | 1945     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0594   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2664     |
|    fps              | 106      |
|    time_elapsed     | 448      |
|    total_timesteps  | 47841    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000149 |
|    n_updates        | 1960     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0699   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2668     |
|    fps              | 106      |
|    time_elapsed     | 448      |
|    total_timesteps  | 47923    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.83e-05 |
|    n_updates        | 1980     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2672     |
|    fps              | 107      |
|    time_elapsed     | 448      |
|    total_timesteps  | 47993    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00715  |
|    n_updates        | 1998     |
----------------------------------
Eval num_timesteps=48000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.996    |
| time/               |          |
|    total_timesteps  | 48000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.29e-05 |
|    n_updates        | 1999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2676     |
|    fps              | 106      |
|    time_elapsed     | 452      |
|    total_timesteps  | 48061    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.7e-05  |
|    n_updates        | 2015     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0596   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2680     |
|    fps              | 106      |
|    time_elapsed     | 452      |
|    total_timesteps  | 48144    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00726  |
|    n_updates        | 2035     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0392   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2684     |
|    fps              | 106      |
|    time_elapsed     | 452      |
|    total_timesteps  | 48217    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0074   |
|    n_updates        | 2054     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0386   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2688     |
|    fps              | 106      |
|    time_elapsed     | 453      |
|    total_timesteps  | 48305    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.63e-05 |
|    n_updates        | 2076     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0489   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2692     |
|    fps              | 106      |
|    time_elapsed     | 453      |
|    total_timesteps  | 48381    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000113 |
|    n_updates        | 2095     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0485   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2696     |
|    fps              | 106      |
|    time_elapsed     | 453      |
|    total_timesteps  | 48456    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00716  |
|    n_updates        | 2113     |
----------------------------------
Eval num_timesteps=48500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.995    |
| time/               |          |
|    total_timesteps  | 48500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000131 |
|    n_updates        | 2124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0487   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2700     |
|    fps              | 105      |
|    time_elapsed     | 458      |
|    total_timesteps  | 48521    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.014    |
|    n_updates        | 2130     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0487   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2704     |
|    fps              | 106      |
|    time_elapsed     | 458      |
|    total_timesteps  | 48591    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000194 |
|    n_updates        | 2147     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.049    |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2708     |
|    fps              | 106      |
|    time_elapsed     | 458      |
|    total_timesteps  | 48654    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.68e-05 |
|    n_updates        | 2163     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0588   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2712     |
|    fps              | 106      |
|    time_elapsed     | 458      |
|    total_timesteps  | 48733    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0072   |
|    n_updates        | 2183     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0489   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2716     |
|    fps              | 106      |
|    time_elapsed     | 458      |
|    total_timesteps  | 48805    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000105 |
|    n_updates        | 2201     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0491   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2720     |
|    fps              | 106      |
|    time_elapsed     | 458      |
|    total_timesteps  | 48867    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00724  |
|    n_updates        | 2216     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0487   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2724     |
|    fps              | 106      |
|    time_elapsed     | 458      |
|    total_timesteps  | 48953    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000118 |
|    n_updates        | 2238     |
----------------------------------
Eval num_timesteps=49000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.995    |
| time/               |          |
|    total_timesteps  | 49000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00712  |
|    n_updates        | 2249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2728     |
|    fps              | 105      |
|    time_elapsed     | 463      |
|    total_timesteps  | 49031    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000154 |
|    n_updates        | 2257     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0389   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2732     |
|    fps              | 105      |
|    time_elapsed     | 463      |
|    total_timesteps  | 49094    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00704  |
|    n_updates        | 2273     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2736     |
|    fps              | 106      |
|    time_elapsed     | 463      |
|    total_timesteps  | 49162    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.38e-05 |
|    n_updates        | 2290     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2740     |
|    fps              | 106      |
|    time_elapsed     | 463      |
|    total_timesteps  | 49246    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000113 |
|    n_updates        | 2311     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2744     |
|    fps              | 106      |
|    time_elapsed     | 463      |
|    total_timesteps  | 49319    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.33e-05 |
|    n_updates        | 2329     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2748     |
|    fps              | 106      |
|    time_elapsed     | 463      |
|    total_timesteps  | 49384    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00694  |
|    n_updates        | 2345     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00792  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2752     |
|    fps              | 106      |
|    time_elapsed     | 463      |
|    total_timesteps  | 49465    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00775  |
|    n_updates        | 2366     |
----------------------------------
Eval num_timesteps=49500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.995    |
| time/               |          |
|    total_timesteps  | 49500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00684  |
|    n_updates        | 2374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00848  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2756     |
|    fps              | 105      |
|    time_elapsed     | 468      |
|    total_timesteps  | 49529    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.31e-05 |
|    n_updates        | 2382     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2760     |
|    fps              | 105      |
|    time_elapsed     | 468      |
|    total_timesteps  | 49611    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00691  |
|    n_updates        | 2402     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00736  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2764     |
|    fps              | 106      |
|    time_elapsed     | 468      |
|    total_timesteps  | 49683    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.85e-05 |
|    n_updates        | 2420     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0077   |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2768     |
|    fps              | 106      |
|    time_elapsed     | 468      |
|    total_timesteps  | 49756    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.23e-05 |
|    n_updates        | 2438     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00798  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2772     |
|    fps              | 106      |
|    time_elapsed     | 468      |
|    total_timesteps  | 49819    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0154   |
|    n_updates        | 2454     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00283 |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2776     |
|    fps              | 106      |
|    time_elapsed     | 468      |
|    total_timesteps  | 49907    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.39e-05 |
|    n_updates        | 2476     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00734  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2780     |
|    fps              | 106      |
|    time_elapsed     | 468      |
|    total_timesteps  | 49986    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000164 |
|    n_updates        | 2496     |
----------------------------------
Eval num_timesteps=50000, episode_reward=0.02 +/- 0.28
Episode length: 15.44 +/- 1.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.4     |
|    mean_reward      | 0.0192   |
| rollout/            |          |
|    exploration_rate | 0.994    |
| time/               |          |
|    total_timesteps  | 50000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000179 |
|    n_updates        | 2499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2784     |
|    fps              | 106      |
|    time_elapsed     | 469      |
|    total_timesteps  | 50056    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00707  |
|    n_updates        | 2513     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2788     |
|    fps              | 106      |
|    time_elapsed     | 469      |
|    total_timesteps  | 50125    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000131 |
|    n_updates        | 2531     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00825  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2792     |
|    fps              | 106      |
|    time_elapsed     | 469      |
|    total_timesteps  | 50200    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.16e-05 |
|    n_updates        | 2549     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2796     |
|    fps              | 106      |
|    time_elapsed     | 470      |
|    total_timesteps  | 50266    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000102 |
|    n_updates        | 2566     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2800     |
|    fps              | 107      |
|    time_elapsed     | 470      |
|    total_timesteps  | 50348    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000109 |
|    n_updates        | 2586     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2804     |
|    fps              | 107      |
|    time_elapsed     | 470      |
|    total_timesteps  | 50413    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00683  |
|    n_updates        | 2603     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2808     |
|    fps              | 107      |
|    time_elapsed     | 470      |
|    total_timesteps  | 50479    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000141 |
|    n_updates        | 2619     |
----------------------------------
Eval num_timesteps=50500, episode_reward=-0.06 +/- 0.30
Episode length: 34.72 +/- 25.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.7     |
|    mean_reward      | -0.0581  |
| rollout/            |          |
|    exploration_rate | 0.994    |
| time/               |          |
|    total_timesteps  | 50500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000141 |
|    n_updates        | 2624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0081   |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2812     |
|    fps              | 106      |
|    time_elapsed     | 472      |
|    total_timesteps  | 50556    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000146 |
|    n_updates        | 2638     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00802  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2816     |
|    fps              | 107      |
|    time_elapsed     | 472      |
|    total_timesteps  | 50630    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000139 |
|    n_updates        | 2657     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00754  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2820     |
|    fps              | 107      |
|    time_elapsed     | 472      |
|    total_timesteps  | 50704    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0002   |
|    n_updates        | 2675     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00774  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2824     |
|    fps              | 107      |
|    time_elapsed     | 472      |
|    total_timesteps  | 50785    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00629  |
|    n_updates        | 2696     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2828     |
|    fps              | 107      |
|    time_elapsed     | 472      |
|    total_timesteps  | 50850    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000155 |
|    n_updates        | 2712     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2832     |
|    fps              | 107      |
|    time_elapsed     | 473      |
|    total_timesteps  | 50914    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000123 |
|    n_updates        | 2728     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00797  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2836     |
|    fps              | 107      |
|    time_elapsed     | 473      |
|    total_timesteps  | 50989    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00652  |
|    n_updates        | 2747     |
----------------------------------
Eval num_timesteps=51000, episode_reward=-0.28 +/- 0.17
Episode length: 74.02 +/- 6.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.276   |
| rollout/            |          |
|    exploration_rate | 0.993    |
| time/               |          |
|    total_timesteps  | 51000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000167 |
|    n_updates        | 2749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00833  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2840     |
|    fps              | 106      |
|    time_elapsed     | 477      |
|    total_timesteps  | 51064    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.79e-05 |
|    n_updates        | 2765     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00845  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2844     |
|    fps              | 106      |
|    time_elapsed     | 477      |
|    total_timesteps  | 51134    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000319 |
|    n_updates        | 2783     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00769  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2848     |
|    fps              | 107      |
|    time_elapsed     | 478      |
|    total_timesteps  | 51218    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.51e-05 |
|    n_updates        | 2804     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2852     |
|    fps              | 107      |
|    time_elapsed     | 478      |
|    total_timesteps  | 51297    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.21e-05 |
|    n_updates        | 2824     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2856     |
|    fps              | 107      |
|    time_elapsed     | 478      |
|    total_timesteps  | 51361    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.42e-05 |
|    n_updates        | 2840     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2860     |
|    fps              | 107      |
|    time_elapsed     | 478      |
|    total_timesteps  | 51425    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000204 |
|    n_updates        | 2856     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0286   |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2864     |
|    fps              | 107      |
|    time_elapsed     | 478      |
|    total_timesteps  | 51494    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000308 |
|    n_updates        | 2873     |
----------------------------------
Eval num_timesteps=51500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.993    |
| time/               |          |
|    total_timesteps  | 51500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000196 |
|    n_updates        | 2874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2868     |
|    fps              | 106      |
|    time_elapsed     | 482      |
|    total_timesteps  | 51562    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000245 |
|    n_updates        | 2890     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2872     |
|    fps              | 106      |
|    time_elapsed     | 482      |
|    total_timesteps  | 51630    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.47e-05 |
|    n_updates        | 2907     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2876     |
|    fps              | 107      |
|    time_elapsed     | 482      |
|    total_timesteps  | 51706    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.27e-05 |
|    n_updates        | 2926     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00977  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2880     |
|    fps              | 107      |
|    time_elapsed     | 483      |
|    total_timesteps  | 51768    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.62e-05 |
|    n_updates        | 2941     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2884     |
|    fps              | 107      |
|    time_elapsed     | 483      |
|    total_timesteps  | 51832    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000138 |
|    n_updates        | 2957     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0203   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2888     |
|    fps              | 107      |
|    time_elapsed     | 483      |
|    total_timesteps  | 51894    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000148 |
|    n_updates        | 2973     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0203   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2892     |
|    fps              | 107      |
|    time_elapsed     | 483      |
|    total_timesteps  | 51969    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000217 |
|    n_updates        | 2992     |
----------------------------------
Eval num_timesteps=52000, episode_reward=-0.14 +/- 0.33
Episode length: 61.10 +/- 19.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.1     |
|    mean_reward      | -0.144   |
| rollout/            |          |
|    exploration_rate | 0.992    |
| time/               |          |
|    total_timesteps  | 52000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000117 |
|    n_updates        | 2999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2896     |
|    fps              | 106      |
|    time_elapsed     | 487      |
|    total_timesteps  | 52034    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000174 |
|    n_updates        | 3008     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0106   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2900     |
|    fps              | 106      |
|    time_elapsed     | 487      |
|    total_timesteps  | 52109    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00706  |
|    n_updates        | 3027     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00029  |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2904     |
|    fps              | 107      |
|    time_elapsed     | 487      |
|    total_timesteps  | 52181    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000154 |
|    n_updates        | 3045     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00017  |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2908     |
|    fps              | 107      |
|    time_elapsed     | 487      |
|    total_timesteps  | 52250    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00659  |
|    n_updates        | 3062     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00045  |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2912     |
|    fps              | 107      |
|    time_elapsed     | 487      |
|    total_timesteps  | 52320    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000392 |
|    n_updates        | 3079     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2916     |
|    fps              | 107      |
|    time_elapsed     | 487      |
|    total_timesteps  | 52399    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00023  |
|    n_updates        | 3099     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0303   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2920     |
|    fps              | 107      |
|    time_elapsed     | 487      |
|    total_timesteps  | 52472    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000168 |
|    n_updates        | 3117     |
----------------------------------
Eval num_timesteps=52500, episode_reward=-0.28 +/- 0.14
Episode length: 74.86 +/- 0.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.279   |
| rollout/            |          |
|    exploration_rate | 0.992    |
| time/               |          |
|    total_timesteps  | 52500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00641  |
|    n_updates        | 3124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0309   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2924     |
|    fps              | 106      |
|    time_elapsed     | 492      |
|    total_timesteps  | 52536    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00021  |
|    n_updates        | 3133     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2928     |
|    fps              | 106      |
|    time_elapsed     | 492      |
|    total_timesteps  | 52619    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0064   |
|    n_updates        | 3154     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00973  |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2932     |
|    fps              | 106      |
|    time_elapsed     | 492      |
|    total_timesteps  | 52695    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0198   |
|    n_updates        | 3173     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00989  |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2936     |
|    fps              | 107      |
|    time_elapsed     | 492      |
|    total_timesteps  | 52766    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000166 |
|    n_updates        | 3191     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0302   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2940     |
|    fps              | 107      |
|    time_elapsed     | 492      |
|    total_timesteps  | 52833    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0004   |
|    n_updates        | 3208     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2944     |
|    fps              | 107      |
|    time_elapsed     | 493      |
|    total_timesteps  | 52907    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000199 |
|    n_updates        | 3226     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0301   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2948     |
|    fps              | 107      |
|    time_elapsed     | 493      |
|    total_timesteps  | 52988    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000154 |
|    n_updates        | 3246     |
----------------------------------
Eval num_timesteps=53000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.991    |
| time/               |          |
|    total_timesteps  | 53000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000109 |
|    n_updates        | 3249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2952     |
|    fps              | 106      |
|    time_elapsed     | 497      |
|    total_timesteps  | 53070    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000113 |
|    n_updates        | 3267     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00974  |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2956     |
|    fps              | 106      |
|    time_elapsed     | 497      |
|    total_timesteps  | 53141    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000177 |
|    n_updates        | 3285     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00969  |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2960     |
|    fps              | 106      |
|    time_elapsed     | 497      |
|    total_timesteps  | 53207    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000217 |
|    n_updates        | 3301     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00965  |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2964     |
|    fps              | 106      |
|    time_elapsed     | 498      |
|    total_timesteps  | 53277    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.83e-05 |
|    n_updates        | 3319     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00929  |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2968     |
|    fps              | 107      |
|    time_elapsed     | 498      |
|    total_timesteps  | 53354    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00025  |
|    n_updates        | 3338     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00869  |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2972     |
|    fps              | 107      |
|    time_elapsed     | 498      |
|    total_timesteps  | 53437    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0076   |
|    n_updates        | 3359     |
----------------------------------
Eval num_timesteps=53500, episode_reward=-0.29 +/- 0.03
Episode length: 72.48 +/- 6.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.5     |
|    mean_reward      | -0.29    |
| rollout/            |          |
|    exploration_rate | 0.991    |
| time/               |          |
|    total_timesteps  | 53500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00708  |
|    n_updates        | 3374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00893  |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2976     |
|    fps              | 106      |
|    time_elapsed     | 503      |
|    total_timesteps  | 53507    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00693  |
|    n_updates        | 3376     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2980     |
|    fps              | 106      |
|    time_elapsed     | 503      |
|    total_timesteps  | 53578    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000298 |
|    n_updates        | 3394     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00712  |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2984     |
|    fps              | 106      |
|    time_elapsed     | 503      |
|    total_timesteps  | 53679    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000142 |
|    n_updates        | 3419     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00682  |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2988     |
|    fps              | 106      |
|    time_elapsed     | 503      |
|    total_timesteps  | 53749    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000303 |
|    n_updates        | 3437     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2992     |
|    fps              | 106      |
|    time_elapsed     | 503      |
|    total_timesteps  | 53823    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000235 |
|    n_updates        | 3455     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0158   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2996     |
|    fps              | 107      |
|    time_elapsed     | 503      |
|    total_timesteps  | 53914    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.82e-05 |
|    n_updates        | 3478     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0161   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3000     |
|    fps              | 107      |
|    time_elapsed     | 503      |
|    total_timesteps  | 53983    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00694  |
|    n_updates        | 3495     |
----------------------------------
Eval num_timesteps=54000, episode_reward=-0.09 +/- 0.28
Episode length: 41.94 +/- 19.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.9     |
|    mean_reward      | -0.0868  |
| rollout/            |          |
|    exploration_rate | 0.99     |
| time/               |          |
|    total_timesteps  | 54000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000237 |
|    n_updates        | 3499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3004     |
|    fps              | 106      |
|    time_elapsed     | 506      |
|    total_timesteps  | 54051    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00637  |
|    n_updates        | 3512     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0164   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3008     |
|    fps              | 106      |
|    time_elapsed     | 506      |
|    total_timesteps  | 54117    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0001   |
|    n_updates        | 3529     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0164   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3012     |
|    fps              | 107      |
|    time_elapsed     | 506      |
|    total_timesteps  | 54185    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0001   |
|    n_updates        | 3546     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00315 |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3016     |
|    fps              | 107      |
|    time_elapsed     | 506      |
|    total_timesteps  | 54254    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0145   |
|    n_updates        | 3563     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00309 |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3020     |
|    fps              | 107      |
|    time_elapsed     | 506      |
|    total_timesteps  | 54326    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000319 |
|    n_updates        | 3581     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00361 |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3024     |
|    fps              | 107      |
|    time_elapsed     | 506      |
|    total_timesteps  | 54403    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000157 |
|    n_updates        | 3600     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00385 |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3028     |
|    fps              | 107      |
|    time_elapsed     | 506      |
|    total_timesteps  | 54492    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000103 |
|    n_updates        | 3622     |
----------------------------------
Eval num_timesteps=54500, episode_reward=-0.20 +/- 0.27
Episode length: 65.38 +/- 16.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.4     |
|    mean_reward      | -0.201   |
| rollout/            |          |
|    exploration_rate | 0.99     |
| time/               |          |
|    total_timesteps  | 54500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.7e-05  |
|    n_updates        | 3624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00361 |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3032     |
|    fps              | 106      |
|    time_elapsed     | 511      |
|    total_timesteps  | 54562    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000178 |
|    n_updates        | 3640     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00373 |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3036     |
|    fps              | 106      |
|    time_elapsed     | 511      |
|    total_timesteps  | 54636    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000176 |
|    n_updates        | 3658     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0245  |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3040     |
|    fps              | 107      |
|    time_elapsed     | 511      |
|    total_timesteps  | 54723    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000189 |
|    n_updates        | 3680     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0247  |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3044     |
|    fps              | 107      |
|    time_elapsed     | 511      |
|    total_timesteps  | 54803    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000161 |
|    n_updates        | 3700     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 3048     |
|    fps              | 107      |
|    time_elapsed     | 511      |
|    total_timesteps  | 54865    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000319 |
|    n_updates        | 3716     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0236  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3052     |
|    fps              | 107      |
|    time_elapsed     | 511      |
|    total_timesteps  | 54937    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00622  |
|    n_updates        | 3734     |
----------------------------------
Eval num_timesteps=55000, episode_reward=-0.26 +/- 0.20
Episode length: 74.76 +/- 1.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.259   |
| rollout/            |          |
|    exploration_rate | 0.989    |
| time/               |          |
|    total_timesteps  | 55000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00705  |
|    n_updates        | 3749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3056     |
|    fps              | 106      |
|    time_elapsed     | 516      |
|    total_timesteps  | 55018    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000334 |
|    n_updates        | 3754     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0339  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3060     |
|    fps              | 106      |
|    time_elapsed     | 516      |
|    total_timesteps  | 55080    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.7e-05  |
|    n_updates        | 3769     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0337  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3064     |
|    fps              | 106      |
|    time_elapsed     | 516      |
|    total_timesteps  | 55147    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00705  |
|    n_updates        | 3786     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0334  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3068     |
|    fps              | 106      |
|    time_elapsed     | 516      |
|    total_timesteps  | 55215    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0124   |
|    n_updates        | 3803     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3072     |
|    fps              | 107      |
|    time_elapsed     | 516      |
|    total_timesteps  | 55290    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00683  |
|    n_updates        | 3822     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0328  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3076     |
|    fps              | 107      |
|    time_elapsed     | 516      |
|    total_timesteps  | 55353    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000118 |
|    n_updates        | 3838     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3080     |
|    fps              | 107      |
|    time_elapsed     | 516      |
|    total_timesteps  | 55413    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0142   |
|    n_updates        | 3853     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0109  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3084     |
|    fps              | 107      |
|    time_elapsed     | 516      |
|    total_timesteps  | 55478    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000182 |
|    n_updates        | 3869     |
----------------------------------
Eval num_timesteps=55500, episode_reward=0.08 +/- 0.38
Episode length: 31.14 +/- 16.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 31.1     |
|    mean_reward      | 0.0765   |
| rollout/            |          |
|    exploration_rate | 0.989    |
| time/               |          |
|    total_timesteps  | 55500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000117 |
|    n_updates        | 3874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3088     |
|    fps              | 107      |
|    time_elapsed     | 518      |
|    total_timesteps  | 55543    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000156 |
|    n_updates        | 3885     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3092     |
|    fps              | 107      |
|    time_elapsed     | 519      |
|    total_timesteps  | 55608    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000109 |
|    n_updates        | 3901     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00965 |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3096     |
|    fps              | 107      |
|    time_elapsed     | 519      |
|    total_timesteps  | 55681    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000165 |
|    n_updates        | 3920     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 3100     |
|    fps              | 107      |
|    time_elapsed     | 519      |
|    total_timesteps  | 55761    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0071   |
|    n_updates        | 3940     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0105  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3104     |
|    fps              | 107      |
|    time_elapsed     | 519      |
|    total_timesteps  | 55839    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00681  |
|    n_updates        | 3959     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3108     |
|    fps              | 107      |
|    time_elapsed     | 519      |
|    total_timesteps  | 55911    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000101 |
|    n_updates        | 3977     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0111  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3112     |
|    fps              | 107      |
|    time_elapsed     | 519      |
|    total_timesteps  | 55988    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000195 |
|    n_updates        | 3996     |
----------------------------------
Eval num_timesteps=56000, episode_reward=0.00 +/- 0.33
Episode length: 24.98 +/- 17.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 25       |
|    mean_reward      | 0.0011   |
| rollout/            |          |
|    exploration_rate | 0.988    |
| time/               |          |
|    total_timesteps  | 56000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00618  |
|    n_updates        | 3999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00907  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3116     |
|    fps              | 107      |
|    time_elapsed     | 521      |
|    total_timesteps  | 56054    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00662  |
|    n_updates        | 4013     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00131 |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3120     |
|    fps              | 107      |
|    time_elapsed     | 521      |
|    total_timesteps  | 56135    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000172 |
|    n_updates        | 4033     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00091 |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3124     |
|    fps              | 107      |
|    time_elapsed     | 521      |
|    total_timesteps  | 56202    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000114 |
|    n_updates        | 4050     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00975  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3128     |
|    fps              | 107      |
|    time_elapsed     | 521      |
|    total_timesteps  | 56275    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.17e-05 |
|    n_updates        | 4068     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00899  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3132     |
|    fps              | 108      |
|    time_elapsed     | 521      |
|    total_timesteps  | 56364    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00683  |
|    n_updates        | 4090     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00855  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3136     |
|    fps              | 108      |
|    time_elapsed     | 521      |
|    total_timesteps  | 56449    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000113 |
|    n_updates        | 4112     |
----------------------------------
Eval num_timesteps=56500, episode_reward=-0.04 +/- 0.33
Episode length: 40.42 +/- 18.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.4     |
|    mean_reward      | -0.0407  |
| rollout/            |          |
|    exploration_rate | 0.988    |
| time/               |          |
|    total_timesteps  | 56500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00018  |
|    n_updates        | 4124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00935  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3140     |
|    fps              | 107      |
|    time_elapsed     | 524      |
|    total_timesteps  | 56516    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00698  |
|    n_updates        | 4128     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0198   |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3144     |
|    fps              | 107      |
|    time_elapsed     | 524      |
|    total_timesteps  | 56584    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000186 |
|    n_updates        | 4145     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 3148     |
|    fps              | 108      |
|    time_elapsed     | 524      |
|    total_timesteps  | 56649    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00759  |
|    n_updates        | 4162     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3152     |
|    fps              | 108      |
|    time_elapsed     | 524      |
|    total_timesteps  | 56725    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00681  |
|    n_updates        | 4181     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0394   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3156     |
|    fps              | 108      |
|    time_elapsed     | 524      |
|    total_timesteps  | 56811    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000212 |
|    n_updates        | 4202     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3160     |
|    fps              | 108      |
|    time_elapsed     | 524      |
|    total_timesteps  | 56880    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000171 |
|    n_updates        | 4219     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3164     |
|    fps              | 108      |
|    time_elapsed     | 524      |
|    total_timesteps  | 56946    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00793  |
|    n_updates        | 4236     |
----------------------------------
Eval num_timesteps=57000, episode_reward=-0.05 +/- 0.42
Episode length: 62.68 +/- 18.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.7     |
|    mean_reward      | -0.0502  |
| rollout/            |          |
|    exploration_rate | 0.987    |
| time/               |          |
|    total_timesteps  | 57000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000207 |
|    n_updates        | 4249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0387   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3168     |
|    fps              | 107      |
|    time_elapsed     | 528      |
|    total_timesteps  | 57024    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000383 |
|    n_updates        | 4255     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3172     |
|    fps              | 108      |
|    time_elapsed     | 528      |
|    total_timesteps  | 57125    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00784  |
|    n_updates        | 4281     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0372   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3176     |
|    fps              | 108      |
|    time_elapsed     | 528      |
|    total_timesteps  | 57199    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00016  |
|    n_updates        | 4299     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0167   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3180     |
|    fps              | 108      |
|    time_elapsed     | 528      |
|    total_timesteps  | 57272    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000198 |
|    n_updates        | 4317     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0268   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3184     |
|    fps              | 108      |
|    time_elapsed     | 528      |
|    total_timesteps  | 57335    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0207   |
|    n_updates        | 4333     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0165   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3188     |
|    fps              | 108      |
|    time_elapsed     | 529      |
|    total_timesteps  | 57407    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000188 |
|    n_updates        | 4351     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0155   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3192     |
|    fps              | 108      |
|    time_elapsed     | 529      |
|    total_timesteps  | 57497    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000194 |
|    n_updates        | 4374     |
----------------------------------
Eval num_timesteps=57500, episode_reward=-0.11 +/- 0.27
Episode length: 42.96 +/- 23.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43       |
|    mean_reward      | -0.111   |
| rollout/            |          |
|    exploration_rate | 0.987    |
| time/               |          |
|    total_timesteps  | 57500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0158   |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 3196     |
|    fps              | 108      |
|    time_elapsed     | 531      |
|    total_timesteps  | 57563    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00663  |
|    n_updates        | 4390     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0364   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3200     |
|    fps              | 108      |
|    time_elapsed     | 532      |
|    total_timesteps  | 57627    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000183 |
|    n_updates        | 4406     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0364   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3204     |
|    fps              | 108      |
|    time_elapsed     | 532      |
|    total_timesteps  | 57705    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000136 |
|    n_updates        | 4426     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0358   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3208     |
|    fps              | 108      |
|    time_elapsed     | 532      |
|    total_timesteps  | 57792    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000303 |
|    n_updates        | 4447     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3212     |
|    fps              | 108      |
|    time_elapsed     | 532      |
|    total_timesteps  | 57862    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000152 |
|    n_updates        | 4465     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0158   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3216     |
|    fps              | 108      |
|    time_elapsed     | 532      |
|    total_timesteps  | 57934    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00022  |
|    n_updates        | 4483     |
----------------------------------
Eval num_timesteps=58000, episode_reward=-0.27 +/- 0.16
Episode length: 72.82 +/- 9.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.8     |
|    mean_reward      | -0.271   |
| rollout/            |          |
|    exploration_rate | 0.986    |
| time/               |          |
|    total_timesteps  | 58000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0138   |
|    n_updates        | 4499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.016    |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3220     |
|    fps              | 108      |
|    time_elapsed     | 536      |
|    total_timesteps  | 58010    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000351 |
|    n_updates        | 4502     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3224     |
|    fps              | 108      |
|    time_elapsed     | 536      |
|    total_timesteps  | 58088    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00698  |
|    n_updates        | 4521     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0055   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3228     |
|    fps              | 108      |
|    time_elapsed     | 537      |
|    total_timesteps  | 58163    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000104 |
|    n_updates        | 4540     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3232     |
|    fps              | 108      |
|    time_elapsed     | 537      |
|    total_timesteps  | 58226    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000116 |
|    n_updates        | 4556     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3236     |
|    fps              | 108      |
|    time_elapsed     | 537      |
|    total_timesteps  | 58291    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000127 |
|    n_updates        | 4572     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0374   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3240     |
|    fps              | 108      |
|    time_elapsed     | 537      |
|    total_timesteps  | 58357    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000192 |
|    n_updates        | 4589     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 3244     |
|    fps              | 108      |
|    time_elapsed     | 537      |
|    total_timesteps  | 58428    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000185 |
|    n_updates        | 4606     |
----------------------------------
Eval num_timesteps=58500, episode_reward=-0.17 +/- 0.09
Episode length: 42.50 +/- 21.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.5     |
|    mean_reward      | -0.169   |
| rollout/            |          |
|    exploration_rate | 0.985    |
| time/               |          |
|    total_timesteps  | 58500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000232 |
|    n_updates        | 4624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.037    |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3248     |
|    fps              | 108      |
|    time_elapsed     | 540      |
|    total_timesteps  | 58502    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00731  |
|    n_updates        | 4625     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0273   |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3252     |
|    fps              | 108      |
|    time_elapsed     | 540      |
|    total_timesteps  | 58568    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000229 |
|    n_updates        | 4641     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3256     |
|    fps              | 108      |
|    time_elapsed     | 540      |
|    total_timesteps  | 58633    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.44e-05 |
|    n_updates        | 4658     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3260     |
|    fps              | 108      |
|    time_elapsed     | 540      |
|    total_timesteps  | 58705    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000113 |
|    n_updates        | 4676     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3264     |
|    fps              | 108      |
|    time_elapsed     | 540      |
|    total_timesteps  | 58778    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00712  |
|    n_updates        | 4694     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3268     |
|    fps              | 108      |
|    time_elapsed     | 540      |
|    total_timesteps  | 58856    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000215 |
|    n_updates        | 4713     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3272     |
|    fps              | 108      |
|    time_elapsed     | 540      |
|    total_timesteps  | 58931    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00688  |
|    n_updates        | 4732     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3276     |
|    fps              | 109      |
|    time_elapsed     | 540      |
|    total_timesteps  | 58995    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000125 |
|    n_updates        | 4748     |
----------------------------------
Eval num_timesteps=59000, episode_reward=0.01 +/- 0.34
Episode length: 27.96 +/- 20.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28       |
|    mean_reward      | 0.00918  |
| rollout/            |          |
|    exploration_rate | 0.985    |
| time/               |          |
|    total_timesteps  | 59000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000168 |
|    n_updates        | 4749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0193   |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3280     |
|    fps              | 108      |
|    time_elapsed     | 542      |
|    total_timesteps  | 59066    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000183 |
|    n_updates        | 4766     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00113 |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3284     |
|    fps              | 108      |
|    time_elapsed     | 542      |
|    total_timesteps  | 59140    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000171 |
|    n_updates        | 4784     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00905  |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3288     |
|    fps              | 109      |
|    time_elapsed     | 542      |
|    total_timesteps  | 59208    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000135 |
|    n_updates        | 4801     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00019 |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 3292     |
|    fps              | 109      |
|    time_elapsed     | 542      |
|    total_timesteps  | 59279    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000151 |
|    n_updates        | 4819     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00976  |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3296     |
|    fps              | 109      |
|    time_elapsed     | 542      |
|    total_timesteps  | 59346    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000163 |
|    n_updates        | 4836     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00092 |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3300     |
|    fps              | 109      |
|    time_elapsed     | 543      |
|    total_timesteps  | 59427    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000164 |
|    n_updates        | 4856     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00044 |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3304     |
|    fps              | 109      |
|    time_elapsed     | 543      |
|    total_timesteps  | 59493    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00707  |
|    n_updates        | 4873     |
----------------------------------
Eval num_timesteps=59500, episode_reward=0.08 +/- 0.39
Episode length: 35.88 +/- 16.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 35.9     |
|    mean_reward      | 0.0777   |
| rollout/            |          |
|    exploration_rate | 0.984    |
| time/               |          |
|    total_timesteps  | 59500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000189 |
|    n_updates        | 4874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00012  |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3308     |
|    fps              | 109      |
|    time_elapsed     | 545      |
|    total_timesteps  | 59566    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.23e-05 |
|    n_updates        | 4891     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0002   |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3312     |
|    fps              | 109      |
|    time_elapsed     | 545      |
|    total_timesteps  | 59634    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000172 |
|    n_updates        | 4908     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -8e-05   |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3316     |
|    fps              | 109      |
|    time_elapsed     | 545      |
|    total_timesteps  | 59713    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000165 |
|    n_updates        | 4928     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00028 |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3320     |
|    fps              | 109      |
|    time_elapsed     | 545      |
|    total_timesteps  | 59794    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00011  |
|    n_updates        | 4948     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0203   |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3324     |
|    fps              | 109      |
|    time_elapsed     | 545      |
|    total_timesteps  | 59857    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.58e-05 |
|    n_updates        | 4964     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0199   |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3328     |
|    fps              | 109      |
|    time_elapsed     | 545      |
|    total_timesteps  | 59941    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00627  |
|    n_updates        | 4985     |
----------------------------------
Eval num_timesteps=60000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.984    |
| time/               |          |
|    total_timesteps  | 60000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000251 |
|    n_updates        | 4999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00961  |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3332     |
|    fps              | 108      |
|    time_elapsed     | 550      |
|    total_timesteps  | 60012    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000192 |
|    n_updates        | 5002     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00905  |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 3336     |
|    fps              | 109      |
|    time_elapsed     | 550      |
|    total_timesteps  | 60091    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00603  |
|    n_updates        | 5022     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00098 |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3340     |
|    fps              | 109      |
|    time_elapsed     | 550      |
|    total_timesteps  | 60157    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000145 |
|    n_updates        | 5039     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3344     |
|    fps              | 109      |
|    time_elapsed     | 551      |
|    total_timesteps  | 60238    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000283 |
|    n_updates        | 5059     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00201 |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3348     |
|    fps              | 109      |
|    time_elapsed     | 551      |
|    total_timesteps  | 60327    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00689  |
|    n_updates        | 5081     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00209 |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3352     |
|    fps              | 109      |
|    time_elapsed     | 551      |
|    total_timesteps  | 60395    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000387 |
|    n_updates        | 5098     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00767  |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3356     |
|    fps              | 109      |
|    time_elapsed     | 551      |
|    total_timesteps  | 60466    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000193 |
|    n_updates        | 5116     |
----------------------------------
Eval num_timesteps=60500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.983    |
| time/               |          |
|    total_timesteps  | 60500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000218 |
|    n_updates        | 5124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3360     |
|    fps              | 108      |
|    time_elapsed     | 555      |
|    total_timesteps  | 60536    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000161 |
|    n_updates        | 5133     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3364     |
|    fps              | 109      |
|    time_elapsed     | 555      |
|    total_timesteps  | 60601    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000143 |
|    n_updates        | 5150     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3368     |
|    fps              | 109      |
|    time_elapsed     | 556      |
|    total_timesteps  | 60667    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000206 |
|    n_updates        | 5166     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3372     |
|    fps              | 109      |
|    time_elapsed     | 556      |
|    total_timesteps  | 60740    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.72e-05 |
|    n_updates        | 5184     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3376     |
|    fps              | 109      |
|    time_elapsed     | 556      |
|    total_timesteps  | 60826    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000451 |
|    n_updates        | 5206     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 3380     |
|    fps              | 109      |
|    time_elapsed     | 556      |
|    total_timesteps  | 60894    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00791  |
|    n_updates        | 5223     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3384     |
|    fps              | 109      |
|    time_elapsed     | 556      |
|    total_timesteps  | 60959    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000256 |
|    n_updates        | 5239     |
----------------------------------
Eval num_timesteps=61000, episode_reward=-0.29 +/- 0.05
Episode length: 71.64 +/- 11.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.6     |
|    mean_reward      | -0.286   |
| rollout/            |          |
|    exploration_rate | 0.982    |
| time/               |          |
|    total_timesteps  | 61000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000167 |
|    n_updates        | 5249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3388     |
|    fps              | 108      |
|    time_elapsed     | 560      |
|    total_timesteps  | 61031    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000135 |
|    n_updates        | 5257     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3392     |
|    fps              | 108      |
|    time_elapsed     | 561      |
|    total_timesteps  | 61104    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000181 |
|    n_updates        | 5275     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00767  |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3396     |
|    fps              | 109      |
|    time_elapsed     | 561      |
|    total_timesteps  | 61179    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000137 |
|    n_updates        | 5294     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00214 |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3400     |
|    fps              | 109      |
|    time_elapsed     | 561      |
|    total_timesteps  | 61255    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000214 |
|    n_updates        | 5313     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00254 |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3404     |
|    fps              | 109      |
|    time_elapsed     | 561      |
|    total_timesteps  | 61331    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000172 |
|    n_updates        | 5332     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00254 |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3408     |
|    fps              | 109      |
|    time_elapsed     | 561      |
|    total_timesteps  | 61404    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000184 |
|    n_updates        | 5350     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00782  |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3412     |
|    fps              | 109      |
|    time_elapsed     | 561      |
|    total_timesteps  | 61463    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00787  |
|    n_updates        | 5365     |
----------------------------------
Eval num_timesteps=61500, episode_reward=-0.26 +/- 0.06
Episode length: 66.08 +/- 14.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.1     |
|    mean_reward      | -0.264   |
| rollout/            |          |
|    exploration_rate | 0.982    |
| time/               |          |
|    total_timesteps  | 61500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00677  |
|    n_updates        | 5374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3416     |
|    fps              | 108      |
|    time_elapsed     | 565      |
|    total_timesteps  | 61534    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000107 |
|    n_updates        | 5383     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3420     |
|    fps              | 108      |
|    time_elapsed     | 565      |
|    total_timesteps  | 61602    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000276 |
|    n_updates        | 5400     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00154 |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 3424     |
|    fps              | 108      |
|    time_elapsed     | 565      |
|    total_timesteps  | 61671    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00723  |
|    n_updates        | 5417     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00939  |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3428     |
|    fps              | 109      |
|    time_elapsed     | 565      |
|    total_timesteps  | 61732    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000404 |
|    n_updates        | 5432     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00915  |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3432     |
|    fps              | 109      |
|    time_elapsed     | 566      |
|    total_timesteps  | 61809    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000203 |
|    n_updates        | 5452     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3436     |
|    fps              | 109      |
|    time_elapsed     | 566      |
|    total_timesteps  | 61878    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000322 |
|    n_updates        | 5469     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00871  |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3440     |
|    fps              | 109      |
|    time_elapsed     | 566      |
|    total_timesteps  | 61965    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00703  |
|    n_updates        | 5491     |
----------------------------------
Eval num_timesteps=62000, episode_reward=-0.12 +/- 0.26
Episode length: 46.42 +/- 22.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.4     |
|    mean_reward      | -0.125   |
| rollout/            |          |
|    exploration_rate | 0.981    |
| time/               |          |
|    total_timesteps  | 62000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00017  |
|    n_updates        | 5499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00943  |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3444     |
|    fps              | 108      |
|    time_elapsed     | 569      |
|    total_timesteps  | 62028    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000209 |
|    n_updates        | 5506     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3448     |
|    fps              | 109      |
|    time_elapsed     | 569      |
|    total_timesteps  | 62096    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000146 |
|    n_updates        | 5523     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3452     |
|    fps              | 109      |
|    time_elapsed     | 569      |
|    total_timesteps  | 62171    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000231 |
|    n_updates        | 5542     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 4e-05    |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3456     |
|    fps              | 109      |
|    time_elapsed     | 569      |
|    total_timesteps  | 62241    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000153 |
|    n_updates        | 5560     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -5e-05   |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3460     |
|    fps              | 109      |
|    time_elapsed     | 569      |
|    total_timesteps  | 62313    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000138 |
|    n_updates        | 5578     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00961  |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3464     |
|    fps              | 109      |
|    time_elapsed     | 569      |
|    total_timesteps  | 62387    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000227 |
|    n_updates        | 5596     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 3468     |
|    fps              | 109      |
|    time_elapsed     | 569      |
|    total_timesteps  | 62465    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000176 |
|    n_updates        | 5616     |
----------------------------------
Eval num_timesteps=62500, episode_reward=-0.22 +/- 0.10
Episode length: 54.66 +/- 26.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.7     |
|    mean_reward      | -0.218   |
| rollout/            |          |
|    exploration_rate | 0.98     |
| time/               |          |
|    total_timesteps  | 62500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0062   |
|    n_updates        | 5624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3472     |
|    fps              | 109      |
|    time_elapsed     | 573      |
|    total_timesteps  | 62537    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00681  |
|    n_updates        | 5634     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3476     |
|    fps              | 109      |
|    time_elapsed     | 573      |
|    total_timesteps  | 62612    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00033  |
|    n_updates        | 5652     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3480     |
|    fps              | 109      |
|    time_elapsed     | 573      |
|    total_timesteps  | 62685    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0191   |
|    n_updates        | 5671     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3484     |
|    fps              | 109      |
|    time_elapsed     | 573      |
|    total_timesteps  | 62746    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00043  |
|    n_updates        | 5686     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0291   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3488     |
|    fps              | 109      |
|    time_elapsed     | 573      |
|    total_timesteps  | 62830    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00013  |
|    n_updates        | 5707     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3492     |
|    fps              | 109      |
|    time_elapsed     | 573      |
|    total_timesteps  | 62897    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000217 |
|    n_updates        | 5724     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3496     |
|    fps              | 109      |
|    time_elapsed     | 574      |
|    total_timesteps  | 62969    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00793  |
|    n_updates        | 5742     |
----------------------------------
Eval num_timesteps=63000, episode_reward=-0.29 +/- 0.05
Episode length: 71.58 +/- 13.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.6     |
|    mean_reward      | -0.286   |
| rollout/            |          |
|    exploration_rate | 0.98     |
| time/               |          |
|    total_timesteps  | 63000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00029  |
|    n_updates        | 5749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3500     |
|    fps              | 108      |
|    time_elapsed     | 578      |
|    total_timesteps  | 63036    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000305 |
|    n_updates        | 5758     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3504     |
|    fps              | 109      |
|    time_elapsed     | 579      |
|    total_timesteps  | 63115    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000304 |
|    n_updates        | 5778     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0401   |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 3508     |
|    fps              | 109      |
|    time_elapsed     | 579      |
|    total_timesteps  | 63178    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000301 |
|    n_updates        | 5794     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3512     |
|    fps              | 109      |
|    time_elapsed     | 579      |
|    total_timesteps  | 63239    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000169 |
|    n_updates        | 5809     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3516     |
|    fps              | 109      |
|    time_elapsed     | 579      |
|    total_timesteps  | 63326    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000199 |
|    n_updates        | 5831     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0394   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3520     |
|    fps              | 109      |
|    time_elapsed     | 579      |
|    total_timesteps  | 63394    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00654  |
|    n_updates        | 5848     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0591   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3524     |
|    fps              | 109      |
|    time_elapsed     | 579      |
|    total_timesteps  | 63469    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000234 |
|    n_updates        | 5867     |
----------------------------------
Eval num_timesteps=63500, episode_reward=-0.17 +/- 0.08
Episode length: 41.96 +/- 20.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42       |
|    mean_reward      | -0.167   |
| rollout/            |          |
|    exploration_rate | 0.979    |
| time/               |          |
|    total_timesteps  | 63500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00659  |
|    n_updates        | 5874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0587   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3528     |
|    fps              | 109      |
|    time_elapsed     | 582      |
|    total_timesteps  | 63540    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000287 |
|    n_updates        | 5884     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0593   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3532     |
|    fps              | 109      |
|    time_elapsed     | 582      |
|    total_timesteps  | 63603    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00664  |
|    n_updates        | 5900     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3536     |
|    fps              | 109      |
|    time_elapsed     | 582      |
|    total_timesteps  | 63690    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000241 |
|    n_updates        | 5922     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0488   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3540     |
|    fps              | 109      |
|    time_elapsed     | 582      |
|    total_timesteps  | 63770    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000203 |
|    n_updates        | 5942     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0587   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3544     |
|    fps              | 109      |
|    time_elapsed     | 582      |
|    total_timesteps  | 63837    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000238 |
|    n_updates        | 5959     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0477   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 3548     |
|    fps              | 109      |
|    time_elapsed     | 582      |
|    total_timesteps  | 63929    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000173 |
|    n_updates        | 5982     |
----------------------------------
Eval num_timesteps=64000, episode_reward=-0.30 +/- 0.03
Episode length: 73.84 +/- 8.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.978    |
| time/               |          |
|    total_timesteps  | 64000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000198 |
|    n_updates        | 5999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0478   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3552     |
|    fps              | 108      |
|    time_elapsed     | 587      |
|    total_timesteps  | 64003    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00654  |
|    n_updates        | 6000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0577   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3556     |
|    fps              | 109      |
|    time_elapsed     | 587      |
|    total_timesteps  | 64074    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000131 |
|    n_updates        | 6018     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0475   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3560     |
|    fps              | 109      |
|    time_elapsed     | 587      |
|    total_timesteps  | 64153    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000313 |
|    n_updates        | 6038     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3564     |
|    fps              | 109      |
|    time_elapsed     | 587      |
|    total_timesteps  | 64221    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00042  |
|    n_updates        | 6055     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3568     |
|    fps              | 109      |
|    time_elapsed     | 587      |
|    total_timesteps  | 64298    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000218 |
|    n_updates        | 6074     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3572     |
|    fps              | 109      |
|    time_elapsed     | 587      |
|    total_timesteps  | 64364    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0062   |
|    n_updates        | 6090     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3576     |
|    fps              | 109      |
|    time_elapsed     | 587      |
|    total_timesteps  | 64424    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00011  |
|    n_updates        | 6105     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3580     |
|    fps              | 109      |
|    time_elapsed     | 588      |
|    total_timesteps  | 64492    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000301 |
|    n_updates        | 6122     |
----------------------------------
Eval num_timesteps=64500, episode_reward=-0.21 +/- 0.08
Episode length: 52.14 +/- 20.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.1     |
|    mean_reward      | -0.208   |
| rollout/            |          |
|    exploration_rate | 0.978    |
| time/               |          |
|    total_timesteps  | 64500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.014    |
|    n_updates        | 6124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3584     |
|    fps              | 109      |
|    time_elapsed     | 591      |
|    total_timesteps  | 64572    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0132   |
|    n_updates        | 6142     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3588     |
|    fps              | 109      |
|    time_elapsed     | 591      |
|    total_timesteps  | 64652    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000293 |
|    n_updates        | 6162     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 3592     |
|    fps              | 109      |
|    time_elapsed     | 591      |
|    total_timesteps  | 64723    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000284 |
|    n_updates        | 6180     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3596     |
|    fps              | 109      |
|    time_elapsed     | 591      |
|    total_timesteps  | 64798    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000269 |
|    n_updates        | 6199     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3600     |
|    fps              | 109      |
|    time_elapsed     | 591      |
|    total_timesteps  | 64857    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000351 |
|    n_updates        | 6214     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0286   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3604     |
|    fps              | 109      |
|    time_elapsed     | 591      |
|    total_timesteps  | 64925    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000101 |
|    n_updates        | 6231     |
----------------------------------
Eval num_timesteps=65000, episode_reward=-0.04 +/- 0.33
Episode length: 34.28 +/- 21.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.3     |
|    mean_reward      | -0.0362  |
| rollout/            |          |
|    exploration_rate | 0.977    |
| time/               |          |
|    total_timesteps  | 65000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00652  |
|    n_updates        | 6249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3608     |
|    fps              | 109      |
|    time_elapsed     | 594      |
|    total_timesteps  | 65007    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00777  |
|    n_updates        | 6251     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3612     |
|    fps              | 109      |
|    time_elapsed     | 594      |
|    total_timesteps  | 65076    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000431 |
|    n_updates        | 6268     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3616     |
|    fps              | 109      |
|    time_elapsed     | 594      |
|    total_timesteps  | 65141    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000216 |
|    n_updates        | 6285     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0084   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3620     |
|    fps              | 109      |
|    time_elapsed     | 594      |
|    total_timesteps  | 65209    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000159 |
|    n_updates        | 6302     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3624     |
|    fps              | 109      |
|    time_elapsed     | 594      |
|    total_timesteps  | 65278    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000256 |
|    n_updates        | 6319     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3628     |
|    fps              | 109      |
|    time_elapsed     | 594      |
|    total_timesteps  | 65347    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000289 |
|    n_updates        | 6336     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 3632     |
|    fps              | 110      |
|    time_elapsed     | 594      |
|    total_timesteps  | 65409    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00716  |
|    n_updates        | 6352     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0012  |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3636     |
|    fps              | 110      |
|    time_elapsed     | 594      |
|    total_timesteps  | 65496    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00594  |
|    n_updates        | 6373     |
----------------------------------
Eval num_timesteps=65500, episode_reward=-0.01 +/- 0.34
Episode length: 38.98 +/- 20.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39       |
|    mean_reward      | -0.015   |
| rollout/            |          |
|    exploration_rate | 0.976    |
| time/               |          |
|    total_timesteps  | 65500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000168 |
|    n_updates        | 6374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00084 |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3640     |
|    fps              | 109      |
|    time_elapsed     | 597      |
|    total_timesteps  | 65567    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000252 |
|    n_updates        | 6391     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3644     |
|    fps              | 109      |
|    time_elapsed     | 597      |
|    total_timesteps  | 65630    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000197 |
|    n_updates        | 6407     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3648     |
|    fps              | 109      |
|    time_elapsed     | 597      |
|    total_timesteps  | 65710    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0003   |
|    n_updates        | 6427     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00994 |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3652     |
|    fps              | 110      |
|    time_elapsed     | 597      |
|    total_timesteps  | 65777    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000486 |
|    n_updates        | 6444     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3656     |
|    fps              | 110      |
|    time_elapsed     | 597      |
|    total_timesteps  | 65848    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00732  |
|    n_updates        | 6461     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00945 |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3660     |
|    fps              | 110      |
|    time_elapsed     | 597      |
|    total_timesteps  | 65915    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00746  |
|    n_updates        | 6478     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00953 |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3664     |
|    fps              | 110      |
|    time_elapsed     | 597      |
|    total_timesteps  | 65985    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000257 |
|    n_updates        | 6496     |
----------------------------------
Eval num_timesteps=66000, episode_reward=-0.16 +/- 0.15
Episode length: 46.12 +/- 22.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | -0.164   |
| rollout/            |          |
|    exploration_rate | 0.976    |
| time/               |          |
|    total_timesteps  | 66000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00715  |
|    n_updates        | 6499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00921 |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3668     |
|    fps              | 109      |
|    time_elapsed     | 600      |
|    total_timesteps  | 66054    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000464 |
|    n_updates        | 6513     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00102  |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 3672     |
|    fps              | 110      |
|    time_elapsed     | 601      |
|    total_timesteps  | 66114    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0128   |
|    n_updates        | 6528     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00926 |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3676     |
|    fps              | 110      |
|    time_elapsed     | 601      |
|    total_timesteps  | 66181    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000177 |
|    n_updates        | 6545     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00942 |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3680     |
|    fps              | 110      |
|    time_elapsed     | 601      |
|    total_timesteps  | 66253    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000233 |
|    n_updates        | 6563     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00029  |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3684     |
|    fps              | 110      |
|    time_elapsed     | 601      |
|    total_timesteps  | 66340    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000205 |
|    n_updates        | 6584     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00099  |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3688     |
|    fps              | 110      |
|    time_elapsed     | 601      |
|    total_timesteps  | 66403    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00031  |
|    n_updates        | 6600     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0209   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3692     |
|    fps              | 110      |
|    time_elapsed     | 601      |
|    total_timesteps  | 66476    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00017  |
|    n_updates        | 6618     |
----------------------------------
Eval num_timesteps=66500, episode_reward=-0.03 +/- 0.24
Episode length: 22.40 +/- 5.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22.4     |
|    mean_reward      | -0.0286  |
| rollout/            |          |
|    exploration_rate | 0.975    |
| time/               |          |
|    total_timesteps  | 66500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000342 |
|    n_updates        | 6624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3696     |
|    fps              | 110      |
|    time_elapsed     | 603      |
|    total_timesteps  | 66554    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000131 |
|    n_updates        | 6638     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3700     |
|    fps              | 110      |
|    time_elapsed     | 603      |
|    total_timesteps  | 66629    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000128 |
|    n_updates        | 6657     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3704     |
|    fps              | 110      |
|    time_elapsed     | 603      |
|    total_timesteps  | 66696    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000266 |
|    n_updates        | 6673     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0311   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3708     |
|    fps              | 110      |
|    time_elapsed     | 603      |
|    total_timesteps  | 66756    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000205 |
|    n_updates        | 6688     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 3712     |
|    fps              | 110      |
|    time_elapsed     | 603      |
|    total_timesteps  | 66839    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00599  |
|    n_updates        | 6709     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0297   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3716     |
|    fps              | 110      |
|    time_elapsed     | 603      |
|    total_timesteps  | 66924    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00617  |
|    n_updates        | 6730     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0498   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3720     |
|    fps              | 110      |
|    time_elapsed     | 603      |
|    total_timesteps  | 66989    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000313 |
|    n_updates        | 6747     |
----------------------------------
Eval num_timesteps=67000, episode_reward=0.08 +/- 0.41
Episode length: 31.00 +/- 18.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 31       |
|    mean_reward      | 0.0772   |
| rollout/            |          |
|    exploration_rate | 0.974    |
| time/               |          |
|    total_timesteps  | 67000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000259 |
|    n_updates        | 6749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0496   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3724     |
|    fps              | 110      |
|    time_elapsed     | 605      |
|    total_timesteps  | 67065    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000198 |
|    n_updates        | 6766     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0496   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3728     |
|    fps              | 110      |
|    time_elapsed     | 605      |
|    total_timesteps  | 67134    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000275 |
|    n_updates        | 6783     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0392   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3732     |
|    fps              | 110      |
|    time_elapsed     | 605      |
|    total_timesteps  | 67204    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000304 |
|    n_updates        | 6800     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3736     |
|    fps              | 111      |
|    time_elapsed     | 605      |
|    total_timesteps  | 67271    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000358 |
|    n_updates        | 6817     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0301   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3740     |
|    fps              | 111      |
|    time_elapsed     | 605      |
|    total_timesteps  | 67340    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000158 |
|    n_updates        | 6834     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0299   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3744     |
|    fps              | 111      |
|    time_elapsed     | 605      |
|    total_timesteps  | 67409    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00773  |
|    n_updates        | 6852     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0303   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3748     |
|    fps              | 111      |
|    time_elapsed     | 606      |
|    total_timesteps  | 67478    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00676  |
|    n_updates        | 6869     |
----------------------------------
Eval num_timesteps=67500, episode_reward=-0.29 +/- 0.03
Episode length: 73.26 +/- 8.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.3     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.974    |
| time/               |          |
|    total_timesteps  | 67500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00564  |
|    n_updates        | 6874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0404   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3752     |
|    fps              | 110      |
|    time_elapsed     | 610      |
|    total_timesteps  | 67542    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00785  |
|    n_updates        | 6885     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0406   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3756     |
|    fps              | 110      |
|    time_elapsed     | 610      |
|    total_timesteps  | 67610    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000364 |
|    n_updates        | 6902     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3760     |
|    fps              | 110      |
|    time_elapsed     | 610      |
|    total_timesteps  | 67678    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0067   |
|    n_updates        | 6919     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0302   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3764     |
|    fps              | 110      |
|    time_elapsed     | 611      |
|    total_timesteps  | 67756    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000382 |
|    n_updates        | 6938     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0299   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3768     |
|    fps              | 110      |
|    time_elapsed     | 611      |
|    total_timesteps  | 67831    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000157 |
|    n_updates        | 6957     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3772     |
|    fps              | 111      |
|    time_elapsed     | 611      |
|    total_timesteps  | 67911    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000479 |
|    n_updates        | 6977     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3776     |
|    fps              | 111      |
|    time_elapsed     | 611      |
|    total_timesteps  | 67978    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000104 |
|    n_updates        | 6994     |
----------------------------------
Eval num_timesteps=68000, episode_reward=-0.11 +/- 0.23
Episode length: 42.86 +/- 19.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | -0.11    |
| rollout/            |          |
|    exploration_rate | 0.973    |
| time/               |          |
|    total_timesteps  | 68000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000148 |
|    n_updates        | 6999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.029    |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3780     |
|    fps              | 110      |
|    time_elapsed     | 614      |
|    total_timesteps  | 68054    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00714  |
|    n_updates        | 7013     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3784     |
|    fps              | 110      |
|    time_elapsed     | 614      |
|    total_timesteps  | 68132    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0132   |
|    n_updates        | 7032     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00867  |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3788     |
|    fps              | 111      |
|    time_elapsed     | 614      |
|    total_timesteps  | 68212    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000163 |
|    n_updates        | 7052     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3792     |
|    fps              | 111      |
|    time_elapsed     | 614      |
|    total_timesteps  | 68288    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000257 |
|    n_updates        | 7071     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0011  |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3796     |
|    fps              | 111      |
|    time_elapsed     | 614      |
|    total_timesteps  | 68358    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000196 |
|    n_updates        | 7089     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0015  |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3800     |
|    fps              | 111      |
|    time_elapsed     | 614      |
|    total_timesteps  | 68443    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00805  |
|    n_updates        | 7110     |
----------------------------------
Eval num_timesteps=68500, episode_reward=-0.15 +/- 0.20
Episode length: 47.88 +/- 20.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.9     |
|    mean_reward      | -0.151   |
| rollout/            |          |
|    exploration_rate | 0.972    |
| time/               |          |
|    total_timesteps  | 68500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.007    |
|    n_updates        | 7124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00147 |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3804     |
|    fps              | 110      |
|    time_elapsed     | 617      |
|    total_timesteps  | 68509    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000345 |
|    n_updates        | 7127     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3808     |
|    fps              | 111      |
|    time_elapsed     | 617      |
|    total_timesteps  | 68582    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00706  |
|    n_updates        | 7145     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3812     |
|    fps              | 111      |
|    time_elapsed     | 617      |
|    total_timesteps  | 68656    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000159 |
|    n_updates        | 7163     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3816     |
|    fps              | 111      |
|    time_elapsed     | 617      |
|    total_timesteps  | 68718    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00667  |
|    n_updates        | 7179     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0315  |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3820     |
|    fps              | 111      |
|    time_elapsed     | 618      |
|    total_timesteps  | 68802    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00775  |
|    n_updates        | 7200     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0314  |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3824     |
|    fps              | 111      |
|    time_elapsed     | 618      |
|    total_timesteps  | 68875    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00636  |
|    n_updates        | 7218     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3828     |
|    fps              | 111      |
|    time_elapsed     | 618      |
|    total_timesteps  | 68952    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000378 |
|    n_updates        | 7237     |
----------------------------------
Eval num_timesteps=69000, episode_reward=-0.19 +/- 0.08
Episode length: 48.16 +/- 19.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.2     |
|    mean_reward      | -0.192   |
| rollout/            |          |
|    exploration_rate | 0.971    |
| time/               |          |
|    total_timesteps  | 69000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000376 |
|    n_updates        | 7249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3832     |
|    fps              | 111      |
|    time_elapsed     | 621      |
|    total_timesteps  | 69023    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000229 |
|    n_updates        | 7255     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00145 |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3836     |
|    fps              | 111      |
|    time_elapsed     | 621      |
|    total_timesteps  | 69083    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000587 |
|    n_updates        | 7270     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00181 |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3840     |
|    fps              | 111      |
|    time_elapsed     | 621      |
|    total_timesteps  | 69161    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.13e-05 |
|    n_updates        | 7290     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00225 |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3844     |
|    fps              | 111      |
|    time_elapsed     | 621      |
|    total_timesteps  | 69241    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00678  |
|    n_updates        | 7310     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00245 |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3848     |
|    fps              | 111      |
|    time_elapsed     | 621      |
|    total_timesteps  | 69315    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000384 |
|    n_updates        | 7328     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3852     |
|    fps              | 111      |
|    time_elapsed     | 621      |
|    total_timesteps  | 69398    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00671  |
|    n_updates        | 7349     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3856     |
|    fps              | 111      |
|    time_elapsed     | 621      |
|    total_timesteps  | 69468    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00668  |
|    n_updates        | 7366     |
----------------------------------
Eval num_timesteps=69500, episode_reward=-0.12 +/- 0.30
Episode length: 48.96 +/- 23.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49       |
|    mean_reward      | -0.115   |
| rollout/            |          |
|    exploration_rate | 0.971    |
| time/               |          |
|    total_timesteps  | 69500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.44e-05 |
|    n_updates        | 7374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3860     |
|    fps              | 111      |
|    time_elapsed     | 624      |
|    total_timesteps  | 69536    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00037  |
|    n_updates        | 7383     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3864     |
|    fps              | 111      |
|    time_elapsed     | 624      |
|    total_timesteps  | 69614    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000195 |
|    n_updates        | 7403     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3868     |
|    fps              | 111      |
|    time_elapsed     | 624      |
|    total_timesteps  | 69690    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000394 |
|    n_updates        | 7422     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3872     |
|    fps              | 111      |
|    time_elapsed     | 625      |
|    total_timesteps  | 69758    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000142 |
|    n_updates        | 7439     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3876     |
|    fps              | 111      |
|    time_elapsed     | 625      |
|    total_timesteps  | 69846    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00767  |
|    n_updates        | 7461     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3880     |
|    fps              | 111      |
|    time_elapsed     | 625      |
|    total_timesteps  | 69921    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000151 |
|    n_updates        | 7480     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00274 |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3884     |
|    fps              | 111      |
|    time_elapsed     | 625      |
|    total_timesteps  | 69976    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000384 |
|    n_updates        | 7493     |
----------------------------------
Eval num_timesteps=70000, episode_reward=0.06 +/- 0.33
Episode length: 14.60 +/- 1.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0626   |
| rollout/            |          |
|    exploration_rate | 0.97     |
| time/               |          |
|    total_timesteps  | 70000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000521 |
|    n_updates        | 7499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00812  |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3888     |
|    fps              | 111      |
|    time_elapsed     | 626      |
|    total_timesteps  | 70035    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000436 |
|    n_updates        | 7508     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00844  |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3892     |
|    fps              | 111      |
|    time_elapsed     | 626      |
|    total_timesteps  | 70103    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00853  |
|    n_updates        | 7525     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00154 |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3896     |
|    fps              | 112      |
|    time_elapsed     | 626      |
|    total_timesteps  | 70172    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000344 |
|    n_updates        | 7542     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00086 |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3900     |
|    fps              | 112      |
|    time_elapsed     | 626      |
|    total_timesteps  | 70240    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00084  |
|    n_updates        | 7559     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0111  |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3904     |
|    fps              | 112      |
|    time_elapsed     | 626      |
|    total_timesteps  | 70311    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00038  |
|    n_updates        | 7577     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.011   |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3908     |
|    fps              | 112      |
|    time_elapsed     | 626      |
|    total_timesteps  | 70382    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000407 |
|    n_updates        | 7595     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0111  |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3912     |
|    fps              | 112      |
|    time_elapsed     | 626      |
|    total_timesteps  | 70458    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000196 |
|    n_updates        | 7614     |
----------------------------------
Eval num_timesteps=70500, episode_reward=-0.29 +/- 0.06
Episode length: 71.40 +/- 14.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.4     |
|    mean_reward      | -0.286   |
| rollout/            |          |
|    exploration_rate | 0.969    |
| time/               |          |
|    total_timesteps  | 70500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000353 |
|    n_updates        | 7624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3916     |
|    fps              | 111      |
|    time_elapsed     | 631      |
|    total_timesteps  | 70524    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000281 |
|    n_updates        | 7630     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00048 |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3920     |
|    fps              | 111      |
|    time_elapsed     | 631      |
|    total_timesteps  | 70590    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00681  |
|    n_updates        | 7647     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0097   |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3924     |
|    fps              | 111      |
|    time_elapsed     | 631      |
|    total_timesteps  | 70659    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000301 |
|    n_updates        | 7664     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00984  |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3928     |
|    fps              | 111      |
|    time_elapsed     | 631      |
|    total_timesteps  | 70732    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00754  |
|    n_updates        | 7682     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3932     |
|    fps              | 112      |
|    time_elapsed     | 631      |
|    total_timesteps  | 70799    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000169 |
|    n_updates        | 7699     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3936     |
|    fps              | 112      |
|    time_elapsed     | 631      |
|    total_timesteps  | 70874    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00572  |
|    n_updates        | 7718     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0298   |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3940     |
|    fps              | 112      |
|    time_elapsed     | 631      |
|    total_timesteps  | 70943    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00633  |
|    n_updates        | 7735     |
----------------------------------
Eval num_timesteps=71000, episode_reward=-0.06 +/- 0.34
Episode length: 46.36 +/- 23.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.4     |
|    mean_reward      | -0.0648  |
| rollout/            |          |
|    exploration_rate | 0.968    |
| time/               |          |
|    total_timesteps  | 71000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0081   |
|    n_updates        | 7749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0302   |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3944     |
|    fps              | 111      |
|    time_elapsed     | 634      |
|    total_timesteps  | 71012    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00822  |
|    n_updates        | 7752     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0509   |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3948     |
|    fps              | 111      |
|    time_elapsed     | 634      |
|    total_timesteps  | 71071    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000298 |
|    n_updates        | 7767     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0612   |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3952     |
|    fps              | 112      |
|    time_elapsed     | 634      |
|    total_timesteps  | 71145    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00041  |
|    n_updates        | 7786     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0712   |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3956     |
|    fps              | 112      |
|    time_elapsed     | 635      |
|    total_timesteps  | 71217    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0076   |
|    n_updates        | 7804     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0706   |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3960     |
|    fps              | 112      |
|    time_elapsed     | 635      |
|    total_timesteps  | 71299    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00696  |
|    n_updates        | 7824     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0806   |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3964     |
|    fps              | 112      |
|    time_elapsed     | 635      |
|    total_timesteps  | 71377    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000519 |
|    n_updates        | 7844     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0807   |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3968     |
|    fps              | 112      |
|    time_elapsed     | 635      |
|    total_timesteps  | 71452    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000552 |
|    n_updates        | 7862     |
----------------------------------
Eval num_timesteps=71500, episode_reward=-0.27 +/- 0.15
Episode length: 72.52 +/- 11.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.5     |
|    mean_reward      | -0.27    |
| rollout/            |          |
|    exploration_rate | 0.968    |
| time/               |          |
|    total_timesteps  | 71500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00669  |
|    n_updates        | 7874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0806   |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3972     |
|    fps              | 111      |
|    time_elapsed     | 639      |
|    total_timesteps  | 71521    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00652  |
|    n_updates        | 7880     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0813   |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3976     |
|    fps              | 111      |
|    time_elapsed     | 639      |
|    total_timesteps  | 71592    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000353 |
|    n_updates        | 7897     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0714   |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3980     |
|    fps              | 111      |
|    time_elapsed     | 639      |
|    total_timesteps  | 71664    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000435 |
|    n_updates        | 7915     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0607   |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3984     |
|    fps              | 112      |
|    time_elapsed     | 640      |
|    total_timesteps  | 71738    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00656  |
|    n_updates        | 7934     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0502   |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3988     |
|    fps              | 112      |
|    time_elapsed     | 640      |
|    total_timesteps  | 71808    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00011  |
|    n_updates        | 7951     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3992     |
|    fps              | 112      |
|    time_elapsed     | 640      |
|    total_timesteps  | 71880    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000528 |
|    n_updates        | 7969     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0595   |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3996     |
|    fps              | 112      |
|    time_elapsed     | 640      |
|    total_timesteps  | 71962    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000763 |
|    n_updates        | 7990     |
----------------------------------
Eval num_timesteps=72000, episode_reward=-0.05 +/- 0.36
Episode length: 47.02 +/- 25.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47       |
|    mean_reward      | -0.0473  |
| rollout/            |          |
|    exploration_rate | 0.967    |
| time/               |          |
|    total_timesteps  | 72000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0125   |
|    n_updates        | 7999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0694   |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 4000     |
|    fps              | 111      |
|    time_elapsed     | 643      |
|    total_timesteps  | 72034    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0075   |
|    n_updates        | 8008     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0694   |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 4004     |
|    fps              | 112      |
|    time_elapsed     | 643      |
|    total_timesteps  | 72104    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000488 |
|    n_updates        | 8025     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0688   |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 4008     |
|    fps              | 112      |
|    time_elapsed     | 643      |
|    total_timesteps  | 72191    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000264 |
|    n_updates        | 8047     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0791   |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 4012     |
|    fps              | 112      |
|    time_elapsed     | 643      |
|    total_timesteps  | 72259    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00546  |
|    n_updates        | 8064     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0785   |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 4016     |
|    fps              | 112      |
|    time_elapsed     | 643      |
|    total_timesteps  | 72341    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000379 |
|    n_updates        | 8085     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0784   |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 4020     |
|    fps              | 112      |
|    time_elapsed     | 644      |
|    total_timesteps  | 72408    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000248 |
|    n_updates        | 8101     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0789   |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 4024     |
|    fps              | 112      |
|    time_elapsed     | 644      |
|    total_timesteps  | 72466    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000264 |
|    n_updates        | 8116     |
----------------------------------
Eval num_timesteps=72500, episode_reward=-0.19 +/- 0.10
Episode length: 48.04 +/- 24.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48       |
|    mean_reward      | -0.192   |
| rollout/            |          |
|    exploration_rate | 0.966    |
| time/               |          |
|    total_timesteps  | 72500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000314 |
|    n_updates        | 8124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0692   |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 4028     |
|    fps              | 112      |
|    time_elapsed     | 647      |
|    total_timesteps  | 72532    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00775  |
|    n_updates        | 8132     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0587   |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 4032     |
|    fps              | 112      |
|    time_elapsed     | 647      |
|    total_timesteps  | 72609    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00665  |
|    n_updates        | 8152     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0488   |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 4036     |
|    fps              | 112      |
|    time_elapsed     | 647      |
|    total_timesteps  | 72683    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000363 |
|    n_updates        | 8170     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0591   |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 4040     |
|    fps              | 112      |
|    time_elapsed     | 647      |
|    total_timesteps  | 72744    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000328 |
|    n_updates        | 8185     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.069    |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 4044     |
|    fps              | 112      |
|    time_elapsed     | 647      |
|    total_timesteps  | 72815    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00664  |
|    n_updates        | 8203     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 4048     |
|    fps              | 112      |
|    time_elapsed     | 647      |
|    total_timesteps  | 72884    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000512 |
|    n_updates        | 8220     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0483   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 4052     |
|    fps              | 112      |
|    time_elapsed     | 647      |
|    total_timesteps  | 72965    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00688  |
|    n_updates        | 8241     |
----------------------------------
Eval num_timesteps=73000, episode_reward=-0.19 +/- 0.16
Episode length: 52.30 +/- 22.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.3     |
|    mean_reward      | -0.189   |
| rollout/            |          |
|    exploration_rate | 0.965    |
| time/               |          |
|    total_timesteps  | 73000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0132   |
|    n_updates        | 8249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0484   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 4056     |
|    fps              | 112      |
|    time_elapsed     | 651      |
|    total_timesteps  | 73035    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00653  |
|    n_updates        | 8258     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0689   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 4060     |
|    fps              | 112      |
|    time_elapsed     | 651      |
|    total_timesteps  | 73102    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00707  |
|    n_updates        | 8275     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0794   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 4064     |
|    fps              | 112      |
|    time_elapsed     | 651      |
|    total_timesteps  | 73168    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00796  |
|    n_updates        | 8291     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0894   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 4068     |
|    fps              | 112      |
|    time_elapsed     | 651      |
|    total_timesteps  | 73243    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000389 |
|    n_updates        | 8310     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0892   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 4072     |
|    fps              | 112      |
|    time_elapsed     | 651      |
|    total_timesteps  | 73318    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000437 |
|    n_updates        | 8329     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0892   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 4076     |
|    fps              | 112      |
|    time_elapsed     | 651      |
|    total_timesteps  | 73389    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00586  |
|    n_updates        | 8347     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0993   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 4080     |
|    fps              | 112      |
|    time_elapsed     | 651      |
|    total_timesteps  | 73457    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000525 |
|    n_updates        | 8364     |
----------------------------------
Eval num_timesteps=73500, episode_reward=-0.14 +/- 0.17
Episode length: 39.56 +/- 21.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.6     |
|    mean_reward      | -0.137   |
| rollout/            |          |
|    exploration_rate | 0.965    |
| time/               |          |
|    total_timesteps  | 73500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000541 |
|    n_updates        | 8374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0997   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 4084     |
|    fps              | 112      |
|    time_elapsed     | 654      |
|    total_timesteps  | 73522    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000429 |
|    n_updates        | 8380     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 4088     |
|    fps              | 112      |
|    time_elapsed     | 654      |
|    total_timesteps  | 73590    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000287 |
|    n_updates        | 8397     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0991   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 4092     |
|    fps              | 112      |
|    time_elapsed     | 654      |
|    total_timesteps  | 73680    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00555  |
|    n_updates        | 8419     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0992   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 4096     |
|    fps              | 112      |
|    time_elapsed     | 654      |
|    total_timesteps  | 73759    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000285 |
|    n_updates        | 8439     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0893   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 4100     |
|    fps              | 112      |
|    time_elapsed     | 654      |
|    total_timesteps  | 73827    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000238 |
|    n_updates        | 8456     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0891   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 4104     |
|    fps              | 112      |
|    time_elapsed     | 654      |
|    total_timesteps  | 73902    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000566 |
|    n_updates        | 8475     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0897   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 4108     |
|    fps              | 112      |
|    time_elapsed     | 654      |
|    total_timesteps  | 73975    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000338 |
|    n_updates        | 8493     |
----------------------------------
Eval num_timesteps=74000, episode_reward=-0.11 +/- 0.21
Episode length: 37.14 +/- 22.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.1     |
|    mean_reward      | -0.108   |
| rollout/            |          |
|    exploration_rate | 0.964    |
| time/               |          |
|    total_timesteps  | 74000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00628  |
|    n_updates        | 8499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0896   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 4112     |
|    fps              | 112      |
|    time_elapsed     | 657      |
|    total_timesteps  | 74044    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000506 |
|    n_updates        | 8510     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0903   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 4116     |
|    fps              | 112      |
|    time_elapsed     | 657      |
|    total_timesteps  | 74109    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000586 |
|    n_updates        | 8527     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0804   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 4120     |
|    fps              | 112      |
|    time_elapsed     | 657      |
|    total_timesteps  | 74173    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000426 |
|    n_updates        | 8543     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0797   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 4124     |
|    fps              | 112      |
|    time_elapsed     | 657      |
|    total_timesteps  | 74249    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000585 |
|    n_updates        | 8562     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0698   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 4128     |
|    fps              | 113      |
|    time_elapsed     | 657      |
|    total_timesteps  | 74314    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000305 |
|    n_updates        | 8578     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0702   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 4132     |
|    fps              | 113      |
|    time_elapsed     | 657      |
|    total_timesteps  | 74381    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00586  |
|    n_updates        | 8595     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0704   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 4136     |
|    fps              | 113      |
|    time_elapsed     | 657      |
|    total_timesteps  | 74449    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000352 |
|    n_updates        | 8612     |
----------------------------------
Eval num_timesteps=74500, episode_reward=0.00 +/- 0.24
Episode length: 14.82 +/- 0.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00178  |
| rollout/            |          |
|    exploration_rate | 0.963    |
| time/               |          |
|    total_timesteps  | 74500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000321 |
|    n_updates        | 8624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0494   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 4140     |
|    fps              | 113      |
|    time_elapsed     | 658      |
|    total_timesteps  | 74536    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000693 |
|    n_updates        | 8633     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0392   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 4144     |
|    fps              | 113      |
|    time_elapsed     | 658      |
|    total_timesteps  | 74611    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000504 |
|    n_updates        | 8652     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 4148     |
|    fps              | 113      |
|    time_elapsed     | 658      |
|    total_timesteps  | 74679    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000183 |
|    n_updates        | 8669     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0593   |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 4152     |
|    fps              | 113      |
|    time_elapsed     | 659      |
|    total_timesteps  | 74761    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00041  |
|    n_updates        | 8690     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 4156     |
|    fps              | 113      |
|    time_elapsed     | 659      |
|    total_timesteps  | 74847    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000334 |
|    n_updates        | 8711     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0386   |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 4160     |
|    fps              | 113      |
|    time_elapsed     | 659      |
|    total_timesteps  | 74914    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000424 |
|    n_updates        | 8728     |
----------------------------------
Eval num_timesteps=75000, episode_reward=-0.24 +/- 0.09
Episode length: 60.74 +/- 22.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60.7     |
|    mean_reward      | -0.243   |
| rollout/            |          |
|    exploration_rate | 0.962    |
| time/               |          |
|    total_timesteps  | 75000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00587  |
|    n_updates        | 8749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 4164     |
|    fps              | 113      |
|    time_elapsed     | 663      |
|    total_timesteps  | 75016    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00672  |
|    n_updates        | 8753     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00757  |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 4168     |
|    fps              | 113      |
|    time_elapsed     | 663      |
|    total_timesteps  | 75081    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000437 |
|    n_updates        | 8770     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00765  |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 4172     |
|    fps              | 113      |
|    time_elapsed     | 663      |
|    total_timesteps  | 75154    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000513 |
|    n_updates        | 8788     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00625  |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 4176     |
|    fps              | 113      |
|    time_elapsed     | 663      |
|    total_timesteps  | 75260    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000324 |
|    n_updates        | 8814     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00387 |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 4180     |
|    fps              | 113      |
|    time_elapsed     | 663      |
|    total_timesteps  | 75331    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000436 |
|    n_updates        | 8832     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00427 |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 4184     |
|    fps              | 113      |
|    time_elapsed     | 663      |
|    total_timesteps  | 75406    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00641  |
|    n_updates        | 8851     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 4188     |
|    fps              | 113      |
|    time_elapsed     | 663      |
|    total_timesteps  | 75477    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000321 |
|    n_updates        | 8869     |
----------------------------------
Eval num_timesteps=75500, episode_reward=-0.01 +/- 0.32
Episode length: 32.82 +/- 18.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 32.8     |
|    mean_reward      | -0.0104  |
| rollout/            |          |
|    exploration_rate | 0.961    |
| time/               |          |
|    total_timesteps  | 75500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000463 |
|    n_updates        | 8874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 4192     |
|    fps              | 113      |
|    time_elapsed     | 665      |
|    total_timesteps  | 75543    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000198 |
|    n_updates        | 8885     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 4196     |
|    fps              | 113      |
|    time_elapsed     | 665      |
|    total_timesteps  | 75610    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00816  |
|    n_updates        | 8902     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 4200     |
|    fps              | 113      |
|    time_elapsed     | 666      |
|    total_timesteps  | 75677    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0066   |
|    n_updates        | 8919     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0125  |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 4204     |
|    fps              | 113      |
|    time_elapsed     | 666      |
|    total_timesteps  | 75742    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000415 |
|    n_updates        | 8935     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 4208     |
|    fps              | 113      |
|    time_elapsed     | 666      |
|    total_timesteps  | 75823    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000174 |
|    n_updates        | 8955     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00267 |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 4212     |
|    fps              | 113      |
|    time_elapsed     | 666      |
|    total_timesteps  | 75888    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000268 |
|    n_updates        | 8971     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00315 |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 4216     |
|    fps              | 113      |
|    time_elapsed     | 666      |
|    total_timesteps  | 75965    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000423 |
|    n_updates        | 8991     |
----------------------------------
Eval num_timesteps=76000, episode_reward=-0.16 +/- 0.17
Episode length: 46.30 +/- 24.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.3     |
|    mean_reward      | -0.165   |
| rollout/            |          |
|    exploration_rate | 0.96     |
| time/               |          |
|    total_timesteps  | 76000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000775 |
|    n_updates        | 8999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00674  |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 4220     |
|    fps              | 113      |
|    time_elapsed     | 669      |
|    total_timesteps  | 76032    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000402 |
|    n_updates        | 9007     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0028  |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 4224     |
|    fps              | 113      |
|    time_elapsed     | 669      |
|    total_timesteps  | 76096    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000514 |
|    n_updates        | 9023     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 4228     |
|    fps              | 113      |
|    time_elapsed     | 669      |
|    total_timesteps  | 76177    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000447 |
|    n_updates        | 9044     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0364   |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 4232     |
|    fps              | 113      |
|    time_elapsed     | 669      |
|    total_timesteps  | 76249    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000294 |
|    n_updates        | 9062     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 4236     |
|    fps              | 113      |
|    time_elapsed     | 669      |
|    total_timesteps  | 76324    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00767  |
|    n_updates        | 9080     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0468   |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 4240     |
|    fps              | 114      |
|    time_elapsed     | 669      |
|    total_timesteps  | 76393    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000463 |
|    n_updates        | 9098     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0465   |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 4244     |
|    fps              | 114      |
|    time_elapsed     | 669      |
|    total_timesteps  | 76475    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00739  |
|    n_updates        | 9118     |
----------------------------------
Eval num_timesteps=76500, episode_reward=-0.09 +/- 0.23
Episode length: 31.62 +/- 22.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 31.6     |
|    mean_reward      | -0.0856  |
| rollout/            |          |
|    exploration_rate | 0.96     |
| time/               |          |
|    total_timesteps  | 76500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000822 |
|    n_updates        | 9124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.026    |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 4248     |
|    fps              | 113      |
|    time_elapsed     | 672      |
|    total_timesteps  | 76555    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000409 |
|    n_updates        | 9138     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0267   |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 4252     |
|    fps              | 113      |
|    time_elapsed     | 672      |
|    total_timesteps  | 76620    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000397 |
|    n_updates        | 9154     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 4256     |
|    fps              | 114      |
|    time_elapsed     | 672      |
|    total_timesteps  | 76689    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000496 |
|    n_updates        | 9172     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 4260     |
|    fps              | 114      |
|    time_elapsed     | 672      |
|    total_timesteps  | 76767    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00562  |
|    n_updates        | 9191     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 4264     |
|    fps              | 114      |
|    time_elapsed     | 672      |
|    total_timesteps  | 76842    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000425 |
|    n_updates        | 9210     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 4268     |
|    fps              | 114      |
|    time_elapsed     | 672      |
|    total_timesteps  | 76901    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00634  |
|    n_updates        | 9225     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0483   |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 4272     |
|    fps              | 114      |
|    time_elapsed     | 672      |
|    total_timesteps  | 76972    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0206   |
|    n_updates        | 9242     |
----------------------------------
Eval num_timesteps=77000, episode_reward=-0.13 +/- 0.24
Episode length: 43.88 +/- 25.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | -0.135   |
| rollout/            |          |
|    exploration_rate | 0.959    |
| time/               |          |
|    total_timesteps  | 77000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000275 |
|    n_updates        | 9249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0597   |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 4276     |
|    fps              | 114      |
|    time_elapsed     | 675      |
|    total_timesteps  | 77045    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00808  |
|    n_updates        | 9261     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0587   |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 4280     |
|    fps              | 114      |
|    time_elapsed     | 675      |
|    total_timesteps  | 77141    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000413 |
|    n_updates        | 9285     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0588   |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 4284     |
|    fps              | 114      |
|    time_elapsed     | 675      |
|    total_timesteps  | 77212    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000455 |
|    n_updates        | 9302     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.059    |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 4288     |
|    fps              | 114      |
|    time_elapsed     | 675      |
|    total_timesteps  | 77278    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000312 |
|    n_updates        | 9319     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0588   |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 4292     |
|    fps              | 114      |
|    time_elapsed     | 675      |
|    total_timesteps  | 77349    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000515 |
|    n_updates        | 9337     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 4296     |
|    fps              | 114      |
|    time_elapsed     | 675      |
|    total_timesteps  | 77421    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000429 |
|    n_updates        | 9355     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0688   |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 4300     |
|    fps              | 114      |
|    time_elapsed     | 675      |
|    total_timesteps  | 77484    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000465 |
|    n_updates        | 9370     |
----------------------------------
Eval num_timesteps=77500, episode_reward=-0.20 +/- 0.23
Episode length: 59.26 +/- 23.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.3     |
|    mean_reward      | -0.197   |
| rollout/            |          |
|    exploration_rate | 0.958    |
| time/               |          |
|    total_timesteps  | 77500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00661  |
|    n_updates        | 9374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0682   |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 4304     |
|    fps              | 114      |
|    time_elapsed     | 679      |
|    total_timesteps  | 77565    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000223 |
|    n_updates        | 9391     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 4308     |
|    fps              | 114      |
|    time_elapsed     | 679      |
|    total_timesteps  | 77633    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000595 |
|    n_updates        | 9408     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0479   |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 4312     |
|    fps              | 114      |
|    time_elapsed     | 679      |
|    total_timesteps  | 77717    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00645  |
|    n_updates        | 9429     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0475   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 4316     |
|    fps              | 114      |
|    time_elapsed     | 680      |
|    total_timesteps  | 77803    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000369 |
|    n_updates        | 9450     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 4320     |
|    fps              | 114      |
|    time_elapsed     | 680      |
|    total_timesteps  | 77868    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000447 |
|    n_updates        | 9466     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0576   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 4324     |
|    fps              | 114      |
|    time_elapsed     | 680      |
|    total_timesteps  | 77933    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000668 |
|    n_updates        | 9483     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0483   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 4328     |
|    fps              | 114      |
|    time_elapsed     | 680      |
|    total_timesteps  | 77997    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000167 |
|    n_updates        | 9499     |
----------------------------------
Eval num_timesteps=78000, episode_reward=-0.15 +/- 0.09
Episode length: 38.62 +/- 22.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.6     |
|    mean_reward      | -0.154   |
| rollout/            |          |
|    exploration_rate | 0.957    |
| time/               |          |
|    total_timesteps  | 78000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0283   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 4332     |
|    fps              | 114      |
|    time_elapsed     | 682      |
|    total_timesteps  | 78068    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000485 |
|    n_updates        | 9516     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 4336     |
|    fps              | 114      |
|    time_elapsed     | 682      |
|    total_timesteps  | 78137    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000292 |
|    n_updates        | 9534     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 4340     |
|    fps              | 114      |
|    time_elapsed     | 682      |
|    total_timesteps  | 78212    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000756 |
|    n_updates        | 9552     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 4344     |
|    fps              | 114      |
|    time_elapsed     | 682      |
|    total_timesteps  | 78297    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000365 |
|    n_updates        | 9574     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 4348     |
|    fps              | 114      |
|    time_elapsed     | 682      |
|    total_timesteps  | 78360    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000302 |
|    n_updates        | 9589     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00842  |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 4352     |
|    fps              | 114      |
|    time_elapsed     | 682      |
|    total_timesteps  | 78435    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000511 |
|    n_updates        | 9608     |
----------------------------------
Eval num_timesteps=78500, episode_reward=-0.18 +/- 0.19
Episode length: 50.42 +/- 25.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.4     |
|    mean_reward      | -0.181   |
| rollout/            |          |
|    exploration_rate | 0.956    |
| time/               |          |
|    total_timesteps  | 78500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00833  |
|    n_updates        | 9624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 4356     |
|    fps              | 114      |
|    time_elapsed     | 686      |
|    total_timesteps  | 78501    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000233 |
|    n_updates        | 9625     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00901  |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 4360     |
|    fps              | 114      |
|    time_elapsed     | 686      |
|    total_timesteps  | 78567    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000455 |
|    n_updates        | 9641     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00917  |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 4364     |
|    fps              | 114      |
|    time_elapsed     | 686      |
|    total_timesteps  | 78638    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000345 |
|    n_updates        | 9659     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00883  |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 4368     |
|    fps              | 114      |
|    time_elapsed     | 686      |
|    total_timesteps  | 78706    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00033  |
|    n_updates        | 9676     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00093 |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 4372     |
|    fps              | 114      |
|    time_elapsed     | 686      |
|    total_timesteps  | 78771    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000687 |
|    n_updates        | 9692     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00962  |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 4376     |
|    fps              | 114      |
|    time_elapsed     | 686      |
|    total_timesteps  | 78831    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000335 |
|    n_updates        | 9707     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 4380     |
|    fps              | 114      |
|    time_elapsed     | 686      |
|    total_timesteps  | 78909    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000407 |
|    n_updates        | 9727     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 4384     |
|    fps              | 115      |
|    time_elapsed     | 686      |
|    total_timesteps  | 78975    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00626  |
|    n_updates        | 9743     |
----------------------------------
Eval num_timesteps=79000, episode_reward=-0.20 +/- 0.18
Episode length: 54.76 +/- 23.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.8     |
|    mean_reward      | -0.199   |
| rollout/            |          |
|    exploration_rate | 0.955    |
| time/               |          |
|    total_timesteps  | 79000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000421 |
|    n_updates        | 9749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 4388     |
|    fps              | 114      |
|    time_elapsed     | 690      |
|    total_timesteps  | 79050    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0126   |
|    n_updates        | 9762     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 4392     |
|    fps              | 114      |
|    time_elapsed     | 690      |
|    total_timesteps  | 79121    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000265 |
|    n_updates        | 9780     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 4396     |
|    fps              | 114      |
|    time_elapsed     | 690      |
|    total_timesteps  | 79195    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000338 |
|    n_updates        | 9798     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00951  |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 4400     |
|    fps              | 114      |
|    time_elapsed     | 690      |
|    total_timesteps  | 79273    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000401 |
|    n_updates        | 9818     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00991  |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 4404     |
|    fps              | 114      |
|    time_elapsed     | 690      |
|    total_timesteps  | 79344    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00013  |
|    n_updates        | 9835     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0298   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 4408     |
|    fps              | 114      |
|    time_elapsed     | 690      |
|    total_timesteps  | 79416    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00633  |
|    n_updates        | 9853     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 4412     |
|    fps              | 115      |
|    time_elapsed     | 690      |
|    total_timesteps  | 79484    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000458 |
|    n_updates        | 9870     |
----------------------------------
Eval num_timesteps=79500, episode_reward=-0.26 +/- 0.08
Episode length: 64.62 +/- 19.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.6     |
|    mean_reward      | -0.258   |
| rollout/            |          |
|    exploration_rate | 0.955    |
| time/               |          |
|    total_timesteps  | 79500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000389 |
|    n_updates        | 9874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.031    |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 4416     |
|    fps              | 114      |
|    time_elapsed     | 694      |
|    total_timesteps  | 79555    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00661  |
|    n_updates        | 9888     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0309   |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 4420     |
|    fps              | 114      |
|    time_elapsed     | 694      |
|    total_timesteps  | 79623    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000248 |
|    n_updates        | 9905     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00998  |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 4424     |
|    fps              | 114      |
|    time_elapsed     | 694      |
|    total_timesteps  | 79710    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000423 |
|    n_updates        | 9927     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00065 |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 4428     |
|    fps              | 114      |
|    time_elapsed     | 694      |
|    total_timesteps  | 79790    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0059   |
|    n_updates        | 9947     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00121 |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 4432     |
|    fps              | 114      |
|    time_elapsed     | 695      |
|    total_timesteps  | 79875    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000264 |
|    n_updates        | 9968     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00181 |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 4436     |
|    fps              | 115      |
|    time_elapsed     | 695      |
|    total_timesteps  | 79959    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000415 |
|    n_updates        | 9989     |
----------------------------------
Eval num_timesteps=80000, episode_reward=-0.18 +/- 0.08
Episode length: 44.94 +/- 19.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | -0.179   |
| rollout/            |          |
|    exploration_rate | 0.954    |
| time/               |          |
|    total_timesteps  | 80000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00644  |
|    n_updates        | 9999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00137 |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 4440     |
|    fps              | 114      |
|    time_elapsed     | 698      |
|    total_timesteps  | 80023    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000485 |
|    n_updates        | 10005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00049 |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 4444     |
|    fps              | 114      |
|    time_elapsed     | 698      |
|    total_timesteps  | 80086    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000743 |
|    n_updates        | 10021    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00121 |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 4448     |
|    fps              | 114      |
|    time_elapsed     | 698      |
|    total_timesteps  | 80167    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000263 |
|    n_updates        | 10041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00121 |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 4452     |
|    fps              | 114      |
|    time_elapsed     | 698      |
|    total_timesteps  | 80242    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0168   |
|    n_updates        | 10060    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0009  |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 4456     |
|    fps              | 114      |
|    time_elapsed     | 698      |
|    total_timesteps  | 80300    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000316 |
|    n_updates        | 10074    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00078 |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 4460     |
|    fps              | 115      |
|    time_elapsed     | 698      |
|    total_timesteps  | 80363    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000828 |
|    n_updates        | 10090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00922  |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 4464     |
|    fps              | 115      |
|    time_elapsed     | 698      |
|    total_timesteps  | 80434    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000397 |
|    n_updates        | 10108    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00067 |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 4468     |
|    fps              | 115      |
|    time_elapsed     | 698      |
|    total_timesteps  | 80499    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0114   |
|    n_updates        | 10124    |
----------------------------------
Eval num_timesteps=80500, episode_reward=-0.28 +/- 0.06
Episode length: 69.14 +/- 16.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 69.1     |
|    mean_reward     | -0.276   |
| time/              |          |
|    total_timesteps | 80500    |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00071 |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 4472     |
|    fps              | 114      |
|    time_elapsed     | 703      |
|    total_timesteps  | 80565    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 10141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 4476     |
|    fps              | 114      |
|    time_elapsed     | 703      |
|    total_timesteps  | 80636    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0124   |
|    n_updates        | 10158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 4480     |
|    fps              | 114      |
|    time_elapsed     | 703      |
|    total_timesteps  | 80701    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00047  |
|    n_updates        | 10175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 4484     |
|    fps              | 114      |
|    time_elapsed     | 703      |
|    total_timesteps  | 80778    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0154   |
|    n_updates        | 10194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0208  |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 4488     |
|    fps              | 114      |
|    time_elapsed     | 703      |
|    total_timesteps  | 80846    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000397 |
|    n_updates        | 10211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00064 |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 4492     |
|    fps              | 114      |
|    time_elapsed     | 703      |
|    total_timesteps  | 80913    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000372 |
|    n_updates        | 10228    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00076 |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 4496     |
|    fps              | 115      |
|    time_elapsed     | 704      |
|    total_timesteps  | 80990    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00681  |
|    n_updates        | 10247    |
----------------------------------
Eval num_timesteps=81000, episode_reward=-0.12 +/- 0.24
Episode length: 45.68 +/- 21.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.7     |
|    mean_reward      | -0.122   |
| rollout/            |          |
|    exploration_rate | 0.952    |
| time/               |          |
|    total_timesteps  | 81000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00755  |
|    n_updates        | 10249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00064 |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 4500     |
|    fps              | 114      |
|    time_elapsed     | 706      |
|    total_timesteps  | 81065    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0125   |
|    n_updates        | 10266    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0006  |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 4504     |
|    fps              | 114      |
|    time_elapsed     | 707      |
|    total_timesteps  | 81135    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000602 |
|    n_updates        | 10283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 4508     |
|    fps              | 114      |
|    time_elapsed     | 707      |
|    total_timesteps  | 81221    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 10305    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 4512     |
|    fps              | 114      |
|    time_elapsed     | 707      |
|    total_timesteps  | 81302    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000297 |
|    n_updates        | 10325    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0215  |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 4516     |
|    fps              | 115      |
|    time_elapsed     | 707      |
|    total_timesteps  | 81367    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00497  |
|    n_updates        | 10341    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.022   |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 4520     |
|    fps              | 115      |
|    time_elapsed     | 707      |
|    total_timesteps  | 81448    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000809 |
|    n_updates        | 10361    |
----------------------------------
Eval num_timesteps=81500, episode_reward=-0.11 +/- 0.22
Episode length: 36.80 +/- 19.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36.8     |
|    mean_reward      | -0.106   |
| rollout/            |          |
|    exploration_rate | 0.951    |
| time/               |          |
|    total_timesteps  | 81500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000463 |
|    n_updates        | 10374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0111  |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 4524     |
|    fps              | 114      |
|    time_elapsed     | 709      |
|    total_timesteps  | 81514    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000667 |
|    n_updates        | 10378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 4528     |
|    fps              | 114      |
|    time_elapsed     | 709      |
|    total_timesteps  | 81600    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0072   |
|    n_updates        | 10399    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0108  |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 4532     |
|    fps              | 115      |
|    time_elapsed     | 709      |
|    total_timesteps  | 81672    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000734 |
|    n_updates        | 10417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00083 |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 4536     |
|    fps              | 115      |
|    time_elapsed     | 710      |
|    total_timesteps  | 81756    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000456 |
|    n_updates        | 10438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00143 |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 4540     |
|    fps              | 115      |
|    time_elapsed     | 710      |
|    total_timesteps  | 81835    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000277 |
|    n_updates        | 10458    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00842  |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 4544     |
|    fps              | 115      |
|    time_elapsed     | 710      |
|    total_timesteps  | 81902    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000508 |
|    n_updates        | 10475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00862  |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 4548     |
|    fps              | 115      |
|    time_elapsed     | 710      |
|    total_timesteps  | 81978    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000364 |
|    n_updates        | 10494    |
----------------------------------
Eval num_timesteps=82000, episode_reward=-0.09 +/- 0.16
Episode length: 27.98 +/- 14.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28       |
|    mean_reward      | -0.091   |
| rollout/            |          |
|    exploration_rate | 0.95     |
| time/               |          |
|    total_timesteps  | 82000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000578 |
|    n_updates        | 10499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00866  |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 4552     |
|    fps              | 115      |
|    time_elapsed     | 712      |
|    total_timesteps  | 82052    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000595 |
|    n_updates        | 10512    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00178 |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 4556     |
|    fps              | 115      |
|    time_elapsed     | 712      |
|    total_timesteps  | 82121    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00716  |
|    n_updates        | 10530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00254 |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 4560     |
|    fps              | 115      |
|    time_elapsed     | 712      |
|    total_timesteps  | 82203    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000484 |
|    n_updates        | 10550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 4564     |
|    fps              | 115      |
|    time_elapsed     | 712      |
|    total_timesteps  | 82279    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0139   |
|    n_updates        | 10569    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 4568     |
|    fps              | 115      |
|    time_elapsed     | 712      |
|    total_timesteps  | 82371    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000804 |
|    n_updates        | 10592    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00419 |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 4572     |
|    fps              | 115      |
|    time_elapsed     | 712      |
|    total_timesteps  | 82446    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00607  |
|    n_updates        | 10611    |
----------------------------------
Eval num_timesteps=82500, episode_reward=0.06 +/- 0.42
Episode length: 30.46 +/- 16.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 30.5     |
|    mean_reward      | 0.0592   |
| rollout/            |          |
|    exploration_rate | 0.949    |
| time/               |          |
|    total_timesteps  | 82500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000588 |
|    n_updates        | 10624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00427 |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 4576     |
|    fps              | 115      |
|    time_elapsed     | 714      |
|    total_timesteps  | 82519    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000407 |
|    n_updates        | 10629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00467 |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 4580     |
|    fps              | 115      |
|    time_elapsed     | 714      |
|    total_timesteps  | 82594    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000602 |
|    n_updates        | 10648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0151  |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 4584     |
|    fps              | 115      |
|    time_elapsed     | 714      |
|    total_timesteps  | 82681    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00528  |
|    n_updates        | 10670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00491 |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 4588     |
|    fps              | 115      |
|    time_elapsed     | 714      |
|    total_timesteps  | 82745    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000463 |
|    n_updates        | 10686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0152  |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 4592     |
|    fps              | 115      |
|    time_elapsed     | 714      |
|    total_timesteps  | 82818    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000657 |
|    n_updates        | 10704    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 4596     |
|    fps              | 115      |
|    time_elapsed     | 714      |
|    total_timesteps  | 82888    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00818  |
|    n_updates        | 10721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0046  |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 4600     |
|    fps              | 116      |
|    time_elapsed     | 715      |
|    total_timesteps  | 82956    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000614 |
|    n_updates        | 10738    |
----------------------------------
Eval num_timesteps=83000, episode_reward=-0.16 +/- 0.28
Episode length: 56.18 +/- 21.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.2     |
|    mean_reward      | -0.164   |
| rollout/            |          |
|    exploration_rate | 0.948    |
| time/               |          |
|    total_timesteps  | 83000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000429 |
|    n_updates        | 10749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00468 |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 4604     |
|    fps              | 115      |
|    time_elapsed     | 717      |
|    total_timesteps  | 83028    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0118   |
|    n_updates        | 10756    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00637  |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 4608     |
|    fps              | 115      |
|    time_elapsed     | 717      |
|    total_timesteps  | 83088    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000658 |
|    n_updates        | 10771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00685  |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 4612     |
|    fps              | 115      |
|    time_elapsed     | 718      |
|    total_timesteps  | 83157    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000766 |
|    n_updates        | 10789    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00641  |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 4616     |
|    fps              | 115      |
|    time_elapsed     | 718      |
|    total_timesteps  | 83233    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000474 |
|    n_updates        | 10808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00617  |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 4620     |
|    fps              | 116      |
|    time_elapsed     | 718      |
|    total_timesteps  | 83320    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00592  |
|    n_updates        | 10829    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00534  |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 4624     |
|    fps              | 116      |
|    time_elapsed     | 718      |
|    total_timesteps  | 83407    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0006   |
|    n_updates        | 10851    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00614  |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 4628     |
|    fps              | 116      |
|    time_elapsed     | 718      |
|    total_timesteps  | 83473    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000147 |
|    n_updates        | 10868    |
----------------------------------
Eval num_timesteps=83500, episode_reward=-0.01 +/- 0.32
Episode length: 36.68 +/- 21.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36.7     |
|    mean_reward      | -0.00574 |
| rollout/            |          |
|    exploration_rate | 0.947    |
| time/               |          |
|    total_timesteps  | 83500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00044  |
|    n_updates        | 10874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.016    |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 4632     |
|    fps              | 115      |
|    time_elapsed     | 720      |
|    total_timesteps  | 83547    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000508 |
|    n_updates        | 10886    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00687  |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 4636     |
|    fps              | 116      |
|    time_elapsed     | 720      |
|    total_timesteps  | 83610    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00749  |
|    n_updates        | 10902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00739  |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 4640     |
|    fps              | 116      |
|    time_elapsed     | 720      |
|    total_timesteps  | 83676    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000876 |
|    n_updates        | 10918    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00262 |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 4644     |
|    fps              | 116      |
|    time_elapsed     | 720      |
|    total_timesteps  | 83743    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00046  |
|    n_updates        | 10935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00254 |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 4648     |
|    fps              | 116      |
|    time_elapsed     | 720      |
|    total_timesteps  | 83817    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000674 |
|    n_updates        | 10954    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00258 |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 4652     |
|    fps              | 116      |
|    time_elapsed     | 721      |
|    total_timesteps  | 83892    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 10972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00286 |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 4656     |
|    fps              | 116      |
|    time_elapsed     | 721      |
|    total_timesteps  | 83968    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00085  |
|    n_updates        | 10991    |
----------------------------------
Eval num_timesteps=84000, episode_reward=-0.00 +/- 0.37
Episode length: 40.24 +/- 24.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.2     |
|    mean_reward      | -4e-05   |
| rollout/            |          |
|    exploration_rate | 0.947    |
| time/               |          |
|    total_timesteps  | 84000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000394 |
|    n_updates        | 10999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 4660     |
|    fps              | 116      |
|    time_elapsed     | 723      |
|    total_timesteps  | 84028    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000998 |
|    n_updates        | 11006    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 4664     |
|    fps              | 116      |
|    time_elapsed     | 723      |
|    total_timesteps  | 84104    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00701  |
|    n_updates        | 11025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.029    |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 4668     |
|    fps              | 116      |
|    time_elapsed     | 723      |
|    total_timesteps  | 84173    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000751 |
|    n_updates        | 11043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 4672     |
|    fps              | 116      |
|    time_elapsed     | 723      |
|    total_timesteps  | 84252    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00551  |
|    n_updates        | 11062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 4676     |
|    fps              | 116      |
|    time_elapsed     | 723      |
|    total_timesteps  | 84345    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00771  |
|    n_updates        | 11086    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0284   |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 4680     |
|    fps              | 116      |
|    time_elapsed     | 723      |
|    total_timesteps  | 84412    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000878 |
|    n_updates        | 11102    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0393   |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 4684     |
|    fps              | 116      |
|    time_elapsed     | 724      |
|    total_timesteps  | 84475    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000713 |
|    n_updates        | 11118    |
----------------------------------
Eval num_timesteps=84500, episode_reward=-0.08 +/- 0.37
Episode length: 49.50 +/- 21.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.5     |
|    mean_reward      | -0.0772  |
| rollout/            |          |
|    exploration_rate | 0.946    |
| time/               |          |
|    total_timesteps  | 84500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00531  |
|    n_updates        | 11124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 4688     |
|    fps              | 116      |
|    time_elapsed     | 727      |
|    total_timesteps  | 84570    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000507 |
|    n_updates        | 11142    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 4692     |
|    fps              | 116      |
|    time_elapsed     | 727      |
|    total_timesteps  | 84636    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00748  |
|    n_updates        | 11158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 4696     |
|    fps              | 116      |
|    time_elapsed     | 727      |
|    total_timesteps  | 84725    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000308 |
|    n_updates        | 11181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.047    |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 4700     |
|    fps              | 116      |
|    time_elapsed     | 727      |
|    total_timesteps  | 84808    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000272 |
|    n_updates        | 11201    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0468   |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 4704     |
|    fps              | 116      |
|    time_elapsed     | 727      |
|    total_timesteps  | 84883    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000527 |
|    n_updates        | 11220    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0364   |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 4708     |
|    fps              | 116      |
|    time_elapsed     | 727      |
|    total_timesteps  | 84953    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00735  |
|    n_updates        | 11238    |
----------------------------------
Eval num_timesteps=85000, episode_reward=-0.15 +/- 0.27
Episode length: 52.74 +/- 24.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.7     |
|    mean_reward      | -0.15    |
| rollout/            |          |
|    exploration_rate | 0.945    |
| time/               |          |
|    total_timesteps  | 85000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000711 |
|    n_updates        | 11249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0469   |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 4712     |
|    fps              | 116      |
|    time_elapsed     | 731      |
|    total_timesteps  | 85012    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000479 |
|    n_updates        | 11252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0467   |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 4716     |
|    fps              | 116      |
|    time_elapsed     | 731      |
|    total_timesteps  | 85092    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000502 |
|    n_updates        | 11272    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0474   |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 4720     |
|    fps              | 116      |
|    time_elapsed     | 731      |
|    total_timesteps  | 85162    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0055   |
|    n_updates        | 11290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 4724     |
|    fps              | 116      |
|    time_elapsed     | 731      |
|    total_timesteps  | 85236    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000493 |
|    n_updates        | 11308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 4728     |
|    fps              | 116      |
|    time_elapsed     | 731      |
|    total_timesteps  | 85309    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000592 |
|    n_updates        | 11327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 4732     |
|    fps              | 116      |
|    time_elapsed     | 731      |
|    total_timesteps  | 85395    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00515  |
|    n_updates        | 11348    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0266   |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 4736     |
|    fps              | 116      |
|    time_elapsed     | 731      |
|    total_timesteps  | 85471    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000685 |
|    n_updates        | 11367    |
----------------------------------
Eval num_timesteps=85500, episode_reward=0.14 +/- 0.48
Episode length: 39.40 +/- 23.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.4     |
|    mean_reward      | 0.143    |
| rollout/            |          |
|    exploration_rate | 0.944    |
| time/               |          |
|    total_timesteps  | 85500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000427 |
|    n_updates        | 11374    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0265   |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 4740     |
|    fps              | 116      |
|    time_elapsed     | 734      |
|    total_timesteps  | 85541    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000563 |
|    n_updates        | 11385    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0262   |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 4744     |
|    fps              | 116      |
|    time_elapsed     | 734      |
|    total_timesteps  | 85615    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000488 |
|    n_updates        | 11403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 4748     |
|    fps              | 116      |
|    time_elapsed     | 734      |
|    total_timesteps  | 85691    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00569  |
|    n_updates        | 11422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 4752     |
|    fps              | 116      |
|    time_elapsed     | 734      |
|    total_timesteps  | 85771    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000475 |
|    n_updates        | 11442    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0358   |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 4756     |
|    fps              | 116      |
|    time_elapsed     | 734      |
|    total_timesteps  | 85850    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0087   |
|    n_updates        | 11462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 4760     |
|    fps              | 116      |
|    time_elapsed     | 734      |
|    total_timesteps  | 85913    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0166   |
|    n_updates        | 11478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00597  |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 4764     |
|    fps              | 117      |
|    time_elapsed     | 734      |
|    total_timesteps  | 85980    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000304 |
|    n_updates        | 11494    |
----------------------------------
Eval num_timesteps=86000, episode_reward=0.03 +/- 0.47
Episode length: 46.58 +/- 24.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.6     |
|    mean_reward      | 0.0345   |
| rollout/            |          |
|    exploration_rate | 0.943    |
| time/               |          |
|    total_timesteps  | 86000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000345 |
|    n_updates        | 11499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.016    |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 4768     |
|    fps              | 116      |
|    time_elapsed     | 737      |
|    total_timesteps  | 86048    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000518 |
|    n_updates        | 11511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 4772     |
|    fps              | 116      |
|    time_elapsed     | 737      |
|    total_timesteps  | 86113    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000468 |
|    n_updates        | 11528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 4776     |
|    fps              | 116      |
|    time_elapsed     | 737      |
|    total_timesteps  | 86186    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000732 |
|    n_updates        | 11546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 4780     |
|    fps              | 116      |
|    time_elapsed     | 738      |
|    total_timesteps  | 86253    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000523 |
|    n_updates        | 11563    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00708  |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 4784     |
|    fps              | 116      |
|    time_elapsed     | 738      |
|    total_timesteps  | 86323    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000498 |
|    n_updates        | 11580    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 4788     |
|    fps              | 117      |
|    time_elapsed     | 738      |
|    total_timesteps  | 86400    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00575  |
|    n_updates        | 11599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00722  |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 4792     |
|    fps              | 117      |
|    time_elapsed     | 738      |
|    total_timesteps  | 86481    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00019  |
|    n_updates        | 11620    |
----------------------------------
Eval num_timesteps=86500, episode_reward=-0.11 +/- 0.27
Episode length: 42.78 +/- 22.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | -0.11    |
| rollout/            |          |
|    exploration_rate | 0.942    |
| time/               |          |
|    total_timesteps  | 86500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000555 |
|    n_updates        | 11624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00734  |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 4796     |
|    fps              | 116      |
|    time_elapsed     | 741      |
|    total_timesteps  | 86567    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000385 |
|    n_updates        | 11641    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 4800     |
|    fps              | 116      |
|    time_elapsed     | 741      |
|    total_timesteps  | 86660    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00736  |
|    n_updates        | 11664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 4804     |
|    fps              | 117      |
|    time_elapsed     | 741      |
|    total_timesteps  | 86736    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000448 |
|    n_updates        | 11683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 4808     |
|    fps              | 117      |
|    time_elapsed     | 741      |
|    total_timesteps  | 86806    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000331 |
|    n_updates        | 11701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0236  |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 4812     |
|    fps              | 117      |
|    time_elapsed     | 741      |
|    total_timesteps  | 86876    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000613 |
|    n_updates        | 11718    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 4816     |
|    fps              | 117      |
|    time_elapsed     | 741      |
|    total_timesteps  | 86942    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000428 |
|    n_updates        | 11735    |
----------------------------------
Eval num_timesteps=87000, episode_reward=-0.28 +/- 0.06
Episode length: 69.90 +/- 14.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.9     |
|    mean_reward      | -0.279   |
| rollout/            |          |
|    exploration_rate | 0.941    |
| time/               |          |
|    total_timesteps  | 87000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000447 |
|    n_updates        | 11749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 4820     |
|    fps              | 116      |
|    time_elapsed     | 745      |
|    total_timesteps  | 87017    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00617  |
|    n_updates        | 11754    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 4824     |
|    fps              | 116      |
|    time_elapsed     | 746      |
|    total_timesteps  | 87092    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000399 |
|    n_updates        | 11772    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 4828     |
|    fps              | 116      |
|    time_elapsed     | 746      |
|    total_timesteps  | 87167    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00645  |
|    n_updates        | 11791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 4832     |
|    fps              | 116      |
|    time_elapsed     | 746      |
|    total_timesteps  | 87238    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00565  |
|    n_updates        | 11809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 4836     |
|    fps              | 117      |
|    time_elapsed     | 746      |
|    total_timesteps  | 87325    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000291 |
|    n_updates        | 11831    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 4840     |
|    fps              | 117      |
|    time_elapsed     | 746      |
|    total_timesteps  | 87400    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000492 |
|    n_updates        | 11849    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 4844     |
|    fps              | 117      |
|    time_elapsed     | 746      |
|    total_timesteps  | 87468    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000254 |
|    n_updates        | 11866    |
----------------------------------
Eval num_timesteps=87500, episode_reward=-0.15 +/- 0.23
Episode length: 47.12 +/- 20.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.1     |
|    mean_reward      | -0.148   |
| rollout/            |          |
|    exploration_rate | 0.94     |
| time/               |          |
|    total_timesteps  | 87500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000474 |
|    n_updates        | 11874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 4848     |
|    fps              | 116      |
|    time_elapsed     | 749      |
|    total_timesteps  | 87539    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00561  |
|    n_updates        | 11884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00207 |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 4852     |
|    fps              | 116      |
|    time_elapsed     | 749      |
|    total_timesteps  | 87598    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0056   |
|    n_updates        | 11899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00207 |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 4856     |
|    fps              | 116      |
|    time_elapsed     | 749      |
|    total_timesteps  | 87677    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000356 |
|    n_updates        | 11919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00243 |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 4860     |
|    fps              | 117      |
|    time_elapsed     | 749      |
|    total_timesteps  | 87749    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000236 |
|    n_updates        | 11937    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00351 |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 4864     |
|    fps              | 117      |
|    time_elapsed     | 749      |
|    total_timesteps  | 87843    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000548 |
|    n_updates        | 11960    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 4868     |
|    fps              | 117      |
|    time_elapsed     | 750      |
|    total_timesteps  | 87908    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00028  |
|    n_updates        | 11976    |
----------------------------------
Eval num_timesteps=88000, episode_reward=-0.27 +/- 0.05
Episode length: 67.98 +/- 13.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68       |
|    mean_reward      | -0.272   |
| rollout/            |          |
|    exploration_rate | 0.939    |
| time/               |          |
|    total_timesteps  | 88000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0122   |
|    n_updates        | 11999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 4872     |
|    fps              | 116      |
|    time_elapsed     | 754      |
|    total_timesteps  | 88001    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000657 |
|    n_updates        | 12000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00434 |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 4876     |
|    fps              | 116      |
|    time_elapsed     | 754      |
|    total_timesteps  | 88070    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00386  |
|    n_updates        | 12017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 4880     |
|    fps              | 116      |
|    time_elapsed     | 754      |
|    total_timesteps  | 88137    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000343 |
|    n_updates        | 12034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00446 |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 4884     |
|    fps              | 116      |
|    time_elapsed     | 754      |
|    total_timesteps  | 88210    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000441 |
|    n_updates        | 12052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 4888     |
|    fps              | 116      |
|    time_elapsed     | 754      |
|    total_timesteps  | 88291    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000311 |
|    n_updates        | 12072    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 4892     |
|    fps              | 117      |
|    time_elapsed     | 754      |
|    total_timesteps  | 88351    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000577 |
|    n_updates        | 12087    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 4896     |
|    fps              | 117      |
|    time_elapsed     | 754      |
|    total_timesteps  | 88420    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00546  |
|    n_updates        | 12104    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0122  |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 4900     |
|    fps              | 117      |
|    time_elapsed     | 754      |
|    total_timesteps  | 88491    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00757  |
|    n_updates        | 12122    |
----------------------------------
Eval num_timesteps=88500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.938    |
| time/               |          |
|    total_timesteps  | 88500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00068  |
|    n_updates        | 12124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0122  |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 4904     |
|    fps              | 116      |
|    time_elapsed     | 759      |
|    total_timesteps  | 88567    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00504  |
|    n_updates        | 12141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 4908     |
|    fps              | 116      |
|    time_elapsed     | 759      |
|    total_timesteps  | 88650    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000583 |
|    n_updates        | 12162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 4912     |
|    fps              | 116      |
|    time_elapsed     | 759      |
|    total_timesteps  | 88724    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000311 |
|    n_updates        | 12180    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00674  |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 4916     |
|    fps              | 116      |
|    time_elapsed     | 759      |
|    total_timesteps  | 88800    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00665  |
|    n_updates        | 12199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 4920     |
|    fps              | 116      |
|    time_elapsed     | 759      |
|    total_timesteps  | 88860    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000381 |
|    n_updates        | 12214    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 4924     |
|    fps              | 117      |
|    time_elapsed     | 759      |
|    total_timesteps  | 88939    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000714 |
|    n_updates        | 12234    |
----------------------------------
Eval num_timesteps=89000, episode_reward=-0.16 +/- 0.24
Episode length: 49.06 +/- 24.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.1     |
|    mean_reward      | -0.156   |
| rollout/            |          |
|    exploration_rate | 0.937    |
| time/               |          |
|    total_timesteps  | 89000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000495 |
|    n_updates        | 12249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 4928     |
|    fps              | 116      |
|    time_elapsed     | 763      |
|    total_timesteps  | 89010    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000332 |
|    n_updates        | 12252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 4932     |
|    fps              | 116      |
|    time_elapsed     | 763      |
|    total_timesteps  | 89089    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00531  |
|    n_updates        | 12272    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 4936     |
|    fps              | 116      |
|    time_elapsed     | 763      |
|    total_timesteps  | 89169    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000409 |
|    n_updates        | 12292    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 4940     |
|    fps              | 116      |
|    time_elapsed     | 763      |
|    total_timesteps  | 89236    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000276 |
|    n_updates        | 12308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 4944     |
|    fps              | 116      |
|    time_elapsed     | 763      |
|    total_timesteps  | 89304    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000522 |
|    n_updates        | 12325    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00728  |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 4948     |
|    fps              | 117      |
|    time_elapsed     | 763      |
|    total_timesteps  | 89384    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000468 |
|    n_updates        | 12345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00357 |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 4952     |
|    fps              | 117      |
|    time_elapsed     | 763      |
|    total_timesteps  | 89464    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00019  |
|    n_updates        | 12365    |
----------------------------------
Eval num_timesteps=89500, episode_reward=-0.23 +/- 0.08
Episode length: 56.62 +/- 21.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.6     |
|    mean_reward      | -0.226   |
| rollout/            |          |
|    exploration_rate | 0.936    |
| time/               |          |
|    total_timesteps  | 89500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000289 |
|    n_updates        | 12374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00349 |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 4956     |
|    fps              | 116      |
|    time_elapsed     | 767      |
|    total_timesteps  | 89541    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000351 |
|    n_updates        | 12385    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00381 |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 4960     |
|    fps              | 116      |
|    time_elapsed     | 767      |
|    total_timesteps  | 89621    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00537  |
|    n_updates        | 12405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0067   |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 4964     |
|    fps              | 116      |
|    time_elapsed     | 767      |
|    total_timesteps  | 89702    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000318 |
|    n_updates        | 12425    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0067   |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 4968     |
|    fps              | 116      |
|    time_elapsed     | 767      |
|    total_timesteps  | 89767    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000475 |
|    n_updates        | 12441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0073   |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 4972     |
|    fps              | 117      |
|    time_elapsed     | 767      |
|    total_timesteps  | 89845    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0061   |
|    n_updates        | 12461    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00303 |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 4976     |
|    fps              | 117      |
|    time_elapsed     | 767      |
|    total_timesteps  | 89922    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000316 |
|    n_updates        | 12480    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00695  |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 4980     |
|    fps              | 117      |
|    time_elapsed     | 767      |
|    total_timesteps  | 89990    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00738  |
|    n_updates        | 12497    |
----------------------------------
Eval num_timesteps=90000, episode_reward=-0.30 +/- 0.01
Episode length: 74.28 +/- 3.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.3     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.935    |
| time/               |          |
|    total_timesteps  | 90000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000733 |
|    n_updates        | 12499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00638  |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 4984     |
|    fps              | 116      |
|    time_elapsed     | 772      |
|    total_timesteps  | 90078    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 12519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 4988     |
|    fps              | 116      |
|    time_elapsed     | 772      |
|    total_timesteps  | 90140    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00069  |
|    n_updates        | 12534    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00684  |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 4992     |
|    fps              | 116      |
|    time_elapsed     | 772      |
|    total_timesteps  | 90207    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000782 |
|    n_updates        | 12551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00664  |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 4996     |
|    fps              | 116      |
|    time_elapsed     | 772      |
|    total_timesteps  | 90281    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000462 |
|    n_updates        | 12570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00688  |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 5000     |
|    fps              | 116      |
|    time_elapsed     | 772      |
|    total_timesteps  | 90346    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00377  |
|    n_updates        | 12586    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00696  |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 5004     |
|    fps              | 117      |
|    time_elapsed     | 772      |
|    total_timesteps  | 90420    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000448 |
|    n_updates        | 12604    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 5008     |
|    fps              | 117      |
|    time_elapsed     | 772      |
|    total_timesteps  | 90487    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00585  |
|    n_updates        | 12621    |
----------------------------------
Eval num_timesteps=90500, episode_reward=-0.29 +/- 0.05
Episode length: 72.64 +/- 11.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.6     |
|    mean_reward      | -0.291   |
| rollout/            |          |
|    exploration_rate | 0.934    |
| time/               |          |
|    total_timesteps  | 90500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000456 |
|    n_updates        | 12624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 5012     |
|    fps              | 116      |
|    time_elapsed     | 777      |
|    total_timesteps  | 90568    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000737 |
|    n_updates        | 12641    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00723  |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 5016     |
|    fps              | 116      |
|    time_elapsed     | 777      |
|    total_timesteps  | 90646    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000899 |
|    n_updates        | 12661    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 5020     |
|    fps              | 116      |
|    time_elapsed     | 777      |
|    total_timesteps  | 90718    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00078  |
|    n_updates        | 12679    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 5024     |
|    fps              | 116      |
|    time_elapsed     | 777      |
|    total_timesteps  | 90791    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000346 |
|    n_updates        | 12697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 5028     |
|    fps              | 116      |
|    time_elapsed     | 777      |
|    total_timesteps  | 90881    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000546 |
|    n_updates        | 12720    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 5032     |
|    fps              | 116      |
|    time_elapsed     | 777      |
|    total_timesteps  | 90947    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00061  |
|    n_updates        | 12736    |
----------------------------------
Eval num_timesteps=91000, episode_reward=-0.20 +/- 0.18
Episode length: 55.20 +/- 22.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.2     |
|    mean_reward      | -0.2     |
| rollout/            |          |
|    exploration_rate | 0.933    |
| time/               |          |
|    total_timesteps  | 91000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000531 |
|    n_updates        | 12749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 5036     |
|    fps              | 116      |
|    time_elapsed     | 781      |
|    total_timesteps  | 91039    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000575 |
|    n_updates        | 12759    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 5040     |
|    fps              | 116      |
|    time_elapsed     | 781      |
|    total_timesteps  | 91118    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000541 |
|    n_updates        | 12779    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 5044     |
|    fps              | 116      |
|    time_elapsed     | 781      |
|    total_timesteps  | 91193    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00646  |
|    n_updates        | 12798    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 5048     |
|    fps              | 116      |
|    time_elapsed     | 781      |
|    total_timesteps  | 91258    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00515  |
|    n_updates        | 12814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 5052     |
|    fps              | 116      |
|    time_elapsed     | 781      |
|    total_timesteps  | 91342    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000688 |
|    n_updates        | 12835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 5056     |
|    fps              | 116      |
|    time_elapsed     | 782      |
|    total_timesteps  | 91415    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00546  |
|    n_updates        | 12853    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00321 |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 5060     |
|    fps              | 116      |
|    time_elapsed     | 782      |
|    total_timesteps  | 91478    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000669 |
|    n_updates        | 12869    |
----------------------------------
Eval num_timesteps=91500, episode_reward=-0.27 +/- 0.07
Episode length: 67.38 +/- 18.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.4     |
|    mean_reward      | -0.269   |
| rollout/            |          |
|    exploration_rate | 0.932    |
| time/               |          |
|    total_timesteps  | 91500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00511  |
|    n_updates        | 12874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00265 |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 5064     |
|    fps              | 116      |
|    time_elapsed     | 786      |
|    total_timesteps  | 91545    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00529  |
|    n_updates        | 12886    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00281 |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 5068     |
|    fps              | 116      |
|    time_elapsed     | 786      |
|    total_timesteps  | 91614    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000777 |
|    n_updates        | 12903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00253 |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 5072     |
|    fps              | 116      |
|    time_elapsed     | 786      |
|    total_timesteps  | 91685    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000493 |
|    n_updates        | 12921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00261 |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 5076     |
|    fps              | 116      |
|    time_elapsed     | 786      |
|    total_timesteps  | 91764    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000426 |
|    n_updates        | 12940    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00244 |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 5080     |
|    fps              | 116      |
|    time_elapsed     | 786      |
|    total_timesteps  | 91827    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000927 |
|    n_updates        | 12956    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 5084     |
|    fps              | 116      |
|    time_elapsed     | 786      |
|    total_timesteps  | 91913    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000533 |
|    n_updates        | 12978    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 5088     |
|    fps              | 116      |
|    time_elapsed     | 787      |
|    total_timesteps  | 91986    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000527 |
|    n_updates        | 12996    |
----------------------------------
Eval num_timesteps=92000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.931    |
| time/               |          |
|    total_timesteps  | 92000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000447 |
|    n_updates        | 12999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 5092     |
|    fps              | 116      |
|    time_elapsed     | 791      |
|    total_timesteps  | 92058    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00684  |
|    n_updates        | 13014    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 5096     |
|    fps              | 116      |
|    time_elapsed     | 791      |
|    total_timesteps  | 92144    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000578 |
|    n_updates        | 13035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 5100     |
|    fps              | 116      |
|    time_elapsed     | 791      |
|    total_timesteps  | 92220    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000446 |
|    n_updates        | 13054    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 5104     |
|    fps              | 116      |
|    time_elapsed     | 791      |
|    total_timesteps  | 92285    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00063  |
|    n_updates        | 13071    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 5108     |
|    fps              | 116      |
|    time_elapsed     | 791      |
|    total_timesteps  | 92350    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000548 |
|    n_updates        | 13087    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 5112     |
|    fps              | 116      |
|    time_elapsed     | 792      |
|    total_timesteps  | 92425    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000352 |
|    n_updates        | 13106    |
----------------------------------
Eval num_timesteps=92500, episode_reward=-0.29 +/- 0.05
Episode length: 71.34 +/- 12.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.3     |
|    mean_reward      | -0.285   |
| rollout/            |          |
|    exploration_rate | 0.93     |
| time/               |          |
|    total_timesteps  | 92500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000831 |
|    n_updates        | 13124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0238  |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 5116     |
|    fps              | 116      |
|    time_elapsed     | 796      |
|    total_timesteps  | 92515    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00039  |
|    n_updates        | 13128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 5120     |
|    fps              | 116      |
|    time_elapsed     | 796      |
|    total_timesteps  | 92586    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00051  |
|    n_updates        | 13146    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 5124     |
|    fps              | 116      |
|    time_elapsed     | 796      |
|    total_timesteps  | 92671    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00751  |
|    n_updates        | 13167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 5128     |
|    fps              | 116      |
|    time_elapsed     | 796      |
|    total_timesteps  | 92744    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00466  |
|    n_updates        | 13185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0239  |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 5132     |
|    fps              | 116      |
|    time_elapsed     | 796      |
|    total_timesteps  | 92820    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000883 |
|    n_updates        | 13204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 5136     |
|    fps              | 116      |
|    time_elapsed     | 796      |
|    total_timesteps  | 92902    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000551 |
|    n_updates        | 13225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 5140     |
|    fps              | 116      |
|    time_elapsed     | 796      |
|    total_timesteps  | 92985    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00041  |
|    n_updates        | 13246    |
----------------------------------
Eval num_timesteps=93000, episode_reward=-0.29 +/- 0.05
Episode length: 71.60 +/- 13.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.6     |
|    mean_reward      | -0.286   |
| rollout/            |          |
|    exploration_rate | 0.929    |
| time/               |          |
|    total_timesteps  | 93000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000362 |
|    n_updates        | 13249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0243  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 5144     |
|    fps              | 116      |
|    time_elapsed     | 801      |
|    total_timesteps  | 93076    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000312 |
|    n_updates        | 13268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 5148     |
|    fps              | 116      |
|    time_elapsed     | 801      |
|    total_timesteps  | 93143    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00685  |
|    n_updates        | 13285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 5152     |
|    fps              | 116      |
|    time_elapsed     | 801      |
|    total_timesteps  | 93210    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000538 |
|    n_updates        | 13302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 5156     |
|    fps              | 116      |
|    time_elapsed     | 801      |
|    total_timesteps  | 93277    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000676 |
|    n_updates        | 13319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 5160     |
|    fps              | 116      |
|    time_elapsed     | 801      |
|    total_timesteps  | 93345    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00835  |
|    n_updates        | 13336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0343  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 5164     |
|    fps              | 116      |
|    time_elapsed     | 801      |
|    total_timesteps  | 93427    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000516 |
|    n_updates        | 13356    |
----------------------------------
Eval num_timesteps=93500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.928    |
| time/               |          |
|    total_timesteps  | 93500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000766 |
|    n_updates        | 13374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.025   |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 5168     |
|    fps              | 116      |
|    time_elapsed     | 806      |
|    total_timesteps  | 93515    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00689  |
|    n_updates        | 13378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0153  |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 5172     |
|    fps              | 116      |
|    time_elapsed     | 806      |
|    total_timesteps  | 93593    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00052  |
|    n_updates        | 13398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00487 |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 5176     |
|    fps              | 116      |
|    time_elapsed     | 806      |
|    total_timesteps  | 93661    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000713 |
|    n_updates        | 13415    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0151  |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 5180     |
|    fps              | 116      |
|    time_elapsed     | 806      |
|    total_timesteps  | 93730    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000545 |
|    n_updates        | 13432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 5184     |
|    fps              | 116      |
|    time_elapsed     | 806      |
|    total_timesteps  | 93795    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000441 |
|    n_updates        | 13448    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 5188     |
|    fps              | 116      |
|    time_elapsed     | 806      |
|    total_timesteps  | 93867    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000417 |
|    n_updates        | 13466    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.014   |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 5192     |
|    fps              | 116      |
|    time_elapsed     | 806      |
|    total_timesteps  | 93934    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00514  |
|    n_updates        | 13483    |
----------------------------------
Eval num_timesteps=94000, episode_reward=-0.29 +/- 0.04
Episode length: 72.20 +/- 9.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.2     |
|    mean_reward      | -0.289   |
| rollout/            |          |
|    exploration_rate | 0.927    |
| time/               |          |
|    total_timesteps  | 94000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0108   |
|    n_updates        | 13499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 5196     |
|    fps              | 115      |
|    time_elapsed     | 811      |
|    total_timesteps  | 94014    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000764 |
|    n_updates        | 13503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00357 |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 5200     |
|    fps              | 115      |
|    time_elapsed     | 811      |
|    total_timesteps  | 94085    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000892 |
|    n_updates        | 13521    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00365 |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 5204     |
|    fps              | 116      |
|    time_elapsed     | 811      |
|    total_timesteps  | 94152    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00408  |
|    n_updates        | 13537    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00409 |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 5208     |
|    fps              | 116      |
|    time_elapsed     | 811      |
|    total_timesteps  | 94228    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00577  |
|    n_updates        | 13556    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 5212     |
|    fps              | 116      |
|    time_elapsed     | 811      |
|    total_timesteps  | 94322    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000303 |
|    n_updates        | 13580    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 5216     |
|    fps              | 116      |
|    time_elapsed     | 811      |
|    total_timesteps  | 94393    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000547 |
|    n_updates        | 13598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 5220     |
|    fps              | 116      |
|    time_elapsed     | 811      |
|    total_timesteps  | 94466    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00446  |
|    n_updates        | 13616    |
----------------------------------
Eval num_timesteps=94500, episode_reward=-0.14 +/- 0.18
Episode length: 41.00 +/- 22.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41       |
|    mean_reward      | -0.143   |
| rollout/            |          |
|    exploration_rate | 0.926    |
| time/               |          |
|    total_timesteps  | 94500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00518  |
|    n_updates        | 13624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 5224     |
|    fps              | 116      |
|    time_elapsed     | 814      |
|    total_timesteps  | 94535    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00299  |
|    n_updates        | 13633    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.014   |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 5228     |
|    fps              | 116      |
|    time_elapsed     | 814      |
|    total_timesteps  | 94619    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000348 |
|    n_updates        | 13654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00343 |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 5232     |
|    fps              | 116      |
|    time_elapsed     | 814      |
|    total_timesteps  | 94681    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000959 |
|    n_updates        | 13670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00303 |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 5236     |
|    fps              | 116      |
|    time_elapsed     | 814      |
|    total_timesteps  | 94753    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000475 |
|    n_updates        | 13688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00275 |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 5240     |
|    fps              | 116      |
|    time_elapsed     | 814      |
|    total_timesteps  | 94829    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000299 |
|    n_updates        | 13707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00831  |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 5244     |
|    fps              | 116      |
|    time_elapsed     | 814      |
|    total_timesteps  | 94894    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00658  |
|    n_updates        | 13723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00173 |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 5248     |
|    fps              | 116      |
|    time_elapsed     | 814      |
|    total_timesteps  | 94962    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00634  |
|    n_updates        | 13740    |
----------------------------------
Eval num_timesteps=95000, episode_reward=-0.03 +/- 0.42
Episode length: 56.56 +/- 20.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.6     |
|    mean_reward      | -0.0255  |
| rollout/            |          |
|    exploration_rate | 0.925    |
| time/               |          |
|    total_timesteps  | 95000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00378  |
|    n_updates        | 13749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00165 |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 5252     |
|    fps              | 116      |
|    time_elapsed     | 818      |
|    total_timesteps  | 95027    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000355 |
|    n_updates        | 13756    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00169 |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 5256     |
|    fps              | 116      |
|    time_elapsed     | 818      |
|    total_timesteps  | 95095    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000611 |
|    n_updates        | 13773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 5260     |
|    fps              | 116      |
|    time_elapsed     | 818      |
|    total_timesteps  | 95167    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0054   |
|    n_updates        | 13791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 5264     |
|    fps              | 116      |
|    time_elapsed     | 818      |
|    total_timesteps  | 95240    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000443 |
|    n_updates        | 13809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00949  |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 5268     |
|    fps              | 116      |
|    time_elapsed     | 818      |
|    total_timesteps  | 95304    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00625  |
|    n_updates        | 13825    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00039 |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 5272     |
|    fps              | 116      |
|    time_elapsed     | 818      |
|    total_timesteps  | 95379    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000656 |
|    n_updates        | 13844    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 5276     |
|    fps              | 116      |
|    time_elapsed     | 818      |
|    total_timesteps  | 95446    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000558 |
|    n_updates        | 13861    |
----------------------------------
Eval num_timesteps=95500, episode_reward=-0.20 +/- 0.16
Episode length: 55.02 +/- 22.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55       |
|    mean_reward      | -0.2     |
| rollout/            |          |
|    exploration_rate | 0.924    |
| time/               |          |
|    total_timesteps  | 95500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000651 |
|    n_updates        | 13874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0106  |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 5280     |
|    fps              | 116      |
|    time_elapsed     | 822      |
|    total_timesteps  | 95520    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000424 |
|    n_updates        | 13879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0108  |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 5284     |
|    fps              | 116      |
|    time_elapsed     | 822      |
|    total_timesteps  | 95591    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000644 |
|    n_updates        | 13897    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 5288     |
|    fps              | 116      |
|    time_elapsed     | 822      |
|    total_timesteps  | 95654    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000362 |
|    n_updates        | 13913    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0208  |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 5292     |
|    fps              | 116      |
|    time_elapsed     | 822      |
|    total_timesteps  | 95731    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000809 |
|    n_updates        | 13932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0105  |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 5296     |
|    fps              | 116      |
|    time_elapsed     | 822      |
|    total_timesteps  | 95803    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000583 |
|    n_updates        | 13950    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 5300     |
|    fps              | 116      |
|    time_elapsed     | 822      |
|    total_timesteps  | 95871    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000816 |
|    n_updates        | 13967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 5304     |
|    fps              | 116      |
|    time_elapsed     | 823      |
|    total_timesteps  | 95934    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000683 |
|    n_updates        | 13983    |
----------------------------------
Eval num_timesteps=96000, episode_reward=-0.23 +/- 0.16
Episode length: 63.66 +/- 21.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.7     |
|    mean_reward      | -0.234   |
| rollout/            |          |
|    exploration_rate | 0.923    |
| time/               |          |
|    total_timesteps  | 96000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00607  |
|    n_updates        | 13999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 5308     |
|    fps              | 116      |
|    time_elapsed     | 827      |
|    total_timesteps  | 96011    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000194 |
|    n_updates        | 14002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00094  |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 5312     |
|    fps              | 116      |
|    time_elapsed     | 827      |
|    total_timesteps  | 96074    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000623 |
|    n_updates        | 14018    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0104   |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 5316     |
|    fps              | 116      |
|    time_elapsed     | 827      |
|    total_timesteps  | 96159    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000405 |
|    n_updates        | 14039    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0106   |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 5320     |
|    fps              | 116      |
|    time_elapsed     | 827      |
|    total_timesteps  | 96227    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00386  |
|    n_updates        | 14056    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 5324     |
|    fps              | 116      |
|    time_elapsed     | 827      |
|    total_timesteps  | 96298    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000191 |
|    n_updates        | 14074    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0111   |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 5328     |
|    fps              | 116      |
|    time_elapsed     | 827      |
|    total_timesteps  | 96368    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 14091    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00961  |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 5332     |
|    fps              | 116      |
|    time_elapsed     | 827      |
|    total_timesteps  | 96466    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00562  |
|    n_updates        | 14116    |
----------------------------------
Eval num_timesteps=96500, episode_reward=0.04 +/- 0.30
Episode length: 14.92 +/- 1.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.0413   |
| rollout/            |          |
|    exploration_rate | 0.922    |
| time/               |          |
|    total_timesteps  | 96500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000451 |
|    n_updates        | 14124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00961  |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 5336     |
|    fps              | 116      |
|    time_elapsed     | 828      |
|    total_timesteps  | 96538    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000713 |
|    n_updates        | 14134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00949  |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 5340     |
|    fps              | 116      |
|    time_elapsed     | 828      |
|    total_timesteps  | 96617    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000609 |
|    n_updates        | 14154    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00948  |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 5344     |
|    fps              | 116      |
|    time_elapsed     | 828      |
|    total_timesteps  | 96682    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000575 |
|    n_updates        | 14170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00944  |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 5348     |
|    fps              | 116      |
|    time_elapsed     | 828      |
|    total_timesteps  | 96751    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00479  |
|    n_updates        | 14187    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00916  |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 5352     |
|    fps              | 116      |
|    time_elapsed     | 828      |
|    total_timesteps  | 96823    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00494  |
|    n_updates        | 14205    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00868  |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 5356     |
|    fps              | 116      |
|    time_elapsed     | 828      |
|    total_timesteps  | 96903    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000422 |
|    n_updates        | 14225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00155 |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 5360     |
|    fps              | 116      |
|    time_elapsed     | 829      |
|    total_timesteps  | 96981    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00636  |
|    n_updates        | 14245    |
----------------------------------
Eval num_timesteps=97000, episode_reward=-0.18 +/- 0.08
Episode length: 45.34 +/- 21.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | -0.181   |
| rollout/            |          |
|    exploration_rate | 0.921    |
| time/               |          |
|    total_timesteps  | 97000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000581 |
|    n_updates        | 14249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 5364     |
|    fps              | 116      |
|    time_elapsed     | 831      |
|    total_timesteps  | 97048    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000769 |
|    n_updates        | 14261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0284   |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 5368     |
|    fps              | 116      |
|    time_elapsed     | 831      |
|    total_timesteps  | 97120    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000666 |
|    n_updates        | 14279    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0284   |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 5372     |
|    fps              | 116      |
|    time_elapsed     | 831      |
|    total_timesteps  | 97195    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000596 |
|    n_updates        | 14298    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 5376     |
|    fps              | 116      |
|    time_elapsed     | 831      |
|    total_timesteps  | 97277    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00578  |
|    n_updates        | 14319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 5380     |
|    fps              | 116      |
|    time_elapsed     | 832      |
|    total_timesteps  | 97348    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000955 |
|    n_updates        | 14336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 5384     |
|    fps              | 117      |
|    time_elapsed     | 832      |
|    total_timesteps  | 97422    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000953 |
|    n_updates        | 14355    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 5388     |
|    fps              | 117      |
|    time_elapsed     | 832      |
|    total_timesteps  | 97482    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000659 |
|    n_updates        | 14370    |
----------------------------------
Eval num_timesteps=97500, episode_reward=-0.21 +/- 0.09
Episode length: 52.60 +/- 22.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.6     |
|    mean_reward      | -0.21    |
| rollout/            |          |
|    exploration_rate | 0.92     |
| time/               |          |
|    total_timesteps  | 97500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000611 |
|    n_updates        | 14374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0381   |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 5392     |
|    fps              | 116      |
|    time_elapsed     | 835      |
|    total_timesteps  | 97554    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000536 |
|    n_updates        | 14388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 5396     |
|    fps              | 116      |
|    time_elapsed     | 835      |
|    total_timesteps  | 97623    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00732  |
|    n_updates        | 14405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 5400     |
|    fps              | 116      |
|    time_elapsed     | 835      |
|    total_timesteps  | 97691    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 14422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 5404     |
|    fps              | 116      |
|    time_elapsed     | 836      |
|    total_timesteps  | 97759    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000816 |
|    n_updates        | 14439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 5408     |
|    fps              | 117      |
|    time_elapsed     | 836      |
|    total_timesteps  | 97835    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00355  |
|    n_updates        | 14458    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 5412     |
|    fps              | 117      |
|    time_elapsed     | 836      |
|    total_timesteps  | 97907    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000795 |
|    n_updates        | 14476    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 5416     |
|    fps              | 117      |
|    time_elapsed     | 836      |
|    total_timesteps  | 97984    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00483  |
|    n_updates        | 14495    |
----------------------------------
Eval num_timesteps=98000, episode_reward=-0.22 +/- 0.09
Episode length: 54.16 +/- 23.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.2     |
|    mean_reward      | -0.216   |
| rollout/            |          |
|    exploration_rate | 0.919    |
| time/               |          |
|    total_timesteps  | 98000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000643 |
|    n_updates        | 14499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 5420     |
|    fps              | 116      |
|    time_elapsed     | 839      |
|    total_timesteps  | 98043    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00549  |
|    n_updates        | 14510    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0485   |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 5424     |
|    fps              | 116      |
|    time_elapsed     | 839      |
|    total_timesteps  | 98111    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00066  |
|    n_updates        | 14527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0482   |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 5428     |
|    fps              | 116      |
|    time_elapsed     | 839      |
|    total_timesteps  | 98188    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00411  |
|    n_updates        | 14546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0387   |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 5432     |
|    fps              | 116      |
|    time_elapsed     | 840      |
|    total_timesteps  | 98275    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00038  |
|    n_updates        | 14568    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0587   |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 5436     |
|    fps              | 117      |
|    time_elapsed     | 840      |
|    total_timesteps  | 98346    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000443 |
|    n_updates        | 14586    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0593   |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 5440     |
|    fps              | 117      |
|    time_elapsed     | 840      |
|    total_timesteps  | 98410    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000348 |
|    n_updates        | 14602    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 5444     |
|    fps              | 117      |
|    time_elapsed     | 840      |
|    total_timesteps  | 98476    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000858 |
|    n_updates        | 14618    |
----------------------------------
Eval num_timesteps=98500, episode_reward=-0.25 +/- 0.08
Episode length: 63.36 +/- 18.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.4     |
|    mean_reward      | -0.253   |
| rollout/            |          |
|    exploration_rate | 0.918    |
| time/               |          |
|    total_timesteps  | 98500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000629 |
|    n_updates        | 14624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0591   |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 5448     |
|    fps              | 116      |
|    time_elapsed     | 844      |
|    total_timesteps  | 98550    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000395 |
|    n_updates        | 14637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0592   |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 5452     |
|    fps              | 116      |
|    time_elapsed     | 844      |
|    total_timesteps  | 98619    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000305 |
|    n_updates        | 14654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0697   |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 5456     |
|    fps              | 116      |
|    time_elapsed     | 844      |
|    total_timesteps  | 98688    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000454 |
|    n_updates        | 14671    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0695   |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 5460     |
|    fps              | 116      |
|    time_elapsed     | 844      |
|    total_timesteps  | 98770    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000421 |
|    n_updates        | 14692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 5464     |
|    fps              | 116      |
|    time_elapsed     | 844      |
|    total_timesteps  | 98841    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000291 |
|    n_updates        | 14710    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.049    |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 5468     |
|    fps              | 117      |
|    time_elapsed     | 845      |
|    total_timesteps  | 98922    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000452 |
|    n_updates        | 14730    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0489   |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 5472     |
|    fps              | 117      |
|    time_elapsed     | 845      |
|    total_timesteps  | 98998    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000689 |
|    n_updates        | 14749    |
----------------------------------
Eval num_timesteps=99000, episode_reward=-0.17 +/- 0.08
Episode length: 41.82 +/- 20.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.8     |
|    mean_reward      | -0.166   |
| rollout/            |          |
|    exploration_rate | 0.917    |
| time/               |          |
|    total_timesteps  | 99000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 5476     |
|    fps              | 116      |
|    time_elapsed     | 848      |
|    total_timesteps  | 99088    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00598  |
|    n_updates        | 14771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0589   |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 5480     |
|    fps              | 116      |
|    time_elapsed     | 848      |
|    total_timesteps  | 99151    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00054  |
|    n_updates        | 14787    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0592   |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 5484     |
|    fps              | 116      |
|    time_elapsed     | 848      |
|    total_timesteps  | 99218    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000638 |
|    n_updates        | 14804    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0488   |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 5488     |
|    fps              | 117      |
|    time_elapsed     | 848      |
|    total_timesteps  | 99288    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000659 |
|    n_updates        | 14821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0691   |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 5492     |
|    fps              | 117      |
|    time_elapsed     | 848      |
|    total_timesteps  | 99351    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000878 |
|    n_updates        | 14837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.079    |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 5496     |
|    fps              | 117      |
|    time_elapsed     | 848      |
|    total_timesteps  | 99424    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000711 |
|    n_updates        | 14855    |
----------------------------------
Eval num_timesteps=99500, episode_reward=-0.28 +/- 0.05
Episode length: 70.78 +/- 12.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.8     |
|    mean_reward      | -0.283   |
| rollout/            |          |
|    exploration_rate | 0.916    |
| time/               |          |
|    total_timesteps  | 99500    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000792 |
|    n_updates        | 14874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.078    |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 5500     |
|    fps              | 116      |
|    time_elapsed     | 852      |
|    total_timesteps  | 99518    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 14879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0883   |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 5504     |
|    fps              | 116      |
|    time_elapsed     | 852      |
|    total_timesteps  | 99577    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000875 |
|    n_updates        | 14894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0886   |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 5508     |
|    fps              | 116      |
|    time_elapsed     | 852      |
|    total_timesteps  | 99646    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 14911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0685   |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 5512     |
|    fps              | 116      |
|    time_elapsed     | 852      |
|    total_timesteps  | 99721    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00664  |
|    n_updates        | 14930    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0691   |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 5516     |
|    fps              | 116      |
|    time_elapsed     | 852      |
|    total_timesteps  | 99784    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000449 |
|    n_updates        | 14945    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.058    |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 5520     |
|    fps              | 117      |
|    time_elapsed     | 853      |
|    total_timesteps  | 99869    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000514 |
|    n_updates        | 14967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0481   |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 5524     |
|    fps              | 117      |
|    time_elapsed     | 853      |
|    total_timesteps  | 99935    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00434  |
|    n_updates        | 14983    |
----------------------------------
Eval num_timesteps=100000, episode_reward=-0.27 +/- 0.08
Episode length: 67.68 +/- 19.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.7     |
|    mean_reward      | -0.271   |
| rollout/            |          |
|    exploration_rate | 0.915    |
| time/               |          |
|    total_timesteps  | 100000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000645 |
|    n_updates        | 14999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0482   |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 5528     |
|    fps              | 116      |
|    time_elapsed     | 857      |
|    total_timesteps  | 100010   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000895 |
|    n_updates        | 15002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0589   |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 5532     |
|    fps              | 116      |
|    time_elapsed     | 857      |
|    total_timesteps  | 100080   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00947  |
|    n_updates        | 15019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0389   |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 5536     |
|    fps              | 116      |
|    time_elapsed     | 857      |
|    total_timesteps  | 100151   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000643 |
|    n_updates        | 15037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0487   |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 5540     |
|    fps              | 116      |
|    time_elapsed     | 857      |
|    total_timesteps  | 100220   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000536 |
|    n_updates        | 15054    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0481   |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 5544     |
|    fps              | 116      |
|    time_elapsed     | 857      |
|    total_timesteps  | 100299   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0008   |
|    n_updates        | 15074    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0479   |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 5548     |
|    fps              | 116      |
|    time_elapsed     | 857      |
|    total_timesteps  | 100377   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 15094    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0473   |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 5552     |
|    fps              | 117      |
|    time_elapsed     | 858      |
|    total_timesteps  | 100461   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000838 |
|    n_updates        | 15115    |
----------------------------------
Eval num_timesteps=100500, episode_reward=-0.25 +/- 0.16
Episode length: 67.20 +/- 18.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.2     |
|    mean_reward      | -0.249   |
| rollout/            |          |
|    exploration_rate | 0.914    |
| time/               |          |
|    total_timesteps  | 100500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00069  |
|    n_updates        | 15124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0472   |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 5556     |
|    fps              | 116      |
|    time_elapsed     | 862      |
|    total_timesteps  | 100533   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000856 |
|    n_updates        | 15133    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0375   |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 5560     |
|    fps              | 116      |
|    time_elapsed     | 862      |
|    total_timesteps  | 100609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000513 |
|    n_updates        | 15152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 5564     |
|    fps              | 116      |
|    time_elapsed     | 862      |
|    total_timesteps  | 100675   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00859  |
|    n_updates        | 15168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 5568     |
|    fps              | 116      |
|    time_elapsed     | 862      |
|    total_timesteps  | 100740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000475 |
|    n_updates        | 15184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 5572     |
|    fps              | 116      |
|    time_elapsed     | 862      |
|    total_timesteps  | 100814   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000497 |
|    n_updates        | 15203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 5576     |
|    fps              | 116      |
|    time_elapsed     | 862      |
|    total_timesteps  | 100903   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000746 |
|    n_updates        | 15225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 5580     |
|    fps              | 117      |
|    time_elapsed     | 862      |
|    total_timesteps  | 100979   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000705 |
|    n_updates        | 15244    |
----------------------------------
Eval num_timesteps=101000, episode_reward=-0.16 +/- 0.17
Episode length: 45.88 +/- 25.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | -0.163   |
| rollout/            |          |
|    exploration_rate | 0.913    |
| time/               |          |
|    total_timesteps  | 101000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000601 |
|    n_updates        | 15249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 5584     |
|    fps              | 116      |
|    time_elapsed     | 865      |
|    total_timesteps  | 101047   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000811 |
|    n_updates        | 15261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0372   |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 5588     |
|    fps              | 116      |
|    time_elapsed     | 865      |
|    total_timesteps  | 101133   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00048  |
|    n_updates        | 15283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0265   |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 5592     |
|    fps              | 116      |
|    time_elapsed     | 865      |
|    total_timesteps  | 101215   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000925 |
|    n_updates        | 15303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 5596     |
|    fps              | 116      |
|    time_elapsed     | 865      |
|    total_timesteps  | 101292   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0183   |
|    n_updates        | 15322    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0265   |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 5600     |
|    fps              | 117      |
|    time_elapsed     | 866      |
|    total_timesteps  | 101380   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.011    |
|    n_updates        | 15344    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0161   |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 5604     |
|    fps              | 117      |
|    time_elapsed     | 866      |
|    total_timesteps  | 101449   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00604  |
|    n_updates        | 15362    |
----------------------------------
Eval num_timesteps=101500, episode_reward=-0.22 +/- 0.09
Episode length: 54.30 +/- 21.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.3     |
|    mean_reward      | -0.217   |
| rollout/            |          |
|    exploration_rate | 0.912    |
| time/               |          |
|    total_timesteps  | 101500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00068  |
|    n_updates        | 15374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00572  |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 5608     |
|    fps              | 116      |
|    time_elapsed     | 869      |
|    total_timesteps  | 101528   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000457 |
|    n_updates        | 15381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00616  |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 5612     |
|    fps              | 116      |
|    time_elapsed     | 869      |
|    total_timesteps  | 101592   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000631 |
|    n_updates        | 15397    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00548  |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 5616     |
|    fps              | 116      |
|    time_elapsed     | 869      |
|    total_timesteps  | 101672   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00646  |
|    n_updates        | 15417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00624  |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 5620     |
|    fps              | 116      |
|    time_elapsed     | 869      |
|    total_timesteps  | 101738   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000518 |
|    n_updates        | 15434    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00632  |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 5624     |
|    fps              | 117      |
|    time_elapsed     | 870      |
|    total_timesteps  | 101802   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000557 |
|    n_updates        | 15450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0064   |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 5628     |
|    fps              | 117      |
|    time_elapsed     | 870      |
|    total_timesteps  | 101875   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000889 |
|    n_updates        | 15468    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00405 |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 5632     |
|    fps              | 117      |
|    time_elapsed     | 870      |
|    total_timesteps  | 101956   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00073  |
|    n_updates        | 15488    |
----------------------------------
Eval num_timesteps=102000, episode_reward=-0.22 +/- 0.09
Episode length: 54.22 +/- 21.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.2     |
|    mean_reward      | -0.216   |
| rollout/            |          |
|    exploration_rate | 0.911    |
| time/               |          |
|    total_timesteps  | 102000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0106   |
|    n_updates        | 15499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00417 |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 5636     |
|    fps              | 116      |
|    time_elapsed     | 873      |
|    total_timesteps  | 102030   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000849 |
|    n_updates        | 15507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0152  |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 5640     |
|    fps              | 116      |
|    time_elapsed     | 873      |
|    total_timesteps  | 102125   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000629 |
|    n_updates        | 15531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00491 |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 5644     |
|    fps              | 116      |
|    time_elapsed     | 874      |
|    total_timesteps  | 102197   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000648 |
|    n_updates        | 15549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00446 |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 5648     |
|    fps              | 116      |
|    time_elapsed     | 874      |
|    total_timesteps  | 102264   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00298  |
|    n_updates        | 15565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00366 |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 5652     |
|    fps              | 117      |
|    time_elapsed     | 874      |
|    total_timesteps  | 102328   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 15581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00413 |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 5656     |
|    fps              | 117      |
|    time_elapsed     | 874      |
|    total_timesteps  | 102412   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 15602    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00421 |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 5660     |
|    fps              | 117      |
|    time_elapsed     | 874      |
|    total_timesteps  | 102490   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00607  |
|    n_updates        | 15622    |
----------------------------------
Eval num_timesteps=102500, episode_reward=-0.28 +/- 0.06
Episode length: 70.44 +/- 14.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.4     |
|    mean_reward      | -0.282   |
| rollout/            |          |
|    exploration_rate | 0.91     |
| time/               |          |
|    total_timesteps  | 102500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000768 |
|    n_updates        | 15624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00457 |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 5664     |
|    fps              | 116      |
|    time_elapsed     | 879      |
|    total_timesteps  | 102565   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0006   |
|    n_updates        | 15641    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0155  |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 5668     |
|    fps              | 116      |
|    time_elapsed     | 879      |
|    total_timesteps  | 102653   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000798 |
|    n_updates        | 15663    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0154  |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 5672     |
|    fps              | 116      |
|    time_elapsed     | 879      |
|    total_timesteps  | 102726   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000779 |
|    n_updates        | 15681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 5676     |
|    fps              | 116      |
|    time_elapsed     | 879      |
|    total_timesteps  | 102795   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00339  |
|    n_updates        | 15698    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 5680     |
|    fps              | 116      |
|    time_elapsed     | 879      |
|    total_timesteps  | 102865   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000829 |
|    n_updates        | 15716    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 5684     |
|    fps              | 117      |
|    time_elapsed     | 879      |
|    total_timesteps  | 102944   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00619  |
|    n_updates        | 15735    |
----------------------------------
Eval num_timesteps=103000, episode_reward=-0.11 +/- 0.39
Episode length: 61.64 +/- 21.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.6     |
|    mean_reward      | -0.106   |
| rollout/            |          |
|    exploration_rate | 0.908    |
| time/               |          |
|    total_timesteps  | 103000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000615 |
|    n_updates        | 15749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 5688     |
|    fps              | 116      |
|    time_elapsed     | 883      |
|    total_timesteps  | 103018   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000375 |
|    n_updates        | 15754    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 5692     |
|    fps              | 116      |
|    time_elapsed     | 883      |
|    total_timesteps  | 103092   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000818 |
|    n_updates        | 15772    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 5696     |
|    fps              | 116      |
|    time_elapsed     | 883      |
|    total_timesteps  | 103161   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000574 |
|    n_updates        | 15790    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 5700     |
|    fps              | 116      |
|    time_elapsed     | 883      |
|    total_timesteps  | 103227   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000562 |
|    n_updates        | 15806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 5704     |
|    fps              | 116      |
|    time_elapsed     | 883      |
|    total_timesteps  | 103294   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00668  |
|    n_updates        | 15823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 5708     |
|    fps              | 116      |
|    time_elapsed     | 883      |
|    total_timesteps  | 103371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00508  |
|    n_updates        | 15842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 5712     |
|    fps              | 117      |
|    time_elapsed     | 883      |
|    total_timesteps  | 103465   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00713  |
|    n_updates        | 15866    |
----------------------------------
Eval num_timesteps=103500, episode_reward=0.03 +/- 0.43
Episode length: 47.28 +/- 19.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | 0.0318   |
| rollout/            |          |
|    exploration_rate | 0.907    |
| time/               |          |
|    total_timesteps  | 103500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000548 |
|    n_updates        | 15874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 5716     |
|    fps              | 116      |
|    time_elapsed     | 886      |
|    total_timesteps  | 103536   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000862 |
|    n_updates        | 15883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 5720     |
|    fps              | 116      |
|    time_elapsed     | 886      |
|    total_timesteps  | 103609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000582 |
|    n_updates        | 15902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 5724     |
|    fps              | 116      |
|    time_elapsed     | 887      |
|    total_timesteps  | 103690   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000902 |
|    n_updates        | 15922    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00437 |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 5728     |
|    fps              | 116      |
|    time_elapsed     | 887      |
|    total_timesteps  | 103760   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000742 |
|    n_updates        | 15939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00373 |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 5732     |
|    fps              | 117      |
|    time_elapsed     | 887      |
|    total_timesteps  | 103825   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000566 |
|    n_updates        | 15956    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00622  |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 5736     |
|    fps              | 117      |
|    time_elapsed     | 887      |
|    total_timesteps  | 103900   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0119   |
|    n_updates        | 15974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 5740     |
|    fps              | 117      |
|    time_elapsed     | 887      |
|    total_timesteps  | 103966   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000405 |
|    n_updates        | 15991    |
----------------------------------
Eval num_timesteps=104000, episode_reward=-0.28 +/- 0.06
Episode length: 69.18 +/- 14.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.2     |
|    mean_reward      | -0.277   |
| rollout/            |          |
|    exploration_rate | 0.906    |
| time/               |          |
|    total_timesteps  | 104000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000762 |
|    n_updates        | 15999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 5744     |
|    fps              | 116      |
|    time_elapsed     | 891      |
|    total_timesteps  | 104030   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00058  |
|    n_updates        | 16007    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00776  |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 5748     |
|    fps              | 116      |
|    time_elapsed     | 891      |
|    total_timesteps  | 104095   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000691 |
|    n_updates        | 16023    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 5752     |
|    fps              | 116      |
|    time_elapsed     | 892      |
|    total_timesteps  | 104174   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000572 |
|    n_updates        | 16043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00709  |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 5756     |
|    fps              | 116      |
|    time_elapsed     | 892      |
|    total_timesteps  | 104260   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 16064    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00653  |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 5760     |
|    fps              | 116      |
|    time_elapsed     | 892      |
|    total_timesteps  | 104352   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000618 |
|    n_updates        | 16087    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00653  |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 5764     |
|    fps              | 117      |
|    time_elapsed     | 892      |
|    total_timesteps  | 104427   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000447 |
|    n_updates        | 16106    |
----------------------------------
Eval num_timesteps=104500, episode_reward=-0.16 +/- 0.19
Episode length: 44.00 +/- 26.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44       |
|    mean_reward      | -0.155   |
| rollout/            |          |
|    exploration_rate | 0.905    |
| time/               |          |
|    total_timesteps  | 104500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000802 |
|    n_updates        | 16124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00693  |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 5768     |
|    fps              | 116      |
|    time_elapsed     | 895      |
|    total_timesteps  | 104505   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000634 |
|    n_updates        | 16126    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00713  |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 5772     |
|    fps              | 116      |
|    time_elapsed     | 895      |
|    total_timesteps  | 104573   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0034   |
|    n_updates        | 16143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 5776     |
|    fps              | 116      |
|    time_elapsed     | 895      |
|    total_timesteps  | 104635   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000534 |
|    n_updates        | 16158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 5780     |
|    fps              | 116      |
|    time_elapsed     | 895      |
|    total_timesteps  | 104710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000639 |
|    n_updates        | 16177    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 5784     |
|    fps              | 117      |
|    time_elapsed     | 895      |
|    total_timesteps  | 104789   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000444 |
|    n_updates        | 16197    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.904    |
| time/               |          |
|    episodes         | 5788     |
|    fps              | 117      |
|    time_elapsed     | 895      |
|    total_timesteps  | 104870   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000681 |
|    n_updates        | 16217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.904    |
| time/               |          |
|    episodes         | 5792     |
|    fps              | 117      |
|    time_elapsed     | 895      |
|    total_timesteps  | 104941   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00535  |
|    n_updates        | 16235    |
----------------------------------
Eval num_timesteps=105000, episode_reward=-0.19 +/- 0.18
Episode length: 52.40 +/- 22.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.4     |
|    mean_reward      | -0.189   |
| rollout/            |          |
|    exploration_rate | 0.904    |
| time/               |          |
|    total_timesteps  | 105000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000701 |
|    n_updates        | 16249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 0.904    |
| time/               |          |
|    episodes         | 5796     |
|    fps              | 116      |
|    time_elapsed     | 899      |
|    total_timesteps  | 105010   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000624 |
|    n_updates        | 16252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0266   |
|    exploration_rate | 0.904    |
| time/               |          |
|    episodes         | 5800     |
|    fps              | 116      |
|    time_elapsed     | 899      |
|    total_timesteps  | 105086   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000652 |
|    n_updates        | 16271    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0263   |
|    exploration_rate | 0.904    |
| time/               |          |
|    episodes         | 5804     |
|    fps              | 116      |
|    time_elapsed     | 899      |
|    total_timesteps  | 105161   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 16290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0266   |
|    exploration_rate | 0.904    |
| time/               |          |
|    episodes         | 5808     |
|    fps              | 116      |
|    time_elapsed     | 899      |
|    total_timesteps  | 105232   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000846 |
|    n_updates        | 16307    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.037    |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 5812     |
|    fps              | 117      |
|    time_elapsed     | 899      |
|    total_timesteps  | 105315   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000443 |
|    n_updates        | 16328    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0366   |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 5816     |
|    fps              | 117      |
|    time_elapsed     | 899      |
|    total_timesteps  | 105397   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000686 |
|    n_updates        | 16349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.037    |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 5820     |
|    fps              | 117      |
|    time_elapsed     | 900      |
|    total_timesteps  | 105460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00594  |
|    n_updates        | 16364    |
----------------------------------
Eval num_timesteps=105500, episode_reward=-0.24 +/- 0.21
Episode length: 70.20 +/- 13.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.2     |
|    mean_reward      | -0.241   |
| rollout/            |          |
|    exploration_rate | 0.903    |
| time/               |          |
|    total_timesteps  | 105500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00053  |
|    n_updates        | 16374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 5824     |
|    fps              | 116      |
|    time_elapsed     | 904      |
|    total_timesteps  | 105533   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000287 |
|    n_updates        | 16383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0263   |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 5828     |
|    fps              | 116      |
|    time_elapsed     | 904      |
|    total_timesteps  | 105628   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000652 |
|    n_updates        | 16406    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0262   |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 5832     |
|    fps              | 116      |
|    time_elapsed     | 904      |
|    total_timesteps  | 105695   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.007    |
|    n_updates        | 16423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0264   |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 5836     |
|    fps              | 116      |
|    time_elapsed     | 904      |
|    total_timesteps  | 105765   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00047  |
|    n_updates        | 16441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0159   |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 5840     |
|    fps              | 116      |
|    time_elapsed     | 904      |
|    total_timesteps  | 105844   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000746 |
|    n_updates        | 16460    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00575  |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 5844     |
|    fps              | 117      |
|    time_elapsed     | 904      |
|    total_timesteps  | 105912   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000418 |
|    n_updates        | 16477    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00579  |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 5848     |
|    fps              | 117      |
|    time_elapsed     | 905      |
|    total_timesteps  | 105976   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0097   |
|    n_updates        | 16493    |
----------------------------------
Eval num_timesteps=106000, episode_reward=-0.11 +/- 0.30
Episode length: 48.60 +/- 21.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.6     |
|    mean_reward      | -0.114   |
| rollout/            |          |
|    exploration_rate | 0.902    |
| time/               |          |
|    total_timesteps  | 106000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000796 |
|    n_updates        | 16499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00383 |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 5852     |
|    fps              | 116      |
|    time_elapsed     | 908      |
|    total_timesteps  | 106045   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00609  |
|    n_updates        | 16511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00355 |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 5856     |
|    fps              | 116      |
|    time_elapsed     | 908      |
|    total_timesteps  | 106124   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00599  |
|    n_updates        | 16530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00275 |
|    exploration_rate | 0.901    |
| time/               |          |
|    episodes         | 5860     |
|    fps              | 116      |
|    time_elapsed     | 908      |
|    total_timesteps  | 106196   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000781 |
|    n_updates        | 16548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00259 |
|    exploration_rate | 0.901    |
| time/               |          |
|    episodes         | 5864     |
|    fps              | 116      |
|    time_elapsed     | 908      |
|    total_timesteps  | 106267   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00056  |
|    n_updates        | 16566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0076   |
|    exploration_rate | 0.901    |
| time/               |          |
|    episodes         | 5868     |
|    fps              | 117      |
|    time_elapsed     | 908      |
|    total_timesteps  | 106340   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000445 |
|    n_updates        | 16584    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00712  |
|    exploration_rate | 0.901    |
| time/               |          |
|    episodes         | 5872     |
|    fps              | 117      |
|    time_elapsed     | 908      |
|    total_timesteps  | 106420   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000539 |
|    n_updates        | 16604    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00334 |
|    exploration_rate | 0.901    |
| time/               |          |
|    episodes         | 5876     |
|    fps              | 117      |
|    time_elapsed     | 908      |
|    total_timesteps  | 106493   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000887 |
|    n_updates        | 16623    |
----------------------------------
Eval num_timesteps=106500, episode_reward=-0.20 +/- 0.10
Episode length: 49.68 +/- 23.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.7     |
|    mean_reward      | -0.198   |
| rollout/            |          |
|    exploration_rate | 0.901    |
| time/               |          |
|    total_timesteps  | 106500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00603  |
|    n_updates        | 16624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00349 |
|    exploration_rate | 0.901    |
| time/               |          |
|    episodes         | 5880     |
|    fps              | 116      |
|    time_elapsed     | 912      |
|    total_timesteps  | 106572   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 16642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 5884     |
|    fps              | 116      |
|    time_elapsed     | 912      |
|    total_timesteps  | 106659   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00652  |
|    n_updates        | 16664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 5888     |
|    fps              | 116      |
|    time_elapsed     | 912      |
|    total_timesteps  | 106727   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000868 |
|    n_updates        | 16681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 5892     |
|    fps              | 117      |
|    time_elapsed     | 912      |
|    total_timesteps  | 106797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.004    |
|    n_updates        | 16699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 5896     |
|    fps              | 117      |
|    time_elapsed     | 912      |
|    total_timesteps  | 106861   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000973 |
|    n_updates        | 16715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 5900     |
|    fps              | 117      |
|    time_elapsed     | 912      |
|    total_timesteps  | 106933   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000614 |
|    n_updates        | 16733    |
----------------------------------
Eval num_timesteps=107000, episode_reward=-0.16 +/- 0.29
Episode length: 60.14 +/- 19.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60.1     |
|    mean_reward      | -0.16    |
| rollout/            |          |
|    exploration_rate | 0.9      |
| time/               |          |
|    total_timesteps  | 107000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000677 |
|    n_updates        | 16749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 5904     |
|    fps              | 116      |
|    time_elapsed     | 916      |
|    total_timesteps  | 107010   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00543  |
|    n_updates        | 16752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 5908     |
|    fps              | 116      |
|    time_elapsed     | 916      |
|    total_timesteps  | 107094   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000741 |
|    n_updates        | 16773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 5912     |
|    fps              | 116      |
|    time_elapsed     | 916      |
|    total_timesteps  | 107177   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000504 |
|    n_updates        | 16794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 5916     |
|    fps              | 116      |
|    time_elapsed     | 916      |
|    total_timesteps  | 107247   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000687 |
|    n_updates        | 16811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0336  |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 5920     |
|    fps              | 117      |
|    time_elapsed     | 916      |
|    total_timesteps  | 107326   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00045  |
|    n_updates        | 16831    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0333  |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 5924     |
|    fps              | 117      |
|    time_elapsed     | 916      |
|    total_timesteps  | 107390   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000766 |
|    n_updates        | 16847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0326  |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 5928     |
|    fps              | 117      |
|    time_elapsed     | 916      |
|    total_timesteps  | 107469   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000717 |
|    n_updates        | 16867    |
----------------------------------
Eval num_timesteps=107500, episode_reward=-0.13 +/- 0.23
Episode length: 47.80 +/- 19.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.8     |
|    mean_reward      | -0.13    |
| rollout/            |          |
|    exploration_rate | 0.898    |
| time/               |          |
|    total_timesteps  | 107500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000886 |
|    n_updates        | 16874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 5932     |
|    fps              | 116      |
|    time_elapsed     | 920      |
|    total_timesteps  | 107547   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000565 |
|    n_updates        | 16886    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0334  |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 5936     |
|    fps              | 116      |
|    time_elapsed     | 920      |
|    total_timesteps  | 107625   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000976 |
|    n_updates        | 16906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 5940     |
|    fps              | 116      |
|    time_elapsed     | 920      |
|    total_timesteps  | 107689   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00043  |
|    n_updates        | 16922    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 5944     |
|    fps              | 117      |
|    time_elapsed     | 920      |
|    total_timesteps  | 107760   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000759 |
|    n_updates        | 16939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 5948     |
|    fps              | 117      |
|    time_elapsed     | 920      |
|    total_timesteps  | 107827   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00634  |
|    n_updates        | 16956    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 5952     |
|    fps              | 117      |
|    time_elapsed     | 920      |
|    total_timesteps  | 107891   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 16972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0025  |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 5956     |
|    fps              | 117      |
|    time_elapsed     | 920      |
|    total_timesteps  | 107963   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000709 |
|    n_updates        | 16990    |
----------------------------------
Eval num_timesteps=108000, episode_reward=-0.05 +/- 0.40
Episode length: 56.90 +/- 17.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.9     |
|    mean_reward      | -0.047   |
| rollout/            |          |
|    exploration_rate | 0.897    |
| time/               |          |
|    total_timesteps  | 108000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000533 |
|    n_updates        | 16999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00704  |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 5960     |
|    fps              | 116      |
|    time_elapsed     | 923      |
|    total_timesteps  | 108047   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000643 |
|    n_updates        | 17011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00692  |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 5964     |
|    fps              | 117      |
|    time_elapsed     | 924      |
|    total_timesteps  | 108121   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00054  |
|    n_updates        | 17030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00283 |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 5968     |
|    fps              | 117      |
|    time_elapsed     | 924      |
|    total_timesteps  | 108188   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000479 |
|    n_updates        | 17046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00315 |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 5972     |
|    fps              | 117      |
|    time_elapsed     | 924      |
|    total_timesteps  | 108276   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00828  |
|    n_updates        | 17068    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00287 |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 5976     |
|    fps              | 117      |
|    time_elapsed     | 924      |
|    total_timesteps  | 108342   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000392 |
|    n_updates        | 17085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 5980     |
|    fps              | 117      |
|    time_elapsed     | 924      |
|    total_timesteps  | 108425   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000546 |
|    n_updates        | 17106    |
----------------------------------
Eval num_timesteps=108500, episode_reward=-0.28 +/- 0.06
Episode length: 69.46 +/- 14.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.5     |
|    mean_reward      | -0.278   |
| rollout/            |          |
|    exploration_rate | 0.896    |
| time/               |          |
|    total_timesteps  | 108500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00425  |
|    n_updates        | 17124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00293 |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 5984     |
|    fps              | 116      |
|    time_elapsed     | 928      |
|    total_timesteps  | 108509   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0107   |
|    n_updates        | 17127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00293 |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 5988     |
|    fps              | 116      |
|    time_elapsed     | 928      |
|    total_timesteps  | 108577   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000625 |
|    n_updates        | 17144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00365 |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 5992     |
|    fps              | 117      |
|    time_elapsed     | 928      |
|    total_timesteps  | 108665   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000597 |
|    n_updates        | 17166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00409 |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 5996     |
|    fps              | 117      |
|    time_elapsed     | 928      |
|    total_timesteps  | 108740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00605  |
|    n_updates        | 17184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00609  |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 6000     |
|    fps              | 117      |
|    time_elapsed     | 928      |
|    total_timesteps  | 108807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000871 |
|    n_updates        | 17201    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 6004     |
|    fps              | 117      |
|    time_elapsed     | 928      |
|    total_timesteps  | 108872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000456 |
|    n_updates        | 17217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 6008     |
|    fps              | 117      |
|    time_elapsed     | 929      |
|    total_timesteps  | 108948   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00036  |
|    n_updates        | 17236    |
----------------------------------
Eval num_timesteps=109000, episode_reward=-0.26 +/- 0.15
Episode length: 70.70 +/- 11.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.7     |
|    mean_reward      | -0.263   |
| rollout/            |          |
|    exploration_rate | 0.895    |
| time/               |          |
|    total_timesteps  | 109000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000884 |
|    n_updates        | 17249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0273   |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 6012     |
|    fps              | 116      |
|    time_elapsed     | 933      |
|    total_timesteps  | 109022   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000475 |
|    n_updates        | 17255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 6016     |
|    fps              | 116      |
|    time_elapsed     | 933      |
|    total_timesteps  | 109093   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000863 |
|    n_updates        | 17273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0371   |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 6020     |
|    fps              | 116      |
|    time_elapsed     | 933      |
|    total_timesteps  | 109176   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000552 |
|    n_updates        | 17293    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0472   |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 6024     |
|    fps              | 117      |
|    time_elapsed     | 933      |
|    total_timesteps  | 109238   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.013    |
|    n_updates        | 17309    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0471   |
|    exploration_rate | 0.894    |
| time/               |          |
|    episodes         | 6028     |
|    fps              | 117      |
|    time_elapsed     | 933      |
|    total_timesteps  | 109320   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00398  |
|    n_updates        | 17329    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0371   |
|    exploration_rate | 0.894    |
| time/               |          |
|    episodes         | 6032     |
|    fps              | 117      |
|    time_elapsed     | 933      |
|    total_timesteps  | 109397   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000492 |
|    n_updates        | 17349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0477   |
|    exploration_rate | 0.894    |
| time/               |          |
|    episodes         | 6036     |
|    fps              | 117      |
|    time_elapsed     | 933      |
|    total_timesteps  | 109461   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000638 |
|    n_updates        | 17365    |
----------------------------------
Eval num_timesteps=109500, episode_reward=-0.26 +/- 0.15
Episode length: 70.26 +/- 13.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.3     |
|    mean_reward      | -0.261   |
| rollout/            |          |
|    exploration_rate | 0.894    |
| time/               |          |
|    total_timesteps  | 109500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00552  |
|    n_updates        | 17374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 0.894    |
| time/               |          |
|    episodes         | 6040     |
|    fps              | 116      |
|    time_elapsed     | 937      |
|    total_timesteps  | 109527   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000726 |
|    n_updates        | 17381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0374   |
|    exploration_rate | 0.894    |
| time/               |          |
|    episodes         | 6044     |
|    fps              | 116      |
|    time_elapsed     | 938      |
|    total_timesteps  | 109604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 17400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0471   |
|    exploration_rate | 0.894    |
| time/               |          |
|    episodes         | 6048     |
|    fps              | 116      |
|    time_elapsed     | 938      |
|    total_timesteps  | 109678   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00706  |
|    n_updates        | 17419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0362   |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 6052     |
|    fps              | 116      |
|    time_elapsed     | 938      |
|    total_timesteps  | 109764   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000546 |
|    n_updates        | 17440    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0261   |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 6056     |
|    fps              | 117      |
|    time_elapsed     | 938      |
|    total_timesteps  | 109838   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000382 |
|    n_updates        | 17459    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 6060     |
|    fps              | 117      |
|    time_elapsed     | 938      |
|    total_timesteps  | 109901   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000907 |
|    n_updates        | 17475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0367   |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 6064     |
|    fps              | 117      |
|    time_elapsed     | 938      |
|    total_timesteps  | 109980   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00053  |
|    n_updates        | 17494    |
----------------------------------
Eval num_timesteps=110000, episode_reward=-0.09 +/- 0.37
Episode length: 57.08 +/- 20.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.1     |
|    mean_reward      | -0.0877  |
| rollout/            |          |
|    exploration_rate | 0.893    |
| time/               |          |
|    total_timesteps  | 110000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00662  |
|    n_updates        | 17499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.036    |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 6068     |
|    fps              | 116      |
|    time_elapsed     | 942      |
|    total_timesteps  | 110065   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00651  |
|    n_updates        | 17516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0368   |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 6072     |
|    fps              | 116      |
|    time_elapsed     | 942      |
|    total_timesteps  | 110132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 17532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0369   |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 6076     |
|    fps              | 116      |
|    time_elapsed     | 942      |
|    total_timesteps  | 110197   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0065   |
|    n_updates        | 17549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 6080     |
|    fps              | 117      |
|    time_elapsed     | 942      |
|    total_timesteps  | 110268   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 17566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 6084     |
|    fps              | 117      |
|    time_elapsed     | 942      |
|    total_timesteps  | 110364   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000789 |
|    n_updates        | 17590    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0268   |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 6088     |
|    fps              | 117      |
|    time_elapsed     | 942      |
|    total_timesteps  | 110433   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000729 |
|    n_updates        | 17608    |
----------------------------------
Eval num_timesteps=110500, episode_reward=-0.22 +/- 0.17
Episode length: 61.30 +/- 18.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.3     |
|    mean_reward      | -0.225   |
| rollout/            |          |
|    exploration_rate | 0.892    |
| time/               |          |
|    total_timesteps  | 110500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000425 |
|    n_updates        | 17624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 6092     |
|    fps              | 116      |
|    time_elapsed     | 946      |
|    total_timesteps  | 110507   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00684  |
|    n_updates        | 17626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 6096     |
|    fps              | 116      |
|    time_elapsed     | 946      |
|    total_timesteps  | 110581   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00578  |
|    n_updates        | 17645    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00731  |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 6100     |
|    fps              | 116      |
|    time_elapsed     | 946      |
|    total_timesteps  | 110651   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000566 |
|    n_updates        | 17662    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00319 |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 6104     |
|    fps              | 117      |
|    time_elapsed     | 946      |
|    total_timesteps  | 110728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000731 |
|    n_updates        | 17681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00308 |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 6108     |
|    fps              | 117      |
|    time_elapsed     | 946      |
|    total_timesteps  | 110801   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000603 |
|    n_updates        | 17700    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00284 |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 6112     |
|    fps              | 117      |
|    time_elapsed     | 946      |
|    total_timesteps  | 110869   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00598  |
|    n_updates        | 17717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0026  |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 6116     |
|    fps              | 117      |
|    time_elapsed     | 946      |
|    total_timesteps  | 110934   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00762  |
|    n_updates        | 17733    |
----------------------------------
Eval num_timesteps=111000, episode_reward=-0.27 +/- 0.16
Episode length: 71.78 +/- 11.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.8     |
|    mean_reward      | -0.267   |
| rollout/            |          |
|    exploration_rate | 0.891    |
| time/               |          |
|    total_timesteps  | 111000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000797 |
|    n_updates        | 17749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 6120     |
|    fps              | 116      |
|    time_elapsed     | 950      |
|    total_timesteps  | 111002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000569 |
|    n_updates        | 17750    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0122  |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 6124     |
|    fps              | 116      |
|    time_elapsed     | 951      |
|    total_timesteps  | 111069   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00567  |
|    n_updates        | 17767    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00142 |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 6128     |
|    fps              | 116      |
|    time_elapsed     | 951      |
|    total_timesteps  | 111131   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000902 |
|    n_updates        | 17782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00166 |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 6132     |
|    fps              | 116      |
|    time_elapsed     | 951      |
|    total_timesteps  | 111214   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000644 |
|    n_updates        | 17803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 6136     |
|    fps              | 116      |
|    time_elapsed     | 951      |
|    total_timesteps  | 111285   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000864 |
|    n_updates        | 17821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00195 |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 6140     |
|    fps              | 117      |
|    time_elapsed     | 951      |
|    total_timesteps  | 111351   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 17837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00207 |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 6144     |
|    fps              | 117      |
|    time_elapsed     | 951      |
|    total_timesteps  | 111431   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00648  |
|    n_updates        | 17857    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00167 |
|    exploration_rate | 0.889    |
| time/               |          |
|    episodes         | 6148     |
|    fps              | 117      |
|    time_elapsed     | 951      |
|    total_timesteps  | 111495   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000743 |
|    n_updates        | 17873    |
----------------------------------
Eval num_timesteps=111500, episode_reward=-0.16 +/- 0.21
Episode length: 49.30 +/- 23.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.3     |
|    mean_reward      | -0.156   |
| rollout/            |          |
|    exploration_rate | 0.889    |
| time/               |          |
|    total_timesteps  | 111500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 17874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00908  |
|    exploration_rate | 0.889    |
| time/               |          |
|    episodes         | 6152     |
|    fps              | 116      |
|    time_elapsed     | 954      |
|    total_timesteps  | 111562   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0113   |
|    n_updates        | 17890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00912  |
|    exploration_rate | 0.889    |
| time/               |          |
|    episodes         | 6156     |
|    fps              | 116      |
|    time_elapsed     | 954      |
|    total_timesteps  | 111635   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000783 |
|    n_updates        | 17908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00115 |
|    exploration_rate | 0.889    |
| time/               |          |
|    episodes         | 6160     |
|    fps              | 116      |
|    time_elapsed     | 954      |
|    total_timesteps  | 111705   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00602  |
|    n_updates        | 17926    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 0.889    |
| time/               |          |
|    episodes         | 6164     |
|    fps              | 117      |
|    time_elapsed     | 955      |
|    total_timesteps  | 111789   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000616 |
|    n_updates        | 17947    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.889    |
| time/               |          |
|    episodes         | 6168     |
|    fps              | 117      |
|    time_elapsed     | 955      |
|    total_timesteps  | 111858   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000559 |
|    n_updates        | 17964    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.011   |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 6172     |
|    fps              | 117      |
|    time_elapsed     | 955      |
|    total_timesteps  | 111932   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000439 |
|    n_updates        | 17982    |
----------------------------------
Eval num_timesteps=112000, episode_reward=-0.05 +/- 0.38
Episode length: 51.68 +/- 18.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.7     |
|    mean_reward      | -0.0459  |
| rollout/            |          |
|    exploration_rate | 0.888    |
| time/               |          |
|    total_timesteps  | 112000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 17999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 6176     |
|    fps              | 116      |
|    time_elapsed     | 958      |
|    total_timesteps  | 112003   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00582  |
|    n_updates        | 18000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 6180     |
|    fps              | 116      |
|    time_elapsed     | 958      |
|    total_timesteps  | 112080   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000631 |
|    n_updates        | 18019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 6184     |
|    fps              | 116      |
|    time_elapsed     | 958      |
|    total_timesteps  | 112156   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00432  |
|    n_updates        | 18038    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0108  |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 6188     |
|    fps              | 117      |
|    time_elapsed     | 958      |
|    total_timesteps  | 112229   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000593 |
|    n_updates        | 18057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0106  |
|    exploration_rate | 0.887    |
| time/               |          |
|    episodes         | 6192     |
|    fps              | 117      |
|    time_elapsed     | 958      |
|    total_timesteps  | 112298   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 18074    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.887    |
| time/               |          |
|    episodes         | 6196     |
|    fps              | 117      |
|    time_elapsed     | 958      |
|    total_timesteps  | 112367   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 18091    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00012 |
|    exploration_rate | 0.887    |
| time/               |          |
|    episodes         | 6200     |
|    fps              | 117      |
|    time_elapsed     | 959      |
|    total_timesteps  | 112429   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00604  |
|    n_updates        | 18107    |
----------------------------------
Eval num_timesteps=112500, episode_reward=-0.28 +/- 0.05
Episode length: 70.98 +/- 12.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71       |
|    mean_reward      | -0.284   |
| rollout/            |          |
|    exploration_rate | 0.887    |
| time/               |          |
|    total_timesteps  | 112500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 18124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00016 |
|    exploration_rate | 0.887    |
| time/               |          |
|    episodes         | 6204     |
|    fps              | 116      |
|    time_elapsed     | 963      |
|    total_timesteps  | 112507   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00606  |
|    n_updates        | 18126    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0109  |
|    exploration_rate | 0.887    |
| time/               |          |
|    episodes         | 6208     |
|    fps              | 116      |
|    time_elapsed     | 963      |
|    total_timesteps  | 112598   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000789 |
|    n_updates        | 18149    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.887    |
| time/               |          |
|    episodes         | 6212     |
|    fps              | 116      |
|    time_elapsed     | 963      |
|    total_timesteps  | 112674   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 18168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 6216     |
|    fps              | 117      |
|    time_elapsed     | 963      |
|    total_timesteps  | 112739   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 18184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00104 |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 6220     |
|    fps              | 117      |
|    time_elapsed     | 963      |
|    total_timesteps  | 112803   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 18200    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 6224     |
|    fps              | 117      |
|    time_elapsed     | 963      |
|    total_timesteps  | 112878   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00093  |
|    n_updates        | 18219    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0225  |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 6228     |
|    fps              | 117      |
|    time_elapsed     | 963      |
|    total_timesteps  | 112968   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 18241    |
----------------------------------
Eval num_timesteps=113000, episode_reward=-0.22 +/- 0.09
Episode length: 54.40 +/- 21.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.4     |
|    mean_reward      | -0.217   |
| rollout/            |          |
|    exploration_rate | 0.886    |
| time/               |          |
|    total_timesteps  | 113000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 18249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 6232     |
|    fps              | 116      |
|    time_elapsed     | 966      |
|    total_timesteps  | 113042   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000556 |
|    n_updates        | 18260    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 6236     |
|    fps              | 116      |
|    time_elapsed     | 967      |
|    total_timesteps  | 113112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00945  |
|    n_updates        | 18277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0321  |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 6240     |
|    fps              | 117      |
|    time_elapsed     | 967      |
|    total_timesteps  | 113178   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 18294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 6244     |
|    fps              | 117      |
|    time_elapsed     | 967      |
|    total_timesteps  | 113237   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000523 |
|    n_updates        | 18309    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0321  |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 6248     |
|    fps              | 117      |
|    time_elapsed     | 967      |
|    total_timesteps  | 113322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000384 |
|    n_updates        | 18330    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0324  |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 6252     |
|    fps              | 117      |
|    time_elapsed     | 967      |
|    total_timesteps  | 113397   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000375 |
|    n_updates        | 18349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0324  |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 6256     |
|    fps              | 117      |
|    time_elapsed     | 967      |
|    total_timesteps  | 113471   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00538  |
|    n_updates        | 18367    |
----------------------------------
Eval num_timesteps=113500, episode_reward=-0.05 +/- 0.43
Episode length: 57.82 +/- 21.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.8     |
|    mean_reward      | -0.0507  |
| rollout/            |          |
|    exploration_rate | 0.885    |
| time/               |          |
|    total_timesteps  | 113500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00248  |
|    n_updates        | 18374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0323  |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 6260     |
|    fps              | 116      |
|    time_elapsed     | 971      |
|    total_timesteps  | 113537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000742 |
|    n_updates        | 18384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0319  |
|    exploration_rate | 0.884    |
| time/               |          |
|    episodes         | 6264     |
|    fps              | 116      |
|    time_elapsed     | 971      |
|    total_timesteps  | 113612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000779 |
|    n_updates        | 18402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.884    |
| time/               |          |
|    episodes         | 6268     |
|    fps              | 117      |
|    time_elapsed     | 971      |
|    total_timesteps  | 113699   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00092  |
|    n_updates        | 18424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 0.884    |
| time/               |          |
|    episodes         | 6272     |
|    fps              | 117      |
|    time_elapsed     | 971      |
|    total_timesteps  | 113767   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00084  |
|    n_updates        | 18441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.884    |
| time/               |          |
|    episodes         | 6276     |
|    fps              | 117      |
|    time_elapsed     | 971      |
|    total_timesteps  | 113847   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000653 |
|    n_updates        | 18461    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0028  |
|    exploration_rate | 0.884    |
| time/               |          |
|    episodes         | 6280     |
|    fps              | 117      |
|    time_elapsed     | 971      |
|    total_timesteps  | 113926   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00066  |
|    n_updates        | 18481    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00268 |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 6284     |
|    fps              | 117      |
|    time_elapsed     | 971      |
|    total_timesteps  | 113999   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000769 |
|    n_updates        | 18499    |
----------------------------------
Eval num_timesteps=114000, episode_reward=-0.18 +/- 0.28
Episode length: 61.10 +/- 21.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 61.1     |
|    mean_reward     | -0.184   |
| time/              |          |
|    total_timesteps | 114000   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00256 |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 6288     |
|    fps              | 116      |
|    time_elapsed     | 975      |
|    total_timesteps  | 114069   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000573 |
|    n_updates        | 18517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00783  |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 6292     |
|    fps              | 116      |
|    time_elapsed     | 975      |
|    total_timesteps  | 114128   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000308 |
|    n_updates        | 18531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00763  |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 6296     |
|    fps              | 117      |
|    time_elapsed     | 975      |
|    total_timesteps  | 114202   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00239  |
|    n_updates        | 18550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00755  |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 6300     |
|    fps              | 117      |
|    time_elapsed     | 975      |
|    total_timesteps  | 114266   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 18566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 6304     |
|    fps              | 117      |
|    time_elapsed     | 975      |
|    total_timesteps  | 114336   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.015    |
|    n_updates        | 18583    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 6308     |
|    fps              | 117      |
|    time_elapsed     | 975      |
|    total_timesteps  | 114400   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000607 |
|    n_updates        | 18599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0189   |
|    exploration_rate | 0.882    |
| time/               |          |
|    episodes         | 6312     |
|    fps              | 117      |
|    time_elapsed     | 976      |
|    total_timesteps  | 114477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000823 |
|    n_updates        | 18619    |
----------------------------------
Eval num_timesteps=114500, episode_reward=-0.15 +/- 0.32
Episode length: 56.78 +/- 23.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.8     |
|    mean_reward      | -0.147   |
| rollout/            |          |
|    exploration_rate | 0.882    |
| time/               |          |
|    total_timesteps  | 114500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000659 |
|    n_updates        | 18624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.882    |
| time/               |          |
|    episodes         | 6316     |
|    fps              | 116      |
|    time_elapsed     | 979      |
|    total_timesteps  | 114556   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00569  |
|    n_updates        | 18638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00812  |
|    exploration_rate | 0.882    |
| time/               |          |
|    episodes         | 6320     |
|    fps              | 117      |
|    time_elapsed     | 979      |
|    total_timesteps  | 114626   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00036  |
|    n_updates        | 18656    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.882    |
| time/               |          |
|    episodes         | 6324     |
|    fps              | 117      |
|    time_elapsed     | 979      |
|    total_timesteps  | 114690   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000684 |
|    n_updates        | 18672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0189   |
|    exploration_rate | 0.882    |
| time/               |          |
|    episodes         | 6328     |
|    fps              | 117      |
|    time_elapsed     | 979      |
|    total_timesteps  | 114771   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000894 |
|    n_updates        | 18692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0295   |
|    exploration_rate | 0.882    |
| time/               |          |
|    episodes         | 6332     |
|    fps              | 117      |
|    time_elapsed     | 979      |
|    total_timesteps  | 114831   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000513 |
|    n_updates        | 18707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0289   |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 6336     |
|    fps              | 117      |
|    time_elapsed     | 979      |
|    total_timesteps  | 114916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000824 |
|    n_updates        | 18728    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 6340     |
|    fps              | 117      |
|    time_elapsed     | 979      |
|    total_timesteps  | 114987   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000939 |
|    n_updates        | 18746    |
----------------------------------
Eval num_timesteps=115000, episode_reward=-0.20 +/- 0.22
Episode length: 59.74 +/- 21.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.7     |
|    mean_reward      | -0.199   |
| rollout/            |          |
|    exploration_rate | 0.881    |
| time/               |          |
|    total_timesteps  | 115000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00679  |
|    n_updates        | 18749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 6344     |
|    fps              | 116      |
|    time_elapsed     | 983      |
|    total_timesteps  | 115055   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000649 |
|    n_updates        | 18763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 6348     |
|    fps              | 117      |
|    time_elapsed     | 983      |
|    total_timesteps  | 115132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000739 |
|    n_updates        | 18782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00854  |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 6352     |
|    fps              | 117      |
|    time_elapsed     | 983      |
|    total_timesteps  | 115210   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 18802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00874  |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 6356     |
|    fps              | 117      |
|    time_elapsed     | 984      |
|    total_timesteps  | 115279   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000772 |
|    n_updates        | 18819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0085   |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 6360     |
|    fps              | 117      |
|    time_elapsed     | 984      |
|    total_timesteps  | 115351   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00564  |
|    n_updates        | 18837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 6364     |
|    fps              | 117      |
|    time_elapsed     | 984      |
|    total_timesteps  | 115419   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00218  |
|    n_updates        | 18854    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00936  |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 6368     |
|    fps              | 117      |
|    time_elapsed     | 984      |
|    total_timesteps  | 115491   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000428 |
|    n_updates        | 18872    |
----------------------------------
Eval num_timesteps=115500, episode_reward=-0.20 +/- 0.29
Episode length: 63.88 +/- 21.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.9     |
|    mean_reward      | -0.195   |
| rollout/            |          |
|    exploration_rate | 0.88     |
| time/               |          |
|    total_timesteps  | 115500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0034   |
|    n_updates        | 18874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00958  |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 6372     |
|    fps              | 116      |
|    time_elapsed     | 988      |
|    total_timesteps  | 115554   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 18888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00994  |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 6376     |
|    fps              | 116      |
|    time_elapsed     | 988      |
|    total_timesteps  | 115625   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000868 |
|    n_updates        | 18906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 6380     |
|    fps              | 117      |
|    time_elapsed     | 988      |
|    total_timesteps  | 115697   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00069  |
|    n_updates        | 18924    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 6384     |
|    fps              | 117      |
|    time_elapsed     | 988      |
|    total_timesteps  | 115760   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000902 |
|    n_updates        | 18939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0209   |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 6388     |
|    fps              | 117      |
|    time_elapsed     | 988      |
|    total_timesteps  | 115823   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 18955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 6392     |
|    fps              | 117      |
|    time_elapsed     | 989      |
|    total_timesteps  | 115898   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000573 |
|    n_updates        | 18974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 6396     |
|    fps              | 117      |
|    time_elapsed     | 989      |
|    total_timesteps  | 115975   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000543 |
|    n_updates        | 18993    |
----------------------------------
Eval num_timesteps=116000, episode_reward=-0.24 +/- 0.24
Episode length: 69.34 +/- 14.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.3     |
|    mean_reward      | -0.237   |
| rollout/            |          |
|    exploration_rate | 0.879    |
| time/               |          |
|    total_timesteps  | 116000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000354 |
|    n_updates        | 18999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 6400     |
|    fps              | 116      |
|    time_elapsed     | 993      |
|    total_timesteps  | 116043   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000945 |
|    n_updates        | 19010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 6404     |
|    fps              | 116      |
|    time_elapsed     | 993      |
|    total_timesteps  | 116112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000997 |
|    n_updates        | 19027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00917  |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 6408     |
|    fps              | 116      |
|    time_elapsed     | 993      |
|    total_timesteps  | 116198   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00824  |
|    n_updates        | 19049    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00921  |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 6412     |
|    fps              | 117      |
|    time_elapsed     | 993      |
|    total_timesteps  | 116274   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000844 |
|    n_updates        | 19068    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0199   |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 6416     |
|    fps              | 117      |
|    time_elapsed     | 993      |
|    total_timesteps  | 116337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000773 |
|    n_updates        | 19084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 6420     |
|    fps              | 117      |
|    time_elapsed     | 993      |
|    total_timesteps  | 116433   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00308  |
|    n_updates        | 19108    |
----------------------------------
Eval num_timesteps=116500, episode_reward=-0.19 +/- 0.22
Episode length: 58.14 +/- 23.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.1     |
|    mean_reward      | -0.192   |
| rollout/            |          |
|    exploration_rate | 0.878    |
| time/               |          |
|    total_timesteps  | 116500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000466 |
|    n_updates        | 19124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.877    |
| time/               |          |
|    episodes         | 6424     |
|    fps              | 116      |
|    time_elapsed     | 997      |
|    total_timesteps  | 116527   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000922 |
|    n_updates        | 19131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.877    |
| time/               |          |
|    episodes         | 6428     |
|    fps              | 116      |
|    time_elapsed     | 997      |
|    total_timesteps  | 116600   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000923 |
|    n_updates        | 19149    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00747  |
|    exploration_rate | 0.877    |
| time/               |          |
|    episodes         | 6432     |
|    fps              | 116      |
|    time_elapsed     | 997      |
|    total_timesteps  | 116672   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000745 |
|    n_updates        | 19167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.877    |
| time/               |          |
|    episodes         | 6436     |
|    fps              | 116      |
|    time_elapsed     | 997      |
|    total_timesteps  | 116743   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000684 |
|    n_updates        | 19185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.877    |
| time/               |          |
|    episodes         | 6440     |
|    fps              | 117      |
|    time_elapsed     | 998      |
|    total_timesteps  | 116818   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00058  |
|    n_updates        | 19204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.877    |
| time/               |          |
|    episodes         | 6444     |
|    fps              | 117      |
|    time_elapsed     | 998      |
|    total_timesteps  | 116883   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 19220    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 6448     |
|    fps              | 117      |
|    time_elapsed     | 998      |
|    total_timesteps  | 116954   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000582 |
|    n_updates        | 19238    |
----------------------------------
Eval num_timesteps=117000, episode_reward=-0.10 +/- 0.15
Episode length: 30.72 +/- 20.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 30.7     |
|    mean_reward      | -0.102   |
| rollout/            |          |
|    exploration_rate | 0.876    |
| time/               |          |
|    total_timesteps  | 117000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000941 |
|    n_updates        | 19249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0283   |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 6452     |
|    fps              | 117      |
|    time_elapsed     | 1000     |
|    total_timesteps  | 117030   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000894 |
|    n_updates        | 19257    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 6456     |
|    fps              | 117      |
|    time_elapsed     | 1000     |
|    total_timesteps  | 117121   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0103   |
|    n_updates        | 19280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0372   |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 6460     |
|    fps              | 117      |
|    time_elapsed     | 1000     |
|    total_timesteps  | 117199   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 19299    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 6464     |
|    fps              | 117      |
|    time_elapsed     | 1000     |
|    total_timesteps  | 117266   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00501  |
|    n_updates        | 19316    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 6468     |
|    fps              | 117      |
|    time_elapsed     | 1000     |
|    total_timesteps  | 117334   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00072  |
|    n_updates        | 19333    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 6472     |
|    fps              | 117      |
|    time_elapsed     | 1000     |
|    total_timesteps  | 117399   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000461 |
|    n_updates        | 19349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 6476     |
|    fps              | 117      |
|    time_elapsed     | 1000     |
|    total_timesteps  | 117480   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0059   |
|    n_updates        | 19369    |
----------------------------------
Eval num_timesteps=117500, episode_reward=-0.21 +/- 0.22
Episode length: 62.64 +/- 19.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.6     |
|    mean_reward      | -0.21    |
| rollout/            |          |
|    exploration_rate | 0.875    |
| time/               |          |
|    total_timesteps  | 117500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000451 |
|    n_updates        | 19374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 6480     |
|    fps              | 117      |
|    time_elapsed     | 1004     |
|    total_timesteps  | 117547   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000474 |
|    n_updates        | 19386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00686  |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 6484     |
|    fps              | 117      |
|    time_elapsed     | 1004     |
|    total_timesteps  | 117615   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000707 |
|    n_updates        | 19403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00662  |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 6488     |
|    fps              | 117      |
|    time_elapsed     | 1004     |
|    total_timesteps  | 117684   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000628 |
|    n_updates        | 19420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00662  |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 6492     |
|    fps              | 117      |
|    time_elapsed     | 1004     |
|    total_timesteps  | 117759   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 19439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00702  |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 6496     |
|    fps              | 117      |
|    time_elapsed     | 1004     |
|    total_timesteps  | 117826   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 19456    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00307 |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 6500     |
|    fps              | 117      |
|    time_elapsed     | 1004     |
|    total_timesteps  | 117896   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 19473    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00327 |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 6504     |
|    fps              | 117      |
|    time_elapsed     | 1004     |
|    total_timesteps  | 117970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000697 |
|    n_updates        | 19492    |
----------------------------------
Eval num_timesteps=118000, episode_reward=-0.24 +/- 0.08
Episode length: 59.46 +/- 19.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.5     |
|    mean_reward      | -0.237   |
| rollout/            |          |
|    exploration_rate | 0.874    |
| time/               |          |
|    total_timesteps  | 118000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000897 |
|    n_updates        | 19499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00267 |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 6508     |
|    fps              | 117      |
|    time_elapsed     | 1008     |
|    total_timesteps  | 118041   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000683 |
|    n_updates        | 19510    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0074   |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 6512     |
|    fps              | 117      |
|    time_elapsed     | 1008     |
|    total_timesteps  | 118115   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00405  |
|    n_updates        | 19528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00274 |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 6516     |
|    fps              | 117      |
|    time_elapsed     | 1008     |
|    total_timesteps  | 118181   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00739  |
|    n_updates        | 19545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00166 |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 6520     |
|    fps              | 117      |
|    time_elapsed     | 1008     |
|    total_timesteps  | 118250   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000835 |
|    n_updates        | 19562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 6524     |
|    fps              | 117      |
|    time_elapsed     | 1008     |
|    total_timesteps  | 118319   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000943 |
|    n_updates        | 19579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 6528     |
|    fps              | 117      |
|    time_elapsed     | 1008     |
|    total_timesteps  | 118386   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000601 |
|    n_updates        | 19596    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 6532     |
|    fps              | 117      |
|    time_elapsed     | 1008     |
|    total_timesteps  | 118457   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000776 |
|    n_updates        | 19614    |
----------------------------------
Eval num_timesteps=118500, episode_reward=-0.17 +/- 0.24
Episode length: 53.40 +/- 23.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.4     |
|    mean_reward      | -0.173   |
| rollout/            |          |
|    exploration_rate | 0.873    |
| time/               |          |
|    total_timesteps  | 118500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000841 |
|    n_updates        | 19624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 6536     |
|    fps              | 117      |
|    time_elapsed     | 1012     |
|    total_timesteps  | 118532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000764 |
|    n_updates        | 19632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0203  |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 6540     |
|    fps              | 117      |
|    time_elapsed     | 1012     |
|    total_timesteps  | 118600   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00516  |
|    n_updates        | 19649    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 6544     |
|    fps              | 117      |
|    time_elapsed     | 1012     |
|    total_timesteps  | 118671   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000529 |
|    n_updates        | 19667    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 6548     |
|    fps              | 117      |
|    time_elapsed     | 1012     |
|    total_timesteps  | 118755   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000913 |
|    n_updates        | 19688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0208  |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 6552     |
|    fps              | 117      |
|    time_elapsed     | 1012     |
|    total_timesteps  | 118824   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000486 |
|    n_updates        | 19705    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 6556     |
|    fps              | 117      |
|    time_elapsed     | 1012     |
|    total_timesteps  | 118920   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00591  |
|    n_updates        | 19729    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 6560     |
|    fps              | 117      |
|    time_elapsed     | 1012     |
|    total_timesteps  | 118990   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000781 |
|    n_updates        | 19747    |
----------------------------------
Eval num_timesteps=119000, episode_reward=-0.24 +/- 0.18
Episode length: 65.58 +/- 16.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.6     |
|    mean_reward      | -0.242   |
| rollout/            |          |
|    exploration_rate | 0.871    |
| time/               |          |
|    total_timesteps  | 119000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000726 |
|    n_updates        | 19749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 0.871    |
| time/               |          |
|    episodes         | 6564     |
|    fps              | 117      |
|    time_elapsed     | 1016     |
|    total_timesteps  | 119058   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 19764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 0.871    |
| time/               |          |
|    episodes         | 6568     |
|    fps              | 117      |
|    time_elapsed     | 1016     |
|    total_timesteps  | 119140   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 19784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0218  |
|    exploration_rate | 0.871    |
| time/               |          |
|    episodes         | 6572     |
|    fps              | 117      |
|    time_elapsed     | 1016     |
|    total_timesteps  | 119219   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 19804    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0209  |
|    exploration_rate | 0.871    |
| time/               |          |
|    episodes         | 6576     |
|    fps              | 117      |
|    time_elapsed     | 1016     |
|    total_timesteps  | 119278   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000464 |
|    n_updates        | 19819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.871    |
| time/               |          |
|    episodes         | 6580     |
|    fps              | 117      |
|    time_elapsed     | 1016     |
|    total_timesteps  | 119367   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000589 |
|    n_updates        | 19841    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0225  |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 6584     |
|    fps              | 117      |
|    time_elapsed     | 1017     |
|    total_timesteps  | 119454   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00563  |
|    n_updates        | 19863    |
----------------------------------
Eval num_timesteps=119500, episode_reward=-0.28 +/- 0.06
Episode length: 69.16 +/- 14.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.2     |
|    mean_reward      | -0.276   |
| rollout/            |          |
|    exploration_rate | 0.87     |
| time/               |          |
|    total_timesteps  | 119500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000564 |
|    n_updates        | 19874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 6588     |
|    fps              | 117      |
|    time_elapsed     | 1021     |
|    total_timesteps  | 119520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000584 |
|    n_updates        | 19879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 6592     |
|    fps              | 117      |
|    time_elapsed     | 1021     |
|    total_timesteps  | 119587   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00559  |
|    n_updates        | 19896    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 6596     |
|    fps              | 117      |
|    time_elapsed     | 1021     |
|    total_timesteps  | 119649   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00581  |
|    n_updates        | 19912    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0218  |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 6600     |
|    fps              | 117      |
|    time_elapsed     | 1021     |
|    total_timesteps  | 119717   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.011    |
|    n_updates        | 19929    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0316  |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 6604     |
|    fps              | 117      |
|    time_elapsed     | 1021     |
|    total_timesteps  | 119785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000769 |
|    n_updates        | 19946    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0315  |
|    exploration_rate | 0.869    |
| time/               |          |
|    episodes         | 6608     |
|    fps              | 117      |
|    time_elapsed     | 1021     |
|    total_timesteps  | 119854   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 19963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0318  |
|    exploration_rate | 0.869    |
| time/               |          |
|    episodes         | 6612     |
|    fps              | 117      |
|    time_elapsed     | 1022     |
|    total_timesteps  | 119936   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000543 |
|    n_updates        | 19983    |
----------------------------------
Eval num_timesteps=120000, episode_reward=-0.26 +/- 0.07
Episode length: 64.48 +/- 18.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.5     |
|    mean_reward      | -0.258   |
| rollout/            |          |
|    exploration_rate | 0.869    |
| time/               |          |
|    total_timesteps  | 120000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000574 |
|    n_updates        | 19999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.869    |
| time/               |          |
|    episodes         | 6616     |
|    fps              | 116      |
|    time_elapsed     | 1025     |
|    total_timesteps  | 120012   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00557  |
|    n_updates        | 20002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.869    |
| time/               |          |
|    episodes         | 6620     |
|    fps              | 117      |
|    time_elapsed     | 1025     |
|    total_timesteps  | 120080   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000666 |
|    n_updates        | 20019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.869    |
| time/               |          |
|    episodes         | 6624     |
|    fps              | 117      |
|    time_elapsed     | 1026     |
|    total_timesteps  | 120177   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 20044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0236  |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 6628     |
|    fps              | 117      |
|    time_elapsed     | 1026     |
|    total_timesteps  | 120253   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000682 |
|    n_updates        | 20063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 6632     |
|    fps              | 117      |
|    time_elapsed     | 1026     |
|    total_timesteps  | 120326   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0048   |
|    n_updates        | 20081    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0239  |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 6636     |
|    fps              | 117      |
|    time_elapsed     | 1026     |
|    total_timesteps  | 120406   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000376 |
|    n_updates        | 20101    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 6640     |
|    fps              | 117      |
|    time_elapsed     | 1026     |
|    total_timesteps  | 120486   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 20121    |
----------------------------------
Eval num_timesteps=120500, episode_reward=-0.08 +/- 0.03
Episode length: 20.76 +/- 8.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20.8     |
|    mean_reward      | -0.0821  |
| rollout/            |          |
|    exploration_rate | 0.868    |
| time/               |          |
|    total_timesteps  | 120500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00305  |
|    n_updates        | 20124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0243  |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 6644     |
|    fps              | 117      |
|    time_elapsed     | 1027     |
|    total_timesteps  | 120554   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000667 |
|    n_updates        | 20138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 6648     |
|    fps              | 117      |
|    time_elapsed     | 1028     |
|    total_timesteps  | 120623   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000947 |
|    n_updates        | 20155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0239  |
|    exploration_rate | 0.867    |
| time/               |          |
|    episodes         | 6652     |
|    fps              | 117      |
|    time_elapsed     | 1028     |
|    total_timesteps  | 120697   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00543  |
|    n_updates        | 20174    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.867    |
| time/               |          |
|    episodes         | 6656     |
|    fps              | 117      |
|    time_elapsed     | 1028     |
|    total_timesteps  | 120766   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000584 |
|    n_updates        | 20191    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00298 |
|    exploration_rate | 0.867    |
| time/               |          |
|    episodes         | 6660     |
|    fps              | 117      |
|    time_elapsed     | 1028     |
|    total_timesteps  | 120841   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000618 |
|    n_updates        | 20210    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00294 |
|    exploration_rate | 0.867    |
| time/               |          |
|    episodes         | 6664     |
|    fps              | 117      |
|    time_elapsed     | 1028     |
|    total_timesteps  | 120908   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 20226    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00242 |
|    exploration_rate | 0.867    |
| time/               |          |
|    episodes         | 6668     |
|    fps              | 117      |
|    time_elapsed     | 1028     |
|    total_timesteps  | 120977   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 20244    |
----------------------------------
Eval num_timesteps=121000, episode_reward=-0.06 +/- 0.14
Episode length: 19.50 +/- 1.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.5     |
|    mean_reward      | -0.057   |
| rollout/            |          |
|    exploration_rate | 0.867    |
| time/               |          |
|    total_timesteps  | 121000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00535  |
|    n_updates        | 20249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0078   |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 6672     |
|    fps              | 117      |
|    time_elapsed     | 1029     |
|    total_timesteps  | 121051   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000986 |
|    n_updates        | 20262    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0031  |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 6676     |
|    fps              | 117      |
|    time_elapsed     | 1029     |
|    total_timesteps  | 121132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000631 |
|    n_updates        | 20282    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00258 |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 6680     |
|    fps              | 117      |
|    time_elapsed     | 1029     |
|    total_timesteps  | 121208   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000585 |
|    n_updates        | 20301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00186 |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 6684     |
|    fps              | 117      |
|    time_elapsed     | 1029     |
|    total_timesteps  | 121277   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000644 |
|    n_updates        | 20319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 6688     |
|    fps              | 117      |
|    time_elapsed     | 1030     |
|    total_timesteps  | 121339   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000566 |
|    n_updates        | 20334    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 6692     |
|    fps              | 117      |
|    time_elapsed     | 1030     |
|    total_timesteps  | 121413   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 20353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.865    |
| time/               |          |
|    episodes         | 6696     |
|    fps              | 117      |
|    time_elapsed     | 1030     |
|    total_timesteps  | 121485   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000773 |
|    n_updates        | 20371    |
----------------------------------
Eval num_timesteps=121500, episode_reward=-0.06 +/- 0.14
Episode length: 19.36 +/- 1.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.4     |
|    mean_reward      | -0.0565  |
| rollout/            |          |
|    exploration_rate | 0.865    |
| time/               |          |
|    total_timesteps  | 121500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000682 |
|    n_updates        | 20374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.865    |
| time/               |          |
|    episodes         | 6700     |
|    fps              | 117      |
|    time_elapsed     | 1031     |
|    total_timesteps  | 121550   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000787 |
|    n_updates        | 20387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.865    |
| time/               |          |
|    episodes         | 6704     |
|    fps              | 117      |
|    time_elapsed     | 1031     |
|    total_timesteps  | 121623   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000414 |
|    n_updates        | 20405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.865    |
| time/               |          |
|    episodes         | 6708     |
|    fps              | 117      |
|    time_elapsed     | 1031     |
|    total_timesteps  | 121710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00319  |
|    n_updates        | 20427    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00691  |
|    exploration_rate | 0.865    |
| time/               |          |
|    episodes         | 6712     |
|    fps              | 118      |
|    time_elapsed     | 1031     |
|    total_timesteps  | 121789   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 20447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 6716     |
|    fps              | 118      |
|    time_elapsed     | 1031     |
|    total_timesteps  | 121847   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000659 |
|    n_updates        | 20461    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 6720     |
|    fps              | 118      |
|    time_elapsed     | 1031     |
|    total_timesteps  | 121922   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 20480    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 6724     |
|    fps              | 118      |
|    time_elapsed     | 1032     |
|    total_timesteps  | 121992   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000622 |
|    n_updates        | 20497    |
----------------------------------
Eval num_timesteps=122000, episode_reward=-0.30 +/- 0.03
Episode length: 73.86 +/- 7.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.864    |
| time/               |          |
|    total_timesteps  | 122000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 20499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 6728     |
|    fps              | 117      |
|    time_elapsed     | 1036     |
|    total_timesteps  | 122064   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000526 |
|    n_updates        | 20515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 6732     |
|    fps              | 117      |
|    time_elapsed     | 1036     |
|    total_timesteps  | 122141   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 20535    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 6736     |
|    fps              | 117      |
|    time_elapsed     | 1036     |
|    total_timesteps  | 122217   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000405 |
|    n_updates        | 20554    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.863    |
| time/               |          |
|    episodes         | 6740     |
|    fps              | 117      |
|    time_elapsed     | 1036     |
|    total_timesteps  | 122287   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000657 |
|    n_updates        | 20571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00854  |
|    exploration_rate | 0.863    |
| time/               |          |
|    episodes         | 6744     |
|    fps              | 118      |
|    time_elapsed     | 1036     |
|    total_timesteps  | 122366   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00077  |
|    n_updates        | 20591    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00774  |
|    exploration_rate | 0.863    |
| time/               |          |
|    episodes         | 6748     |
|    fps              | 118      |
|    time_elapsed     | 1037     |
|    total_timesteps  | 122455   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00579  |
|    n_updates        | 20613    |
----------------------------------
Eval num_timesteps=122500, episode_reward=-0.06 +/- 0.22
Episode length: 25.48 +/- 18.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 25.5     |
|    mean_reward      | -0.061   |
| rollout/            |          |
|    exploration_rate | 0.863    |
| time/               |          |
|    total_timesteps  | 122500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00648  |
|    n_updates        | 20624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0079   |
|    exploration_rate | 0.863    |
| time/               |          |
|    episodes         | 6752     |
|    fps              | 117      |
|    time_elapsed     | 1038     |
|    total_timesteps  | 122525   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00098  |
|    n_updates        | 20631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00193 |
|    exploration_rate | 0.863    |
| time/               |          |
|    episodes         | 6756     |
|    fps              | 118      |
|    time_elapsed     | 1038     |
|    total_timesteps  | 122590   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000588 |
|    n_updates        | 20647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00227 |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 6760     |
|    fps              | 118      |
|    time_elapsed     | 1038     |
|    total_timesteps  | 122673   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00056  |
|    n_updates        | 20668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0122  |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 6764     |
|    fps              | 118      |
|    time_elapsed     | 1038     |
|    total_timesteps  | 122737   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000865 |
|    n_updates        | 20684    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0122  |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 6768     |
|    fps              | 118      |
|    time_elapsed     | 1038     |
|    total_timesteps  | 122807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00552  |
|    n_updates        | 20701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 6772     |
|    fps              | 118      |
|    time_elapsed     | 1039     |
|    total_timesteps  | 122868   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000771 |
|    n_updates        | 20716    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 6776     |
|    fps              | 118      |
|    time_elapsed     | 1039     |
|    total_timesteps  | 122947   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000511 |
|    n_updates        | 20736    |
----------------------------------
Eval num_timesteps=123000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.862    |
| time/               |          |
|    total_timesteps  | 123000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000367 |
|    n_updates        | 20749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00196 |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 6780     |
|    fps              | 117      |
|    time_elapsed     | 1043     |
|    total_timesteps  | 123031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000477 |
|    n_updates        | 20757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00188 |
|    exploration_rate | 0.861    |
| time/               |          |
|    episodes         | 6784     |
|    fps              | 117      |
|    time_elapsed     | 1043     |
|    total_timesteps  | 123098   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00063  |
|    n_updates        | 20774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.861    |
| time/               |          |
|    episodes         | 6788     |
|    fps              | 117      |
|    time_elapsed     | 1043     |
|    total_timesteps  | 123162   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 20790    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.861    |
| time/               |          |
|    episodes         | 6792     |
|    fps              | 118      |
|    time_elapsed     | 1043     |
|    total_timesteps  | 123234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000705 |
|    n_updates        | 20808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0216  |
|    exploration_rate | 0.861    |
| time/               |          |
|    episodes         | 6796     |
|    fps              | 118      |
|    time_elapsed     | 1043     |
|    total_timesteps  | 123299   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000452 |
|    n_updates        | 20824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.861    |
| time/               |          |
|    episodes         | 6800     |
|    fps              | 118      |
|    time_elapsed     | 1044     |
|    total_timesteps  | 123368   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00631  |
|    n_updates        | 20841    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0125  |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 6804     |
|    fps              | 118      |
|    time_elapsed     | 1044     |
|    total_timesteps  | 123460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 20864    |
----------------------------------
Eval num_timesteps=123500, episode_reward=-0.28 +/- 0.17
Episode length: 73.90 +/- 7.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.276   |
| rollout/            |          |
|    exploration_rate | 0.86     |
| time/               |          |
|    total_timesteps  | 123500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 20874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00217 |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 6808     |
|    fps              | 117      |
|    time_elapsed     | 1048     |
|    total_timesteps  | 123538   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000778 |
|    n_updates        | 20884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00835  |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 6812     |
|    fps              | 117      |
|    time_elapsed     | 1048     |
|    total_timesteps  | 123604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000707 |
|    n_updates        | 20900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 6816     |
|    fps              | 117      |
|    time_elapsed     | 1048     |
|    total_timesteps  | 123685   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 20921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00249 |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 6820     |
|    fps              | 118      |
|    time_elapsed     | 1048     |
|    total_timesteps  | 123758   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 20939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00261 |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 6824     |
|    fps              | 118      |
|    time_elapsed     | 1048     |
|    total_timesteps  | 123831   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00562  |
|    n_updates        | 20957    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0077   |
|    exploration_rate | 0.859    |
| time/               |          |
|    episodes         | 6828     |
|    fps              | 118      |
|    time_elapsed     | 1048     |
|    total_timesteps  | 123895   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000831 |
|    n_updates        | 20973    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00802  |
|    exploration_rate | 0.859    |
| time/               |          |
|    episodes         | 6832     |
|    fps              | 118      |
|    time_elapsed     | 1049     |
|    total_timesteps  | 123964   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000324 |
|    n_updates        | 20990    |
----------------------------------
Eval num_timesteps=124000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.859    |
| time/               |          |
|    total_timesteps  | 124000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 20999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00802  |
|    exploration_rate | 0.859    |
| time/               |          |
|    episodes         | 6836     |
|    fps              | 117      |
|    time_elapsed     | 1053     |
|    total_timesteps  | 124040   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000485 |
|    n_updates        | 21009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00766  |
|    exploration_rate | 0.859    |
| time/               |          |
|    episodes         | 6840     |
|    fps              | 117      |
|    time_elapsed     | 1053     |
|    total_timesteps  | 124119   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000631 |
|    n_updates        | 21029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00794  |
|    exploration_rate | 0.859    |
| time/               |          |
|    episodes         | 6844     |
|    fps              | 117      |
|    time_elapsed     | 1053     |
|    total_timesteps  | 124191   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000517 |
|    n_updates        | 21047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.858    |
| time/               |          |
|    episodes         | 6848     |
|    fps              | 117      |
|    time_elapsed     | 1053     |
|    total_timesteps  | 124259   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00045  |
|    n_updates        | 21064    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 0.858    |
| time/               |          |
|    episodes         | 6852     |
|    fps              | 117      |
|    time_elapsed     | 1053     |
|    total_timesteps  | 124336   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000721 |
|    n_updates        | 21083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.858    |
| time/               |          |
|    episodes         | 6856     |
|    fps              | 118      |
|    time_elapsed     | 1053     |
|    total_timesteps  | 124415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000403 |
|    n_updates        | 21103    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0079   |
|    exploration_rate | 0.858    |
| time/               |          |
|    episodes         | 6860     |
|    fps              | 118      |
|    time_elapsed     | 1054     |
|    total_timesteps  | 124499   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000836 |
|    n_updates        | 21124    |
----------------------------------
Eval num_timesteps=124500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 124500   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00778  |
|    exploration_rate | 0.858    |
| time/               |          |
|    episodes         | 6864     |
|    fps              | 117      |
|    time_elapsed     | 1058     |
|    total_timesteps  | 124566   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000616 |
|    n_updates        | 21141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00762  |
|    exploration_rate | 0.857    |
| time/               |          |
|    episodes         | 6868     |
|    fps              | 117      |
|    time_elapsed     | 1058     |
|    total_timesteps  | 124640   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00047  |
|    n_updates        | 21159    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00285 |
|    exploration_rate | 0.857    |
| time/               |          |
|    episodes         | 6872     |
|    fps              | 117      |
|    time_elapsed     | 1058     |
|    total_timesteps  | 124713   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000908 |
|    n_updates        | 21178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00253 |
|    exploration_rate | 0.857    |
| time/               |          |
|    episodes         | 6876     |
|    fps              | 117      |
|    time_elapsed     | 1058     |
|    total_timesteps  | 124784   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000482 |
|    n_updates        | 21195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00244 |
|    exploration_rate | 0.857    |
| time/               |          |
|    episodes         | 6880     |
|    fps              | 117      |
|    time_elapsed     | 1058     |
|    total_timesteps  | 124866   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000524 |
|    n_updates        | 21216    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0032  |
|    exploration_rate | 0.857    |
| time/               |          |
|    episodes         | 6884     |
|    fps              | 117      |
|    time_elapsed     | 1058     |
|    total_timesteps  | 124952   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000496 |
|    n_updates        | 21237    |
----------------------------------
Eval num_timesteps=125000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.857    |
| time/               |          |
|    total_timesteps  | 125000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000823 |
|    n_updates        | 21249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00392 |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 6888     |
|    fps              | 117      |
|    time_elapsed     | 1063     |
|    total_timesteps  | 125034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000719 |
|    n_updates        | 21258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00404 |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 6892     |
|    fps              | 117      |
|    time_elapsed     | 1063     |
|    total_timesteps  | 125109   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000373 |
|    n_updates        | 21277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0042  |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 6896     |
|    fps              | 117      |
|    time_elapsed     | 1063     |
|    total_timesteps  | 125178   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000912 |
|    n_updates        | 21294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0159   |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 6900     |
|    fps              | 117      |
|    time_elapsed     | 1064     |
|    total_timesteps  | 125245   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00397  |
|    n_updates        | 21311    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 6904     |
|    fps              | 117      |
|    time_elapsed     | 1064     |
|    total_timesteps  | 125311   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 21327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 6908     |
|    fps              | 117      |
|    time_elapsed     | 1064     |
|    total_timesteps  | 125371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000561 |
|    n_updates        | 21342    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.855    |
| time/               |          |
|    episodes         | 6912     |
|    fps              | 117      |
|    time_elapsed     | 1064     |
|    total_timesteps  | 125447   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000709 |
|    n_updates        | 21361    |
----------------------------------
Eval num_timesteps=125500, episode_reward=-0.30 +/- 0.03
Episode length: 73.86 +/- 7.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.855    |
| time/               |          |
|    total_timesteps  | 125500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00086  |
|    n_updates        | 21374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.855    |
| time/               |          |
|    episodes         | 6916     |
|    fps              | 117      |
|    time_elapsed     | 1069     |
|    total_timesteps  | 125508   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000722 |
|    n_updates        | 21376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00791  |
|    exploration_rate | 0.855    |
| time/               |          |
|    episodes         | 6920     |
|    fps              | 117      |
|    time_elapsed     | 1069     |
|    total_timesteps  | 125585   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000551 |
|    n_updates        | 21396    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00791  |
|    exploration_rate | 0.855    |
| time/               |          |
|    episodes         | 6924     |
|    fps              | 117      |
|    time_elapsed     | 1069     |
|    total_timesteps  | 125658   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000596 |
|    n_updates        | 21414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00719  |
|    exploration_rate | 0.855    |
| time/               |          |
|    episodes         | 6928     |
|    fps              | 117      |
|    time_elapsed     | 1069     |
|    total_timesteps  | 125740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000669 |
|    n_updates        | 21434    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00679  |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 6932     |
|    fps              | 117      |
|    time_elapsed     | 1069     |
|    total_timesteps  | 125819   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000474 |
|    n_updates        | 21454    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00659  |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 6936     |
|    fps              | 117      |
|    time_elapsed     | 1069     |
|    total_timesteps  | 125900   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000312 |
|    n_updates        | 21474    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00691  |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 6940     |
|    fps              | 117      |
|    time_elapsed     | 1069     |
|    total_timesteps  | 125971   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000697 |
|    n_updates        | 21492    |
----------------------------------
Eval num_timesteps=126000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.854    |
| time/               |          |
|    total_timesteps  | 126000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00064  |
|    n_updates        | 21499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00727  |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 6944     |
|    fps              | 117      |
|    time_elapsed     | 1074     |
|    total_timesteps  | 126034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000629 |
|    n_updates        | 21508    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00376 |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 6948     |
|    fps              | 117      |
|    time_elapsed     | 1074     |
|    total_timesteps  | 126128   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000496 |
|    n_updates        | 21531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0034  |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 6952     |
|    fps              | 117      |
|    time_elapsed     | 1074     |
|    total_timesteps  | 126196   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000672 |
|    n_updates        | 21548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00324 |
|    exploration_rate | 0.853    |
| time/               |          |
|    episodes         | 6956     |
|    fps              | 117      |
|    time_elapsed     | 1074     |
|    total_timesteps  | 126271   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00459  |
|    n_updates        | 21567    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0026  |
|    exploration_rate | 0.853    |
| time/               |          |
|    episodes         | 6960     |
|    fps              | 117      |
|    time_elapsed     | 1074     |
|    total_timesteps  | 126339   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000921 |
|    n_updates        | 21584    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00276 |
|    exploration_rate | 0.853    |
| time/               |          |
|    episodes         | 6964     |
|    fps              | 117      |
|    time_elapsed     | 1074     |
|    total_timesteps  | 126410   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00523  |
|    n_updates        | 21602    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00248 |
|    exploration_rate | 0.853    |
| time/               |          |
|    episodes         | 6968     |
|    fps              | 117      |
|    time_elapsed     | 1074     |
|    total_timesteps  | 126477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000788 |
|    n_updates        | 21619    |
----------------------------------
Eval num_timesteps=126500, episode_reward=0.02 +/- 0.41
Episode length: 34.02 +/- 24.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34       |
|    mean_reward      | 0.0247   |
| rollout/            |          |
|    exploration_rate | 0.853    |
| time/               |          |
|    total_timesteps  | 126500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000909 |
|    n_updates        | 21624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00244 |
|    exploration_rate | 0.853    |
| time/               |          |
|    episodes         | 6972     |
|    fps              | 117      |
|    time_elapsed     | 1076     |
|    total_timesteps  | 126549   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000834 |
|    n_updates        | 21637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0022  |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 6976     |
|    fps              | 117      |
|    time_elapsed     | 1076     |
|    total_timesteps  | 126614   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0034   |
|    n_updates        | 21653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 6980     |
|    fps              | 117      |
|    time_elapsed     | 1077     |
|    total_timesteps  | 126680   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000982 |
|    n_updates        | 21669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0108  |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 6984     |
|    fps              | 117      |
|    time_elapsed     | 1077     |
|    total_timesteps  | 126748   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000691 |
|    n_updates        | 21686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 6988     |
|    fps              | 117      |
|    time_elapsed     | 1077     |
|    total_timesteps  | 126826   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000416 |
|    n_updates        | 21706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00048 |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 6992     |
|    fps              | 117      |
|    time_elapsed     | 1077     |
|    total_timesteps  | 126896   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000447 |
|    n_updates        | 21723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00036 |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 6996     |
|    fps              | 117      |
|    time_elapsed     | 1077     |
|    total_timesteps  | 126962   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000704 |
|    n_updates        | 21740    |
----------------------------------
Eval num_timesteps=127000, episode_reward=-0.27 +/- 0.18
Episode length: 73.06 +/- 9.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.1     |
|    mean_reward      | -0.272   |
| rollout/            |          |
|    exploration_rate | 0.851    |
| time/               |          |
|    total_timesteps  | 127000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000895 |
|    n_updates        | 21749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.851    |
| time/               |          |
|    episodes         | 7000     |
|    fps              | 117      |
|    time_elapsed     | 1081     |
|    total_timesteps  | 127028   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00792  |
|    n_updates        | 21756    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0208  |
|    exploration_rate | 0.851    |
| time/               |          |
|    episodes         | 7004     |
|    fps              | 117      |
|    time_elapsed     | 1081     |
|    total_timesteps  | 127107   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 21776    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0313  |
|    exploration_rate | 0.851    |
| time/               |          |
|    episodes         | 7008     |
|    fps              | 117      |
|    time_elapsed     | 1081     |
|    total_timesteps  | 127179   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000731 |
|    n_updates        | 21794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 0.851    |
| time/               |          |
|    episodes         | 7012     |
|    fps              | 117      |
|    time_elapsed     | 1082     |
|    total_timesteps  | 127259   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000842 |
|    n_updates        | 21814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 0.851    |
| time/               |          |
|    episodes         | 7016     |
|    fps              | 117      |
|    time_elapsed     | 1082     |
|    total_timesteps  | 127336   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000976 |
|    n_updates        | 21833    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00194 |
|    exploration_rate | 0.85     |
| time/               |          |
|    episodes         | 7020     |
|    fps              | 117      |
|    time_elapsed     | 1082     |
|    total_timesteps  | 127410   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00731  |
|    n_updates        | 21852    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00206 |
|    exploration_rate | 0.85     |
| time/               |          |
|    episodes         | 7024     |
|    fps              | 117      |
|    time_elapsed     | 1082     |
|    total_timesteps  | 127486   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000501 |
|    n_updates        | 21871    |
----------------------------------
Eval num_timesteps=127500, episode_reward=-0.13 +/- 0.37
Episode length: 56.92 +/- 26.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.9     |
|    mean_reward      | -0.127   |
| rollout/            |          |
|    exploration_rate | 0.85     |
| time/               |          |
|    total_timesteps  | 127500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00678  |
|    n_updates        | 21874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.85     |
| time/               |          |
|    episodes         | 7028     |
|    fps              | 117      |
|    time_elapsed     | 1085     |
|    total_timesteps  | 127566   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000717 |
|    n_updates        | 21891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00813  |
|    exploration_rate | 0.85     |
| time/               |          |
|    episodes         | 7032     |
|    fps              | 117      |
|    time_elapsed     | 1085     |
|    total_timesteps  | 127642   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000903 |
|    n_updates        | 21910    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.85     |
| time/               |          |
|    episodes         | 7036     |
|    fps              | 117      |
|    time_elapsed     | 1085     |
|    total_timesteps  | 127720   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 21929    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 7040     |
|    fps              | 117      |
|    time_elapsed     | 1086     |
|    total_timesteps  | 127786   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000795 |
|    n_updates        | 21946    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 7044     |
|    fps              | 117      |
|    time_elapsed     | 1086     |
|    total_timesteps  | 127852   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000535 |
|    n_updates        | 21962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 7048     |
|    fps              | 117      |
|    time_elapsed     | 1086     |
|    total_timesteps  | 127921   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 21980    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0393   |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 7052     |
|    fps              | 117      |
|    time_elapsed     | 1086     |
|    total_timesteps  | 127989   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000456 |
|    n_updates        | 21997    |
----------------------------------
Eval num_timesteps=128000, episode_reward=-0.19 +/- 0.21
Episode length: 57.28 +/- 20.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.3     |
|    mean_reward      | -0.189   |
| rollout/            |          |
|    exploration_rate | 0.849    |
| time/               |          |
|    total_timesteps  | 128000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 21999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0392   |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 7056     |
|    fps              | 117      |
|    time_elapsed     | 1090     |
|    total_timesteps  | 128067   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000864 |
|    n_updates        | 22016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0491   |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 7060     |
|    fps              | 117      |
|    time_elapsed     | 1090     |
|    total_timesteps  | 128137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00201  |
|    n_updates        | 22034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0494   |
|    exploration_rate | 0.848    |
| time/               |          |
|    episodes         | 7064     |
|    fps              | 117      |
|    time_elapsed     | 1090     |
|    total_timesteps  | 128200   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 22049    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0489   |
|    exploration_rate | 0.848    |
| time/               |          |
|    episodes         | 7068     |
|    fps              | 117      |
|    time_elapsed     | 1090     |
|    total_timesteps  | 128281   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000818 |
|    n_updates        | 22070    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0482   |
|    exploration_rate | 0.848    |
| time/               |          |
|    episodes         | 7072     |
|    fps              | 117      |
|    time_elapsed     | 1090     |
|    total_timesteps  | 128370   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000562 |
|    n_updates        | 22092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.058    |
|    exploration_rate | 0.848    |
| time/               |          |
|    episodes         | 7076     |
|    fps              | 117      |
|    time_elapsed     | 1090     |
|    total_timesteps  | 128440   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000233 |
|    n_updates        | 22109    |
----------------------------------
Eval num_timesteps=128500, episode_reward=-0.17 +/- 0.33
Episode length: 67.72 +/- 12.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.7     |
|    mean_reward      | -0.17    |
| rollout/            |          |
|    exploration_rate | 0.848    |
| time/               |          |
|    total_timesteps  | 128500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0126   |
|    n_updates        | 22124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0578   |
|    exploration_rate | 0.848    |
| time/               |          |
|    episodes         | 7080     |
|    fps              | 117      |
|    time_elapsed     | 1094     |
|    total_timesteps  | 128510   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000885 |
|    n_updates        | 22127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0676   |
|    exploration_rate | 0.847    |
| time/               |          |
|    episodes         | 7084     |
|    fps              | 117      |
|    time_elapsed     | 1094     |
|    total_timesteps  | 128584   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000581 |
|    n_updates        | 22145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0677   |
|    exploration_rate | 0.847    |
| time/               |          |
|    episodes         | 7088     |
|    fps              | 117      |
|    time_elapsed     | 1095     |
|    total_timesteps  | 128659   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000722 |
|    n_updates        | 22164    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0576   |
|    exploration_rate | 0.847    |
| time/               |          |
|    episodes         | 7092     |
|    fps              | 117      |
|    time_elapsed     | 1095     |
|    total_timesteps  | 128731   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00675  |
|    n_updates        | 22182    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.057    |
|    exploration_rate | 0.847    |
| time/               |          |
|    episodes         | 7096     |
|    fps              | 117      |
|    time_elapsed     | 1095     |
|    total_timesteps  | 128812   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000846 |
|    n_updates        | 22202    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0464   |
|    exploration_rate | 0.847    |
| time/               |          |
|    episodes         | 7100     |
|    fps              | 117      |
|    time_elapsed     | 1095     |
|    total_timesteps  | 128892   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00076  |
|    n_updates        | 22222    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.037    |
|    exploration_rate | 0.846    |
| time/               |          |
|    episodes         | 7104     |
|    fps              | 117      |
|    time_elapsed     | 1095     |
|    total_timesteps  | 128956   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00075  |
|    n_updates        | 22238    |
----------------------------------
Eval num_timesteps=129000, episode_reward=-0.27 +/- 0.07
Episode length: 67.58 +/- 16.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.6     |
|    mean_reward      | -0.27    |
| rollout/            |          |
|    exploration_rate | 0.846    |
| time/               |          |
|    total_timesteps  | 129000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00328  |
|    n_updates        | 22249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0367   |
|    exploration_rate | 0.846    |
| time/               |          |
|    episodes         | 7108     |
|    fps              | 117      |
|    time_elapsed     | 1099     |
|    total_timesteps  | 129036   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000478 |
|    n_updates        | 22258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0265   |
|    exploration_rate | 0.846    |
| time/               |          |
|    episodes         | 7112     |
|    fps              | 117      |
|    time_elapsed     | 1099     |
|    total_timesteps  | 129121   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000904 |
|    n_updates        | 22280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0165   |
|    exploration_rate | 0.846    |
| time/               |          |
|    episodes         | 7116     |
|    fps              | 117      |
|    time_elapsed     | 1099     |
|    total_timesteps  | 129197   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000867 |
|    n_updates        | 22299    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00669  |
|    exploration_rate | 0.846    |
| time/               |          |
|    episodes         | 7120     |
|    fps              | 117      |
|    time_elapsed     | 1099     |
|    total_timesteps  | 129267   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000641 |
|    n_updates        | 22316    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00709  |
|    exploration_rate | 0.845    |
| time/               |          |
|    episodes         | 7124     |
|    fps              | 117      |
|    time_elapsed     | 1099     |
|    total_timesteps  | 129333   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000528 |
|    n_updates        | 22333    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.845    |
| time/               |          |
|    episodes         | 7128     |
|    fps              | 117      |
|    time_elapsed     | 1099     |
|    total_timesteps  | 129407   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000355 |
|    n_updates        | 22351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00788  |
|    exploration_rate | 0.845    |
| time/               |          |
|    episodes         | 7132     |
|    fps              | 117      |
|    time_elapsed     | 1099     |
|    total_timesteps  | 129470   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000735 |
|    n_updates        | 22367    |
----------------------------------
Eval num_timesteps=129500, episode_reward=-0.23 +/- 0.22
Episode length: 67.86 +/- 17.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.9     |
|    mean_reward      | -0.231   |
| rollout/            |          |
|    exploration_rate | 0.845    |
| time/               |          |
|    total_timesteps  | 129500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000597 |
|    n_updates        | 22374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00235 |
|    exploration_rate | 0.845    |
| time/               |          |
|    episodes         | 7136     |
|    fps              | 117      |
|    time_elapsed     | 1104     |
|    total_timesteps  | 129554   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000457 |
|    n_updates        | 22388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00279 |
|    exploration_rate | 0.845    |
| time/               |          |
|    episodes         | 7140     |
|    fps              | 117      |
|    time_elapsed     | 1104     |
|    total_timesteps  | 129631   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00444  |
|    n_updates        | 22407    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00339 |
|    exploration_rate | 0.844    |
| time/               |          |
|    episodes         | 7144     |
|    fps              | 117      |
|    time_elapsed     | 1104     |
|    total_timesteps  | 129712   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000432 |
|    n_updates        | 22427    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.844    |
| time/               |          |
|    episodes         | 7148     |
|    fps              | 117      |
|    time_elapsed     | 1104     |
|    total_timesteps  | 129791   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000831 |
|    n_updates        | 22447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.844    |
| time/               |          |
|    episodes         | 7152     |
|    fps              | 117      |
|    time_elapsed     | 1104     |
|    total_timesteps  | 129875   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000869 |
|    n_updates        | 22468    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.025   |
|    exploration_rate | 0.844    |
| time/               |          |
|    episodes         | 7156     |
|    fps              | 117      |
|    time_elapsed     | 1104     |
|    total_timesteps  | 129966   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000405 |
|    n_updates        | 22491    |
----------------------------------
Eval num_timesteps=130000, episode_reward=-0.23 +/- 0.30
Episode length: 71.34 +/- 14.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.3     |
|    mean_reward      | -0.225   |
| rollout/            |          |
|    exploration_rate | 0.844    |
| time/               |          |
|    total_timesteps  | 130000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000455 |
|    n_updates        | 22499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0351  |
|    exploration_rate | 0.844    |
| time/               |          |
|    episodes         | 7160     |
|    fps              | 117      |
|    time_elapsed     | 1109     |
|    total_timesteps  | 130040   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000531 |
|    n_updates        | 22509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0254  |
|    exploration_rate | 0.843    |
| time/               |          |
|    episodes         | 7164     |
|    fps              | 117      |
|    time_elapsed     | 1109     |
|    total_timesteps  | 130110   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 22527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0251  |
|    exploration_rate | 0.843    |
| time/               |          |
|    episodes         | 7168     |
|    fps              | 117      |
|    time_elapsed     | 1109     |
|    total_timesteps  | 130183   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000656 |
|    n_updates        | 22545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.843    |
| time/               |          |
|    episodes         | 7172     |
|    fps              | 117      |
|    time_elapsed     | 1109     |
|    total_timesteps  | 130260   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000655 |
|    n_updates        | 22564    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 0.843    |
| time/               |          |
|    episodes         | 7176     |
|    fps              | 117      |
|    time_elapsed     | 1109     |
|    total_timesteps  | 130326   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00688  |
|    n_updates        | 22581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0343  |
|    exploration_rate | 0.843    |
| time/               |          |
|    episodes         | 7180     |
|    fps              | 117      |
|    time_elapsed     | 1109     |
|    total_timesteps  | 130394   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00689  |
|    n_updates        | 22598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0446  |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 7184     |
|    fps              | 117      |
|    time_elapsed     | 1109     |
|    total_timesteps  | 130474   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00632  |
|    n_updates        | 22618    |
----------------------------------
Eval num_timesteps=130500, episode_reward=-0.09 +/- 0.33
Episode length: 47.60 +/- 19.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.6     |
|    mean_reward      | -0.0895  |
| rollout/            |          |
|    exploration_rate | 0.842    |
| time/               |          |
|    total_timesteps  | 130500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000824 |
|    n_updates        | 22624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0447  |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 7188     |
|    fps              | 117      |
|    time_elapsed     | 1112     |
|    total_timesteps  | 130552   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000843 |
|    n_updates        | 22637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 7192     |
|    fps              | 117      |
|    time_elapsed     | 1112     |
|    total_timesteps  | 130625   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 22656    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0346  |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 7196     |
|    fps              | 117      |
|    time_elapsed     | 1112     |
|    total_timesteps  | 130702   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00628  |
|    n_updates        | 22675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0341  |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 7200     |
|    fps              | 117      |
|    time_elapsed     | 1112     |
|    total_timesteps  | 130771   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000684 |
|    n_updates        | 22692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 7204     |
|    fps              | 117      |
|    time_elapsed     | 1113     |
|    total_timesteps  | 130851   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 22712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0349  |
|    exploration_rate | 0.841    |
| time/               |          |
|    episodes         | 7208     |
|    fps              | 117      |
|    time_elapsed     | 1113     |
|    total_timesteps  | 130936   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000754 |
|    n_updates        | 22733    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 0.841    |
| time/               |          |
|    episodes         | 7212     |
|    fps              | 117      |
|    time_elapsed     | 1113     |
|    total_timesteps  | 130998   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00458  |
|    n_updates        | 22749    |
----------------------------------
Eval num_timesteps=131000, episode_reward=-0.18 +/- 0.20
Episode length: 55.18 +/- 18.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.2     |
|    mean_reward      | -0.18    |
| rollout/            |          |
|    exploration_rate | 0.841    |
| time/               |          |
|    total_timesteps  | 131000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 0.841    |
| time/               |          |
|    episodes         | 7216     |
|    fps              | 117      |
|    time_elapsed     | 1116     |
|    total_timesteps  | 131073   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0102   |
|    n_updates        | 22768    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 0.841    |
| time/               |          |
|    episodes         | 7220     |
|    fps              | 117      |
|    time_elapsed     | 1116     |
|    total_timesteps  | 131143   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000615 |
|    n_updates        | 22785    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.841    |
| time/               |          |
|    episodes         | 7224     |
|    fps              | 117      |
|    time_elapsed     | 1116     |
|    total_timesteps  | 131213   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000926 |
|    n_updates        | 22803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.034   |
|    exploration_rate | 0.84     |
| time/               |          |
|    episodes         | 7228     |
|    fps              | 117      |
|    time_elapsed     | 1116     |
|    total_timesteps  | 131283   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000533 |
|    n_updates        | 22820    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0442  |
|    exploration_rate | 0.84     |
| time/               |          |
|    episodes         | 7232     |
|    fps              | 117      |
|    time_elapsed     | 1116     |
|    total_timesteps  | 131350   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00777  |
|    n_updates        | 22837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0337  |
|    exploration_rate | 0.84     |
| time/               |          |
|    episodes         | 7236     |
|    fps              | 117      |
|    time_elapsed     | 1117     |
|    total_timesteps  | 131422   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 22855    |
----------------------------------
Eval num_timesteps=131500, episode_reward=0.01 +/- 0.39
Episode length: 42.78 +/- 19.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 0.00998  |
| rollout/            |          |
|    exploration_rate | 0.84     |
| time/               |          |
|    total_timesteps  | 131500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000838 |
|    n_updates        | 22874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0338  |
|    exploration_rate | 0.84     |
| time/               |          |
|    episodes         | 7240     |
|    fps              | 117      |
|    time_elapsed     | 1119     |
|    total_timesteps  | 131502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000442 |
|    n_updates        | 22875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.84     |
| time/               |          |
|    episodes         | 7244     |
|    fps              | 117      |
|    time_elapsed     | 1119     |
|    total_timesteps  | 131569   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000845 |
|    n_updates        | 22892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.839    |
| time/               |          |
|    episodes         | 7248     |
|    fps              | 117      |
|    time_elapsed     | 1119     |
|    total_timesteps  | 131636   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 22908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.839    |
| time/               |          |
|    episodes         | 7252     |
|    fps              | 117      |
|    time_elapsed     | 1119     |
|    total_timesteps  | 131707   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000661 |
|    n_updates        | 22926    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.839    |
| time/               |          |
|    episodes         | 7256     |
|    fps              | 117      |
|    time_elapsed     | 1119     |
|    total_timesteps  | 131781   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000673 |
|    n_updates        | 22945    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00118 |
|    exploration_rate | 0.839    |
| time/               |          |
|    episodes         | 7260     |
|    fps              | 117      |
|    time_elapsed     | 1120     |
|    total_timesteps  | 131846   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000641 |
|    n_updates        | 22961    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.839    |
| time/               |          |
|    episodes         | 7264     |
|    fps              | 117      |
|    time_elapsed     | 1120     |
|    total_timesteps  | 131924   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000435 |
|    n_updates        | 22980    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00155 |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 7268     |
|    fps              | 117      |
|    time_elapsed     | 1120     |
|    total_timesteps  | 131998   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000763 |
|    n_updates        | 22999    |
----------------------------------
Eval num_timesteps=132000, episode_reward=-0.12 +/- 0.34
Episode length: 55.46 +/- 21.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.5     |
|    mean_reward      | -0.121   |
| rollout/            |          |
|    exploration_rate | 0.838    |
| time/               |          |
|    total_timesteps  | 132000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00131 |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 7272     |
|    fps              | 117      |
|    time_elapsed     | 1123     |
|    total_timesteps  | 132069   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000642 |
|    n_updates        | 23017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00167 |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 7276     |
|    fps              | 117      |
|    time_elapsed     | 1123     |
|    total_timesteps  | 132144   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000609 |
|    n_updates        | 23035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00195 |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 7280     |
|    fps              | 117      |
|    time_elapsed     | 1123     |
|    total_timesteps  | 132219   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 23054    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00818  |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 7284     |
|    fps              | 117      |
|    time_elapsed     | 1123     |
|    total_timesteps  | 132296   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00066  |
|    n_updates        | 23073    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00866  |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 7288     |
|    fps              | 117      |
|    time_elapsed     | 1123     |
|    total_timesteps  | 132362   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000804 |
|    n_updates        | 23090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0014  |
|    exploration_rate | 0.837    |
| time/               |          |
|    episodes         | 7292     |
|    fps              | 117      |
|    time_elapsed     | 1124     |
|    total_timesteps  | 132436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000525 |
|    n_updates        | 23108    |
----------------------------------
Eval num_timesteps=132500, episode_reward=-0.16 +/- 0.23
Episode length: 51.24 +/- 23.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.2     |
|    mean_reward      | -0.164   |
| rollout/            |          |
|    exploration_rate | 0.837    |
| time/               |          |
|    total_timesteps  | 132500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000647 |
|    n_updates        | 23124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00108 |
|    exploration_rate | 0.837    |
| time/               |          |
|    episodes         | 7296     |
|    fps              | 117      |
|    time_elapsed     | 1127     |
|    total_timesteps  | 132505   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000988 |
|    n_updates        | 23126    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00873  |
|    exploration_rate | 0.837    |
| time/               |          |
|    episodes         | 7300     |
|    fps              | 117      |
|    time_elapsed     | 1127     |
|    total_timesteps  | 132579   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000991 |
|    n_updates        | 23144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 0.837    |
| time/               |          |
|    episodes         | 7304     |
|    fps              | 117      |
|    time_elapsed     | 1127     |
|    total_timesteps  | 132649   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000693 |
|    n_updates        | 23162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 0.837    |
| time/               |          |
|    episodes         | 7308     |
|    fps              | 117      |
|    time_elapsed     | 1127     |
|    total_timesteps  | 132720   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000493 |
|    n_updates        | 23179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0091   |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 7312     |
|    fps              | 117      |
|    time_elapsed     | 1127     |
|    total_timesteps  | 132797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 23199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 7316     |
|    fps              | 117      |
|    time_elapsed     | 1127     |
|    total_timesteps  | 132872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000422 |
|    n_updates        | 23217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 7320     |
|    fps              | 117      |
|    time_elapsed     | 1127     |
|    total_timesteps  | 132956   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000715 |
|    n_updates        | 23238    |
----------------------------------
Eval num_timesteps=133000, episode_reward=-0.11 +/- 0.27
Episode length: 42.74 +/- 20.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.7     |
|    mean_reward      | -0.11    |
| rollout/            |          |
|    exploration_rate | 0.836    |
| time/               |          |
|    total_timesteps  | 133000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000707 |
|    n_updates        | 23249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 7324     |
|    fps              | 117      |
|    time_elapsed     | 1130     |
|    total_timesteps  | 133023   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 23255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 7328     |
|    fps              | 117      |
|    time_elapsed     | 1130     |
|    total_timesteps  | 133093   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000705 |
|    n_updates        | 23273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 7332     |
|    fps              | 117      |
|    time_elapsed     | 1130     |
|    total_timesteps  | 133175   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000485 |
|    n_updates        | 23293    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 7336     |
|    fps              | 117      |
|    time_elapsed     | 1130     |
|    total_timesteps  | 133241   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00424  |
|    n_updates        | 23310    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 7340     |
|    fps              | 117      |
|    time_elapsed     | 1130     |
|    total_timesteps  | 133324   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00776  |
|    n_updates        | 23330    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 7344     |
|    fps              | 117      |
|    time_elapsed     | 1131     |
|    total_timesteps  | 133400   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000654 |
|    n_updates        | 23349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 7348     |
|    fps              | 118      |
|    time_elapsed     | 1131     |
|    total_timesteps  | 133480   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 23369    |
----------------------------------
Eval num_timesteps=133500, episode_reward=-0.18 +/- 0.18
Episode length: 51.18 +/- 19.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.2     |
|    mean_reward      | -0.184   |
| rollout/            |          |
|    exploration_rate | 0.835    |
| time/               |          |
|    total_timesteps  | 133500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00553  |
|    n_updates        | 23374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.834    |
| time/               |          |
|    episodes         | 7352     |
|    fps              | 117      |
|    time_elapsed     | 1134     |
|    total_timesteps  | 133549   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0004   |
|    n_updates        | 23387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00699  |
|    exploration_rate | 0.834    |
| time/               |          |
|    episodes         | 7356     |
|    fps              | 117      |
|    time_elapsed     | 1134     |
|    total_timesteps  | 133632   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000814 |
|    n_updates        | 23407    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00369 |
|    exploration_rate | 0.834    |
| time/               |          |
|    episodes         | 7360     |
|    fps              | 117      |
|    time_elapsed     | 1134     |
|    total_timesteps  | 133714   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00201  |
|    n_updates        | 23428    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00353 |
|    exploration_rate | 0.834    |
| time/               |          |
|    episodes         | 7364     |
|    fps              | 117      |
|    time_elapsed     | 1134     |
|    total_timesteps  | 133788   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000587 |
|    n_updates        | 23446    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.834    |
| time/               |          |
|    episodes         | 7368     |
|    fps              | 117      |
|    time_elapsed     | 1134     |
|    total_timesteps  | 133879   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00521  |
|    n_updates        | 23469    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00439 |
|    exploration_rate | 0.833    |
| time/               |          |
|    episodes         | 7372     |
|    fps              | 118      |
|    time_elapsed     | 1134     |
|    total_timesteps  | 133954   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 23488    |
----------------------------------
Eval num_timesteps=134000, episode_reward=-0.10 +/- 0.29
Episode length: 46.12 +/- 21.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | -0.104   |
| rollout/            |          |
|    exploration_rate | 0.833    |
| time/               |          |
|    total_timesteps  | 134000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000531 |
|    n_updates        | 23499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00403 |
|    exploration_rate | 0.833    |
| time/               |          |
|    episodes         | 7376     |
|    fps              | 117      |
|    time_elapsed     | 1137     |
|    total_timesteps  | 134020   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 23504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00383 |
|    exploration_rate | 0.833    |
| time/               |          |
|    episodes         | 7380     |
|    fps              | 117      |
|    time_elapsed     | 1137     |
|    total_timesteps  | 134090   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000939 |
|    n_updates        | 23522    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.833    |
| time/               |          |
|    episodes         | 7384     |
|    fps              | 117      |
|    time_elapsed     | 1137     |
|    total_timesteps  | 134177   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000848 |
|    n_updates        | 23544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00438 |
|    exploration_rate | 0.833    |
| time/               |          |
|    episodes         | 7388     |
|    fps              | 117      |
|    time_elapsed     | 1137     |
|    total_timesteps  | 134247   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00382  |
|    n_updates        | 23561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00474 |
|    exploration_rate | 0.832    |
| time/               |          |
|    episodes         | 7392     |
|    fps              | 118      |
|    time_elapsed     | 1138     |
|    total_timesteps  | 134330   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000769 |
|    n_updates        | 23582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00548  |
|    exploration_rate | 0.832    |
| time/               |          |
|    episodes         | 7396     |
|    fps              | 118      |
|    time_elapsed     | 1138     |
|    total_timesteps  | 134394   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000683 |
|    n_updates        | 23598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.016    |
|    exploration_rate | 0.832    |
| time/               |          |
|    episodes         | 7400     |
|    fps              | 118      |
|    time_elapsed     | 1138     |
|    total_timesteps  | 134456   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000821 |
|    n_updates        | 23613    |
----------------------------------
Eval num_timesteps=134500, episode_reward=-0.17 +/- 0.22
Episode length: 53.82 +/- 18.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.8     |
|    mean_reward      | -0.175   |
| rollout/            |          |
|    exploration_rate | 0.832    |
| time/               |          |
|    total_timesteps  | 134500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000968 |
|    n_updates        | 23624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00621  |
|    exploration_rate | 0.832    |
| time/               |          |
|    episodes         | 7404     |
|    fps              | 117      |
|    time_elapsed     | 1141     |
|    total_timesteps  | 134520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000552 |
|    n_updates        | 23629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00561  |
|    exploration_rate | 0.832    |
| time/               |          |
|    episodes         | 7408     |
|    fps              | 117      |
|    time_elapsed     | 1141     |
|    total_timesteps  | 134606   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00572  |
|    n_updates        | 23651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00533  |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 7412     |
|    fps              | 117      |
|    time_elapsed     | 1141     |
|    total_timesteps  | 134690   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000616 |
|    n_updates        | 23672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0042  |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 7416     |
|    fps              | 118      |
|    time_elapsed     | 1141     |
|    total_timesteps  | 134753   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 23688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 7420     |
|    fps              | 118      |
|    time_elapsed     | 1141     |
|    total_timesteps  | 134827   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00077  |
|    n_updates        | 23706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 7424     |
|    fps              | 118      |
|    time_elapsed     | 1142     |
|    total_timesteps  | 134897   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00962  |
|    n_updates        | 23724    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00381 |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 7428     |
|    fps              | 118      |
|    time_elapsed     | 1142     |
|    total_timesteps  | 134965   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00084  |
|    n_updates        | 23741    |
----------------------------------
Eval num_timesteps=135000, episode_reward=-0.10 +/- 0.26
Episode length: 40.12 +/- 19.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.1     |
|    mean_reward      | -0.0995  |
| rollout/            |          |
|    exploration_rate | 0.831    |
| time/               |          |
|    total_timesteps  | 135000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000396 |
|    n_updates        | 23749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00365 |
|    exploration_rate | 0.83     |
| time/               |          |
|    episodes         | 7432     |
|    fps              | 117      |
|    time_elapsed     | 1144     |
|    total_timesteps  | 135043   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00631  |
|    n_updates        | 23760    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00377 |
|    exploration_rate | 0.83     |
| time/               |          |
|    episodes         | 7436     |
|    fps              | 118      |
|    time_elapsed     | 1144     |
|    total_timesteps  | 135112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000892 |
|    n_updates        | 23777    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00353 |
|    exploration_rate | 0.83     |
| time/               |          |
|    episodes         | 7440     |
|    fps              | 118      |
|    time_elapsed     | 1144     |
|    total_timesteps  | 135189   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00829  |
|    n_updates        | 23797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.83     |
| time/               |          |
|    episodes         | 7444     |
|    fps              | 118      |
|    time_elapsed     | 1144     |
|    total_timesteps  | 135257   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000411 |
|    n_updates        | 23814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.83     |
| time/               |          |
|    episodes         | 7448     |
|    fps              | 118      |
|    time_elapsed     | 1145     |
|    total_timesteps  | 135323   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000663 |
|    n_updates        | 23830    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00247 |
|    exploration_rate | 0.829    |
| time/               |          |
|    episodes         | 7452     |
|    fps              | 118      |
|    time_elapsed     | 1145     |
|    total_timesteps  | 135388   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00672  |
|    n_updates        | 23846    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00279 |
|    exploration_rate | 0.829    |
| time/               |          |
|    episodes         | 7456     |
|    fps              | 118      |
|    time_elapsed     | 1145     |
|    total_timesteps  | 135479   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000588 |
|    n_updates        | 23869    |
----------------------------------
Eval num_timesteps=135500, episode_reward=-0.09 +/- 0.27
Episode length: 42.00 +/- 23.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42       |
|    mean_reward      | -0.0872  |
| rollout/            |          |
|    exploration_rate | 0.829    |
| time/               |          |
|    total_timesteps  | 135500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0072   |
|    n_updates        | 23874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00247 |
|    exploration_rate | 0.829    |
| time/               |          |
|    episodes         | 7460     |
|    fps              | 118      |
|    time_elapsed     | 1147     |
|    total_timesteps  | 135553   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 23888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00207 |
|    exploration_rate | 0.829    |
| time/               |          |
|    episodes         | 7464     |
|    fps              | 118      |
|    time_elapsed     | 1147     |
|    total_timesteps  | 135617   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000732 |
|    n_updates        | 23904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00139 |
|    exploration_rate | 0.829    |
| time/               |          |
|    episodes         | 7468     |
|    fps              | 118      |
|    time_elapsed     | 1147     |
|    total_timesteps  | 135691   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000569 |
|    n_updates        | 23922    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.828    |
| time/               |          |
|    episodes         | 7472     |
|    fps              | 118      |
|    time_elapsed     | 1148     |
|    total_timesteps  | 135762   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000671 |
|    n_updates        | 23940    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 0.828    |
| time/               |          |
|    episodes         | 7476     |
|    fps              | 118      |
|    time_elapsed     | 1148     |
|    total_timesteps  | 135829   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00067  |
|    n_updates        | 23957    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 0.828    |
| time/               |          |
|    episodes         | 7480     |
|    fps              | 118      |
|    time_elapsed     | 1148     |
|    total_timesteps  | 135901   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0101   |
|    n_updates        | 23975    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0007  |
|    exploration_rate | 0.828    |
| time/               |          |
|    episodes         | 7484     |
|    fps              | 118      |
|    time_elapsed     | 1148     |
|    total_timesteps  | 135972   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0059   |
|    n_updates        | 23992    |
----------------------------------
Eval num_timesteps=136000, episode_reward=-0.03 +/- 0.34
Episode length: 37.90 +/- 22.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.9     |
|    mean_reward      | -0.0308  |
| rollout/            |          |
|    exploration_rate | 0.828    |
| time/               |          |
|    total_timesteps  | 136000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000749 |
|    n_updates        | 23999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.828    |
| time/               |          |
|    episodes         | 7488     |
|    fps              | 118      |
|    time_elapsed     | 1150     |
|    total_timesteps  | 136063   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 24015    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00088 |
|    exploration_rate | 0.827    |
| time/               |          |
|    episodes         | 7492     |
|    fps              | 118      |
|    time_elapsed     | 1150     |
|    total_timesteps  | 136129   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00278  |
|    n_updates        | 24032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00094 |
|    exploration_rate | 0.827    |
| time/               |          |
|    episodes         | 7496     |
|    fps              | 118      |
|    time_elapsed     | 1150     |
|    total_timesteps  | 136194   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 24048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.022   |
|    exploration_rate | 0.827    |
| time/               |          |
|    episodes         | 7500     |
|    fps              | 118      |
|    time_elapsed     | 1150     |
|    total_timesteps  | 136281   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00844  |
|    n_updates        | 24070    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.827    |
| time/               |          |
|    episodes         | 7504     |
|    fps              | 118      |
|    time_elapsed     | 1151     |
|    total_timesteps  | 136360   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000749 |
|    n_updates        | 24089    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0218  |
|    exploration_rate | 0.827    |
| time/               |          |
|    episodes         | 7508     |
|    fps              | 118      |
|    time_elapsed     | 1151     |
|    total_timesteps  | 136427   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000548 |
|    n_updates        | 24106    |
----------------------------------
Eval num_timesteps=136500, episode_reward=-0.16 +/- 0.30
Episode length: 59.28 +/- 16.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.3     |
|    mean_reward      | -0.156   |
| rollout/            |          |
|    exploration_rate | 0.826    |
| time/               |          |
|    total_timesteps  | 136500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00421  |
|    n_updates        | 24124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 7512     |
|    fps              | 118      |
|    time_elapsed     | 1154     |
|    total_timesteps  | 136518   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00418  |
|    n_updates        | 24129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 7516     |
|    fps              | 118      |
|    time_elapsed     | 1154     |
|    total_timesteps  | 136595   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 24148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 7520     |
|    fps              | 118      |
|    time_elapsed     | 1154     |
|    total_timesteps  | 136662   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00476  |
|    n_updates        | 24165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0225  |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 7524     |
|    fps              | 118      |
|    time_elapsed     | 1155     |
|    total_timesteps  | 136735   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000412 |
|    n_updates        | 24183    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0223  |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 7528     |
|    fps              | 118      |
|    time_elapsed     | 1155     |
|    total_timesteps  | 136799   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00331  |
|    n_updates        | 24199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.022   |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 7532     |
|    fps              | 118      |
|    time_elapsed     | 1155     |
|    total_timesteps  | 136868   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000521 |
|    n_updates        | 24216    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.825    |
| time/               |          |
|    episodes         | 7536     |
|    fps              | 118      |
|    time_elapsed     | 1155     |
|    total_timesteps  | 136934   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000845 |
|    n_updates        | 24233    |
----------------------------------
Eval num_timesteps=137000, episode_reward=-0.14 +/- 0.25
Episode length: 50.06 +/- 19.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.1     |
|    mean_reward      | -0.139   |
| rollout/            |          |
|    exploration_rate | 0.825    |
| time/               |          |
|    total_timesteps  | 137000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000982 |
|    n_updates        | 24249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.825    |
| time/               |          |
|    episodes         | 7540     |
|    fps              | 118      |
|    time_elapsed     | 1158     |
|    total_timesteps  | 137012   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 24252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0225  |
|    exploration_rate | 0.825    |
| time/               |          |
|    episodes         | 7544     |
|    fps              | 118      |
|    time_elapsed     | 1158     |
|    total_timesteps  | 137095   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 24273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.825    |
| time/               |          |
|    episodes         | 7548     |
|    fps              | 118      |
|    time_elapsed     | 1158     |
|    total_timesteps  | 137176   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00507  |
|    n_updates        | 24293    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.824    |
| time/               |          |
|    episodes         | 7552     |
|    fps              | 118      |
|    time_elapsed     | 1158     |
|    total_timesteps  | 137241   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000673 |
|    n_updates        | 24310    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.824    |
| time/               |          |
|    episodes         | 7556     |
|    fps              | 118      |
|    time_elapsed     | 1158     |
|    total_timesteps  | 137318   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000951 |
|    n_updates        | 24329    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.824    |
| time/               |          |
|    episodes         | 7560     |
|    fps              | 118      |
|    time_elapsed     | 1158     |
|    total_timesteps  | 137406   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000842 |
|    n_updates        | 24351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.824    |
| time/               |          |
|    episodes         | 7564     |
|    fps              | 118      |
|    time_elapsed     | 1159     |
|    total_timesteps  | 137477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000826 |
|    n_updates        | 24369    |
----------------------------------
Eval num_timesteps=137500, episode_reward=-0.02 +/- 0.41
Episode length: 45.62 +/- 23.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | -0.0217  |
| rollout/            |          |
|    exploration_rate | 0.824    |
| time/               |          |
|    total_timesteps  | 137500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00086  |
|    n_updates        | 24374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.824    |
| time/               |          |
|    episodes         | 7568     |
|    fps              | 118      |
|    time_elapsed     | 1161     |
|    total_timesteps  | 137551   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000781 |
|    n_updates        | 24387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.823    |
| time/               |          |
|    episodes         | 7572     |
|    fps              | 118      |
|    time_elapsed     | 1162     |
|    total_timesteps  | 137627   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 24406    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.823    |
| time/               |          |
|    episodes         | 7576     |
|    fps              | 118      |
|    time_elapsed     | 1162     |
|    total_timesteps  | 137706   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 24426    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.823    |
| time/               |          |
|    episodes         | 7580     |
|    fps              | 118      |
|    time_elapsed     | 1162     |
|    total_timesteps  | 137799   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000911 |
|    n_updates        | 24449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0252  |
|    exploration_rate | 0.823    |
| time/               |          |
|    episodes         | 7584     |
|    fps              | 118      |
|    time_elapsed     | 1162     |
|    total_timesteps  | 137877   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000638 |
|    n_updates        | 24469    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.823    |
| time/               |          |
|    episodes         | 7588     |
|    fps              | 118      |
|    time_elapsed     | 1162     |
|    total_timesteps  | 137951   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000492 |
|    n_updates        | 24487    |
----------------------------------
Eval num_timesteps=138000, episode_reward=-0.24 +/- 0.16
Episode length: 64.12 +/- 17.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.1     |
|    mean_reward      | -0.236   |
| rollout/            |          |
|    exploration_rate | 0.822    |
| time/               |          |
|    total_timesteps  | 138000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000953 |
|    n_updates        | 24499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.822    |
| time/               |          |
|    episodes         | 7592     |
|    fps              | 118      |
|    time_elapsed     | 1166     |
|    total_timesteps  | 138018   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000613 |
|    n_updates        | 24504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.822    |
| time/               |          |
|    episodes         | 7596     |
|    fps              | 118      |
|    time_elapsed     | 1166     |
|    total_timesteps  | 138079   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000952 |
|    n_updates        | 24519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.822    |
| time/               |          |
|    episodes         | 7600     |
|    fps              | 118      |
|    time_elapsed     | 1166     |
|    total_timesteps  | 138150   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000897 |
|    n_updates        | 24537    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.822    |
| time/               |          |
|    episodes         | 7604     |
|    fps              | 118      |
|    time_elapsed     | 1166     |
|    total_timesteps  | 138224   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00293  |
|    n_updates        | 24555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.004   |
|    exploration_rate | 0.822    |
| time/               |          |
|    episodes         | 7608     |
|    fps              | 118      |
|    time_elapsed     | 1166     |
|    total_timesteps  | 138303   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000582 |
|    n_updates        | 24575    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00654  |
|    exploration_rate | 0.821    |
| time/               |          |
|    episodes         | 7612     |
|    fps              | 118      |
|    time_elapsed     | 1166     |
|    total_timesteps  | 138381   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00431  |
|    n_updates        | 24595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00634  |
|    exploration_rate | 0.821    |
| time/               |          |
|    episodes         | 7616     |
|    fps              | 118      |
|    time_elapsed     | 1166     |
|    total_timesteps  | 138463   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000464 |
|    n_updates        | 24615    |
----------------------------------
Eval num_timesteps=138500, episode_reward=-0.15 +/- 0.29
Episode length: 58.20 +/- 18.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.2     |
|    mean_reward      | -0.152   |
| rollout/            |          |
|    exploration_rate | 0.821    |
| time/               |          |
|    total_timesteps  | 138500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 24624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0065   |
|    exploration_rate | 0.821    |
| time/               |          |
|    episodes         | 7620     |
|    fps              | 118      |
|    time_elapsed     | 1170     |
|    total_timesteps  | 138526   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00762  |
|    n_updates        | 24631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0061   |
|    exploration_rate | 0.821    |
| time/               |          |
|    episodes         | 7624     |
|    fps              | 118      |
|    time_elapsed     | 1170     |
|    total_timesteps  | 138609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000682 |
|    n_updates        | 24652    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00425 |
|    exploration_rate | 0.821    |
| time/               |          |
|    episodes         | 7628     |
|    fps              | 118      |
|    time_elapsed     | 1170     |
|    total_timesteps  | 138682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000838 |
|    n_updates        | 24670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00405 |
|    exploration_rate | 0.82     |
| time/               |          |
|    episodes         | 7632     |
|    fps              | 118      |
|    time_elapsed     | 1171     |
|    total_timesteps  | 138746   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000852 |
|    n_updates        | 24686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00437 |
|    exploration_rate | 0.82     |
| time/               |          |
|    episodes         | 7636     |
|    fps              | 118      |
|    time_elapsed     | 1171     |
|    total_timesteps  | 138820   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 24704    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00477 |
|    exploration_rate | 0.82     |
| time/               |          |
|    episodes         | 7640     |
|    fps              | 118      |
|    time_elapsed     | 1171     |
|    total_timesteps  | 138908   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000845 |
|    n_updates        | 24726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00437 |
|    exploration_rate | 0.82     |
| time/               |          |
|    episodes         | 7644     |
|    fps              | 118      |
|    time_elapsed     | 1171     |
|    total_timesteps  | 138981   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000939 |
|    n_updates        | 24745    |
----------------------------------
Eval num_timesteps=139000, episode_reward=-0.26 +/- 0.17
Episode length: 68.98 +/- 13.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69       |
|    mean_reward      | -0.256   |
| rollout/            |          |
|    exploration_rate | 0.82     |
| time/               |          |
|    total_timesteps  | 139000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000792 |
|    n_updates        | 24749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00461 |
|    exploration_rate | 0.82     |
| time/               |          |
|    episodes         | 7648     |
|    fps              | 118      |
|    time_elapsed     | 1175     |
|    total_timesteps  | 139068   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 24766    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00479 |
|    exploration_rate | 0.819    |
| time/               |          |
|    episodes         | 7652     |
|    fps              | 118      |
|    time_elapsed     | 1175     |
|    total_timesteps  | 139138   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000621 |
|    n_updates        | 24784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00483 |
|    exploration_rate | 0.819    |
| time/               |          |
|    episodes         | 7656     |
|    fps              | 118      |
|    time_elapsed     | 1175     |
|    total_timesteps  | 139216   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00511  |
|    n_updates        | 24803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.819    |
| time/               |          |
|    episodes         | 7660     |
|    fps              | 118      |
|    time_elapsed     | 1175     |
|    total_timesteps  | 139294   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00319  |
|    n_updates        | 24823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.819    |
| time/               |          |
|    episodes         | 7664     |
|    fps              | 118      |
|    time_elapsed     | 1175     |
|    total_timesteps  | 139369   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000811 |
|    n_updates        | 24842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.818    |
| time/               |          |
|    episodes         | 7668     |
|    fps              | 118      |
|    time_elapsed     | 1175     |
|    total_timesteps  | 139450   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000876 |
|    n_updates        | 24862    |
----------------------------------
Eval num_timesteps=139500, episode_reward=-0.13 +/- 0.33
Episode length: 58.32 +/- 18.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.3     |
|    mean_reward      | -0.133   |
| rollout/            |          |
|    exploration_rate | 0.818    |
| time/               |          |
|    total_timesteps  | 139500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00845  |
|    n_updates        | 24874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.818    |
| time/               |          |
|    episodes         | 7672     |
|    fps              | 118      |
|    time_elapsed     | 1179     |
|    total_timesteps  | 139526   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000633 |
|    n_updates        | 24881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.818    |
| time/               |          |
|    episodes         | 7676     |
|    fps              | 118      |
|    time_elapsed     | 1179     |
|    total_timesteps  | 139597   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000414 |
|    n_updates        | 24899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00358 |
|    exploration_rate | 0.818    |
| time/               |          |
|    episodes         | 7680     |
|    fps              | 118      |
|    time_elapsed     | 1180     |
|    total_timesteps  | 139666   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 24916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0035  |
|    exploration_rate | 0.818    |
| time/               |          |
|    episodes         | 7684     |
|    fps              | 118      |
|    time_elapsed     | 1180     |
|    total_timesteps  | 139742   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 24935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 7688     |
|    fps              | 118      |
|    time_elapsed     | 1180     |
|    total_timesteps  | 139822   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 24955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0239  |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 7692     |
|    fps              | 118      |
|    time_elapsed     | 1180     |
|    total_timesteps  | 139892   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000612 |
|    n_updates        | 24972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 7696     |
|    fps              | 118      |
|    time_elapsed     | 1180     |
|    total_timesteps  | 139970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000394 |
|    n_updates        | 24992    |
----------------------------------
Eval num_timesteps=140000, episode_reward=-0.17 +/- 0.24
Episode length: 53.08 +/- 25.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.1     |
|    mean_reward      | -0.172   |
| rollout/            |          |
|    exploration_rate | 0.817    |
| time/               |          |
|    total_timesteps  | 140000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000651 |
|    n_updates        | 24999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 7700     |
|    fps              | 118      |
|    time_elapsed     | 1183     |
|    total_timesteps  | 140042   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00647  |
|    n_updates        | 25010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0245  |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 7704     |
|    fps              | 118      |
|    time_elapsed     | 1183     |
|    total_timesteps  | 140113   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 25028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 0.816    |
| time/               |          |
|    episodes         | 7708     |
|    fps              | 118      |
|    time_elapsed     | 1183     |
|    total_timesteps  | 140190   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 25047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0443  |
|    exploration_rate | 0.816    |
| time/               |          |
|    episodes         | 7712     |
|    fps              | 118      |
|    time_elapsed     | 1183     |
|    total_timesteps  | 140263   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000915 |
|    n_updates        | 25065    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0439  |
|    exploration_rate | 0.816    |
| time/               |          |
|    episodes         | 7716     |
|    fps              | 118      |
|    time_elapsed     | 1184     |
|    total_timesteps  | 140335   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000973 |
|    n_updates        | 25083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.816    |
| time/               |          |
|    episodes         | 7720     |
|    fps              | 118      |
|    time_elapsed     | 1184     |
|    total_timesteps  | 140402   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 25100    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0339  |
|    exploration_rate | 0.816    |
| time/               |          |
|    episodes         | 7724     |
|    fps              | 118      |
|    time_elapsed     | 1184     |
|    total_timesteps  | 140482   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00463  |
|    n_updates        | 25120    |
----------------------------------
Eval num_timesteps=140500, episode_reward=-0.12 +/- 0.30
Episode length: 50.52 +/- 20.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.5     |
|    mean_reward      | -0.121   |
| rollout/            |          |
|    exploration_rate | 0.816    |
| time/               |          |
|    total_timesteps  | 140500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00659  |
|    n_updates        | 25124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0342  |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 7728     |
|    fps              | 118      |
|    time_elapsed     | 1187     |
|    total_timesteps  | 140563   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 25140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0351  |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 7732     |
|    fps              | 118      |
|    time_elapsed     | 1187     |
|    total_timesteps  | 140648   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 25161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0147  |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 7736     |
|    fps              | 118      |
|    time_elapsed     | 1187     |
|    total_timesteps  | 140713   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000684 |
|    n_updates        | 25178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 7740     |
|    fps              | 118      |
|    time_elapsed     | 1187     |
|    total_timesteps  | 140786   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000426 |
|    n_updates        | 25196    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 7744     |
|    fps              | 118      |
|    time_elapsed     | 1187     |
|    total_timesteps  | 140861   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000806 |
|    n_updates        | 25215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.814    |
| time/               |          |
|    episodes         | 7748     |
|    fps              | 118      |
|    time_elapsed     | 1188     |
|    total_timesteps  | 140928   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000982 |
|    n_updates        | 25231    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.814    |
| time/               |          |
|    episodes         | 7752     |
|    fps              | 118      |
|    time_elapsed     | 1188     |
|    total_timesteps  | 140991   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000906 |
|    n_updates        | 25247    |
----------------------------------
Eval num_timesteps=141000, episode_reward=0.01 +/- 0.27
Episode length: 18.80 +/- 8.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.8     |
|    mean_reward      | 0.00582  |
| rollout/            |          |
|    exploration_rate | 0.814    |
| time/               |          |
|    total_timesteps  | 141000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00369  |
|    n_updates        | 25249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.814    |
| time/               |          |
|    episodes         | 7756     |
|    fps              | 118      |
|    time_elapsed     | 1189     |
|    total_timesteps  | 141063   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000874 |
|    n_updates        | 25265    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.814    |
| time/               |          |
|    episodes         | 7760     |
|    fps              | 118      |
|    time_elapsed     | 1189     |
|    total_timesteps  | 141140   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000778 |
|    n_updates        | 25284    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.814    |
| time/               |          |
|    episodes         | 7764     |
|    fps              | 118      |
|    time_elapsed     | 1189     |
|    total_timesteps  | 141233   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000651 |
|    n_updates        | 25308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00277 |
|    exploration_rate | 0.813    |
| time/               |          |
|    episodes         | 7768     |
|    fps              | 118      |
|    time_elapsed     | 1189     |
|    total_timesteps  | 141295   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000667 |
|    n_updates        | 25323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00277 |
|    exploration_rate | 0.813    |
| time/               |          |
|    episodes         | 7772     |
|    fps              | 118      |
|    time_elapsed     | 1189     |
|    total_timesteps  | 141371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 25342    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00309 |
|    exploration_rate | 0.813    |
| time/               |          |
|    episodes         | 7776     |
|    fps              | 118      |
|    time_elapsed     | 1189     |
|    total_timesteps  | 141450   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000768 |
|    n_updates        | 25362    |
----------------------------------
Eval num_timesteps=141500, episode_reward=0.05 +/- 0.43
Episode length: 38.72 +/- 19.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.7     |
|    mean_reward      | 0.046    |
| rollout/            |          |
|    exploration_rate | 0.813    |
| time/               |          |
|    total_timesteps  | 141500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000938 |
|    n_updates        | 25374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.813    |
| time/               |          |
|    episodes         | 7780     |
|    fps              | 118      |
|    time_elapsed     | 1192     |
|    total_timesteps  | 141513   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000834 |
|    n_updates        | 25378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0125  |
|    exploration_rate | 0.813    |
| time/               |          |
|    episodes         | 7784     |
|    fps              | 118      |
|    time_elapsed     | 1192     |
|    total_timesteps  | 141581   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000417 |
|    n_updates        | 25395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.812    |
| time/               |          |
|    episodes         | 7788     |
|    fps              | 118      |
|    time_elapsed     | 1192     |
|    total_timesteps  | 141641   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00071  |
|    n_updates        | 25410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.812    |
| time/               |          |
|    episodes         | 7792     |
|    fps              | 118      |
|    time_elapsed     | 1192     |
|    total_timesteps  | 141714   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000931 |
|    n_updates        | 25428    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.812    |
| time/               |          |
|    episodes         | 7796     |
|    fps              | 118      |
|    time_elapsed     | 1193     |
|    total_timesteps  | 141790   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000998 |
|    n_updates        | 25447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0284   |
|    exploration_rate | 0.812    |
| time/               |          |
|    episodes         | 7800     |
|    fps              | 118      |
|    time_elapsed     | 1193     |
|    total_timesteps  | 141858   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000517 |
|    n_updates        | 25464    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0388   |
|    exploration_rate | 0.812    |
| time/               |          |
|    episodes         | 7804     |
|    fps              | 118      |
|    time_elapsed     | 1193     |
|    total_timesteps  | 141919   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000685 |
|    n_updates        | 25479    |
----------------------------------
Eval num_timesteps=142000, episode_reward=0.08 +/- 0.35
Episode length: 15.74 +/- 2.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.7     |
|    mean_reward      | 0.0781   |
| rollout/            |          |
|    exploration_rate | 0.811    |
| time/               |          |
|    total_timesteps  | 142000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00268  |
|    n_updates        | 25499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0386   |
|    exploration_rate | 0.811    |
| time/               |          |
|    episodes         | 7808     |
|    fps              | 118      |
|    time_elapsed     | 1194     |
|    total_timesteps  | 142002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00092  |
|    n_updates        | 25500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 0.811    |
| time/               |          |
|    episodes         | 7812     |
|    fps              | 118      |
|    time_elapsed     | 1194     |
|    total_timesteps  | 142075   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 25518    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0488   |
|    exploration_rate | 0.811    |
| time/               |          |
|    episodes         | 7816     |
|    fps              | 119      |
|    time_elapsed     | 1194     |
|    total_timesteps  | 142142   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000793 |
|    n_updates        | 25535    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 0.811    |
| time/               |          |
|    episodes         | 7820     |
|    fps              | 119      |
|    time_elapsed     | 1194     |
|    total_timesteps  | 142212   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 25552    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0593   |
|    exploration_rate | 0.811    |
| time/               |          |
|    episodes         | 7824     |
|    fps              | 119      |
|    time_elapsed     | 1194     |
|    total_timesteps  | 142275   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 25568    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0597   |
|    exploration_rate | 0.81     |
| time/               |          |
|    episodes         | 7828     |
|    fps              | 119      |
|    time_elapsed     | 1194     |
|    total_timesteps  | 142346   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 25586    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0595   |
|    exploration_rate | 0.81     |
| time/               |          |
|    episodes         | 7832     |
|    fps              | 119      |
|    time_elapsed     | 1194     |
|    total_timesteps  | 142436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000373 |
|    n_updates        | 25608    |
----------------------------------
Eval num_timesteps=142500, episode_reward=0.06 +/- 0.36
Episode length: 19.16 +/- 14.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.2     |
|    mean_reward      | 0.0643   |
| rollout/            |          |
|    exploration_rate | 0.81     |
| time/               |          |
|    total_timesteps  | 142500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 25624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 0.81     |
| time/               |          |
|    episodes         | 7836     |
|    fps              | 119      |
|    time_elapsed     | 1196     |
|    total_timesteps  | 142502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 25625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0399   |
|    exploration_rate | 0.81     |
| time/               |          |
|    episodes         | 7840     |
|    fps              | 119      |
|    time_elapsed     | 1196     |
|    total_timesteps  | 142564   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 25640    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0401   |
|    exploration_rate | 0.81     |
| time/               |          |
|    episodes         | 7844     |
|    fps              | 119      |
|    time_elapsed     | 1196     |
|    total_timesteps  | 142634   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000659 |
|    n_updates        | 25658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0499   |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 7848     |
|    fps              | 119      |
|    time_elapsed     | 1196     |
|    total_timesteps  | 142708   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000881 |
|    n_updates        | 25676    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 7852     |
|    fps              | 119      |
|    time_elapsed     | 1196     |
|    total_timesteps  | 142776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 25693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 7856     |
|    fps              | 119      |
|    time_elapsed     | 1196     |
|    total_timesteps  | 142844   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000559 |
|    n_updates        | 25710    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 7860     |
|    fps              | 119      |
|    time_elapsed     | 1196     |
|    total_timesteps  | 142927   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000905 |
|    n_updates        | 25731    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0509   |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 7864     |
|    fps              | 119      |
|    time_elapsed     | 1196     |
|    total_timesteps  | 142987   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000535 |
|    n_updates        | 25746    |
----------------------------------
Eval num_timesteps=143000, episode_reward=-0.11 +/- 0.25
Episode length: 41.66 +/- 23.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.7     |
|    mean_reward      | -0.106   |
| rollout/            |          |
|    exploration_rate | 0.809    |
| time/               |          |
|    total_timesteps  | 143000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000771 |
|    n_updates        | 25749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 0.808    |
| time/               |          |
|    episodes         | 7868     |
|    fps              | 119      |
|    time_elapsed     | 1199     |
|    total_timesteps  | 143077   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000712 |
|    n_updates        | 25769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0497   |
|    exploration_rate | 0.808    |
| time/               |          |
|    episodes         | 7872     |
|    fps              | 119      |
|    time_elapsed     | 1199     |
|    total_timesteps  | 143155   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000641 |
|    n_updates        | 25788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0599   |
|    exploration_rate | 0.808    |
| time/               |          |
|    episodes         | 7876     |
|    fps              | 119      |
|    time_elapsed     | 1199     |
|    total_timesteps  | 143230   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00602  |
|    n_updates        | 25807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0597   |
|    exploration_rate | 0.808    |
| time/               |          |
|    episodes         | 7880     |
|    fps              | 119      |
|    time_elapsed     | 1199     |
|    total_timesteps  | 143297   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 25824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0598   |
|    exploration_rate | 0.808    |
| time/               |          |
|    episodes         | 7884     |
|    fps              | 119      |
|    time_elapsed     | 1199     |
|    total_timesteps  | 143364   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 25840    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 7888     |
|    fps              | 119      |
|    time_elapsed     | 1200     |
|    total_timesteps  | 143422   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000538 |
|    n_updates        | 25855    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0505   |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 7892     |
|    fps              | 119      |
|    time_elapsed     | 1200     |
|    total_timesteps  | 143479   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00072  |
|    n_updates        | 25869    |
----------------------------------
Eval num_timesteps=143500, episode_reward=-0.14 +/- 0.23
Episode length: 46.24 +/- 29.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.2     |
|    mean_reward      | -0.144   |
| rollout/            |          |
|    exploration_rate | 0.807    |
| time/               |          |
|    total_timesteps  | 143500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000813 |
|    n_updates        | 25874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0404   |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 7896     |
|    fps              | 119      |
|    time_elapsed     | 1202     |
|    total_timesteps  | 143557   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000466 |
|    n_updates        | 25889    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 7900     |
|    fps              | 119      |
|    time_elapsed     | 1203     |
|    total_timesteps  | 143626   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000979 |
|    n_updates        | 25906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 7904     |
|    fps              | 119      |
|    time_elapsed     | 1203     |
|    total_timesteps  | 143697   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000483 |
|    n_updates        | 25924    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 7908     |
|    fps              | 119      |
|    time_elapsed     | 1203     |
|    total_timesteps  | 143769   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 25942    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 0.806    |
| time/               |          |
|    episodes         | 7912     |
|    fps              | 119      |
|    time_elapsed     | 1203     |
|    total_timesteps  | 143836   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000771 |
|    n_updates        | 25958    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0204   |
|    exploration_rate | 0.806    |
| time/               |          |
|    episodes         | 7916     |
|    fps              | 119      |
|    time_elapsed     | 1203     |
|    total_timesteps  | 143910   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000674 |
|    n_updates        | 25977    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0306   |
|    exploration_rate | 0.806    |
| time/               |          |
|    episodes         | 7920     |
|    fps              | 119      |
|    time_elapsed     | 1203     |
|    total_timesteps  | 143975   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000856 |
|    n_updates        | 25993    |
----------------------------------
Eval num_timesteps=144000, episode_reward=-0.01 +/- 0.25
Episode length: 18.62 +/- 10.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.6     |
|    mean_reward      | -0.0135  |
| rollout/            |          |
|    exploration_rate | 0.806    |
| time/               |          |
|    total_timesteps  | 144000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 25999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.806    |
| time/               |          |
|    episodes         | 7924     |
|    fps              | 119      |
|    time_elapsed     | 1204     |
|    total_timesteps  | 144044   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000612 |
|    n_updates        | 26010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.806    |
| time/               |          |
|    episodes         | 7928     |
|    fps              | 119      |
|    time_elapsed     | 1204     |
|    total_timesteps  | 144115   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0097   |
|    n_updates        | 26028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0107   |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 7932     |
|    fps              | 119      |
|    time_elapsed     | 1204     |
|    total_timesteps  | 144195   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 26048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0104   |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 7936     |
|    fps              | 119      |
|    time_elapsed     | 1205     |
|    total_timesteps  | 144269   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000997 |
|    n_updates        | 26067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 7940     |
|    fps              | 119      |
|    time_elapsed     | 1205     |
|    total_timesteps  | 144335   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000662 |
|    n_updates        | 26083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 7944     |
|    fps              | 119      |
|    time_elapsed     | 1205     |
|    total_timesteps  | 144407   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000505 |
|    n_updates        | 26101    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00037  |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 7948     |
|    fps              | 119      |
|    time_elapsed     | 1205     |
|    total_timesteps  | 144475   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 26118    |
----------------------------------
Eval num_timesteps=144500, episode_reward=-0.06 +/- 0.33
Episode length: 40.30 +/- 24.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.3     |
|    mean_reward      | -0.0603  |
| rollout/            |          |
|    exploration_rate | 0.804    |
| time/               |          |
|    total_timesteps  | 144500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00606  |
|    n_updates        | 26124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00041  |
|    exploration_rate | 0.804    |
| time/               |          |
|    episodes         | 7952     |
|    fps              | 119      |
|    time_elapsed     | 1208     |
|    total_timesteps  | 144542   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0057   |
|    n_updates        | 26135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00033  |
|    exploration_rate | 0.804    |
| time/               |          |
|    episodes         | 7956     |
|    fps              | 119      |
|    time_elapsed     | 1208     |
|    total_timesteps  | 144612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00077  |
|    n_updates        | 26152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00021  |
|    exploration_rate | 0.804    |
| time/               |          |
|    episodes         | 7960     |
|    fps              | 119      |
|    time_elapsed     | 1208     |
|    total_timesteps  | 144698   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 26174    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00037 |
|    exploration_rate | 0.804    |
| time/               |          |
|    episodes         | 7964     |
|    fps              | 119      |
|    time_elapsed     | 1208     |
|    total_timesteps  | 144773   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000894 |
|    n_updates        | 26193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00055  |
|    exploration_rate | 0.804    |
| time/               |          |
|    episodes         | 7968     |
|    fps              | 119      |
|    time_elapsed     | 1208     |
|    total_timesteps  | 144840   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000476 |
|    n_updates        | 26209    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00905 |
|    exploration_rate | 0.803    |
| time/               |          |
|    episodes         | 7972     |
|    fps              | 119      |
|    time_elapsed     | 1208     |
|    total_timesteps  | 144908   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000435 |
|    n_updates        | 26226    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0189  |
|    exploration_rate | 0.803    |
| time/               |          |
|    episodes         | 7976     |
|    fps              | 119      |
|    time_elapsed     | 1208     |
|    total_timesteps  | 144979   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000741 |
|    n_updates        | 26244    |
----------------------------------
Eval num_timesteps=145000, episode_reward=-0.07 +/- 0.14
Episode length: 23.16 +/- 18.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 23.2     |
|    mean_reward      | -0.0717  |
| rollout/            |          |
|    exploration_rate | 0.803    |
| time/               |          |
|    total_timesteps  | 145000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 26249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0191  |
|    exploration_rate | 0.803    |
| time/               |          |
|    episodes         | 7980     |
|    fps              | 119      |
|    time_elapsed     | 1210     |
|    total_timesteps  | 145050   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 26262    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.019   |
|    exploration_rate | 0.803    |
| time/               |          |
|    episodes         | 7984     |
|    fps              | 119      |
|    time_elapsed     | 1210     |
|    total_timesteps  | 145116   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 26278    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0297  |
|    exploration_rate | 0.803    |
| time/               |          |
|    episodes         | 7988     |
|    fps              | 119      |
|    time_elapsed     | 1210     |
|    total_timesteps  | 145192   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000859 |
|    n_updates        | 26297    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0406  |
|    exploration_rate | 0.802    |
| time/               |          |
|    episodes         | 7992     |
|    fps              | 120      |
|    time_elapsed     | 1210     |
|    total_timesteps  | 145271   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 26317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0301  |
|    exploration_rate | 0.802    |
| time/               |          |
|    episodes         | 7996     |
|    fps              | 120      |
|    time_elapsed     | 1210     |
|    total_timesteps  | 145337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000973 |
|    n_updates        | 26334    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0198  |
|    exploration_rate | 0.802    |
| time/               |          |
|    episodes         | 8000     |
|    fps              | 120      |
|    time_elapsed     | 1210     |
|    total_timesteps  | 145397   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000792 |
|    n_updates        | 26349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0301  |
|    exploration_rate | 0.802    |
| time/               |          |
|    episodes         | 8004     |
|    fps              | 120      |
|    time_elapsed     | 1210     |
|    total_timesteps  | 145475   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000563 |
|    n_updates        | 26368    |
----------------------------------
Eval num_timesteps=145500, episode_reward=-0.05 +/- 0.22
Episode length: 22.40 +/- 18.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22.4     |
|    mean_reward      | -0.0487  |
| rollout/            |          |
|    exploration_rate | 0.802    |
| time/               |          |
|    total_timesteps  | 145500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0134   |
|    n_updates        | 26374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0303  |
|    exploration_rate | 0.802    |
| time/               |          |
|    episodes         | 8008     |
|    fps              | 120      |
|    time_elapsed     | 1212     |
|    total_timesteps  | 145552   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 26387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.801    |
| time/               |          |
|    episodes         | 8012     |
|    fps              | 120      |
|    time_elapsed     | 1212     |
|    total_timesteps  | 145614   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000698 |
|    n_updates        | 26403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0097  |
|    exploration_rate | 0.801    |
| time/               |          |
|    episodes         | 8016     |
|    fps              | 120      |
|    time_elapsed     | 1212     |
|    total_timesteps  | 145679   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000923 |
|    n_updates        | 26419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0198  |
|    exploration_rate | 0.801    |
| time/               |          |
|    episodes         | 8020     |
|    fps              | 120      |
|    time_elapsed     | 1212     |
|    total_timesteps  | 145745   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00081  |
|    n_updates        | 26436    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00973 |
|    exploration_rate | 0.801    |
| time/               |          |
|    episodes         | 8024     |
|    fps              | 120      |
|    time_elapsed     | 1212     |
|    total_timesteps  | 145813   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000545 |
|    n_updates        | 26453    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00981 |
|    exploration_rate | 0.801    |
| time/               |          |
|    episodes         | 8028     |
|    fps              | 120      |
|    time_elapsed     | 1212     |
|    total_timesteps  | 145886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00508  |
|    n_updates        | 26471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00993 |
|    exploration_rate | 0.8      |
| time/               |          |
|    episodes         | 8032     |
|    fps              | 120      |
|    time_elapsed     | 1212     |
|    total_timesteps  | 145969   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00623  |
|    n_updates        | 26492    |
----------------------------------
Eval num_timesteps=146000, episode_reward=-0.09 +/- 0.05
Episode length: 23.38 +/- 13.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 23.4     |
|    mean_reward      | -0.0925  |
| rollout/            |          |
|    exploration_rate | 0.8      |
| time/               |          |
|    total_timesteps  | 146000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 26499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00989 |
|    exploration_rate | 0.8      |
| time/               |          |
|    episodes         | 8036     |
|    fps              | 120      |
|    time_elapsed     | 1214     |
|    total_timesteps  | 146042   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000705 |
|    n_updates        | 26510    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.01    |
|    exploration_rate | 0.8      |
| time/               |          |
|    episodes         | 8040     |
|    fps              | 120      |
|    time_elapsed     | 1214     |
|    total_timesteps  | 146112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000822 |
|    n_updates        | 26527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00965 |
|    exploration_rate | 0.8      |
| time/               |          |
|    episodes         | 8044     |
|    fps              | 120      |
|    time_elapsed     | 1214     |
|    total_timesteps  | 146174   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00439  |
|    n_updates        | 26543    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00977 |
|    exploration_rate | 0.8      |
| time/               |          |
|    episodes         | 8048     |
|    fps              | 120      |
|    time_elapsed     | 1214     |
|    total_timesteps  | 146245   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 26561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00969 |
|    exploration_rate | 0.799    |
| time/               |          |
|    episodes         | 8052     |
|    fps              | 120      |
|    time_elapsed     | 1214     |
|    total_timesteps  | 146310   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000761 |
|    n_updates        | 26577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00965 |
|    exploration_rate | 0.799    |
| time/               |          |
|    episodes         | 8056     |
|    fps              | 120      |
|    time_elapsed     | 1215     |
|    total_timesteps  | 146379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000685 |
|    n_updates        | 26594    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00913 |
|    exploration_rate | 0.799    |
| time/               |          |
|    episodes         | 8060     |
|    fps              | 120      |
|    time_elapsed     | 1215     |
|    total_timesteps  | 146452   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 26612    |
----------------------------------
Eval num_timesteps=146500, episode_reward=-0.03 +/- 0.24
Episode length: 21.52 +/- 12.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 21.5     |
|    mean_reward      | -0.0251  |
| rollout/            |          |
|    exploration_rate | 0.799    |
| time/               |          |
|    total_timesteps  | 146500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000805 |
|    n_updates        | 26624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 0.799    |
| time/               |          |
|    episodes         | 8064     |
|    fps              | 120      |
|    time_elapsed     | 1216     |
|    total_timesteps  | 146528   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000993 |
|    n_updates        | 26631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0194  |
|    exploration_rate | 0.799    |
| time/               |          |
|    episodes         | 8068     |
|    fps              | 120      |
|    time_elapsed     | 1216     |
|    total_timesteps  | 146601   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00189  |
|    n_updates        | 26650    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 0.798    |
| time/               |          |
|    episodes         | 8072     |
|    fps              | 120      |
|    time_elapsed     | 1216     |
|    total_timesteps  | 146676   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000992 |
|    n_updates        | 26668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0195  |
|    exploration_rate | 0.798    |
| time/               |          |
|    episodes         | 8076     |
|    fps              | 120      |
|    time_elapsed     | 1216     |
|    total_timesteps  | 146742   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 26685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.798    |
| time/               |          |
|    episodes         | 8080     |
|    fps              | 120      |
|    time_elapsed     | 1217     |
|    total_timesteps  | 146815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000731 |
|    n_updates        | 26703    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0198  |
|    exploration_rate | 0.798    |
| time/               |          |
|    episodes         | 8084     |
|    fps              | 120      |
|    time_elapsed     | 1217     |
|    total_timesteps  | 146887   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000824 |
|    n_updates        | 26721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 0.798    |
| time/               |          |
|    episodes         | 8088     |
|    fps              | 120      |
|    time_elapsed     | 1217     |
|    total_timesteps  | 146964   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000636 |
|    n_updates        | 26740    |
----------------------------------
Eval num_timesteps=147000, episode_reward=-0.03 +/- 0.26
Episode length: 22.90 +/- 17.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22.9     |
|    mean_reward      | -0.0307  |
| rollout/            |          |
|    exploration_rate | 0.797    |
| time/               |          |
|    total_timesteps  | 147000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000847 |
|    n_updates        | 26749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0193  |
|    exploration_rate | 0.797    |
| time/               |          |
|    episodes         | 8092     |
|    fps              | 120      |
|    time_elapsed     | 1218     |
|    total_timesteps  | 147028   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 26756    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0292  |
|    exploration_rate | 0.797    |
| time/               |          |
|    episodes         | 8096     |
|    fps              | 120      |
|    time_elapsed     | 1218     |
|    total_timesteps  | 147093   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000743 |
|    n_updates        | 26773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0399  |
|    exploration_rate | 0.797    |
| time/               |          |
|    episodes         | 8100     |
|    fps              | 120      |
|    time_elapsed     | 1218     |
|    total_timesteps  | 147170   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000726 |
|    n_updates        | 26792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0395  |
|    exploration_rate | 0.797    |
| time/               |          |
|    episodes         | 8104     |
|    fps              | 120      |
|    time_elapsed     | 1218     |
|    total_timesteps  | 147238   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000983 |
|    n_updates        | 26809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.039   |
|    exploration_rate | 0.797    |
| time/               |          |
|    episodes         | 8108     |
|    fps              | 120      |
|    time_elapsed     | 1219     |
|    total_timesteps  | 147302   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00071  |
|    n_updates        | 26825    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0496  |
|    exploration_rate | 0.796    |
| time/               |          |
|    episodes         | 8112     |
|    fps              | 120      |
|    time_elapsed     | 1219     |
|    total_timesteps  | 147379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000774 |
|    n_updates        | 26844    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0598  |
|    exploration_rate | 0.796    |
| time/               |          |
|    episodes         | 8116     |
|    fps              | 120      |
|    time_elapsed     | 1219     |
|    total_timesteps  | 147449   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00604  |
|    n_updates        | 26862    |
----------------------------------
Eval num_timesteps=147500, episode_reward=-0.06 +/- 0.27
Episode length: 30.16 +/- 24.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 30.2     |
|    mean_reward      | -0.0598  |
| rollout/            |          |
|    exploration_rate | 0.796    |
| time/               |          |
|    total_timesteps  | 147500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000855 |
|    n_updates        | 26874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0605  |
|    exploration_rate | 0.796    |
| time/               |          |
|    episodes         | 8120     |
|    fps              | 120      |
|    time_elapsed     | 1221     |
|    total_timesteps  | 147532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 26882    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0706  |
|    exploration_rate | 0.796    |
| time/               |          |
|    episodes         | 8124     |
|    fps              | 120      |
|    time_elapsed     | 1221     |
|    total_timesteps  | 147602   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 26900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0604  |
|    exploration_rate | 0.796    |
| time/               |          |
|    episodes         | 8128     |
|    fps              | 120      |
|    time_elapsed     | 1221     |
|    total_timesteps  | 147671   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000879 |
|    n_updates        | 26917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0499  |
|    exploration_rate | 0.795    |
| time/               |          |
|    episodes         | 8132     |
|    fps              | 120      |
|    time_elapsed     | 1221     |
|    total_timesteps  | 147742   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00226  |
|    n_updates        | 26935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0501  |
|    exploration_rate | 0.795    |
| time/               |          |
|    episodes         | 8136     |
|    fps              | 120      |
|    time_elapsed     | 1221     |
|    total_timesteps  | 147819   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000843 |
|    n_updates        | 26954    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0501  |
|    exploration_rate | 0.795    |
| time/               |          |
|    episodes         | 8140     |
|    fps              | 121      |
|    time_elapsed     | 1221     |
|    total_timesteps  | 147889   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000785 |
|    n_updates        | 26972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0505  |
|    exploration_rate | 0.795    |
| time/               |          |
|    episodes         | 8144     |
|    fps              | 121      |
|    time_elapsed     | 1222     |
|    total_timesteps  | 147961   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00488  |
|    n_updates        | 26990    |
----------------------------------
Eval num_timesteps=148000, episode_reward=0.03 +/- 0.30
Episode length: 16.56 +/- 6.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.6     |
|    mean_reward      | 0.0348   |
| rollout/            |          |
|    exploration_rate | 0.795    |
| time/               |          |
|    total_timesteps  | 148000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000833 |
|    n_updates        | 26999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0512  |
|    exploration_rate | 0.794    |
| time/               |          |
|    episodes         | 8148     |
|    fps              | 121      |
|    time_elapsed     | 1223     |
|    total_timesteps  | 148050   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00504  |
|    n_updates        | 27012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0518  |
|    exploration_rate | 0.794    |
| time/               |          |
|    episodes         | 8152     |
|    fps              | 121      |
|    time_elapsed     | 1223     |
|    total_timesteps  | 148131   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000504 |
|    n_updates        | 27032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0519  |
|    exploration_rate | 0.794    |
| time/               |          |
|    episodes         | 8156     |
|    fps              | 121      |
|    time_elapsed     | 1223     |
|    total_timesteps  | 148200   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000474 |
|    n_updates        | 27049    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0515  |
|    exploration_rate | 0.794    |
| time/               |          |
|    episodes         | 8160     |
|    fps              | 121      |
|    time_elapsed     | 1223     |
|    total_timesteps  | 148263   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000475 |
|    n_updates        | 27065    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0511  |
|    exploration_rate | 0.794    |
| time/               |          |
|    episodes         | 8164     |
|    fps              | 121      |
|    time_elapsed     | 1223     |
|    total_timesteps  | 148330   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000611 |
|    n_updates        | 27082    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0418  |
|    exploration_rate | 0.793    |
| time/               |          |
|    episodes         | 8168     |
|    fps              | 121      |
|    time_elapsed     | 1223     |
|    total_timesteps  | 148421   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00418  |
|    n_updates        | 27105    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0315  |
|    exploration_rate | 0.793    |
| time/               |          |
|    episodes         | 8172     |
|    fps              | 121      |
|    time_elapsed     | 1224     |
|    total_timesteps  | 148490   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00574  |
|    n_updates        | 27122    |
----------------------------------
Eval num_timesteps=148500, episode_reward=0.02 +/- 0.31
Episode length: 21.02 +/- 14.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 21       |
|    mean_reward      | 0.0169   |
| rollout/            |          |
|    exploration_rate | 0.793    |
| time/               |          |
|    total_timesteps  | 148500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000719 |
|    n_updates        | 27124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 0.793    |
| time/               |          |
|    episodes         | 8176     |
|    fps              | 121      |
|    time_elapsed     | 1225     |
|    total_timesteps  | 148551   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 27137    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00083 |
|    exploration_rate | 0.793    |
| time/               |          |
|    episodes         | 8180     |
|    fps              | 121      |
|    time_elapsed     | 1225     |
|    total_timesteps  | 148611   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0105   |
|    n_updates        | 27152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00051 |
|    exploration_rate | 0.793    |
| time/               |          |
|    episodes         | 8184     |
|    fps              | 121      |
|    time_elapsed     | 1226     |
|    total_timesteps  | 148675   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000878 |
|    n_updates        | 27168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00031 |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 8188     |
|    fps              | 121      |
|    time_elapsed     | 1226     |
|    total_timesteps  | 148747   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000663 |
|    n_updates        | 27186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00055 |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 8192     |
|    fps              | 121      |
|    time_elapsed     | 1226     |
|    total_timesteps  | 148817   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000446 |
|    n_updates        | 27204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 8196     |
|    fps              | 121      |
|    time_elapsed     | 1226     |
|    total_timesteps  | 148878   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00084  |
|    n_updates        | 27219    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0301   |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 8200     |
|    fps              | 121      |
|    time_elapsed     | 1226     |
|    total_timesteps  | 148944   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000848 |
|    n_updates        | 27235    |
----------------------------------
Eval num_timesteps=149000, episode_reward=-0.04 +/- 0.26
Episode length: 26.44 +/- 21.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 26.4     |
|    mean_reward      | -0.0449  |
| rollout/            |          |
|    exploration_rate | 0.792    |
| time/               |          |
|    total_timesteps  | 149000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000849 |
|    n_updates        | 27249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0302   |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 8204     |
|    fps              | 121      |
|    time_elapsed     | 1228     |
|    total_timesteps  | 149010   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 27252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0303   |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 8208     |
|    fps              | 121      |
|    time_elapsed     | 1228     |
|    total_timesteps  | 149071   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000887 |
|    n_updates        | 27267    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0301   |
|    exploration_rate | 0.791    |
| time/               |          |
|    episodes         | 8212     |
|    fps              | 121      |
|    time_elapsed     | 1228     |
|    total_timesteps  | 149153   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 27288    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0297   |
|    exploration_rate | 0.791    |
| time/               |          |
|    episodes         | 8216     |
|    fps              | 121      |
|    time_elapsed     | 1228     |
|    total_timesteps  | 149233   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 27308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0303   |
|    exploration_rate | 0.791    |
| time/               |          |
|    episodes         | 8220     |
|    fps              | 121      |
|    time_elapsed     | 1228     |
|    total_timesteps  | 149302   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00099  |
|    n_updates        | 27325    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.791    |
| time/               |          |
|    episodes         | 8224     |
|    fps              | 121      |
|    time_elapsed     | 1228     |
|    total_timesteps  | 149379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0133   |
|    n_updates        | 27344    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.79     |
| time/               |          |
|    episodes         | 8228     |
|    fps              | 121      |
|    time_elapsed     | 1228     |
|    total_timesteps  | 149448   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 27361    |
----------------------------------
Eval num_timesteps=149500, episode_reward=-0.01 +/- 0.29
Episode length: 22.02 +/- 16.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22       |
|    mean_reward      | -0.00706 |
| rollout/            |          |
|    exploration_rate | 0.79     |
| time/               |          |
|    total_timesteps  | 149500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 27374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00983  |
|    exploration_rate | 0.79     |
| time/               |          |
|    episodes         | 8232     |
|    fps              | 121      |
|    time_elapsed     | 1230     |
|    total_timesteps  | 149523   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 27380    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0204   |
|    exploration_rate | 0.79     |
| time/               |          |
|    episodes         | 8236     |
|    fps              | 121      |
|    time_elapsed     | 1230     |
|    total_timesteps  | 149585   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 27396    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 0.79     |
| time/               |          |
|    episodes         | 8240     |
|    fps              | 121      |
|    time_elapsed     | 1230     |
|    total_timesteps  | 149652   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00674  |
|    n_updates        | 27412    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0203   |
|    exploration_rate | 0.79     |
| time/               |          |
|    episodes         | 8244     |
|    fps              | 121      |
|    time_elapsed     | 1230     |
|    total_timesteps  | 149730   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00078  |
|    n_updates        | 27432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.021    |
|    exploration_rate | 0.789    |
| time/               |          |
|    episodes         | 8248     |
|    fps              | 121      |
|    time_elapsed     | 1230     |
|    total_timesteps  | 149801   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 27450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0213   |
|    exploration_rate | 0.789    |
| time/               |          |
|    episodes         | 8252     |
|    fps              | 121      |
|    time_elapsed     | 1230     |
|    total_timesteps  | 149874   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0018   |
|    n_updates        | 27468    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.789    |
| time/               |          |
|    episodes         | 8256     |
|    fps              | 121      |
|    time_elapsed     | 1230     |
|    total_timesteps  | 149948   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000849 |
|    n_updates        | 27486    |
----------------------------------
Eval num_timesteps=150000, episode_reward=-0.11 +/- 0.08
Episode length: 26.86 +/- 21.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 26.9     |
|    mean_reward      | -0.107   |
| rollout/            |          |
|    exploration_rate | 0.789    |
| time/               |          |
|    total_timesteps  | 150000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 27499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 0.789    |
| time/               |          |
|    episodes         | 8260     |
|    fps              | 121      |
|    time_elapsed     | 1232     |
|    total_timesteps  | 150026   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000847 |
|    n_updates        | 27506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 0.789    |
| time/               |          |
|    episodes         | 8264     |
|    fps              | 121      |
|    time_elapsed     | 1232     |
|    total_timesteps  | 150105   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000541 |
|    n_updates        | 27526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0112   |
|    exploration_rate | 0.788    |
| time/               |          |
|    episodes         | 8268     |
|    fps              | 121      |
|    time_elapsed     | 1232     |
|    total_timesteps  | 150166   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 27541    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00108  |
|    exploration_rate | 0.788    |
| time/               |          |
|    episodes         | 8272     |
|    fps              | 121      |
|    time_elapsed     | 1232     |
|    total_timesteps  | 150239   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0079   |
|    n_updates        | 27559    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 0.788    |
| time/               |          |
|    episodes         | 8276     |
|    fps              | 121      |
|    time_elapsed     | 1232     |
|    total_timesteps  | 150308   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000963 |
|    n_updates        | 27576    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0296  |
|    exploration_rate | 0.788    |
| time/               |          |
|    episodes         | 8280     |
|    fps              | 121      |
|    time_elapsed     | 1232     |
|    total_timesteps  | 150378   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 27594    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.788    |
| time/               |          |
|    episodes         | 8284     |
|    fps              | 122      |
|    time_elapsed     | 1233     |
|    total_timesteps  | 150446   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 27611    |
----------------------------------
Eval num_timesteps=150500, episode_reward=-0.04 +/- 0.21
Episode length: 20.36 +/- 16.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20.4     |
|    mean_reward      | -0.0405  |
| rollout/            |          |
|    exploration_rate | 0.787    |
| time/               |          |
|    total_timesteps  | 150500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000408 |
|    n_updates        | 27624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.787    |
| time/               |          |
|    episodes         | 8288     |
|    fps              | 121      |
|    time_elapsed     | 1234     |
|    total_timesteps  | 150514   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 27628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0193  |
|    exploration_rate | 0.787    |
| time/               |          |
|    episodes         | 8292     |
|    fps              | 121      |
|    time_elapsed     | 1234     |
|    total_timesteps  | 150576   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000561 |
|    n_updates        | 27643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0194  |
|    exploration_rate | 0.787    |
| time/               |          |
|    episodes         | 8296     |
|    fps              | 122      |
|    time_elapsed     | 1234     |
|    total_timesteps  | 150639   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00608  |
|    n_updates        | 27659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0296  |
|    exploration_rate | 0.787    |
| time/               |          |
|    episodes         | 8300     |
|    fps              | 122      |
|    time_elapsed     | 1234     |
|    total_timesteps  | 150710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000846 |
|    n_updates        | 27677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0295  |
|    exploration_rate | 0.787    |
| time/               |          |
|    episodes         | 8304     |
|    fps              | 122      |
|    time_elapsed     | 1234     |
|    total_timesteps  | 150772   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000734 |
|    n_updates        | 27692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.786    |
| time/               |          |
|    episodes         | 8308     |
|    fps              | 122      |
|    time_elapsed     | 1234     |
|    total_timesteps  | 150837   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 27709    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00864 |
|    exploration_rate | 0.786    |
| time/               |          |
|    episodes         | 8312     |
|    fps              | 122      |
|    time_elapsed     | 1234     |
|    total_timesteps  | 150895   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00278  |
|    n_updates        | 27723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00808 |
|    exploration_rate | 0.786    |
| time/               |          |
|    episodes         | 8316     |
|    fps              | 122      |
|    time_elapsed     | 1235     |
|    total_timesteps  | 150961   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00384  |
|    n_updates        | 27740    |
----------------------------------
Eval num_timesteps=151000, episode_reward=-0.05 +/- 0.15
Episode length: 17.62 +/- 11.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.6     |
|    mean_reward      | -0.0495  |
| rollout/            |          |
|    exploration_rate | 0.786    |
| time/               |          |
|    total_timesteps  | 151000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000941 |
|    n_updates        | 27749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0082  |
|    exploration_rate | 0.786    |
| time/               |          |
|    episodes         | 8320     |
|    fps              | 122      |
|    time_elapsed     | 1236     |
|    total_timesteps  | 151033   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000992 |
|    n_updates        | 27758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00824 |
|    exploration_rate | 0.786    |
| time/               |          |
|    episodes         | 8324     |
|    fps              | 122      |
|    time_elapsed     | 1236     |
|    total_timesteps  | 151111   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000867 |
|    n_updates        | 27777    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00816 |
|    exploration_rate | 0.785    |
| time/               |          |
|    episodes         | 8328     |
|    fps              | 122      |
|    time_elapsed     | 1236     |
|    total_timesteps  | 151178   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000332 |
|    n_updates        | 27794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.00792 |
|    exploration_rate | 0.785    |
| time/               |          |
|    episodes         | 8332     |
|    fps              | 122      |
|    time_elapsed     | 1236     |
|    total_timesteps  | 151247   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000348 |
|    n_updates        | 27811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.018   |
|    exploration_rate | 0.785    |
| time/               |          |
|    episodes         | 8336     |
|    fps              | 122      |
|    time_elapsed     | 1236     |
|    total_timesteps  | 151312   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 27827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.00783 |
|    exploration_rate | 0.785    |
| time/               |          |
|    episodes         | 8340     |
|    fps              | 122      |
|    time_elapsed     | 1236     |
|    total_timesteps  | 151374   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000622 |
|    n_updates        | 27843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00747 |
|    exploration_rate | 0.785    |
| time/               |          |
|    episodes         | 8344     |
|    fps              | 122      |
|    time_elapsed     | 1236     |
|    total_timesteps  | 151443   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00581  |
|    n_updates        | 27860    |
----------------------------------
Eval num_timesteps=151500, episode_reward=-0.01 +/- 0.25
Episode length: 18.76 +/- 11.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.8     |
|    mean_reward      | -0.0141  |
| rollout/            |          |
|    exploration_rate | 0.785    |
| time/               |          |
|    total_timesteps  | 151500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000909 |
|    n_updates        | 27874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00281  |
|    exploration_rate | 0.784    |
| time/               |          |
|    episodes         | 8348     |
|    fps              | 122      |
|    time_elapsed     | 1238     |
|    total_timesteps  | 151507   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 27876    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00301  |
|    exploration_rate | 0.784    |
| time/               |          |
|    episodes         | 8352     |
|    fps              | 122      |
|    time_elapsed     | 1238     |
|    total_timesteps  | 151575   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000747 |
|    n_updates        | 27893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00289  |
|    exploration_rate | 0.784    |
| time/               |          |
|    episodes         | 8356     |
|    fps              | 122      |
|    time_elapsed     | 1238     |
|    total_timesteps  | 151652   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000429 |
|    n_updates        | 27912    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00309  |
|    exploration_rate | 0.784    |
| time/               |          |
|    episodes         | 8360     |
|    fps              | 122      |
|    time_elapsed     | 1238     |
|    total_timesteps  | 151725   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000948 |
|    n_updates        | 27931    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00341  |
|    exploration_rate | 0.784    |
| time/               |          |
|    episodes         | 8364     |
|    fps              | 122      |
|    time_elapsed     | 1238     |
|    total_timesteps  | 151796   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000709 |
|    n_updates        | 27948    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0128   |
|    exploration_rate | 0.783    |
| time/               |          |
|    episodes         | 8368     |
|    fps              | 122      |
|    time_elapsed     | 1238     |
|    total_timesteps  | 151874   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000719 |
|    n_updates        | 27968    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0132   |
|    exploration_rate | 0.783    |
| time/               |          |
|    episodes         | 8372     |
|    fps              | 122      |
|    time_elapsed     | 1238     |
|    total_timesteps  | 151937   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000984 |
|    n_updates        | 27984    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0235   |
|    exploration_rate | 0.783    |
| time/               |          |
|    episodes         | 8376     |
|    fps              | 122      |
|    time_elapsed     | 1238     |
|    total_timesteps  | 151997   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00782  |
|    n_updates        | 27999    |
----------------------------------
Eval num_timesteps=152000, episode_reward=-0.03 +/- 0.21
Episode length: 17.64 +/- 11.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.6     |
|    mean_reward      | -0.0296  |
| rollout/            |          |
|    exploration_rate | 0.783    |
| time/               |          |
|    total_timesteps  | 152000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0229   |
|    exploration_rate | 0.783    |
| time/               |          |
|    episodes         | 8380     |
|    fps              | 122      |
|    time_elapsed     | 1239     |
|    total_timesteps  | 152083   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000797 |
|    n_updates        | 28020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0225   |
|    exploration_rate | 0.783    |
| time/               |          |
|    episodes         | 8384     |
|    fps              | 122      |
|    time_elapsed     | 1239     |
|    total_timesteps  | 152161   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000746 |
|    n_updates        | 28040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0225   |
|    exploration_rate | 0.782    |
| time/               |          |
|    episodes         | 8388     |
|    fps              | 122      |
|    time_elapsed     | 1240     |
|    total_timesteps  | 152229   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0126   |
|    n_updates        | 28057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0223   |
|    exploration_rate | 0.782    |
| time/               |          |
|    episodes         | 8392     |
|    fps              | 122      |
|    time_elapsed     | 1240     |
|    total_timesteps  | 152296   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000575 |
|    n_updates        | 28073    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0118   |
|    exploration_rate | 0.782    |
| time/               |          |
|    episodes         | 8396     |
|    fps              | 122      |
|    time_elapsed     | 1240     |
|    total_timesteps  | 152370   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00733  |
|    n_updates        | 28092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0118   |
|    exploration_rate | 0.782    |
| time/               |          |
|    episodes         | 8400     |
|    fps              | 122      |
|    time_elapsed     | 1240     |
|    total_timesteps  | 152442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00573  |
|    n_updates        | 28110    |
----------------------------------
Eval num_timesteps=152500, episode_reward=-0.07 +/- 0.16
Episode length: 22.96 +/- 13.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 23       |
|    mean_reward      | -0.0708  |
| rollout/            |          |
|    exploration_rate | 0.782    |
| time/               |          |
|    total_timesteps  | 152500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000564 |
|    n_updates        | 28124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0111   |
|    exploration_rate | 0.782    |
| time/               |          |
|    episodes         | 8404     |
|    fps              | 122      |
|    time_elapsed     | 1242     |
|    total_timesteps  | 152520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00658  |
|    n_updates        | 28129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00039  |
|    exploration_rate | 0.781    |
| time/               |          |
|    episodes         | 8408     |
|    fps              | 122      |
|    time_elapsed     | 1242     |
|    total_timesteps  | 152603   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000554 |
|    n_updates        | 28150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 0.781    |
| time/               |          |
|    episodes         | 8412     |
|    fps              | 122      |
|    time_elapsed     | 1242     |
|    total_timesteps  | 152673   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 28168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.781    |
| time/               |          |
|    episodes         | 8416     |
|    fps              | 122      |
|    time_elapsed     | 1242     |
|    total_timesteps  | 152747   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000855 |
|    n_updates        | 28186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00015 |
|    exploration_rate | 0.781    |
| time/               |          |
|    episodes         | 8420     |
|    fps              | 122      |
|    time_elapsed     | 1242     |
|    total_timesteps  | 152812   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 28202    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 9e-05    |
|    exploration_rate | 0.78     |
| time/               |          |
|    episodes         | 8424     |
|    fps              | 123      |
|    time_elapsed     | 1242     |
|    total_timesteps  | 152884   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000716 |
|    n_updates        | 28220    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00019 |
|    exploration_rate | 0.78     |
| time/               |          |
|    episodes         | 8428     |
|    fps              | 123      |
|    time_elapsed     | 1242     |
|    total_timesteps  | 152958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 28239    |
----------------------------------
Eval num_timesteps=153000, episode_reward=-0.04 +/- 0.14
Episode length: 15.94 +/- 0.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.0428  |
| rollout/            |          |
|    exploration_rate | 0.78     |
| time/               |          |
|    total_timesteps  | 153000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 28249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00011 |
|    exploration_rate | 0.78     |
| time/               |          |
|    episodes         | 8432     |
|    fps              | 123      |
|    time_elapsed     | 1243     |
|    total_timesteps  | 153025   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 28256    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00973  |
|    exploration_rate | 0.78     |
| time/               |          |
|    episodes         | 8436     |
|    fps              | 123      |
|    time_elapsed     | 1243     |
|    total_timesteps  | 153094   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 28273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00031 |
|    exploration_rate | 0.78     |
| time/               |          |
|    episodes         | 8440     |
|    fps              | 123      |
|    time_elapsed     | 1243     |
|    total_timesteps  | 153157   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00068  |
|    n_updates        | 28289    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00019 |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 8444     |
|    fps              | 123      |
|    time_elapsed     | 1244     |
|    total_timesteps  | 153223   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00491  |
|    n_updates        | 28305    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 8448     |
|    fps              | 123      |
|    time_elapsed     | 1244     |
|    total_timesteps  | 153287   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000802 |
|    n_updates        | 28321    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00017  |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 8452     |
|    fps              | 123      |
|    time_elapsed     | 1244     |
|    total_timesteps  | 153346   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000965 |
|    n_updates        | 28336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00025  |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 8456     |
|    fps              | 123      |
|    time_elapsed     | 1244     |
|    total_timesteps  | 153421   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000503 |
|    n_updates        | 28355    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 8460     |
|    fps              | 123      |
|    time_elapsed     | 1244     |
|    total_timesteps  | 153493   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 28373    |
----------------------------------
Eval num_timesteps=153500, episode_reward=-0.00 +/- 0.24
Episode length: 16.04 +/- 1.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.00306 |
| rollout/            |          |
|    exploration_rate | 0.779    |
| time/               |          |
|    total_timesteps  | 153500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 28374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 8464     |
|    fps              | 123      |
|    time_elapsed     | 1245     |
|    total_timesteps  | 153558   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 28389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00103  |
|    exploration_rate | 0.778    |
| time/               |          |
|    episodes         | 8468     |
|    fps              | 123      |
|    time_elapsed     | 1245     |
|    total_timesteps  | 153623   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000865 |
|    n_updates        | 28405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 0.778    |
| time/               |          |
|    episodes         | 8472     |
|    fps              | 123      |
|    time_elapsed     | 1245     |
|    total_timesteps  | 153692   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000924 |
|    n_updates        | 28422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0302   |
|    exploration_rate | 0.778    |
| time/               |          |
|    episodes         | 8476     |
|    fps              | 123      |
|    time_elapsed     | 1245     |
|    total_timesteps  | 153767   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 28441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 0.778    |
| time/               |          |
|    episodes         | 8480     |
|    fps              | 123      |
|    time_elapsed     | 1245     |
|    total_timesteps  | 153846   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 28461    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0311   |
|    exploration_rate | 0.777    |
| time/               |          |
|    episodes         | 8484     |
|    fps              | 123      |
|    time_elapsed     | 1246     |
|    total_timesteps  | 153909   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000846 |
|    n_updates        | 28477    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0313   |
|    exploration_rate | 0.777    |
| time/               |          |
|    episodes         | 8488     |
|    fps              | 123      |
|    time_elapsed     | 1246     |
|    total_timesteps  | 153971   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000981 |
|    n_updates        | 28492    |
----------------------------------
Eval num_timesteps=154000, episode_reward=-0.19 +/- 0.10
Episode length: 47.56 +/- 25.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.6     |
|    mean_reward      | -0.19    |
| rollout/            |          |
|    exploration_rate | 0.777    |
| time/               |          |
|    total_timesteps  | 154000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 28499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0405   |
|    exploration_rate | 0.777    |
| time/               |          |
|    episodes         | 8492     |
|    fps              | 123      |
|    time_elapsed     | 1249     |
|    total_timesteps  | 154058   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 28514    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0309   |
|    exploration_rate | 0.777    |
| time/               |          |
|    episodes         | 8496     |
|    fps              | 123      |
|    time_elapsed     | 1249     |
|    total_timesteps  | 154123   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 28530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 0.777    |
| time/               |          |
|    episodes         | 8500     |
|    fps              | 123      |
|    time_elapsed     | 1249     |
|    total_timesteps  | 154207   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00369  |
|    n_updates        | 28551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0303   |
|    exploration_rate | 0.776    |
| time/               |          |
|    episodes         | 8504     |
|    fps              | 123      |
|    time_elapsed     | 1249     |
|    total_timesteps  | 154287   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000551 |
|    n_updates        | 28571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.041    |
|    exploration_rate | 0.776    |
| time/               |          |
|    episodes         | 8508     |
|    fps              | 123      |
|    time_elapsed     | 1249     |
|    total_timesteps  | 154353   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000827 |
|    n_updates        | 28588    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0406   |
|    exploration_rate | 0.776    |
| time/               |          |
|    episodes         | 8512     |
|    fps              | 123      |
|    time_elapsed     | 1249     |
|    total_timesteps  | 154433   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000527 |
|    n_updates        | 28608    |
----------------------------------
Eval num_timesteps=154500, episode_reward=0.02 +/- 0.27
Episode length: 15.24 +/- 1.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | 0.0201   |
| rollout/            |          |
|    exploration_rate | 0.776    |
| time/               |          |
|    total_timesteps  | 154500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 28624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0408   |
|    exploration_rate | 0.776    |
| time/               |          |
|    episodes         | 8516     |
|    fps              | 123      |
|    time_elapsed     | 1250     |
|    total_timesteps  | 154501   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000635 |
|    n_updates        | 28625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0307   |
|    exploration_rate | 0.776    |
| time/               |          |
|    episodes         | 8520     |
|    fps              | 123      |
|    time_elapsed     | 1250     |
|    total_timesteps  | 154570   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00713  |
|    n_updates        | 28642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0307   |
|    exploration_rate | 0.775    |
| time/               |          |
|    episodes         | 8524     |
|    fps              | 123      |
|    time_elapsed     | 1251     |
|    total_timesteps  | 154641   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0164   |
|    n_updates        | 28660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 0.775    |
| time/               |          |
|    episodes         | 8528     |
|    fps              | 123      |
|    time_elapsed     | 1251     |
|    total_timesteps  | 154724   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00468  |
|    n_updates        | 28680    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0298   |
|    exploration_rate | 0.775    |
| time/               |          |
|    episodes         | 8532     |
|    fps              | 123      |
|    time_elapsed     | 1251     |
|    total_timesteps  | 154805   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000558 |
|    n_updates        | 28701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 0.775    |
| time/               |          |
|    episodes         | 8536     |
|    fps              | 123      |
|    time_elapsed     | 1251     |
|    total_timesteps  | 154868   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00499  |
|    n_updates        | 28716    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 0.774    |
| time/               |          |
|    episodes         | 8540     |
|    fps              | 123      |
|    time_elapsed     | 1251     |
|    total_timesteps  | 154947   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000816 |
|    n_updates        | 28736    |
----------------------------------
Eval num_timesteps=155000, episode_reward=0.02 +/- 0.27
Episode length: 15.10 +/- 0.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | 0.0207   |
| rollout/            |          |
|    exploration_rate | 0.774    |
| time/               |          |
|    total_timesteps  | 155000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0112   |
|    n_updates        | 28749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.774    |
| time/               |          |
|    episodes         | 8544     |
|    fps              | 123      |
|    time_elapsed     | 1252     |
|    total_timesteps  | 155023   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 28755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.774    |
| time/               |          |
|    episodes         | 8548     |
|    fps              | 123      |
|    time_elapsed     | 1252     |
|    total_timesteps  | 155096   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00735  |
|    n_updates        | 28773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00817  |
|    exploration_rate | 0.774    |
| time/               |          |
|    episodes         | 8552     |
|    fps              | 123      |
|    time_elapsed     | 1252     |
|    total_timesteps  | 155167   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000739 |
|    n_updates        | 28791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00869  |
|    exploration_rate | 0.774    |
| time/               |          |
|    episodes         | 8556     |
|    fps              | 123      |
|    time_elapsed     | 1252     |
|    total_timesteps  | 155229   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00348  |
|    n_updates        | 28807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00111 |
|    exploration_rate | 0.773    |
| time/               |          |
|    episodes         | 8560     |
|    fps              | 123      |
|    time_elapsed     | 1252     |
|    total_timesteps  | 155296   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000744 |
|    n_updates        | 28823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00907  |
|    exploration_rate | 0.773    |
| time/               |          |
|    episodes         | 8564     |
|    fps              | 123      |
|    time_elapsed     | 1253     |
|    total_timesteps  | 155357   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000848 |
|    n_updates        | 28839    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00831  |
|    exploration_rate | 0.773    |
| time/               |          |
|    episodes         | 8568     |
|    fps              | 124      |
|    time_elapsed     | 1253     |
|    total_timesteps  | 155441   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 28860    |
----------------------------------
Eval num_timesteps=155500, episode_reward=0.02 +/- 0.28
Episode length: 15.16 +/- 1.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | 0.0204   |
| rollout/            |          |
|    exploration_rate | 0.773    |
| time/               |          |
|    total_timesteps  | 155500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000524 |
|    n_updates        | 28874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00207 |
|    exploration_rate | 0.773    |
| time/               |          |
|    episodes         | 8572     |
|    fps              | 123      |
|    time_elapsed     | 1254     |
|    total_timesteps  | 155520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00546  |
|    n_updates        | 28879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.773    |
| time/               |          |
|    episodes         | 8576     |
|    fps              | 124      |
|    time_elapsed     | 1254     |
|    total_timesteps  | 155595   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000891 |
|    n_updates        | 28898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.772    |
| time/               |          |
|    episodes         | 8580     |
|    fps              | 124      |
|    time_elapsed     | 1254     |
|    total_timesteps  | 155664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 28915    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.772    |
| time/               |          |
|    episodes         | 8584     |
|    fps              | 124      |
|    time_elapsed     | 1254     |
|    total_timesteps  | 155734   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 28933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0322  |
|    exploration_rate | 0.772    |
| time/               |          |
|    episodes         | 8588     |
|    fps              | 124      |
|    time_elapsed     | 1254     |
|    total_timesteps  | 155803   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000583 |
|    n_updates        | 28950    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0313  |
|    exploration_rate | 0.772    |
| time/               |          |
|    episodes         | 8592     |
|    fps              | 124      |
|    time_elapsed     | 1254     |
|    total_timesteps  | 155866   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000734 |
|    n_updates        | 28966    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 0.772    |
| time/               |          |
|    episodes         | 8596     |
|    fps              | 124      |
|    time_elapsed     | 1254     |
|    total_timesteps  | 155928   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 28981    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0106  |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 8600     |
|    fps              | 124      |
|    time_elapsed     | 1255     |
|    total_timesteps  | 155998   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00518  |
|    n_updates        | 28999    |
----------------------------------
Eval num_timesteps=156000, episode_reward=-0.00 +/- 0.36
Episode length: 41.26 +/- 20.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.3     |
|    mean_reward      | -0.00402 |
| rollout/            |          |
|    exploration_rate | 0.771    |
| time/               |          |
|    total_timesteps  | 156000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0105  |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 8604     |
|    fps              | 124      |
|    time_elapsed     | 1257     |
|    total_timesteps  | 156077   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00247  |
|    n_updates        | 29019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 8608     |
|    fps              | 124      |
|    time_elapsed     | 1258     |
|    total_timesteps  | 156137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000909 |
|    n_updates        | 29034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00979 |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 8612     |
|    fps              | 124      |
|    time_elapsed     | 1258     |
|    total_timesteps  | 156204   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000595 |
|    n_updates        | 29050    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00967 |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 8616     |
|    fps              | 124      |
|    time_elapsed     | 1258     |
|    total_timesteps  | 156269   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000902 |
|    n_updates        | 29067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00051  |
|    exploration_rate | 0.77     |
| time/               |          |
|    episodes         | 8620     |
|    fps              | 124      |
|    time_elapsed     | 1258     |
|    total_timesteps  | 156334   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 29083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00079  |
|    exploration_rate | 0.77     |
| time/               |          |
|    episodes         | 8624     |
|    fps              | 124      |
|    time_elapsed     | 1258     |
|    total_timesteps  | 156398   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000675 |
|    n_updates        | 29099    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00143  |
|    exploration_rate | 0.77     |
| time/               |          |
|    episodes         | 8628     |
|    fps              | 124      |
|    time_elapsed     | 1258     |
|    total_timesteps  | 156465   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 29116    |
----------------------------------
Eval num_timesteps=156500, episode_reward=-0.04 +/- 0.14
Episode length: 16.06 +/- 2.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0432  |
| rollout/            |          |
|    exploration_rate | 0.77     |
| time/               |          |
|    total_timesteps  | 156500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000681 |
|    n_updates        | 29124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00191  |
|    exploration_rate | 0.77     |
| time/               |          |
|    episodes         | 8632     |
|    fps              | 124      |
|    time_elapsed     | 1259     |
|    total_timesteps  | 156534   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000875 |
|    n_updates        | 29133    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0121   |
|    exploration_rate | 0.77     |
| time/               |          |
|    episodes         | 8636     |
|    fps              | 124      |
|    time_elapsed     | 1259     |
|    total_timesteps  | 156594   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000518 |
|    n_updates        | 29148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0221   |
|    exploration_rate | 0.769    |
| time/               |          |
|    episodes         | 8640     |
|    fps              | 124      |
|    time_elapsed     | 1259     |
|    total_timesteps  | 156672   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00532  |
|    n_updates        | 29167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0222   |
|    exploration_rate | 0.769    |
| time/               |          |
|    episodes         | 8644     |
|    fps              | 124      |
|    time_elapsed     | 1260     |
|    total_timesteps  | 156745   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000948 |
|    n_updates        | 29186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0224   |
|    exploration_rate | 0.769    |
| time/               |          |
|    episodes         | 8648     |
|    fps              | 124      |
|    time_elapsed     | 1260     |
|    total_timesteps  | 156814   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 29203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0218   |
|    exploration_rate | 0.769    |
| time/               |          |
|    episodes         | 8652     |
|    fps              | 124      |
|    time_elapsed     | 1260     |
|    total_timesteps  | 156899   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000673 |
|    n_updates        | 29224    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0214   |
|    exploration_rate | 0.768    |
| time/               |          |
|    episodes         | 8656     |
|    fps              | 124      |
|    time_elapsed     | 1260     |
|    total_timesteps  | 156972   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000816 |
|    n_updates        | 29242    |
----------------------------------
Eval num_timesteps=157000, episode_reward=0.00 +/- 0.24
Episode length: 14.96 +/- 0.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | 0.00114  |
| rollout/            |          |
|    exploration_rate | 0.768    |
| time/               |          |
|    total_timesteps  | 157000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 29249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0213   |
|    exploration_rate | 0.768    |
| time/               |          |
|    episodes         | 8660     |
|    fps              | 124      |
|    time_elapsed     | 1261     |
|    total_timesteps  | 157041   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000945 |
|    n_updates        | 29260    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0111   |
|    exploration_rate | 0.768    |
| time/               |          |
|    episodes         | 8664     |
|    fps              | 124      |
|    time_elapsed     | 1261     |
|    total_timesteps  | 157108   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000504 |
|    n_updates        | 29276    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0116   |
|    exploration_rate | 0.768    |
| time/               |          |
|    episodes         | 8668     |
|    fps              | 124      |
|    time_elapsed     | 1261     |
|    total_timesteps  | 157178   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 29294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00183  |
|    exploration_rate | 0.768    |
| time/               |          |
|    episodes         | 8672     |
|    fps              | 124      |
|    time_elapsed     | 1261     |
|    total_timesteps  | 157251   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000613 |
|    n_updates        | 29312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00239  |
|    exploration_rate | 0.767    |
| time/               |          |
|    episodes         | 8676     |
|    fps              | 124      |
|    time_elapsed     | 1261     |
|    total_timesteps  | 157312   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00498  |
|    n_updates        | 29327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0127   |
|    exploration_rate | 0.767    |
| time/               |          |
|    episodes         | 8680     |
|    fps              | 124      |
|    time_elapsed     | 1261     |
|    total_timesteps  | 157373   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00322  |
|    n_updates        | 29343    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0128   |
|    exploration_rate | 0.767    |
| time/               |          |
|    episodes         | 8684     |
|    fps              | 124      |
|    time_elapsed     | 1261     |
|    total_timesteps  | 157441   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000873 |
|    n_updates        | 29360    |
----------------------------------
Eval num_timesteps=157500, episode_reward=0.06 +/- 0.33
Episode length: 16.38 +/- 8.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | 0.0555   |
| rollout/            |          |
|    exploration_rate | 0.767    |
| time/               |          |
|    total_timesteps  | 157500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000759 |
|    n_updates        | 29374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0127   |
|    exploration_rate | 0.767    |
| time/               |          |
|    episodes         | 8688     |
|    fps              | 124      |
|    time_elapsed     | 1263     |
|    total_timesteps  | 157514   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 29378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0126   |
|    exploration_rate | 0.767    |
| time/               |          |
|    episodes         | 8692     |
|    fps              | 124      |
|    time_elapsed     | 1263     |
|    total_timesteps  | 157577   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 29394    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00252  |
|    exploration_rate | 0.766    |
| time/               |          |
|    episodes         | 8696     |
|    fps              | 124      |
|    time_elapsed     | 1263     |
|    total_timesteps  | 157642   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 29410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00739 |
|    exploration_rate | 0.766    |
| time/               |          |
|    episodes         | 8700     |
|    fps              | 124      |
|    time_elapsed     | 1263     |
|    total_timesteps  | 157710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 29427    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00252  |
|    exploration_rate | 0.766    |
| time/               |          |
|    episodes         | 8704     |
|    fps              | 124      |
|    time_elapsed     | 1263     |
|    total_timesteps  | 157791   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00523  |
|    n_updates        | 29447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00197  |
|    exploration_rate | 0.766    |
| time/               |          |
|    episodes         | 8708     |
|    fps              | 124      |
|    time_elapsed     | 1263     |
|    total_timesteps  | 157865   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000634 |
|    n_updates        | 29466    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00205  |
|    exploration_rate | 0.766    |
| time/               |          |
|    episodes         | 8712     |
|    fps              | 124      |
|    time_elapsed     | 1263     |
|    total_timesteps  | 157930   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 29482    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0121   |
|    exploration_rate | 0.765    |
| time/               |          |
|    episodes         | 8716     |
|    fps              | 125      |
|    time_elapsed     | 1263     |
|    total_timesteps  | 157995   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00691  |
|    n_updates        | 29498    |
----------------------------------
Eval num_timesteps=158000, episode_reward=-0.02 +/- 0.20
Episode length: 15.62 +/- 2.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.6     |
|    mean_reward      | -0.0214  |
| rollout/            |          |
|    exploration_rate | 0.765    |
| time/               |          |
|    total_timesteps  | 158000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 29499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.012    |
|    exploration_rate | 0.765    |
| time/               |          |
|    episodes         | 8720     |
|    fps              | 124      |
|    time_elapsed     | 1264     |
|    total_timesteps  | 158061   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 29515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 0.765    |
| time/               |          |
|    episodes         | 8724     |
|    fps              | 124      |
|    time_elapsed     | 1265     |
|    total_timesteps  | 158133   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000551 |
|    n_updates        | 29533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0114   |
|    exploration_rate | 0.765    |
| time/               |          |
|    episodes         | 8728     |
|    fps              | 125      |
|    time_elapsed     | 1265     |
|    total_timesteps  | 158208   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00486  |
|    n_updates        | 29551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0112   |
|    exploration_rate | 0.765    |
| time/               |          |
|    episodes         | 8732     |
|    fps              | 125      |
|    time_elapsed     | 1265     |
|    total_timesteps  | 158281   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 29570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00076  |
|    exploration_rate | 0.764    |
| time/               |          |
|    episodes         | 8736     |
|    fps              | 125      |
|    time_elapsed     | 1265     |
|    total_timesteps  | 158352   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000871 |
|    n_updates        | 29587    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0091  |
|    exploration_rate | 0.764    |
| time/               |          |
|    episodes         | 8740     |
|    fps              | 125      |
|    time_elapsed     | 1265     |
|    total_timesteps  | 158426   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000808 |
|    n_updates        | 29606    |
----------------------------------
Eval num_timesteps=158500, episode_reward=0.06 +/- 0.33
Episode length: 15.30 +/- 2.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | 0.0598   |
| rollout/            |          |
|    exploration_rate | 0.764    |
| time/               |          |
|    total_timesteps  | 158500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000554 |
|    n_updates        | 29624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00958 |
|    exploration_rate | 0.764    |
| time/               |          |
|    episodes         | 8744     |
|    fps              | 125      |
|    time_elapsed     | 1266     |
|    total_timesteps  | 158511   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000587 |
|    n_updates        | 29627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00064  |
|    exploration_rate | 0.764    |
| time/               |          |
|    episodes         | 8748     |
|    fps              | 125      |
|    time_elapsed     | 1266     |
|    total_timesteps  | 158575   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00739  |
|    n_updates        | 29643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0113   |
|    exploration_rate | 0.763    |
| time/               |          |
|    episodes         | 8752     |
|    fps              | 125      |
|    time_elapsed     | 1266     |
|    total_timesteps  | 158643   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00627  |
|    n_updates        | 29660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.011    |
|    exploration_rate | 0.763    |
| time/               |          |
|    episodes         | 8756     |
|    fps              | 125      |
|    time_elapsed     | 1267     |
|    total_timesteps  | 158724   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00564  |
|    n_updates        | 29680    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0111   |
|    exploration_rate | 0.763    |
| time/               |          |
|    episodes         | 8760     |
|    fps              | 125      |
|    time_elapsed     | 1267     |
|    total_timesteps  | 158791   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000757 |
|    n_updates        | 29697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0108   |
|    exploration_rate | 0.763    |
| time/               |          |
|    episodes         | 8764     |
|    fps              | 125      |
|    time_elapsed     | 1267     |
|    total_timesteps  | 158866   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000841 |
|    n_updates        | 29716    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00994  |
|    exploration_rate | 0.763    |
| time/               |          |
|    episodes         | 8768     |
|    fps              | 125      |
|    time_elapsed     | 1267     |
|    total_timesteps  | 158957   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000929 |
|    n_updates        | 29739    |
----------------------------------
Eval num_timesteps=159000, episode_reward=-0.06 +/- 0.00
Episode length: 15.32 +/- 1.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | -0.0603  |
| rollout/            |          |
|    exploration_rate | 0.762    |
| time/               |          |
|    total_timesteps  | 159000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00717  |
|    n_updates        | 29749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0099   |
|    exploration_rate | 0.762    |
| time/               |          |
|    episodes         | 8772     |
|    fps              | 125      |
|    time_elapsed     | 1268     |
|    total_timesteps  | 159031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000517 |
|    n_updates        | 29757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00978  |
|    exploration_rate | 0.762    |
| time/               |          |
|    episodes         | 8776     |
|    fps              | 125      |
|    time_elapsed     | 1268     |
|    total_timesteps  | 159095   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 29773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00064 |
|    exploration_rate | 0.762    |
| time/               |          |
|    episodes         | 8780     |
|    fps              | 125      |
|    time_elapsed     | 1268     |
|    total_timesteps  | 159166   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00731  |
|    n_updates        | 29791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00052 |
|    exploration_rate | 0.762    |
| time/               |          |
|    episodes         | 8784     |
|    fps              | 125      |
|    time_elapsed     | 1268     |
|    total_timesteps  | 159231   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000908 |
|    n_updates        | 29807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00068 |
|    exploration_rate | 0.761    |
| time/               |          |
|    episodes         | 8788     |
|    fps              | 125      |
|    time_elapsed     | 1268     |
|    total_timesteps  | 159308   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00586  |
|    n_updates        | 29826    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.761    |
| time/               |          |
|    episodes         | 8792     |
|    fps              | 125      |
|    time_elapsed     | 1268     |
|    total_timesteps  | 159385   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00064  |
|    n_updates        | 29846    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.011   |
|    exploration_rate | 0.761    |
| time/               |          |
|    episodes         | 8796     |
|    fps              | 125      |
|    time_elapsed     | 1269     |
|    total_timesteps  | 159445   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000702 |
|    n_updates        | 29861    |
----------------------------------
Eval num_timesteps=159500, episode_reward=-0.04 +/- 0.14
Episode length: 15.16 +/- 1.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | -0.0397  |
| rollout/            |          |
|    exploration_rate | 0.761    |
| time/               |          |
|    total_timesteps  | 159500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000705 |
|    n_updates        | 29874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00084 |
|    exploration_rate | 0.761    |
| time/               |          |
|    episodes         | 8800     |
|    fps              | 125      |
|    time_elapsed     | 1270     |
|    total_timesteps  | 159508   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000909 |
|    n_updates        | 29876    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.761    |
| time/               |          |
|    episodes         | 8804     |
|    fps              | 125      |
|    time_elapsed     | 1270     |
|    total_timesteps  | 159579   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000565 |
|    n_updates        | 29894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.76     |
| time/               |          |
|    episodes         | 8808     |
|    fps              | 125      |
|    time_elapsed     | 1270     |
|    total_timesteps  | 159645   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 29911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 0.76     |
| time/               |          |
|    episodes         | 8812     |
|    fps              | 125      |
|    time_elapsed     | 1270     |
|    total_timesteps  | 159712   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00524  |
|    n_updates        | 29927    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 0.76     |
| time/               |          |
|    episodes         | 8816     |
|    fps              | 125      |
|    time_elapsed     | 1270     |
|    total_timesteps  | 159784   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 29945    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0305  |
|    exploration_rate | 0.76     |
| time/               |          |
|    episodes         | 8820     |
|    fps              | 125      |
|    time_elapsed     | 1270     |
|    total_timesteps  | 159850   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000469 |
|    n_updates        | 29962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0302  |
|    exploration_rate | 0.76     |
| time/               |          |
|    episodes         | 8824     |
|    fps              | 125      |
|    time_elapsed     | 1270     |
|    total_timesteps  | 159914   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000381 |
|    n_updates        | 29978    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.759    |
| time/               |          |
|    episodes         | 8828     |
|    fps              | 125      |
|    time_elapsed     | 1270     |
|    total_timesteps  | 159979   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000684 |
|    n_updates        | 29994    |
----------------------------------
Eval num_timesteps=160000, episode_reward=-0.04 +/- 0.14
Episode length: 15.00 +/- 0.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.039   |
| rollout/            |          |
|    exploration_rate | 0.759    |
| time/               |          |
|    total_timesteps  | 160000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000811 |
|    n_updates        | 29999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0296  |
|    exploration_rate | 0.759    |
| time/               |          |
|    episodes         | 8832     |
|    fps              | 125      |
|    time_elapsed     | 1272     |
|    total_timesteps  | 160048   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 30011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0296  |
|    exploration_rate | 0.759    |
| time/               |          |
|    episodes         | 8836     |
|    fps              | 125      |
|    time_elapsed     | 1272     |
|    total_timesteps  | 160119   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 30029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0294  |
|    exploration_rate | 0.759    |
| time/               |          |
|    episodes         | 8840     |
|    fps              | 125      |
|    time_elapsed     | 1272     |
|    total_timesteps  | 160187   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 30046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0291  |
|    exploration_rate | 0.759    |
| time/               |          |
|    episodes         | 8844     |
|    fps              | 125      |
|    time_elapsed     | 1272     |
|    total_timesteps  | 160265   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 30066    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0289  |
|    exploration_rate | 0.758    |
| time/               |          |
|    episodes         | 8848     |
|    fps              | 125      |
|    time_elapsed     | 1272     |
|    total_timesteps  | 160323   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0018   |
|    n_updates        | 30080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0389  |
|    exploration_rate | 0.758    |
| time/               |          |
|    episodes         | 8852     |
|    fps              | 126      |
|    time_elapsed     | 1272     |
|    total_timesteps  | 160391   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 30097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0386  |
|    exploration_rate | 0.758    |
| time/               |          |
|    episodes         | 8856     |
|    fps              | 126      |
|    time_elapsed     | 1272     |
|    total_timesteps  | 160464   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 30115    |
----------------------------------
Eval num_timesteps=160500, episode_reward=0.02 +/- 0.28
Episode length: 14.74 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0221   |
| rollout/            |          |
|    exploration_rate | 0.758    |
| time/               |          |
|    total_timesteps  | 160500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00244  |
|    n_updates        | 30124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0385  |
|    exploration_rate | 0.758    |
| time/               |          |
|    episodes         | 8860     |
|    fps              | 126      |
|    time_elapsed     | 1273     |
|    total_timesteps  | 160529   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 30132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0382  |
|    exploration_rate | 0.758    |
| time/               |          |
|    episodes         | 8864     |
|    fps              | 126      |
|    time_elapsed     | 1273     |
|    total_timesteps  | 160597   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0031   |
|    n_updates        | 30149    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0372  |
|    exploration_rate | 0.757    |
| time/               |          |
|    episodes         | 8868     |
|    fps              | 126      |
|    time_elapsed     | 1273     |
|    total_timesteps  | 160663   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 30165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0268  |
|    exploration_rate | 0.757    |
| time/               |          |
|    episodes         | 8872     |
|    fps              | 126      |
|    time_elapsed     | 1274     |
|    total_timesteps  | 160726   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 30181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0268  |
|    exploration_rate | 0.757    |
| time/               |          |
|    episodes         | 8876     |
|    fps              | 126      |
|    time_elapsed     | 1274     |
|    total_timesteps  | 160790   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000745 |
|    n_updates        | 30197    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0269  |
|    exploration_rate | 0.757    |
| time/               |          |
|    episodes         | 8880     |
|    fps              | 126      |
|    time_elapsed     | 1274     |
|    total_timesteps  | 160864   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00598  |
|    n_updates        | 30215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.757    |
| time/               |          |
|    episodes         | 8884     |
|    fps              | 126      |
|    time_elapsed     | 1274     |
|    total_timesteps  | 160931   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000776 |
|    n_updates        | 30232    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0266  |
|    exploration_rate | 0.756    |
| time/               |          |
|    episodes         | 8888     |
|    fps              | 126      |
|    time_elapsed     | 1274     |
|    total_timesteps  | 160997   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00271  |
|    n_updates        | 30249    |
----------------------------------
Eval num_timesteps=161000, episode_reward=0.04 +/- 0.30
Episode length: 14.62 +/- 1.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0425   |
| rollout/            |          |
|    exploration_rate | 0.756    |
| time/               |          |
|    total_timesteps  | 161000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0261  |
|    exploration_rate | 0.756    |
| time/               |          |
|    episodes         | 8892     |
|    fps              | 126      |
|    time_elapsed     | 1275     |
|    total_timesteps  | 161062   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 30265    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0266  |
|    exploration_rate | 0.756    |
| time/               |          |
|    episodes         | 8896     |
|    fps              | 126      |
|    time_elapsed     | 1275     |
|    total_timesteps  | 161136   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00626  |
|    n_updates        | 30283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0367  |
|    exploration_rate | 0.756    |
| time/               |          |
|    episodes         | 8900     |
|    fps              | 126      |
|    time_elapsed     | 1275     |
|    total_timesteps  | 161200   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000909 |
|    n_updates        | 30299    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0163  |
|    exploration_rate | 0.756    |
| time/               |          |
|    episodes         | 8904     |
|    fps              | 126      |
|    time_elapsed     | 1275     |
|    total_timesteps  | 161260   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 30314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0163  |
|    exploration_rate | 0.755    |
| time/               |          |
|    episodes         | 8908     |
|    fps              | 126      |
|    time_elapsed     | 1275     |
|    total_timesteps  | 161326   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 30331    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0167  |
|    exploration_rate | 0.755    |
| time/               |          |
|    episodes         | 8912     |
|    fps              | 126      |
|    time_elapsed     | 1275     |
|    total_timesteps  | 161404   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00334  |
|    n_updates        | 30350    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0265  |
|    exploration_rate | 0.755    |
| time/               |          |
|    episodes         | 8916     |
|    fps              | 126      |
|    time_elapsed     | 1275     |
|    total_timesteps  | 161471   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00224  |
|    n_updates        | 30367    |
----------------------------------
Eval num_timesteps=161500, episode_reward=-0.04 +/- 0.14
Episode length: 14.90 +/- 0.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0386  |
| rollout/            |          |
|    exploration_rate | 0.755    |
| time/               |          |
|    total_timesteps  | 161500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 30374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0266  |
|    exploration_rate | 0.755    |
| time/               |          |
|    episodes         | 8920     |
|    fps              | 126      |
|    time_elapsed     | 1277     |
|    total_timesteps  | 161540   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00333  |
|    n_updates        | 30384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0267  |
|    exploration_rate | 0.755    |
| time/               |          |
|    episodes         | 8924     |
|    fps              | 126      |
|    time_elapsed     | 1277     |
|    total_timesteps  | 161606   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 30401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0267  |
|    exploration_rate | 0.754    |
| time/               |          |
|    episodes         | 8928     |
|    fps              | 126      |
|    time_elapsed     | 1277     |
|    total_timesteps  | 161671   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 30417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.754    |
| time/               |          |
|    episodes         | 8932     |
|    fps              | 126      |
|    time_elapsed     | 1277     |
|    total_timesteps  | 161747   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 30436    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0167  |
|    exploration_rate | 0.754    |
| time/               |          |
|    episodes         | 8936     |
|    fps              | 126      |
|    time_elapsed     | 1277     |
|    total_timesteps  | 161812   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 30452    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00664 |
|    exploration_rate | 0.754    |
| time/               |          |
|    episodes         | 8940     |
|    fps              | 126      |
|    time_elapsed     | 1277     |
|    total_timesteps  | 161878   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 30469    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00608 |
|    exploration_rate | 0.754    |
| time/               |          |
|    episodes         | 8944     |
|    fps              | 126      |
|    time_elapsed     | 1277     |
|    total_timesteps  | 161942   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00266  |
|    n_updates        | 30485    |
----------------------------------
Eval num_timesteps=162000, episode_reward=0.02 +/- 0.27
Episode length: 14.78 +/- 0.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.0219   |
| rollout/            |          |
|    exploration_rate | 0.753    |
| time/               |          |
|    total_timesteps  | 162000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000621 |
|    n_updates        | 30499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.753    |
| time/               |          |
|    episodes         | 8948     |
|    fps              | 126      |
|    time_elapsed     | 1278     |
|    total_timesteps  | 162008   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00048  |
|    n_updates        | 30501    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00612 |
|    exploration_rate | 0.753    |
| time/               |          |
|    episodes         | 8952     |
|    fps              | 126      |
|    time_elapsed     | 1279     |
|    total_timesteps  | 162069   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0134   |
|    n_updates        | 30517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0064  |
|    exploration_rate | 0.753    |
| time/               |          |
|    episodes         | 8956     |
|    fps              | 126      |
|    time_elapsed     | 1279     |
|    total_timesteps  | 162149   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000757 |
|    n_updates        | 30537    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00296  |
|    exploration_rate | 0.753    |
| time/               |          |
|    episodes         | 8960     |
|    fps              | 126      |
|    time_elapsed     | 1279     |
|    total_timesteps  | 162230   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000697 |
|    n_updates        | 30557    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.003    |
|    exploration_rate | 0.752    |
| time/               |          |
|    episodes         | 8964     |
|    fps              | 126      |
|    time_elapsed     | 1279     |
|    total_timesteps  | 162297   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000636 |
|    n_updates        | 30574    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00292  |
|    exploration_rate | 0.752    |
| time/               |          |
|    episodes         | 8968     |
|    fps              | 126      |
|    time_elapsed     | 1279     |
|    total_timesteps  | 162365   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000911 |
|    n_updates        | 30591    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00735 |
|    exploration_rate | 0.752    |
| time/               |          |
|    episodes         | 8972     |
|    fps              | 126      |
|    time_elapsed     | 1279     |
|    total_timesteps  | 162435   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000924 |
|    n_updates        | 30608    |
----------------------------------
Eval num_timesteps=162500, episode_reward=0.04 +/- 0.30
Episode length: 14.66 +/- 1.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0424   |
| rollout/            |          |
|    exploration_rate | 0.752    |
| time/               |          |
|    total_timesteps  | 162500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00777  |
|    n_updates        | 30624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00755 |
|    exploration_rate | 0.752    |
| time/               |          |
|    episodes         | 8976     |
|    fps              | 126      |
|    time_elapsed     | 1280     |
|    total_timesteps  | 162504   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00681  |
|    n_updates        | 30625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00719 |
|    exploration_rate | 0.752    |
| time/               |          |
|    episodes         | 8980     |
|    fps              | 126      |
|    time_elapsed     | 1280     |
|    total_timesteps  | 162569   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000661 |
|    n_updates        | 30642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00751 |
|    exploration_rate | 0.751    |
| time/               |          |
|    episodes         | 8984     |
|    fps              | 126      |
|    time_elapsed     | 1280     |
|    total_timesteps  | 162644   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000875 |
|    n_updates        | 30660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0027   |
|    exploration_rate | 0.751    |
| time/               |          |
|    episodes         | 8988     |
|    fps              | 127      |
|    time_elapsed     | 1280     |
|    total_timesteps  | 162705   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00248  |
|    n_updates        | 30676    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00266  |
|    exploration_rate | 0.751    |
| time/               |          |
|    episodes         | 8992     |
|    fps              | 127      |
|    time_elapsed     | 1280     |
|    total_timesteps  | 162771   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000804 |
|    n_updates        | 30692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00302  |
|    exploration_rate | 0.751    |
| time/               |          |
|    episodes         | 8996     |
|    fps              | 127      |
|    time_elapsed     | 1280     |
|    total_timesteps  | 162836   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 30708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00266  |
|    exploration_rate | 0.751    |
| time/               |          |
|    episodes         | 9000     |
|    fps              | 127      |
|    time_elapsed     | 1281     |
|    total_timesteps  | 162909   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00326  |
|    n_updates        | 30727    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0175  |
|    exploration_rate | 0.75     |
| time/               |          |
|    episodes         | 9004     |
|    fps              | 127      |
|    time_elapsed     | 1281     |
|    total_timesteps  | 162974   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 30743    |
----------------------------------
Eval num_timesteps=163000, episode_reward=0.06 +/- 0.33
Episode length: 14.58 +/- 1.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0627   |
| rollout/            |          |
|    exploration_rate | 0.75     |
| time/               |          |
|    total_timesteps  | 163000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00218  |
|    n_updates        | 30749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.00784 |
|    exploration_rate | 0.75     |
| time/               |          |
|    episodes         | 9008     |
|    fps              | 127      |
|    time_elapsed     | 1282     |
|    total_timesteps  | 163048   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0101   |
|    n_updates        | 30761    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00748 |
|    exploration_rate | 0.75     |
| time/               |          |
|    episodes         | 9012     |
|    fps              | 127      |
|    time_elapsed     | 1282     |
|    total_timesteps  | 163117   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 30779    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00266  |
|    exploration_rate | 0.75     |
| time/               |          |
|    episodes         | 9016     |
|    fps              | 127      |
|    time_elapsed     | 1282     |
|    total_timesteps  | 163181   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00643  |
|    n_updates        | 30795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.75     |
| time/               |          |
|    episodes         | 9020     |
|    fps              | 127      |
|    time_elapsed     | 1282     |
|    total_timesteps  | 163243   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000645 |
|    n_updates        | 30810    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0229   |
|    exploration_rate | 0.749    |
| time/               |          |
|    episodes         | 9024     |
|    fps              | 127      |
|    time_elapsed     | 1282     |
|    total_timesteps  | 163309   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000723 |
|    n_updates        | 30827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.033    |
|    exploration_rate | 0.749    |
| time/               |          |
|    episodes         | 9028     |
|    fps              | 127      |
|    time_elapsed     | 1282     |
|    total_timesteps  | 163372   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 30842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0434   |
|    exploration_rate | 0.749    |
| time/               |          |
|    episodes         | 9032     |
|    fps              | 127      |
|    time_elapsed     | 1282     |
|    total_timesteps  | 163440   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 30859    |
----------------------------------
Eval num_timesteps=163500, episode_reward=0.03 +/- 0.28
Episode length: 17.10 +/- 9.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.1     |
|    mean_reward      | 0.0327   |
| rollout/            |          |
|    exploration_rate | 0.749    |
| time/               |          |
|    total_timesteps  | 163500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 30874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0429   |
|    exploration_rate | 0.749    |
| time/               |          |
|    episodes         | 9036     |
|    fps              | 127      |
|    time_elapsed     | 1284     |
|    total_timesteps  | 163517   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000679 |
|    n_updates        | 30879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0328   |
|    exploration_rate | 0.749    |
| time/               |          |
|    episodes         | 9040     |
|    fps              | 127      |
|    time_elapsed     | 1284     |
|    total_timesteps  | 163584   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0017   |
|    n_updates        | 30895    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0328   |
|    exploration_rate | 0.748    |
| time/               |          |
|    episodes         | 9044     |
|    fps              | 127      |
|    time_elapsed     | 1284     |
|    total_timesteps  | 163650   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000908 |
|    n_updates        | 30912    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0429   |
|    exploration_rate | 0.748    |
| time/               |          |
|    episodes         | 9048     |
|    fps              | 127      |
|    time_elapsed     | 1284     |
|    total_timesteps  | 163714   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00684  |
|    n_updates        | 30928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0324   |
|    exploration_rate | 0.748    |
| time/               |          |
|    episodes         | 9052     |
|    fps              | 127      |
|    time_elapsed     | 1284     |
|    total_timesteps  | 163787   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 30946    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0433   |
|    exploration_rate | 0.748    |
| time/               |          |
|    episodes         | 9056     |
|    fps              | 127      |
|    time_elapsed     | 1284     |
|    total_timesteps  | 163845   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000556 |
|    n_updates        | 30961    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0338   |
|    exploration_rate | 0.748    |
| time/               |          |
|    episodes         | 9060     |
|    fps              | 127      |
|    time_elapsed     | 1284     |
|    total_timesteps  | 163913   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 30978    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0437   |
|    exploration_rate | 0.747    |
| time/               |          |
|    episodes         | 9064     |
|    fps              | 127      |
|    time_elapsed     | 1284     |
|    total_timesteps  | 163983   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 30995    |
----------------------------------
Eval num_timesteps=164000, episode_reward=0.00 +/- 0.24
Episode length: 14.82 +/- 0.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00172  |
| rollout/            |          |
|    exploration_rate | 0.747    |
| time/               |          |
|    total_timesteps  | 164000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 30999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0539   |
|    exploration_rate | 0.747    |
| time/               |          |
|    episodes         | 9068     |
|    fps              | 127      |
|    time_elapsed     | 1285     |
|    total_timesteps  | 164046   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 31011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0538   |
|    exploration_rate | 0.747    |
| time/               |          |
|    episodes         | 9072     |
|    fps              | 127      |
|    time_elapsed     | 1286     |
|    total_timesteps  | 164118   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 31029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.054    |
|    exploration_rate | 0.747    |
| time/               |          |
|    episodes         | 9076     |
|    fps              | 127      |
|    time_elapsed     | 1286     |
|    total_timesteps  | 164181   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000671 |
|    n_updates        | 31045    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.054    |
|    exploration_rate | 0.747    |
| time/               |          |
|    episodes         | 9080     |
|    fps              | 127      |
|    time_elapsed     | 1286     |
|    total_timesteps  | 164246   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000583 |
|    n_updates        | 31061    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.054    |
|    exploration_rate | 0.746    |
| time/               |          |
|    episodes         | 9084     |
|    fps              | 127      |
|    time_elapsed     | 1286     |
|    total_timesteps  | 164322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 31080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0437   |
|    exploration_rate | 0.746    |
| time/               |          |
|    episodes         | 9088     |
|    fps              | 127      |
|    time_elapsed     | 1286     |
|    total_timesteps  | 164390   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000784 |
|    n_updates        | 31097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0438   |
|    exploration_rate | 0.746    |
| time/               |          |
|    episodes         | 9092     |
|    fps              | 127      |
|    time_elapsed     | 1286     |
|    total_timesteps  | 164454   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 31113    |
----------------------------------
Eval num_timesteps=164500, episode_reward=0.00 +/- 0.24
Episode length: 14.80 +/- 0.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00186  |
| rollout/            |          |
|    exploration_rate | 0.746    |
| time/               |          |
|    total_timesteps  | 164500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000912 |
|    n_updates        | 31124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0436   |
|    exploration_rate | 0.746    |
| time/               |          |
|    episodes         | 9096     |
|    fps              | 127      |
|    time_elapsed     | 1287     |
|    total_timesteps  | 164525   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00646  |
|    n_updates        | 31131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0533   |
|    exploration_rate | 0.745    |
| time/               |          |
|    episodes         | 9100     |
|    fps              | 127      |
|    time_elapsed     | 1287     |
|    total_timesteps  | 164604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000686 |
|    n_updates        | 31150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.053    |
|    exploration_rate | 0.745    |
| time/               |          |
|    episodes         | 9104     |
|    fps              | 127      |
|    time_elapsed     | 1287     |
|    total_timesteps  | 164677   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000579 |
|    n_updates        | 31169    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0534   |
|    exploration_rate | 0.745    |
| time/               |          |
|    episodes         | 9108     |
|    fps              | 127      |
|    time_elapsed     | 1287     |
|    total_timesteps  | 164741   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 31185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0535   |
|    exploration_rate | 0.745    |
| time/               |          |
|    episodes         | 9112     |
|    fps              | 127      |
|    time_elapsed     | 1287     |
|    total_timesteps  | 164807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00562  |
|    n_updates        | 31201    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0433   |
|    exploration_rate | 0.745    |
| time/               |          |
|    episodes         | 9116     |
|    fps              | 128      |
|    time_elapsed     | 1288     |
|    total_timesteps  | 164875   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 31218    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0329   |
|    exploration_rate | 0.744    |
| time/               |          |
|    episodes         | 9120     |
|    fps              | 128      |
|    time_elapsed     | 1288     |
|    total_timesteps  | 164947   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000917 |
|    n_updates        | 31236    |
----------------------------------
Eval num_timesteps=165000, episode_reward=0.02 +/- 0.28
Episode length: 14.70 +/- 1.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0222   |
| rollout/            |          |
|    exploration_rate | 0.744    |
| time/               |          |
|    total_timesteps  | 165000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000962 |
|    n_updates        | 31249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0229   |
|    exploration_rate | 0.744    |
| time/               |          |
|    episodes         | 9124     |
|    fps              | 128      |
|    time_elapsed     | 1289     |
|    total_timesteps  | 165013   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 31253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0127   |
|    exploration_rate | 0.744    |
| time/               |          |
|    episodes         | 9128     |
|    fps              | 128      |
|    time_elapsed     | 1289     |
|    total_timesteps  | 165081   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000802 |
|    n_updates        | 31270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00257  |
|    exploration_rate | 0.744    |
| time/               |          |
|    episodes         | 9132     |
|    fps              | 128      |
|    time_elapsed     | 1289     |
|    total_timesteps  | 165152   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 31287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00704 |
|    exploration_rate | 0.744    |
| time/               |          |
|    episodes         | 9136     |
|    fps              | 128      |
|    time_elapsed     | 1289     |
|    total_timesteps  | 165219   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 31304    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00688 |
|    exploration_rate | 0.743    |
| time/               |          |
|    episodes         | 9140     |
|    fps              | 128      |
|    time_elapsed     | 1289     |
|    total_timesteps  | 165282   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 31320    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00672 |
|    exploration_rate | 0.743    |
| time/               |          |
|    episodes         | 9144     |
|    fps              | 128      |
|    time_elapsed     | 1289     |
|    total_timesteps  | 165344   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 31335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0167  |
|    exploration_rate | 0.743    |
| time/               |          |
|    episodes         | 9148     |
|    fps              | 128      |
|    time_elapsed     | 1289     |
|    total_timesteps  | 165408   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 31351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0168  |
|    exploration_rate | 0.743    |
| time/               |          |
|    episodes         | 9152     |
|    fps              | 128      |
|    time_elapsed     | 1289     |
|    total_timesteps  | 165483   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000902 |
|    n_updates        | 31370    |
----------------------------------
Eval num_timesteps=165500, episode_reward=-0.02 +/- 0.20
Episode length: 14.86 +/- 0.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0184  |
| rollout/            |          |
|    exploration_rate | 0.743    |
| time/               |          |
|    total_timesteps  | 165500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 31374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0273  |
|    exploration_rate | 0.743    |
| time/               |          |
|    episodes         | 9156     |
|    fps              | 128      |
|    time_elapsed     | 1290     |
|    total_timesteps  | 165552   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 31387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0185  |
|    exploration_rate | 0.742    |
| time/               |          |
|    episodes         | 9160     |
|    fps              | 128      |
|    time_elapsed     | 1291     |
|    total_timesteps  | 165652   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00275  |
|    n_updates        | 31412    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.029   |
|    exploration_rate | 0.742    |
| time/               |          |
|    episodes         | 9164     |
|    fps              | 128      |
|    time_elapsed     | 1291     |
|    total_timesteps  | 165733   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00781  |
|    n_updates        | 31433    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.039   |
|    exploration_rate | 0.742    |
| time/               |          |
|    episodes         | 9168     |
|    fps              | 128      |
|    time_elapsed     | 1291     |
|    total_timesteps  | 165796   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0069   |
|    n_updates        | 31448    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0387  |
|    exploration_rate | 0.742    |
| time/               |          |
|    episodes         | 9172     |
|    fps              | 128      |
|    time_elapsed     | 1291     |
|    total_timesteps  | 165860   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 31464    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0285  |
|    exploration_rate | 0.741    |
| time/               |          |
|    episodes         | 9176     |
|    fps              | 128      |
|    time_elapsed     | 1291     |
|    total_timesteps  | 165918   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000811 |
|    n_updates        | 31479    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0288  |
|    exploration_rate | 0.741    |
| time/               |          |
|    episodes         | 9180     |
|    fps              | 128      |
|    time_elapsed     | 1291     |
|    total_timesteps  | 165992   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00618  |
|    n_updates        | 31497    |
----------------------------------
Eval num_timesteps=166000, episode_reward=0.04 +/- 0.30
Episode length: 14.76 +/- 0.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.0421   |
| rollout/            |          |
|    exploration_rate | 0.741    |
| time/               |          |
|    total_timesteps  | 166000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 31499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0182  |
|    exploration_rate | 0.741    |
| time/               |          |
|    episodes         | 9184     |
|    fps              | 128      |
|    time_elapsed     | 1292     |
|    total_timesteps  | 166053   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000882 |
|    n_updates        | 31513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0182  |
|    exploration_rate | 0.741    |
| time/               |          |
|    episodes         | 9188     |
|    fps              | 128      |
|    time_elapsed     | 1292     |
|    total_timesteps  | 166122   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00325  |
|    n_updates        | 31530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0183  |
|    exploration_rate | 0.741    |
| time/               |          |
|    episodes         | 9192     |
|    fps              | 128      |
|    time_elapsed     | 1292     |
|    total_timesteps  | 166187   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 31546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0188  |
|    exploration_rate | 0.74     |
| time/               |          |
|    episodes         | 9196     |
|    fps              | 128      |
|    time_elapsed     | 1292     |
|    total_timesteps  | 166270   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000809 |
|    n_updates        | 31567    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0283  |
|    exploration_rate | 0.74     |
| time/               |          |
|    episodes         | 9200     |
|    fps              | 128      |
|    time_elapsed     | 1293     |
|    total_timesteps  | 166337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 31584    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0279  |
|    exploration_rate | 0.74     |
| time/               |          |
|    episodes         | 9204     |
|    fps              | 128      |
|    time_elapsed     | 1293     |
|    total_timesteps  | 166401   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 31600    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0387  |
|    exploration_rate | 0.74     |
| time/               |          |
|    episodes         | 9208     |
|    fps              | 128      |
|    time_elapsed     | 1293     |
|    total_timesteps  | 166485   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00827  |
|    n_updates        | 31621    |
----------------------------------
Eval num_timesteps=166500, episode_reward=0.04 +/- 0.30
Episode length: 14.68 +/- 1.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0423   |
| rollout/            |          |
|    exploration_rate | 0.74     |
| time/               |          |
|    total_timesteps  | 166500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 31624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0391  |
|    exploration_rate | 0.739    |
| time/               |          |
|    episodes         | 9212     |
|    fps              | 128      |
|    time_elapsed     | 1294     |
|    total_timesteps  | 166559   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0023   |
|    n_updates        | 31639    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0391  |
|    exploration_rate | 0.739    |
| time/               |          |
|    episodes         | 9216     |
|    fps              | 128      |
|    time_elapsed     | 1294     |
|    total_timesteps  | 166629   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000987 |
|    n_updates        | 31657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0399  |
|    exploration_rate | 0.739    |
| time/               |          |
|    episodes         | 9220     |
|    fps              | 128      |
|    time_elapsed     | 1294     |
|    total_timesteps  | 166721   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000524 |
|    n_updates        | 31680    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.04    |
|    exploration_rate | 0.739    |
| time/               |          |
|    episodes         | 9224     |
|    fps              | 128      |
|    time_elapsed     | 1294     |
|    total_timesteps  | 166788   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 31696    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.739    |
| time/               |          |
|    episodes         | 9228     |
|    fps              | 128      |
|    time_elapsed     | 1294     |
|    total_timesteps  | 166852   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000935 |
|    n_updates        | 31712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0294  |
|    exploration_rate | 0.738    |
| time/               |          |
|    episodes         | 9232     |
|    fps              | 128      |
|    time_elapsed     | 1294     |
|    total_timesteps  | 166913   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000868 |
|    n_updates        | 31728    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0295  |
|    exploration_rate | 0.738    |
| time/               |          |
|    episodes         | 9236     |
|    fps              | 128      |
|    time_elapsed     | 1294     |
|    total_timesteps  | 166982   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00493  |
|    n_updates        | 31745    |
----------------------------------
Eval num_timesteps=167000, episode_reward=0.04 +/- 0.30
Episode length: 14.76 +/- 1.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.042    |
| rollout/            |          |
|    exploration_rate | 0.738    |
| time/               |          |
|    total_timesteps  | 167000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00657  |
|    n_updates        | 31749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0295  |
|    exploration_rate | 0.738    |
| time/               |          |
|    episodes         | 9240     |
|    fps              | 128      |
|    time_elapsed     | 1295     |
|    total_timesteps  | 167046   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000658 |
|    n_updates        | 31761    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0195  |
|    exploration_rate | 0.738    |
| time/               |          |
|    episodes         | 9244     |
|    fps              | 128      |
|    time_elapsed     | 1295     |
|    total_timesteps  | 167107   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00315  |
|    n_updates        | 31776    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 0.737    |
| time/               |          |
|    episodes         | 9248     |
|    fps              | 128      |
|    time_elapsed     | 1296     |
|    total_timesteps  | 167189   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 31797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0099  |
|    exploration_rate | 0.737    |
| time/               |          |
|    episodes         | 9252     |
|    fps              | 129      |
|    time_elapsed     | 1296     |
|    total_timesteps  | 167257   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00446  |
|    n_updates        | 31814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00998 |
|    exploration_rate | 0.737    |
| time/               |          |
|    episodes         | 9256     |
|    fps              | 129      |
|    time_elapsed     | 1296     |
|    total_timesteps  | 167328   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 31831    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0188  |
|    exploration_rate | 0.737    |
| time/               |          |
|    episodes         | 9260     |
|    fps              | 129      |
|    time_elapsed     | 1296     |
|    total_timesteps  | 167400   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00703  |
|    n_updates        | 31849    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0182  |
|    exploration_rate | 0.737    |
| time/               |          |
|    episodes         | 9264     |
|    fps              | 129      |
|    time_elapsed     | 1296     |
|    total_timesteps  | 167466   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 31866    |
----------------------------------
Eval num_timesteps=167500, episode_reward=0.10 +/- 0.37
Episode length: 14.46 +/- 1.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.103    |
| rollout/            |          |
|    exploration_rate | 0.736    |
| time/               |          |
|    total_timesteps  | 167500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 31874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0184  |
|    exploration_rate | 0.736    |
| time/               |          |
|    episodes         | 9268     |
|    fps              | 129      |
|    time_elapsed     | 1297     |
|    total_timesteps  | 167534   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00596  |
|    n_updates        | 31883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00824 |
|    exploration_rate | 0.736    |
| time/               |          |
|    episodes         | 9272     |
|    fps              | 129      |
|    time_elapsed     | 1297     |
|    total_timesteps  | 167593   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00213  |
|    n_updates        | 31898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.019   |
|    exploration_rate | 0.736    |
| time/               |          |
|    episodes         | 9276     |
|    fps              | 129      |
|    time_elapsed     | 1297     |
|    total_timesteps  | 167669   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00613  |
|    n_updates        | 31917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0186  |
|    exploration_rate | 0.736    |
| time/               |          |
|    episodes         | 9280     |
|    fps              | 129      |
|    time_elapsed     | 1297     |
|    total_timesteps  | 167733   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 31933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0288  |
|    exploration_rate | 0.736    |
| time/               |          |
|    episodes         | 9284     |
|    fps              | 129      |
|    time_elapsed     | 1297     |
|    total_timesteps  | 167798   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00535  |
|    n_updates        | 31949    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0288  |
|    exploration_rate | 0.735    |
| time/               |          |
|    episodes         | 9288     |
|    fps              | 129      |
|    time_elapsed     | 1298     |
|    total_timesteps  | 167868   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000838 |
|    n_updates        | 31966    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0286  |
|    exploration_rate | 0.735    |
| time/               |          |
|    episodes         | 9292     |
|    fps              | 129      |
|    time_elapsed     | 1298     |
|    total_timesteps  | 167929   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000902 |
|    n_updates        | 31982    |
----------------------------------
Eval num_timesteps=168000, episode_reward=0.06 +/- 0.33
Episode length: 14.56 +/- 1.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0628   |
| rollout/            |          |
|    exploration_rate | 0.735    |
| time/               |          |
|    total_timesteps  | 168000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 31999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0285  |
|    exploration_rate | 0.735    |
| time/               |          |
|    episodes         | 9296     |
|    fps              | 129      |
|    time_elapsed     | 1299     |
|    total_timesteps  | 168009   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 32002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0181  |
|    exploration_rate | 0.735    |
| time/               |          |
|    episodes         | 9300     |
|    fps              | 129      |
|    time_elapsed     | 1299     |
|    total_timesteps  | 168066   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00283  |
|    n_updates        | 32016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0181  |
|    exploration_rate | 0.735    |
| time/               |          |
|    episodes         | 9304     |
|    fps              | 129      |
|    time_elapsed     | 1299     |
|    total_timesteps  | 168130   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000743 |
|    n_updates        | 32032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0173  |
|    exploration_rate | 0.734    |
| time/               |          |
|    episodes         | 9308     |
|    fps              | 129      |
|    time_elapsed     | 1299     |
|    total_timesteps  | 168194   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000864 |
|    n_updates        | 32048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00677 |
|    exploration_rate | 0.734    |
| time/               |          |
|    episodes         | 9312     |
|    fps              | 129      |
|    time_elapsed     | 1299     |
|    total_timesteps  | 168254   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 32063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00347  |
|    exploration_rate | 0.734    |
| time/               |          |
|    episodes         | 9316     |
|    fps              | 129      |
|    time_elapsed     | 1299     |
|    total_timesteps  | 168318   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00552  |
|    n_updates        | 32079    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00471  |
|    exploration_rate | 0.734    |
| time/               |          |
|    episodes         | 9320     |
|    fps              | 129      |
|    time_elapsed     | 1299     |
|    total_timesteps  | 168379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 32094    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00443  |
|    exploration_rate | 0.734    |
| time/               |          |
|    episodes         | 9324     |
|    fps              | 129      |
|    time_elapsed     | 1299     |
|    total_timesteps  | 168453   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00258  |
|    n_updates        | 32113    |
----------------------------------
Eval num_timesteps=168500, episode_reward=0.12 +/- 0.39
Episode length: 14.86 +/- 2.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.122    |
| rollout/            |          |
|    exploration_rate | 0.733    |
| time/               |          |
|    total_timesteps  | 168500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 32124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00564 |
|    exploration_rate | 0.733    |
| time/               |          |
|    episodes         | 9328     |
|    fps              | 129      |
|    time_elapsed     | 1300     |
|    total_timesteps  | 168519   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000862 |
|    n_updates        | 32129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00628 |
|    exploration_rate | 0.733    |
| time/               |          |
|    episodes         | 9332     |
|    fps              | 129      |
|    time_elapsed     | 1301     |
|    total_timesteps  | 168596   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000869 |
|    n_updates        | 32148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00668 |
|    exploration_rate | 0.733    |
| time/               |          |
|    episodes         | 9336     |
|    fps              | 129      |
|    time_elapsed     | 1301     |
|    total_timesteps  | 168675   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 32168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00319  |
|    exploration_rate | 0.733    |
| time/               |          |
|    episodes         | 9340     |
|    fps              | 129      |
|    time_elapsed     | 1301     |
|    total_timesteps  | 168742   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000498 |
|    n_updates        | 32185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00683 |
|    exploration_rate | 0.732    |
| time/               |          |
|    episodes         | 9344     |
|    fps              | 129      |
|    time_elapsed     | 1301     |
|    total_timesteps  | 168803   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00433  |
|    n_updates        | 32200    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00635 |
|    exploration_rate | 0.732    |
| time/               |          |
|    episodes         | 9348     |
|    fps              | 129      |
|    time_elapsed     | 1301     |
|    total_timesteps  | 168873   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00438  |
|    n_updates        | 32218    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.732    |
| time/               |          |
|    episodes         | 9352     |
|    fps              | 129      |
|    time_elapsed     | 1301     |
|    total_timesteps  | 168942   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 32235    |
----------------------------------
Eval num_timesteps=169000, episode_reward=0.12 +/- 0.39
Episode length: 14.60 +/- 1.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.123    |
| rollout/            |          |
|    exploration_rate | 0.732    |
| time/               |          |
|    total_timesteps  | 169000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 32249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00596 |
|    exploration_rate | 0.732    |
| time/               |          |
|    episodes         | 9356     |
|    fps              | 129      |
|    time_elapsed     | 1302     |
|    total_timesteps  | 169002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00191  |
|    n_updates        | 32250    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00584 |
|    exploration_rate | 0.732    |
| time/               |          |
|    episodes         | 9360     |
|    fps              | 129      |
|    time_elapsed     | 1302     |
|    total_timesteps  | 169071   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 32267    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00592 |
|    exploration_rate | 0.731    |
| time/               |          |
|    episodes         | 9364     |
|    fps              | 129      |
|    time_elapsed     | 1302     |
|    total_timesteps  | 169139   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00235  |
|    n_updates        | 32284    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00572 |
|    exploration_rate | 0.731    |
| time/               |          |
|    episodes         | 9368     |
|    fps              | 129      |
|    time_elapsed     | 1302     |
|    total_timesteps  | 169202   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000999 |
|    n_updates        | 32300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.016   |
|    exploration_rate | 0.731    |
| time/               |          |
|    episodes         | 9372     |
|    fps              | 129      |
|    time_elapsed     | 1302     |
|    total_timesteps  | 169269   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00341  |
|    n_updates        | 32317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00551 |
|    exploration_rate | 0.731    |
| time/               |          |
|    episodes         | 9376     |
|    fps              | 129      |
|    time_elapsed     | 1303     |
|    total_timesteps  | 169332   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 32332    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00567 |
|    exploration_rate | 0.731    |
| time/               |          |
|    episodes         | 9380     |
|    fps              | 129      |
|    time_elapsed     | 1303     |
|    total_timesteps  | 169400   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000775 |
|    n_updates        | 32349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00441  |
|    exploration_rate | 0.73     |
| time/               |          |
|    episodes         | 9384     |
|    fps              | 130      |
|    time_elapsed     | 1303     |
|    total_timesteps  | 169463   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000373 |
|    n_updates        | 32365    |
----------------------------------
Eval num_timesteps=169500, episode_reward=0.10 +/- 0.37
Episode length: 14.52 +/- 1.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.103    |
| rollout/            |          |
|    exploration_rate | 0.73     |
| time/               |          |
|    total_timesteps  | 169500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0023   |
|    n_updates        | 32374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00393  |
|    exploration_rate | 0.73     |
| time/               |          |
|    episodes         | 9388     |
|    fps              | 129      |
|    time_elapsed     | 1304     |
|    total_timesteps  | 169545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 32386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0141   |
|    exploration_rate | 0.73     |
| time/               |          |
|    episodes         | 9392     |
|    fps              | 130      |
|    time_elapsed     | 1304     |
|    total_timesteps  | 169602   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0105   |
|    n_updates        | 32400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0249   |
|    exploration_rate | 0.73     |
| time/               |          |
|    episodes         | 9396     |
|    fps              | 130      |
|    time_elapsed     | 1304     |
|    total_timesteps  | 169661   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 32415    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0144   |
|    exploration_rate | 0.73     |
| time/               |          |
|    episodes         | 9400     |
|    fps              | 130      |
|    time_elapsed     | 1304     |
|    total_timesteps  | 169732   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 32432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.729    |
| time/               |          |
|    episodes         | 9404     |
|    fps              | 130      |
|    time_elapsed     | 1304     |
|    total_timesteps  | 169799   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000428 |
|    n_updates        | 32449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.729    |
| time/               |          |
|    episodes         | 9408     |
|    fps              | 130      |
|    time_elapsed     | 1304     |
|    total_timesteps  | 169863   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00201  |
|    n_updates        | 32465    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00402  |
|    exploration_rate | 0.729    |
| time/               |          |
|    episodes         | 9412     |
|    fps              | 130      |
|    time_elapsed     | 1304     |
|    total_timesteps  | 169929   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 32482    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00602 |
|    exploration_rate | 0.729    |
| time/               |          |
|    episodes         | 9416     |
|    fps              | 130      |
|    time_elapsed     | 1304     |
|    total_timesteps  | 169994   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 32498    |
----------------------------------
Eval num_timesteps=170000, episode_reward=-0.06 +/- 0.00
Episode length: 15.04 +/- 0.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.0592  |
| rollout/            |          |
|    exploration_rate | 0.729    |
| time/               |          |
|    total_timesteps  | 170000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00474  |
|    n_updates        | 32499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00638 |
|    exploration_rate | 0.729    |
| time/               |          |
|    episodes         | 9420     |
|    fps              | 130      |
|    time_elapsed     | 1305     |
|    total_timesteps  | 170064   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 32515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00411  |
|    exploration_rate | 0.728    |
| time/               |          |
|    episodes         | 9424     |
|    fps              | 130      |
|    time_elapsed     | 1306     |
|    total_timesteps  | 170126   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 32531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00415  |
|    exploration_rate | 0.728    |
| time/               |          |
|    episodes         | 9428     |
|    fps              | 130      |
|    time_elapsed     | 1306     |
|    total_timesteps  | 170191   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00451  |
|    n_updates        | 32547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00447  |
|    exploration_rate | 0.728    |
| time/               |          |
|    episodes         | 9432     |
|    fps              | 130      |
|    time_elapsed     | 1306     |
|    total_timesteps  | 170260   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000813 |
|    n_updates        | 32564    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00487  |
|    exploration_rate | 0.728    |
| time/               |          |
|    episodes         | 9436     |
|    fps              | 130      |
|    time_elapsed     | 1306     |
|    total_timesteps  | 170329   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 32582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00516 |
|    exploration_rate | 0.727    |
| time/               |          |
|    episodes         | 9440     |
|    fps              | 130      |
|    time_elapsed     | 1306     |
|    total_timesteps  | 170397   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 32599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00528 |
|    exploration_rate | 0.727    |
| time/               |          |
|    episodes         | 9444     |
|    fps              | 130      |
|    time_elapsed     | 1306     |
|    total_timesteps  | 170461   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 32615    |
----------------------------------
Eval num_timesteps=170500, episode_reward=-0.02 +/- 0.20
Episode length: 14.84 +/- 0.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | -0.0183  |
| rollout/            |          |
|    exploration_rate | 0.727    |
| time/               |          |
|    total_timesteps  | 170500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 32624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00513  |
|    exploration_rate | 0.727    |
| time/               |          |
|    episodes         | 9448     |
|    fps              | 130      |
|    time_elapsed     | 1307     |
|    total_timesteps  | 170521   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00715  |
|    n_updates        | 32630    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.727    |
| time/               |          |
|    episodes         | 9452     |
|    fps              | 130      |
|    time_elapsed     | 1307     |
|    total_timesteps  | 170584   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 32645    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0155   |
|    exploration_rate | 0.727    |
| time/               |          |
|    episodes         | 9456     |
|    fps              | 130      |
|    time_elapsed     | 1307     |
|    total_timesteps  | 170641   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000919 |
|    n_updates        | 32660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.726    |
| time/               |          |
|    episodes         | 9460     |
|    fps              | 130      |
|    time_elapsed     | 1307     |
|    total_timesteps  | 170714   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 32678    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0257   |
|    exploration_rate | 0.726    |
| time/               |          |
|    episodes         | 9464     |
|    fps              | 130      |
|    time_elapsed     | 1307     |
|    total_timesteps  | 170773   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 32693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.726    |
| time/               |          |
|    episodes         | 9468     |
|    fps              | 130      |
|    time_elapsed     | 1308     |
|    total_timesteps  | 170839   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 32709    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.726    |
| time/               |          |
|    episodes         | 9472     |
|    fps              | 130      |
|    time_elapsed     | 1308     |
|    total_timesteps  | 170906   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 32726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.726    |
| time/               |          |
|    episodes         | 9476     |
|    fps              | 130      |
|    time_elapsed     | 1308     |
|    total_timesteps  | 170974   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000916 |
|    n_updates        | 32743    |
----------------------------------
Eval num_timesteps=171000, episode_reward=0.02 +/- 0.28
Episode length: 14.72 +/- 0.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0222   |
| rollout/            |          |
|    exploration_rate | 0.726    |
| time/               |          |
|    total_timesteps  | 171000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00407  |
|    n_updates        | 32749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.725    |
| time/               |          |
|    episodes         | 9480     |
|    fps              | 130      |
|    time_elapsed     | 1309     |
|    total_timesteps  | 171042   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 32760    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0155   |
|    exploration_rate | 0.725    |
| time/               |          |
|    episodes         | 9484     |
|    fps              | 130      |
|    time_elapsed     | 1309     |
|    total_timesteps  | 171103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 32775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0261   |
|    exploration_rate | 0.725    |
| time/               |          |
|    episodes         | 9488     |
|    fps              | 130      |
|    time_elapsed     | 1309     |
|    total_timesteps  | 171170   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00715  |
|    n_updates        | 32792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.725    |
| time/               |          |
|    episodes         | 9492     |
|    fps              | 130      |
|    time_elapsed     | 1309     |
|    total_timesteps  | 171240   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 32809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.015    |
|    exploration_rate | 0.725    |
| time/               |          |
|    episodes         | 9496     |
|    fps              | 130      |
|    time_elapsed     | 1309     |
|    total_timesteps  | 171312   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 32827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0148   |
|    exploration_rate | 0.724    |
| time/               |          |
|    episodes         | 9500     |
|    fps              | 130      |
|    time_elapsed     | 1309     |
|    total_timesteps  | 171390   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000996 |
|    n_updates        | 32847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0149   |
|    exploration_rate | 0.724    |
| time/               |          |
|    episodes         | 9504     |
|    fps              | 130      |
|    time_elapsed     | 1309     |
|    total_timesteps  | 171453   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 32863    |
----------------------------------
Eval num_timesteps=171500, episode_reward=-0.02 +/- 0.20
Episode length: 14.82 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | -0.0183  |
| rollout/            |          |
|    exploration_rate | 0.724    |
| time/               |          |
|    total_timesteps  | 171500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0082   |
|    n_updates        | 32874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0148   |
|    exploration_rate | 0.724    |
| time/               |          |
|    episodes         | 9508     |
|    fps              | 130      |
|    time_elapsed     | 1311     |
|    total_timesteps  | 171519   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000649 |
|    n_updates        | 32879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.724    |
| time/               |          |
|    episodes         | 9512     |
|    fps              | 130      |
|    time_elapsed     | 1311     |
|    total_timesteps  | 171591   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 32897    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0142   |
|    exploration_rate | 0.723    |
| time/               |          |
|    episodes         | 9516     |
|    fps              | 130      |
|    time_elapsed     | 1311     |
|    total_timesteps  | 171666   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 32916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0144   |
|    exploration_rate | 0.723    |
| time/               |          |
|    episodes         | 9520     |
|    fps              | 130      |
|    time_elapsed     | 1311     |
|    total_timesteps  | 171731   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000915 |
|    n_updates        | 32932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0141   |
|    exploration_rate | 0.723    |
| time/               |          |
|    episodes         | 9524     |
|    fps              | 131      |
|    time_elapsed     | 1311     |
|    total_timesteps  | 171801   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000768 |
|    n_updates        | 32950    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.723    |
| time/               |          |
|    episodes         | 9528     |
|    fps              | 131      |
|    time_elapsed     | 1311     |
|    total_timesteps  | 171869   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 32967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0142   |
|    exploration_rate | 0.723    |
| time/               |          |
|    episodes         | 9532     |
|    fps              | 131      |
|    time_elapsed     | 1311     |
|    total_timesteps  | 171933   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 32983    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.722    |
| time/               |          |
|    episodes         | 9536     |
|    fps              | 131      |
|    time_elapsed     | 1311     |
|    total_timesteps  | 171998   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 32999    |
----------------------------------
Eval num_timesteps=172000, episode_reward=0.04 +/- 0.30
Episode length: 14.70 +/- 0.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0422   |
| rollout/            |          |
|    exploration_rate | 0.722    |
| time/               |          |
|    total_timesteps  | 172000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0243   |
|    exploration_rate | 0.722    |
| time/               |          |
|    episodes         | 9540     |
|    fps              | 131      |
|    time_elapsed     | 1312     |
|    total_timesteps  | 172066   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00071  |
|    n_updates        | 33016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0241   |
|    exploration_rate | 0.722    |
| time/               |          |
|    episodes         | 9544     |
|    fps              | 131      |
|    time_elapsed     | 1312     |
|    total_timesteps  | 172136   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000975 |
|    n_updates        | 33033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0136   |
|    exploration_rate | 0.722    |
| time/               |          |
|    episodes         | 9548     |
|    fps              | 131      |
|    time_elapsed     | 1312     |
|    total_timesteps  | 172207   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00269  |
|    n_updates        | 33051    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0135   |
|    exploration_rate | 0.722    |
| time/               |          |
|    episodes         | 9552     |
|    fps              | 131      |
|    time_elapsed     | 1312     |
|    total_timesteps  | 172274   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 33068    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0235   |
|    exploration_rate | 0.721    |
| time/               |          |
|    episodes         | 9556     |
|    fps              | 131      |
|    time_elapsed     | 1313     |
|    total_timesteps  | 172331   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000681 |
|    n_updates        | 33082    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0235   |
|    exploration_rate | 0.721    |
| time/               |          |
|    episodes         | 9560     |
|    fps              | 131      |
|    time_elapsed     | 1313     |
|    total_timesteps  | 172403   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 33100    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0127   |
|    exploration_rate | 0.721    |
| time/               |          |
|    episodes         | 9564     |
|    fps              | 131      |
|    time_elapsed     | 1313     |
|    total_timesteps  | 172481   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 33120    |
----------------------------------
Eval num_timesteps=172500, episode_reward=0.02 +/- 0.28
Episode length: 14.84 +/- 1.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.0216   |
| rollout/            |          |
|    exploration_rate | 0.721    |
| time/               |          |
|    total_timesteps  | 172500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000697 |
|    n_updates        | 33124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0228   |
|    exploration_rate | 0.721    |
| time/               |          |
|    episodes         | 9568     |
|    fps              | 131      |
|    time_elapsed     | 1314     |
|    total_timesteps  | 172545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 33136    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0227   |
|    exploration_rate | 0.72     |
| time/               |          |
|    episodes         | 9572     |
|    fps              | 131      |
|    time_elapsed     | 1314     |
|    total_timesteps  | 172614   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00442  |
|    n_updates        | 33153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0227   |
|    exploration_rate | 0.72     |
| time/               |          |
|    episodes         | 9576     |
|    fps              | 131      |
|    time_elapsed     | 1314     |
|    total_timesteps  | 172682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 33170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0229   |
|    exploration_rate | 0.72     |
| time/               |          |
|    episodes         | 9580     |
|    fps              | 131      |
|    time_elapsed     | 1314     |
|    total_timesteps  | 172746   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00366  |
|    n_updates        | 33186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0228   |
|    exploration_rate | 0.72     |
| time/               |          |
|    episodes         | 9584     |
|    fps              | 131      |
|    time_elapsed     | 1314     |
|    total_timesteps  | 172809   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.011    |
|    n_updates        | 33202    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0232   |
|    exploration_rate | 0.72     |
| time/               |          |
|    episodes         | 9588     |
|    fps              | 131      |
|    time_elapsed     | 1314     |
|    total_timesteps  | 172867   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00463  |
|    n_updates        | 33216    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0234   |
|    exploration_rate | 0.719    |
| time/               |          |
|    episodes         | 9592     |
|    fps              | 131      |
|    time_elapsed     | 1314     |
|    total_timesteps  | 172931   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000611 |
|    n_updates        | 33232    |
----------------------------------
Eval num_timesteps=173000, episode_reward=0.04 +/- 0.30
Episode length: 14.68 +/- 0.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0424   |
| rollout/            |          |
|    exploration_rate | 0.719    |
| time/               |          |
|    total_timesteps  | 173000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00097  |
|    n_updates        | 33249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0133   |
|    exploration_rate | 0.719    |
| time/               |          |
|    episodes         | 9596     |
|    fps              | 131      |
|    time_elapsed     | 1316     |
|    total_timesteps  | 173005   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 33251    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0133   |
|    exploration_rate | 0.719    |
| time/               |          |
|    episodes         | 9600     |
|    fps              | 131      |
|    time_elapsed     | 1316     |
|    total_timesteps  | 173084   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00554  |
|    n_updates        | 33270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0132   |
|    exploration_rate | 0.719    |
| time/               |          |
|    episodes         | 9604     |
|    fps              | 131      |
|    time_elapsed     | 1316     |
|    total_timesteps  | 173150   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00068  |
|    n_updates        | 33287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0234   |
|    exploration_rate | 0.719    |
| time/               |          |
|    episodes         | 9608     |
|    fps              | 131      |
|    time_elapsed     | 1316     |
|    total_timesteps  | 173210   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00225  |
|    n_updates        | 33302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0236   |
|    exploration_rate | 0.718    |
| time/               |          |
|    episodes         | 9612     |
|    fps              | 131      |
|    time_elapsed     | 1316     |
|    total_timesteps  | 173277   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00289  |
|    n_updates        | 33319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.024    |
|    exploration_rate | 0.718    |
| time/               |          |
|    episodes         | 9616     |
|    fps              | 131      |
|    time_elapsed     | 1316     |
|    total_timesteps  | 173341   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 33335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0237   |
|    exploration_rate | 0.718    |
| time/               |          |
|    episodes         | 9620     |
|    fps              | 131      |
|    time_elapsed     | 1316     |
|    total_timesteps  | 173413   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00577  |
|    n_updates        | 33353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.718    |
| time/               |          |
|    episodes         | 9624     |
|    fps              | 131      |
|    time_elapsed     | 1316     |
|    total_timesteps  | 173477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00411  |
|    n_updates        | 33369    |
----------------------------------
Eval num_timesteps=173500, episode_reward=0.02 +/- 0.28
Episode length: 14.68 +/- 1.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0223   |
| rollout/            |          |
|    exploration_rate | 0.718    |
| time/               |          |
|    total_timesteps  | 173500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 33374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0135   |
|    exploration_rate | 0.717    |
| time/               |          |
|    episodes         | 9628     |
|    fps              | 131      |
|    time_elapsed     | 1317     |
|    total_timesteps  | 173557   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 33389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0132   |
|    exploration_rate | 0.717    |
| time/               |          |
|    episodes         | 9632     |
|    fps              | 131      |
|    time_elapsed     | 1317     |
|    total_timesteps  | 173628   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0124   |
|    n_updates        | 33406    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0233   |
|    exploration_rate | 0.717    |
| time/               |          |
|    episodes         | 9636     |
|    fps              | 131      |
|    time_elapsed     | 1317     |
|    total_timesteps  | 173691   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00383  |
|    n_updates        | 33422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0135   |
|    exploration_rate | 0.717    |
| time/               |          |
|    episodes         | 9640     |
|    fps              | 131      |
|    time_elapsed     | 1318     |
|    total_timesteps  | 173754   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 33438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0136   |
|    exploration_rate | 0.717    |
| time/               |          |
|    episodes         | 9644     |
|    fps              | 131      |
|    time_elapsed     | 1318     |
|    total_timesteps  | 173822   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 33455    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0138   |
|    exploration_rate | 0.716    |
| time/               |          |
|    episodes         | 9648     |
|    fps              | 131      |
|    time_elapsed     | 1318     |
|    total_timesteps  | 173887   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 33471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00357  |
|    exploration_rate | 0.716    |
| time/               |          |
|    episodes         | 9652     |
|    fps              | 131      |
|    time_elapsed     | 1318     |
|    total_timesteps  | 173960   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00253  |
|    n_updates        | 33489    |
----------------------------------
Eval num_timesteps=174000, episode_reward=-0.02 +/- 0.20
Episode length: 14.92 +/- 0.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0186  |
| rollout/            |          |
|    exploration_rate | 0.716    |
| time/               |          |
|    total_timesteps  | 174000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 33499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.017   |
|    exploration_rate | 0.716    |
| time/               |          |
|    episodes         | 9656     |
|    fps              | 131      |
|    time_elapsed     | 1319     |
|    total_timesteps  | 174031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 33507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0174  |
|    exploration_rate | 0.716    |
| time/               |          |
|    episodes         | 9660     |
|    fps              | 131      |
|    time_elapsed     | 1319     |
|    total_timesteps  | 174114   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0108   |
|    n_updates        | 33528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.017   |
|    exploration_rate | 0.716    |
| time/               |          |
|    episodes         | 9664     |
|    fps              | 132      |
|    time_elapsed     | 1319     |
|    total_timesteps  | 174182   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00356  |
|    n_updates        | 33545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0269  |
|    exploration_rate | 0.715    |
| time/               |          |
|    episodes         | 9668     |
|    fps              | 132      |
|    time_elapsed     | 1319     |
|    total_timesteps  | 174243   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 33560    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0266  |
|    exploration_rate | 0.715    |
| time/               |          |
|    episodes         | 9672     |
|    fps              | 132      |
|    time_elapsed     | 1319     |
|    total_timesteps  | 174305   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 33576    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0264  |
|    exploration_rate | 0.715    |
| time/               |          |
|    episodes         | 9676     |
|    fps              | 132      |
|    time_elapsed     | 1319     |
|    total_timesteps  | 174368   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000922 |
|    n_updates        | 33591    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0269  |
|    exploration_rate | 0.715    |
| time/               |          |
|    episodes         | 9680     |
|    fps              | 132      |
|    time_elapsed     | 1319     |
|    total_timesteps  | 174444   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 33610    |
----------------------------------
Eval num_timesteps=174500, episode_reward=0.02 +/- 0.27
Episode length: 14.84 +/- 1.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.0217   |
| rollout/            |          |
|    exploration_rate | 0.715    |
| time/               |          |
|    total_timesteps  | 174500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0007   |
|    n_updates        | 33624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0373  |
|    exploration_rate | 0.714    |
| time/               |          |
|    episodes         | 9684     |
|    fps              | 132      |
|    time_elapsed     | 1321     |
|    total_timesteps  | 174518   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 33629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0475  |
|    exploration_rate | 0.714    |
| time/               |          |
|    episodes         | 9688     |
|    fps              | 132      |
|    time_elapsed     | 1321     |
|    total_timesteps  | 174580   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 33644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0478  |
|    exploration_rate | 0.714    |
| time/               |          |
|    episodes         | 9692     |
|    fps              | 132      |
|    time_elapsed     | 1321     |
|    total_timesteps  | 174651   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 33662    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0479  |
|    exploration_rate | 0.714    |
| time/               |          |
|    episodes         | 9696     |
|    fps              | 132      |
|    time_elapsed     | 1321     |
|    total_timesteps  | 174728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000468 |
|    n_updates        | 33681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0474  |
|    exploration_rate | 0.714    |
| time/               |          |
|    episodes         | 9700     |
|    fps              | 132      |
|    time_elapsed     | 1321     |
|    total_timesteps  | 174795   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00279  |
|    n_updates        | 33698    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0373  |
|    exploration_rate | 0.713    |
| time/               |          |
|    episodes         | 9704     |
|    fps              | 132      |
|    time_elapsed     | 1321     |
|    total_timesteps  | 174856   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000932 |
|    n_updates        | 33713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0476  |
|    exploration_rate | 0.713    |
| time/               |          |
|    episodes         | 9708     |
|    fps              | 132      |
|    time_elapsed     | 1321     |
|    total_timesteps  | 174924   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00235  |
|    n_updates        | 33730    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0374  |
|    exploration_rate | 0.713    |
| time/               |          |
|    episodes         | 9712     |
|    fps              | 132      |
|    time_elapsed     | 1321     |
|    total_timesteps  | 174986   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 33746    |
----------------------------------
Eval num_timesteps=175000, episode_reward=0.04 +/- 0.30
Episode length: 14.68 +/- 1.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0424   |
| rollout/            |          |
|    exploration_rate | 0.713    |
| time/               |          |
|    total_timesteps  | 175000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00649  |
|    n_updates        | 33749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0274  |
|    exploration_rate | 0.713    |
| time/               |          |
|    episodes         | 9716     |
|    fps              | 132      |
|    time_elapsed     | 1322     |
|    total_timesteps  | 175051   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 33762    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0171  |
|    exploration_rate | 0.713    |
| time/               |          |
|    episodes         | 9720     |
|    fps              | 132      |
|    time_elapsed     | 1322     |
|    total_timesteps  | 175116   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 33778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.017   |
|    exploration_rate | 0.712    |
| time/               |          |
|    episodes         | 9724     |
|    fps              | 132      |
|    time_elapsed     | 1323     |
|    total_timesteps  | 175179   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 33794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0163  |
|    exploration_rate | 0.712    |
| time/               |          |
|    episodes         | 9728     |
|    fps              | 132      |
|    time_elapsed     | 1323     |
|    total_timesteps  | 175241   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000838 |
|    n_updates        | 33810    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00631 |
|    exploration_rate | 0.712    |
| time/               |          |
|    episodes         | 9732     |
|    fps              | 132      |
|    time_elapsed     | 1323     |
|    total_timesteps  | 175312   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000535 |
|    n_updates        | 33827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0163  |
|    exploration_rate | 0.712    |
| time/               |          |
|    episodes         | 9736     |
|    fps              | 132      |
|    time_elapsed     | 1323     |
|    total_timesteps  | 175375   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 33843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00621 |
|    exploration_rate | 0.712    |
| time/               |          |
|    episodes         | 9740     |
|    fps              | 132      |
|    time_elapsed     | 1323     |
|    total_timesteps  | 175436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 33858    |
----------------------------------
Eval num_timesteps=175500, episode_reward=0.04 +/- 0.31
Episode length: 14.56 +/- 1.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0427   |
| rollout/            |          |
|    exploration_rate | 0.711    |
| time/               |          |
|    total_timesteps  | 175500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 33874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00621 |
|    exploration_rate | 0.711    |
| time/               |          |
|    episodes         | 9744     |
|    fps              | 132      |
|    time_elapsed     | 1324     |
|    total_timesteps  | 175504   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 33875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00389  |
|    exploration_rate | 0.711    |
| time/               |          |
|    episodes         | 9748     |
|    fps              | 132      |
|    time_elapsed     | 1324     |
|    total_timesteps  | 175567   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 33891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0243   |
|    exploration_rate | 0.711    |
| time/               |          |
|    episodes         | 9752     |
|    fps              | 132      |
|    time_elapsed     | 1324     |
|    total_timesteps  | 175630   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 33907    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.045    |
|    exploration_rate | 0.711    |
| time/               |          |
|    episodes         | 9756     |
|    fps              | 132      |
|    time_elapsed     | 1324     |
|    total_timesteps  | 175682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 33920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0454   |
|    exploration_rate | 0.71     |
| time/               |          |
|    episodes         | 9760     |
|    fps              | 132      |
|    time_elapsed     | 1324     |
|    total_timesteps  | 175757   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 33939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0453   |
|    exploration_rate | 0.71     |
| time/               |          |
|    episodes         | 9764     |
|    fps              | 132      |
|    time_elapsed     | 1324     |
|    total_timesteps  | 175826   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000765 |
|    n_updates        | 33956    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0449   |
|    exploration_rate | 0.71     |
| time/               |          |
|    episodes         | 9768     |
|    fps              | 132      |
|    time_elapsed     | 1324     |
|    total_timesteps  | 175898   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 33974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0446   |
|    exploration_rate | 0.71     |
| time/               |          |
|    episodes         | 9772     |
|    fps              | 132      |
|    time_elapsed     | 1325     |
|    total_timesteps  | 175968   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000576 |
|    n_updates        | 33991    |
----------------------------------
Eval num_timesteps=176000, episode_reward=0.02 +/- 0.28
Episode length: 14.74 +/- 1.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.022    |
| rollout/            |          |
|    exploration_rate | 0.71     |
| time/               |          |
|    total_timesteps  | 176000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00411  |
|    n_updates        | 33999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0443   |
|    exploration_rate | 0.71     |
| time/               |          |
|    episodes         | 9776     |
|    fps              | 132      |
|    time_elapsed     | 1326     |
|    total_timesteps  | 176037   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 34009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0446   |
|    exploration_rate | 0.709    |
| time/               |          |
|    episodes         | 9780     |
|    fps              | 132      |
|    time_elapsed     | 1326     |
|    total_timesteps  | 176107   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000732 |
|    n_updates        | 34026    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.055    |
|    exploration_rate | 0.709    |
| time/               |          |
|    episodes         | 9784     |
|    fps              | 132      |
|    time_elapsed     | 1326     |
|    total_timesteps  | 176171   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000761 |
|    n_updates        | 34042    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0548   |
|    exploration_rate | 0.709    |
| time/               |          |
|    episodes         | 9788     |
|    fps              | 132      |
|    time_elapsed     | 1326     |
|    total_timesteps  | 176238   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 34059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.065    |
|    exploration_rate | 0.709    |
| time/               |          |
|    episodes         | 9792     |
|    fps              | 132      |
|    time_elapsed     | 1326     |
|    total_timesteps  | 176303   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000847 |
|    n_updates        | 34075    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0654   |
|    exploration_rate | 0.709    |
| time/               |          |
|    episodes         | 9796     |
|    fps              | 132      |
|    time_elapsed     | 1326     |
|    total_timesteps  | 176370   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 34092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0655   |
|    exploration_rate | 0.708    |
| time/               |          |
|    episodes         | 9800     |
|    fps              | 132      |
|    time_elapsed     | 1326     |
|    total_timesteps  | 176435   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000504 |
|    n_updates        | 34108    |
----------------------------------
Eval num_timesteps=176500, episode_reward=0.02 +/- 0.27
Episode length: 14.76 +/- 0.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.022    |
| rollout/            |          |
|    exploration_rate | 0.708    |
| time/               |          |
|    total_timesteps  | 176500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000729 |
|    n_updates        | 34124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0644   |
|    exploration_rate | 0.708    |
| time/               |          |
|    episodes         | 9804     |
|    fps              | 132      |
|    time_elapsed     | 1327     |
|    total_timesteps  | 176523   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 34130    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0744   |
|    exploration_rate | 0.708    |
| time/               |          |
|    episodes         | 9808     |
|    fps              | 132      |
|    time_elapsed     | 1328     |
|    total_timesteps  | 176591   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00876  |
|    n_updates        | 34147    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0643   |
|    exploration_rate | 0.708    |
| time/               |          |
|    episodes         | 9812     |
|    fps              | 133      |
|    time_elapsed     | 1328     |
|    total_timesteps  | 176655   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 34163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0538   |
|    exploration_rate | 0.707    |
| time/               |          |
|    episodes         | 9816     |
|    fps              | 133      |
|    time_elapsed     | 1328     |
|    total_timesteps  | 176733   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000922 |
|    n_updates        | 34183    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0438   |
|    exploration_rate | 0.707    |
| time/               |          |
|    episodes         | 9820     |
|    fps              | 133      |
|    time_elapsed     | 1328     |
|    total_timesteps  | 176798   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00068  |
|    n_updates        | 34199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0537   |
|    exploration_rate | 0.707    |
| time/               |          |
|    episodes         | 9824     |
|    fps              | 133      |
|    time_elapsed     | 1328     |
|    total_timesteps  | 176864   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 34215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0637   |
|    exploration_rate | 0.707    |
| time/               |          |
|    episodes         | 9828     |
|    fps              | 133      |
|    time_elapsed     | 1328     |
|    total_timesteps  | 176924   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00833  |
|    n_updates        | 34230    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.054    |
|    exploration_rate | 0.707    |
| time/               |          |
|    episodes         | 9832     |
|    fps              | 133      |
|    time_elapsed     | 1328     |
|    total_timesteps  | 176988   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00696  |
|    n_updates        | 34246    |
----------------------------------
Eval num_timesteps=177000, episode_reward=0.06 +/- 0.33
Episode length: 15.58 +/- 7.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.6     |
|    mean_reward      | 0.0587   |
| rollout/            |          |
|    exploration_rate | 0.707    |
| time/               |          |
|    total_timesteps  | 177000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 34249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0536   |
|    exploration_rate | 0.706    |
| time/               |          |
|    episodes         | 9836     |
|    fps              | 133      |
|    time_elapsed     | 1329     |
|    total_timesteps  | 177061   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 34265    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0536   |
|    exploration_rate | 0.706    |
| time/               |          |
|    episodes         | 9840     |
|    fps              | 133      |
|    time_elapsed     | 1329     |
|    total_timesteps  | 177121   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 34280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0535   |
|    exploration_rate | 0.706    |
| time/               |          |
|    episodes         | 9844     |
|    fps              | 133      |
|    time_elapsed     | 1330     |
|    total_timesteps  | 177193   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 34298    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0434   |
|    exploration_rate | 0.706    |
| time/               |          |
|    episodes         | 9848     |
|    fps              | 133      |
|    time_elapsed     | 1330     |
|    total_timesteps  | 177256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 34313    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0437   |
|    exploration_rate | 0.705    |
| time/               |          |
|    episodes         | 9852     |
|    fps              | 133      |
|    time_elapsed     | 1330     |
|    total_timesteps  | 177313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 34328    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0334   |
|    exploration_rate | 0.705    |
| time/               |          |
|    episodes         | 9856     |
|    fps              | 133      |
|    time_elapsed     | 1330     |
|    total_timesteps  | 177373   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000623 |
|    n_updates        | 34343    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0336   |
|    exploration_rate | 0.705    |
| time/               |          |
|    episodes         | 9860     |
|    fps              | 133      |
|    time_elapsed     | 1330     |
|    total_timesteps  | 177441   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000392 |
|    n_updates        | 34360    |
----------------------------------
Eval num_timesteps=177500, episode_reward=-0.02 +/- 0.20
Episode length: 14.82 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | -0.0183  |
| rollout/            |          |
|    exploration_rate | 0.705    |
| time/               |          |
|    total_timesteps  | 177500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 34374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0337   |
|    exploration_rate | 0.705    |
| time/               |          |
|    episodes         | 9864     |
|    fps              | 133      |
|    time_elapsed     | 1331     |
|    total_timesteps  | 177508   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00543  |
|    n_updates        | 34376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0337   |
|    exploration_rate | 0.705    |
| time/               |          |
|    episodes         | 9868     |
|    fps              | 133      |
|    time_elapsed     | 1331     |
|    total_timesteps  | 177581   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 34395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0341   |
|    exploration_rate | 0.704    |
| time/               |          |
|    episodes         | 9872     |
|    fps              | 133      |
|    time_elapsed     | 1331     |
|    total_timesteps  | 177641   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000769 |
|    n_updates        | 34410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0445   |
|    exploration_rate | 0.704    |
| time/               |          |
|    episodes         | 9876     |
|    fps              | 133      |
|    time_elapsed     | 1331     |
|    total_timesteps  | 177699   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00299  |
|    n_updates        | 34424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.055    |
|    exploration_rate | 0.704    |
| time/               |          |
|    episodes         | 9880     |
|    fps              | 133      |
|    time_elapsed     | 1331     |
|    total_timesteps  | 177758   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000888 |
|    n_updates        | 34439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0446   |
|    exploration_rate | 0.704    |
| time/               |          |
|    episodes         | 9884     |
|    fps              | 133      |
|    time_elapsed     | 1331     |
|    total_timesteps  | 177833   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 34458    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0438   |
|    exploration_rate | 0.704    |
| time/               |          |
|    episodes         | 9888     |
|    fps              | 133      |
|    time_elapsed     | 1332     |
|    total_timesteps  | 177918   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00225  |
|    n_updates        | 34479    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0441   |
|    exploration_rate | 0.703    |
| time/               |          |
|    episodes         | 9892     |
|    fps              | 133      |
|    time_elapsed     | 1332     |
|    total_timesteps  | 177978   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 34494    |
----------------------------------
Eval num_timesteps=178000, episode_reward=0.14 +/- 0.41
Episode length: 14.32 +/- 1.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.3     |
|    mean_reward      | 0.144    |
| rollout/            |          |
|    exploration_rate | 0.703    |
| time/               |          |
|    total_timesteps  | 178000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 34499    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0441   |
|    exploration_rate | 0.703    |
| time/               |          |
|    episodes         | 9896     |
|    fps              | 133      |
|    time_elapsed     | 1333     |
|    total_timesteps  | 178043   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00453  |
|    n_updates        | 34510    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0641   |
|    exploration_rate | 0.703    |
| time/               |          |
|    episodes         | 9900     |
|    fps              | 133      |
|    time_elapsed     | 1333     |
|    total_timesteps  | 178108   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000827 |
|    n_updates        | 34526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0648   |
|    exploration_rate | 0.703    |
| time/               |          |
|    episodes         | 9904     |
|    fps              | 133      |
|    time_elapsed     | 1333     |
|    total_timesteps  | 178179   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00456  |
|    n_updates        | 34544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0546   |
|    exploration_rate | 0.702    |
| time/               |          |
|    episodes         | 9908     |
|    fps              | 133      |
|    time_elapsed     | 1333     |
|    total_timesteps  | 178251   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 34562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0541   |
|    exploration_rate | 0.702    |
| time/               |          |
|    episodes         | 9912     |
|    fps              | 133      |
|    time_elapsed     | 1333     |
|    total_timesteps  | 178329   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 34582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0646   |
|    exploration_rate | 0.702    |
| time/               |          |
|    episodes         | 9916     |
|    fps              | 133      |
|    time_elapsed     | 1333     |
|    total_timesteps  | 178394   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 34598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0644   |
|    exploration_rate | 0.702    |
| time/               |          |
|    episodes         | 9920     |
|    fps              | 133      |
|    time_elapsed     | 1333     |
|    total_timesteps  | 178465   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 34616    |
----------------------------------
Eval num_timesteps=178500, episode_reward=0.00 +/- 0.24
Episode length: 14.84 +/- 0.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00162  |
| rollout/            |          |
|    exploration_rate | 0.702    |
| time/               |          |
|    total_timesteps  | 178500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 34624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.054    |
|    exploration_rate | 0.702    |
| time/               |          |
|    episodes         | 9924     |
|    fps              | 133      |
|    time_elapsed     | 1334     |
|    total_timesteps  | 178539   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 34634    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0436   |
|    exploration_rate | 0.701    |
| time/               |          |
|    episodes         | 9928     |
|    fps              | 133      |
|    time_elapsed     | 1335     |
|    total_timesteps  | 178609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000672 |
|    n_updates        | 34652    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0437   |
|    exploration_rate | 0.701    |
| time/               |          |
|    episodes         | 9932     |
|    fps              | 133      |
|    time_elapsed     | 1335     |
|    total_timesteps  | 178670   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 34667    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0442   |
|    exploration_rate | 0.701    |
| time/               |          |
|    episodes         | 9936     |
|    fps              | 133      |
|    time_elapsed     | 1335     |
|    total_timesteps  | 178731   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000916 |
|    n_updates        | 34682    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0339   |
|    exploration_rate | 0.701    |
| time/               |          |
|    episodes         | 9940     |
|    fps              | 133      |
|    time_elapsed     | 1335     |
|    total_timesteps  | 178799   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 34699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0443   |
|    exploration_rate | 0.7      |
| time/               |          |
|    episodes         | 9944     |
|    fps              | 133      |
|    time_elapsed     | 1335     |
|    total_timesteps  | 178862   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00836  |
|    n_updates        | 34715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0441   |
|    exploration_rate | 0.7      |
| time/               |          |
|    episodes         | 9948     |
|    fps              | 133      |
|    time_elapsed     | 1335     |
|    total_timesteps  | 178929   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0037   |
|    n_updates        | 34732    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0238   |
|    exploration_rate | 0.7      |
| time/               |          |
|    episodes         | 9952     |
|    fps              | 134      |
|    time_elapsed     | 1335     |
|    total_timesteps  | 178993   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 34748    |
----------------------------------
Eval num_timesteps=179000, episode_reward=0.02 +/- 0.28
Episode length: 14.74 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0222   |
| rollout/            |          |
|    exploration_rate | 0.7      |
| time/               |          |
|    total_timesteps  | 179000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 34749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0137   |
|    exploration_rate | 0.7      |
| time/               |          |
|    episodes         | 9956     |
|    fps              | 133      |
|    time_elapsed     | 1336     |
|    total_timesteps  | 179057   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 34764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0137   |
|    exploration_rate | 0.7      |
| time/               |          |
|    episodes         | 9960     |
|    fps              | 133      |
|    time_elapsed     | 1336     |
|    total_timesteps  | 179124   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 34780    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.699    |
| time/               |          |
|    episodes         | 9964     |
|    fps              | 134      |
|    time_elapsed     | 1337     |
|    total_timesteps  | 179185   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00601  |
|    n_updates        | 34796    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0142   |
|    exploration_rate | 0.699    |
| time/               |          |
|    episodes         | 9968     |
|    fps              | 134      |
|    time_elapsed     | 1337     |
|    total_timesteps  | 179252   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 34812    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.699    |
| time/               |          |
|    episodes         | 9972     |
|    fps              | 134      |
|    time_elapsed     | 1337     |
|    total_timesteps  | 179318   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00398  |
|    n_updates        | 34829    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00333  |
|    exploration_rate | 0.699    |
| time/               |          |
|    episodes         | 9976     |
|    fps              | 134      |
|    time_elapsed     | 1337     |
|    total_timesteps  | 179391   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000539 |
|    n_updates        | 34847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00733 |
|    exploration_rate | 0.699    |
| time/               |          |
|    episodes         | 9980     |
|    fps              | 134      |
|    time_elapsed     | 1337     |
|    total_timesteps  | 179466   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000744 |
|    n_updates        | 34866    |
----------------------------------
Eval num_timesteps=179500, episode_reward=0.02 +/- 0.28
Episode length: 14.68 +/- 1.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0223   |
| rollout/            |          |
|    exploration_rate | 0.698    |
| time/               |          |
|    total_timesteps  | 179500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000928 |
|    n_updates        | 34874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00689 |
|    exploration_rate | 0.698    |
| time/               |          |
|    episodes         | 9984     |
|    fps              | 134      |
|    time_elapsed     | 1338     |
|    total_timesteps  | 179530   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000698 |
|    n_updates        | 34882    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00609 |
|    exploration_rate | 0.698    |
| time/               |          |
|    episodes         | 9988     |
|    fps              | 134      |
|    time_elapsed     | 1338     |
|    total_timesteps  | 179595   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 34898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00613 |
|    exploration_rate | 0.698    |
| time/               |          |
|    episodes         | 9992     |
|    fps              | 134      |
|    time_elapsed     | 1338     |
|    total_timesteps  | 179656   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 34913    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00407  |
|    exploration_rate | 0.698    |
| time/               |          |
|    episodes         | 9996     |
|    fps              | 134      |
|    time_elapsed     | 1338     |
|    total_timesteps  | 179716   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00241  |
|    n_updates        | 34928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00562 |
|    exploration_rate | 0.698    |
| time/               |          |
|    episodes         | 10000    |
|    fps              | 134      |
|    time_elapsed     | 1338     |
|    total_timesteps  | 179773   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00091  |
|    n_updates        | 34943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0155  |
|    exploration_rate | 0.697    |
| time/               |          |
|    episodes         | 10004    |
|    fps              | 134      |
|    time_elapsed     | 1338     |
|    total_timesteps  | 179840   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000934 |
|    n_updates        | 34959    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0153  |
|    exploration_rate | 0.697    |
| time/               |          |
|    episodes         | 10008    |
|    fps              | 134      |
|    time_elapsed     | 1338     |
|    total_timesteps  | 179907   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 34976    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.697    |
| time/               |          |
|    episodes         | 10012    |
|    fps              | 134      |
|    time_elapsed     | 1339     |
|    total_timesteps  | 179977   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00581  |
|    n_updates        | 34994    |
----------------------------------
Eval num_timesteps=180000, episode_reward=0.10 +/- 0.37
Episode length: 14.50 +/- 1.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.103    |
| rollout/            |          |
|    exploration_rate | 0.697    |
| time/               |          |
|    total_timesteps  | 180000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00348  |
|    n_updates        | 34999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0248  |
|    exploration_rate | 0.697    |
| time/               |          |
|    episodes         | 10016    |
|    fps              | 134      |
|    time_elapsed     | 1340     |
|    total_timesteps  | 180040   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 35009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0252  |
|    exploration_rate | 0.696    |
| time/               |          |
|    episodes         | 10020    |
|    fps              | 134      |
|    time_elapsed     | 1340     |
|    total_timesteps  | 180120   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000674 |
|    n_updates        | 35029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0251  |
|    exploration_rate | 0.696    |
| time/               |          |
|    episodes         | 10024    |
|    fps              | 134      |
|    time_elapsed     | 1340     |
|    total_timesteps  | 180191   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 35047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.696    |
| time/               |          |
|    episodes         | 10028    |
|    fps              | 134      |
|    time_elapsed     | 1340     |
|    total_timesteps  | 180256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00228  |
|    n_updates        | 35063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00501 |
|    exploration_rate | 0.696    |
| time/               |          |
|    episodes         | 10032    |
|    fps              | 134      |
|    time_elapsed     | 1340     |
|    total_timesteps  | 180321   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00364  |
|    n_updates        | 35080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00517 |
|    exploration_rate | 0.696    |
| time/               |          |
|    episodes         | 10036    |
|    fps              | 134      |
|    time_elapsed     | 1340     |
|    total_timesteps  | 180386   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 35096    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0147   |
|    exploration_rate | 0.695    |
| time/               |          |
|    episodes         | 10040    |
|    fps              | 134      |
|    time_elapsed     | 1340     |
|    total_timesteps  | 180459   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 35114    |
----------------------------------
Eval num_timesteps=180500, episode_reward=0.04 +/- 0.30
Episode length: 14.62 +/- 1.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0425   |
| rollout/            |          |
|    exploration_rate | 0.695    |
| time/               |          |
|    total_timesteps  | 180500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00253  |
|    n_updates        | 35124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0145   |
|    exploration_rate | 0.695    |
| time/               |          |
|    episodes         | 10044    |
|    fps              | 134      |
|    time_elapsed     | 1341     |
|    total_timesteps  | 180525   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 35131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0249   |
|    exploration_rate | 0.695    |
| time/               |          |
|    episodes         | 10048    |
|    fps              | 134      |
|    time_elapsed     | 1341     |
|    total_timesteps  | 180583   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00325  |
|    n_updates        | 35145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0249   |
|    exploration_rate | 0.695    |
| time/               |          |
|    episodes         | 10052    |
|    fps              | 134      |
|    time_elapsed     | 1342     |
|    total_timesteps  | 180647   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 35161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0249   |
|    exploration_rate | 0.694    |
| time/               |          |
|    episodes         | 10056    |
|    fps              | 134      |
|    time_elapsed     | 1342     |
|    total_timesteps  | 180711   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000863 |
|    n_updates        | 35177    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0249   |
|    exploration_rate | 0.694    |
| time/               |          |
|    episodes         | 10060    |
|    fps              | 134      |
|    time_elapsed     | 1342     |
|    total_timesteps  | 180779   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00739  |
|    n_updates        | 35194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0345   |
|    exploration_rate | 0.694    |
| time/               |          |
|    episodes         | 10064    |
|    fps              | 134      |
|    time_elapsed     | 1342     |
|    total_timesteps  | 180848   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 35211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0345   |
|    exploration_rate | 0.694    |
| time/               |          |
|    episodes         | 10068    |
|    fps              | 134      |
|    time_elapsed     | 1342     |
|    total_timesteps  | 180915   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00517  |
|    n_updates        | 35228    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0348   |
|    exploration_rate | 0.694    |
| time/               |          |
|    episodes         | 10072    |
|    fps              | 134      |
|    time_elapsed     | 1342     |
|    total_timesteps  | 180975   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 35243    |
----------------------------------
Eval num_timesteps=181000, episode_reward=0.00 +/- 0.24
Episode length: 14.76 +/- 0.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.002    |
| rollout/            |          |
|    exploration_rate | 0.694    |
| time/               |          |
|    total_timesteps  | 181000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000912 |
|    n_updates        | 35249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0348   |
|    exploration_rate | 0.693    |
| time/               |          |
|    episodes         | 10076    |
|    fps              | 134      |
|    time_elapsed     | 1343     |
|    total_timesteps  | 181048   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00269  |
|    n_updates        | 35261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0352   |
|    exploration_rate | 0.693    |
| time/               |          |
|    episodes         | 10080    |
|    fps              | 134      |
|    time_elapsed     | 1343     |
|    total_timesteps  | 181112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 35277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.035    |
|    exploration_rate | 0.693    |
| time/               |          |
|    episodes         | 10084    |
|    fps              | 134      |
|    time_elapsed     | 1343     |
|    total_timesteps  | 181181   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00493  |
|    n_updates        | 35295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0451   |
|    exploration_rate | 0.693    |
| time/               |          |
|    episodes         | 10088    |
|    fps              | 134      |
|    time_elapsed     | 1343     |
|    total_timesteps  | 181245   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00538  |
|    n_updates        | 35311    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0349   |
|    exploration_rate | 0.693    |
| time/               |          |
|    episodes         | 10092    |
|    fps              | 134      |
|    time_elapsed     | 1344     |
|    total_timesteps  | 181310   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 35327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0248   |
|    exploration_rate | 0.692    |
| time/               |          |
|    episodes         | 10096    |
|    fps              | 134      |
|    time_elapsed     | 1344     |
|    total_timesteps  | 181372   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 35342    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0142   |
|    exploration_rate | 0.692    |
| time/               |          |
|    episodes         | 10100    |
|    fps              | 134      |
|    time_elapsed     | 1344     |
|    total_timesteps  | 181446   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 35361    |
----------------------------------
Eval num_timesteps=181500, episode_reward=-0.06 +/- 0.00
Episode length: 15.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.059   |
| rollout/            |          |
|    exploration_rate | 0.692    |
| time/               |          |
|    total_timesteps  | 181500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0039   |
|    n_updates        | 35374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.692    |
| time/               |          |
|    episodes         | 10104    |
|    fps              | 134      |
|    time_elapsed     | 1345     |
|    total_timesteps  | 181509   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 35377    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0144   |
|    exploration_rate | 0.692    |
| time/               |          |
|    episodes         | 10108    |
|    fps              | 134      |
|    time_elapsed     | 1345     |
|    total_timesteps  | 181574   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 35393    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0351   |
|    exploration_rate | 0.692    |
| time/               |          |
|    episodes         | 10112    |
|    fps              | 135      |
|    time_elapsed     | 1345     |
|    total_timesteps  | 181627   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000932 |
|    n_updates        | 35406    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0552   |
|    exploration_rate | 0.691    |
| time/               |          |
|    episodes         | 10116    |
|    fps              | 135      |
|    time_elapsed     | 1345     |
|    total_timesteps  | 181688   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 35421    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.066    |
|    exploration_rate | 0.691    |
| time/               |          |
|    episodes         | 10120    |
|    fps              | 135      |
|    time_elapsed     | 1345     |
|    total_timesteps  | 181746   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00488  |
|    n_updates        | 35436    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0664   |
|    exploration_rate | 0.691    |
| time/               |          |
|    episodes         | 10124    |
|    fps              | 135      |
|    time_elapsed     | 1345     |
|    total_timesteps  | 181809   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 35452    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0559   |
|    exploration_rate | 0.691    |
| time/               |          |
|    episodes         | 10128    |
|    fps              | 135      |
|    time_elapsed     | 1345     |
|    total_timesteps  | 181885   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 35471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0559   |
|    exploration_rate | 0.69     |
| time/               |          |
|    episodes         | 10132    |
|    fps              | 135      |
|    time_elapsed     | 1345     |
|    total_timesteps  | 181950   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00396  |
|    n_updates        | 35487    |
----------------------------------
Eval num_timesteps=182000, episode_reward=0.06 +/- 0.33
Episode length: 14.54 +/- 1.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.0629   |
| rollout/            |          |
|    exploration_rate | 0.69     |
| time/               |          |
|    total_timesteps  | 182000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 35499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0558   |
|    exploration_rate | 0.69     |
| time/               |          |
|    episodes         | 10136    |
|    fps              | 135      |
|    time_elapsed     | 1346     |
|    total_timesteps  | 182018   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00892  |
|    n_updates        | 35504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0462   |
|    exploration_rate | 0.69     |
| time/               |          |
|    episodes         | 10140    |
|    fps              | 135      |
|    time_elapsed     | 1346     |
|    total_timesteps  | 182079   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00355  |
|    n_updates        | 35519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0363   |
|    exploration_rate | 0.69     |
| time/               |          |
|    episodes         | 10144    |
|    fps              | 135      |
|    time_elapsed     | 1347     |
|    total_timesteps  | 182143   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 35535    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0261   |
|    exploration_rate | 0.69     |
| time/               |          |
|    episodes         | 10148    |
|    fps              | 135      |
|    time_elapsed     | 1347     |
|    total_timesteps  | 182206   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000736 |
|    n_updates        | 35551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0261   |
|    exploration_rate | 0.689    |
| time/               |          |
|    episodes         | 10152    |
|    fps              | 135      |
|    time_elapsed     | 1347     |
|    total_timesteps  | 182271   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00575  |
|    n_updates        | 35567    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.689    |
| time/               |          |
|    episodes         | 10156    |
|    fps              | 135      |
|    time_elapsed     | 1347     |
|    total_timesteps  | 182340   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00577  |
|    n_updates        | 35584    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.689    |
| time/               |          |
|    episodes         | 10160    |
|    fps              | 135      |
|    time_elapsed     | 1347     |
|    total_timesteps  | 182408   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000832 |
|    n_updates        | 35601    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0159   |
|    exploration_rate | 0.689    |
| time/               |          |
|    episodes         | 10164    |
|    fps              | 135      |
|    time_elapsed     | 1347     |
|    total_timesteps  | 182476   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 35618    |
----------------------------------
Eval num_timesteps=182500, episode_reward=-0.02 +/- 0.20
Episode length: 14.86 +/- 0.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0184  |
| rollout/            |          |
|    exploration_rate | 0.689    |
| time/               |          |
|    total_timesteps  | 182500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000958 |
|    n_updates        | 35624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.016    |
|    exploration_rate | 0.689    |
| time/               |          |
|    episodes         | 10168    |
|    fps              | 135      |
|    time_elapsed     | 1348     |
|    total_timesteps  | 182541   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 35635    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0257   |
|    exploration_rate | 0.688    |
| time/               |          |
|    episodes         | 10172    |
|    fps              | 135      |
|    time_elapsed     | 1348     |
|    total_timesteps  | 182608   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 35651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.688    |
| time/               |          |
|    episodes         | 10176    |
|    fps              | 135      |
|    time_elapsed     | 1348     |
|    total_timesteps  | 182676   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000898 |
|    n_updates        | 35668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0258   |
|    exploration_rate | 0.688    |
| time/               |          |
|    episodes         | 10180    |
|    fps              | 135      |
|    time_elapsed     | 1348     |
|    total_timesteps  | 182742   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00269  |
|    n_updates        | 35685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0462   |
|    exploration_rate | 0.688    |
| time/               |          |
|    episodes         | 10184    |
|    fps              | 135      |
|    time_elapsed     | 1348     |
|    total_timesteps  | 182802   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00341  |
|    n_updates        | 35700    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0463   |
|    exploration_rate | 0.687    |
| time/               |          |
|    episodes         | 10188    |
|    fps              | 135      |
|    time_elapsed     | 1349     |
|    total_timesteps  | 182862   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00436  |
|    n_updates        | 35715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0463   |
|    exploration_rate | 0.687    |
| time/               |          |
|    episodes         | 10192    |
|    fps              | 135      |
|    time_elapsed     | 1349     |
|    total_timesteps  | 182929   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 35732    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0562   |
|    exploration_rate | 0.687    |
| time/               |          |
|    episodes         | 10196    |
|    fps              | 135      |
|    time_elapsed     | 1349     |
|    total_timesteps  | 182992   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 35747    |
----------------------------------
Eval num_timesteps=183000, episode_reward=0.02 +/- 0.28
Episode length: 14.68 +/- 1.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0223   |
| rollout/            |          |
|    exploration_rate | 0.687    |
| time/               |          |
|    total_timesteps  | 183000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 35749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0666   |
|    exploration_rate | 0.687    |
| time/               |          |
|    episodes         | 10200    |
|    fps              | 135      |
|    time_elapsed     | 1350     |
|    total_timesteps  | 183055   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0081   |
|    n_updates        | 35763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0667   |
|    exploration_rate | 0.687    |
| time/               |          |
|    episodes         | 10204    |
|    fps              | 135      |
|    time_elapsed     | 1350     |
|    total_timesteps  | 183116   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000734 |
|    n_updates        | 35778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0665   |
|    exploration_rate | 0.686    |
| time/               |          |
|    episodes         | 10208    |
|    fps              | 135      |
|    time_elapsed     | 1350     |
|    total_timesteps  | 183186   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 35796    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.046    |
|    exploration_rate | 0.686    |
| time/               |          |
|    episodes         | 10212    |
|    fps              | 135      |
|    time_elapsed     | 1350     |
|    total_timesteps  | 183252   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00096  |
|    n_updates        | 35812    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.686    |
| time/               |          |
|    episodes         | 10216    |
|    fps              | 135      |
|    time_elapsed     | 1350     |
|    total_timesteps  | 183316   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 35828    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0157   |
|    exploration_rate | 0.686    |
| time/               |          |
|    episodes         | 10220    |
|    fps              | 135      |
|    time_elapsed     | 1350     |
|    total_timesteps  | 183379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 35844    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0258   |
|    exploration_rate | 0.686    |
| time/               |          |
|    episodes         | 10224    |
|    fps              | 135      |
|    time_elapsed     | 1350     |
|    total_timesteps  | 183439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 35859    |
----------------------------------
Eval num_timesteps=183500, episode_reward=0.02 +/- 0.28
Episode length: 14.68 +/- 1.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0223   |
| rollout/            |          |
|    exploration_rate | 0.685    |
| time/               |          |
|    total_timesteps  | 183500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000612 |
|    n_updates        | 35874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0262   |
|    exploration_rate | 0.685    |
| time/               |          |
|    episodes         | 10228    |
|    fps              | 135      |
|    time_elapsed     | 1351     |
|    total_timesteps  | 183505   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 35876    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.026    |
|    exploration_rate | 0.685    |
| time/               |          |
|    episodes         | 10232    |
|    fps              | 135      |
|    time_elapsed     | 1351     |
|    total_timesteps  | 183574   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000918 |
|    n_updates        | 35893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.685    |
| time/               |          |
|    episodes         | 10236    |
|    fps              | 135      |
|    time_elapsed     | 1351     |
|    total_timesteps  | 183646   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00315  |
|    n_updates        | 35911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0158   |
|    exploration_rate | 0.685    |
| time/               |          |
|    episodes         | 10240    |
|    fps              | 135      |
|    time_elapsed     | 1351     |
|    total_timesteps  | 183710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 35927    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.684    |
| time/               |          |
|    episodes         | 10244    |
|    fps              | 135      |
|    time_elapsed     | 1351     |
|    total_timesteps  | 183779   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00203  |
|    n_updates        | 35944    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.684    |
| time/               |          |
|    episodes         | 10248    |
|    fps              | 135      |
|    time_elapsed     | 1352     |
|    total_timesteps  | 183842   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 35960    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.684    |
| time/               |          |
|    episodes         | 10252    |
|    fps              | 136      |
|    time_elapsed     | 1352     |
|    total_timesteps  | 183921   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 35980    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0354   |
|    exploration_rate | 0.684    |
| time/               |          |
|    episodes         | 10256    |
|    fps              | 136      |
|    time_elapsed     | 1352     |
|    total_timesteps  | 183981   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 35995    |
----------------------------------
Eval num_timesteps=184000, episode_reward=0.10 +/- 0.37
Episode length: 14.50 +/- 1.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.103    |
| rollout/            |          |
|    exploration_rate | 0.684    |
| time/               |          |
|    total_timesteps  | 184000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 35999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0355   |
|    exploration_rate | 0.684    |
| time/               |          |
|    episodes         | 10260    |
|    fps              | 135      |
|    time_elapsed     | 1353     |
|    total_timesteps  | 184047   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00255  |
|    n_updates        | 36011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.035    |
|    exploration_rate | 0.683    |
| time/               |          |
|    episodes         | 10264    |
|    fps              | 136      |
|    time_elapsed     | 1353     |
|    total_timesteps  | 184126   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 36031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0452   |
|    exploration_rate | 0.683    |
| time/               |          |
|    episodes         | 10268    |
|    fps              | 136      |
|    time_elapsed     | 1353     |
|    total_timesteps  | 184188   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00372  |
|    n_updates        | 36046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0353   |
|    exploration_rate | 0.683    |
| time/               |          |
|    episodes         | 10272    |
|    fps              | 136      |
|    time_elapsed     | 1353     |
|    total_timesteps  | 184251   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 36062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0457   |
|    exploration_rate | 0.683    |
| time/               |          |
|    episodes         | 10276    |
|    fps              | 136      |
|    time_elapsed     | 1353     |
|    total_timesteps  | 184311   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 36077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0456   |
|    exploration_rate | 0.682    |
| time/               |          |
|    episodes         | 10280    |
|    fps              | 136      |
|    time_elapsed     | 1353     |
|    total_timesteps  | 184379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 36094    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.682    |
| time/               |          |
|    episodes         | 10284    |
|    fps              | 136      |
|    time_elapsed     | 1353     |
|    total_timesteps  | 184446   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 36111    |
----------------------------------
Eval num_timesteps=184500, episode_reward=-0.02 +/- 0.20
Episode length: 14.84 +/- 0.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | -0.0184  |
| rollout/            |          |
|    exploration_rate | 0.682    |
| time/               |          |
|    total_timesteps  | 184500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 36124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0148   |
|    exploration_rate | 0.682    |
| time/               |          |
|    episodes         | 10288    |
|    fps              | 136      |
|    time_elapsed     | 1355     |
|    total_timesteps  | 184519   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 36129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.682    |
| time/               |          |
|    episodes         | 10292    |
|    fps              | 136      |
|    time_elapsed     | 1355     |
|    total_timesteps  | 184580   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 36144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0148   |
|    exploration_rate | 0.682    |
| time/               |          |
|    episodes         | 10296    |
|    fps              | 136      |
|    time_elapsed     | 1355     |
|    total_timesteps  | 184649   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000659 |
|    n_updates        | 36162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00471  |
|    exploration_rate | 0.681    |
| time/               |          |
|    episodes         | 10300    |
|    fps              | 136      |
|    time_elapsed     | 1355     |
|    total_timesteps  | 184714   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00234  |
|    n_updates        | 36178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00435  |
|    exploration_rate | 0.681    |
| time/               |          |
|    episodes         | 10304    |
|    fps              | 136      |
|    time_elapsed     | 1355     |
|    total_timesteps  | 184784   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 36195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.681    |
| time/               |          |
|    episodes         | 10308    |
|    fps              | 136      |
|    time_elapsed     | 1355     |
|    total_timesteps  | 184847   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 36211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0148   |
|    exploration_rate | 0.681    |
| time/               |          |
|    episodes         | 10312    |
|    fps              | 136      |
|    time_elapsed     | 1355     |
|    total_timesteps  | 184910   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000802 |
|    n_updates        | 36227    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.68     |
| time/               |          |
|    episodes         | 10316    |
|    fps              | 136      |
|    time_elapsed     | 1355     |
|    total_timesteps  | 184977   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000811 |
|    n_updates        | 36244    |
----------------------------------
Eval num_timesteps=185000, episode_reward=0.10 +/- 0.37
Episode length: 14.32 +/- 1.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.3     |
|    mean_reward      | 0.104    |
| rollout/            |          |
|    exploration_rate | 0.68     |
| time/               |          |
|    total_timesteps  | 185000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 36249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0142   |
|    exploration_rate | 0.68     |
| time/               |          |
|    episodes         | 10320    |
|    fps              | 136      |
|    time_elapsed     | 1356     |
|    total_timesteps  | 185050   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 36262    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00398  |
|    exploration_rate | 0.68     |
| time/               |          |
|    episodes         | 10324    |
|    fps              | 136      |
|    time_elapsed     | 1356     |
|    total_timesteps  | 185116   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 36278    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.68     |
| time/               |          |
|    episodes         | 10328    |
|    fps              | 136      |
|    time_elapsed     | 1357     |
|    total_timesteps  | 185184   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00528  |
|    n_updates        | 36295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0037   |
|    exploration_rate | 0.68     |
| time/               |          |
|    episodes         | 10332    |
|    fps              | 136      |
|    time_elapsed     | 1357     |
|    total_timesteps  | 185258   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 36314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0041   |
|    exploration_rate | 0.679    |
| time/               |          |
|    episodes         | 10336    |
|    fps              | 136      |
|    time_elapsed     | 1357     |
|    total_timesteps  | 185320   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00697  |
|    n_updates        | 36329    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00394  |
|    exploration_rate | 0.679    |
| time/               |          |
|    episodes         | 10340    |
|    fps              | 136      |
|    time_elapsed     | 1357     |
|    total_timesteps  | 185388   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 36346    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0243   |
|    exploration_rate | 0.679    |
| time/               |          |
|    episodes         | 10344    |
|    fps              | 136      |
|    time_elapsed     | 1357     |
|    total_timesteps  | 185448   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 36361    |
----------------------------------
Eval num_timesteps=185500, episode_reward=0.04 +/- 0.30
Episode length: 14.64 +/- 1.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0425   |
| rollout/            |          |
|    exploration_rate | 0.679    |
| time/               |          |
|    total_timesteps  | 185500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000919 |
|    n_updates        | 36374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0141   |
|    exploration_rate | 0.679    |
| time/               |          |
|    episodes         | 10348    |
|    fps              | 136      |
|    time_elapsed     | 1358     |
|    total_timesteps  | 185518   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00286  |
|    n_updates        | 36379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0248   |
|    exploration_rate | 0.679    |
| time/               |          |
|    episodes         | 10352    |
|    fps              | 136      |
|    time_elapsed     | 1358     |
|    total_timesteps  | 185578   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00231  |
|    n_updates        | 36394    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0248   |
|    exploration_rate | 0.678    |
| time/               |          |
|    episodes         | 10356    |
|    fps              | 136      |
|    time_elapsed     | 1358     |
|    total_timesteps  | 185638   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000831 |
|    n_updates        | 36409    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0451   |
|    exploration_rate | 0.678    |
| time/               |          |
|    episodes         | 10360    |
|    fps              | 136      |
|    time_elapsed     | 1358     |
|    total_timesteps  | 185695   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00773  |
|    n_updates        | 36423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0457   |
|    exploration_rate | 0.678    |
| time/               |          |
|    episodes         | 10364    |
|    fps              | 136      |
|    time_elapsed     | 1358     |
|    total_timesteps  | 185760   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 36439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0452   |
|    exploration_rate | 0.678    |
| time/               |          |
|    episodes         | 10368    |
|    fps              | 136      |
|    time_elapsed     | 1359     |
|    total_timesteps  | 185834   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000452 |
|    n_updates        | 36458    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0452   |
|    exploration_rate | 0.677    |
| time/               |          |
|    episodes         | 10372    |
|    fps              | 136      |
|    time_elapsed     | 1359     |
|    total_timesteps  | 185897   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00926  |
|    n_updates        | 36474    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0451   |
|    exploration_rate | 0.677    |
| time/               |          |
|    episodes         | 10376    |
|    fps              | 136      |
|    time_elapsed     | 1359     |
|    total_timesteps  | 185959   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 36489    |
----------------------------------
Eval num_timesteps=186000, episode_reward=0.08 +/- 0.35
Episode length: 14.44 +/- 1.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.4     |
|    mean_reward      | 0.0834   |
| rollout/            |          |
|    exploration_rate | 0.677    |
| time/               |          |
|    total_timesteps  | 186000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 36499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0453   |
|    exploration_rate | 0.677    |
| time/               |          |
|    episodes         | 10380    |
|    fps              | 136      |
|    time_elapsed     | 1360     |
|    total_timesteps  | 186022   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00266  |
|    n_updates        | 36505    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0454   |
|    exploration_rate | 0.677    |
| time/               |          |
|    episodes         | 10384    |
|    fps              | 136      |
|    time_elapsed     | 1360     |
|    total_timesteps  | 186088   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 36521    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0558   |
|    exploration_rate | 0.677    |
| time/               |          |
|    episodes         | 10388    |
|    fps              | 136      |
|    time_elapsed     | 1360     |
|    total_timesteps  | 186150   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0103   |
|    n_updates        | 36537    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0456   |
|    exploration_rate | 0.676    |
| time/               |          |
|    episodes         | 10392    |
|    fps              | 136      |
|    time_elapsed     | 1360     |
|    total_timesteps  | 186215   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000754 |
|    n_updates        | 36553    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.045    |
|    exploration_rate | 0.676    |
| time/               |          |
|    episodes         | 10396    |
|    fps              | 136      |
|    time_elapsed     | 1360     |
|    total_timesteps  | 186299   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0029   |
|    n_updates        | 36574    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0452   |
|    exploration_rate | 0.676    |
| time/               |          |
|    episodes         | 10400    |
|    fps              | 136      |
|    time_elapsed     | 1360     |
|    total_timesteps  | 186359   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00528  |
|    n_updates        | 36589    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0456   |
|    exploration_rate | 0.676    |
| time/               |          |
|    episodes         | 10404    |
|    fps              | 136      |
|    time_elapsed     | 1360     |
|    total_timesteps  | 186420   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 36604    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0355   |
|    exploration_rate | 0.675    |
| time/               |          |
|    episodes         | 10408    |
|    fps              | 137      |
|    time_elapsed     | 1361     |
|    total_timesteps  | 186486   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 36621    |
----------------------------------
Eval num_timesteps=186500, episode_reward=0.08 +/- 0.35
Episode length: 14.46 +/- 1.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.0832   |
| rollout/            |          |
|    exploration_rate | 0.675    |
| time/               |          |
|    total_timesteps  | 186500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 36624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0456   |
|    exploration_rate | 0.675    |
| time/               |          |
|    episodes         | 10412    |
|    fps              | 136      |
|    time_elapsed     | 1362     |
|    total_timesteps  | 186546   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00261  |
|    n_updates        | 36636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0454   |
|    exploration_rate | 0.675    |
| time/               |          |
|    episodes         | 10416    |
|    fps              | 136      |
|    time_elapsed     | 1362     |
|    total_timesteps  | 186617   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 36654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0456   |
|    exploration_rate | 0.675    |
| time/               |          |
|    episodes         | 10420    |
|    fps              | 137      |
|    time_elapsed     | 1362     |
|    total_timesteps  | 186687   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00762  |
|    n_updates        | 36671    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0554   |
|    exploration_rate | 0.675    |
| time/               |          |
|    episodes         | 10424    |
|    fps              | 137      |
|    time_elapsed     | 1362     |
|    total_timesteps  | 186757   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 36689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0445   |
|    exploration_rate | 0.674    |
| time/               |          |
|    episodes         | 10428    |
|    fps              | 137      |
|    time_elapsed     | 1362     |
|    total_timesteps  | 186849   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000803 |
|    n_updates        | 36712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0546   |
|    exploration_rate | 0.674    |
| time/               |          |
|    episodes         | 10432    |
|    fps              | 137      |
|    time_elapsed     | 1362     |
|    total_timesteps  | 186919   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000814 |
|    n_updates        | 36729    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0645   |
|    exploration_rate | 0.674    |
| time/               |          |
|    episodes         | 10436    |
|    fps              | 137      |
|    time_elapsed     | 1362     |
|    total_timesteps  | 186985   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 36746    |
----------------------------------
Eval num_timesteps=187000, episode_reward=0.06 +/- 0.33
Episode length: 14.58 +/- 1.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0628   |
| rollout/            |          |
|    exploration_rate | 0.674    |
| time/               |          |
|    total_timesteps  | 187000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00476  |
|    n_updates        | 36749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0645   |
|    exploration_rate | 0.674    |
| time/               |          |
|    episodes         | 10440    |
|    fps              | 137      |
|    time_elapsed     | 1363     |
|    total_timesteps  | 187053   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 36763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0443   |
|    exploration_rate | 0.673    |
| time/               |          |
|    episodes         | 10444    |
|    fps              | 137      |
|    time_elapsed     | 1363     |
|    total_timesteps  | 187116   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 36778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0443   |
|    exploration_rate | 0.673    |
| time/               |          |
|    episodes         | 10448    |
|    fps              | 137      |
|    time_elapsed     | 1364     |
|    total_timesteps  | 187186   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000973 |
|    n_updates        | 36796    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0441   |
|    exploration_rate | 0.673    |
| time/               |          |
|    episodes         | 10452    |
|    fps              | 137      |
|    time_elapsed     | 1364     |
|    total_timesteps  | 187253   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 36813    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0442   |
|    exploration_rate | 0.673    |
| time/               |          |
|    episodes         | 10456    |
|    fps              | 137      |
|    time_elapsed     | 1364     |
|    total_timesteps  | 187310   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 36827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0239   |
|    exploration_rate | 0.673    |
| time/               |          |
|    episodes         | 10460    |
|    fps              | 137      |
|    time_elapsed     | 1364     |
|    total_timesteps  | 187374   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00373  |
|    n_updates        | 36843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0341   |
|    exploration_rate | 0.672    |
| time/               |          |
|    episodes         | 10464    |
|    fps              | 137      |
|    time_elapsed     | 1364     |
|    total_timesteps  | 187433   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00238  |
|    n_updates        | 36858    |
----------------------------------
Eval num_timesteps=187500, episode_reward=0.04 +/- 0.30
Episode length: 14.66 +/- 1.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0424   |
| rollout/            |          |
|    exploration_rate | 0.672    |
| time/               |          |
|    total_timesteps  | 187500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 36874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0344   |
|    exploration_rate | 0.672    |
| time/               |          |
|    episodes         | 10468    |
|    fps              | 137      |
|    time_elapsed     | 1365     |
|    total_timesteps  | 187501   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 36875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0339   |
|    exploration_rate | 0.672    |
| time/               |          |
|    episodes         | 10472    |
|    fps              | 137      |
|    time_elapsed     | 1365     |
|    total_timesteps  | 187576   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 36893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0235   |
|    exploration_rate | 0.672    |
| time/               |          |
|    episodes         | 10476    |
|    fps              | 137      |
|    time_elapsed     | 1366     |
|    total_timesteps  | 187649   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000868 |
|    n_updates        | 36912    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.023    |
|    exploration_rate | 0.671    |
| time/               |          |
|    episodes         | 10480    |
|    fps              | 137      |
|    time_elapsed     | 1366     |
|    total_timesteps  | 187724   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 36930    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0232   |
|    exploration_rate | 0.671    |
| time/               |          |
|    episodes         | 10484    |
|    fps              | 137      |
|    time_elapsed     | 1366     |
|    total_timesteps  | 187785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 36946    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0131   |
|    exploration_rate | 0.671    |
| time/               |          |
|    episodes         | 10488    |
|    fps              | 137      |
|    time_elapsed     | 1366     |
|    total_timesteps  | 187849   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 36962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0233   |
|    exploration_rate | 0.671    |
| time/               |          |
|    episodes         | 10492    |
|    fps              | 137      |
|    time_elapsed     | 1366     |
|    total_timesteps  | 187908   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 36976    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0242   |
|    exploration_rate | 0.671    |
| time/               |          |
|    episodes         | 10496    |
|    fps              | 137      |
|    time_elapsed     | 1366     |
|    total_timesteps  | 187971   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00212  |
|    n_updates        | 36992    |
----------------------------------
Eval num_timesteps=188000, episode_reward=-0.02 +/- 0.20
Episode length: 15.22 +/- 1.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | -0.0199  |
| rollout/            |          |
|    exploration_rate | 0.67     |
| time/               |          |
|    total_timesteps  | 188000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00246  |
|    n_updates        | 36999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0238   |
|    exploration_rate | 0.67     |
| time/               |          |
|    episodes         | 10500    |
|    fps              | 137      |
|    time_elapsed     | 1367     |
|    total_timesteps  | 188039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00199  |
|    n_updates        | 37009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0339   |
|    exploration_rate | 0.67     |
| time/               |          |
|    episodes         | 10504    |
|    fps              | 137      |
|    time_elapsed     | 1367     |
|    total_timesteps  | 188099   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00732  |
|    n_updates        | 37024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0341   |
|    exploration_rate | 0.67     |
| time/               |          |
|    episodes         | 10508    |
|    fps              | 137      |
|    time_elapsed     | 1367     |
|    total_timesteps  | 188161   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00591  |
|    n_updates        | 37040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0237   |
|    exploration_rate | 0.67     |
| time/               |          |
|    episodes         | 10512    |
|    fps              | 137      |
|    time_elapsed     | 1367     |
|    total_timesteps  | 188229   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000927 |
|    n_updates        | 37057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.034    |
|    exploration_rate | 0.669    |
| time/               |          |
|    episodes         | 10516    |
|    fps              | 137      |
|    time_elapsed     | 1368     |
|    total_timesteps  | 188294   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 37073    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0343   |
|    exploration_rate | 0.669    |
| time/               |          |
|    episodes         | 10520    |
|    fps              | 137      |
|    time_elapsed     | 1368     |
|    total_timesteps  | 188357   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00544  |
|    n_updates        | 37089    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0244   |
|    exploration_rate | 0.669    |
| time/               |          |
|    episodes         | 10524    |
|    fps              | 137      |
|    time_elapsed     | 1368     |
|    total_timesteps  | 188423   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 37105    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.669    |
| time/               |          |
|    episodes         | 10528    |
|    fps              | 137      |
|    time_elapsed     | 1368     |
|    total_timesteps  | 188485   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 37121    |
----------------------------------
Eval num_timesteps=188500, episode_reward=-0.02 +/- 0.20
Episode length: 14.82 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | -0.0183  |
| rollout/            |          |
|    exploration_rate | 0.669    |
| time/               |          |
|    total_timesteps  | 188500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 37124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.669    |
| time/               |          |
|    episodes         | 10532    |
|    fps              | 137      |
|    time_elapsed     | 1369     |
|    total_timesteps  | 188562   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 37140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0258   |
|    exploration_rate | 0.668    |
| time/               |          |
|    episodes         | 10536    |
|    fps              | 137      |
|    time_elapsed     | 1369     |
|    total_timesteps  | 188616   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 37153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.668    |
| time/               |          |
|    episodes         | 10540    |
|    fps              | 137      |
|    time_elapsed     | 1369     |
|    total_timesteps  | 188681   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00341  |
|    n_updates        | 37170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.668    |
| time/               |          |
|    episodes         | 10544    |
|    fps              | 137      |
|    time_elapsed     | 1369     |
|    total_timesteps  | 188751   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 37187    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.668    |
| time/               |          |
|    episodes         | 10548    |
|    fps              | 137      |
|    time_elapsed     | 1369     |
|    total_timesteps  | 188822   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000995 |
|    n_updates        | 37205    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.668    |
| time/               |          |
|    episodes         | 10552    |
|    fps              | 137      |
|    time_elapsed     | 1369     |
|    total_timesteps  | 188882   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00238  |
|    n_updates        | 37220    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.667    |
| time/               |          |
|    episodes         | 10556    |
|    fps              | 137      |
|    time_elapsed     | 1369     |
|    total_timesteps  | 188947   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 37236    |
----------------------------------
Eval num_timesteps=189000, episode_reward=0.04 +/- 0.30
Episode length: 14.70 +/- 1.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0423   |
| rollout/            |          |
|    exploration_rate | 0.667    |
| time/               |          |
|    total_timesteps  | 189000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00084  |
|    n_updates        | 37249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0155   |
|    exploration_rate | 0.667    |
| time/               |          |
|    episodes         | 10560    |
|    fps              | 137      |
|    time_elapsed     | 1370     |
|    total_timesteps  | 189012   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 37252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00545  |
|    exploration_rate | 0.667    |
| time/               |          |
|    episodes         | 10564    |
|    fps              | 137      |
|    time_elapsed     | 1371     |
|    total_timesteps  | 189073   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 37268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00469 |
|    exploration_rate | 0.667    |
| time/               |          |
|    episodes         | 10568    |
|    fps              | 137      |
|    time_elapsed     | 1371     |
|    total_timesteps  | 189144   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 37285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00421 |
|    exploration_rate | 0.666    |
| time/               |          |
|    episodes         | 10572    |
|    fps              | 137      |
|    time_elapsed     | 1371     |
|    total_timesteps  | 189207   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 37301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00373 |
|    exploration_rate | 0.666    |
| time/               |          |
|    episodes         | 10576    |
|    fps              | 138      |
|    time_elapsed     | 1371     |
|    total_timesteps  | 189268   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 37316    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00663  |
|    exploration_rate | 0.666    |
| time/               |          |
|    episodes         | 10580    |
|    fps              | 138      |
|    time_elapsed     | 1371     |
|    total_timesteps  | 189334   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 37333    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00659  |
|    exploration_rate | 0.666    |
| time/               |          |
|    episodes         | 10584    |
|    fps              | 138      |
|    time_elapsed     | 1371     |
|    total_timesteps  | 189396   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00755  |
|    n_updates        | 37348    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00655  |
|    exploration_rate | 0.666    |
| time/               |          |
|    episodes         | 10588    |
|    fps              | 138      |
|    time_elapsed     | 1371     |
|    total_timesteps  | 189461   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000748 |
|    n_updates        | 37365    |
----------------------------------
Eval num_timesteps=189500, episode_reward=0.02 +/- 0.28
Episode length: 14.88 +/- 0.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.0216   |
| rollout/            |          |
|    exploration_rate | 0.665    |
| time/               |          |
|    total_timesteps  | 189500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 37374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00368 |
|    exploration_rate | 0.665    |
| time/               |          |
|    episodes         | 10592    |
|    fps              | 138      |
|    time_elapsed     | 1372     |
|    total_timesteps  | 189526   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 37381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00412 |
|    exploration_rate | 0.665    |
| time/               |          |
|    episodes         | 10596    |
|    fps              | 138      |
|    time_elapsed     | 1372     |
|    total_timesteps  | 189600   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000857 |
|    n_updates        | 37399    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0158   |
|    exploration_rate | 0.665    |
| time/               |          |
|    episodes         | 10600    |
|    fps              | 138      |
|    time_elapsed     | 1373     |
|    total_timesteps  | 189669   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 37417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0157   |
|    exploration_rate | 0.665    |
| time/               |          |
|    episodes         | 10604    |
|    fps              | 138      |
|    time_elapsed     | 1373     |
|    total_timesteps  | 189733   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 37433    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0255   |
|    exploration_rate | 0.664    |
| time/               |          |
|    episodes         | 10608    |
|    fps              | 138      |
|    time_elapsed     | 1373     |
|    total_timesteps  | 189799   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000955 |
|    n_updates        | 37449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0459   |
|    exploration_rate | 0.664    |
| time/               |          |
|    episodes         | 10612    |
|    fps              | 138      |
|    time_elapsed     | 1373     |
|    total_timesteps  | 189857   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 37464    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0462   |
|    exploration_rate | 0.664    |
| time/               |          |
|    episodes         | 10616    |
|    fps              | 138      |
|    time_elapsed     | 1373     |
|    total_timesteps  | 189915   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00744  |
|    n_updates        | 37478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0462   |
|    exploration_rate | 0.664    |
| time/               |          |
|    episodes         | 10620    |
|    fps              | 138      |
|    time_elapsed     | 1373     |
|    total_timesteps  | 189979   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 37494    |
----------------------------------
Eval num_timesteps=190000, episode_reward=0.00 +/- 0.24
Episode length: 14.76 +/- 1.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.0019   |
| rollout/            |          |
|    exploration_rate | 0.664    |
| time/               |          |
|    total_timesteps  | 190000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 37499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0461   |
|    exploration_rate | 0.664    |
| time/               |          |
|    episodes         | 10624    |
|    fps              | 138      |
|    time_elapsed     | 1374     |
|    total_timesteps  | 190047   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00725  |
|    n_updates        | 37511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.046    |
|    exploration_rate | 0.663    |
| time/               |          |
|    episodes         | 10628    |
|    fps              | 138      |
|    time_elapsed     | 1374     |
|    total_timesteps  | 190110   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00332  |
|    n_updates        | 37527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0466   |
|    exploration_rate | 0.663    |
| time/               |          |
|    episodes         | 10632    |
|    fps              | 138      |
|    time_elapsed     | 1374     |
|    total_timesteps  | 190173   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 37543    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0262   |
|    exploration_rate | 0.663    |
| time/               |          |
|    episodes         | 10636    |
|    fps              | 138      |
|    time_elapsed     | 1374     |
|    total_timesteps  | 190237   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0021   |
|    n_updates        | 37559    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0264   |
|    exploration_rate | 0.663    |
| time/               |          |
|    episodes         | 10640    |
|    fps              | 138      |
|    time_elapsed     | 1375     |
|    total_timesteps  | 190297   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00228  |
|    n_updates        | 37574    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0265   |
|    exploration_rate | 0.663    |
| time/               |          |
|    episodes         | 10644    |
|    fps              | 138      |
|    time_elapsed     | 1375     |
|    total_timesteps  | 190365   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00409  |
|    n_updates        | 37591    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0268   |
|    exploration_rate | 0.662    |
| time/               |          |
|    episodes         | 10648    |
|    fps              | 138      |
|    time_elapsed     | 1375     |
|    total_timesteps  | 190427   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000805 |
|    n_updates        | 37606    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.662    |
| time/               |          |
|    episodes         | 10652    |
|    fps              | 138      |
|    time_elapsed     | 1375     |
|    total_timesteps  | 190489   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 37622    |
----------------------------------
Eval num_timesteps=190500, episode_reward=0.00 +/- 0.24
Episode length: 14.92 +/- 1.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.00132  |
| rollout/            |          |
|    exploration_rate | 0.662    |
| time/               |          |
|    total_timesteps  | 190500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00709  |
|    n_updates        | 37624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.662    |
| time/               |          |
|    episodes         | 10656    |
|    fps              | 138      |
|    time_elapsed     | 1376     |
|    total_timesteps  | 190554   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 37638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.662    |
| time/               |          |
|    episodes         | 10660    |
|    fps              | 138      |
|    time_elapsed     | 1376     |
|    total_timesteps  | 190622   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 37655    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.661    |
| time/               |          |
|    episodes         | 10664    |
|    fps              | 138      |
|    time_elapsed     | 1376     |
|    total_timesteps  | 190691   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 37672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0367   |
|    exploration_rate | 0.661    |
| time/               |          |
|    episodes         | 10668    |
|    fps              | 138      |
|    time_elapsed     | 1376     |
|    total_timesteps  | 190753   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000821 |
|    n_updates        | 37688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0367   |
|    exploration_rate | 0.661    |
| time/               |          |
|    episodes         | 10672    |
|    fps              | 138      |
|    time_elapsed     | 1376     |
|    total_timesteps  | 190816   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00249  |
|    n_updates        | 37703    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0465   |
|    exploration_rate | 0.661    |
| time/               |          |
|    episodes         | 10676    |
|    fps              | 138      |
|    time_elapsed     | 1376     |
|    total_timesteps  | 190881   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00788  |
|    n_updates        | 37720    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0364   |
|    exploration_rate | 0.661    |
| time/               |          |
|    episodes         | 10680    |
|    fps              | 138      |
|    time_elapsed     | 1376     |
|    total_timesteps  | 190950   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 37737    |
----------------------------------
Eval num_timesteps=191000, episode_reward=0.04 +/- 0.30
Episode length: 14.66 +/- 1.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0424   |
| rollout/            |          |
|    exploration_rate | 0.66     |
| time/               |          |
|    total_timesteps  | 191000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 37749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0364   |
|    exploration_rate | 0.66     |
| time/               |          |
|    episodes         | 10684    |
|    fps              | 138      |
|    time_elapsed     | 1378     |
|    total_timesteps  | 191012   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 37752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0465   |
|    exploration_rate | 0.66     |
| time/               |          |
|    episodes         | 10688    |
|    fps              | 138      |
|    time_elapsed     | 1378     |
|    total_timesteps  | 191075   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00242  |
|    n_updates        | 37768    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0465   |
|    exploration_rate | 0.66     |
| time/               |          |
|    episodes         | 10692    |
|    fps              | 138      |
|    time_elapsed     | 1378     |
|    total_timesteps  | 191139   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 37784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0465   |
|    exploration_rate | 0.66     |
| time/               |          |
|    episodes         | 10696    |
|    fps              | 138      |
|    time_elapsed     | 1378     |
|    total_timesteps  | 191213   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000834 |
|    n_updates        | 37803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0366   |
|    exploration_rate | 0.659    |
| time/               |          |
|    episodes         | 10700    |
|    fps              | 138      |
|    time_elapsed     | 1378     |
|    total_timesteps  | 191280   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 37819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0264   |
|    exploration_rate | 0.659    |
| time/               |          |
|    episodes         | 10704    |
|    fps              | 138      |
|    time_elapsed     | 1378     |
|    total_timesteps  | 191350   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 37837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.659    |
| time/               |          |
|    episodes         | 10708    |
|    fps              | 138      |
|    time_elapsed     | 1378     |
|    total_timesteps  | 191419   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00071  |
|    n_updates        | 37854    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00405 |
|    exploration_rate | 0.659    |
| time/               |          |
|    episodes         | 10712    |
|    fps              | 138      |
|    time_elapsed     | 1378     |
|    total_timesteps  | 191484   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00619  |
|    n_updates        | 37870    |
----------------------------------
Eval num_timesteps=191500, episode_reward=0.08 +/- 0.35
Episode length: 14.42 +/- 1.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.4     |
|    mean_reward      | 0.0833   |
| rollout/            |          |
|    exploration_rate | 0.659    |
| time/               |          |
|    total_timesteps  | 191500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000745 |
|    n_updates        | 37874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.659    |
| time/               |          |
|    episodes         | 10716    |
|    fps              | 138      |
|    time_elapsed     | 1379     |
|    total_timesteps  | 191544   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 37885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.658    |
| time/               |          |
|    episodes         | 10720    |
|    fps              | 138      |
|    time_elapsed     | 1379     |
|    total_timesteps  | 191609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 37902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00402 |
|    exploration_rate | 0.658    |
| time/               |          |
|    episodes         | 10724    |
|    fps              | 138      |
|    time_elapsed     | 1380     |
|    total_timesteps  | 191673   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 37918    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00394 |
|    exploration_rate | 0.658    |
| time/               |          |
|    episodes         | 10728    |
|    fps              | 138      |
|    time_elapsed     | 1380     |
|    total_timesteps  | 191734   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 37933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00608  |
|    exploration_rate | 0.658    |
| time/               |          |
|    episodes         | 10732    |
|    fps              | 138      |
|    time_elapsed     | 1380     |
|    total_timesteps  | 191797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 37949    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.657    |
| time/               |          |
|    episodes         | 10736    |
|    fps              | 138      |
|    time_elapsed     | 1380     |
|    total_timesteps  | 191856   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00341  |
|    n_updates        | 37963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0263   |
|    exploration_rate | 0.657    |
| time/               |          |
|    episodes         | 10740    |
|    fps              | 139      |
|    time_elapsed     | 1380     |
|    total_timesteps  | 191916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0045   |
|    n_updates        | 37978    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0266   |
|    exploration_rate | 0.657    |
| time/               |          |
|    episodes         | 10744    |
|    fps              | 139      |
|    time_elapsed     | 1380     |
|    total_timesteps  | 191977   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 37994    |
----------------------------------
Eval num_timesteps=192000, episode_reward=0.06 +/- 0.33
Episode length: 14.76 +/- 1.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.062    |
| rollout/            |          |
|    exploration_rate | 0.657    |
| time/               |          |
|    total_timesteps  | 192000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00459  |
|    n_updates        | 37999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0363   |
|    exploration_rate | 0.657    |
| time/               |          |
|    episodes         | 10748    |
|    fps              | 138      |
|    time_elapsed     | 1381     |
|    total_timesteps  | 192046   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 38011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.036    |
|    exploration_rate | 0.657    |
| time/               |          |
|    episodes         | 10752    |
|    fps              | 139      |
|    time_elapsed     | 1381     |
|    total_timesteps  | 192114   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 38028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.656    |
| time/               |          |
|    episodes         | 10756    |
|    fps              | 139      |
|    time_elapsed     | 1381     |
|    total_timesteps  | 192178   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 38044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0464   |
|    exploration_rate | 0.656    |
| time/               |          |
|    episodes         | 10760    |
|    fps              | 139      |
|    time_elapsed     | 1381     |
|    total_timesteps  | 192237   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 38059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0567   |
|    exploration_rate | 0.656    |
| time/               |          |
|    episodes         | 10764    |
|    fps              | 139      |
|    time_elapsed     | 1382     |
|    total_timesteps  | 192300   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 38074    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0468   |
|    exploration_rate | 0.656    |
| time/               |          |
|    episodes         | 10768    |
|    fps              | 139      |
|    time_elapsed     | 1382     |
|    total_timesteps  | 192360   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000712 |
|    n_updates        | 38089    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0468   |
|    exploration_rate | 0.656    |
| time/               |          |
|    episodes         | 10772    |
|    fps              | 139      |
|    time_elapsed     | 1382     |
|    total_timesteps  | 192423   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00629  |
|    n_updates        | 38105    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.047    |
|    exploration_rate | 0.655    |
| time/               |          |
|    episodes         | 10776    |
|    fps              | 139      |
|    time_elapsed     | 1382     |
|    total_timesteps  | 192482   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 38120    |
----------------------------------
Eval num_timesteps=192500, episode_reward=-0.02 +/- 0.20
Episode length: 14.88 +/- 0.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0185  |
| rollout/            |          |
|    exploration_rate | 0.655    |
| time/               |          |
|    total_timesteps  | 192500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000816 |
|    n_updates        | 38124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0572   |
|    exploration_rate | 0.655    |
| time/               |          |
|    episodes         | 10780    |
|    fps              | 139      |
|    time_elapsed     | 1383     |
|    total_timesteps  | 192546   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00329  |
|    n_updates        | 38136    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.067    |
|    exploration_rate | 0.655    |
| time/               |          |
|    episodes         | 10784    |
|    fps              | 139      |
|    time_elapsed     | 1383     |
|    total_timesteps  | 192614   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00381  |
|    n_updates        | 38153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0567   |
|    exploration_rate | 0.655    |
| time/               |          |
|    episodes         | 10788    |
|    fps              | 139      |
|    time_elapsed     | 1383     |
|    total_timesteps  | 192684   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 38170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0669   |
|    exploration_rate | 0.654    |
| time/               |          |
|    episodes         | 10792    |
|    fps              | 139      |
|    time_elapsed     | 1383     |
|    total_timesteps  | 192741   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 38185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0877   |
|    exploration_rate | 0.654    |
| time/               |          |
|    episodes         | 10796    |
|    fps              | 139      |
|    time_elapsed     | 1383     |
|    total_timesteps  | 192797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 38199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.088    |
|    exploration_rate | 0.654    |
| time/               |          |
|    episodes         | 10800    |
|    fps              | 139      |
|    time_elapsed     | 1383     |
|    total_timesteps  | 192857   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00316  |
|    n_updates        | 38214    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0883   |
|    exploration_rate | 0.654    |
| time/               |          |
|    episodes         | 10804    |
|    fps              | 139      |
|    time_elapsed     | 1383     |
|    total_timesteps  | 192919   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00306  |
|    n_updates        | 38229    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0984   |
|    exploration_rate | 0.654    |
| time/               |          |
|    episodes         | 10808    |
|    fps              | 139      |
|    time_elapsed     | 1384     |
|    total_timesteps  | 192987   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000783 |
|    n_updates        | 38246    |
----------------------------------
Eval num_timesteps=193000, episode_reward=0.06 +/- 0.33
Episode length: 14.60 +/- 1.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0627   |
| rollout/            |          |
|    exploration_rate | 0.654    |
| time/               |          |
|    total_timesteps  | 193000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 38249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0983   |
|    exploration_rate | 0.653    |
| time/               |          |
|    episodes         | 10812    |
|    fps              | 139      |
|    time_elapsed     | 1385     |
|    total_timesteps  | 193053   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 38263    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.107    |
|    exploration_rate | 0.653    |
| time/               |          |
|    episodes         | 10816    |
|    fps              | 139      |
|    time_elapsed     | 1385     |
|    total_timesteps  | 193135   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 38283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.107    |
|    exploration_rate | 0.653    |
| time/               |          |
|    episodes         | 10820    |
|    fps              | 139      |
|    time_elapsed     | 1385     |
|    total_timesteps  | 193201   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000894 |
|    n_updates        | 38300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.097    |
|    exploration_rate | 0.653    |
| time/               |          |
|    episodes         | 10824    |
|    fps              | 139      |
|    time_elapsed     | 1385     |
|    total_timesteps  | 193275   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00392  |
|    n_updates        | 38318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0965   |
|    exploration_rate | 0.652    |
| time/               |          |
|    episodes         | 10828    |
|    fps              | 139      |
|    time_elapsed     | 1385     |
|    total_timesteps  | 193348   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00336  |
|    n_updates        | 38336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0863   |
|    exploration_rate | 0.652    |
| time/               |          |
|    episodes         | 10832    |
|    fps              | 139      |
|    time_elapsed     | 1385     |
|    total_timesteps  | 193415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00336  |
|    n_updates        | 38353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0762   |
|    exploration_rate | 0.652    |
| time/               |          |
|    episodes         | 10836    |
|    fps              | 139      |
|    time_elapsed     | 1385     |
|    total_timesteps  | 193477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000725 |
|    n_updates        | 38369    |
----------------------------------
Eval num_timesteps=193500, episode_reward=0.02 +/- 0.28
Episode length: 14.76 +/- 1.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.022    |
| rollout/            |          |
|    exploration_rate | 0.652    |
| time/               |          |
|    total_timesteps  | 193500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 38374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0661   |
|    exploration_rate | 0.652    |
| time/               |          |
|    episodes         | 10840    |
|    fps              | 139      |
|    time_elapsed     | 1386     |
|    total_timesteps  | 193540   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 38384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0658   |
|    exploration_rate | 0.652    |
| time/               |          |
|    episodes         | 10844    |
|    fps              | 139      |
|    time_elapsed     | 1386     |
|    total_timesteps  | 193608   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 38401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0662   |
|    exploration_rate | 0.651    |
| time/               |          |
|    episodes         | 10848    |
|    fps              | 139      |
|    time_elapsed     | 1386     |
|    total_timesteps  | 193668   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0031   |
|    n_updates        | 38416    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0762   |
|    exploration_rate | 0.651    |
| time/               |          |
|    episodes         | 10852    |
|    fps              | 139      |
|    time_elapsed     | 1387     |
|    total_timesteps  | 193735   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0028   |
|    n_updates        | 38433    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0763   |
|    exploration_rate | 0.651    |
| time/               |          |
|    episodes         | 10856    |
|    fps              | 139      |
|    time_elapsed     | 1387     |
|    total_timesteps  | 193797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00392  |
|    n_updates        | 38449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0662   |
|    exploration_rate | 0.651    |
| time/               |          |
|    episodes         | 10860    |
|    fps              | 139      |
|    time_elapsed     | 1387     |
|    total_timesteps  | 193858   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 38464    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0562   |
|    exploration_rate | 0.65     |
| time/               |          |
|    episodes         | 10864    |
|    fps              | 139      |
|    time_elapsed     | 1387     |
|    total_timesteps  | 193920   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 38479    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0461   |
|    exploration_rate | 0.65     |
| time/               |          |
|    episodes         | 10868    |
|    fps              | 139      |
|    time_elapsed     | 1387     |
|    total_timesteps  | 193983   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00713  |
|    n_updates        | 38495    |
----------------------------------
Eval num_timesteps=194000, episode_reward=0.06 +/- 0.33
Episode length: 14.58 +/- 1.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0627   |
| rollout/            |          |
|    exploration_rate | 0.65     |
| time/               |          |
|    total_timesteps  | 194000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 38499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0459   |
|    exploration_rate | 0.65     |
| time/               |          |
|    episodes         | 10872    |
|    fps              | 139      |
|    time_elapsed     | 1388     |
|    total_timesteps  | 194050   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0026   |
|    n_updates        | 38512    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0458   |
|    exploration_rate | 0.65     |
| time/               |          |
|    episodes         | 10876    |
|    fps              | 139      |
|    time_elapsed     | 1388     |
|    total_timesteps  | 194112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 38527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.65     |
| time/               |          |
|    episodes         | 10880    |
|    fps              | 139      |
|    time_elapsed     | 1388     |
|    total_timesteps  | 194179   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000791 |
|    n_updates        | 38544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.649    |
| time/               |          |
|    episodes         | 10884    |
|    fps              | 139      |
|    time_elapsed     | 1388     |
|    total_timesteps  | 194242   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 38560    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0257   |
|    exploration_rate | 0.649    |
| time/               |          |
|    episodes         | 10888    |
|    fps              | 139      |
|    time_elapsed     | 1388     |
|    total_timesteps  | 194317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00424  |
|    n_updates        | 38579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.649    |
| time/               |          |
|    episodes         | 10892    |
|    fps              | 139      |
|    time_elapsed     | 1389     |
|    total_timesteps  | 194385   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 38596    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00505 |
|    exploration_rate | 0.649    |
| time/               |          |
|    episodes         | 10896    |
|    fps              | 139      |
|    time_elapsed     | 1389     |
|    total_timesteps  | 194449   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 38612    |
----------------------------------
Eval num_timesteps=194500, episode_reward=-0.04 +/- 0.14
Episode length: 15.06 +/- 1.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | -0.0393  |
| rollout/            |          |
|    exploration_rate | 0.649    |
| time/               |          |
|    total_timesteps  | 194500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00618  |
|    n_updates        | 38624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0153  |
|    exploration_rate | 0.648    |
| time/               |          |
|    episodes         | 10900    |
|    fps              | 139      |
|    time_elapsed     | 1390     |
|    total_timesteps  | 194515   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 38628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0158  |
|    exploration_rate | 0.648    |
| time/               |          |
|    episodes         | 10904    |
|    fps              | 139      |
|    time_elapsed     | 1390     |
|    total_timesteps  | 194590   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 38647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.648    |
| time/               |          |
|    episodes         | 10908    |
|    fps              | 139      |
|    time_elapsed     | 1390     |
|    total_timesteps  | 194654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 38663    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0258  |
|    exploration_rate | 0.648    |
| time/               |          |
|    episodes         | 10912    |
|    fps              | 140      |
|    time_elapsed     | 1390     |
|    total_timesteps  | 194722   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 38680    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0354  |
|    exploration_rate | 0.648    |
| time/               |          |
|    episodes         | 10916    |
|    fps              | 140      |
|    time_elapsed     | 1390     |
|    total_timesteps  | 194795   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 38698    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0352  |
|    exploration_rate | 0.647    |
| time/               |          |
|    episodes         | 10920    |
|    fps              | 140      |
|    time_elapsed     | 1390     |
|    total_timesteps  | 194855   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00276  |
|    n_updates        | 38713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0346  |
|    exploration_rate | 0.647    |
| time/               |          |
|    episodes         | 10924    |
|    fps              | 140      |
|    time_elapsed     | 1390     |
|    total_timesteps  | 194915   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 38728    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.647    |
| time/               |          |
|    episodes         | 10928    |
|    fps              | 140      |
|    time_elapsed     | 1390     |
|    total_timesteps  | 194988   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.006    |
|    n_updates        | 38746    |
----------------------------------
Eval num_timesteps=195000, episode_reward=0.06 +/- 0.33
Episode length: 14.66 +/- 1.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0624   |
| rollout/            |          |
|    exploration_rate | 0.647    |
| time/               |          |
|    total_timesteps  | 195000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0175   |
|    n_updates        | 38749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0247  |
|    exploration_rate | 0.647    |
| time/               |          |
|    episodes         | 10932    |
|    fps              | 140      |
|    time_elapsed     | 1391     |
|    total_timesteps  | 195059   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00365  |
|    n_updates        | 38764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.025   |
|    exploration_rate | 0.646    |
| time/               |          |
|    episodes         | 10936    |
|    fps              | 140      |
|    time_elapsed     | 1392     |
|    total_timesteps  | 195127   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0024   |
|    n_updates        | 38781    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.646    |
| time/               |          |
|    episodes         | 10940    |
|    fps              | 140      |
|    time_elapsed     | 1392     |
|    total_timesteps  | 195197   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 38799    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0259  |
|    exploration_rate | 0.646    |
| time/               |          |
|    episodes         | 10944    |
|    fps              | 140      |
|    time_elapsed     | 1392     |
|    total_timesteps  | 195280   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 38819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0361  |
|    exploration_rate | 0.646    |
| time/               |          |
|    episodes         | 10948    |
|    fps              | 140      |
|    time_elapsed     | 1392     |
|    total_timesteps  | 195346   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00492  |
|    n_updates        | 38836    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.046   |
|    exploration_rate | 0.645    |
| time/               |          |
|    episodes         | 10952    |
|    fps              | 140      |
|    time_elapsed     | 1392     |
|    total_timesteps  | 195410   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00355  |
|    n_updates        | 38852    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0362  |
|    exploration_rate | 0.645    |
| time/               |          |
|    episodes         | 10956    |
|    fps              | 140      |
|    time_elapsed     | 1392     |
|    total_timesteps  | 195477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 38869    |
----------------------------------
Eval num_timesteps=195500, episode_reward=-0.02 +/- 0.20
Episode length: 14.98 +/- 1.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.0189  |
| rollout/            |          |
|    exploration_rate | 0.645    |
| time/               |          |
|    total_timesteps  | 195500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 38874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0261  |
|    exploration_rate | 0.645    |
| time/               |          |
|    episodes         | 10960    |
|    fps              | 140      |
|    time_elapsed     | 1393     |
|    total_timesteps  | 195535   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 38883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0262  |
|    exploration_rate | 0.645    |
| time/               |          |
|    episodes         | 10964    |
|    fps              | 140      |
|    time_elapsed     | 1393     |
|    total_timesteps  | 195600   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000768 |
|    n_updates        | 38899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0262  |
|    exploration_rate | 0.645    |
| time/               |          |
|    episodes         | 10968    |
|    fps              | 140      |
|    time_elapsed     | 1393     |
|    total_timesteps  | 195663   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00631  |
|    n_updates        | 38915    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.026   |
|    exploration_rate | 0.644    |
| time/               |          |
|    episodes         | 10972    |
|    fps              | 140      |
|    time_elapsed     | 1393     |
|    total_timesteps  | 195725   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00432  |
|    n_updates        | 38931    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0363  |
|    exploration_rate | 0.644    |
| time/               |          |
|    episodes         | 10976    |
|    fps              | 140      |
|    time_elapsed     | 1394     |
|    total_timesteps  | 195794   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00334  |
|    n_updates        | 38948    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.644    |
| time/               |          |
|    episodes         | 10980    |
|    fps              | 140      |
|    time_elapsed     | 1394     |
|    total_timesteps  | 195855   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 38963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.644    |
| time/               |          |
|    episodes         | 10984    |
|    fps              | 140      |
|    time_elapsed     | 1394     |
|    total_timesteps  | 195918   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 38979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0356  |
|    exploration_rate | 0.643    |
| time/               |          |
|    episodes         | 10988    |
|    fps              | 140      |
|    time_elapsed     | 1394     |
|    total_timesteps  | 195983   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00258  |
|    n_updates        | 38995    |
----------------------------------
Eval num_timesteps=196000, episode_reward=0.08 +/- 0.35
Episode length: 14.52 +/- 1.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.083    |
| rollout/            |          |
|    exploration_rate | 0.643    |
| time/               |          |
|    total_timesteps  | 196000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 38999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0356  |
|    exploration_rate | 0.643    |
| time/               |          |
|    episodes         | 10992    |
|    fps              | 140      |
|    time_elapsed     | 1395     |
|    total_timesteps  | 196050   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 39012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0355  |
|    exploration_rate | 0.643    |
| time/               |          |
|    episodes         | 10996    |
|    fps              | 140      |
|    time_elapsed     | 1395     |
|    total_timesteps  | 196112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00234  |
|    n_updates        | 39027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.643    |
| time/               |          |
|    episodes         | 11000    |
|    fps              | 140      |
|    time_elapsed     | 1395     |
|    total_timesteps  | 196174   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 39043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.643    |
| time/               |          |
|    episodes         | 11004    |
|    fps              | 140      |
|    time_elapsed     | 1395     |
|    total_timesteps  | 196249   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 39062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.642    |
| time/               |          |
|    episodes         | 11008    |
|    fps              | 140      |
|    time_elapsed     | 1395     |
|    total_timesteps  | 196313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 39078    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.642    |
| time/               |          |
|    episodes         | 11012    |
|    fps              | 140      |
|    time_elapsed     | 1395     |
|    total_timesteps  | 196379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 39094    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0251  |
|    exploration_rate | 0.642    |
| time/               |          |
|    episodes         | 11016    |
|    fps              | 140      |
|    time_elapsed     | 1395     |
|    total_timesteps  | 196448   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 39111    |
----------------------------------
Eval num_timesteps=196500, episode_reward=0.00 +/- 0.24
Episode length: 15.04 +/- 1.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | 0.00092  |
| rollout/            |          |
|    exploration_rate | 0.642    |
| time/               |          |
|    total_timesteps  | 196500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 39124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.642    |
| time/               |          |
|    episodes         | 11020    |
|    fps              | 140      |
|    time_elapsed     | 1397     |
|    total_timesteps  | 196514   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 39128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0254  |
|    exploration_rate | 0.641    |
| time/               |          |
|    episodes         | 11024    |
|    fps              | 140      |
|    time_elapsed     | 1397     |
|    total_timesteps  | 196576   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 39143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0248  |
|    exploration_rate | 0.641    |
| time/               |          |
|    episodes         | 11028    |
|    fps              | 140      |
|    time_elapsed     | 1397     |
|    total_timesteps  | 196634   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00712  |
|    n_updates        | 39158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0245  |
|    exploration_rate | 0.641    |
| time/               |          |
|    episodes         | 11032    |
|    fps              | 140      |
|    time_elapsed     | 1397     |
|    total_timesteps  | 196698   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 39174    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00417 |
|    exploration_rate | 0.641    |
| time/               |          |
|    episodes         | 11036    |
|    fps              | 140      |
|    time_elapsed     | 1397     |
|    total_timesteps  | 196757   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 39189    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00413 |
|    exploration_rate | 0.641    |
| time/               |          |
|    episodes         | 11040    |
|    fps              | 140      |
|    time_elapsed     | 1397     |
|    total_timesteps  | 196826   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 39206    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00325 |
|    exploration_rate | 0.64     |
| time/               |          |
|    episodes         | 11044    |
|    fps              | 140      |
|    time_elapsed     | 1397     |
|    total_timesteps  | 196887   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00626  |
|    n_updates        | 39221    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00333 |
|    exploration_rate | 0.64     |
| time/               |          |
|    episodes         | 11048    |
|    fps              | 140      |
|    time_elapsed     | 1397     |
|    total_timesteps  | 196955   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00228  |
|    n_updates        | 39238    |
----------------------------------
Eval num_timesteps=197000, episode_reward=0.02 +/- 0.28
Episode length: 14.68 +/- 1.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0223   |
| rollout/            |          |
|    exploration_rate | 0.64     |
| time/               |          |
|    total_timesteps  | 197000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 39249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00693  |
|    exploration_rate | 0.64     |
| time/               |          |
|    episodes         | 11052    |
|    fps              | 140      |
|    time_elapsed     | 1398     |
|    total_timesteps  | 197013   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000993 |
|    n_updates        | 39253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00298 |
|    exploration_rate | 0.64     |
| time/               |          |
|    episodes         | 11056    |
|    fps              | 140      |
|    time_elapsed     | 1398     |
|    total_timesteps  | 197078   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 39269    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.639    |
| time/               |          |
|    episodes         | 11060    |
|    fps              | 140      |
|    time_elapsed     | 1399     |
|    total_timesteps  | 197142   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 39285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.639    |
| time/               |          |
|    episodes         | 11064    |
|    fps              | 140      |
|    time_elapsed     | 1399     |
|    total_timesteps  | 197210   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 39302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.639    |
| time/               |          |
|    episodes         | 11068    |
|    fps              | 140      |
|    time_elapsed     | 1399     |
|    total_timesteps  | 197278   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00315  |
|    n_updates        | 39319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.639    |
| time/               |          |
|    episodes         | 11072    |
|    fps              | 141      |
|    time_elapsed     | 1399     |
|    total_timesteps  | 197341   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 39335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.639    |
| time/               |          |
|    episodes         | 11076    |
|    fps              | 141      |
|    time_elapsed     | 1399     |
|    total_timesteps  | 197407   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 39351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00359 |
|    exploration_rate | 0.638    |
| time/               |          |
|    episodes         | 11080    |
|    fps              | 141      |
|    time_elapsed     | 1399     |
|    total_timesteps  | 197471   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 39367    |
----------------------------------
Eval num_timesteps=197500, episode_reward=-0.04 +/- 0.14
Episode length: 14.92 +/- 0.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0387  |
| rollout/            |          |
|    exploration_rate | 0.638    |
| time/               |          |
|    total_timesteps  | 197500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 39374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00375 |
|    exploration_rate | 0.638    |
| time/               |          |
|    episodes         | 11084    |
|    fps              | 141      |
|    time_elapsed     | 1400     |
|    total_timesteps  | 197538   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00636  |
|    n_updates        | 39384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0165   |
|    exploration_rate | 0.638    |
| time/               |          |
|    episodes         | 11088    |
|    fps              | 141      |
|    time_elapsed     | 1400     |
|    total_timesteps  | 197596   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 39398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0268   |
|    exploration_rate | 0.638    |
| time/               |          |
|    episodes         | 11092    |
|    fps              | 141      |
|    time_elapsed     | 1400     |
|    total_timesteps  | 197657   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 39414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0267   |
|    exploration_rate | 0.637    |
| time/               |          |
|    episodes         | 11096    |
|    fps              | 141      |
|    time_elapsed     | 1400     |
|    total_timesteps  | 197720   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 39429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.637    |
| time/               |          |
|    episodes         | 11100    |
|    fps              | 141      |
|    time_elapsed     | 1400     |
|    total_timesteps  | 197785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 39446    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.637    |
| time/               |          |
|    episodes         | 11104    |
|    fps              | 141      |
|    time_elapsed     | 1401     |
|    total_timesteps  | 197848   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 39461    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.637    |
| time/               |          |
|    episodes         | 11108    |
|    fps              | 141      |
|    time_elapsed     | 1401     |
|    total_timesteps  | 197911   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 39477    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.637    |
| time/               |          |
|    episodes         | 11112    |
|    fps              | 141      |
|    time_elapsed     | 1401     |
|    total_timesteps  | 197978   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000999 |
|    n_updates        | 39494    |
----------------------------------
Eval num_timesteps=198000, episode_reward=0.00 +/- 0.24
Episode length: 14.76 +/- 0.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00198  |
| rollout/            |          |
|    exploration_rate | 0.636    |
| time/               |          |
|    total_timesteps  | 198000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00306  |
|    n_updates        | 39499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.636    |
| time/               |          |
|    episodes         | 11116    |
|    fps              | 141      |
|    time_elapsed     | 1402     |
|    total_timesteps  | 198044   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 39510    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.636    |
| time/               |          |
|    episodes         | 11120    |
|    fps              | 141      |
|    time_elapsed     | 1402     |
|    total_timesteps  | 198106   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 39526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0273   |
|    exploration_rate | 0.636    |
| time/               |          |
|    episodes         | 11124    |
|    fps              | 141      |
|    time_elapsed     | 1402     |
|    total_timesteps  | 198169   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 39542    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.636    |
| time/               |          |
|    episodes         | 11128    |
|    fps              | 141      |
|    time_elapsed     | 1402     |
|    total_timesteps  | 198234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00277  |
|    n_updates        | 39558    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0273   |
|    exploration_rate | 0.635    |
| time/               |          |
|    episodes         | 11132    |
|    fps              | 141      |
|    time_elapsed     | 1402     |
|    total_timesteps  | 198291   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00517  |
|    n_updates        | 39572    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00693  |
|    exploration_rate | 0.635    |
| time/               |          |
|    episodes         | 11136    |
|    fps              | 141      |
|    time_elapsed     | 1402     |
|    total_timesteps  | 198359   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00279  |
|    n_updates        | 39589    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.635    |
| time/               |          |
|    episodes         | 11140    |
|    fps              | 141      |
|    time_elapsed     | 1403     |
|    total_timesteps  | 198416   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00254  |
|    n_updates        | 39603    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.635    |
| time/               |          |
|    episodes         | 11144    |
|    fps              | 141      |
|    time_elapsed     | 1403     |
|    total_timesteps  | 198488   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 39621    |
----------------------------------
Eval num_timesteps=198500, episode_reward=0.00 +/- 0.24
Episode length: 14.84 +/- 1.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00164  |
| rollout/            |          |
|    exploration_rate | 0.635    |
| time/               |          |
|    total_timesteps  | 198500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 39624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.635    |
| time/               |          |
|    episodes         | 11148    |
|    fps              | 141      |
|    time_elapsed     | 1404     |
|    total_timesteps  | 198556   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000705 |
|    n_updates        | 39638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.634    |
| time/               |          |
|    episodes         | 11152    |
|    fps              | 141      |
|    time_elapsed     | 1404     |
|    total_timesteps  | 198617   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000909 |
|    n_updates        | 39654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0268   |
|    exploration_rate | 0.634    |
| time/               |          |
|    episodes         | 11156    |
|    fps              | 141      |
|    time_elapsed     | 1404     |
|    total_timesteps  | 198683   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00299  |
|    n_updates        | 39670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0267   |
|    exploration_rate | 0.634    |
| time/               |          |
|    episodes         | 11160    |
|    fps              | 141      |
|    time_elapsed     | 1404     |
|    total_timesteps  | 198749   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 39687    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.634    |
| time/               |          |
|    episodes         | 11164    |
|    fps              | 141      |
|    time_elapsed     | 1404     |
|    total_timesteps  | 198814   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 39703    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.633    |
| time/               |          |
|    episodes         | 11168    |
|    fps              | 141      |
|    time_elapsed     | 1404     |
|    total_timesteps  | 198877   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00471  |
|    n_updates        | 39719    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.633    |
| time/               |          |
|    episodes         | 11172    |
|    fps              | 141      |
|    time_elapsed     | 1404     |
|    total_timesteps  | 198940   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00189  |
|    n_updates        | 39734    |
----------------------------------
Eval num_timesteps=199000, episode_reward=-0.04 +/- 0.14
Episode length: 14.94 +/- 0.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0387  |
| rollout/            |          |
|    exploration_rate | 0.633    |
| time/               |          |
|    total_timesteps  | 199000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000957 |
|    n_updates        | 39749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.633    |
| time/               |          |
|    episodes         | 11176    |
|    fps              | 141      |
|    time_elapsed     | 1405     |
|    total_timesteps  | 199002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 39750    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.633    |
| time/               |          |
|    episodes         | 11180    |
|    fps              | 141      |
|    time_elapsed     | 1405     |
|    total_timesteps  | 199064   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00713  |
|    n_updates        | 39765    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.633    |
| time/               |          |
|    episodes         | 11184    |
|    fps              | 141      |
|    time_elapsed     | 1406     |
|    total_timesteps  | 199132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00228  |
|    n_updates        | 39782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00314 |
|    exploration_rate | 0.632    |
| time/               |          |
|    episodes         | 11188    |
|    fps              | 141      |
|    time_elapsed     | 1406     |
|    total_timesteps  | 199200   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 39799    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.632    |
| time/               |          |
|    episodes         | 11192    |
|    fps              | 141      |
|    time_elapsed     | 1406     |
|    total_timesteps  | 199267   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00232  |
|    n_updates        | 39816    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.632    |
| time/               |          |
|    episodes         | 11196    |
|    fps              | 141      |
|    time_elapsed     | 1406     |
|    total_timesteps  | 199328   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 39831    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.632    |
| time/               |          |
|    episodes         | 11200    |
|    fps              | 141      |
|    time_elapsed     | 1406     |
|    total_timesteps  | 199390   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0082   |
|    n_updates        | 39847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.631    |
| time/               |          |
|    episodes         | 11204    |
|    fps              | 141      |
|    time_elapsed     | 1406     |
|    total_timesteps  | 199460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 39864    |
----------------------------------
Eval num_timesteps=199500, episode_reward=0.02 +/- 0.27
Episode length: 14.74 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0221   |
| rollout/            |          |
|    exploration_rate | 0.631    |
| time/               |          |
|    total_timesteps  | 199500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00652  |
|    n_updates        | 39874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00333 |
|    exploration_rate | 0.631    |
| time/               |          |
|    episodes         | 11208    |
|    fps              | 141      |
|    time_elapsed     | 1407     |
|    total_timesteps  | 199520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000534 |
|    n_updates        | 39879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.631    |
| time/               |          |
|    episodes         | 11212    |
|    fps              | 141      |
|    time_elapsed     | 1407     |
|    total_timesteps  | 199583   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000597 |
|    n_updates        | 39895    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.003   |
|    exploration_rate | 0.631    |
| time/               |          |
|    episodes         | 11216    |
|    fps              | 141      |
|    time_elapsed     | 1407     |
|    total_timesteps  | 199645   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00611  |
|    n_updates        | 39911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00718  |
|    exploration_rate | 0.631    |
| time/               |          |
|    episodes         | 11220    |
|    fps              | 141      |
|    time_elapsed     | 1408     |
|    total_timesteps  | 199703   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00481  |
|    n_updates        | 39925    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00686  |
|    exploration_rate | 0.63     |
| time/               |          |
|    episodes         | 11224    |
|    fps              | 141      |
|    time_elapsed     | 1408     |
|    total_timesteps  | 199774   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00268  |
|    n_updates        | 39943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00674  |
|    exploration_rate | 0.63     |
| time/               |          |
|    episodes         | 11228    |
|    fps              | 141      |
|    time_elapsed     | 1408     |
|    total_timesteps  | 199842   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00244  |
|    n_updates        | 39960    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00366 |
|    exploration_rate | 0.63     |
| time/               |          |
|    episodes         | 11232    |
|    fps              | 141      |
|    time_elapsed     | 1408     |
|    total_timesteps  | 199909   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00311  |
|    n_updates        | 39977    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00677  |
|    exploration_rate | 0.63     |
| time/               |          |
|    episodes         | 11236    |
|    fps              | 141      |
|    time_elapsed     | 1408     |
|    total_timesteps  | 199966   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 39991    |
----------------------------------
Eval num_timesteps=200000, episode_reward=0.02 +/- 0.28
Episode length: 14.70 +/- 1.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0223   |
| rollout/            |          |
|    exploration_rate | 0.63     |
| time/               |          |
|    total_timesteps  | 200000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 39999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00658  |
|    exploration_rate | 0.629    |
| time/               |          |
|    episodes         | 11240    |
|    fps              | 141      |
|    time_elapsed     | 1409     |
|    total_timesteps  | 200028   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00052  |
|    n_updates        | 40006    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00686  |
|    exploration_rate | 0.629    |
| time/               |          |
|    episodes         | 11244    |
|    fps              | 141      |
|    time_elapsed     | 1409     |
|    total_timesteps  | 200093   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00544  |
|    n_updates        | 40023    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0266   |
|    exploration_rate | 0.629    |
| time/               |          |
|    episodes         | 11248    |
|    fps              | 141      |
|    time_elapsed     | 1409     |
|    total_timesteps  | 200168   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00324  |
|    n_updates        | 40041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0262   |
|    exploration_rate | 0.629    |
| time/               |          |
|    episodes         | 11252    |
|    fps              | 142      |
|    time_elapsed     | 1409     |
|    total_timesteps  | 200239   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00463  |
|    n_updates        | 40059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.629    |
| time/               |          |
|    episodes         | 11256    |
|    fps              | 142      |
|    time_elapsed     | 1409     |
|    total_timesteps  | 200303   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00363  |
|    n_updates        | 40075    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.628    |
| time/               |          |
|    episodes         | 11260    |
|    fps              | 142      |
|    time_elapsed     | 1410     |
|    total_timesteps  | 200371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00659  |
|    n_updates        | 40092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0161   |
|    exploration_rate | 0.628    |
| time/               |          |
|    episodes         | 11264    |
|    fps              | 142      |
|    time_elapsed     | 1410     |
|    total_timesteps  | 200438   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00411  |
|    n_updates        | 40109    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0362   |
|    exploration_rate | 0.628    |
| time/               |          |
|    episodes         | 11268    |
|    fps              | 142      |
|    time_elapsed     | 1410     |
|    total_timesteps  | 200498   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00699  |
|    n_updates        | 40124    |
----------------------------------
Eval num_timesteps=200500, episode_reward=-0.02 +/- 0.20
Episode length: 14.82 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | -0.0183  |
| rollout/            |          |
|    exploration_rate | 0.628    |
| time/               |          |
|    total_timesteps  | 200500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.628    |
| time/               |          |
|    episodes         | 11272    |
|    fps              | 142      |
|    time_elapsed     | 1411     |
|    total_timesteps  | 200570   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00303  |
|    n_updates        | 40142    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.627    |
| time/               |          |
|    episodes         | 11276    |
|    fps              | 142      |
|    time_elapsed     | 1411     |
|    total_timesteps  | 200636   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00225  |
|    n_updates        | 40158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0354   |
|    exploration_rate | 0.627    |
| time/               |          |
|    episodes         | 11280    |
|    fps              | 142      |
|    time_elapsed     | 1411     |
|    total_timesteps  | 200706   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 40176    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0457   |
|    exploration_rate | 0.627    |
| time/               |          |
|    episodes         | 11284    |
|    fps              | 142      |
|    time_elapsed     | 1411     |
|    total_timesteps  | 200767   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000872 |
|    n_updates        | 40191    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0458   |
|    exploration_rate | 0.627    |
| time/               |          |
|    episodes         | 11288    |
|    fps              | 142      |
|    time_elapsed     | 1411     |
|    total_timesteps  | 200832   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000918 |
|    n_updates        | 40207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.046    |
|    exploration_rate | 0.626    |
| time/               |          |
|    episodes         | 11292    |
|    fps              | 142      |
|    time_elapsed     | 1411     |
|    total_timesteps  | 200894   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00449  |
|    n_updates        | 40223    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0561   |
|    exploration_rate | 0.626    |
| time/               |          |
|    episodes         | 11296    |
|    fps              | 142      |
|    time_elapsed     | 1412     |
|    total_timesteps  | 200954   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 40238    |
----------------------------------
Eval num_timesteps=201000, episode_reward=0.02 +/- 0.28
Episode length: 14.82 +/- 1.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.0218   |
| rollout/            |          |
|    exploration_rate | 0.626    |
| time/               |          |
|    total_timesteps  | 201000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00347  |
|    n_updates        | 40249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0558   |
|    exploration_rate | 0.626    |
| time/               |          |
|    episodes         | 11300    |
|    fps              | 142      |
|    time_elapsed     | 1413     |
|    total_timesteps  | 201023   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 40255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.066    |
|    exploration_rate | 0.626    |
| time/               |          |
|    episodes         | 11304    |
|    fps              | 142      |
|    time_elapsed     | 1413     |
|    total_timesteps  | 201089   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0115   |
|    n_updates        | 40272    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0554   |
|    exploration_rate | 0.626    |
| time/               |          |
|    episodes         | 11308    |
|    fps              | 142      |
|    time_elapsed     | 1413     |
|    total_timesteps  | 201162   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 40290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0553   |
|    exploration_rate | 0.625    |
| time/               |          |
|    episodes         | 11312    |
|    fps              | 142      |
|    time_elapsed     | 1413     |
|    total_timesteps  | 201228   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00426  |
|    n_updates        | 40306    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0452   |
|    exploration_rate | 0.625    |
| time/               |          |
|    episodes         | 11316    |
|    fps              | 142      |
|    time_elapsed     | 1413     |
|    total_timesteps  | 201293   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 40323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0349   |
|    exploration_rate | 0.625    |
| time/               |          |
|    episodes         | 11320    |
|    fps              | 142      |
|    time_elapsed     | 1413     |
|    total_timesteps  | 201357   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00376  |
|    n_updates        | 40339    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0452   |
|    exploration_rate | 0.625    |
| time/               |          |
|    episodes         | 11324    |
|    fps              | 142      |
|    time_elapsed     | 1413     |
|    total_timesteps  | 201421   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00836  |
|    n_updates        | 40355    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0455   |
|    exploration_rate | 0.624    |
| time/               |          |
|    episodes         | 11328    |
|    fps              | 142      |
|    time_elapsed     | 1414     |
|    total_timesteps  | 201482   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 40370    |
----------------------------------
Eval num_timesteps=201500, episode_reward=0.08 +/- 0.35
Episode length: 14.54 +/- 1.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.0828   |
| rollout/            |          |
|    exploration_rate | 0.624    |
| time/               |          |
|    total_timesteps  | 201500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00431  |
|    n_updates        | 40374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0762   |
|    exploration_rate | 0.624    |
| time/               |          |
|    episodes         | 11332    |
|    fps              | 142      |
|    time_elapsed     | 1415     |
|    total_timesteps  | 201532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000975 |
|    n_updates        | 40382    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.066    |
|    exploration_rate | 0.624    |
| time/               |          |
|    episodes         | 11336    |
|    fps              | 142      |
|    time_elapsed     | 1415     |
|    total_timesteps  | 201594   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 40398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.066    |
|    exploration_rate | 0.624    |
| time/               |          |
|    episodes         | 11340    |
|    fps              | 142      |
|    time_elapsed     | 1415     |
|    total_timesteps  | 201656   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 40413    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0657   |
|    exploration_rate | 0.624    |
| time/               |          |
|    episodes         | 11344    |
|    fps              | 142      |
|    time_elapsed     | 1415     |
|    total_timesteps  | 201728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0074   |
|    n_updates        | 40431    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0462   |
|    exploration_rate | 0.623    |
| time/               |          |
|    episodes         | 11348    |
|    fps              | 142      |
|    time_elapsed     | 1415     |
|    total_timesteps  | 201790   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00421  |
|    n_updates        | 40447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0366   |
|    exploration_rate | 0.623    |
| time/               |          |
|    episodes         | 11352    |
|    fps              | 142      |
|    time_elapsed     | 1415     |
|    total_timesteps  | 201852   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0018   |
|    n_updates        | 40462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0362   |
|    exploration_rate | 0.623    |
| time/               |          |
|    episodes         | 11356    |
|    fps              | 142      |
|    time_elapsed     | 1415     |
|    total_timesteps  | 201925   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 40481    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0363   |
|    exploration_rate | 0.623    |
| time/               |          |
|    episodes         | 11360    |
|    fps              | 142      |
|    time_elapsed     | 1415     |
|    total_timesteps  | 201990   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00769  |
|    n_updates        | 40497    |
----------------------------------
Eval num_timesteps=202000, episode_reward=0.09 +/- 0.41
Episode length: 31.60 +/- 16.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 31.6     |
|    mean_reward      | 0.0947   |
| rollout/            |          |
|    exploration_rate | 0.623    |
| time/               |          |
|    total_timesteps  | 202000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00266  |
|    n_updates        | 40499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0358   |
|    exploration_rate | 0.622    |
| time/               |          |
|    episodes         | 11364    |
|    fps              | 142      |
|    time_elapsed     | 1418     |
|    total_timesteps  | 202069   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00227  |
|    n_updates        | 40517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0157   |
|    exploration_rate | 0.622    |
| time/               |          |
|    episodes         | 11368    |
|    fps              | 142      |
|    time_elapsed     | 1418     |
|    total_timesteps  | 202132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00274  |
|    n_updates        | 40532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.622    |
| time/               |          |
|    episodes         | 11372    |
|    fps              | 142      |
|    time_elapsed     | 1418     |
|    total_timesteps  | 202193   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000773 |
|    n_updates        | 40548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0365   |
|    exploration_rate | 0.622    |
| time/               |          |
|    episodes         | 11376    |
|    fps              | 142      |
|    time_elapsed     | 1418     |
|    total_timesteps  | 202251   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 40562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0364   |
|    exploration_rate | 0.621    |
| time/               |          |
|    episodes         | 11380    |
|    fps              | 142      |
|    time_elapsed     | 1418     |
|    total_timesteps  | 202322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 40580    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0461   |
|    exploration_rate | 0.621    |
| time/               |          |
|    episodes         | 11384    |
|    fps              | 142      |
|    time_elapsed     | 1418     |
|    total_timesteps  | 202391   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00239  |
|    n_updates        | 40597    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0463   |
|    exploration_rate | 0.621    |
| time/               |          |
|    episodes         | 11388    |
|    fps              | 142      |
|    time_elapsed     | 1418     |
|    total_timesteps  | 202452   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 40612    |
----------------------------------
Eval num_timesteps=202500, episode_reward=-0.04 +/- 0.15
Episode length: 15.98 +/- 6.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.0429  |
| rollout/            |          |
|    exploration_rate | 0.621    |
| time/               |          |
|    total_timesteps  | 202500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00435  |
|    n_updates        | 40624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0565   |
|    exploration_rate | 0.621    |
| time/               |          |
|    episodes         | 11392    |
|    fps              | 142      |
|    time_elapsed     | 1419     |
|    total_timesteps  | 202507   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 40626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0462   |
|    exploration_rate | 0.621    |
| time/               |          |
|    episodes         | 11396    |
|    fps              | 142      |
|    time_elapsed     | 1419     |
|    total_timesteps  | 202576   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 40643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0464   |
|    exploration_rate | 0.62     |
| time/               |          |
|    episodes         | 11400    |
|    fps              | 142      |
|    time_elapsed     | 1419     |
|    total_timesteps  | 202639   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00057  |
|    n_updates        | 40659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0466   |
|    exploration_rate | 0.62     |
| time/               |          |
|    episodes         | 11404    |
|    fps              | 142      |
|    time_elapsed     | 1420     |
|    total_timesteps  | 202699   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0024   |
|    n_updates        | 40674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.047    |
|    exploration_rate | 0.62     |
| time/               |          |
|    episodes         | 11408    |
|    fps              | 142      |
|    time_elapsed     | 1420     |
|    total_timesteps  | 202762   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 40690    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.047    |
|    exploration_rate | 0.62     |
| time/               |          |
|    episodes         | 11412    |
|    fps              | 142      |
|    time_elapsed     | 1420     |
|    total_timesteps  | 202829   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00379  |
|    n_updates        | 40707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.047    |
|    exploration_rate | 0.619    |
| time/               |          |
|    episodes         | 11416    |
|    fps              | 142      |
|    time_elapsed     | 1420     |
|    total_timesteps  | 202893   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 40723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.047    |
|    exploration_rate | 0.619    |
| time/               |          |
|    episodes         | 11420    |
|    fps              | 142      |
|    time_elapsed     | 1420     |
|    total_timesteps  | 202958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 40739    |
----------------------------------
Eval num_timesteps=203000, episode_reward=-0.04 +/- 0.14
Episode length: 15.82 +/- 6.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | -0.0423  |
| rollout/            |          |
|    exploration_rate | 0.619    |
| time/               |          |
|    total_timesteps  | 203000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00295  |
|    n_updates        | 40749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0366   |
|    exploration_rate | 0.619    |
| time/               |          |
|    episodes         | 11424    |
|    fps              | 142      |
|    time_elapsed     | 1421     |
|    total_timesteps  | 203033   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0023   |
|    n_updates        | 40758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.619    |
| time/               |          |
|    episodes         | 11428    |
|    fps              | 142      |
|    time_elapsed     | 1421     |
|    total_timesteps  | 203105   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00182  |
|    n_updates        | 40776    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00553  |
|    exploration_rate | 0.619    |
| time/               |          |
|    episodes         | 11432    |
|    fps              | 142      |
|    time_elapsed     | 1421     |
|    total_timesteps  | 203169   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 40792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.618    |
| time/               |          |
|    episodes         | 11436    |
|    fps              | 142      |
|    time_elapsed     | 1421     |
|    total_timesteps  | 203235   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00596  |
|    n_updates        | 40808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00543  |
|    exploration_rate | 0.618    |
| time/               |          |
|    episodes         | 11440    |
|    fps              | 142      |
|    time_elapsed     | 1422     |
|    total_timesteps  | 203296   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 40823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.618    |
| time/               |          |
|    episodes         | 11444    |
|    fps              | 142      |
|    time_elapsed     | 1422     |
|    total_timesteps  | 203364   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 40840    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.618    |
| time/               |          |
|    episodes         | 11448    |
|    fps              | 143      |
|    time_elapsed     | 1422     |
|    total_timesteps  | 203434   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 40858    |
----------------------------------
Eval num_timesteps=203500, episode_reward=-0.00 +/- 0.24
Episode length: 15.30 +/- 1.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | -0.00016 |
| rollout/            |          |
|    exploration_rate | 0.617    |
| time/               |          |
|    total_timesteps  | 203500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00251  |
|    n_updates        | 40874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0151   |
|    exploration_rate | 0.617    |
| time/               |          |
|    episodes         | 11452    |
|    fps              | 142      |
|    time_elapsed     | 1423     |
|    total_timesteps  | 203501   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 40875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.617    |
| time/               |          |
|    episodes         | 11456    |
|    fps              | 142      |
|    time_elapsed     | 1423     |
|    total_timesteps  | 203559   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 40889    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0358   |
|    exploration_rate | 0.617    |
| time/               |          |
|    episodes         | 11460    |
|    fps              | 143      |
|    time_elapsed     | 1423     |
|    total_timesteps  | 203620   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 40904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0365   |
|    exploration_rate | 0.617    |
| time/               |          |
|    episodes         | 11464    |
|    fps              | 143      |
|    time_elapsed     | 1423     |
|    total_timesteps  | 203683   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00412  |
|    n_updates        | 40920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0465   |
|    exploration_rate | 0.616    |
| time/               |          |
|    episodes         | 11468    |
|    fps              | 143      |
|    time_elapsed     | 1423     |
|    total_timesteps  | 203745   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00526  |
|    n_updates        | 40936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0462   |
|    exploration_rate | 0.616    |
| time/               |          |
|    episodes         | 11472    |
|    fps              | 143      |
|    time_elapsed     | 1423     |
|    total_timesteps  | 203815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 40953    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.026    |
|    exploration_rate | 0.616    |
| time/               |          |
|    episodes         | 11476    |
|    fps              | 143      |
|    time_elapsed     | 1424     |
|    total_timesteps  | 203877   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 40969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0261   |
|    exploration_rate | 0.616    |
| time/               |          |
|    episodes         | 11480    |
|    fps              | 143      |
|    time_elapsed     | 1424     |
|    total_timesteps  | 203945   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0037   |
|    n_updates        | 40986    |
----------------------------------
Eval num_timesteps=204000, episode_reward=0.01 +/- 0.28
Episode length: 17.20 +/- 9.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.2     |
|    mean_reward      | 0.0122   |
| rollout/            |          |
|    exploration_rate | 0.616    |
| time/               |          |
|    total_timesteps  | 204000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00344  |
|    n_updates        | 40999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00634  |
|    exploration_rate | 0.616    |
| time/               |          |
|    episodes         | 11484    |
|    fps              | 143      |
|    time_elapsed     | 1425     |
|    total_timesteps  | 204008   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 41001    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0164   |
|    exploration_rate | 0.615    |
| time/               |          |
|    episodes         | 11488    |
|    fps              | 143      |
|    time_elapsed     | 1425     |
|    total_timesteps  | 204067   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0025   |
|    n_updates        | 41016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0059   |
|    exploration_rate | 0.615    |
| time/               |          |
|    episodes         | 11492    |
|    fps              | 143      |
|    time_elapsed     | 1425     |
|    total_timesteps  | 204135   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00213  |
|    n_updates        | 41033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00562  |
|    exploration_rate | 0.615    |
| time/               |          |
|    episodes         | 11496    |
|    fps              | 143      |
|    time_elapsed     | 1425     |
|    total_timesteps  | 204211   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00361  |
|    n_updates        | 41052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0155   |
|    exploration_rate | 0.615    |
| time/               |          |
|    episodes         | 11500    |
|    fps              | 143      |
|    time_elapsed     | 1425     |
|    total_timesteps  | 204277   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 41069    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00522  |
|    exploration_rate | 0.614    |
| time/               |          |
|    episodes         | 11504    |
|    fps              | 143      |
|    time_elapsed     | 1425     |
|    total_timesteps  | 204344   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 41085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00514  |
|    exploration_rate | 0.614    |
| time/               |          |
|    episodes         | 11508    |
|    fps              | 143      |
|    time_elapsed     | 1425     |
|    total_timesteps  | 204409   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00228  |
|    n_updates        | 41102    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.614    |
| time/               |          |
|    episodes         | 11512    |
|    fps              | 143      |
|    time_elapsed     | 1426     |
|    total_timesteps  | 204469   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 41117    |
----------------------------------
Eval num_timesteps=204500, episode_reward=-0.02 +/- 0.20
Episode length: 15.22 +/- 2.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | -0.0199  |
| rollout/            |          |
|    exploration_rate | 0.614    |
| time/               |          |
|    total_timesteps  | 204500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00395  |
|    n_updates        | 41124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0356   |
|    exploration_rate | 0.614    |
| time/               |          |
|    episodes         | 11516    |
|    fps              | 143      |
|    time_elapsed     | 1427     |
|    total_timesteps  | 204528   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00632  |
|    n_updates        | 41131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.614    |
| time/               |          |
|    episodes         | 11520    |
|    fps              | 143      |
|    time_elapsed     | 1427     |
|    total_timesteps  | 204592   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00786  |
|    n_updates        | 41147    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0355   |
|    exploration_rate | 0.613    |
| time/               |          |
|    episodes         | 11524    |
|    fps              | 143      |
|    time_elapsed     | 1427     |
|    total_timesteps  | 204672   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 41167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0453   |
|    exploration_rate | 0.613    |
| time/               |          |
|    episodes         | 11528    |
|    fps              | 143      |
|    time_elapsed     | 1427     |
|    total_timesteps  | 204749   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 41187    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0454   |
|    exploration_rate | 0.613    |
| time/               |          |
|    episodes         | 11532    |
|    fps              | 143      |
|    time_elapsed     | 1427     |
|    total_timesteps  | 204809   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 41202    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0456   |
|    exploration_rate | 0.613    |
| time/               |          |
|    episodes         | 11536    |
|    fps              | 143      |
|    time_elapsed     | 1427     |
|    total_timesteps  | 204872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 41217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0553   |
|    exploration_rate | 0.612    |
| time/               |          |
|    episodes         | 11540    |
|    fps              | 143      |
|    time_elapsed     | 1427     |
|    total_timesteps  | 204940   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00396  |
|    n_updates        | 41234    |
----------------------------------
Eval num_timesteps=205000, episode_reward=0.04 +/- 0.31
Episode length: 14.78 +/- 1.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.042    |
| rollout/            |          |
|    exploration_rate | 0.612    |
| time/               |          |
|    total_timesteps  | 205000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 41249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0453   |
|    exploration_rate | 0.612    |
| time/               |          |
|    episodes         | 11544    |
|    fps              | 143      |
|    time_elapsed     | 1428     |
|    total_timesteps  | 205008   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00618  |
|    n_updates        | 41251    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0455   |
|    exploration_rate | 0.612    |
| time/               |          |
|    episodes         | 11548    |
|    fps              | 143      |
|    time_elapsed     | 1428     |
|    total_timesteps  | 205072   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 41267    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0454   |
|    exploration_rate | 0.612    |
| time/               |          |
|    episodes         | 11552    |
|    fps              | 143      |
|    time_elapsed     | 1429     |
|    total_timesteps  | 205142   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 41285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.611    |
| time/               |          |
|    episodes         | 11556    |
|    fps              | 143      |
|    time_elapsed     | 1429     |
|    total_timesteps  | 205203   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0027   |
|    n_updates        | 41300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.611    |
| time/               |          |
|    episodes         | 11560    |
|    fps              | 143      |
|    time_elapsed     | 1429     |
|    total_timesteps  | 205264   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 41315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0245   |
|    exploration_rate | 0.611    |
| time/               |          |
|    episodes         | 11564    |
|    fps              | 143      |
|    time_elapsed     | 1429     |
|    total_timesteps  | 205346   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0069   |
|    n_updates        | 41336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.611    |
| time/               |          |
|    episodes         | 11568    |
|    fps              | 143      |
|    time_elapsed     | 1429     |
|    total_timesteps  | 205415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00246  |
|    n_updates        | 41353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.61     |
| time/               |          |
|    episodes         | 11572    |
|    fps              | 143      |
|    time_elapsed     | 1429     |
|    total_timesteps  | 205484   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00317  |
|    n_updates        | 41370    |
----------------------------------
Eval num_timesteps=205500, episode_reward=-0.01 +/- 0.25
Episode length: 17.22 +/- 10.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.2     |
|    mean_reward      | -0.00788 |
| rollout/            |          |
|    exploration_rate | 0.61     |
| time/               |          |
|    total_timesteps  | 205500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 41374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0141   |
|    exploration_rate | 0.61     |
| time/               |          |
|    episodes         | 11576    |
|    fps              | 143      |
|    time_elapsed     | 1430     |
|    total_timesteps  | 205550   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 41387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0344   |
|    exploration_rate | 0.61     |
| time/               |          |
|    episodes         | 11580    |
|    fps              | 143      |
|    time_elapsed     | 1431     |
|    total_timesteps  | 205613   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 41403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0342   |
|    exploration_rate | 0.61     |
| time/               |          |
|    episodes         | 11584    |
|    fps              | 143      |
|    time_elapsed     | 1431     |
|    total_timesteps  | 205680   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00346  |
|    n_updates        | 41419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0338   |
|    exploration_rate | 0.609    |
| time/               |          |
|    episodes         | 11588    |
|    fps              | 143      |
|    time_elapsed     | 1431     |
|    total_timesteps  | 205749   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 41437    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0341   |
|    exploration_rate | 0.609    |
| time/               |          |
|    episodes         | 11592    |
|    fps              | 143      |
|    time_elapsed     | 1431     |
|    total_timesteps  | 205810   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 41452    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0345   |
|    exploration_rate | 0.609    |
| time/               |          |
|    episodes         | 11596    |
|    fps              | 143      |
|    time_elapsed     | 1431     |
|    total_timesteps  | 205874   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 41468    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.045    |
|    exploration_rate | 0.609    |
| time/               |          |
|    episodes         | 11600    |
|    fps              | 143      |
|    time_elapsed     | 1431     |
|    total_timesteps  | 205930   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 41482    |
----------------------------------
Eval num_timesteps=206000, episode_reward=0.02 +/- 0.27
Episode length: 15.28 +/- 1.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | 0.02     |
| rollout/            |          |
|    exploration_rate | 0.609    |
| time/               |          |
|    total_timesteps  | 206000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00291  |
|    n_updates        | 41499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0446   |
|    exploration_rate | 0.609    |
| time/               |          |
|    episodes         | 11604    |
|    fps              | 143      |
|    time_elapsed     | 1432     |
|    total_timesteps  | 206007   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 41501    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0548   |
|    exploration_rate | 0.608    |
| time/               |          |
|    episodes         | 11608    |
|    fps              | 143      |
|    time_elapsed     | 1432     |
|    total_timesteps  | 206067   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 41516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.054    |
|    exploration_rate | 0.608    |
| time/               |          |
|    episodes         | 11612    |
|    fps              | 143      |
|    time_elapsed     | 1432     |
|    total_timesteps  | 206145   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000781 |
|    n_updates        | 41536    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0339   |
|    exploration_rate | 0.608    |
| time/               |          |
|    episodes         | 11616    |
|    fps              | 143      |
|    time_elapsed     | 1432     |
|    total_timesteps  | 206208   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 41551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.044    |
|    exploration_rate | 0.608    |
| time/               |          |
|    episodes         | 11620    |
|    fps              | 143      |
|    time_elapsed     | 1433     |
|    total_timesteps  | 206268   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00587  |
|    n_updates        | 41566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0448   |
|    exploration_rate | 0.607    |
| time/               |          |
|    episodes         | 11624    |
|    fps              | 143      |
|    time_elapsed     | 1433     |
|    total_timesteps  | 206330   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 41582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0353   |
|    exploration_rate | 0.607    |
| time/               |          |
|    episodes         | 11628    |
|    fps              | 144      |
|    time_elapsed     | 1433     |
|    total_timesteps  | 206394   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 41598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0449   |
|    exploration_rate | 0.607    |
| time/               |          |
|    episodes         | 11632    |
|    fps              | 144      |
|    time_elapsed     | 1433     |
|    total_timesteps  | 206463   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00371  |
|    n_updates        | 41615    |
----------------------------------
Eval num_timesteps=206500, episode_reward=-0.04 +/- 0.14
Episode length: 15.78 +/- 2.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | -0.0421  |
| rollout/            |          |
|    exploration_rate | 0.607    |
| time/               |          |
|    total_timesteps  | 206500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0026   |
|    n_updates        | 41624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0451   |
|    exploration_rate | 0.607    |
| time/               |          |
|    episodes         | 11636    |
|    fps              | 143      |
|    time_elapsed     | 1434     |
|    total_timesteps  | 206522   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 41630    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0352   |
|    exploration_rate | 0.606    |
| time/               |          |
|    episodes         | 11640    |
|    fps              | 144      |
|    time_elapsed     | 1434     |
|    total_timesteps  | 206587   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00251  |
|    n_updates        | 41646    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0354   |
|    exploration_rate | 0.606    |
| time/               |          |
|    episodes         | 11644    |
|    fps              | 144      |
|    time_elapsed     | 1434     |
|    total_timesteps  | 206650   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000397 |
|    n_updates        | 41662    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0356   |
|    exploration_rate | 0.606    |
| time/               |          |
|    episodes         | 11648    |
|    fps              | 144      |
|    time_elapsed     | 1434     |
|    total_timesteps  | 206710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00638  |
|    n_updates        | 41677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0358   |
|    exploration_rate | 0.606    |
| time/               |          |
|    episodes         | 11652    |
|    fps              | 144      |
|    time_elapsed     | 1434     |
|    total_timesteps  | 206775   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 41693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0354   |
|    exploration_rate | 0.606    |
| time/               |          |
|    episodes         | 11656    |
|    fps              | 144      |
|    time_elapsed     | 1435     |
|    total_timesteps  | 206844   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00334  |
|    n_updates        | 41710    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.035    |
|    exploration_rate | 0.605    |
| time/               |          |
|    episodes         | 11660    |
|    fps              | 144      |
|    time_elapsed     | 1435     |
|    total_timesteps  | 206916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 41728    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.605    |
| time/               |          |
|    episodes         | 11664    |
|    fps              | 144      |
|    time_elapsed     | 1435     |
|    total_timesteps  | 206976   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 41743    |
----------------------------------
Eval num_timesteps=207000, episode_reward=-0.04 +/- 0.14
Episode length: 15.42 +/- 1.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.4     |
|    mean_reward      | -0.0406  |
| rollout/            |          |
|    exploration_rate | 0.605    |
| time/               |          |
|    total_timesteps  | 207000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00297  |
|    n_updates        | 41749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0362   |
|    exploration_rate | 0.605    |
| time/               |          |
|    episodes         | 11668    |
|    fps              | 144      |
|    time_elapsed     | 1436     |
|    total_timesteps  | 207037   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00372  |
|    n_updates        | 41759    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0565   |
|    exploration_rate | 0.605    |
| time/               |          |
|    episodes         | 11672    |
|    fps              | 144      |
|    time_elapsed     | 1436     |
|    total_timesteps  | 207098   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00403  |
|    n_updates        | 41774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0563   |
|    exploration_rate | 0.604    |
| time/               |          |
|    episodes         | 11676    |
|    fps              | 144      |
|    time_elapsed     | 1436     |
|    total_timesteps  | 207170   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 41792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0362   |
|    exploration_rate | 0.604    |
| time/               |          |
|    episodes         | 11680    |
|    fps              | 144      |
|    time_elapsed     | 1436     |
|    total_timesteps  | 207234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00582  |
|    n_updates        | 41808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.036    |
|    exploration_rate | 0.604    |
| time/               |          |
|    episodes         | 11684    |
|    fps              | 144      |
|    time_elapsed     | 1436     |
|    total_timesteps  | 207306   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00253  |
|    n_updates        | 41826    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0262   |
|    exploration_rate | 0.604    |
| time/               |          |
|    episodes         | 11688    |
|    fps              | 144      |
|    time_elapsed     | 1436     |
|    total_timesteps  | 207372   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00385  |
|    n_updates        | 41842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.603    |
| time/               |          |
|    episodes         | 11692    |
|    fps              | 144      |
|    time_elapsed     | 1436     |
|    total_timesteps  | 207434   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00586  |
|    n_updates        | 41858    |
----------------------------------
Eval num_timesteps=207500, episode_reward=0.06 +/- 0.33
Episode length: 14.66 +/- 1.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0624   |
| rollout/            |          |
|    exploration_rate | 0.603    |
| time/               |          |
|    total_timesteps  | 207500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00328  |
|    n_updates        | 41874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.603    |
| time/               |          |
|    episodes         | 11696    |
|    fps              | 144      |
|    time_elapsed     | 1438     |
|    total_timesteps  | 207503   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00614  |
|    n_updates        | 41875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0157   |
|    exploration_rate | 0.603    |
| time/               |          |
|    episodes         | 11700    |
|    fps              | 144      |
|    time_elapsed     | 1438     |
|    total_timesteps  | 207564   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 41890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.603    |
| time/               |          |
|    episodes         | 11704    |
|    fps              | 144      |
|    time_elapsed     | 1438     |
|    total_timesteps  | 207627   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 41906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0152   |
|    exploration_rate | 0.602    |
| time/               |          |
|    episodes         | 11708    |
|    fps              | 144      |
|    time_elapsed     | 1438     |
|    total_timesteps  | 207713   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00308  |
|    n_updates        | 41928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0158   |
|    exploration_rate | 0.602    |
| time/               |          |
|    episodes         | 11712    |
|    fps              | 144      |
|    time_elapsed     | 1438     |
|    total_timesteps  | 207776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 41943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.026    |
|    exploration_rate | 0.602    |
| time/               |          |
|    episodes         | 11716    |
|    fps              | 144      |
|    time_elapsed     | 1438     |
|    total_timesteps  | 207835   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 41958    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.602    |
| time/               |          |
|    episodes         | 11720    |
|    fps              | 144      |
|    time_elapsed     | 1438     |
|    total_timesteps  | 207906   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 41976    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0155   |
|    exploration_rate | 0.602    |
| time/               |          |
|    episodes         | 11724    |
|    fps              | 144      |
|    time_elapsed     | 1438     |
|    total_timesteps  | 207970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 41992    |
----------------------------------
Eval num_timesteps=208000, episode_reward=0.12 +/- 0.39
Episode length: 15.58 +/- 8.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.6     |
|    mean_reward      | 0.119    |
| rollout/            |          |
|    exploration_rate | 0.601    |
| time/               |          |
|    total_timesteps  | 208000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 41999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.601    |
| time/               |          |
|    episodes         | 11728    |
|    fps              | 144      |
|    time_elapsed     | 1440     |
|    total_timesteps  | 208039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00523  |
|    n_updates        | 42009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00549  |
|    exploration_rate | 0.601    |
| time/               |          |
|    episodes         | 11732    |
|    fps              | 144      |
|    time_elapsed     | 1440     |
|    total_timesteps  | 208102   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00522  |
|    n_updates        | 42025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00501 |
|    exploration_rate | 0.601    |
| time/               |          |
|    episodes         | 11736    |
|    fps              | 144      |
|    time_elapsed     | 1440     |
|    total_timesteps  | 208173   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0026   |
|    n_updates        | 42043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00565 |
|    exploration_rate | 0.601    |
| time/               |          |
|    episodes         | 11740    |
|    fps              | 144      |
|    time_elapsed     | 1440     |
|    total_timesteps  | 208254   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 42063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00421  |
|    exploration_rate | 0.6      |
| time/               |          |
|    episodes         | 11744    |
|    fps              | 144      |
|    time_elapsed     | 1440     |
|    total_timesteps  | 208321   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 42080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0242   |
|    exploration_rate | 0.6      |
| time/               |          |
|    episodes         | 11748    |
|    fps              | 144      |
|    time_elapsed     | 1440     |
|    total_timesteps  | 208382   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00349  |
|    n_updates        | 42095    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0242   |
|    exploration_rate | 0.6      |
| time/               |          |
|    episodes         | 11752    |
|    fps              | 144      |
|    time_elapsed     | 1440     |
|    total_timesteps  | 208447   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000737 |
|    n_updates        | 42111    |
----------------------------------
Eval num_timesteps=208500, episode_reward=0.00 +/- 0.24
Episode length: 14.94 +/- 0.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.0013   |
| rollout/            |          |
|    exploration_rate | 0.6      |
| time/               |          |
|    total_timesteps  | 208500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0113   |
|    n_updates        | 42124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0344   |
|    exploration_rate | 0.6      |
| time/               |          |
|    episodes         | 11756    |
|    fps              | 144      |
|    time_elapsed     | 1441     |
|    total_timesteps  | 208510   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 42127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0449   |
|    exploration_rate | 0.599    |
| time/               |          |
|    episodes         | 11760    |
|    fps              | 144      |
|    time_elapsed     | 1441     |
|    total_timesteps  | 208571   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00325  |
|    n_updates        | 42142    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0445   |
|    exploration_rate | 0.599    |
| time/               |          |
|    episodes         | 11764    |
|    fps              | 144      |
|    time_elapsed     | 1441     |
|    total_timesteps  | 208641   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 42160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0442   |
|    exploration_rate | 0.599    |
| time/               |          |
|    episodes         | 11768    |
|    fps              | 144      |
|    time_elapsed     | 1442     |
|    total_timesteps  | 208710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 42177    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0236   |
|    exploration_rate | 0.599    |
| time/               |          |
|    episodes         | 11772    |
|    fps              | 144      |
|    time_elapsed     | 1442     |
|    total_timesteps  | 208785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00309  |
|    n_updates        | 42196    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0238   |
|    exploration_rate | 0.598    |
| time/               |          |
|    episodes         | 11776    |
|    fps              | 144      |
|    time_elapsed     | 1442     |
|    total_timesteps  | 208851   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00189  |
|    n_updates        | 42212    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0237   |
|    exploration_rate | 0.598    |
| time/               |          |
|    episodes         | 11780    |
|    fps              | 144      |
|    time_elapsed     | 1442     |
|    total_timesteps  | 208918   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0226   |
|    n_updates        | 42229    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.024    |
|    exploration_rate | 0.598    |
| time/               |          |
|    episodes         | 11784    |
|    fps              | 144      |
|    time_elapsed     | 1442     |
|    total_timesteps  | 208982   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000965 |
|    n_updates        | 42245    |
----------------------------------
Eval num_timesteps=209000, episode_reward=0.02 +/- 0.27
Episode length: 15.10 +/- 1.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | 0.0206   |
| rollout/            |          |
|    exploration_rate | 0.598    |
| time/               |          |
|    total_timesteps  | 209000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000685 |
|    n_updates        | 42249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0342   |
|    exploration_rate | 0.598    |
| time/               |          |
|    episodes         | 11788    |
|    fps              | 144      |
|    time_elapsed     | 1443     |
|    total_timesteps  | 209044   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 42260    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0236   |
|    exploration_rate | 0.597    |
| time/               |          |
|    episodes         | 11792    |
|    fps              | 144      |
|    time_elapsed     | 1443     |
|    total_timesteps  | 209121   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000728 |
|    n_updates        | 42280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0339   |
|    exploration_rate | 0.597    |
| time/               |          |
|    episodes         | 11796    |
|    fps              | 144      |
|    time_elapsed     | 1443     |
|    total_timesteps  | 209184   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 42295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0331   |
|    exploration_rate | 0.597    |
| time/               |          |
|    episodes         | 11800    |
|    fps              | 144      |
|    time_elapsed     | 1443     |
|    total_timesteps  | 209263   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 42315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0429   |
|    exploration_rate | 0.597    |
| time/               |          |
|    episodes         | 11804    |
|    fps              | 144      |
|    time_elapsed     | 1443     |
|    total_timesteps  | 209331   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00552  |
|    n_updates        | 42332    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0333   |
|    exploration_rate | 0.596    |
| time/               |          |
|    episodes         | 11808    |
|    fps              | 145      |
|    time_elapsed     | 1444     |
|    total_timesteps  | 209407   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 42351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0227   |
|    exploration_rate | 0.596    |
| time/               |          |
|    episodes         | 11812    |
|    fps              | 145      |
|    time_elapsed     | 1444     |
|    total_timesteps  | 209485   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 42371    |
----------------------------------
Eval num_timesteps=209500, episode_reward=-0.02 +/- 0.20
Episode length: 16.12 +/- 3.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0235  |
| rollout/            |          |
|    exploration_rate | 0.596    |
| time/               |          |
|    total_timesteps  | 209500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 42374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0225   |
|    exploration_rate | 0.596    |
| time/               |          |
|    episodes         | 11816    |
|    fps              | 144      |
|    time_elapsed     | 1445     |
|    total_timesteps  | 209550   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00591  |
|    n_updates        | 42387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0223   |
|    exploration_rate | 0.596    |
| time/               |          |
|    episodes         | 11820    |
|    fps              | 145      |
|    time_elapsed     | 1445     |
|    total_timesteps  | 209626   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00191  |
|    n_updates        | 42406    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0223   |
|    exploration_rate | 0.595    |
| time/               |          |
|    episodes         | 11824    |
|    fps              | 145      |
|    time_elapsed     | 1445     |
|    total_timesteps  | 209690   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 42422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0225   |
|    exploration_rate | 0.595    |
| time/               |          |
|    episodes         | 11828    |
|    fps              | 145      |
|    time_elapsed     | 1445     |
|    total_timesteps  | 209753   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 42438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0226   |
|    exploration_rate | 0.595    |
| time/               |          |
|    episodes         | 11832    |
|    fps              | 145      |
|    time_elapsed     | 1445     |
|    total_timesteps  | 209815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 42453    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0227   |
|    exploration_rate | 0.595    |
| time/               |          |
|    episodes         | 11836    |
|    fps              | 145      |
|    time_elapsed     | 1446     |
|    total_timesteps  | 209883   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0017   |
|    n_updates        | 42470    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0333   |
|    exploration_rate | 0.594    |
| time/               |          |
|    episodes         | 11840    |
|    fps              | 145      |
|    time_elapsed     | 1446     |
|    total_timesteps  | 209949   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 42487    |
----------------------------------
Eval num_timesteps=210000, episode_reward=0.02 +/- 0.28
Episode length: 15.82 +/- 7.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.0177   |
| rollout/            |          |
|    exploration_rate | 0.594    |
| time/               |          |
|    total_timesteps  | 210000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 42499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0335   |
|    exploration_rate | 0.594    |
| time/               |          |
|    episodes         | 11844    |
|    fps              | 145      |
|    time_elapsed     | 1447     |
|    total_timesteps  | 210009   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00324  |
|    n_updates        | 42502    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0133   |
|    exploration_rate | 0.594    |
| time/               |          |
|    episodes         | 11848    |
|    fps              | 145      |
|    time_elapsed     | 1447     |
|    total_timesteps  | 210076   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 42518    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0232   |
|    exploration_rate | 0.594    |
| time/               |          |
|    episodes         | 11852    |
|    fps              | 145      |
|    time_elapsed     | 1447     |
|    total_timesteps  | 210143   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 42535    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0121   |
|    exploration_rate | 0.593    |
| time/               |          |
|    episodes         | 11856    |
|    fps              | 145      |
|    time_elapsed     | 1447     |
|    total_timesteps  | 210234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00474  |
|    n_updates        | 42558    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00194  |
|    exploration_rate | 0.593    |
| time/               |          |
|    episodes         | 11860    |
|    fps              | 145      |
|    time_elapsed     | 1447     |
|    total_timesteps  | 210298   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00436  |
|    n_updates        | 42574    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00098  |
|    exploration_rate | 0.593    |
| time/               |          |
|    episodes         | 11864    |
|    fps              | 145      |
|    time_elapsed     | 1447     |
|    total_timesteps  | 210392   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 42597    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00114  |
|    exploration_rate | 0.593    |
| time/               |          |
|    episodes         | 11868    |
|    fps              | 145      |
|    time_elapsed     | 1447     |
|    total_timesteps  | 210457   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00229  |
|    n_updates        | 42614    |
----------------------------------
Eval num_timesteps=210500, episode_reward=-0.04 +/- 0.14
Episode length: 15.18 +/- 0.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | -0.0397  |
| rollout/            |          |
|    exploration_rate | 0.593    |
| time/               |          |
|    total_timesteps  | 210500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00485  |
|    n_updates        | 42624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 0.592    |
| time/               |          |
|    episodes         | 11872    |
|    fps              | 145      |
|    time_elapsed     | 1448     |
|    total_timesteps  | 210518   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 42629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.022    |
|    exploration_rate | 0.592    |
| time/               |          |
|    episodes         | 11876    |
|    fps              | 145      |
|    time_elapsed     | 1448     |
|    total_timesteps  | 210578   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 42644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0222   |
|    exploration_rate | 0.592    |
| time/               |          |
|    episodes         | 11880    |
|    fps              | 145      |
|    time_elapsed     | 1449     |
|    total_timesteps  | 210638   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00553  |
|    n_updates        | 42659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0219   |
|    exploration_rate | 0.592    |
| time/               |          |
|    episodes         | 11884    |
|    fps              | 145      |
|    time_elapsed     | 1449     |
|    total_timesteps  | 210710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 42677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 0.592    |
| time/               |          |
|    episodes         | 11888    |
|    fps              | 145      |
|    time_elapsed     | 1449     |
|    total_timesteps  | 210776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00667  |
|    n_updates        | 42693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0121   |
|    exploration_rate | 0.591    |
| time/               |          |
|    episodes         | 11892    |
|    fps              | 145      |
|    time_elapsed     | 1449     |
|    total_timesteps  | 210845   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00368  |
|    n_updates        | 42711    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00209  |
|    exploration_rate | 0.591    |
| time/               |          |
|    episodes         | 11896    |
|    fps              | 145      |
|    time_elapsed     | 1449     |
|    total_timesteps  | 210907   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00616  |
|    n_updates        | 42726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00269  |
|    exploration_rate | 0.591    |
| time/               |          |
|    episodes         | 11900    |
|    fps              | 145      |
|    time_elapsed     | 1449     |
|    total_timesteps  | 210971   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00333  |
|    n_updates        | 42742    |
----------------------------------
Eval num_timesteps=211000, episode_reward=-0.04 +/- 0.14
Episode length: 15.22 +/- 1.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | -0.0398  |
| rollout/            |          |
|    exploration_rate | 0.591    |
| time/               |          |
|    total_timesteps  | 211000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 42749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00703 |
|    exploration_rate | 0.591    |
| time/               |          |
|    episodes         | 11904    |
|    fps              | 145      |
|    time_elapsed     | 1450     |
|    total_timesteps  | 211032   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0024   |
|    n_updates        | 42757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00651 |
|    exploration_rate | 0.59     |
| time/               |          |
|    episodes         | 11908    |
|    fps              | 145      |
|    time_elapsed     | 1450     |
|    total_timesteps  | 211095   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00494  |
|    n_updates        | 42773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00591 |
|    exploration_rate | 0.59     |
| time/               |          |
|    episodes         | 11912    |
|    fps              | 145      |
|    time_elapsed     | 1450     |
|    total_timesteps  | 211158   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 42789    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.016   |
|    exploration_rate | 0.59     |
| time/               |          |
|    episodes         | 11916    |
|    fps              | 145      |
|    time_elapsed     | 1450     |
|    total_timesteps  | 211224   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 42805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00525 |
|    exploration_rate | 0.59     |
| time/               |          |
|    episodes         | 11920    |
|    fps              | 145      |
|    time_elapsed     | 1451     |
|    total_timesteps  | 211282   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 42820    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00557 |
|    exploration_rate | 0.589    |
| time/               |          |
|    episodes         | 11924    |
|    fps              | 145      |
|    time_elapsed     | 1451     |
|    total_timesteps  | 211354   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 42838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00577 |
|    exploration_rate | 0.589    |
| time/               |          |
|    episodes         | 11928    |
|    fps              | 145      |
|    time_elapsed     | 1451     |
|    total_timesteps  | 211422   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 42855    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.004    |
|    exploration_rate | 0.589    |
| time/               |          |
|    episodes         | 11932    |
|    fps              | 145      |
|    time_elapsed     | 1451     |
|    total_timesteps  | 211490   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00587  |
|    n_updates        | 42872    |
----------------------------------
Eval num_timesteps=211500, episode_reward=-0.00 +/- 0.24
Episode length: 16.36 +/- 8.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | -0.00438 |
| rollout/            |          |
|    exploration_rate | 0.589    |
| time/               |          |
|    total_timesteps  | 211500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00246  |
|    n_updates        | 42874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00396  |
|    exploration_rate | 0.589    |
| time/               |          |
|    episodes         | 11936    |
|    fps              | 145      |
|    time_elapsed     | 1452     |
|    total_timesteps  | 211559   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 42889    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00357  |
|    exploration_rate | 0.588    |
| time/               |          |
|    episodes         | 11940    |
|    fps              | 145      |
|    time_elapsed     | 1452     |
|    total_timesteps  | 211635   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00267  |
|    n_updates        | 42908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00682 |
|    exploration_rate | 0.588    |
| time/               |          |
|    episodes         | 11944    |
|    fps              | 145      |
|    time_elapsed     | 1452     |
|    total_timesteps  | 211705   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 42926    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0071  |
|    exploration_rate | 0.588    |
| time/               |          |
|    episodes         | 11948    |
|    fps              | 145      |
|    time_elapsed     | 1452     |
|    total_timesteps  | 211779   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00304  |
|    n_updates        | 42944    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0174  |
|    exploration_rate | 0.588    |
| time/               |          |
|    episodes         | 11952    |
|    fps              | 145      |
|    time_elapsed     | 1453     |
|    total_timesteps  | 211854   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 42963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0162  |
|    exploration_rate | 0.587    |
| time/               |          |
|    episodes         | 11956    |
|    fps              | 145      |
|    time_elapsed     | 1453     |
|    total_timesteps  | 211916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00281  |
|    n_updates        | 42978    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.587    |
| time/               |          |
|    episodes         | 11960    |
|    fps              | 145      |
|    time_elapsed     | 1453     |
|    total_timesteps  | 211983   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 42995    |
----------------------------------
Eval num_timesteps=212000, episode_reward=-0.02 +/- 0.30
Episode length: 24.44 +/- 18.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 24.4     |
|    mean_reward      | -0.0168  |
| rollout/            |          |
|    exploration_rate | 0.587    |
| time/               |          |
|    total_timesteps  | 212000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 42999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.015   |
|    exploration_rate | 0.587    |
| time/               |          |
|    episodes         | 11964    |
|    fps              | 145      |
|    time_elapsed     | 1454     |
|    total_timesteps  | 212044   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00733  |
|    n_updates        | 43010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0051  |
|    exploration_rate | 0.587    |
| time/               |          |
|    episodes         | 11968    |
|    fps              | 145      |
|    time_elapsed     | 1455     |
|    total_timesteps  | 212110   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 43027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0154  |
|    exploration_rate | 0.586    |
| time/               |          |
|    episodes         | 11972    |
|    fps              | 145      |
|    time_elapsed     | 1455     |
|    total_timesteps  | 212178   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 43044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0156  |
|    exploration_rate | 0.586    |
| time/               |          |
|    episodes         | 11976    |
|    fps              | 145      |
|    time_elapsed     | 1455     |
|    total_timesteps  | 212243   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 43060    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0158  |
|    exploration_rate | 0.586    |
| time/               |          |
|    episodes         | 11980    |
|    fps              | 145      |
|    time_elapsed     | 1455     |
|    total_timesteps  | 212309   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 43077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0158  |
|    exploration_rate | 0.586    |
| time/               |          |
|    episodes         | 11984    |
|    fps              | 145      |
|    time_elapsed     | 1455     |
|    total_timesteps  | 212381   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00225  |
|    n_updates        | 43095    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0159  |
|    exploration_rate | 0.586    |
| time/               |          |
|    episodes         | 11988    |
|    fps              | 145      |
|    time_elapsed     | 1455     |
|    total_timesteps  | 212448   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00236  |
|    n_updates        | 43111    |
----------------------------------
Eval num_timesteps=212500, episode_reward=-0.06 +/- 0.15
Episode length: 19.58 +/- 12.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.6     |
|    mean_reward      | -0.0574  |
| rollout/            |          |
|    exploration_rate | 0.585    |
| time/               |          |
|    total_timesteps  | 212500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00203  |
|    n_updates        | 43124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0157  |
|    exploration_rate | 0.585    |
| time/               |          |
|    episodes         | 11992    |
|    fps              | 145      |
|    time_elapsed     | 1456     |
|    total_timesteps  | 212513   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 43128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0161  |
|    exploration_rate | 0.585    |
| time/               |          |
|    episodes         | 11996    |
|    fps              | 145      |
|    time_elapsed     | 1456     |
|    total_timesteps  | 212586   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000943 |
|    n_updates        | 43146    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00602 |
|    exploration_rate | 0.585    |
| time/               |          |
|    episodes         | 12000    |
|    fps              | 145      |
|    time_elapsed     | 1457     |
|    total_timesteps  | 212647   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00238  |
|    n_updates        | 43161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00618 |
|    exploration_rate | 0.585    |
| time/               |          |
|    episodes         | 12004    |
|    fps              | 145      |
|    time_elapsed     | 1457     |
|    total_timesteps  | 212712   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00557  |
|    n_updates        | 43177    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00378  |
|    exploration_rate | 0.584    |
| time/               |          |
|    episodes         | 12008    |
|    fps              | 146      |
|    time_elapsed     | 1457     |
|    total_timesteps  | 212776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 43193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00366  |
|    exploration_rate | 0.584    |
| time/               |          |
|    episodes         | 12012    |
|    fps              | 146      |
|    time_elapsed     | 1457     |
|    total_timesteps  | 212842   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00306  |
|    n_updates        | 43210    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00382  |
|    exploration_rate | 0.584    |
| time/               |          |
|    episodes         | 12016    |
|    fps              | 146      |
|    time_elapsed     | 1457     |
|    total_timesteps  | 212904   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 43225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00638 |
|    exploration_rate | 0.584    |
| time/               |          |
|    episodes         | 12020    |
|    fps              | 146      |
|    time_elapsed     | 1457     |
|    total_timesteps  | 212967   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00289  |
|    n_updates        | 43241    |
----------------------------------
Eval num_timesteps=213000, episode_reward=-0.04 +/- 0.21
Episode length: 20.30 +/- 14.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20.3     |
|    mean_reward      | -0.0402  |
| rollout/            |          |
|    exploration_rate | 0.584    |
| time/               |          |
|    total_timesteps  | 213000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 43249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00395  |
|    exploration_rate | 0.583    |
| time/               |          |
|    episodes         | 12024    |
|    fps              | 146      |
|    time_elapsed     | 1459     |
|    total_timesteps  | 213031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00472  |
|    n_updates        | 43257    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00411  |
|    exploration_rate | 0.583    |
| time/               |          |
|    episodes         | 12028    |
|    fps              | 146      |
|    time_elapsed     | 1459     |
|    total_timesteps  | 213095   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 43273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00566 |
|    exploration_rate | 0.583    |
| time/               |          |
|    episodes         | 12032    |
|    fps              | 146      |
|    time_elapsed     | 1459     |
|    total_timesteps  | 213157   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 43289    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00485  |
|    exploration_rate | 0.583    |
| time/               |          |
|    episodes         | 12036    |
|    fps              | 146      |
|    time_elapsed     | 1459     |
|    total_timesteps  | 213213   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00457  |
|    n_updates        | 43303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00463 |
|    exploration_rate | 0.583    |
| time/               |          |
|    episodes         | 12040    |
|    fps              | 146      |
|    time_elapsed     | 1459     |
|    total_timesteps  | 213276   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 43318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00455 |
|    exploration_rate | 0.582    |
| time/               |          |
|    episodes         | 12044    |
|    fps              | 146      |
|    time_elapsed     | 1459     |
|    total_timesteps  | 213344   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00201  |
|    n_updates        | 43335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00411 |
|    exploration_rate | 0.582    |
| time/               |          |
|    episodes         | 12048    |
|    fps              | 146      |
|    time_elapsed     | 1459     |
|    total_timesteps  | 213407   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 43351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00371 |
|    exploration_rate | 0.582    |
| time/               |          |
|    episodes         | 12052    |
|    fps              | 146      |
|    time_elapsed     | 1459     |
|    total_timesteps  | 213472   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 43367    |
----------------------------------
Eval num_timesteps=213500, episode_reward=-0.03 +/- 0.21
Episode length: 17.84 +/- 11.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.8     |
|    mean_reward      | -0.0304  |
| rollout/            |          |
|    exploration_rate | 0.582    |
| time/               |          |
|    total_timesteps  | 213500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 43374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.00594  |
|    exploration_rate | 0.582    |
| time/               |          |
|    episodes         | 12056    |
|    fps              | 146      |
|    time_elapsed     | 1460     |
|    total_timesteps  | 213543   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 43385    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.00598  |
|    exploration_rate | 0.581    |
| time/               |          |
|    episodes         | 12060    |
|    fps              | 146      |
|    time_elapsed     | 1460     |
|    total_timesteps  | 213609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00654  |
|    n_updates        | 43402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0055   |
|    exploration_rate | 0.581    |
| time/               |          |
|    episodes         | 12064    |
|    fps              | 146      |
|    time_elapsed     | 1461     |
|    total_timesteps  | 213682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 43420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00425 |
|    exploration_rate | 0.581    |
| time/               |          |
|    episodes         | 12068    |
|    fps              | 146      |
|    time_elapsed     | 1461     |
|    total_timesteps  | 213742   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000919 |
|    n_updates        | 43435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00413 |
|    exploration_rate | 0.581    |
| time/               |          |
|    episodes         | 12072    |
|    fps              | 146      |
|    time_elapsed     | 1461     |
|    total_timesteps  | 213807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 43451    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 0.58     |
| time/               |          |
|    episodes         | 12076    |
|    fps              | 146      |
|    time_elapsed     | 1461     |
|    total_timesteps  | 213875   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 43468    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.58     |
| time/               |          |
|    episodes         | 12080    |
|    fps              | 146      |
|    time_elapsed     | 1461     |
|    total_timesteps  | 213936   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00316  |
|    n_updates        | 43483    |
----------------------------------
Eval num_timesteps=214000, episode_reward=-0.00 +/- 0.24
Episode length: 16.04 +/- 4.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.00316 |
| rollout/            |          |
|    exploration_rate | 0.58     |
| time/               |          |
|    total_timesteps  | 214000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 43499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.58     |
| time/               |          |
|    episodes         | 12084    |
|    fps              | 146      |
|    time_elapsed     | 1462     |
|    total_timesteps  | 214000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.58     |
| time/               |          |
|    episodes         | 12088    |
|    fps              | 146      |
|    time_elapsed     | 1462     |
|    total_timesteps  | 214065   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000733 |
|    n_updates        | 43516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.579    |
| time/               |          |
|    episodes         | 12092    |
|    fps              | 146      |
|    time_elapsed     | 1462     |
|    total_timesteps  | 214127   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 43531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.579    |
| time/               |          |
|    episodes         | 12096    |
|    fps              | 146      |
|    time_elapsed     | 1462     |
|    total_timesteps  | 214194   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 43548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.579    |
| time/               |          |
|    episodes         | 12100    |
|    fps              | 146      |
|    time_elapsed     | 1462     |
|    total_timesteps  | 214255   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 43563    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.579    |
| time/               |          |
|    episodes         | 12104    |
|    fps              | 146      |
|    time_elapsed     | 1463     |
|    total_timesteps  | 214317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00352  |
|    n_updates        | 43579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0342  |
|    exploration_rate | 0.578    |
| time/               |          |
|    episodes         | 12108    |
|    fps              | 146      |
|    time_elapsed     | 1463     |
|    total_timesteps  | 214406   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00451  |
|    n_updates        | 43601    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0239  |
|    exploration_rate | 0.578    |
| time/               |          |
|    episodes         | 12112    |
|    fps              | 146      |
|    time_elapsed     | 1463     |
|    total_timesteps  | 214464   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 43615    |
----------------------------------
Eval num_timesteps=214500, episode_reward=0.04 +/- 0.30
Episode length: 14.70 +/- 1.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0422   |
| rollout/            |          |
|    exploration_rate | 0.578    |
| time/               |          |
|    total_timesteps  | 214500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0018   |
|    n_updates        | 43624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.578    |
| time/               |          |
|    episodes         | 12116    |
|    fps              | 146      |
|    time_elapsed     | 1464     |
|    total_timesteps  | 214531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00552  |
|    n_updates        | 43632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.578    |
| time/               |          |
|    episodes         | 12120    |
|    fps              | 146      |
|    time_elapsed     | 1464     |
|    total_timesteps  | 214594   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 43648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0243  |
|    exploration_rate | 0.577    |
| time/               |          |
|    episodes         | 12124    |
|    fps              | 146      |
|    time_elapsed     | 1464     |
|    total_timesteps  | 214664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000954 |
|    n_updates        | 43665    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0245  |
|    exploration_rate | 0.577    |
| time/               |          |
|    episodes         | 12128    |
|    fps              | 146      |
|    time_elapsed     | 1464     |
|    total_timesteps  | 214733   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00268  |
|    n_updates        | 43683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0249  |
|    exploration_rate | 0.577    |
| time/               |          |
|    episodes         | 12132    |
|    fps              | 146      |
|    time_elapsed     | 1464     |
|    total_timesteps  | 214804   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 43700    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0352  |
|    exploration_rate | 0.577    |
| time/               |          |
|    episodes         | 12136    |
|    fps              | 146      |
|    time_elapsed     | 1464     |
|    total_timesteps  | 214867   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000881 |
|    n_updates        | 43716    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0358  |
|    exploration_rate | 0.576    |
| time/               |          |
|    episodes         | 12140    |
|    fps              | 146      |
|    time_elapsed     | 1465     |
|    total_timesteps  | 214947   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 43736    |
----------------------------------
Eval num_timesteps=215000, episode_reward=-0.06 +/- 0.15
Episode length: 20.44 +/- 12.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20.4     |
|    mean_reward      | -0.0608  |
| rollout/            |          |
|    exploration_rate | 0.576    |
| time/               |          |
|    total_timesteps  | 215000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 43749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0254  |
|    exploration_rate | 0.576    |
| time/               |          |
|    episodes         | 12144    |
|    fps              | 146      |
|    time_elapsed     | 1466     |
|    total_timesteps  | 215005   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 43751    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0152  |
|    exploration_rate | 0.576    |
| time/               |          |
|    episodes         | 12148    |
|    fps              | 146      |
|    time_elapsed     | 1466     |
|    total_timesteps  | 215062   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 43765    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00546 |
|    exploration_rate | 0.576    |
| time/               |          |
|    episodes         | 12152    |
|    fps              | 146      |
|    time_elapsed     | 1466     |
|    total_timesteps  | 215134   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00356  |
|    n_updates        | 43783    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0156  |
|    exploration_rate | 0.576    |
| time/               |          |
|    episodes         | 12156    |
|    fps              | 146      |
|    time_elapsed     | 1466     |
|    total_timesteps  | 215209   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00304  |
|    n_updates        | 43802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0159  |
|    exploration_rate | 0.575    |
| time/               |          |
|    episodes         | 12160    |
|    fps              | 146      |
|    time_elapsed     | 1466     |
|    total_timesteps  | 215283   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 43820    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0159  |
|    exploration_rate | 0.575    |
| time/               |          |
|    episodes         | 12164    |
|    fps              | 146      |
|    time_elapsed     | 1466     |
|    total_timesteps  | 215354   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 43838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0159  |
|    exploration_rate | 0.575    |
| time/               |          |
|    episodes         | 12168    |
|    fps              | 146      |
|    time_elapsed     | 1467     |
|    total_timesteps  | 215416   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0106   |
|    n_updates        | 43853    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0159  |
|    exploration_rate | 0.575    |
| time/               |          |
|    episodes         | 12172    |
|    fps              | 146      |
|    time_elapsed     | 1467     |
|    total_timesteps  | 215480   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 43869    |
----------------------------------
Eval num_timesteps=215500, episode_reward=-0.08 +/- 0.28
Episode length: 40.16 +/- 21.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.2     |
|    mean_reward      | -0.0796  |
| rollout/            |          |
|    exploration_rate | 0.574    |
| time/               |          |
|    total_timesteps  | 215500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 43874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0162  |
|    exploration_rate | 0.574    |
| time/               |          |
|    episodes         | 12176    |
|    fps              | 146      |
|    time_elapsed     | 1469     |
|    total_timesteps  | 215555   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 43888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00611 |
|    exploration_rate | 0.574    |
| time/               |          |
|    episodes         | 12180    |
|    fps              | 146      |
|    time_elapsed     | 1469     |
|    total_timesteps  | 215614   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 43903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00627 |
|    exploration_rate | 0.574    |
| time/               |          |
|    episodes         | 12184    |
|    fps              | 146      |
|    time_elapsed     | 1470     |
|    total_timesteps  | 215682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00378  |
|    n_updates        | 43920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00374  |
|    exploration_rate | 0.574    |
| time/               |          |
|    episodes         | 12188    |
|    fps              | 146      |
|    time_elapsed     | 1470     |
|    total_timesteps  | 215747   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00321  |
|    n_updates        | 43936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00378  |
|    exploration_rate | 0.573    |
| time/               |          |
|    episodes         | 12192    |
|    fps              | 146      |
|    time_elapsed     | 1470     |
|    total_timesteps  | 215808   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00382  |
|    n_updates        | 43951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.573    |
| time/               |          |
|    episodes         | 12196    |
|    fps              | 146      |
|    time_elapsed     | 1470     |
|    total_timesteps  | 215870   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000809 |
|    n_updates        | 43967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0136   |
|    exploration_rate | 0.573    |
| time/               |          |
|    episodes         | 12200    |
|    fps              | 146      |
|    time_elapsed     | 1470     |
|    total_timesteps  | 215940   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 43984    |
----------------------------------
Eval num_timesteps=216000, episode_reward=0.04 +/- 0.31
Episode length: 14.98 +/- 1.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | 0.0412   |
| rollout/            |          |
|    exploration_rate | 0.573    |
| time/               |          |
|    total_timesteps  | 216000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 43999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0236   |
|    exploration_rate | 0.573    |
| time/               |          |
|    episodes         | 12204    |
|    fps              | 146      |
|    time_elapsed     | 1471     |
|    total_timesteps  | 216002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00224  |
|    n_updates        | 44000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0248   |
|    exploration_rate | 0.572    |
| time/               |          |
|    episodes         | 12208    |
|    fps              | 146      |
|    time_elapsed     | 1471     |
|    total_timesteps  | 216063   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 44015    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0246   |
|    exploration_rate | 0.572    |
| time/               |          |
|    episodes         | 12212    |
|    fps              | 146      |
|    time_elapsed     | 1471     |
|    total_timesteps  | 216125   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00339  |
|    n_updates        | 44031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0145   |
|    exploration_rate | 0.572    |
| time/               |          |
|    episodes         | 12216    |
|    fps              | 146      |
|    time_elapsed     | 1471     |
|    total_timesteps  | 216196   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00245  |
|    n_updates        | 44048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0246   |
|    exploration_rate | 0.572    |
| time/               |          |
|    episodes         | 12220    |
|    fps              | 146      |
|    time_elapsed     | 1472     |
|    total_timesteps  | 216255   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 44063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0247   |
|    exploration_rate | 0.571    |
| time/               |          |
|    episodes         | 12224    |
|    fps              | 146      |
|    time_elapsed     | 1472     |
|    total_timesteps  | 216322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00207  |
|    n_updates        | 44080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0251   |
|    exploration_rate | 0.571    |
| time/               |          |
|    episodes         | 12228    |
|    fps              | 146      |
|    time_elapsed     | 1472     |
|    total_timesteps  | 216382   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 44095    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0255   |
|    exploration_rate | 0.571    |
| time/               |          |
|    episodes         | 12232    |
|    fps              | 147      |
|    time_elapsed     | 1472     |
|    total_timesteps  | 216444   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 44110    |
----------------------------------
Eval num_timesteps=216500, episode_reward=-0.02 +/- 0.26
Episode length: 21.22 +/- 16.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 21.2     |
|    mean_reward      | -0.0238  |
| rollout/            |          |
|    exploration_rate | 0.571    |
| time/               |          |
|    total_timesteps  | 216500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00324  |
|    n_updates        | 44124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0354   |
|    exploration_rate | 0.571    |
| time/               |          |
|    episodes         | 12236    |
|    fps              | 146      |
|    time_elapsed     | 1473     |
|    total_timesteps  | 216508   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00201  |
|    n_updates        | 44126    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.571    |
| time/               |          |
|    episodes         | 12240    |
|    fps              | 146      |
|    time_elapsed     | 1473     |
|    total_timesteps  | 216580   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 44144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0254   |
|    exploration_rate | 0.57     |
| time/               |          |
|    episodes         | 12244    |
|    fps              | 146      |
|    time_elapsed     | 1474     |
|    total_timesteps  | 216646   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00296  |
|    n_updates        | 44161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0249   |
|    exploration_rate | 0.57     |
| time/               |          |
|    episodes         | 12248    |
|    fps              | 147      |
|    time_elapsed     | 1474     |
|    total_timesteps  | 216716   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 44178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0251   |
|    exploration_rate | 0.57     |
| time/               |          |
|    episodes         | 12252    |
|    fps              | 147      |
|    time_elapsed     | 1474     |
|    total_timesteps  | 216784   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00456  |
|    n_updates        | 44195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0254   |
|    exploration_rate | 0.57     |
| time/               |          |
|    episodes         | 12256    |
|    fps              | 147      |
|    time_elapsed     | 1474     |
|    total_timesteps  | 216850   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000915 |
|    n_updates        | 44212    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0258   |
|    exploration_rate | 0.569    |
| time/               |          |
|    episodes         | 12260    |
|    fps              | 147      |
|    time_elapsed     | 1474     |
|    total_timesteps  | 216914   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 44228    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0258   |
|    exploration_rate | 0.569    |
| time/               |          |
|    episodes         | 12264    |
|    fps              | 147      |
|    time_elapsed     | 1474     |
|    total_timesteps  | 216985   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00596  |
|    n_updates        | 44246    |
----------------------------------
Eval num_timesteps=217000, episode_reward=0.08 +/- 0.35
Episode length: 14.80 +/- 2.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.0818   |
| rollout/            |          |
|    exploration_rate | 0.569    |
| time/               |          |
|    total_timesteps  | 217000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00661  |
|    n_updates        | 44249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0255   |
|    exploration_rate | 0.569    |
| time/               |          |
|    episodes         | 12268    |
|    fps              | 147      |
|    time_elapsed     | 1475     |
|    total_timesteps  | 217055   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 44263    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0255   |
|    exploration_rate | 0.569    |
| time/               |          |
|    episodes         | 12272    |
|    fps              | 147      |
|    time_elapsed     | 1475     |
|    total_timesteps  | 217119   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 44279    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.568    |
| time/               |          |
|    episodes         | 12276    |
|    fps              | 147      |
|    time_elapsed     | 1476     |
|    total_timesteps  | 217192   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 44297    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0152   |
|    exploration_rate | 0.568    |
| time/               |          |
|    episodes         | 12280    |
|    fps              | 147      |
|    time_elapsed     | 1476     |
|    total_timesteps  | 217261   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 44315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.568    |
| time/               |          |
|    episodes         | 12284    |
|    fps              | 147      |
|    time_elapsed     | 1476     |
|    total_timesteps  | 217333   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00623  |
|    n_updates        | 44333    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.568    |
| time/               |          |
|    episodes         | 12288    |
|    fps              | 147      |
|    time_elapsed     | 1476     |
|    total_timesteps  | 217391   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00212  |
|    n_updates        | 44347    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.567    |
| time/               |          |
|    episodes         | 12292    |
|    fps              | 147      |
|    time_elapsed     | 1476     |
|    total_timesteps  | 217460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00306  |
|    n_updates        | 44364    |
----------------------------------
Eval num_timesteps=217500, episode_reward=0.06 +/- 0.33
Episode length: 16.02 +/- 3.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.0569   |
| rollout/            |          |
|    exploration_rate | 0.567    |
| time/               |          |
|    total_timesteps  | 217500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 44374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.567    |
| time/               |          |
|    episodes         | 12296    |
|    fps              | 147      |
|    time_elapsed     | 1477     |
|    total_timesteps  | 217520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00286  |
|    n_updates        | 44379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0252   |
|    exploration_rate | 0.567    |
| time/               |          |
|    episodes         | 12300    |
|    fps              | 147      |
|    time_elapsed     | 1477     |
|    total_timesteps  | 217585   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000649 |
|    n_updates        | 44396    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0148   |
|    exploration_rate | 0.567    |
| time/               |          |
|    episodes         | 12304    |
|    fps              | 147      |
|    time_elapsed     | 1478     |
|    total_timesteps  | 217659   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 44414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.566    |
| time/               |          |
|    episodes         | 12308    |
|    fps              | 147      |
|    time_elapsed     | 1478     |
|    total_timesteps  | 217723   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 44430    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0145   |
|    exploration_rate | 0.566    |
| time/               |          |
|    episodes         | 12312    |
|    fps              | 147      |
|    time_elapsed     | 1478     |
|    total_timesteps  | 217789   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00598  |
|    n_updates        | 44447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.566    |
| time/               |          |
|    episodes         | 12316    |
|    fps              | 147      |
|    time_elapsed     | 1478     |
|    total_timesteps  | 217858   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00472  |
|    n_updates        | 44464    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0243   |
|    exploration_rate | 0.566    |
| time/               |          |
|    episodes         | 12320    |
|    fps              | 147      |
|    time_elapsed     | 1478     |
|    total_timesteps  | 217923   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 44480    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0244   |
|    exploration_rate | 0.565    |
| time/               |          |
|    episodes         | 12324    |
|    fps              | 147      |
|    time_elapsed     | 1478     |
|    total_timesteps  | 217989   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00275  |
|    n_updates        | 44497    |
----------------------------------
Eval num_timesteps=218000, episode_reward=-0.02 +/- 0.20
Episode length: 16.52 +/- 3.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.5     |
|    mean_reward      | -0.025   |
| rollout/            |          |
|    exploration_rate | 0.565    |
| time/               |          |
|    total_timesteps  | 218000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00213  |
|    n_updates        | 44499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0239   |
|    exploration_rate | 0.565    |
| time/               |          |
|    episodes         | 12328    |
|    fps              | 147      |
|    time_elapsed     | 1479     |
|    total_timesteps  | 218062   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 44515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0239   |
|    exploration_rate | 0.565    |
| time/               |          |
|    episodes         | 12332    |
|    fps              | 147      |
|    time_elapsed     | 1479     |
|    total_timesteps  | 218123   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 44530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.565    |
| time/               |          |
|    episodes         | 12336    |
|    fps              | 147      |
|    time_elapsed     | 1479     |
|    total_timesteps  | 218186   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 44546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0242   |
|    exploration_rate | 0.564    |
| time/               |          |
|    episodes         | 12340    |
|    fps              | 147      |
|    time_elapsed     | 1479     |
|    total_timesteps  | 218250   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 44562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0244   |
|    exploration_rate | 0.564    |
| time/               |          |
|    episodes         | 12344    |
|    fps              | 147      |
|    time_elapsed     | 1479     |
|    total_timesteps  | 218312   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00182  |
|    n_updates        | 44577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0147   |
|    exploration_rate | 0.564    |
| time/               |          |
|    episodes         | 12348    |
|    fps              | 147      |
|    time_elapsed     | 1480     |
|    total_timesteps  | 218374   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 44593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00474  |
|    exploration_rate | 0.564    |
| time/               |          |
|    episodes         | 12352    |
|    fps              | 147      |
|    time_elapsed     | 1480     |
|    total_timesteps  | 218441   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00386  |
|    n_updates        | 44610    |
----------------------------------
Eval num_timesteps=218500, episode_reward=0.00 +/- 0.24
Episode length: 15.14 +/- 1.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | 0.00046  |
| rollout/            |          |
|    exploration_rate | 0.564    |
| time/               |          |
|    total_timesteps  | 218500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 44624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00474  |
|    exploration_rate | 0.563    |
| time/               |          |
|    episodes         | 12356    |
|    fps              | 147      |
|    time_elapsed     | 1481     |
|    total_timesteps  | 218507   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00598  |
|    n_updates        | 44626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00474  |
|    exploration_rate | 0.563    |
| time/               |          |
|    episodes         | 12360    |
|    fps              | 147      |
|    time_elapsed     | 1481     |
|    total_timesteps  | 218571   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 44642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00502  |
|    exploration_rate | 0.563    |
| time/               |          |
|    episodes         | 12364    |
|    fps              | 147      |
|    time_elapsed     | 1481     |
|    total_timesteps  | 218635   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00445  |
|    n_updates        | 44658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00514  |
|    exploration_rate | 0.563    |
| time/               |          |
|    episodes         | 12368    |
|    fps              | 147      |
|    time_elapsed     | 1481     |
|    total_timesteps  | 218702   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00207  |
|    n_updates        | 44675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00514  |
|    exploration_rate | 0.563    |
| time/               |          |
|    episodes         | 12372    |
|    fps              | 147      |
|    time_elapsed     | 1481     |
|    total_timesteps  | 218766   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00309  |
|    n_updates        | 44691    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00554  |
|    exploration_rate | 0.562    |
| time/               |          |
|    episodes         | 12376    |
|    fps              | 147      |
|    time_elapsed     | 1481     |
|    total_timesteps  | 218829   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 44707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00562  |
|    exploration_rate | 0.562    |
| time/               |          |
|    episodes         | 12380    |
|    fps              | 147      |
|    time_elapsed     | 1482     |
|    total_timesteps  | 218896   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 44723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00608  |
|    exploration_rate | 0.562    |
| time/               |          |
|    episodes         | 12384    |
|    fps              | 147      |
|    time_elapsed     | 1482     |
|    total_timesteps  | 218957   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 44739    |
----------------------------------
Eval num_timesteps=219000, episode_reward=0.06 +/- 0.33
Episode length: 14.76 +/- 1.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.062    |
| rollout/            |          |
|    exploration_rate | 0.562    |
| time/               |          |
|    total_timesteps  | 219000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00257  |
|    n_updates        | 44749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00413 |
|    exploration_rate | 0.562    |
| time/               |          |
|    episodes         | 12388    |
|    fps              | 147      |
|    time_elapsed     | 1483     |
|    total_timesteps  | 219020   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 44754    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00622  |
|    exploration_rate | 0.561    |
| time/               |          |
|    episodes         | 12392    |
|    fps              | 147      |
|    time_elapsed     | 1483     |
|    total_timesteps  | 219080   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000923 |
|    n_updates        | 44769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00481 |
|    exploration_rate | 0.561    |
| time/               |          |
|    episodes         | 12396    |
|    fps              | 147      |
|    time_elapsed     | 1483     |
|    total_timesteps  | 219166   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 44791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00465 |
|    exploration_rate | 0.561    |
| time/               |          |
|    episodes         | 12400    |
|    fps              | 147      |
|    time_elapsed     | 1483     |
|    total_timesteps  | 219227   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00502  |
|    n_updates        | 44806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00429 |
|    exploration_rate | 0.561    |
| time/               |          |
|    episodes         | 12404    |
|    fps              | 147      |
|    time_elapsed     | 1483     |
|    total_timesteps  | 219292   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 44822    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00485 |
|    exploration_rate | 0.56     |
| time/               |          |
|    episodes         | 12408    |
|    fps              | 147      |
|    time_elapsed     | 1483     |
|    total_timesteps  | 219370   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00261  |
|    n_updates        | 44842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.015   |
|    exploration_rate | 0.56     |
| time/               |          |
|    episodes         | 12412    |
|    fps              | 147      |
|    time_elapsed     | 1483     |
|    total_timesteps  | 219439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00753  |
|    n_updates        | 44859    |
----------------------------------
Eval num_timesteps=219500, episode_reward=0.05 +/- 0.34
Episode length: 16.68 +/- 8.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.7     |
|    mean_reward      | 0.0544   |
| rollout/            |          |
|    exploration_rate | 0.56     |
| time/               |          |
|    total_timesteps  | 219500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 44874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.56     |
| time/               |          |
|    episodes         | 12416    |
|    fps              | 147      |
|    time_elapsed     | 1485     |
|    total_timesteps  | 219504   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00294  |
|    n_updates        | 44875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0248  |
|    exploration_rate | 0.56     |
| time/               |          |
|    episodes         | 12420    |
|    fps              | 147      |
|    time_elapsed     | 1485     |
|    total_timesteps  | 219568   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 44891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0248  |
|    exploration_rate | 0.559    |
| time/               |          |
|    episodes         | 12424    |
|    fps              | 147      |
|    time_elapsed     | 1485     |
|    total_timesteps  | 219633   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00245  |
|    n_updates        | 44908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.559    |
| time/               |          |
|    episodes         | 12428    |
|    fps              | 147      |
|    time_elapsed     | 1485     |
|    total_timesteps  | 219702   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 44925    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0147  |
|    exploration_rate | 0.559    |
| time/               |          |
|    episodes         | 12432    |
|    fps              | 147      |
|    time_elapsed     | 1485     |
|    total_timesteps  | 219766   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000954 |
|    n_updates        | 44941    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.559    |
| time/               |          |
|    episodes         | 12436    |
|    fps              | 147      |
|    time_elapsed     | 1485     |
|    total_timesteps  | 219827   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00672  |
|    n_updates        | 44956    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.558    |
| time/               |          |
|    episodes         | 12440    |
|    fps              | 148      |
|    time_elapsed     | 1485     |
|    total_timesteps  | 219887   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0021   |
|    n_updates        | 44971    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.558    |
| time/               |          |
|    episodes         | 12444    |
|    fps              | 148      |
|    time_elapsed     | 1485     |
|    total_timesteps  | 219951   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 44987    |
----------------------------------
Eval num_timesteps=220000, episode_reward=0.12 +/- 0.39
Episode length: 16.08 +/- 2.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | 0.117    |
| rollout/            |          |
|    exploration_rate | 0.558    |
| time/               |          |
|    total_timesteps  | 220000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 44999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.558    |
| time/               |          |
|    episodes         | 12448    |
|    fps              | 147      |
|    time_elapsed     | 1486     |
|    total_timesteps  | 220011   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 45002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00447 |
|    exploration_rate | 0.558    |
| time/               |          |
|    episodes         | 12452    |
|    fps              | 147      |
|    time_elapsed     | 1487     |
|    total_timesteps  | 220079   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0042   |
|    n_updates        | 45019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00431 |
|    exploration_rate | 0.557    |
| time/               |          |
|    episodes         | 12456    |
|    fps              | 148      |
|    time_elapsed     | 1487     |
|    total_timesteps  | 220141   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00235  |
|    n_updates        | 45035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.00583  |
|    exploration_rate | 0.557    |
| time/               |          |
|    episodes         | 12460    |
|    fps              | 148      |
|    time_elapsed     | 1487     |
|    total_timesteps  | 220202   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00358  |
|    n_updates        | 45050    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.557    |
| time/               |          |
|    episodes         | 12464    |
|    fps              | 148      |
|    time_elapsed     | 1487     |
|    total_timesteps  | 220276   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00408  |
|    n_updates        | 45068    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0155   |
|    exploration_rate | 0.557    |
| time/               |          |
|    episodes         | 12468    |
|    fps              | 148      |
|    time_elapsed     | 1487     |
|    total_timesteps  | 220342   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00277  |
|    n_updates        | 45085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.557    |
| time/               |          |
|    episodes         | 12472    |
|    fps              | 148      |
|    time_elapsed     | 1487     |
|    total_timesteps  | 220403   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 45100    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.556    |
| time/               |          |
|    episodes         | 12476    |
|    fps              | 148      |
|    time_elapsed     | 1487     |
|    total_timesteps  | 220470   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 45117    |
----------------------------------
Eval num_timesteps=220500, episode_reward=-0.04 +/- 0.14
Episode length: 16.14 +/- 2.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0435  |
| rollout/            |          |
|    exploration_rate | 0.556    |
| time/               |          |
|    total_timesteps  | 220500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00364  |
|    n_updates        | 45124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0257   |
|    exploration_rate | 0.556    |
| time/               |          |
|    episodes         | 12480    |
|    fps              | 148      |
|    time_elapsed     | 1488     |
|    total_timesteps  | 220530   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 45132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0148   |
|    exploration_rate | 0.556    |
| time/               |          |
|    episodes         | 12484    |
|    fps              | 148      |
|    time_elapsed     | 1489     |
|    total_timesteps  | 220613   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 45153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.555    |
| time/               |          |
|    episodes         | 12488    |
|    fps              | 148      |
|    time_elapsed     | 1489     |
|    total_timesteps  | 220682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0064   |
|    n_updates        | 45170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00403  |
|    exploration_rate | 0.555    |
| time/               |          |
|    episodes         | 12492    |
|    fps              | 148      |
|    time_elapsed     | 1489     |
|    total_timesteps  | 220756   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 45188    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.555    |
| time/               |          |
|    episodes         | 12496    |
|    fps              | 148      |
|    time_elapsed     | 1489     |
|    total_timesteps  | 220811   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00243  |
|    n_updates        | 45202    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.555    |
| time/               |          |
|    episodes         | 12500    |
|    fps              | 148      |
|    time_elapsed     | 1489     |
|    total_timesteps  | 220872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00291  |
|    n_updates        | 45217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.555    |
| time/               |          |
|    episodes         | 12504    |
|    fps              | 148      |
|    time_elapsed     | 1489     |
|    total_timesteps  | 220929   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0031   |
|    n_updates        | 45232    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0363   |
|    exploration_rate | 0.554    |
| time/               |          |
|    episodes         | 12508    |
|    fps              | 148      |
|    time_elapsed     | 1489     |
|    total_timesteps  | 220989   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 45247    |
----------------------------------
Eval num_timesteps=221000, episode_reward=0.06 +/- 0.33
Episode length: 15.88 +/- 2.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | 0.0576   |
| rollout/            |          |
|    exploration_rate | 0.554    |
| time/               |          |
|    total_timesteps  | 221000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00445  |
|    n_updates        | 45249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0362   |
|    exploration_rate | 0.554    |
| time/               |          |
|    episodes         | 12512    |
|    fps              | 148      |
|    time_elapsed     | 1490     |
|    total_timesteps  | 221060   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 45264    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0463   |
|    exploration_rate | 0.554    |
| time/               |          |
|    episodes         | 12516    |
|    fps              | 148      |
|    time_elapsed     | 1490     |
|    total_timesteps  | 221123   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00212  |
|    n_updates        | 45280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0459   |
|    exploration_rate | 0.554    |
| time/               |          |
|    episodes         | 12520    |
|    fps              | 148      |
|    time_elapsed     | 1490     |
|    total_timesteps  | 221197   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00094  |
|    n_updates        | 45299    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0455   |
|    exploration_rate | 0.553    |
| time/               |          |
|    episodes         | 12524    |
|    fps              | 148      |
|    time_elapsed     | 1491     |
|    total_timesteps  | 221273   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00524  |
|    n_updates        | 45318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0452   |
|    exploration_rate | 0.553    |
| time/               |          |
|    episodes         | 12528    |
|    fps              | 148      |
|    time_elapsed     | 1491     |
|    total_timesteps  | 221348   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00571  |
|    n_updates        | 45336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0348   |
|    exploration_rate | 0.553    |
| time/               |          |
|    episodes         | 12532    |
|    fps              | 148      |
|    time_elapsed     | 1491     |
|    total_timesteps  | 221421   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00333  |
|    n_updates        | 45355    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0346   |
|    exploration_rate | 0.552    |
| time/               |          |
|    episodes         | 12536    |
|    fps              | 148      |
|    time_elapsed     | 1491     |
|    total_timesteps  | 221488   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00606  |
|    n_updates        | 45371    |
----------------------------------
Eval num_timesteps=221500, episode_reward=0.02 +/- 0.28
Episode length: 14.96 +/- 1.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | 0.0212   |
| rollout/            |          |
|    exploration_rate | 0.552    |
| time/               |          |
|    total_timesteps  | 221500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 45374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0246   |
|    exploration_rate | 0.552    |
| time/               |          |
|    episodes         | 12540    |
|    fps              | 148      |
|    time_elapsed     | 1492     |
|    total_timesteps  | 221549   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0124   |
|    n_updates        | 45387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0246   |
|    exploration_rate | 0.552    |
| time/               |          |
|    episodes         | 12544    |
|    fps              | 148      |
|    time_elapsed     | 1492     |
|    total_timesteps  | 221612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00608  |
|    n_updates        | 45402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0244   |
|    exploration_rate | 0.552    |
| time/               |          |
|    episodes         | 12548    |
|    fps              | 148      |
|    time_elapsed     | 1492     |
|    total_timesteps  | 221677   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00252  |
|    n_updates        | 45419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.552    |
| time/               |          |
|    episodes         | 12552    |
|    fps              | 148      |
|    time_elapsed     | 1492     |
|    total_timesteps  | 221740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0031   |
|    n_updates        | 45434    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0145   |
|    exploration_rate | 0.551    |
| time/               |          |
|    episodes         | 12556    |
|    fps              | 148      |
|    time_elapsed     | 1492     |
|    total_timesteps  | 221805   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 45451    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00388  |
|    exploration_rate | 0.551    |
| time/               |          |
|    episodes         | 12560    |
|    fps              | 148      |
|    time_elapsed     | 1493     |
|    total_timesteps  | 221880   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 45469    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00603 |
|    exploration_rate | 0.551    |
| time/               |          |
|    episodes         | 12564    |
|    fps              | 148      |
|    time_elapsed     | 1493     |
|    total_timesteps  | 221952   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0025   |
|    n_updates        | 45487    |
----------------------------------
Eval num_timesteps=222000, episode_reward=0.10 +/- 0.37
Episode length: 15.68 +/- 4.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.7     |
|    mean_reward      | 0.0984   |
| rollout/            |          |
|    exploration_rate | 0.551    |
| time/               |          |
|    total_timesteps  | 222000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 45499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00591 |
|    exploration_rate | 0.551    |
| time/               |          |
|    episodes         | 12568    |
|    fps              | 148      |
|    time_elapsed     | 1494     |
|    total_timesteps  | 222015   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00327  |
|    n_updates        | 45503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00623 |
|    exploration_rate | 0.55     |
| time/               |          |
|    episodes         | 12572    |
|    fps              | 148      |
|    time_elapsed     | 1494     |
|    total_timesteps  | 222084   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 45520    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00376  |
|    exploration_rate | 0.55     |
| time/               |          |
|    episodes         | 12576    |
|    fps              | 148      |
|    time_elapsed     | 1494     |
|    total_timesteps  | 222151   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00263  |
|    n_updates        | 45537    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00678 |
|    exploration_rate | 0.55     |
| time/               |          |
|    episodes         | 12580    |
|    fps              | 148      |
|    time_elapsed     | 1494     |
|    total_timesteps  | 222224   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00304  |
|    n_updates        | 45555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00614 |
|    exploration_rate | 0.55     |
| time/               |          |
|    episodes         | 12584    |
|    fps              | 148      |
|    time_elapsed     | 1494     |
|    total_timesteps  | 222291   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 45572    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00622 |
|    exploration_rate | 0.549    |
| time/               |          |
|    episodes         | 12588    |
|    fps              | 148      |
|    time_elapsed     | 1494     |
|    total_timesteps  | 222362   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00446  |
|    n_updates        | 45590    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00606 |
|    exploration_rate | 0.549    |
| time/               |          |
|    episodes         | 12592    |
|    fps              | 148      |
|    time_elapsed     | 1494     |
|    total_timesteps  | 222432   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00573  |
|    n_updates        | 45607    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00397  |
|    exploration_rate | 0.549    |
| time/               |          |
|    episodes         | 12596    |
|    fps              | 148      |
|    time_elapsed     | 1495     |
|    total_timesteps  | 222487   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 45621    |
----------------------------------
Eval num_timesteps=222500, episode_reward=0.06 +/- 0.33
Episode length: 14.74 +/- 1.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0621   |
| rollout/            |          |
|    exploration_rate | 0.549    |
| time/               |          |
|    total_timesteps  | 222500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.003    |
|    n_updates        | 45624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00365  |
|    exploration_rate | 0.549    |
| time/               |          |
|    episodes         | 12600    |
|    fps              | 148      |
|    time_elapsed     | 1496     |
|    total_timesteps  | 222556   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 45638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00695 |
|    exploration_rate | 0.548    |
| time/               |          |
|    episodes         | 12604    |
|    fps              | 148      |
|    time_elapsed     | 1496     |
|    total_timesteps  | 222628   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00414  |
|    n_updates        | 45656    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00711 |
|    exploration_rate | 0.548    |
| time/               |          |
|    episodes         | 12608    |
|    fps              | 148      |
|    time_elapsed     | 1496     |
|    total_timesteps  | 222692   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00572  |
|    n_updates        | 45672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00671 |
|    exploration_rate | 0.548    |
| time/               |          |
|    episodes         | 12612    |
|    fps              | 148      |
|    time_elapsed     | 1496     |
|    total_timesteps  | 222753   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00684  |
|    n_updates        | 45688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.017   |
|    exploration_rate | 0.548    |
| time/               |          |
|    episodes         | 12616    |
|    fps              | 148      |
|    time_elapsed     | 1496     |
|    total_timesteps  | 222823   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00365  |
|    n_updates        | 45705    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0269  |
|    exploration_rate | 0.547    |
| time/               |          |
|    episodes         | 12620    |
|    fps              | 148      |
|    time_elapsed     | 1496     |
|    total_timesteps  | 222895   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 45723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0165  |
|    exploration_rate | 0.547    |
| time/               |          |
|    episodes         | 12624    |
|    fps              | 148      |
|    time_elapsed     | 1497     |
|    total_timesteps  | 222962   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0032   |
|    n_updates        | 45740    |
----------------------------------
Eval num_timesteps=223000, episode_reward=0.04 +/- 0.31
Episode length: 15.78 +/- 2.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.0379   |
| rollout/            |          |
|    exploration_rate | 0.547    |
| time/               |          |
|    total_timesteps  | 223000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000977 |
|    n_updates        | 45749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0163  |
|    exploration_rate | 0.547    |
| time/               |          |
|    episodes         | 12628    |
|    fps              | 148      |
|    time_elapsed     | 1498     |
|    total_timesteps  | 223032   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00596  |
|    n_updates        | 45757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0161  |
|    exploration_rate | 0.547    |
| time/               |          |
|    episodes         | 12632    |
|    fps              | 148      |
|    time_elapsed     | 1498     |
|    total_timesteps  | 223100   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 45774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.016   |
|    exploration_rate | 0.546    |
| time/               |          |
|    episodes         | 12636    |
|    fps              | 148      |
|    time_elapsed     | 1498     |
|    total_timesteps  | 223163   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00365  |
|    n_updates        | 45790    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.016   |
|    exploration_rate | 0.546    |
| time/               |          |
|    episodes         | 12640    |
|    fps              | 148      |
|    time_elapsed     | 1498     |
|    total_timesteps  | 223224   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00314  |
|    n_updates        | 45805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.016   |
|    exploration_rate | 0.546    |
| time/               |          |
|    episodes         | 12644    |
|    fps              | 149      |
|    time_elapsed     | 1498     |
|    total_timesteps  | 223287   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00513  |
|    n_updates        | 45821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00434  |
|    exploration_rate | 0.546    |
| time/               |          |
|    episodes         | 12648    |
|    fps              | 149      |
|    time_elapsed     | 1498     |
|    total_timesteps  | 223344   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 45835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.545    |
| time/               |          |
|    episodes         | 12652    |
|    fps              | 149      |
|    time_elapsed     | 1498     |
|    total_timesteps  | 223402   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00328  |
|    n_updates        | 45850    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.545    |
| time/               |          |
|    episodes         | 12656    |
|    fps              | 149      |
|    time_elapsed     | 1498     |
|    total_timesteps  | 223467   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 45866    |
----------------------------------
Eval num_timesteps=223500, episode_reward=0.00 +/- 0.24
Episode length: 15.12 +/- 1.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | 0.00052  |
| rollout/            |          |
|    exploration_rate | 0.545    |
| time/               |          |
|    total_timesteps  | 223500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 45874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0248   |
|    exploration_rate | 0.545    |
| time/               |          |
|    episodes         | 12660    |
|    fps              | 149      |
|    time_elapsed     | 1499     |
|    total_timesteps  | 223535   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00381  |
|    n_updates        | 45883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0252   |
|    exploration_rate | 0.545    |
| time/               |          |
|    episodes         | 12664    |
|    fps              | 149      |
|    time_elapsed     | 1499     |
|    total_timesteps  | 223598   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00234  |
|    n_updates        | 45899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0353   |
|    exploration_rate | 0.544    |
| time/               |          |
|    episodes         | 12668    |
|    fps              | 149      |
|    time_elapsed     | 1499     |
|    total_timesteps  | 223659   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 45914    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0457   |
|    exploration_rate | 0.544    |
| time/               |          |
|    episodes         | 12672    |
|    fps              | 149      |
|    time_elapsed     | 1500     |
|    total_timesteps  | 223718   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 45929    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.544    |
| time/               |          |
|    episodes         | 12676    |
|    fps              | 149      |
|    time_elapsed     | 1500     |
|    total_timesteps  | 223780   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.003    |
|    n_updates        | 45944    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.544    |
| time/               |          |
|    episodes         | 12680    |
|    fps              | 149      |
|    time_elapsed     | 1500     |
|    total_timesteps  | 223853   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00226  |
|    n_updates        | 45963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.543    |
| time/               |          |
|    episodes         | 12684    |
|    fps              | 149      |
|    time_elapsed     | 1500     |
|    total_timesteps  | 223919   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 45979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.543    |
| time/               |          |
|    episodes         | 12688    |
|    fps              | 149      |
|    time_elapsed     | 1500     |
|    total_timesteps  | 223985   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00379  |
|    n_updates        | 45996    |
----------------------------------
Eval num_timesteps=224000, episode_reward=0.04 +/- 0.31
Episode length: 15.22 +/- 1.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | 0.0402   |
| rollout/            |          |
|    exploration_rate | 0.543    |
| time/               |          |
|    total_timesteps  | 224000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 45999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0465   |
|    exploration_rate | 0.543    |
| time/               |          |
|    episodes         | 12692    |
|    fps              | 149      |
|    time_elapsed     | 1501     |
|    total_timesteps  | 224045   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00382  |
|    n_updates        | 46011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.543    |
| time/               |          |
|    episodes         | 12696    |
|    fps              | 149      |
|    time_elapsed     | 1501     |
|    total_timesteps  | 224114   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00249  |
|    n_updates        | 46028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.542    |
| time/               |          |
|    episodes         | 12700    |
|    fps              | 149      |
|    time_elapsed     | 1501     |
|    total_timesteps  | 224189   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 46047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.542    |
| time/               |          |
|    episodes         | 12704    |
|    fps              | 149      |
|    time_elapsed     | 1501     |
|    total_timesteps  | 224256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0017   |
|    n_updates        | 46063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.542    |
| time/               |          |
|    episodes         | 12708    |
|    fps              | 149      |
|    time_elapsed     | 1501     |
|    total_timesteps  | 224319   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00212  |
|    n_updates        | 46079    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0559   |
|    exploration_rate | 0.542    |
| time/               |          |
|    episodes         | 12712    |
|    fps              | 149      |
|    time_elapsed     | 1502     |
|    total_timesteps  | 224382   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00229  |
|    n_updates        | 46095    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0559   |
|    exploration_rate | 0.541    |
| time/               |          |
|    episodes         | 12716    |
|    fps              | 149      |
|    time_elapsed     | 1502     |
|    total_timesteps  | 224451   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0025   |
|    n_updates        | 46112    |
----------------------------------
Eval num_timesteps=224500, episode_reward=-0.02 +/- 0.20
Episode length: 15.34 +/- 1.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | -0.0203  |
| rollout/            |          |
|    exploration_rate | 0.541    |
| time/               |          |
|    total_timesteps  | 224500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0021   |
|    n_updates        | 46124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0563   |
|    exploration_rate | 0.541    |
| time/               |          |
|    episodes         | 12720    |
|    fps              | 149      |
|    time_elapsed     | 1503     |
|    total_timesteps  | 224513   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00342  |
|    n_updates        | 46128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0465   |
|    exploration_rate | 0.541    |
| time/               |          |
|    episodes         | 12724    |
|    fps              | 149      |
|    time_elapsed     | 1503     |
|    total_timesteps  | 224575   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 46143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0467   |
|    exploration_rate | 0.541    |
| time/               |          |
|    episodes         | 12728    |
|    fps              | 149      |
|    time_elapsed     | 1503     |
|    total_timesteps  | 224641   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 46160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0469   |
|    exploration_rate | 0.541    |
| time/               |          |
|    episodes         | 12732    |
|    fps              | 149      |
|    time_elapsed     | 1503     |
|    total_timesteps  | 224704   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00315  |
|    n_updates        | 46175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0465   |
|    exploration_rate | 0.54     |
| time/               |          |
|    episodes         | 12736    |
|    fps              | 149      |
|    time_elapsed     | 1503     |
|    total_timesteps  | 224777   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000911 |
|    n_updates        | 46194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0463   |
|    exploration_rate | 0.54     |
| time/               |          |
|    episodes         | 12740    |
|    fps              | 149      |
|    time_elapsed     | 1504     |
|    total_timesteps  | 224842   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000981 |
|    n_updates        | 46210    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0462   |
|    exploration_rate | 0.54     |
| time/               |          |
|    episodes         | 12744    |
|    fps              | 149      |
|    time_elapsed     | 1504     |
|    total_timesteps  | 224909   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 46227    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0255   |
|    exploration_rate | 0.54     |
| time/               |          |
|    episodes         | 12748    |
|    fps              | 149      |
|    time_elapsed     | 1504     |
|    total_timesteps  | 224982   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0026   |
|    n_updates        | 46245    |
----------------------------------
Eval num_timesteps=225000, episode_reward=-0.00 +/- 0.24
Episode length: 15.58 +/- 2.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.6     |
|    mean_reward      | -0.00128 |
| rollout/            |          |
|    exploration_rate | 0.539    |
| time/               |          |
|    total_timesteps  | 225000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 46249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0152   |
|    exploration_rate | 0.539    |
| time/               |          |
|    episodes         | 12752    |
|    fps              | 149      |
|    time_elapsed     | 1505     |
|    total_timesteps  | 225048   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 46261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.539    |
| time/               |          |
|    episodes         | 12756    |
|    fps              | 149      |
|    time_elapsed     | 1505     |
|    total_timesteps  | 225111   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00255  |
|    n_updates        | 46277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00555  |
|    exploration_rate | 0.539    |
| time/               |          |
|    episodes         | 12760    |
|    fps              | 149      |
|    time_elapsed     | 1505     |
|    total_timesteps  | 225172   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 46292    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00543  |
|    exploration_rate | 0.539    |
| time/               |          |
|    episodes         | 12764    |
|    fps              | 149      |
|    time_elapsed     | 1505     |
|    total_timesteps  | 225238   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0037   |
|    n_updates        | 46309    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00459 |
|    exploration_rate | 0.538    |
| time/               |          |
|    episodes         | 12768    |
|    fps              | 149      |
|    time_elapsed     | 1505     |
|    total_timesteps  | 225299   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00203  |
|    n_updates        | 46324    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00485 |
|    exploration_rate | 0.538    |
| time/               |          |
|    episodes         | 12772    |
|    fps              | 149      |
|    time_elapsed     | 1505     |
|    total_timesteps  | 225365   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00695  |
|    n_updates        | 46341    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00489 |
|    exploration_rate | 0.538    |
| time/               |          |
|    episodes         | 12776    |
|    fps              | 149      |
|    time_elapsed     | 1506     |
|    total_timesteps  | 225428   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 46356    |
----------------------------------
Eval num_timesteps=225500, episode_reward=-0.04 +/- 0.14
Episode length: 15.08 +/- 1.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | -0.0393  |
| rollout/            |          |
|    exploration_rate | 0.538    |
| time/               |          |
|    total_timesteps  | 225500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00264  |
|    n_updates        | 46374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00508  |
|    exploration_rate | 0.538    |
| time/               |          |
|    episodes         | 12780    |
|    fps              | 149      |
|    time_elapsed     | 1507     |
|    total_timesteps  | 225502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 46375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00528  |
|    exploration_rate | 0.537    |
| time/               |          |
|    episodes         | 12784    |
|    fps              | 149      |
|    time_elapsed     | 1507     |
|    total_timesteps  | 225563   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 46390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0052   |
|    exploration_rate | 0.537    |
| time/               |          |
|    episodes         | 12788    |
|    fps              | 149      |
|    time_elapsed     | 1507     |
|    total_timesteps  | 225631   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0025   |
|    n_updates        | 46407    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00501  |
|    exploration_rate | 0.537    |
| time/               |          |
|    episodes         | 12792    |
|    fps              | 149      |
|    time_elapsed     | 1507     |
|    total_timesteps  | 225696   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00306  |
|    n_updates        | 46423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00525  |
|    exploration_rate | 0.537    |
| time/               |          |
|    episodes         | 12796    |
|    fps              | 149      |
|    time_elapsed     | 1507     |
|    total_timesteps  | 225759   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00287  |
|    n_updates        | 46439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00447 |
|    exploration_rate | 0.536    |
| time/               |          |
|    episodes         | 12800    |
|    fps              | 149      |
|    time_elapsed     | 1507     |
|    total_timesteps  | 225827   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00259  |
|    n_updates        | 46456    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00459 |
|    exploration_rate | 0.536    |
| time/               |          |
|    episodes         | 12804    |
|    fps              | 149      |
|    time_elapsed     | 1507     |
|    total_timesteps  | 225897   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000978 |
|    n_updates        | 46474    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.536    |
| time/               |          |
|    episodes         | 12808    |
|    fps              | 149      |
|    time_elapsed     | 1507     |
|    total_timesteps  | 225965   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 46491    |
----------------------------------
Eval num_timesteps=226000, episode_reward=-0.03 +/- 0.29
Episode length: 26.52 +/- 14.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 26.5     |
|    mean_reward      | -0.0251  |
| rollout/            |          |
|    exploration_rate | 0.536    |
| time/               |          |
|    total_timesteps  | 226000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00555  |
|    n_updates        | 46499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0348  |
|    exploration_rate | 0.536    |
| time/               |          |
|    episodes         | 12812    |
|    fps              | 149      |
|    time_elapsed     | 1509     |
|    total_timesteps  | 226027   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 46506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0352  |
|    exploration_rate | 0.535    |
| time/               |          |
|    episodes         | 12816    |
|    fps              | 149      |
|    time_elapsed     | 1509     |
|    total_timesteps  | 226106   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0032   |
|    n_updates        | 46526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0256  |
|    exploration_rate | 0.535    |
| time/               |          |
|    episodes         | 12820    |
|    fps              | 149      |
|    time_elapsed     | 1509     |
|    total_timesteps  | 226179   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 46544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0258  |
|    exploration_rate | 0.535    |
| time/               |          |
|    episodes         | 12824    |
|    fps              | 149      |
|    time_elapsed     | 1509     |
|    total_timesteps  | 226247   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 46561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.535    |
| time/               |          |
|    episodes         | 12828    |
|    fps              | 149      |
|    time_elapsed     | 1510     |
|    total_timesteps  | 226310   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 46577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.534    |
| time/               |          |
|    episodes         | 12832    |
|    fps              | 149      |
|    time_elapsed     | 1510     |
|    total_timesteps  | 226373   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 46593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0152  |
|    exploration_rate | 0.534    |
| time/               |          |
|    episodes         | 12836    |
|    fps              | 149      |
|    time_elapsed     | 1510     |
|    total_timesteps  | 226432   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 46607    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0151  |
|    exploration_rate | 0.534    |
| time/               |          |
|    episodes         | 12840    |
|    fps              | 149      |
|    time_elapsed     | 1510     |
|    total_timesteps  | 226495   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00225  |
|    n_updates        | 46623    |
----------------------------------
Eval num_timesteps=226500, episode_reward=-0.00 +/- 0.24
Episode length: 15.50 +/- 1.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.5     |
|    mean_reward      | -0.00098 |
| rollout/            |          |
|    exploration_rate | 0.534    |
| time/               |          |
|    total_timesteps  | 226500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000912 |
|    n_updates        | 46624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.534    |
| time/               |          |
|    episodes         | 12844    |
|    fps              | 149      |
|    time_elapsed     | 1511     |
|    total_timesteps  | 226557   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00307  |
|    n_updates        | 46639    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.533    |
| time/               |          |
|    episodes         | 12848    |
|    fps              | 149      |
|    time_elapsed     | 1511     |
|    total_timesteps  | 226620   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 46654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.533    |
| time/               |          |
|    episodes         | 12852    |
|    fps              | 149      |
|    time_elapsed     | 1511     |
|    total_timesteps  | 226687   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000999 |
|    n_updates        | 46671    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0147  |
|    exploration_rate | 0.533    |
| time/               |          |
|    episodes         | 12856    |
|    fps              | 149      |
|    time_elapsed     | 1511     |
|    total_timesteps  | 226755   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00266  |
|    n_updates        | 46688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00492 |
|    exploration_rate | 0.533    |
| time/               |          |
|    episodes         | 12860    |
|    fps              | 150      |
|    time_elapsed     | 1511     |
|    total_timesteps  | 226821   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 46705    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00526  |
|    exploration_rate | 0.532    |
| time/               |          |
|    episodes         | 12864    |
|    fps              | 150      |
|    time_elapsed     | 1512     |
|    total_timesteps  | 226883   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00228  |
|    n_updates        | 46720    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00514  |
|    exploration_rate | 0.532    |
| time/               |          |
|    episodes         | 12868    |
|    fps              | 150      |
|    time_elapsed     | 1512     |
|    total_timesteps  | 226947   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 46736    |
----------------------------------
Eval num_timesteps=227000, episode_reward=-0.02 +/- 0.20
Episode length: 15.26 +/- 1.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | -0.02    |
| rollout/            |          |
|    exploration_rate | 0.532    |
| time/               |          |
|    total_timesteps  | 227000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00335  |
|    n_updates        | 46749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00475 |
|    exploration_rate | 0.532    |
| time/               |          |
|    episodes         | 12872    |
|    fps              | 150      |
|    time_elapsed     | 1513     |
|    total_timesteps  | 227010   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 46752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00471 |
|    exploration_rate | 0.532    |
| time/               |          |
|    episodes         | 12876    |
|    fps              | 150      |
|    time_elapsed     | 1513     |
|    total_timesteps  | 227072   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 46767    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.531    |
| time/               |          |
|    episodes         | 12880    |
|    fps              | 150      |
|    time_elapsed     | 1513     |
|    total_timesteps  | 227142   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 46785    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.531    |
| time/               |          |
|    episodes         | 12884    |
|    fps              | 150      |
|    time_elapsed     | 1513     |
|    total_timesteps  | 227211   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 46802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0154  |
|    exploration_rate | 0.531    |
| time/               |          |
|    episodes         | 12888    |
|    fps              | 150      |
|    time_elapsed     | 1513     |
|    total_timesteps  | 227291   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00306  |
|    n_updates        | 46822    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0153  |
|    exploration_rate | 0.531    |
| time/               |          |
|    episodes         | 12892    |
|    fps              | 150      |
|    time_elapsed     | 1513     |
|    total_timesteps  | 227355   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00448  |
|    n_updates        | 46838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0153  |
|    exploration_rate | 0.53     |
| time/               |          |
|    episodes         | 12896    |
|    fps              | 150      |
|    time_elapsed     | 1513     |
|    total_timesteps  | 227418   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 46854    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0151  |
|    exploration_rate | 0.53     |
| time/               |          |
|    episodes         | 12900    |
|    fps              | 150      |
|    time_elapsed     | 1514     |
|    total_timesteps  | 227480   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00248  |
|    n_updates        | 46869    |
----------------------------------
Eval num_timesteps=227500, episode_reward=-0.04 +/- 0.14
Episode length: 15.08 +/- 0.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | -0.0393  |
| rollout/            |          |
|    exploration_rate | 0.53     |
| time/               |          |
|    total_timesteps  | 227500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 46874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00462 |
|    exploration_rate | 0.53     |
| time/               |          |
|    episodes         | 12904    |
|    fps              | 150      |
|    time_elapsed     | 1515     |
|    total_timesteps  | 227539   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00225  |
|    n_updates        | 46884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0047  |
|    exploration_rate | 0.53     |
| time/               |          |
|    episodes         | 12908    |
|    fps              | 150      |
|    time_elapsed     | 1515     |
|    total_timesteps  | 227609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 46902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00466 |
|    exploration_rate | 0.529    |
| time/               |          |
|    episodes         | 12912    |
|    fps              | 150      |
|    time_elapsed     | 1515     |
|    total_timesteps  | 227670   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 46917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0062   |
|    exploration_rate | 0.529    |
| time/               |          |
|    episodes         | 12916    |
|    fps              | 150      |
|    time_elapsed     | 1515     |
|    total_timesteps  | 227728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00342  |
|    n_updates        | 46931    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00365 |
|    exploration_rate | 0.529    |
| time/               |          |
|    episodes         | 12920    |
|    fps              | 150      |
|    time_elapsed     | 1515     |
|    total_timesteps  | 227797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 46949    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00682  |
|    exploration_rate | 0.529    |
| time/               |          |
|    episodes         | 12924    |
|    fps              | 150      |
|    time_elapsed     | 1515     |
|    total_timesteps  | 227853   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 46963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00658  |
|    exploration_rate | 0.528    |
| time/               |          |
|    episodes         | 12928    |
|    fps              | 150      |
|    time_elapsed     | 1515     |
|    total_timesteps  | 227922   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 46980    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00658  |
|    exploration_rate | 0.528    |
| time/               |          |
|    episodes         | 12932    |
|    fps              | 150      |
|    time_elapsed     | 1515     |
|    total_timesteps  | 227985   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 46996    |
----------------------------------
Eval num_timesteps=228000, episode_reward=-0.04 +/- 0.14
Episode length: 15.18 +/- 1.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | -0.0397  |
| rollout/            |          |
|    exploration_rate | 0.528    |
| time/               |          |
|    total_timesteps  | 228000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 46999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00365 |
|    exploration_rate | 0.528    |
| time/               |          |
|    episodes         | 12936    |
|    fps              | 150      |
|    time_elapsed     | 1516     |
|    total_timesteps  | 228050   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 47012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00353 |
|    exploration_rate | 0.528    |
| time/               |          |
|    episodes         | 12940    |
|    fps              | 150      |
|    time_elapsed     | 1517     |
|    total_timesteps  | 228110   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0033   |
|    n_updates        | 47027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00373 |
|    exploration_rate | 0.528    |
| time/               |          |
|    episodes         | 12944    |
|    fps              | 150      |
|    time_elapsed     | 1517     |
|    total_timesteps  | 228177   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00691  |
|    n_updates        | 47044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00409 |
|    exploration_rate | 0.527    |
| time/               |          |
|    episodes         | 12948    |
|    fps              | 150      |
|    time_elapsed     | 1517     |
|    total_timesteps  | 228249   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00383  |
|    n_updates        | 47062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00429 |
|    exploration_rate | 0.527    |
| time/               |          |
|    episodes         | 12952    |
|    fps              | 150      |
|    time_elapsed     | 1517     |
|    total_timesteps  | 228321   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 47080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00421 |
|    exploration_rate | 0.527    |
| time/               |          |
|    episodes         | 12956    |
|    fps              | 150      |
|    time_elapsed     | 1517     |
|    total_timesteps  | 228387   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 47096    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.526    |
| time/               |          |
|    episodes         | 12960    |
|    fps              | 150      |
|    time_elapsed     | 1517     |
|    total_timesteps  | 228453   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 47113    |
----------------------------------
Eval num_timesteps=228500, episode_reward=-0.04 +/- 0.14
Episode length: 15.24 +/- 1.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | -0.04    |
| rollout/            |          |
|    exploration_rate | 0.526    |
| time/               |          |
|    total_timesteps  | 228500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0024   |
|    n_updates        | 47124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0243  |
|    exploration_rate | 0.526    |
| time/               |          |
|    episodes         | 12964    |
|    fps              | 150      |
|    time_elapsed     | 1518     |
|    total_timesteps  | 228517   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0019   |
|    n_updates        | 47129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.526    |
| time/               |          |
|    episodes         | 12968    |
|    fps              | 150      |
|    time_elapsed     | 1519     |
|    total_timesteps  | 228577   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 47144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.526    |
| time/               |          |
|    episodes         | 12972    |
|    fps              | 150      |
|    time_elapsed     | 1519     |
|    total_timesteps  | 228645   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00245  |
|    n_updates        | 47161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0245  |
|    exploration_rate | 0.526    |
| time/               |          |
|    episodes         | 12976    |
|    fps              | 150      |
|    time_elapsed     | 1519     |
|    total_timesteps  | 228711   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00376  |
|    n_updates        | 47177    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0243  |
|    exploration_rate | 0.525    |
| time/               |          |
|    episodes         | 12980    |
|    fps              | 150      |
|    time_elapsed     | 1519     |
|    total_timesteps  | 228776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 47193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.525    |
| time/               |          |
|    episodes         | 12984    |
|    fps              | 150      |
|    time_elapsed     | 1519     |
|    total_timesteps  | 228846   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00247  |
|    n_updates        | 47211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0236  |
|    exploration_rate | 0.525    |
| time/               |          |
|    episodes         | 12988    |
|    fps              | 150      |
|    time_elapsed     | 1519     |
|    total_timesteps  | 228907   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00349  |
|    n_updates        | 47226    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0336  |
|    exploration_rate | 0.525    |
| time/               |          |
|    episodes         | 12992    |
|    fps              | 150      |
|    time_elapsed     | 1519     |
|    total_timesteps  | 228972   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 47242    |
----------------------------------
Eval num_timesteps=229000, episode_reward=-0.04 +/- 0.14
Episode length: 15.02 +/- 0.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.0391  |
| rollout/            |          |
|    exploration_rate | 0.524    |
| time/               |          |
|    total_timesteps  | 229000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 47249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0338  |
|    exploration_rate | 0.524    |
| time/               |          |
|    episodes         | 12996    |
|    fps              | 150      |
|    time_elapsed     | 1520     |
|    total_timesteps  | 229040   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0024   |
|    n_updates        | 47259    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0339  |
|    exploration_rate | 0.524    |
| time/               |          |
|    episodes         | 13000    |
|    fps              | 150      |
|    time_elapsed     | 1520     |
|    total_timesteps  | 229103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 47275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0447  |
|    exploration_rate | 0.524    |
| time/               |          |
|    episodes         | 13004    |
|    fps              | 150      |
|    time_elapsed     | 1521     |
|    total_timesteps  | 229181   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00891  |
|    n_updates        | 47295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0343  |
|    exploration_rate | 0.524    |
| time/               |          |
|    episodes         | 13008    |
|    fps              | 150      |
|    time_elapsed     | 1521     |
|    total_timesteps  | 229241   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00297  |
|    n_updates        | 47310    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0348  |
|    exploration_rate | 0.523    |
| time/               |          |
|    episodes         | 13012    |
|    fps              | 150      |
|    time_elapsed     | 1521     |
|    total_timesteps  | 229315   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00533  |
|    n_updates        | 47328    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0451  |
|    exploration_rate | 0.523    |
| time/               |          |
|    episodes         | 13016    |
|    fps              | 150      |
|    time_elapsed     | 1521     |
|    total_timesteps  | 229379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00362  |
|    n_updates        | 47344    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0449  |
|    exploration_rate | 0.523    |
| time/               |          |
|    episodes         | 13020    |
|    fps              | 150      |
|    time_elapsed     | 1521     |
|    total_timesteps  | 229444   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00315  |
|    n_updates        | 47360    |
----------------------------------
Eval num_timesteps=229500, episode_reward=-0.06 +/- 0.00
Episode length: 15.08 +/- 0.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | -0.0593  |
| rollout/            |          |
|    exploration_rate | 0.523    |
| time/               |          |
|    total_timesteps  | 229500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00218  |
|    n_updates        | 47374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0552  |
|    exploration_rate | 0.523    |
| time/               |          |
|    episodes         | 13024    |
|    fps              | 150      |
|    time_elapsed     | 1522     |
|    total_timesteps  | 229508   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 47376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.055   |
|    exploration_rate | 0.522    |
| time/               |          |
|    episodes         | 13028    |
|    fps              | 150      |
|    time_elapsed     | 1522     |
|    total_timesteps  | 229573   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 47393    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0452  |
|    exploration_rate | 0.522    |
| time/               |          |
|    episodes         | 13032    |
|    fps              | 150      |
|    time_elapsed     | 1522     |
|    total_timesteps  | 229639   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0043   |
|    n_updates        | 47409    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0454  |
|    exploration_rate | 0.522    |
| time/               |          |
|    episodes         | 13036    |
|    fps              | 150      |
|    time_elapsed     | 1522     |
|    total_timesteps  | 229710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00387  |
|    n_updates        | 47427    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0456  |
|    exploration_rate | 0.522    |
| time/               |          |
|    episodes         | 13040    |
|    fps              | 150      |
|    time_elapsed     | 1523     |
|    total_timesteps  | 229775   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00201  |
|    n_updates        | 47443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0354  |
|    exploration_rate | 0.521    |
| time/               |          |
|    episodes         | 13044    |
|    fps              | 150      |
|    time_elapsed     | 1523     |
|    total_timesteps  | 229837   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 47459    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0351  |
|    exploration_rate | 0.521    |
| time/               |          |
|    episodes         | 13048    |
|    fps              | 150      |
|    time_elapsed     | 1523     |
|    total_timesteps  | 229901   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0023   |
|    n_updates        | 47475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0349  |
|    exploration_rate | 0.521    |
| time/               |          |
|    episodes         | 13052    |
|    fps              | 150      |
|    time_elapsed     | 1523     |
|    total_timesteps  | 229970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 47492    |
----------------------------------
Eval num_timesteps=230000, episode_reward=-0.04 +/- 0.14
Episode length: 15.76 +/- 2.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | -0.042   |
| rollout/            |          |
|    exploration_rate | 0.521    |
| time/               |          |
|    total_timesteps  | 230000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00485  |
|    n_updates        | 47499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.521    |
| time/               |          |
|    episodes         | 13056    |
|    fps              | 150      |
|    time_elapsed     | 1524     |
|    total_timesteps  | 230031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0023   |
|    n_updates        | 47507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0349  |
|    exploration_rate | 0.52     |
| time/               |          |
|    episodes         | 13060    |
|    fps              | 150      |
|    time_elapsed     | 1524     |
|    total_timesteps  | 230101   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00236  |
|    n_updates        | 47525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0351  |
|    exploration_rate | 0.52     |
| time/               |          |
|    episodes         | 13064    |
|    fps              | 150      |
|    time_elapsed     | 1524     |
|    total_timesteps  | 230170   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 47542    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0353  |
|    exploration_rate | 0.52     |
| time/               |          |
|    episodes         | 13068    |
|    fps              | 150      |
|    time_elapsed     | 1525     |
|    total_timesteps  | 230235   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 47558    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.025   |
|    exploration_rate | 0.52     |
| time/               |          |
|    episodes         | 13072    |
|    fps              | 151      |
|    time_elapsed     | 1525     |
|    total_timesteps  | 230295   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00485  |
|    n_updates        | 47573    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0248  |
|    exploration_rate | 0.519    |
| time/               |          |
|    episodes         | 13076    |
|    fps              | 151      |
|    time_elapsed     | 1525     |
|    total_timesteps  | 230357   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 47589    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.519    |
| time/               |          |
|    episodes         | 13080    |
|    fps              | 151      |
|    time_elapsed     | 1525     |
|    total_timesteps  | 230415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 47603    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.519    |
| time/               |          |
|    episodes         | 13084    |
|    fps              | 151      |
|    time_elapsed     | 1525     |
|    total_timesteps  | 230481   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00262  |
|    n_updates        | 47620    |
----------------------------------
Eval num_timesteps=230500, episode_reward=-0.04 +/- 0.14
Episode length: 16.34 +/- 1.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.3     |
|    mean_reward      | -0.0443  |
| rollout/            |          |
|    exploration_rate | 0.519    |
| time/               |          |
|    total_timesteps  | 230500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 47624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00463 |
|    exploration_rate | 0.519    |
| time/               |          |
|    episodes         | 13088    |
|    fps              | 151      |
|    time_elapsed     | 1526     |
|    total_timesteps  | 230548   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00273  |
|    n_updates        | 47636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00483 |
|    exploration_rate | 0.518    |
| time/               |          |
|    episodes         | 13092    |
|    fps              | 151      |
|    time_elapsed     | 1526     |
|    total_timesteps  | 230618   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0111   |
|    n_updates        | 47654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00487 |
|    exploration_rate | 0.518    |
| time/               |          |
|    episodes         | 13096    |
|    fps              | 151      |
|    time_elapsed     | 1526     |
|    total_timesteps  | 230687   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 47671    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00533  |
|    exploration_rate | 0.518    |
| time/               |          |
|    episodes         | 13100    |
|    fps              | 151      |
|    time_elapsed     | 1526     |
|    total_timesteps  | 230745   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00257  |
|    n_updates        | 47686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00497  |
|    exploration_rate | 0.517    |
| time/               |          |
|    episodes         | 13104    |
|    fps              | 151      |
|    time_elapsed     | 1527     |
|    total_timesteps  | 230832   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00933  |
|    n_updates        | 47707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00526 |
|    exploration_rate | 0.517    |
| time/               |          |
|    episodes         | 13108    |
|    fps              | 151      |
|    time_elapsed     | 1527     |
|    total_timesteps  | 230898   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000879 |
|    n_updates        | 47724    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00478 |
|    exploration_rate | 0.517    |
| time/               |          |
|    episodes         | 13112    |
|    fps              | 151      |
|    time_elapsed     | 1527     |
|    total_timesteps  | 230960   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 47739    |
----------------------------------
Eval num_timesteps=231000, episode_reward=-0.04 +/- 0.15
Episode length: 16.42 +/- 8.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | -0.0447  |
| rollout/            |          |
|    exploration_rate | 0.517    |
| time/               |          |
|    total_timesteps  | 231000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 47749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00466 |
|    exploration_rate | 0.517    |
| time/               |          |
|    episodes         | 13116    |
|    fps              | 151      |
|    time_elapsed     | 1528     |
|    total_timesteps  | 231021   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 47755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00466 |
|    exploration_rate | 0.517    |
| time/               |          |
|    episodes         | 13120    |
|    fps              | 151      |
|    time_elapsed     | 1528     |
|    total_timesteps  | 231086   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 47771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00454 |
|    exploration_rate | 0.516    |
| time/               |          |
|    episodes         | 13124    |
|    fps              | 151      |
|    time_elapsed     | 1528     |
|    total_timesteps  | 231147   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00236  |
|    n_updates        | 47786    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0045  |
|    exploration_rate | 0.516    |
| time/               |          |
|    episodes         | 13128    |
|    fps              | 151      |
|    time_elapsed     | 1528     |
|    total_timesteps  | 231211   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 47802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.516    |
| time/               |          |
|    episodes         | 13132    |
|    fps              | 151      |
|    time_elapsed     | 1528     |
|    total_timesteps  | 231274   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 47818    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.516    |
| time/               |          |
|    episodes         | 13136    |
|    fps              | 151      |
|    time_elapsed     | 1528     |
|    total_timesteps  | 231341   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00295  |
|    n_updates        | 47835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.515    |
| time/               |          |
|    episodes         | 13140    |
|    fps              | 151      |
|    time_elapsed     | 1529     |
|    total_timesteps  | 231416   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 47853    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.515    |
| time/               |          |
|    episodes         | 13144    |
|    fps              | 151      |
|    time_elapsed     | 1529     |
|    total_timesteps  | 231477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 47869    |
----------------------------------
Eval num_timesteps=231500, episode_reward=-0.09 +/- 0.06
Episode length: 23.24 +/- 14.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 23.2     |
|    mean_reward      | -0.092   |
| rollout/            |          |
|    exploration_rate | 0.515    |
| time/               |          |
|    total_timesteps  | 231500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000797 |
|    n_updates        | 47874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0045  |
|    exploration_rate | 0.515    |
| time/               |          |
|    episodes         | 13148    |
|    fps              | 151      |
|    time_elapsed     | 1530     |
|    total_timesteps  | 231538   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 47884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00454 |
|    exploration_rate | 0.515    |
| time/               |          |
|    episodes         | 13152    |
|    fps              | 151      |
|    time_elapsed     | 1530     |
|    total_timesteps  | 231608   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 47901    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0045  |
|    exploration_rate | 0.514    |
| time/               |          |
|    episodes         | 13156    |
|    fps              | 151      |
|    time_elapsed     | 1530     |
|    total_timesteps  | 231668   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00242  |
|    n_updates        | 47916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00422 |
|    exploration_rate | 0.514    |
| time/               |          |
|    episodes         | 13160    |
|    fps              | 151      |
|    time_elapsed     | 1530     |
|    total_timesteps  | 231731   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 47932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00398 |
|    exploration_rate | 0.514    |
| time/               |          |
|    episodes         | 13164    |
|    fps              | 151      |
|    time_elapsed     | 1531     |
|    total_timesteps  | 231794   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000934 |
|    n_updates        | 47948    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00406 |
|    exploration_rate | 0.514    |
| time/               |          |
|    episodes         | 13168    |
|    fps              | 151      |
|    time_elapsed     | 1531     |
|    total_timesteps  | 231861   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 47965    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.513    |
| time/               |          |
|    episodes         | 13172    |
|    fps              | 151      |
|    time_elapsed     | 1531     |
|    total_timesteps  | 231932   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 47982    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00455 |
|    exploration_rate | 0.513    |
| time/               |          |
|    episodes         | 13176    |
|    fps              | 151      |
|    time_elapsed     | 1531     |
|    total_timesteps  | 231996   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000877 |
|    n_updates        | 47998    |
----------------------------------
Eval num_timesteps=232000, episode_reward=0.02 +/- 0.28
Episode length: 15.28 +/- 1.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | 0.0199   |
| rollout/            |          |
|    exploration_rate | 0.513    |
| time/               |          |
|    total_timesteps  | 232000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 47999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0147  |
|    exploration_rate | 0.513    |
| time/               |          |
|    episodes         | 13180    |
|    fps              | 151      |
|    time_elapsed     | 1532     |
|    total_timesteps  | 232058   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 48014    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0147  |
|    exploration_rate | 0.513    |
| time/               |          |
|    episodes         | 13184    |
|    fps              | 151      |
|    time_elapsed     | 1532     |
|    total_timesteps  | 232124   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 48030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0249  |
|    exploration_rate | 0.512    |
| time/               |          |
|    episodes         | 13188    |
|    fps              | 151      |
|    time_elapsed     | 1533     |
|    total_timesteps  | 232196   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 48048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.512    |
| time/               |          |
|    episodes         | 13192    |
|    fps              | 151      |
|    time_elapsed     | 1533     |
|    total_timesteps  | 232254   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00211  |
|    n_updates        | 48063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.512    |
| time/               |          |
|    episodes         | 13196    |
|    fps              | 151      |
|    time_elapsed     | 1533     |
|    total_timesteps  | 232318   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 48079    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.025   |
|    exploration_rate | 0.512    |
| time/               |          |
|    episodes         | 13200    |
|    fps              | 151      |
|    time_elapsed     | 1533     |
|    total_timesteps  | 232394   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00239  |
|    n_updates        | 48098    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.511    |
| time/               |          |
|    episodes         | 13204    |
|    fps              | 151      |
|    time_elapsed     | 1533     |
|    total_timesteps  | 232462   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000967 |
|    n_updates        | 48115    |
----------------------------------
Eval num_timesteps=232500, episode_reward=-0.05 +/- 0.20
Episode length: 22.22 +/- 13.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22.2     |
|    mean_reward      | -0.048   |
| rollout/            |          |
|    exploration_rate | 0.511    |
| time/               |          |
|    total_timesteps  | 232500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 48124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0241  |
|    exploration_rate | 0.511    |
| time/               |          |
|    episodes         | 13208    |
|    fps              | 151      |
|    time_elapsed     | 1535     |
|    total_timesteps  | 232525   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 48131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.511    |
| time/               |          |
|    episodes         | 13212    |
|    fps              | 151      |
|    time_elapsed     | 1535     |
|    total_timesteps  | 232589   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 48147    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0247  |
|    exploration_rate | 0.511    |
| time/               |          |
|    episodes         | 13216    |
|    fps              | 151      |
|    time_elapsed     | 1535     |
|    total_timesteps  | 232663   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 48165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.51     |
| time/               |          |
|    episodes         | 13220    |
|    fps              | 151      |
|    time_elapsed     | 1535     |
|    total_timesteps  | 232725   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00332  |
|    n_updates        | 48181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0251  |
|    exploration_rate | 0.51     |
| time/               |          |
|    episodes         | 13224    |
|    fps              | 151      |
|    time_elapsed     | 1535     |
|    total_timesteps  | 232800   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00235  |
|    n_updates        | 48199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0255  |
|    exploration_rate | 0.51     |
| time/               |          |
|    episodes         | 13228    |
|    fps              | 151      |
|    time_elapsed     | 1535     |
|    total_timesteps  | 232873   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 48218    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0256  |
|    exploration_rate | 0.509    |
| time/               |          |
|    episodes         | 13232    |
|    fps              | 151      |
|    time_elapsed     | 1535     |
|    total_timesteps  | 232939   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 48234    |
----------------------------------
Eval num_timesteps=233000, episode_reward=-0.09 +/- 0.20
Episode length: 33.86 +/- 17.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 33.9     |
|    mean_reward      | -0.0945  |
| rollout/            |          |
|    exploration_rate | 0.509    |
| time/               |          |
|    total_timesteps  | 233000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 48249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0254  |
|    exploration_rate | 0.509    |
| time/               |          |
|    episodes         | 13236    |
|    fps              | 151      |
|    time_elapsed     | 1537     |
|    total_timesteps  | 233001   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 48250    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0254  |
|    exploration_rate | 0.509    |
| time/               |          |
|    episodes         | 13240    |
|    fps              | 151      |
|    time_elapsed     | 1538     |
|    total_timesteps  | 233077   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00866  |
|    n_updates        | 48269    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.509    |
| time/               |          |
|    episodes         | 13244    |
|    fps              | 151      |
|    time_elapsed     | 1538     |
|    total_timesteps  | 233134   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 48283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0356  |
|    exploration_rate | 0.508    |
| time/               |          |
|    episodes         | 13248    |
|    fps              | 151      |
|    time_elapsed     | 1538     |
|    total_timesteps  | 233203   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 48300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.508    |
| time/               |          |
|    episodes         | 13252    |
|    fps              | 151      |
|    time_elapsed     | 1538     |
|    total_timesteps  | 233283   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 48320    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0261  |
|    exploration_rate | 0.508    |
| time/               |          |
|    episodes         | 13256    |
|    fps              | 151      |
|    time_elapsed     | 1538     |
|    total_timesteps  | 233345   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00323  |
|    n_updates        | 48336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0263  |
|    exploration_rate | 0.508    |
| time/               |          |
|    episodes         | 13260    |
|    fps              | 151      |
|    time_elapsed     | 1538     |
|    total_timesteps  | 233415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00218  |
|    n_updates        | 48353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0265  |
|    exploration_rate | 0.507    |
| time/               |          |
|    episodes         | 13264    |
|    fps              | 151      |
|    time_elapsed     | 1538     |
|    total_timesteps  | 233481   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 48370    |
----------------------------------
Eval num_timesteps=233500, episode_reward=-0.09 +/- 0.20
Episode length: 33.94 +/- 18.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 33.9     |
|    mean_reward      | -0.0948  |
| rollout/            |          |
|    exploration_rate | 0.507    |
| time/               |          |
|    total_timesteps  | 233500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 48374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0263  |
|    exploration_rate | 0.507    |
| time/               |          |
|    episodes         | 13268    |
|    fps              | 151      |
|    time_elapsed     | 1540     |
|    total_timesteps  | 233545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00335  |
|    n_updates        | 48386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.016   |
|    exploration_rate | 0.507    |
| time/               |          |
|    episodes         | 13272    |
|    fps              | 151      |
|    time_elapsed     | 1541     |
|    total_timesteps  | 233607   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 48401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0275  |
|    exploration_rate | 0.507    |
| time/               |          |
|    episodes         | 13276    |
|    fps              | 151      |
|    time_elapsed     | 1541     |
|    total_timesteps  | 233709   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00263  |
|    n_updates        | 48427    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0277  |
|    exploration_rate | 0.506    |
| time/               |          |
|    episodes         | 13280    |
|    fps              | 151      |
|    time_elapsed     | 1541     |
|    total_timesteps  | 233776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 48443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0276  |
|    exploration_rate | 0.506    |
| time/               |          |
|    episodes         | 13284    |
|    fps              | 151      |
|    time_elapsed     | 1541     |
|    total_timesteps  | 233839   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00207  |
|    n_updates        | 48459    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.506    |
| time/               |          |
|    episodes         | 13288    |
|    fps              | 151      |
|    time_elapsed     | 1541     |
|    total_timesteps  | 233913   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00301  |
|    n_updates        | 48478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.028   |
|    exploration_rate | 0.506    |
| time/               |          |
|    episodes         | 13292    |
|    fps              | 151      |
|    time_elapsed     | 1541     |
|    total_timesteps  | 233979   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00323  |
|    n_updates        | 48494    |
----------------------------------
Eval num_timesteps=234000, episode_reward=-0.13 +/- 0.06
Episode length: 33.38 +/- 16.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 33.4     |
|    mean_reward      | -0.133   |
| rollout/            |          |
|    exploration_rate | 0.505    |
| time/               |          |
|    total_timesteps  | 234000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00248  |
|    n_updates        | 48499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0183  |
|    exploration_rate | 0.505    |
| time/               |          |
|    episodes         | 13296    |
|    fps              | 151      |
|    time_elapsed     | 1543     |
|    total_timesteps  | 234050   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00368  |
|    n_updates        | 48512    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.018   |
|    exploration_rate | 0.505    |
| time/               |          |
|    episodes         | 13300    |
|    fps              | 151      |
|    time_elapsed     | 1543     |
|    total_timesteps  | 234120   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 48529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0182  |
|    exploration_rate | 0.505    |
| time/               |          |
|    episodes         | 13304    |
|    fps              | 151      |
|    time_elapsed     | 1544     |
|    total_timesteps  | 234193   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 48548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00846 |
|    exploration_rate | 0.504    |
| time/               |          |
|    episodes         | 13308    |
|    fps              | 151      |
|    time_elapsed     | 1544     |
|    total_timesteps  | 234262   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 48565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00136  |
|    exploration_rate | 0.504    |
| time/               |          |
|    episodes         | 13312    |
|    fps              | 151      |
|    time_elapsed     | 1544     |
|    total_timesteps  | 234331   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 48582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0016   |
|    exploration_rate | 0.504    |
| time/               |          |
|    episodes         | 13316    |
|    fps              | 151      |
|    time_elapsed     | 1544     |
|    total_timesteps  | 234399   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 48599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00092  |
|    exploration_rate | 0.504    |
| time/               |          |
|    episodes         | 13320    |
|    fps              | 151      |
|    time_elapsed     | 1544     |
|    total_timesteps  | 234478   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00246  |
|    n_updates        | 48619    |
----------------------------------
Eval num_timesteps=234500, episode_reward=-0.17 +/- 0.08
Episode length: 41.58 +/- 20.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.6     |
|    mean_reward      | -0.165   |
| rollout/            |          |
|    exploration_rate | 0.504    |
| time/               |          |
|    total_timesteps  | 234500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 48624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0012   |
|    exploration_rate | 0.503    |
| time/               |          |
|    episodes         | 13324    |
|    fps              | 151      |
|    time_elapsed     | 1547     |
|    total_timesteps  | 234546   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00226  |
|    n_updates        | 48636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0014   |
|    exploration_rate | 0.503    |
| time/               |          |
|    episodes         | 13328    |
|    fps              | 151      |
|    time_elapsed     | 1547     |
|    total_timesteps  | 234614   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00252  |
|    n_updates        | 48653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0215   |
|    exploration_rate | 0.503    |
| time/               |          |
|    episodes         | 13332    |
|    fps              | 151      |
|    time_elapsed     | 1547     |
|    total_timesteps  | 234677   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 48669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0214   |
|    exploration_rate | 0.503    |
| time/               |          |
|    episodes         | 13336    |
|    fps              | 151      |
|    time_elapsed     | 1547     |
|    total_timesteps  | 234742   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00288  |
|    n_updates        | 48685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0216   |
|    exploration_rate | 0.502    |
| time/               |          |
|    episodes         | 13340    |
|    fps              | 151      |
|    time_elapsed     | 1547     |
|    total_timesteps  | 234814   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00508  |
|    n_updates        | 48703    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0113   |
|    exploration_rate | 0.502    |
| time/               |          |
|    episodes         | 13344    |
|    fps              | 151      |
|    time_elapsed     | 1547     |
|    total_timesteps  | 234877   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0025   |
|    n_updates        | 48719    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 0.502    |
| time/               |          |
|    episodes         | 13348    |
|    fps              | 151      |
|    time_elapsed     | 1548     |
|    total_timesteps  | 234958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 48739    |
----------------------------------
Eval num_timesteps=235000, episode_reward=-0.11 +/- 0.21
Episode length: 38.66 +/- 18.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.7     |
|    mean_reward      | -0.114   |
| rollout/            |          |
|    exploration_rate | 0.502    |
| time/               |          |
|    total_timesteps  | 235000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000998 |
|    n_updates        | 48749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0213   |
|    exploration_rate | 0.502    |
| time/               |          |
|    episodes         | 13352    |
|    fps              | 151      |
|    time_elapsed     | 1550     |
|    total_timesteps  | 235026   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 48756    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0106   |
|    exploration_rate | 0.501    |
| time/               |          |
|    episodes         | 13356    |
|    fps              | 151      |
|    time_elapsed     | 1550     |
|    total_timesteps  | 235107   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 48776    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0104   |
|    exploration_rate | 0.501    |
| time/               |          |
|    episodes         | 13360    |
|    fps              | 151      |
|    time_elapsed     | 1550     |
|    total_timesteps  | 235181   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00211  |
|    n_updates        | 48795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 0.501    |
| time/               |          |
|    episodes         | 13364    |
|    fps              | 151      |
|    time_elapsed     | 1550     |
|    total_timesteps  | 235243   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 48810    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0307   |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 13368    |
|    fps              | 151      |
|    time_elapsed     | 1550     |
|    total_timesteps  | 235303   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00299  |
|    n_updates        | 48825    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 13372    |
|    fps              | 151      |
|    time_elapsed     | 1550     |
|    total_timesteps  | 235368   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 48841    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0215   |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 13376    |
|    fps              | 151      |
|    time_elapsed     | 1551     |
|    total_timesteps  | 235447   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 48861    |
----------------------------------
Eval num_timesteps=235500, episode_reward=-0.10 +/- 0.20
Episode length: 34.02 +/- 17.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34       |
|    mean_reward      | -0.0951  |
| rollout/            |          |
|    exploration_rate | 0.5      |
| time/               |          |
|    total_timesteps  | 235500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 48874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0215   |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 13380    |
|    fps              | 151      |
|    time_elapsed     | 1553     |
|    total_timesteps  | 235514   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00308  |
|    n_updates        | 48878    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0216   |
|    exploration_rate | 0.499    |
| time/               |          |
|    episodes         | 13384    |
|    fps              | 151      |
|    time_elapsed     | 1553     |
|    total_timesteps  | 235575   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 48893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0218   |
|    exploration_rate | 0.499    |
| time/               |          |
|    episodes         | 13388    |
|    fps              | 151      |
|    time_elapsed     | 1553     |
|    total_timesteps  | 235644   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00618  |
|    n_updates        | 48910    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0216   |
|    exploration_rate | 0.499    |
| time/               |          |
|    episodes         | 13392    |
|    fps              | 151      |
|    time_elapsed     | 1553     |
|    total_timesteps  | 235714   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 48928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.499    |
| time/               |          |
|    episodes         | 13396    |
|    fps              | 151      |
|    time_elapsed     | 1553     |
|    total_timesteps  | 235788   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00452  |
|    n_updates        | 48946    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0213   |
|    exploration_rate | 0.498    |
| time/               |          |
|    episodes         | 13400    |
|    fps              | 151      |
|    time_elapsed     | 1553     |
|    total_timesteps  | 235862   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 48965    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0217   |
|    exploration_rate | 0.498    |
| time/               |          |
|    episodes         | 13404    |
|    fps              | 151      |
|    time_elapsed     | 1553     |
|    total_timesteps  | 235925   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 48981    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0321   |
|    exploration_rate | 0.498    |
| time/               |          |
|    episodes         | 13408    |
|    fps              | 151      |
|    time_elapsed     | 1553     |
|    total_timesteps  | 235984   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 48995    |
----------------------------------
Eval num_timesteps=236000, episode_reward=-0.13 +/- 0.07
Episode length: 32.44 +/- 16.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 32.4     |
|    mean_reward      | -0.129   |
| rollout/            |          |
|    exploration_rate | 0.498    |
| time/               |          |
|    total_timesteps  | 236000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00262  |
|    n_updates        | 48999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.022    |
|    exploration_rate | 0.498    |
| time/               |          |
|    episodes         | 13412    |
|    fps              | 151      |
|    time_elapsed     | 1556     |
|    total_timesteps  | 236056   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 49013    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0318   |
|    exploration_rate | 0.497    |
| time/               |          |
|    episodes         | 13416    |
|    fps              | 151      |
|    time_elapsed     | 1556     |
|    total_timesteps  | 236130   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 49032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.042    |
|    exploration_rate | 0.497    |
| time/               |          |
|    episodes         | 13420    |
|    fps              | 151      |
|    time_elapsed     | 1556     |
|    total_timesteps  | 236204   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 49050    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0419   |
|    exploration_rate | 0.497    |
| time/               |          |
|    episodes         | 13424    |
|    fps              | 151      |
|    time_elapsed     | 1556     |
|    total_timesteps  | 236273   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000854 |
|    n_updates        | 49068    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.042    |
|    exploration_rate | 0.496    |
| time/               |          |
|    episodes         | 13428    |
|    fps              | 151      |
|    time_elapsed     | 1556     |
|    total_timesteps  | 236338   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 49084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0217   |
|    exploration_rate | 0.496    |
| time/               |          |
|    episodes         | 13432    |
|    fps              | 151      |
|    time_elapsed     | 1556     |
|    total_timesteps  | 236410   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0077   |
|    n_updates        | 49102    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0312   |
|    exploration_rate | 0.496    |
| time/               |          |
|    episodes         | 13436    |
|    fps              | 151      |
|    time_elapsed     | 1556     |
|    total_timesteps  | 236486   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 49121    |
----------------------------------
Eval num_timesteps=236500, episode_reward=-0.14 +/- 0.21
Episode length: 44.78 +/- 19.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | -0.138   |
| rollout/            |          |
|    exploration_rate | 0.496    |
| time/               |          |
|    total_timesteps  | 236500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00303  |
|    n_updates        | 49124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0315   |
|    exploration_rate | 0.496    |
| time/               |          |
|    episodes         | 13440    |
|    fps              | 151      |
|    time_elapsed     | 1559     |
|    total_timesteps  | 236551   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 49137    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0313   |
|    exploration_rate | 0.495    |
| time/               |          |
|    episodes         | 13444    |
|    fps              | 151      |
|    time_elapsed     | 1559     |
|    total_timesteps  | 236618   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 49154    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0321   |
|    exploration_rate | 0.495    |
| time/               |          |
|    episodes         | 13448    |
|    fps              | 151      |
|    time_elapsed     | 1559     |
|    total_timesteps  | 236680   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00182  |
|    n_updates        | 49169    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0323   |
|    exploration_rate | 0.495    |
| time/               |          |
|    episodes         | 13452    |
|    fps              | 151      |
|    time_elapsed     | 1559     |
|    total_timesteps  | 236743   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 49185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0327   |
|    exploration_rate | 0.495    |
| time/               |          |
|    episodes         | 13456    |
|    fps              | 151      |
|    time_elapsed     | 1559     |
|    total_timesteps  | 236814   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00553  |
|    n_updates        | 49203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0325   |
|    exploration_rate | 0.494    |
| time/               |          |
|    episodes         | 13460    |
|    fps              | 151      |
|    time_elapsed     | 1559     |
|    total_timesteps  | 236894   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 49223    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0324   |
|    exploration_rate | 0.494    |
| time/               |          |
|    episodes         | 13464    |
|    fps              | 151      |
|    time_elapsed     | 1560     |
|    total_timesteps  | 236958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 49239    |
----------------------------------
Eval num_timesteps=237000, episode_reward=-0.15 +/- 0.07
Episode length: 36.60 +/- 18.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36.6     |
|    mean_reward      | -0.145   |
| rollout/            |          |
|    exploration_rate | 0.494    |
| time/               |          |
|    total_timesteps  | 237000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 49249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.022    |
|    exploration_rate | 0.494    |
| time/               |          |
|    episodes         | 13468    |
|    fps              | 151      |
|    time_elapsed     | 1562     |
|    total_timesteps  | 237029   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 49257    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0216   |
|    exploration_rate | 0.494    |
| time/               |          |
|    episodes         | 13472    |
|    fps              | 151      |
|    time_elapsed     | 1562     |
|    total_timesteps  | 237102   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00439  |
|    n_updates        | 49275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0324   |
|    exploration_rate | 0.493    |
| time/               |          |
|    episodes         | 13476    |
|    fps              | 151      |
|    time_elapsed     | 1562     |
|    total_timesteps  | 237162   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00332  |
|    n_updates        | 49290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0426   |
|    exploration_rate | 0.493    |
| time/               |          |
|    episodes         | 13480    |
|    fps              | 151      |
|    time_elapsed     | 1562     |
|    total_timesteps  | 237223   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 49305    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0418   |
|    exploration_rate | 0.493    |
| time/               |          |
|    episodes         | 13484    |
|    fps              | 151      |
|    time_elapsed     | 1562     |
|    total_timesteps  | 237305   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00387  |
|    n_updates        | 49326    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.031    |
|    exploration_rate | 0.492    |
| time/               |          |
|    episodes         | 13488    |
|    fps              | 151      |
|    time_elapsed     | 1563     |
|    total_timesteps  | 237393   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0018   |
|    n_updates        | 49348    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0411   |
|    exploration_rate | 0.492    |
| time/               |          |
|    episodes         | 13492    |
|    fps              | 151      |
|    time_elapsed     | 1563     |
|    total_timesteps  | 237461   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00392  |
|    n_updates        | 49365    |
----------------------------------
Eval num_timesteps=237500, episode_reward=-0.16 +/- 0.17
Episode length: 44.88 +/- 21.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | -0.159   |
| rollout/            |          |
|    exploration_rate | 0.492    |
| time/               |          |
|    total_timesteps  | 237500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 49374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0516   |
|    exploration_rate | 0.492    |
| time/               |          |
|    episodes         | 13496    |
|    fps              | 151      |
|    time_elapsed     | 1565     |
|    total_timesteps  | 237523   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00363  |
|    n_updates        | 49380    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0619   |
|    exploration_rate | 0.492    |
| time/               |          |
|    episodes         | 13500    |
|    fps              | 151      |
|    time_elapsed     | 1566     |
|    total_timesteps  | 237591   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000843 |
|    n_updates        | 49397    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0615   |
|    exploration_rate | 0.491    |
| time/               |          |
|    episodes         | 13504    |
|    fps              | 151      |
|    time_elapsed     | 1566     |
|    total_timesteps  | 237662   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 49415    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0409   |
|    exploration_rate | 0.491    |
| time/               |          |
|    episodes         | 13508    |
|    fps              | 151      |
|    time_elapsed     | 1566     |
|    total_timesteps  | 237736   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00276  |
|    n_updates        | 49433    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0412   |
|    exploration_rate | 0.491    |
| time/               |          |
|    episodes         | 13512    |
|    fps              | 151      |
|    time_elapsed     | 1566     |
|    total_timesteps  | 237802   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 49450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0408   |
|    exploration_rate | 0.49     |
| time/               |          |
|    episodes         | 13516    |
|    fps              | 151      |
|    time_elapsed     | 1566     |
|    total_timesteps  | 237886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000821 |
|    n_updates        | 49471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0308   |
|    exploration_rate | 0.49     |
| time/               |          |
|    episodes         | 13520    |
|    fps              | 151      |
|    time_elapsed     | 1566     |
|    total_timesteps  | 237959   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 49489    |
----------------------------------
Eval num_timesteps=238000, episode_reward=-0.17 +/- 0.07
Episode length: 43.88 +/- 17.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | -0.175   |
| rollout/            |          |
|    exploration_rate | 0.49     |
| time/               |          |
|    total_timesteps  | 238000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 49499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0308   |
|    exploration_rate | 0.49     |
| time/               |          |
|    episodes         | 13524    |
|    fps              | 151      |
|    time_elapsed     | 1569     |
|    total_timesteps  | 238028   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 49506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0307   |
|    exploration_rate | 0.49     |
| time/               |          |
|    episodes         | 13528    |
|    fps              | 151      |
|    time_elapsed     | 1569     |
|    total_timesteps  | 238095   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 49523    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0404   |
|    exploration_rate | 0.489    |
| time/               |          |
|    episodes         | 13532    |
|    fps              | 151      |
|    time_elapsed     | 1569     |
|    total_timesteps  | 238177   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 49544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 0.489    |
| time/               |          |
|    episodes         | 13536    |
|    fps              | 151      |
|    time_elapsed     | 1570     |
|    total_timesteps  | 238249   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00348  |
|    n_updates        | 49562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 0.489    |
| time/               |          |
|    episodes         | 13540    |
|    fps              | 151      |
|    time_elapsed     | 1570     |
|    total_timesteps  | 238317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 49579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 0.489    |
| time/               |          |
|    episodes         | 13544    |
|    fps              | 151      |
|    time_elapsed     | 1570     |
|    total_timesteps  | 238381   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00229  |
|    n_updates        | 49595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0299   |
|    exploration_rate | 0.488    |
| time/               |          |
|    episodes         | 13548    |
|    fps              | 151      |
|    time_elapsed     | 1570     |
|    total_timesteps  | 238458   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 49614    |
----------------------------------
Eval num_timesteps=238500, episode_reward=-0.11 +/- 0.20
Episode length: 37.40 +/- 17.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.4     |
|    mean_reward      | -0.109   |
| rollout/            |          |
|    exploration_rate | 0.488    |
| time/               |          |
|    total_timesteps  | 238500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 49624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0195   |
|    exploration_rate | 0.488    |
| time/               |          |
|    episodes         | 13552    |
|    fps              | 151      |
|    time_elapsed     | 1572     |
|    total_timesteps  | 238531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 49632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 0.488    |
| time/               |          |
|    episodes         | 13556    |
|    fps              | 151      |
|    time_elapsed     | 1572     |
|    total_timesteps  | 238601   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 49650    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0203   |
|    exploration_rate | 0.487    |
| time/               |          |
|    episodes         | 13560    |
|    fps              | 151      |
|    time_elapsed     | 1572     |
|    total_timesteps  | 238663   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 49665    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 0.487    |
| time/               |          |
|    episodes         | 13564    |
|    fps              | 151      |
|    time_elapsed     | 1573     |
|    total_timesteps  | 238730   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00767  |
|    n_updates        | 49682    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00964  |
|    exploration_rate | 0.487    |
| time/               |          |
|    episodes         | 13568    |
|    fps              | 151      |
|    time_elapsed     | 1573     |
|    total_timesteps  | 238814   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00297  |
|    n_updates        | 49703    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00996  |
|    exploration_rate | 0.487    |
| time/               |          |
|    episodes         | 13572    |
|    fps              | 151      |
|    time_elapsed     | 1573     |
|    total_timesteps  | 238879   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 49719    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0008  |
|    exploration_rate | 0.486    |
| time/               |          |
|    episodes         | 13576    |
|    fps              | 151      |
|    time_elapsed     | 1573     |
|    total_timesteps  | 238958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00211  |
|    n_updates        | 49739    |
----------------------------------
Eval num_timesteps=239000, episode_reward=-0.13 +/- 0.15
Episode length: 37.74 +/- 19.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.7     |
|    mean_reward      | -0.13    |
| rollout/            |          |
|    exploration_rate | 0.486    |
| time/               |          |
|    total_timesteps  | 239000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 49749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.486    |
| time/               |          |
|    episodes         | 13580    |
|    fps              | 151      |
|    time_elapsed     | 1576     |
|    total_timesteps  | 239030   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 49757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0105  |
|    exploration_rate | 0.486    |
| time/               |          |
|    episodes         | 13584    |
|    fps              | 151      |
|    time_elapsed     | 1576     |
|    total_timesteps  | 239093   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 49773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0006   |
|    exploration_rate | 0.486    |
| time/               |          |
|    episodes         | 13588    |
|    fps              | 151      |
|    time_elapsed     | 1576     |
|    total_timesteps  | 239154   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00243  |
|    n_updates        | 49788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00971 |
|    exploration_rate | 0.485    |
| time/               |          |
|    episodes         | 13592    |
|    fps              | 151      |
|    time_elapsed     | 1576     |
|    total_timesteps  | 239230   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00295  |
|    n_updates        | 49807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0198  |
|    exploration_rate | 0.485    |
| time/               |          |
|    episodes         | 13596    |
|    fps              | 151      |
|    time_elapsed     | 1576     |
|    total_timesteps  | 239293   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0019   |
|    n_updates        | 49823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0399  |
|    exploration_rate | 0.485    |
| time/               |          |
|    episodes         | 13600    |
|    fps              | 151      |
|    time_elapsed     | 1576     |
|    total_timesteps  | 239364   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 49840    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0297  |
|    exploration_rate | 0.485    |
| time/               |          |
|    episodes         | 13604    |
|    fps              | 151      |
|    time_elapsed     | 1576     |
|    total_timesteps  | 239430   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000957 |
|    n_updates        | 49857    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0193  |
|    exploration_rate | 0.484    |
| time/               |          |
|    episodes         | 13608    |
|    fps              | 151      |
|    time_elapsed     | 1576     |
|    total_timesteps  | 239493   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00334  |
|    n_updates        | 49873    |
----------------------------------
Eval num_timesteps=239500, episode_reward=-0.05 +/- 0.27
Episode length: 33.06 +/- 16.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 33.1     |
|    mean_reward      | -0.0513  |
| rollout/            |          |
|    exploration_rate | 0.484    |
| time/               |          |
|    total_timesteps  | 239500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00504  |
|    n_updates        | 49874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.484    |
| time/               |          |
|    episodes         | 13612    |
|    fps              | 151      |
|    time_elapsed     | 1579     |
|    total_timesteps  | 239568   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00555  |
|    n_updates        | 49891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0289  |
|    exploration_rate | 0.484    |
| time/               |          |
|    episodes         | 13616    |
|    fps              | 151      |
|    time_elapsed     | 1579     |
|    total_timesteps  | 239633   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 49908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0289  |
|    exploration_rate | 0.483    |
| time/               |          |
|    episodes         | 13620    |
|    fps              | 151      |
|    time_elapsed     | 1579     |
|    total_timesteps  | 239706   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 49926    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0187  |
|    exploration_rate | 0.483    |
| time/               |          |
|    episodes         | 13624    |
|    fps              | 151      |
|    time_elapsed     | 1579     |
|    total_timesteps  | 239770   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0038   |
|    n_updates        | 49942    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00881 |
|    exploration_rate | 0.483    |
| time/               |          |
|    episodes         | 13628    |
|    fps              | 151      |
|    time_elapsed     | 1579     |
|    total_timesteps  | 239840   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 49959    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00834 |
|    exploration_rate | 0.483    |
| time/               |          |
|    episodes         | 13632    |
|    fps              | 151      |
|    time_elapsed     | 1579     |
|    total_timesteps  | 239910   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 49977    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00191  |
|    exploration_rate | 0.482    |
| time/               |          |
|    episodes         | 13636    |
|    fps              | 151      |
|    time_elapsed     | 1579     |
|    total_timesteps  | 239976   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 49993    |
----------------------------------
Eval num_timesteps=240000, episode_reward=-0.14 +/- 0.15
Episode length: 39.10 +/- 18.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.1     |
|    mean_reward      | -0.135   |
| rollout/            |          |
|    exploration_rate | 0.482    |
| time/               |          |
|    total_timesteps  | 240000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 49999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00187  |
|    exploration_rate | 0.482    |
| time/               |          |
|    episodes         | 13640    |
|    fps              | 151      |
|    time_elapsed     | 1582     |
|    total_timesteps  | 240045   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 50011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00199  |
|    exploration_rate | 0.482    |
| time/               |          |
|    episodes         | 13644    |
|    fps              | 151      |
|    time_elapsed     | 1582     |
|    total_timesteps  | 240106   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00224  |
|    n_updates        | 50026    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00263  |
|    exploration_rate | 0.482    |
| time/               |          |
|    episodes         | 13648    |
|    fps              | 151      |
|    time_elapsed     | 1582     |
|    total_timesteps  | 240167   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 50041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00283  |
|    exploration_rate | 0.481    |
| time/               |          |
|    episodes         | 13652    |
|    fps              | 151      |
|    time_elapsed     | 1582     |
|    total_timesteps  | 240235   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 50058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00291  |
|    exploration_rate | 0.481    |
| time/               |          |
|    episodes         | 13656    |
|    fps              | 151      |
|    time_elapsed     | 1582     |
|    total_timesteps  | 240303   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 50075    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00247  |
|    exploration_rate | 0.481    |
| time/               |          |
|    episodes         | 13660    |
|    fps              | 151      |
|    time_elapsed     | 1582     |
|    total_timesteps  | 240376   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 50093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00223  |
|    exploration_rate | 0.481    |
| time/               |          |
|    episodes         | 13664    |
|    fps              | 151      |
|    time_elapsed     | 1582     |
|    total_timesteps  | 240449   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 50112    |
----------------------------------
Eval num_timesteps=240500, episode_reward=-0.11 +/- 0.21
Episode length: 38.94 +/- 20.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.9     |
|    mean_reward      | -0.115   |
| rollout/            |          |
|    exploration_rate | 0.48     |
| time/               |          |
|    total_timesteps  | 240500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00629  |
|    n_updates        | 50124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00279  |
|    exploration_rate | 0.48     |
| time/               |          |
|    episodes         | 13668    |
|    fps              | 151      |
|    time_elapsed     | 1585     |
|    total_timesteps  | 240519   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00677  |
|    n_updates        | 50129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0126   |
|    exploration_rate | 0.48     |
| time/               |          |
|    episodes         | 13672    |
|    fps              | 151      |
|    time_elapsed     | 1585     |
|    total_timesteps  | 240590   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0037   |
|    n_updates        | 50147    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.013    |
|    exploration_rate | 0.48     |
| time/               |          |
|    episodes         | 13676    |
|    fps              | 151      |
|    time_elapsed     | 1585     |
|    total_timesteps  | 240658   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 50164    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0131   |
|    exploration_rate | 0.479    |
| time/               |          |
|    episodes         | 13680    |
|    fps              | 151      |
|    time_elapsed     | 1585     |
|    total_timesteps  | 240728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0036   |
|    n_updates        | 50181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0128   |
|    exploration_rate | 0.479    |
| time/               |          |
|    episodes         | 13684    |
|    fps              | 151      |
|    time_elapsed     | 1585     |
|    total_timesteps  | 240797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 50199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0125   |
|    exploration_rate | 0.479    |
| time/               |          |
|    episodes         | 13688    |
|    fps              | 151      |
|    time_elapsed     | 1586     |
|    total_timesteps  | 240868   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 50216    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.479    |
| time/               |          |
|    episodes         | 13692    |
|    fps              | 151      |
|    time_elapsed     | 1586     |
|    total_timesteps  | 240932   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 50232    |
----------------------------------
Eval num_timesteps=241000, episode_reward=-0.12 +/- 0.26
Episode length: 45.92 +/- 23.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | -0.123   |
| rollout/            |          |
|    exploration_rate | 0.478    |
| time/               |          |
|    total_timesteps  | 241000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 50249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.478    |
| time/               |          |
|    episodes         | 13696    |
|    fps              | 151      |
|    time_elapsed     | 1589     |
|    total_timesteps  | 241031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 50257    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 0.478    |
| time/               |          |
|    episodes         | 13700    |
|    fps              | 151      |
|    time_elapsed     | 1589     |
|    total_timesteps  | 241096   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 50273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00159  |
|    exploration_rate | 0.478    |
| time/               |          |
|    episodes         | 13704    |
|    fps              | 151      |
|    time_elapsed     | 1589     |
|    total_timesteps  | 241166   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00264  |
|    n_updates        | 50291    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00845 |
|    exploration_rate | 0.478    |
| time/               |          |
|    episodes         | 13708    |
|    fps              | 151      |
|    time_elapsed     | 1589     |
|    total_timesteps  | 241230   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 50307    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00801 |
|    exploration_rate | 0.477    |
| time/               |          |
|    episodes         | 13712    |
|    fps              | 151      |
|    time_elapsed     | 1589     |
|    total_timesteps  | 241294   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0018   |
|    n_updates        | 50323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00821 |
|    exploration_rate | 0.477    |
| time/               |          |
|    episodes         | 13716    |
|    fps              | 151      |
|    time_elapsed     | 1589     |
|    total_timesteps  | 241364   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 50340    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00833 |
|    exploration_rate | 0.477    |
| time/               |          |
|    episodes         | 13720    |
|    fps              | 151      |
|    time_elapsed     | 1589     |
|    total_timesteps  | 241440   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00397  |
|    n_updates        | 50359    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00805 |
|    exploration_rate | 0.476    |
| time/               |          |
|    episodes         | 13724    |
|    fps              | 151      |
|    time_elapsed     | 1590     |
|    total_timesteps  | 241497   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000988 |
|    n_updates        | 50374    |
----------------------------------
Eval num_timesteps=241500, episode_reward=0.03 +/- 0.38
Episode length: 38.12 +/- 18.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.1     |
|    mean_reward      | 0.0285   |
| rollout/            |          |
|    exploration_rate | 0.476    |
| time/               |          |
|    total_timesteps  | 241500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.00783 |
|    exploration_rate | 0.476    |
| time/               |          |
|    episodes         | 13728    |
|    fps              | 151      |
|    time_elapsed     | 1592     |
|    total_timesteps  | 241561   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 50390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0178  |
|    exploration_rate | 0.476    |
| time/               |          |
|    episodes         | 13732    |
|    fps              | 151      |
|    time_elapsed     | 1592     |
|    total_timesteps  | 241630   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00365  |
|    n_updates        | 50407    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0278  |
|    exploration_rate | 0.476    |
| time/               |          |
|    episodes         | 13736    |
|    fps              | 151      |
|    time_elapsed     | 1592     |
|    total_timesteps  | 241696   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00792  |
|    n_updates        | 50423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0278  |
|    exploration_rate | 0.475    |
| time/               |          |
|    episodes         | 13740    |
|    fps              | 151      |
|    time_elapsed     | 1592     |
|    total_timesteps  | 241765   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 50441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0283  |
|    exploration_rate | 0.475    |
| time/               |          |
|    episodes         | 13744    |
|    fps              | 151      |
|    time_elapsed     | 1593     |
|    total_timesteps  | 241839   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 50459    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0292  |
|    exploration_rate | 0.475    |
| time/               |          |
|    episodes         | 13748    |
|    fps              | 151      |
|    time_elapsed     | 1593     |
|    total_timesteps  | 241922   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 50480    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0188  |
|    exploration_rate | 0.475    |
| time/               |          |
|    episodes         | 13752    |
|    fps              | 151      |
|    time_elapsed     | 1593     |
|    total_timesteps  | 241981   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 50495    |
----------------------------------
Eval num_timesteps=242000, episode_reward=-0.03 +/- 0.34
Episode length: 41.74 +/- 20.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.7     |
|    mean_reward      | -0.0259  |
| rollout/            |          |
|    exploration_rate | 0.475    |
| time/               |          |
|    total_timesteps  | 242000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00288  |
|    n_updates        | 50499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00861 |
|    exploration_rate | 0.474    |
| time/               |          |
|    episodes         | 13756    |
|    fps              | 151      |
|    time_elapsed     | 1595     |
|    total_timesteps  | 242044   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 50510    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00165  |
|    exploration_rate | 0.474    |
| time/               |          |
|    episodes         | 13760    |
|    fps              | 151      |
|    time_elapsed     | 1595     |
|    total_timesteps  | 242111   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00247  |
|    n_updates        | 50527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00157  |
|    exploration_rate | 0.474    |
| time/               |          |
|    episodes         | 13764    |
|    fps              | 151      |
|    time_elapsed     | 1596     |
|    total_timesteps  | 242186   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00292  |
|    n_updates        | 50546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00137  |
|    exploration_rate | 0.474    |
| time/               |          |
|    episodes         | 13768    |
|    fps              | 151      |
|    time_elapsed     | 1596     |
|    total_timesteps  | 242261   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00509  |
|    n_updates        | 50565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00159  |
|    exploration_rate | 0.473    |
| time/               |          |
|    episodes         | 13772    |
|    fps              | 151      |
|    time_elapsed     | 1596     |
|    total_timesteps  | 242326   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00232  |
|    n_updates        | 50581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00163  |
|    exploration_rate | 0.473    |
| time/               |          |
|    episodes         | 13776    |
|    fps              | 151      |
|    time_elapsed     | 1596     |
|    total_timesteps  | 242393   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00439  |
|    n_updates        | 50598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00155  |
|    exploration_rate | 0.473    |
| time/               |          |
|    episodes         | 13780    |
|    fps              | 151      |
|    time_elapsed     | 1596     |
|    total_timesteps  | 242465   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000801 |
|    n_updates        | 50616    |
----------------------------------
Eval num_timesteps=242500, episode_reward=-0.06 +/- 0.19
Episode length: 24.08 +/- 10.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 24.1     |
|    mean_reward      | -0.0553  |
| rollout/            |          |
|    exploration_rate | 0.473    |
| time/               |          |
|    total_timesteps  | 242500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 50624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00151  |
|    exploration_rate | 0.472    |
| time/               |          |
|    episodes         | 13784    |
|    fps              | 151      |
|    time_elapsed     | 1598     |
|    total_timesteps  | 242535   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 50633    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00178  |
|    exploration_rate | 0.472    |
| time/               |          |
|    episodes         | 13788    |
|    fps              | 151      |
|    time_elapsed     | 1598     |
|    total_timesteps  | 242599   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 50649    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0017   |
|    exploration_rate | 0.472    |
| time/               |          |
|    episodes         | 13792    |
|    fps              | 151      |
|    time_elapsed     | 1598     |
|    total_timesteps  | 242665   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 50666    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0128   |
|    exploration_rate | 0.472    |
| time/               |          |
|    episodes         | 13796    |
|    fps              | 151      |
|    time_elapsed     | 1598     |
|    total_timesteps  | 242736   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 50683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.471    |
| time/               |          |
|    episodes         | 13800    |
|    fps              | 151      |
|    time_elapsed     | 1598     |
|    total_timesteps  | 242800   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 50699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.471    |
| time/               |          |
|    episodes         | 13804    |
|    fps              | 151      |
|    time_elapsed     | 1598     |
|    total_timesteps  | 242869   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00721  |
|    n_updates        | 50717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0228   |
|    exploration_rate | 0.471    |
| time/               |          |
|    episodes         | 13808    |
|    fps              | 151      |
|    time_elapsed     | 1599     |
|    total_timesteps  | 242936   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00461  |
|    n_updates        | 50733    |
----------------------------------
Eval num_timesteps=243000, episode_reward=-0.11 +/- 0.15
Episode length: 32.16 +/- 18.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 32.2     |
|    mean_reward      | -0.108   |
| rollout/            |          |
|    exploration_rate | 0.471    |
| time/               |          |
|    total_timesteps  | 243000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 50749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0226   |
|    exploration_rate | 0.471    |
| time/               |          |
|    episodes         | 13812    |
|    fps              | 151      |
|    time_elapsed     | 1601     |
|    total_timesteps  | 243006   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 50751    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0223   |
|    exploration_rate | 0.47     |
| time/               |          |
|    episodes         | 13816    |
|    fps              | 151      |
|    time_elapsed     | 1601     |
|    total_timesteps  | 243082   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00293  |
|    n_updates        | 50770    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0223   |
|    exploration_rate | 0.47     |
| time/               |          |
|    episodes         | 13820    |
|    fps              | 151      |
|    time_elapsed     | 1601     |
|    total_timesteps  | 243158   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00313  |
|    n_updates        | 50789    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 0.47     |
| time/               |          |
|    episodes         | 13824    |
|    fps              | 151      |
|    time_elapsed     | 1601     |
|    total_timesteps  | 243230   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 50807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.012    |
|    exploration_rate | 0.469    |
| time/               |          |
|    episodes         | 13828    |
|    fps              | 151      |
|    time_elapsed     | 1601     |
|    total_timesteps  | 243289   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 50822    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0223   |
|    exploration_rate | 0.469    |
| time/               |          |
|    episodes         | 13832    |
|    fps              | 151      |
|    time_elapsed     | 1601     |
|    total_timesteps  | 243349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00277  |
|    n_updates        | 50837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0225   |
|    exploration_rate | 0.469    |
| time/               |          |
|    episodes         | 13836    |
|    fps              | 151      |
|    time_elapsed     | 1601     |
|    total_timesteps  | 243411   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00298  |
|    n_updates        | 50852    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0327   |
|    exploration_rate | 0.469    |
| time/               |          |
|    episodes         | 13840    |
|    fps              | 151      |
|    time_elapsed     | 1602     |
|    total_timesteps  | 243475   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 50868    |
----------------------------------
Eval num_timesteps=243500, episode_reward=-0.11 +/- 0.16
Episode length: 32.58 +/- 18.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 32.6     |
|    mean_reward      | -0.109   |
| rollout/            |          |
|    exploration_rate | 0.469    |
| time/               |          |
|    total_timesteps  | 243500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00238  |
|    n_updates        | 50874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0431   |
|    exploration_rate | 0.469    |
| time/               |          |
|    episodes         | 13844    |
|    fps              | 151      |
|    time_elapsed     | 1604     |
|    total_timesteps  | 243539   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00492  |
|    n_updates        | 50884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0435   |
|    exploration_rate | 0.468    |
| time/               |          |
|    episodes         | 13848    |
|    fps              | 151      |
|    time_elapsed     | 1604     |
|    total_timesteps  | 243612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 50902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.033    |
|    exploration_rate | 0.468    |
| time/               |          |
|    episodes         | 13852    |
|    fps              | 151      |
|    time_elapsed     | 1604     |
|    total_timesteps  | 243682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0019   |
|    n_updates        | 50920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0228   |
|    exploration_rate | 0.468    |
| time/               |          |
|    episodes         | 13856    |
|    fps              | 151      |
|    time_elapsed     | 1604     |
|    total_timesteps  | 243750   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 50937    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0226   |
|    exploration_rate | 0.467    |
| time/               |          |
|    episodes         | 13860    |
|    fps              | 151      |
|    time_elapsed     | 1604     |
|    total_timesteps  | 243822   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00393  |
|    n_updates        | 50955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0229   |
|    exploration_rate | 0.467    |
| time/               |          |
|    episodes         | 13864    |
|    fps              | 151      |
|    time_elapsed     | 1604     |
|    total_timesteps  | 243889   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00484  |
|    n_updates        | 50972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0232   |
|    exploration_rate | 0.467    |
| time/               |          |
|    episodes         | 13868    |
|    fps              | 151      |
|    time_elapsed     | 1605     |
|    total_timesteps  | 243958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 50989    |
----------------------------------
Eval num_timesteps=244000, episode_reward=-0.03 +/- 0.32
Episode length: 32.00 +/- 20.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 32       |
|    mean_reward      | -0.027   |
| rollout/            |          |
|    exploration_rate | 0.467    |
| time/               |          |
|    total_timesteps  | 244000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00444  |
|    n_updates        | 50999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.467    |
| time/               |          |
|    episodes         | 13872    |
|    fps              | 151      |
|    time_elapsed     | 1607     |
|    total_timesteps  | 244029   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 51007    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0228   |
|    exploration_rate | 0.466    |
| time/               |          |
|    episodes         | 13876    |
|    fps              | 151      |
|    time_elapsed     | 1607     |
|    total_timesteps  | 244100   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00351  |
|    n_updates        | 51024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0232   |
|    exploration_rate | 0.466    |
| time/               |          |
|    episodes         | 13880    |
|    fps              | 151      |
|    time_elapsed     | 1607     |
|    total_timesteps  | 244161   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 51040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0235   |
|    exploration_rate | 0.466    |
| time/               |          |
|    episodes         | 13884    |
|    fps              | 151      |
|    time_elapsed     | 1607     |
|    total_timesteps  | 244224   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000905 |
|    n_updates        | 51055    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0338   |
|    exploration_rate | 0.466    |
| time/               |          |
|    episodes         | 13888    |
|    fps              | 151      |
|    time_elapsed     | 1607     |
|    total_timesteps  | 244280   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 51069    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0339   |
|    exploration_rate | 0.465    |
| time/               |          |
|    episodes         | 13892    |
|    fps              | 151      |
|    time_elapsed     | 1607     |
|    total_timesteps  | 244343   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00266  |
|    n_updates        | 51085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0242   |
|    exploration_rate | 0.465    |
| time/               |          |
|    episodes         | 13896    |
|    fps              | 152      |
|    time_elapsed     | 1607     |
|    total_timesteps  | 244408   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 51101    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0241   |
|    exploration_rate | 0.465    |
| time/               |          |
|    episodes         | 13900    |
|    fps              | 152      |
|    time_elapsed     | 1607     |
|    total_timesteps  | 244474   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000809 |
|    n_updates        | 51118    |
----------------------------------
Eval num_timesteps=244500, episode_reward=-0.06 +/- 0.30
Episode length: 40.34 +/- 19.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.3     |
|    mean_reward      | -0.0605  |
| rollout/            |          |
|    exploration_rate | 0.465    |
| time/               |          |
|    total_timesteps  | 244500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000935 |
|    n_updates        | 51124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0342   |
|    exploration_rate | 0.465    |
| time/               |          |
|    episodes         | 13904    |
|    fps              | 151      |
|    time_elapsed     | 1610     |
|    total_timesteps  | 244540   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 51134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0239   |
|    exploration_rate | 0.464    |
| time/               |          |
|    episodes         | 13908    |
|    fps              | 151      |
|    time_elapsed     | 1610     |
|    total_timesteps  | 244615   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0026   |
|    n_updates        | 51153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0341   |
|    exploration_rate | 0.464    |
| time/               |          |
|    episodes         | 13912    |
|    fps              | 151      |
|    time_elapsed     | 1610     |
|    total_timesteps  | 244678   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0138   |
|    n_updates        | 51169    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0448   |
|    exploration_rate | 0.464    |
| time/               |          |
|    episodes         | 13916    |
|    fps              | 151      |
|    time_elapsed     | 1610     |
|    total_timesteps  | 244739   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000848 |
|    n_updates        | 51184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0446   |
|    exploration_rate | 0.463    |
| time/               |          |
|    episodes         | 13920    |
|    fps              | 151      |
|    time_elapsed     | 1610     |
|    total_timesteps  | 244819   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000811 |
|    n_updates        | 51204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0447   |
|    exploration_rate | 0.463    |
| time/               |          |
|    episodes         | 13924    |
|    fps              | 152      |
|    time_elapsed     | 1610     |
|    total_timesteps  | 244888   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00207  |
|    n_updates        | 51221    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0343   |
|    exploration_rate | 0.463    |
| time/               |          |
|    episodes         | 13928    |
|    fps              | 152      |
|    time_elapsed     | 1611     |
|    total_timesteps  | 244958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00232  |
|    n_updates        | 51239    |
----------------------------------
Eval num_timesteps=245000, episode_reward=0.06 +/- 0.39
Episode length: 35.62 +/- 18.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 35.6     |
|    mean_reward      | 0.0586   |
| rollout/            |          |
|    exploration_rate | 0.463    |
| time/               |          |
|    total_timesteps  | 245000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 51249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0239   |
|    exploration_rate | 0.463    |
| time/               |          |
|    episodes         | 13932    |
|    fps              | 151      |
|    time_elapsed     | 1613     |
|    total_timesteps  | 245027   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00313  |
|    n_updates        | 51256    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0442   |
|    exploration_rate | 0.462    |
| time/               |          |
|    episodes         | 13936    |
|    fps              | 151      |
|    time_elapsed     | 1613     |
|    total_timesteps  | 245082   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00579  |
|    n_updates        | 51270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.034    |
|    exploration_rate | 0.462    |
| time/               |          |
|    episodes         | 13940    |
|    fps              | 151      |
|    time_elapsed     | 1613     |
|    total_timesteps  | 245150   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000861 |
|    n_updates        | 51287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.024    |
|    exploration_rate | 0.462    |
| time/               |          |
|    episodes         | 13944    |
|    fps              | 151      |
|    time_elapsed     | 1613     |
|    total_timesteps  | 245214   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 51303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0242   |
|    exploration_rate | 0.462    |
| time/               |          |
|    episodes         | 13948    |
|    fps              | 151      |
|    time_elapsed     | 1613     |
|    total_timesteps  | 245282   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00275  |
|    n_updates        | 51320    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0243   |
|    exploration_rate | 0.461    |
| time/               |          |
|    episodes         | 13952    |
|    fps              | 152      |
|    time_elapsed     | 1614     |
|    total_timesteps  | 245351   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 51337    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0344   |
|    exploration_rate | 0.461    |
| time/               |          |
|    episodes         | 13956    |
|    fps              | 152      |
|    time_elapsed     | 1614     |
|    total_timesteps  | 245415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00494  |
|    n_updates        | 51353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0247   |
|    exploration_rate | 0.461    |
| time/               |          |
|    episodes         | 13960    |
|    fps              | 152      |
|    time_elapsed     | 1614     |
|    total_timesteps  | 245481   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00381  |
|    n_updates        | 51370    |
----------------------------------
Eval num_timesteps=245500, episode_reward=-0.06 +/- 0.21
Episode length: 25.54 +/- 16.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 25.5     |
|    mean_reward      | -0.0612  |
| rollout/            |          |
|    exploration_rate | 0.461    |
| time/               |          |
|    total_timesteps  | 245500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00231  |
|    n_updates        | 51374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0248   |
|    exploration_rate | 0.461    |
| time/               |          |
|    episodes         | 13964    |
|    fps              | 151      |
|    time_elapsed     | 1615     |
|    total_timesteps  | 245545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00271  |
|    n_updates        | 51386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0251   |
|    exploration_rate | 0.46     |
| time/               |          |
|    episodes         | 13968    |
|    fps              | 151      |
|    time_elapsed     | 1615     |
|    total_timesteps  | 245607   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 51401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.035    |
|    exploration_rate | 0.46     |
| time/               |          |
|    episodes         | 13972    |
|    fps              | 152      |
|    time_elapsed     | 1616     |
|    total_timesteps  | 245679   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 51419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0247   |
|    exploration_rate | 0.46     |
| time/               |          |
|    episodes         | 13976    |
|    fps              | 152      |
|    time_elapsed     | 1616     |
|    total_timesteps  | 245759   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 51439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0346   |
|    exploration_rate | 0.46     |
| time/               |          |
|    episodes         | 13980    |
|    fps              | 152      |
|    time_elapsed     | 1616     |
|    total_timesteps  | 245822   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 51455    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0345   |
|    exploration_rate | 0.459    |
| time/               |          |
|    episodes         | 13984    |
|    fps              | 152      |
|    time_elapsed     | 1616     |
|    total_timesteps  | 245888   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00292  |
|    n_updates        | 51471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.459    |
| time/               |          |
|    episodes         | 13988    |
|    fps              | 152      |
|    time_elapsed     | 1616     |
|    total_timesteps  | 245955   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 51488    |
----------------------------------
Eval num_timesteps=246000, episode_reward=-0.01 +/- 0.39
Episode length: 42.18 +/- 20.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.2     |
|    mean_reward      | -0.0077  |
| rollout/            |          |
|    exploration_rate | 0.459    |
| time/               |          |
|    total_timesteps  | 246000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 51499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0136   |
|    exploration_rate | 0.459    |
| time/               |          |
|    episodes         | 13992    |
|    fps              | 151      |
|    time_elapsed     | 1619     |
|    total_timesteps  | 246029   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 51507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0137   |
|    exploration_rate | 0.458    |
| time/               |          |
|    episodes         | 13996    |
|    fps              | 151      |
|    time_elapsed     | 1619     |
|    total_timesteps  | 246091   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 51522    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0135   |
|    exploration_rate | 0.458    |
| time/               |          |
|    episodes         | 14000    |
|    fps              | 151      |
|    time_elapsed     | 1619     |
|    total_timesteps  | 246162   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000956 |
|    n_updates        | 51540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00341  |
|    exploration_rate | 0.458    |
| time/               |          |
|    episodes         | 14004    |
|    fps              | 152      |
|    time_elapsed     | 1619     |
|    total_timesteps  | 246231   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 51557    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.458    |
| time/               |          |
|    episodes         | 14008    |
|    fps              | 152      |
|    time_elapsed     | 1619     |
|    total_timesteps  | 246292   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00499  |
|    n_updates        | 51572    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00336  |
|    exploration_rate | 0.457    |
| time/               |          |
|    episodes         | 14012    |
|    fps              | 152      |
|    time_elapsed     | 1619     |
|    total_timesteps  | 246370   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00832  |
|    n_updates        | 51592    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00718 |
|    exploration_rate | 0.457    |
| time/               |          |
|    episodes         | 14016    |
|    fps              | 152      |
|    time_elapsed     | 1620     |
|    total_timesteps  | 246444   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 51610    |
----------------------------------
Eval num_timesteps=246500, episode_reward=0.01 +/- 0.34
Episode length: 26.80 +/- 16.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 26.8     |
|    mean_reward      | 0.0138   |
| rollout/            |          |
|    exploration_rate | 0.457    |
| time/               |          |
|    total_timesteps  | 246500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 51624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00706 |
|    exploration_rate | 0.457    |
| time/               |          |
|    episodes         | 14020    |
|    fps              | 151      |
|    time_elapsed     | 1621     |
|    total_timesteps  | 246521   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 51630    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00277  |
|    exploration_rate | 0.457    |
| time/               |          |
|    episodes         | 14024    |
|    fps              | 152      |
|    time_elapsed     | 1622     |
|    total_timesteps  | 246594   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 51648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00297  |
|    exploration_rate | 0.456    |
| time/               |          |
|    episodes         | 14028    |
|    fps              | 152      |
|    time_elapsed     | 1622     |
|    total_timesteps  | 246659   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00258  |
|    n_updates        | 51664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00269  |
|    exploration_rate | 0.456    |
| time/               |          |
|    episodes         | 14032    |
|    fps              | 152      |
|    time_elapsed     | 1622     |
|    total_timesteps  | 246735   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 51683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0076  |
|    exploration_rate | 0.456    |
| time/               |          |
|    episodes         | 14036    |
|    fps              | 152      |
|    time_elapsed     | 1622     |
|    total_timesteps  | 246797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 51699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.00788 |
|    exploration_rate | 0.455    |
| time/               |          |
|    episodes         | 14040    |
|    fps              | 152      |
|    time_elapsed     | 1622     |
|    total_timesteps  | 246872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00225  |
|    n_updates        | 51717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.00796 |
|    exploration_rate | 0.455    |
| time/               |          |
|    episodes         | 14044    |
|    fps              | 152      |
|    time_elapsed     | 1622     |
|    total_timesteps  | 246938   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00238  |
|    n_updates        | 51734    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00251  |
|    exploration_rate | 0.455    |
| time/               |          |
|    episodes         | 14048    |
|    fps              | 152      |
|    time_elapsed     | 1622     |
|    total_timesteps  | 246994   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 51748    |
----------------------------------
Eval num_timesteps=247000, episode_reward=0.05 +/- 0.37
Episode length: 28.06 +/- 15.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28.1     |
|    mean_reward      | 0.0488   |
| rollout/            |          |
|    exploration_rate | 0.455    |
| time/               |          |
|    total_timesteps  | 247000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00244  |
|    n_updates        | 51749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0127   |
|    exploration_rate | 0.455    |
| time/               |          |
|    episodes         | 14052    |
|    fps              | 152      |
|    time_elapsed     | 1624     |
|    total_timesteps  | 247059   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00417  |
|    n_updates        | 51764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00212  |
|    exploration_rate | 0.454    |
| time/               |          |
|    episodes         | 14056    |
|    fps              | 152      |
|    time_elapsed     | 1624     |
|    total_timesteps  | 247137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00213  |
|    n_updates        | 51784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00224  |
|    exploration_rate | 0.454    |
| time/               |          |
|    episodes         | 14060    |
|    fps              | 152      |
|    time_elapsed     | 1624     |
|    total_timesteps  | 247200   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00427  |
|    n_updates        | 51799    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0122   |
|    exploration_rate | 0.454    |
| time/               |          |
|    episodes         | 14064    |
|    fps              | 152      |
|    time_elapsed     | 1625     |
|    total_timesteps  | 247264   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 51815    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.012    |
|    exploration_rate | 0.454    |
| time/               |          |
|    episodes         | 14068    |
|    fps              | 152      |
|    time_elapsed     | 1625     |
|    total_timesteps  | 247331   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000886 |
|    n_updates        | 51832    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00242  |
|    exploration_rate | 0.453    |
| time/               |          |
|    episodes         | 14072    |
|    fps              | 152      |
|    time_elapsed     | 1625     |
|    total_timesteps  | 247393   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0017   |
|    n_updates        | 51848    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00282  |
|    exploration_rate | 0.453    |
| time/               |          |
|    episodes         | 14076    |
|    fps              | 152      |
|    time_elapsed     | 1625     |
|    total_timesteps  | 247463   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00792  |
|    n_updates        | 51865    |
----------------------------------
Eval num_timesteps=247500, episode_reward=-0.00 +/- 0.34
Episode length: 35.62 +/- 20.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 35.6     |
|    mean_reward      | -0.00154 |
| rollout/            |          |
|    exploration_rate | 0.453    |
| time/               |          |
|    total_timesteps  | 247500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 51874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00256  |
|    exploration_rate | 0.453    |
| time/               |          |
|    episodes         | 14080    |
|    fps              | 152      |
|    time_elapsed     | 1628     |
|    total_timesteps  | 247533   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00283  |
|    n_updates        | 51883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0125   |
|    exploration_rate | 0.453    |
| time/               |          |
|    episodes         | 14084    |
|    fps              | 152      |
|    time_elapsed     | 1628     |
|    total_timesteps  | 247602   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00449  |
|    n_updates        | 51900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0126   |
|    exploration_rate | 0.452    |
| time/               |          |
|    episodes         | 14088    |
|    fps              | 152      |
|    time_elapsed     | 1628     |
|    total_timesteps  | 247665   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 51916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0127   |
|    exploration_rate | 0.452    |
| time/               |          |
|    episodes         | 14092    |
|    fps              | 152      |
|    time_elapsed     | 1628     |
|    total_timesteps  | 247737   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 51934    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0124   |
|    exploration_rate | 0.452    |
| time/               |          |
|    episodes         | 14096    |
|    fps              | 152      |
|    time_elapsed     | 1628     |
|    total_timesteps  | 247806   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 51951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0121   |
|    exploration_rate | 0.451    |
| time/               |          |
|    episodes         | 14100    |
|    fps              | 152      |
|    time_elapsed     | 1628     |
|    total_timesteps  | 247886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00218  |
|    n_updates        | 51971    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0224   |
|    exploration_rate | 0.451    |
| time/               |          |
|    episodes         | 14104    |
|    fps              | 152      |
|    time_elapsed     | 1628     |
|    total_timesteps  | 247947   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00544  |
|    n_updates        | 51986    |
----------------------------------
Eval num_timesteps=248000, episode_reward=0.04 +/- 0.34
Episode length: 30.64 +/- 14.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 30.6     |
|    mean_reward      | 0.0385   |
| rollout/            |          |
|    exploration_rate | 0.451    |
| time/               |          |
|    total_timesteps  | 248000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 51999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0119   |
|    exploration_rate | 0.451    |
| time/               |          |
|    episodes         | 14108    |
|    fps              | 152      |
|    time_elapsed     | 1630     |
|    total_timesteps  | 248019   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0031   |
|    n_updates        | 52004    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0227   |
|    exploration_rate | 0.451    |
| time/               |          |
|    episodes         | 14112    |
|    fps              | 152      |
|    time_elapsed     | 1630     |
|    total_timesteps  | 248079   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00281  |
|    n_updates        | 52019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0227   |
|    exploration_rate | 0.45     |
| time/               |          |
|    episodes         | 14116    |
|    fps              | 152      |
|    time_elapsed     | 1630     |
|    total_timesteps  | 248151   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00343  |
|    n_updates        | 52037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0436   |
|    exploration_rate | 0.45     |
| time/               |          |
|    episodes         | 14120    |
|    fps              | 152      |
|    time_elapsed     | 1631     |
|    total_timesteps  | 248207   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 52051    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.034    |
|    exploration_rate | 0.45     |
| time/               |          |
|    episodes         | 14124    |
|    fps              | 152      |
|    time_elapsed     | 1631     |
|    total_timesteps  | 248269   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 52067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0441   |
|    exploration_rate | 0.45     |
| time/               |          |
|    episodes         | 14128    |
|    fps              | 152      |
|    time_elapsed     | 1631     |
|    total_timesteps  | 248333   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 52083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0548   |
|    exploration_rate | 0.449    |
| time/               |          |
|    episodes         | 14132    |
|    fps              | 152      |
|    time_elapsed     | 1631     |
|    total_timesteps  | 248392   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00333  |
|    n_updates        | 52097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0545   |
|    exploration_rate | 0.449    |
| time/               |          |
|    episodes         | 14136    |
|    fps              | 152      |
|    time_elapsed     | 1631     |
|    total_timesteps  | 248461   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00274  |
|    n_updates        | 52115    |
----------------------------------
Eval num_timesteps=248500, episode_reward=-0.04 +/- 0.30
Episode length: 34.50 +/- 16.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.5     |
|    mean_reward      | -0.037   |
| rollout/            |          |
|    exploration_rate | 0.449    |
| time/               |          |
|    total_timesteps  | 248500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00816  |
|    n_updates        | 52124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0547   |
|    exploration_rate | 0.449    |
| time/               |          |
|    episodes         | 14140    |
|    fps              | 152      |
|    time_elapsed     | 1634     |
|    total_timesteps  | 248532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 52132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0542   |
|    exploration_rate | 0.449    |
| time/               |          |
|    episodes         | 14144    |
|    fps              | 152      |
|    time_elapsed     | 1634     |
|    total_timesteps  | 248609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000593 |
|    n_updates        | 52152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0435   |
|    exploration_rate | 0.448    |
| time/               |          |
|    episodes         | 14148    |
|    fps              | 152      |
|    time_elapsed     | 1634     |
|    total_timesteps  | 248683   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00243  |
|    n_updates        | 52170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0335   |
|    exploration_rate | 0.448    |
| time/               |          |
|    episodes         | 14152    |
|    fps              | 152      |
|    time_elapsed     | 1634     |
|    total_timesteps  | 248748   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 52186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0335   |
|    exploration_rate | 0.448    |
| time/               |          |
|    episodes         | 14156    |
|    fps              | 152      |
|    time_elapsed     | 1634     |
|    total_timesteps  | 248826   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 52206    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0333   |
|    exploration_rate | 0.447    |
| time/               |          |
|    episodes         | 14160    |
|    fps              | 152      |
|    time_elapsed     | 1634     |
|    total_timesteps  | 248894   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00258  |
|    n_updates        | 52223    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0334   |
|    exploration_rate | 0.447    |
| time/               |          |
|    episodes         | 14164    |
|    fps              | 152      |
|    time_elapsed     | 1634     |
|    total_timesteps  | 248955   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 52238    |
----------------------------------
Eval num_timesteps=249000, episode_reward=-0.08 +/- 0.24
Episode length: 35.26 +/- 17.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 35.3     |
|    mean_reward      | -0.08    |
| rollout/            |          |
|    exploration_rate | 0.447    |
| time/               |          |
|    total_timesteps  | 249000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00213  |
|    n_updates        | 52249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0333   |
|    exploration_rate | 0.447    |
| time/               |          |
|    episodes         | 14168    |
|    fps              | 152      |
|    time_elapsed     | 1637     |
|    total_timesteps  | 249026   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000798 |
|    n_updates        | 52256    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0332   |
|    exploration_rate | 0.447    |
| time/               |          |
|    episodes         | 14172    |
|    fps              | 152      |
|    time_elapsed     | 1637     |
|    total_timesteps  | 249090   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 52272    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0332   |
|    exploration_rate | 0.446    |
| time/               |          |
|    episodes         | 14176    |
|    fps              | 152      |
|    time_elapsed     | 1637     |
|    total_timesteps  | 249159   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000889 |
|    n_updates        | 52289    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0233   |
|    exploration_rate | 0.446    |
| time/               |          |
|    episodes         | 14180    |
|    fps              | 152      |
|    time_elapsed     | 1637     |
|    total_timesteps  | 249227   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00403  |
|    n_updates        | 52306    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0133   |
|    exploration_rate | 0.446    |
| time/               |          |
|    episodes         | 14184    |
|    fps              | 152      |
|    time_elapsed     | 1637     |
|    total_timesteps  | 249295   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00569  |
|    n_updates        | 52323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0127   |
|    exploration_rate | 0.446    |
| time/               |          |
|    episodes         | 14188    |
|    fps              | 152      |
|    time_elapsed     | 1637     |
|    total_timesteps  | 249372   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 52342    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0125   |
|    exploration_rate | 0.445    |
| time/               |          |
|    episodes         | 14192    |
|    fps              | 152      |
|    time_elapsed     | 1637     |
|    total_timesteps  | 249451   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 52362    |
----------------------------------
Eval num_timesteps=249500, episode_reward=0.01 +/- 0.33
Episode length: 28.52 +/- 17.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28.5     |
|    mean_reward      | 0.007    |
| rollout/            |          |
|    exploration_rate | 0.445    |
| time/               |          |
|    total_timesteps  | 249500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00315  |
|    n_updates        | 52374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0124   |
|    exploration_rate | 0.445    |
| time/               |          |
|    episodes         | 14196    |
|    fps              | 152      |
|    time_elapsed     | 1639     |
|    total_timesteps  | 249522   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 52380    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0123   |
|    exploration_rate | 0.445    |
| time/               |          |
|    episodes         | 14200    |
|    fps              | 152      |
|    time_elapsed     | 1640     |
|    total_timesteps  | 249604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00354  |
|    n_updates        | 52400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00191  |
|    exploration_rate | 0.444    |
| time/               |          |
|    episodes         | 14204    |
|    fps              | 152      |
|    time_elapsed     | 1640     |
|    total_timesteps  | 249675   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 52418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00223  |
|    exploration_rate | 0.444    |
| time/               |          |
|    episodes         | 14208    |
|    fps              | 152      |
|    time_elapsed     | 1640     |
|    total_timesteps  | 249739   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00288  |
|    n_updates        | 52434    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00809 |
|    exploration_rate | 0.444    |
| time/               |          |
|    episodes         | 14212    |
|    fps              | 152      |
|    time_elapsed     | 1640     |
|    total_timesteps  | 249807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00259  |
|    n_updates        | 52451    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.00781 |
|    exploration_rate | 0.444    |
| time/               |          |
|    episodes         | 14216    |
|    fps              | 152      |
|    time_elapsed     | 1640     |
|    total_timesteps  | 249872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00318  |
|    n_updates        | 52467    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0181  |
|    exploration_rate | 0.443    |
| time/               |          |
|    episodes         | 14220    |
|    fps              | 152      |
|    time_elapsed     | 1640     |
|    total_timesteps  | 249937   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00252  |
|    n_updates        | 52484    |
----------------------------------
Eval num_timesteps=250000, episode_reward=-0.08 +/- 0.04
Episode length: 19.26 +/- 11.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.3     |
|    mean_reward      | -0.076   |
| rollout/            |          |
|    exploration_rate | 0.443    |
| time/               |          |
|    total_timesteps  | 250000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 52499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0184  |
|    exploration_rate | 0.443    |
| time/               |          |
|    episodes         | 14224    |
|    fps              | 152      |
|    time_elapsed     | 1641     |
|    total_timesteps  | 250005   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00267  |
|    n_updates        | 52501    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0284  |
|    exploration_rate | 0.443    |
| time/               |          |
|    episodes         | 14228    |
|    fps              | 152      |
|    time_elapsed     | 1641     |
|    total_timesteps  | 250068   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 52516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0386  |
|    exploration_rate | 0.442    |
| time/               |          |
|    episodes         | 14232    |
|    fps              | 152      |
|    time_elapsed     | 1641     |
|    total_timesteps  | 250132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 52532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0485  |
|    exploration_rate | 0.442    |
| time/               |          |
|    episodes         | 14236    |
|    fps              | 152      |
|    time_elapsed     | 1641     |
|    total_timesteps  | 250198   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 52549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0485  |
|    exploration_rate | 0.442    |
| time/               |          |
|    episodes         | 14240    |
|    fps              | 152      |
|    time_elapsed     | 1642     |
|    total_timesteps  | 250269   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 52567    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0483  |
|    exploration_rate | 0.442    |
| time/               |          |
|    episodes         | 14244    |
|    fps              | 152      |
|    time_elapsed     | 1642     |
|    total_timesteps  | 250341   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00307  |
|    n_updates        | 52585    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0479  |
|    exploration_rate | 0.441    |
| time/               |          |
|    episodes         | 14248    |
|    fps              | 152      |
|    time_elapsed     | 1642     |
|    total_timesteps  | 250407   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 52601    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0379  |
|    exploration_rate | 0.441    |
| time/               |          |
|    episodes         | 14252    |
|    fps              | 152      |
|    time_elapsed     | 1642     |
|    total_timesteps  | 250470   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 52617    |
----------------------------------
Eval num_timesteps=250500, episode_reward=-0.09 +/- 0.24
Episode length: 36.80 +/- 16.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36.8     |
|    mean_reward      | -0.0861  |
| rollout/            |          |
|    exploration_rate | 0.441    |
| time/               |          |
|    total_timesteps  | 250500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00275  |
|    n_updates        | 52624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0378  |
|    exploration_rate | 0.441    |
| time/               |          |
|    episodes         | 14256    |
|    fps              | 152      |
|    time_elapsed     | 1644     |
|    total_timesteps  | 250545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00253  |
|    n_updates        | 52636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0374  |
|    exploration_rate | 0.441    |
| time/               |          |
|    episodes         | 14260    |
|    fps              | 152      |
|    time_elapsed     | 1644     |
|    total_timesteps  | 250605   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000912 |
|    n_updates        | 52651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0273  |
|    exploration_rate | 0.44     |
| time/               |          |
|    episodes         | 14264    |
|    fps              | 152      |
|    time_elapsed     | 1644     |
|    total_timesteps  | 250664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00439  |
|    n_updates        | 52665    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.44     |
| time/               |          |
|    episodes         | 14268    |
|    fps              | 152      |
|    time_elapsed     | 1645     |
|    total_timesteps  | 250727   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0024   |
|    n_updates        | 52681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0271  |
|    exploration_rate | 0.44     |
| time/               |          |
|    episodes         | 14272    |
|    fps              | 152      |
|    time_elapsed     | 1645     |
|    total_timesteps  | 250792   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 52697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00714 |
|    exploration_rate | 0.44     |
| time/               |          |
|    episodes         | 14276    |
|    fps              | 152      |
|    time_elapsed     | 1645     |
|    total_timesteps  | 250863   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 52715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00714 |
|    exploration_rate | 0.439    |
| time/               |          |
|    episodes         | 14280    |
|    fps              | 152      |
|    time_elapsed     | 1645     |
|    total_timesteps  | 250931   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 52732    |
----------------------------------
Eval num_timesteps=251000, episode_reward=-0.02 +/- 0.32
Episode length: 30.64 +/- 18.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 30.6     |
|    mean_reward      | -0.0216  |
| rollout/            |          |
|    exploration_rate | 0.439    |
| time/               |          |
|    total_timesteps  | 251000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000947 |
|    n_updates        | 52749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00754 |
|    exploration_rate | 0.439    |
| time/               |          |
|    episodes         | 14284    |
|    fps              | 152      |
|    time_elapsed     | 1647     |
|    total_timesteps  | 251009   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000913 |
|    n_updates        | 52752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00274  |
|    exploration_rate | 0.439    |
| time/               |          |
|    episodes         | 14288    |
|    fps              | 152      |
|    time_elapsed     | 1647     |
|    total_timesteps  | 251079   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000558 |
|    n_updates        | 52769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00334  |
|    exploration_rate | 0.438    |
| time/               |          |
|    episodes         | 14292    |
|    fps              | 152      |
|    time_elapsed     | 1647     |
|    total_timesteps  | 251143   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 52785    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0136   |
|    exploration_rate | 0.438    |
| time/               |          |
|    episodes         | 14296    |
|    fps              | 152      |
|    time_elapsed     | 1647     |
|    total_timesteps  | 251208   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 52801    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0244   |
|    exploration_rate | 0.438    |
| time/               |          |
|    episodes         | 14300    |
|    fps              | 152      |
|    time_elapsed     | 1647     |
|    total_timesteps  | 251269   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00551  |
|    n_updates        | 52817    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0247   |
|    exploration_rate | 0.438    |
| time/               |          |
|    episodes         | 14304    |
|    fps              | 152      |
|    time_elapsed     | 1647     |
|    total_timesteps  | 251334   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00439  |
|    n_updates        | 52833    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0246   |
|    exploration_rate | 0.437    |
| time/               |          |
|    episodes         | 14308    |
|    fps              | 152      |
|    time_elapsed     | 1648     |
|    total_timesteps  | 251399   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 52849    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0247   |
|    exploration_rate | 0.437    |
| time/               |          |
|    episodes         | 14312    |
|    fps              | 152      |
|    time_elapsed     | 1648     |
|    total_timesteps  | 251466   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 52866    |
----------------------------------
Eval num_timesteps=251500, episode_reward=-0.09 +/- 0.17
Episode length: 27.60 +/- 17.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 27.6     |
|    mean_reward      | -0.0894  |
| rollout/            |          |
|    exploration_rate | 0.437    |
| time/               |          |
|    total_timesteps  | 251500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 52874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0248   |
|    exploration_rate | 0.437    |
| time/               |          |
|    episodes         | 14316    |
|    fps              | 152      |
|    time_elapsed     | 1649     |
|    total_timesteps  | 251529   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00245  |
|    n_updates        | 52882    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0149   |
|    exploration_rate | 0.437    |
| time/               |          |
|    episodes         | 14320    |
|    fps              | 152      |
|    time_elapsed     | 1650     |
|    total_timesteps  | 251590   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 52897    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0152   |
|    exploration_rate | 0.436    |
| time/               |          |
|    episodes         | 14324    |
|    fps              | 152      |
|    time_elapsed     | 1650     |
|    total_timesteps  | 251652   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00247  |
|    n_updates        | 52912    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.436    |
| time/               |          |
|    episodes         | 14328    |
|    fps              | 152      |
|    time_elapsed     | 1650     |
|    total_timesteps  | 251711   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000774 |
|    n_updates        | 52927    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0355   |
|    exploration_rate | 0.436    |
| time/               |          |
|    episodes         | 14332    |
|    fps              | 152      |
|    time_elapsed     | 1650     |
|    total_timesteps  | 251771   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00279  |
|    n_updates        | 52942    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0458   |
|    exploration_rate | 0.436    |
| time/               |          |
|    episodes         | 14336    |
|    fps              | 152      |
|    time_elapsed     | 1650     |
|    total_timesteps  | 251829   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00411  |
|    n_updates        | 52957    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0461   |
|    exploration_rate | 0.435    |
| time/               |          |
|    episodes         | 14340    |
|    fps              | 152      |
|    time_elapsed     | 1650     |
|    total_timesteps  | 251893   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 52973    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0566   |
|    exploration_rate | 0.435    |
| time/               |          |
|    episodes         | 14344    |
|    fps              | 152      |
|    time_elapsed     | 1650     |
|    total_timesteps  | 251953   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00255  |
|    n_updates        | 52988    |
----------------------------------
Eval num_timesteps=252000, episode_reward=0.03 +/- 0.30
Episode length: 16.76 +/- 4.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.8     |
|    mean_reward      | 0.034    |
| rollout/            |          |
|    exploration_rate | 0.435    |
| time/               |          |
|    total_timesteps  | 252000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00325  |
|    n_updates        | 52999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0564   |
|    exploration_rate | 0.435    |
| time/               |          |
|    episodes         | 14348    |
|    fps              | 152      |
|    time_elapsed     | 1651     |
|    total_timesteps  | 252023   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 53005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0464   |
|    exploration_rate | 0.435    |
| time/               |          |
|    episodes         | 14352    |
|    fps              | 152      |
|    time_elapsed     | 1651     |
|    total_timesteps  | 252086   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00252  |
|    n_updates        | 53021    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0569   |
|    exploration_rate | 0.434    |
| time/               |          |
|    episodes         | 14356    |
|    fps              | 152      |
|    time_elapsed     | 1652     |
|    total_timesteps  | 252148   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00617  |
|    n_updates        | 53036    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0668   |
|    exploration_rate | 0.434    |
| time/               |          |
|    episodes         | 14360    |
|    fps              | 152      |
|    time_elapsed     | 1652     |
|    total_timesteps  | 252211   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000918 |
|    n_updates        | 53052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0467   |
|    exploration_rate | 0.434    |
| time/               |          |
|    episodes         | 14364    |
|    fps              | 152      |
|    time_elapsed     | 1652     |
|    total_timesteps  | 252272   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 53067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0569   |
|    exploration_rate | 0.434    |
| time/               |          |
|    episodes         | 14368    |
|    fps              | 152      |
|    time_elapsed     | 1652     |
|    total_timesteps  | 252332   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00285  |
|    n_updates        | 53082    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0568   |
|    exploration_rate | 0.433    |
| time/               |          |
|    episodes         | 14372    |
|    fps              | 152      |
|    time_elapsed     | 1652     |
|    total_timesteps  | 252399   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00363  |
|    n_updates        | 53099    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0369   |
|    exploration_rate | 0.433    |
| time/               |          |
|    episodes         | 14376    |
|    fps              | 152      |
|    time_elapsed     | 1652     |
|    total_timesteps  | 252466   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00617  |
|    n_updates        | 53116    |
----------------------------------
Eval num_timesteps=252500, episode_reward=-0.02 +/- 0.25
Episode length: 19.74 +/- 13.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.7     |
|    mean_reward      | -0.018   |
| rollout/            |          |
|    exploration_rate | 0.433    |
| time/               |          |
|    total_timesteps  | 252500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00302  |
|    n_updates        | 53124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0372   |
|    exploration_rate | 0.433    |
| time/               |          |
|    episodes         | 14380    |
|    fps              | 152      |
|    time_elapsed     | 1653     |
|    total_timesteps  | 252527   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000872 |
|    n_updates        | 53131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.433    |
| time/               |          |
|    episodes         | 14384    |
|    fps              | 152      |
|    time_elapsed     | 1653     |
|    total_timesteps  | 252592   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 53147    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.432    |
| time/               |          |
|    episodes         | 14388    |
|    fps              | 152      |
|    time_elapsed     | 1654     |
|    total_timesteps  | 252650   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000996 |
|    n_updates        | 53162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 0.432    |
| time/               |          |
|    episodes         | 14392    |
|    fps              | 152      |
|    time_elapsed     | 1654     |
|    total_timesteps  | 252718   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000969 |
|    n_updates        | 53179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0381   |
|    exploration_rate | 0.432    |
| time/               |          |
|    episodes         | 14396    |
|    fps              | 152      |
|    time_elapsed     | 1654     |
|    total_timesteps  | 252782   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00973  |
|    n_updates        | 53195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 0.432    |
| time/               |          |
|    episodes         | 14400    |
|    fps              | 152      |
|    time_elapsed     | 1654     |
|    total_timesteps  | 252849   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00848  |
|    n_updates        | 53212    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.431    |
| time/               |          |
|    episodes         | 14404    |
|    fps              | 152      |
|    time_elapsed     | 1654     |
|    total_timesteps  | 252920   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 53229    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.431    |
| time/               |          |
|    episodes         | 14408    |
|    fps              | 152      |
|    time_elapsed     | 1654     |
|    total_timesteps  | 252989   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 53247    |
----------------------------------
Eval num_timesteps=253000, episode_reward=0.02 +/- 0.28
Episode length: 16.04 +/- 7.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.0169   |
| rollout/            |          |
|    exploration_rate | 0.431    |
| time/               |          |
|    total_timesteps  | 253000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 53249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.431    |
| time/               |          |
|    episodes         | 14412    |
|    fps              | 152      |
|    time_elapsed     | 1655     |
|    total_timesteps  | 253047   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00298  |
|    n_updates        | 53261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.431    |
| time/               |          |
|    episodes         | 14416    |
|    fps              | 152      |
|    time_elapsed     | 1655     |
|    total_timesteps  | 253110   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 53277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 0.43     |
| time/               |          |
|    episodes         | 14420    |
|    fps              | 152      |
|    time_elapsed     | 1656     |
|    total_timesteps  | 253174   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00269  |
|    n_updates        | 53293    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0477   |
|    exploration_rate | 0.43     |
| time/               |          |
|    episodes         | 14424    |
|    fps              | 152      |
|    time_elapsed     | 1656     |
|    total_timesteps  | 253235   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0032   |
|    n_updates        | 53308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 0.43     |
| time/               |          |
|    episodes         | 14428    |
|    fps              | 152      |
|    time_elapsed     | 1656     |
|    total_timesteps  | 253297   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 53324    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0375   |
|    exploration_rate | 0.43     |
| time/               |          |
|    episodes         | 14432    |
|    fps              | 152      |
|    time_elapsed     | 1656     |
|    total_timesteps  | 253358   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00241  |
|    n_updates        | 53339    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0267   |
|    exploration_rate | 0.429    |
| time/               |          |
|    episodes         | 14436    |
|    fps              | 152      |
|    time_elapsed     | 1656     |
|    total_timesteps  | 253436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00526  |
|    n_updates        | 53358    |
----------------------------------
Eval num_timesteps=253500, episode_reward=0.06 +/- 0.33
Episode length: 14.70 +/- 1.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0622   |
| rollout/            |          |
|    exploration_rate | 0.429    |
| time/               |          |
|    total_timesteps  | 253500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00207  |
|    n_updates        | 53374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0265   |
|    exploration_rate | 0.429    |
| time/               |          |
|    episodes         | 14440    |
|    fps              | 152      |
|    time_elapsed     | 1657     |
|    total_timesteps  | 253505   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00254  |
|    n_updates        | 53376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0266   |
|    exploration_rate | 0.429    |
| time/               |          |
|    episodes         | 14444    |
|    fps              | 152      |
|    time_elapsed     | 1657     |
|    total_timesteps  | 253564   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 53390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.429    |
| time/               |          |
|    episodes         | 14448    |
|    fps              | 152      |
|    time_elapsed     | 1657     |
|    total_timesteps  | 253626   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 53406    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.428    |
| time/               |          |
|    episodes         | 14452    |
|    fps              | 153      |
|    time_elapsed     | 1657     |
|    total_timesteps  | 253688   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 53421    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.428    |
| time/               |          |
|    episodes         | 14456    |
|    fps              | 153      |
|    time_elapsed     | 1658     |
|    total_timesteps  | 253752   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 53437    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00687  |
|    exploration_rate | 0.428    |
| time/               |          |
|    episodes         | 14460    |
|    fps              | 153      |
|    time_elapsed     | 1658     |
|    total_timesteps  | 253814   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 53453    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00651  |
|    exploration_rate | 0.427    |
| time/               |          |
|    episodes         | 14464    |
|    fps              | 153      |
|    time_elapsed     | 1658     |
|    total_timesteps  | 253884   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 53470    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00357 |
|    exploration_rate | 0.427    |
| time/               |          |
|    episodes         | 14468    |
|    fps              | 153      |
|    time_elapsed     | 1658     |
|    total_timesteps  | 253946   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 53486    |
----------------------------------
Eval num_timesteps=254000, episode_reward=0.01 +/- 0.28
Episode length: 17.30 +/- 10.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.3     |
|    mean_reward      | 0.0119   |
| rollout/            |          |
|    exploration_rate | 0.427    |
| time/               |          |
|    total_timesteps  | 254000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00259  |
|    n_updates        | 53499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00329 |
|    exploration_rate | 0.427    |
| time/               |          |
|    episodes         | 14472    |
|    fps              | 153      |
|    time_elapsed     | 1659     |
|    total_timesteps  | 254006   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 53501    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00325 |
|    exploration_rate | 0.427    |
| time/               |          |
|    episodes         | 14476    |
|    fps              | 153      |
|    time_elapsed     | 1659     |
|    total_timesteps  | 254072   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 53517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00373 |
|    exploration_rate | 0.426    |
| time/               |          |
|    episodes         | 14480    |
|    fps              | 153      |
|    time_elapsed     | 1660     |
|    total_timesteps  | 254145   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 53536    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00357 |
|    exploration_rate | 0.426    |
| time/               |          |
|    episodes         | 14484    |
|    fps              | 153      |
|    time_elapsed     | 1660     |
|    total_timesteps  | 254206   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00582  |
|    n_updates        | 53551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.426    |
| time/               |          |
|    episodes         | 14488    |
|    fps              | 153      |
|    time_elapsed     | 1660     |
|    total_timesteps  | 254267   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 53566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.426    |
| time/               |          |
|    episodes         | 14492    |
|    fps              | 153      |
|    time_elapsed     | 1660     |
|    total_timesteps  | 254328   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 53581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.425    |
| time/               |          |
|    episodes         | 14496    |
|    fps              | 153      |
|    time_elapsed     | 1660     |
|    total_timesteps  | 254394   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 53598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.425    |
| time/               |          |
|    episodes         | 14500    |
|    fps              | 153      |
|    time_elapsed     | 1660     |
|    total_timesteps  | 254459   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 53614    |
----------------------------------
Eval num_timesteps=254500, episode_reward=0.02 +/- 0.28
Episode length: 14.86 +/- 1.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.0216   |
| rollout/            |          |
|    exploration_rate | 0.425    |
| time/               |          |
|    total_timesteps  | 254500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 53624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.425    |
| time/               |          |
|    episodes         | 14504    |
|    fps              | 153      |
|    time_elapsed     | 1661     |
|    total_timesteps  | 254523   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000771 |
|    n_updates        | 53630    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.425    |
| time/               |          |
|    episodes         | 14508    |
|    fps              | 153      |
|    time_elapsed     | 1662     |
|    total_timesteps  | 254594   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 53648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.424    |
| time/               |          |
|    episodes         | 14512    |
|    fps              | 153      |
|    time_elapsed     | 1662     |
|    total_timesteps  | 254660   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00276  |
|    n_updates        | 53664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.424    |
| time/               |          |
|    episodes         | 14516    |
|    fps              | 153      |
|    time_elapsed     | 1662     |
|    total_timesteps  | 254723   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00264  |
|    n_updates        | 53680    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.424    |
| time/               |          |
|    episodes         | 14520    |
|    fps              | 153      |
|    time_elapsed     | 1662     |
|    total_timesteps  | 254784   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 53695    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.424    |
| time/               |          |
|    episodes         | 14524    |
|    fps              | 153      |
|    time_elapsed     | 1662     |
|    total_timesteps  | 254845   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 53711    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.423    |
| time/               |          |
|    episodes         | 14528    |
|    fps              | 153      |
|    time_elapsed     | 1662     |
|    total_timesteps  | 254907   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 53726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.423    |
| time/               |          |
|    episodes         | 14532    |
|    fps              | 153      |
|    time_elapsed     | 1662     |
|    total_timesteps  | 254970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 53742    |
----------------------------------
Eval num_timesteps=255000, episode_reward=0.02 +/- 0.28
Episode length: 14.68 +/- 1.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0223   |
| rollout/            |          |
|    exploration_rate | 0.423    |
| time/               |          |
|    total_timesteps  | 255000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00227  |
|    n_updates        | 53749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0329  |
|    exploration_rate | 0.423    |
| time/               |          |
|    episodes         | 14536    |
|    fps              | 153      |
|    time_elapsed     | 1663     |
|    total_timesteps  | 255033   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 53758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.423    |
| time/               |          |
|    episodes         | 14540    |
|    fps              | 153      |
|    time_elapsed     | 1663     |
|    total_timesteps  | 255103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 53775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.422    |
| time/               |          |
|    episodes         | 14544    |
|    fps              | 153      |
|    time_elapsed     | 1664     |
|    total_timesteps  | 255168   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00325  |
|    n_updates        | 53791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.422    |
| time/               |          |
|    episodes         | 14548    |
|    fps              | 153      |
|    time_elapsed     | 1664     |
|    total_timesteps  | 255233   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00297  |
|    n_updates        | 53808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.422    |
| time/               |          |
|    episodes         | 14552    |
|    fps              | 153      |
|    time_elapsed     | 1664     |
|    total_timesteps  | 255299   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 53824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.422    |
| time/               |          |
|    episodes         | 14556    |
|    fps              | 153      |
|    time_elapsed     | 1664     |
|    total_timesteps  | 255362   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 53840    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0236  |
|    exploration_rate | 0.421    |
| time/               |          |
|    episodes         | 14560    |
|    fps              | 153      |
|    time_elapsed     | 1664     |
|    total_timesteps  | 255430   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00302  |
|    n_updates        | 53857    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.421    |
| time/               |          |
|    episodes         | 14564    |
|    fps              | 153      |
|    time_elapsed     | 1664     |
|    total_timesteps  | 255496   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00251  |
|    n_updates        | 53873    |
----------------------------------
Eval num_timesteps=255500, episode_reward=0.00 +/- 0.24
Episode length: 14.90 +/- 0.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.0014   |
| rollout/            |          |
|    exploration_rate | 0.421    |
| time/               |          |
|    total_timesteps  | 255500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 53874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.421    |
| time/               |          |
|    episodes         | 14568    |
|    fps              | 153      |
|    time_elapsed     | 1665     |
|    total_timesteps  | 255557   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 53889    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.42     |
| time/               |          |
|    episodes         | 14572    |
|    fps              | 153      |
|    time_elapsed     | 1665     |
|    total_timesteps  | 255619   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00203  |
|    n_updates        | 53904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.42     |
| time/               |          |
|    episodes         | 14576    |
|    fps              | 153      |
|    time_elapsed     | 1665     |
|    total_timesteps  | 255680   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00892  |
|    n_updates        | 53919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.42     |
| time/               |          |
|    episodes         | 14580    |
|    fps              | 153      |
|    time_elapsed     | 1666     |
|    total_timesteps  | 255746   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 53936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.42     |
| time/               |          |
|    episodes         | 14584    |
|    fps              | 153      |
|    time_elapsed     | 1666     |
|    total_timesteps  | 255807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 53951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.419    |
| time/               |          |
|    episodes         | 14588    |
|    fps              | 153      |
|    time_elapsed     | 1666     |
|    total_timesteps  | 255879   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 53969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.419    |
| time/               |          |
|    episodes         | 14592    |
|    fps              | 153      |
|    time_elapsed     | 1666     |
|    total_timesteps  | 255940   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 53984    |
----------------------------------
Eval num_timesteps=256000, episode_reward=0.00 +/- 0.24
Episode length: 14.90 +/- 1.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.00142  |
| rollout/            |          |
|    exploration_rate | 0.419    |
| time/               |          |
|    total_timesteps  | 256000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 53999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.419    |
| time/               |          |
|    episodes         | 14596    |
|    fps              | 153      |
|    time_elapsed     | 1667     |
|    total_timesteps  | 256002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 54000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00307 |
|    exploration_rate | 0.419    |
| time/               |          |
|    episodes         | 14600    |
|    fps              | 153      |
|    time_elapsed     | 1667     |
|    total_timesteps  | 256062   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00288  |
|    n_updates        | 54015    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0072   |
|    exploration_rate | 0.418    |
| time/               |          |
|    episodes         | 14604    |
|    fps              | 153      |
|    time_elapsed     | 1667     |
|    total_timesteps  | 256119   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 54029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00271 |
|    exploration_rate | 0.418    |
| time/               |          |
|    episodes         | 14608    |
|    fps              | 153      |
|    time_elapsed     | 1667     |
|    total_timesteps  | 256188   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0032   |
|    n_updates        | 54046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00727  |
|    exploration_rate | 0.418    |
| time/               |          |
|    episodes         | 14612    |
|    fps              | 153      |
|    time_elapsed     | 1667     |
|    total_timesteps  | 256255   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00232  |
|    n_updates        | 54063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.418    |
| time/               |          |
|    episodes         | 14616    |
|    fps              | 153      |
|    time_elapsed     | 1667     |
|    total_timesteps  | 256312   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00457  |
|    n_updates        | 54077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.417    |
| time/               |          |
|    episodes         | 14620    |
|    fps              | 153      |
|    time_elapsed     | 1667     |
|    total_timesteps  | 256374   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 54093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00742  |
|    exploration_rate | 0.417    |
| time/               |          |
|    episodes         | 14624    |
|    fps              | 153      |
|    time_elapsed     | 1668     |
|    total_timesteps  | 256436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 54108    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.417    |
| time/               |          |
|    episodes         | 14628    |
|    fps              | 153      |
|    time_elapsed     | 1668     |
|    total_timesteps  | 256492   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 54122    |
----------------------------------
Eval num_timesteps=256500, episode_reward=0.00 +/- 0.24
Episode length: 15.22 +/- 2.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | 0.00018  |
| rollout/            |          |
|    exploration_rate | 0.417    |
| time/               |          |
|    total_timesteps  | 256500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0024   |
|    n_updates        | 54124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.417    |
| time/               |          |
|    episodes         | 14632    |
|    fps              | 153      |
|    time_elapsed     | 1669     |
|    total_timesteps  | 256553   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 54138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.416    |
| time/               |          |
|    episodes         | 14636    |
|    fps              | 153      |
|    time_elapsed     | 1669     |
|    total_timesteps  | 256616   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00087  |
|    n_updates        | 54153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.416    |
| time/               |          |
|    episodes         | 14640    |
|    fps              | 153      |
|    time_elapsed     | 1669     |
|    total_timesteps  | 256679   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 54169    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00816  |
|    exploration_rate | 0.416    |
| time/               |          |
|    episodes         | 14644    |
|    fps              | 153      |
|    time_elapsed     | 1669     |
|    total_timesteps  | 256740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000988 |
|    n_updates        | 54184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00836  |
|    exploration_rate | 0.416    |
| time/               |          |
|    episodes         | 14648    |
|    fps              | 153      |
|    time_elapsed     | 1669     |
|    total_timesteps  | 256800   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00273  |
|    n_updates        | 54199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00844  |
|    exploration_rate | 0.415    |
| time/               |          |
|    episodes         | 14652    |
|    fps              | 153      |
|    time_elapsed     | 1669     |
|    total_timesteps  | 256864   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 54215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.415    |
| time/               |          |
|    episodes         | 14656    |
|    fps              | 153      |
|    time_elapsed     | 1669     |
|    total_timesteps  | 256920   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00308  |
|    n_updates        | 54229    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0291   |
|    exploration_rate | 0.415    |
| time/               |          |
|    episodes         | 14660    |
|    fps              | 153      |
|    time_elapsed     | 1670     |
|    total_timesteps  | 256978   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00495  |
|    n_updates        | 54244    |
----------------------------------
Eval num_timesteps=257000, episode_reward=-0.02 +/- 0.20
Episode length: 16.18 +/- 8.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.2     |
|    mean_reward      | -0.0237  |
| rollout/            |          |
|    exploration_rate | 0.415    |
| time/               |          |
|    total_timesteps  | 257000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 54249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.415    |
| time/               |          |
|    episodes         | 14664    |
|    fps              | 153      |
|    time_elapsed     | 1671     |
|    total_timesteps  | 257039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 54259    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0392   |
|    exploration_rate | 0.415    |
| time/               |          |
|    episodes         | 14668    |
|    fps              | 153      |
|    time_elapsed     | 1671     |
|    total_timesteps  | 257104   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00336  |
|    n_updates        | 54275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0392   |
|    exploration_rate | 0.414    |
| time/               |          |
|    episodes         | 14672    |
|    fps              | 153      |
|    time_elapsed     | 1671     |
|    total_timesteps  | 257164   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00728  |
|    n_updates        | 54290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 0.414    |
| time/               |          |
|    episodes         | 14676    |
|    fps              | 153      |
|    time_elapsed     | 1671     |
|    total_timesteps  | 257227   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00228  |
|    n_updates        | 54306    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 0.414    |
| time/               |          |
|    episodes         | 14680    |
|    fps              | 153      |
|    time_elapsed     | 1671     |
|    total_timesteps  | 257292   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 54322    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 0.413    |
| time/               |          |
|    episodes         | 14684    |
|    fps              | 153      |
|    time_elapsed     | 1671     |
|    total_timesteps  | 257353   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 54338    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0295   |
|    exploration_rate | 0.413    |
| time/               |          |
|    episodes         | 14688    |
|    fps              | 153      |
|    time_elapsed     | 1671     |
|    total_timesteps  | 257419   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 54354    |
----------------------------------
Eval num_timesteps=257500, episode_reward=0.00 +/- 0.24
Episode length: 14.80 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00182  |
| rollout/            |          |
|    exploration_rate | 0.413    |
| time/               |          |
|    total_timesteps  | 257500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00307  |
|    n_updates        | 54374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0286   |
|    exploration_rate | 0.413    |
| time/               |          |
|    episodes         | 14692    |
|    fps              | 153      |
|    time_elapsed     | 1672     |
|    total_timesteps  | 257501   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00423  |
|    n_updates        | 54375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0286   |
|    exploration_rate | 0.413    |
| time/               |          |
|    episodes         | 14696    |
|    fps              | 153      |
|    time_elapsed     | 1673     |
|    total_timesteps  | 257562   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000942 |
|    n_updates        | 54390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0288   |
|    exploration_rate | 0.412    |
| time/               |          |
|    episodes         | 14700    |
|    fps              | 153      |
|    time_elapsed     | 1673     |
|    total_timesteps  | 257617   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 54404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.412    |
| time/               |          |
|    episodes         | 14704    |
|    fps              | 153      |
|    time_elapsed     | 1673     |
|    total_timesteps  | 257671   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 54417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0393   |
|    exploration_rate | 0.412    |
| time/               |          |
|    episodes         | 14708    |
|    fps              | 154      |
|    time_elapsed     | 1673     |
|    total_timesteps  | 257731   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000974 |
|    n_updates        | 54432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 0.412    |
| time/               |          |
|    episodes         | 14712    |
|    fps              | 154      |
|    time_elapsed     | 1673     |
|    total_timesteps  | 257801   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 54450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.411    |
| time/               |          |
|    episodes         | 14716    |
|    fps              | 154      |
|    time_elapsed     | 1673     |
|    total_timesteps  | 257867   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 54466    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.411    |
| time/               |          |
|    episodes         | 14720    |
|    fps              | 154      |
|    time_elapsed     | 1673     |
|    total_timesteps  | 257941   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 54485    |
----------------------------------
Eval num_timesteps=258000, episode_reward=0.06 +/- 0.33
Episode length: 15.00 +/- 2.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | 0.0611   |
| rollout/            |          |
|    exploration_rate | 0.411    |
| time/               |          |
|    total_timesteps  | 258000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 54499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.411    |
| time/               |          |
|    episodes         | 14724    |
|    fps              | 154      |
|    time_elapsed     | 1674     |
|    total_timesteps  | 258002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00224  |
|    n_updates        | 54500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.00207 |
|    exploration_rate | 0.411    |
| time/               |          |
|    episodes         | 14728    |
|    fps              | 154      |
|    time_elapsed     | 1674     |
|    total_timesteps  | 258069   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00443  |
|    n_updates        | 54517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.00203 |
|    exploration_rate | 0.41     |
| time/               |          |
|    episodes         | 14732    |
|    fps              | 154      |
|    time_elapsed     | 1674     |
|    total_timesteps  | 258129   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00242  |
|    n_updates        | 54532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.00211 |
|    exploration_rate | 0.41     |
| time/               |          |
|    episodes         | 14736    |
|    fps              | 154      |
|    time_elapsed     | 1675     |
|    total_timesteps  | 258194   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00263  |
|    n_updates        | 54548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.00211 |
|    exploration_rate | 0.41     |
| time/               |          |
|    episodes         | 14740    |
|    fps              | 154      |
|    time_elapsed     | 1675     |
|    total_timesteps  | 258257   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00321  |
|    n_updates        | 54564    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.00219 |
|    exploration_rate | 0.41     |
| time/               |          |
|    episodes         | 14744    |
|    fps              | 154      |
|    time_elapsed     | 1675     |
|    total_timesteps  | 258320   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00238  |
|    n_updates        | 54579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00251 |
|    exploration_rate | 0.409    |
| time/               |          |
|    episodes         | 14748    |
|    fps              | 154      |
|    time_elapsed     | 1675     |
|    total_timesteps  | 258388   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000563 |
|    n_updates        | 54596    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.00235 |
|    exploration_rate | 0.409    |
| time/               |          |
|    episodes         | 14752    |
|    fps              | 154      |
|    time_elapsed     | 1675     |
|    total_timesteps  | 258448   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00239  |
|    n_updates        | 54611    |
----------------------------------
Eval num_timesteps=258500, episode_reward=-0.00 +/- 0.24
Episode length: 15.46 +/- 4.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.5     |
|    mean_reward      | -0.00074 |
| rollout/            |          |
|    exploration_rate | 0.409    |
| time/               |          |
|    total_timesteps  | 258500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 54624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.409    |
| time/               |          |
|    episodes         | 14756    |
|    fps              | 154      |
|    time_elapsed     | 1676     |
|    total_timesteps  | 258512   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 54627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.409    |
| time/               |          |
|    episodes         | 14760    |
|    fps              | 154      |
|    time_elapsed     | 1676     |
|    total_timesteps  | 258574   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 54643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.408    |
| time/               |          |
|    episodes         | 14764    |
|    fps              | 154      |
|    time_elapsed     | 1676     |
|    total_timesteps  | 258634   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 54658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.408    |
| time/               |          |
|    episodes         | 14768    |
|    fps              | 154      |
|    time_elapsed     | 1676     |
|    total_timesteps  | 258703   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00242  |
|    n_updates        | 54675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0333  |
|    exploration_rate | 0.408    |
| time/               |          |
|    episodes         | 14772    |
|    fps              | 154      |
|    time_elapsed     | 1677     |
|    total_timesteps  | 258771   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00793  |
|    n_updates        | 54692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.407    |
| time/               |          |
|    episodes         | 14776    |
|    fps              | 154      |
|    time_elapsed     | 1677     |
|    total_timesteps  | 258833   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00289  |
|    n_updates        | 54708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0333  |
|    exploration_rate | 0.407    |
| time/               |          |
|    episodes         | 14780    |
|    fps              | 154      |
|    time_elapsed     | 1677     |
|    total_timesteps  | 258900   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 54724    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.407    |
| time/               |          |
|    episodes         | 14784    |
|    fps              | 154      |
|    time_elapsed     | 1677     |
|    total_timesteps  | 258961   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00242  |
|    n_updates        | 54740    |
----------------------------------
Eval num_timesteps=259000, episode_reward=-0.04 +/- 0.14
Episode length: 14.94 +/- 0.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0387  |
| rollout/            |          |
|    exploration_rate | 0.407    |
| time/               |          |
|    total_timesteps  | 259000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 54749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.407    |
| time/               |          |
|    episodes         | 14788    |
|    fps              | 154      |
|    time_elapsed     | 1678     |
|    total_timesteps  | 259022   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 54755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.406    |
| time/               |          |
|    episodes         | 14792    |
|    fps              | 154      |
|    time_elapsed     | 1678     |
|    total_timesteps  | 259086   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00286  |
|    n_updates        | 54771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.406    |
| time/               |          |
|    episodes         | 14796    |
|    fps              | 154      |
|    time_elapsed     | 1678     |
|    total_timesteps  | 259148   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 54786    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0328  |
|    exploration_rate | 0.406    |
| time/               |          |
|    episodes         | 14800    |
|    fps              | 154      |
|    time_elapsed     | 1678     |
|    total_timesteps  | 259212   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00649  |
|    n_updates        | 54802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0531  |
|    exploration_rate | 0.406    |
| time/               |          |
|    episodes         | 14804    |
|    fps              | 154      |
|    time_elapsed     | 1678     |
|    total_timesteps  | 259273   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 54818    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0533  |
|    exploration_rate | 0.405    |
| time/               |          |
|    episodes         | 14808    |
|    fps              | 154      |
|    time_elapsed     | 1679     |
|    total_timesteps  | 259340   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00207  |
|    n_updates        | 54834    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0535  |
|    exploration_rate | 0.405    |
| time/               |          |
|    episodes         | 14812    |
|    fps              | 154      |
|    time_elapsed     | 1679     |
|    total_timesteps  | 259415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 54853    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0535  |
|    exploration_rate | 0.405    |
| time/               |          |
|    episodes         | 14816    |
|    fps              | 154      |
|    time_elapsed     | 1679     |
|    total_timesteps  | 259481   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 54870    |
----------------------------------
Eval num_timesteps=259500, episode_reward=0.00 +/- 0.24
Episode length: 15.06 +/- 1.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | 0.00076  |
| rollout/            |          |
|    exploration_rate | 0.405    |
| time/               |          |
|    total_timesteps  | 259500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 54874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0531  |
|    exploration_rate | 0.405    |
| time/               |          |
|    episodes         | 14820    |
|    fps              | 154      |
|    time_elapsed     | 1680     |
|    total_timesteps  | 259545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 54886    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0534  |
|    exploration_rate | 0.404    |
| time/               |          |
|    episodes         | 14824    |
|    fps              | 154      |
|    time_elapsed     | 1680     |
|    total_timesteps  | 259612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 54902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0532  |
|    exploration_rate | 0.404    |
| time/               |          |
|    episodes         | 14828    |
|    fps              | 154      |
|    time_elapsed     | 1680     |
|    total_timesteps  | 259675   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 54918    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0433  |
|    exploration_rate | 0.404    |
| time/               |          |
|    episodes         | 14832    |
|    fps              | 154      |
|    time_elapsed     | 1680     |
|    total_timesteps  | 259737   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 54934    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0431  |
|    exploration_rate | 0.404    |
| time/               |          |
|    episodes         | 14836    |
|    fps              | 154      |
|    time_elapsed     | 1680     |
|    total_timesteps  | 259798   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00201  |
|    n_updates        | 54949    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0431  |
|    exploration_rate | 0.403    |
| time/               |          |
|    episodes         | 14840    |
|    fps              | 154      |
|    time_elapsed     | 1680     |
|    total_timesteps  | 259861   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 54965    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.403    |
| time/               |          |
|    episodes         | 14844    |
|    fps              | 154      |
|    time_elapsed     | 1680     |
|    total_timesteps  | 259918   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00261  |
|    n_updates        | 54979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00242 |
|    exploration_rate | 0.403    |
| time/               |          |
|    episodes         | 14848    |
|    fps              | 154      |
|    time_elapsed     | 1680     |
|    total_timesteps  | 259975   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 54993    |
----------------------------------
Eval num_timesteps=260000, episode_reward=0.00 +/- 0.24
Episode length: 14.76 +/- 1.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00194  |
| rollout/            |          |
|    exploration_rate | 0.403    |
| time/               |          |
|    total_timesteps  | 260000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 54999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00258 |
|    exploration_rate | 0.403    |
| time/               |          |
|    episodes         | 14852    |
|    fps              | 154      |
|    time_elapsed     | 1682     |
|    total_timesteps  | 260039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 55009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00278 |
|    exploration_rate | 0.402    |
| time/               |          |
|    episodes         | 14856    |
|    fps              | 154      |
|    time_elapsed     | 1682     |
|    total_timesteps  | 260108   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 55026    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00278 |
|    exploration_rate | 0.402    |
| time/               |          |
|    episodes         | 14860    |
|    fps              | 154      |
|    time_elapsed     | 1682     |
|    total_timesteps  | 260170   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00224  |
|    n_updates        | 55042    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0029  |
|    exploration_rate | 0.402    |
| time/               |          |
|    episodes         | 14864    |
|    fps              | 154      |
|    time_elapsed     | 1682     |
|    total_timesteps  | 260233   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00242  |
|    n_updates        | 55058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00282 |
|    exploration_rate | 0.402    |
| time/               |          |
|    episodes         | 14868    |
|    fps              | 154      |
|    time_elapsed     | 1682     |
|    total_timesteps  | 260300   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00695  |
|    n_updates        | 55074    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00735  |
|    exploration_rate | 0.401    |
| time/               |          |
|    episodes         | 14872    |
|    fps              | 154      |
|    time_elapsed     | 1682     |
|    total_timesteps  | 260364   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00373  |
|    n_updates        | 55090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.401    |
| time/               |          |
|    episodes         | 14876    |
|    fps              | 154      |
|    time_elapsed     | 1682     |
|    total_timesteps  | 260422   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 55105    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.401    |
| time/               |          |
|    episodes         | 14880    |
|    fps              | 154      |
|    time_elapsed     | 1682     |
|    total_timesteps  | 260479   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00386  |
|    n_updates        | 55119    |
----------------------------------
Eval num_timesteps=260500, episode_reward=-0.02 +/- 0.20
Episode length: 14.90 +/- 1.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0186  |
| rollout/            |          |
|    exploration_rate | 0.401    |
| time/               |          |
|    total_timesteps  | 260500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00311  |
|    n_updates        | 55124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.401    |
| time/               |          |
|    episodes         | 14884    |
|    fps              | 154      |
|    time_elapsed     | 1683     |
|    total_timesteps  | 260541   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00199  |
|    n_updates        | 55135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0479   |
|    exploration_rate | 0.4      |
| time/               |          |
|    episodes         | 14888    |
|    fps              | 154      |
|    time_elapsed     | 1684     |
|    total_timesteps  | 260600   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 55149    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0479   |
|    exploration_rate | 0.4      |
| time/               |          |
|    episodes         | 14892    |
|    fps              | 154      |
|    time_elapsed     | 1684     |
|    total_timesteps  | 260664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0108   |
|    n_updates        | 55165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0479   |
|    exploration_rate | 0.4      |
| time/               |          |
|    episodes         | 14896    |
|    fps              | 154      |
|    time_elapsed     | 1684     |
|    total_timesteps  | 260726   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 55181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0478   |
|    exploration_rate | 0.4      |
| time/               |          |
|    episodes         | 14900    |
|    fps              | 154      |
|    time_elapsed     | 1684     |
|    total_timesteps  | 260793   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00291  |
|    n_updates        | 55198    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0478   |
|    exploration_rate | 0.399    |
| time/               |          |
|    episodes         | 14904    |
|    fps              | 154      |
|    time_elapsed     | 1684     |
|    total_timesteps  | 260854   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 55213    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0477   |
|    exploration_rate | 0.399    |
| time/               |          |
|    episodes         | 14908    |
|    fps              | 154      |
|    time_elapsed     | 1684     |
|    total_timesteps  | 260924   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 55230    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0686   |
|    exploration_rate | 0.399    |
| time/               |          |
|    episodes         | 14912    |
|    fps              | 154      |
|    time_elapsed     | 1684     |
|    total_timesteps  | 260976   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00258  |
|    n_updates        | 55243    |
----------------------------------
Eval num_timesteps=261000, episode_reward=-0.02 +/- 0.20
Episode length: 14.86 +/- 0.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0184  |
| rollout/            |          |
|    exploration_rate | 0.399    |
| time/               |          |
|    total_timesteps  | 261000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00413  |
|    n_updates        | 55249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0684   |
|    exploration_rate | 0.398    |
| time/               |          |
|    episodes         | 14916    |
|    fps              | 154      |
|    time_elapsed     | 1685     |
|    total_timesteps  | 261046   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00462  |
|    n_updates        | 55261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0685   |
|    exploration_rate | 0.398    |
| time/               |          |
|    episodes         | 14920    |
|    fps              | 154      |
|    time_elapsed     | 1685     |
|    total_timesteps  | 261108   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0027   |
|    n_updates        | 55276    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0787   |
|    exploration_rate | 0.398    |
| time/               |          |
|    episodes         | 14924    |
|    fps              | 154      |
|    time_elapsed     | 1686     |
|    total_timesteps  | 261170   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00267  |
|    n_updates        | 55292    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0789   |
|    exploration_rate | 0.398    |
| time/               |          |
|    episodes         | 14928    |
|    fps              | 154      |
|    time_elapsed     | 1686     |
|    total_timesteps  | 261230   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 55307    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0688   |
|    exploration_rate | 0.397    |
| time/               |          |
|    episodes         | 14932    |
|    fps              | 154      |
|    time_elapsed     | 1686     |
|    total_timesteps  | 261293   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 55323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0789   |
|    exploration_rate | 0.397    |
| time/               |          |
|    episodes         | 14936    |
|    fps              | 154      |
|    time_elapsed     | 1686     |
|    total_timesteps  | 261351   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00243  |
|    n_updates        | 55337    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.089    |
|    exploration_rate | 0.397    |
| time/               |          |
|    episodes         | 14940    |
|    fps              | 155      |
|    time_elapsed     | 1686     |
|    total_timesteps  | 261412   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00343  |
|    n_updates        | 55352    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.397    |
| time/               |          |
|    episodes         | 14944    |
|    fps              | 155      |
|    time_elapsed     | 1686     |
|    total_timesteps  | 261475   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00232  |
|    n_updates        | 55368    |
----------------------------------
Eval num_timesteps=261500, episode_reward=0.02 +/- 0.28
Episode length: 14.72 +/- 1.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0222   |
| rollout/            |          |
|    exploration_rate | 0.397    |
| time/               |          |
|    total_timesteps  | 261500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 55374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.396    |
| time/               |          |
|    episodes         | 14948    |
|    fps              | 154      |
|    time_elapsed     | 1687     |
|    total_timesteps  | 261535   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00264  |
|    n_updates        | 55383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.396    |
| time/               |          |
|    episodes         | 14952    |
|    fps              | 155      |
|    time_elapsed     | 1687     |
|    total_timesteps  | 261599   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 55399    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.059    |
|    exploration_rate | 0.396    |
| time/               |          |
|    episodes         | 14956    |
|    fps              | 155      |
|    time_elapsed     | 1687     |
|    total_timesteps  | 261659   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 55414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.059    |
|    exploration_rate | 0.396    |
| time/               |          |
|    episodes         | 14960    |
|    fps              | 155      |
|    time_elapsed     | 1687     |
|    total_timesteps  | 261721   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00575  |
|    n_updates        | 55430    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0591   |
|    exploration_rate | 0.395    |
| time/               |          |
|    episodes         | 14964    |
|    fps              | 155      |
|    time_elapsed     | 1688     |
|    total_timesteps  | 261781   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00246  |
|    n_updates        | 55445    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0695   |
|    exploration_rate | 0.395    |
| time/               |          |
|    episodes         | 14968    |
|    fps              | 155      |
|    time_elapsed     | 1688     |
|    total_timesteps  | 261838   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 55459    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0595   |
|    exploration_rate | 0.395    |
| time/               |          |
|    episodes         | 14972    |
|    fps              | 155      |
|    time_elapsed     | 1688     |
|    total_timesteps  | 261901   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00191  |
|    n_updates        | 55475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 0.395    |
| time/               |          |
|    episodes         | 14976    |
|    fps              | 155      |
|    time_elapsed     | 1688     |
|    total_timesteps  | 261965   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0074   |
|    n_updates        | 55491    |
----------------------------------
Eval num_timesteps=262000, episode_reward=-0.02 +/- 0.20
Episode length: 14.82 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | -0.0183  |
| rollout/            |          |
|    exploration_rate | 0.395    |
| time/               |          |
|    total_timesteps  | 262000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00315  |
|    n_updates        | 55499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0392   |
|    exploration_rate | 0.394    |
| time/               |          |
|    episodes         | 14980    |
|    fps              | 155      |
|    time_elapsed     | 1689     |
|    total_timesteps  | 262024   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 55505    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.394    |
| time/               |          |
|    episodes         | 14984    |
|    fps              | 155      |
|    time_elapsed     | 1689     |
|    total_timesteps  | 262085   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 55521    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.394    |
| time/               |          |
|    episodes         | 14988    |
|    fps              | 155      |
|    time_elapsed     | 1689     |
|    total_timesteps  | 262146   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00289  |
|    n_updates        | 55536    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.394    |
| time/               |          |
|    episodes         | 14992    |
|    fps              | 155      |
|    time_elapsed     | 1689     |
|    total_timesteps  | 262225   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00244  |
|    n_updates        | 55556    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0288   |
|    exploration_rate | 0.393    |
| time/               |          |
|    episodes         | 14996    |
|    fps              | 155      |
|    time_elapsed     | 1689     |
|    total_timesteps  | 262281   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 55570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.029    |
|    exploration_rate | 0.393    |
| time/               |          |
|    episodes         | 15000    |
|    fps              | 155      |
|    time_elapsed     | 1690     |
|    total_timesteps  | 262344   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 55585    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.393    |
| time/               |          |
|    episodes         | 15004    |
|    fps              | 155      |
|    time_elapsed     | 1690     |
|    total_timesteps  | 262404   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00618  |
|    n_updates        | 55600    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0495   |
|    exploration_rate | 0.393    |
| time/               |          |
|    episodes         | 15008    |
|    fps              | 155      |
|    time_elapsed     | 1690     |
|    total_timesteps  | 262463   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 55615    |
----------------------------------
Eval num_timesteps=262500, episode_reward=0.02 +/- 0.28
Episode length: 14.74 +/- 1.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0221   |
| rollout/            |          |
|    exploration_rate | 0.393    |
| time/               |          |
|    total_timesteps  | 262500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 55624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0291   |
|    exploration_rate | 0.392    |
| time/               |          |
|    episodes         | 15012    |
|    fps              | 155      |
|    time_elapsed     | 1691     |
|    total_timesteps  | 262525   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0048   |
|    n_updates        | 55631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.392    |
| time/               |          |
|    episodes         | 15016    |
|    fps              | 155      |
|    time_elapsed     | 1691     |
|    total_timesteps  | 262590   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00244  |
|    n_updates        | 55647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.392    |
| time/               |          |
|    episodes         | 15020    |
|    fps              | 155      |
|    time_elapsed     | 1691     |
|    total_timesteps  | 262651   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000642 |
|    n_updates        | 55662    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0295   |
|    exploration_rate | 0.392    |
| time/               |          |
|    episodes         | 15024    |
|    fps              | 155      |
|    time_elapsed     | 1691     |
|    total_timesteps  | 262710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00339  |
|    n_updates        | 55677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 0.391    |
| time/               |          |
|    episodes         | 15028    |
|    fps              | 155      |
|    time_elapsed     | 1691     |
|    total_timesteps  | 262772   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 55692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 0.391    |
| time/               |          |
|    episodes         | 15032    |
|    fps              | 155      |
|    time_elapsed     | 1691     |
|    total_timesteps  | 262833   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0031   |
|    n_updates        | 55708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0193   |
|    exploration_rate | 0.391    |
| time/               |          |
|    episodes         | 15036    |
|    fps              | 155      |
|    time_elapsed     | 1692     |
|    total_timesteps  | 262896   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00391  |
|    n_updates        | 55723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00787  |
|    exploration_rate | 0.391    |
| time/               |          |
|    episodes         | 15040    |
|    fps              | 155      |
|    time_elapsed     | 1692     |
|    total_timesteps  | 262992   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000801 |
|    n_updates        | 55747    |
----------------------------------
Eval num_timesteps=263000, episode_reward=-0.06 +/- 0.00
Episode length: 15.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.059   |
| rollout/            |          |
|    exploration_rate | 0.39     |
| time/               |          |
|    total_timesteps  | 263000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00182  |
|    n_updates        | 55749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00795  |
|    exploration_rate | 0.39     |
| time/               |          |
|    episodes         | 15044    |
|    fps              | 155      |
|    time_elapsed     | 1693     |
|    total_timesteps  | 263053   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 55763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00797  |
|    exploration_rate | 0.39     |
| time/               |          |
|    episodes         | 15048    |
|    fps              | 155      |
|    time_elapsed     | 1693     |
|    total_timesteps  | 263112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00306  |
|    n_updates        | 55777    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.39     |
| time/               |          |
|    episodes         | 15052    |
|    fps              | 155      |
|    time_elapsed     | 1693     |
|    total_timesteps  | 263171   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0027   |
|    n_updates        | 55792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.39     |
| time/               |          |
|    episodes         | 15056    |
|    fps              | 155      |
|    time_elapsed     | 1693     |
|    total_timesteps  | 263234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0081   |
|    n_updates        | 55808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.389    |
| time/               |          |
|    episodes         | 15060    |
|    fps              | 155      |
|    time_elapsed     | 1693     |
|    total_timesteps  | 263297   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 55824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.389    |
| time/               |          |
|    episodes         | 15064    |
|    fps              | 155      |
|    time_elapsed     | 1693     |
|    total_timesteps  | 263355   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0032   |
|    n_updates        | 55838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.389    |
| time/               |          |
|    episodes         | 15068    |
|    fps              | 155      |
|    time_elapsed     | 1693     |
|    total_timesteps  | 263418   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 55854    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.389    |
| time/               |          |
|    episodes         | 15072    |
|    fps              | 155      |
|    time_elapsed     | 1694     |
|    total_timesteps  | 263480   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 55869    |
----------------------------------
Eval num_timesteps=263500, episode_reward=-0.04 +/- 0.15
Episode length: 16.42 +/- 8.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | -0.0447  |
| rollout/            |          |
|    exploration_rate | 0.388    |
| time/               |          |
|    total_timesteps  | 263500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 55874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.388    |
| time/               |          |
|    episodes         | 15076    |
|    fps              | 155      |
|    time_elapsed     | 1695     |
|    total_timesteps  | 263554   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00232  |
|    n_updates        | 55888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00743  |
|    exploration_rate | 0.388    |
| time/               |          |
|    episodes         | 15080    |
|    fps              | 155      |
|    time_elapsed     | 1695     |
|    total_timesteps  | 263615   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 55903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00715  |
|    exploration_rate | 0.388    |
| time/               |          |
|    episodes         | 15084    |
|    fps              | 155      |
|    time_elapsed     | 1695     |
|    total_timesteps  | 263683   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 55920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.387    |
| time/               |          |
|    episodes         | 15088    |
|    fps              | 155      |
|    time_elapsed     | 1695     |
|    total_timesteps  | 263741   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000883 |
|    n_updates        | 55935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.387    |
| time/               |          |
|    episodes         | 15092    |
|    fps              | 155      |
|    time_elapsed     | 1695     |
|    total_timesteps  | 263824   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00212  |
|    n_updates        | 55955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 0.387    |
| time/               |          |
|    episodes         | 15096    |
|    fps              | 155      |
|    time_elapsed     | 1695     |
|    total_timesteps  | 263885   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 55971    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.387    |
| time/               |          |
|    episodes         | 15100    |
|    fps              | 155      |
|    time_elapsed     | 1695     |
|    total_timesteps  | 263946   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 55986    |
----------------------------------
Eval num_timesteps=264000, episode_reward=-0.02 +/- 0.20
Episode length: 14.86 +/- 0.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0185  |
| rollout/            |          |
|    exploration_rate | 0.386    |
| time/               |          |
|    total_timesteps  | 264000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 55999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00693  |
|    exploration_rate | 0.386    |
| time/               |          |
|    episodes         | 15104    |
|    fps              | 155      |
|    time_elapsed     | 1696     |
|    total_timesteps  | 264008   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 56001    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00317 |
|    exploration_rate | 0.386    |
| time/               |          |
|    episodes         | 15108    |
|    fps              | 155      |
|    time_elapsed     | 1697     |
|    total_timesteps  | 264069   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 56017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00696  |
|    exploration_rate | 0.386    |
| time/               |          |
|    episodes         | 15112    |
|    fps              | 155      |
|    time_elapsed     | 1697     |
|    total_timesteps  | 264128   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000854 |
|    n_updates        | 56031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00716  |
|    exploration_rate | 0.386    |
| time/               |          |
|    episodes         | 15116    |
|    fps              | 155      |
|    time_elapsed     | 1697     |
|    total_timesteps  | 264188   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 56046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 0.385    |
| time/               |          |
|    episodes         | 15120    |
|    fps              | 155      |
|    time_elapsed     | 1697     |
|    total_timesteps  | 264249   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 56062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00694  |
|    exploration_rate | 0.385    |
| time/               |          |
|    episodes         | 15124    |
|    fps              | 155      |
|    time_elapsed     | 1697     |
|    total_timesteps  | 264313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 56078    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00702  |
|    exploration_rate | 0.385    |
| time/               |          |
|    episodes         | 15128    |
|    fps              | 155      |
|    time_elapsed     | 1697     |
|    total_timesteps  | 264373   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 56093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00674  |
|    exploration_rate | 0.385    |
| time/               |          |
|    episodes         | 15132    |
|    fps              | 155      |
|    time_elapsed     | 1697     |
|    total_timesteps  | 264441   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00247  |
|    n_updates        | 56110    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.384    |
| time/               |          |
|    episodes         | 15136    |
|    fps              | 155      |
|    time_elapsed     | 1697     |
|    total_timesteps  | 264498   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 56124    |
----------------------------------
Eval num_timesteps=264500, episode_reward=-0.04 +/- 0.14
Episode length: 14.96 +/- 0.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.0388  |
| rollout/            |          |
|    exploration_rate | 0.384    |
| time/               |          |
|    total_timesteps  | 264500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.384    |
| time/               |          |
|    episodes         | 15140    |
|    fps              | 155      |
|    time_elapsed     | 1699     |
|    total_timesteps  | 264562   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 56140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.384    |
| time/               |          |
|    episodes         | 15144    |
|    fps              | 155      |
|    time_elapsed     | 1699     |
|    total_timesteps  | 264624   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 56155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.384    |
| time/               |          |
|    episodes         | 15148    |
|    fps              | 155      |
|    time_elapsed     | 1699     |
|    total_timesteps  | 264686   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00363  |
|    n_updates        | 56171    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00802  |
|    exploration_rate | 0.383    |
| time/               |          |
|    episodes         | 15152    |
|    fps              | 155      |
|    time_elapsed     | 1699     |
|    total_timesteps  | 264747   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 56186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.383    |
| time/               |          |
|    episodes         | 15156    |
|    fps              | 155      |
|    time_elapsed     | 1699     |
|    total_timesteps  | 264806   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00352  |
|    n_updates        | 56201    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.383    |
| time/               |          |
|    episodes         | 15160    |
|    fps              | 155      |
|    time_elapsed     | 1699     |
|    total_timesteps  | 264868   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 56216    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00779  |
|    exploration_rate | 0.383    |
| time/               |          |
|    episodes         | 15164    |
|    fps              | 155      |
|    time_elapsed     | 1699     |
|    total_timesteps  | 264936   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 56233    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00783  |
|    exploration_rate | 0.382    |
| time/               |          |
|    episodes         | 15168    |
|    fps              | 155      |
|    time_elapsed     | 1699     |
|    total_timesteps  | 264998   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00324  |
|    n_updates        | 56249    |
----------------------------------
Eval num_timesteps=265000, episode_reward=-0.04 +/- 0.14
Episode length: 15.02 +/- 0.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.0391  |
| rollout/            |          |
|    exploration_rate | 0.382    |
| time/               |          |
|    total_timesteps  | 265000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00759  |
|    exploration_rate | 0.382    |
| time/               |          |
|    episodes         | 15172    |
|    fps              | 155      |
|    time_elapsed     | 1700     |
|    total_timesteps  | 265066   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00276  |
|    n_updates        | 56266    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00815  |
|    exploration_rate | 0.382    |
| time/               |          |
|    episodes         | 15176    |
|    fps              | 155      |
|    time_elapsed     | 1701     |
|    total_timesteps  | 265126   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00947  |
|    n_updates        | 56281    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00815  |
|    exploration_rate | 0.382    |
| time/               |          |
|    episodes         | 15180    |
|    fps              | 155      |
|    time_elapsed     | 1701     |
|    total_timesteps  | 265187   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 56296    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00835  |
|    exploration_rate | 0.381    |
| time/               |          |
|    episodes         | 15184    |
|    fps              | 155      |
|    time_elapsed     | 1701     |
|    total_timesteps  | 265250   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00276  |
|    n_updates        | 56312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.00179 |
|    exploration_rate | 0.381    |
| time/               |          |
|    episodes         | 15188    |
|    fps              | 155      |
|    time_elapsed     | 1701     |
|    total_timesteps  | 265311   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 56327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0109  |
|    exploration_rate | 0.381    |
| time/               |          |
|    episodes         | 15192    |
|    fps              | 155      |
|    time_elapsed     | 1701     |
|    total_timesteps  | 265371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 56342    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 0.38     |
| time/               |          |
|    episodes         | 15196    |
|    fps              | 155      |
|    time_elapsed     | 1701     |
|    total_timesteps  | 265443   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00411  |
|    n_updates        | 56360    |
----------------------------------
Eval num_timesteps=265500, episode_reward=0.06 +/- 0.33
Episode length: 14.64 +/- 0.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0626   |
| rollout/            |          |
|    exploration_rate | 0.38     |
| time/               |          |
|    total_timesteps  | 265500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 56374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.00116 |
|    exploration_rate | 0.38     |
| time/               |          |
|    episodes         | 15200    |
|    fps              | 155      |
|    time_elapsed     | 1702     |
|    total_timesteps  | 265500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.00908  |
|    exploration_rate | 0.38     |
| time/               |          |
|    episodes         | 15204    |
|    fps              | 155      |
|    time_elapsed     | 1702     |
|    total_timesteps  | 265556   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 56388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.009    |
|    exploration_rate | 0.38     |
| time/               |          |
|    episodes         | 15208    |
|    fps              | 155      |
|    time_elapsed     | 1702     |
|    total_timesteps  | 265619   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 56404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.00113 |
|    exploration_rate | 0.379    |
| time/               |          |
|    episodes         | 15212    |
|    fps              | 156      |
|    time_elapsed     | 1702     |
|    total_timesteps  | 265681   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0026   |
|    n_updates        | 56420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.00892  |
|    exploration_rate | 0.379    |
| time/               |          |
|    episodes         | 15216    |
|    fps              | 156      |
|    time_elapsed     | 1702     |
|    total_timesteps  | 265740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 56434    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.00107 |
|    exploration_rate | 0.379    |
| time/               |          |
|    episodes         | 15220    |
|    fps              | 156      |
|    time_elapsed     | 1703     |
|    total_timesteps  | 265801   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0019   |
|    n_updates        | 56450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.00914  |
|    exploration_rate | 0.379    |
| time/               |          |
|    episodes         | 15224    |
|    fps              | 156      |
|    time_elapsed     | 1703     |
|    total_timesteps  | 265860   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 56464    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.00902  |
|    exploration_rate | 0.378    |
| time/               |          |
|    episodes         | 15228    |
|    fps              | 156      |
|    time_elapsed     | 1703     |
|    total_timesteps  | 265923   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 56480    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 0.378    |
| time/               |          |
|    episodes         | 15232    |
|    fps              | 156      |
|    time_elapsed     | 1703     |
|    total_timesteps  | 265983   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 56495    |
----------------------------------
Eval num_timesteps=266000, episode_reward=-0.02 +/- 0.20
Episode length: 14.84 +/- 0.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | -0.0184  |
| rollout/            |          |
|    exploration_rate | 0.378    |
| time/               |          |
|    total_timesteps  | 266000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00498  |
|    n_updates        | 56499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.00907  |
|    exploration_rate | 0.378    |
| time/               |          |
|    episodes         | 15236    |
|    fps              | 156      |
|    time_elapsed     | 1704     |
|    total_timesteps  | 266047   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 56511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.00915  |
|    exploration_rate | 0.378    |
| time/               |          |
|    episodes         | 15240    |
|    fps              | 156      |
|    time_elapsed     | 1704     |
|    total_timesteps  | 266109   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00705  |
|    n_updates        | 56527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.00915  |
|    exploration_rate | 0.377    |
| time/               |          |
|    episodes         | 15244    |
|    fps              | 156      |
|    time_elapsed     | 1704     |
|    total_timesteps  | 266171   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00941  |
|    n_updates        | 56542    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.00098 |
|    exploration_rate | 0.377    |
| time/               |          |
|    episodes         | 15248    |
|    fps              | 156      |
|    time_elapsed     | 1704     |
|    total_timesteps  | 266236   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00361  |
|    n_updates        | 56558    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.00118 |
|    exploration_rate | 0.377    |
| time/               |          |
|    episodes         | 15252    |
|    fps              | 156      |
|    time_elapsed     | 1704     |
|    total_timesteps  | 266302   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0037   |
|    n_updates        | 56575    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 0.377    |
| time/               |          |
|    episodes         | 15256    |
|    fps              | 156      |
|    time_elapsed     | 1704     |
|    total_timesteps  | 266366   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00494  |
|    n_updates        | 56591    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 0.376    |
| time/               |          |
|    episodes         | 15260    |
|    fps              | 156      |
|    time_elapsed     | 1705     |
|    total_timesteps  | 266427   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0057   |
|    n_updates        | 56606    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.376    |
| time/               |          |
|    episodes         | 15264    |
|    fps              | 156      |
|    time_elapsed     | 1705     |
|    total_timesteps  | 266492   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00239  |
|    n_updates        | 56622    |
----------------------------------
Eval num_timesteps=266500, episode_reward=0.02 +/- 0.28
Episode length: 14.96 +/- 1.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | 0.0212   |
| rollout/            |          |
|    exploration_rate | 0.376    |
| time/               |          |
|    total_timesteps  | 266500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00212  |
|    n_updates        | 56624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.376    |
| time/               |          |
|    episodes         | 15268    |
|    fps              | 156      |
|    time_elapsed     | 1706     |
|    total_timesteps  | 266555   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00253  |
|    n_updates        | 56638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.011   |
|    exploration_rate | 0.376    |
| time/               |          |
|    episodes         | 15272    |
|    fps              | 156      |
|    time_elapsed     | 1706     |
|    total_timesteps  | 266616   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00689  |
|    n_updates        | 56653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0111  |
|    exploration_rate | 0.375    |
| time/               |          |
|    episodes         | 15276    |
|    fps              | 156      |
|    time_elapsed     | 1706     |
|    total_timesteps  | 266680   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 56669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.375    |
| time/               |          |
|    episodes         | 15280    |
|    fps              | 156      |
|    time_elapsed     | 1706     |
|    total_timesteps  | 266743   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 56685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0111  |
|    exploration_rate | 0.375    |
| time/               |          |
|    episodes         | 15284    |
|    fps              | 156      |
|    time_elapsed     | 1706     |
|    total_timesteps  | 266804   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00225  |
|    n_updates        | 56700    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.375    |
| time/               |          |
|    episodes         | 15288    |
|    fps              | 156      |
|    time_elapsed     | 1706     |
|    total_timesteps  | 266867   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00261  |
|    n_updates        | 56716    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.374    |
| time/               |          |
|    episodes         | 15292    |
|    fps              | 156      |
|    time_elapsed     | 1706     |
|    total_timesteps  | 266935   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00212  |
|    n_updates        | 56733    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0111  |
|    exploration_rate | 0.374    |
| time/               |          |
|    episodes         | 15296    |
|    fps              | 156      |
|    time_elapsed     | 1707     |
|    total_timesteps  | 266997   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00272  |
|    n_updates        | 56749    |
----------------------------------
Eval num_timesteps=267000, episode_reward=-0.04 +/- 0.15
Episode length: 16.34 +/- 8.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.3     |
|    mean_reward      | -0.0444  |
| rollout/            |          |
|    exploration_rate | 0.374    |
| time/               |          |
|    total_timesteps  | 267000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 0.374    |
| time/               |          |
|    episodes         | 15300    |
|    fps              | 156      |
|    time_elapsed     | 1708     |
|    total_timesteps  | 267059   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 56764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.374    |
| time/               |          |
|    episodes         | 15304    |
|    fps              | 156      |
|    time_elapsed     | 1708     |
|    total_timesteps  | 267125   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 56781    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.00134 |
|    exploration_rate | 0.373    |
| time/               |          |
|    episodes         | 15308    |
|    fps              | 156      |
|    time_elapsed     | 1708     |
|    total_timesteps  | 267178   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 56794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.00166 |
|    exploration_rate | 0.373    |
| time/               |          |
|    episodes         | 15312    |
|    fps              | 156      |
|    time_elapsed     | 1708     |
|    total_timesteps  | 267248   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 56811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 0.373    |
| time/               |          |
|    episodes         | 15316    |
|    fps              | 156      |
|    time_elapsed     | 1708     |
|    total_timesteps  | 267313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00227  |
|    n_updates        | 56828    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 0.372    |
| time/               |          |
|    episodes         | 15320    |
|    fps              | 156      |
|    time_elapsed     | 1708     |
|    total_timesteps  | 267375   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00302  |
|    n_updates        | 56843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.372    |
| time/               |          |
|    episodes         | 15324    |
|    fps              | 156      |
|    time_elapsed     | 1708     |
|    total_timesteps  | 267438   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 56859    |
----------------------------------
Eval num_timesteps=267500, episode_reward=-0.02 +/- 0.20
Episode length: 14.94 +/- 0.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0187  |
| rollout/            |          |
|    exploration_rate | 0.372    |
| time/               |          |
|    total_timesteps  | 267500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00321  |
|    n_updates        | 56874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.372    |
| time/               |          |
|    episodes         | 15328    |
|    fps              | 156      |
|    time_elapsed     | 1709     |
|    total_timesteps  | 267502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 56875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0322  |
|    exploration_rate | 0.372    |
| time/               |          |
|    episodes         | 15332    |
|    fps              | 156      |
|    time_elapsed     | 1709     |
|    total_timesteps  | 267564   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 56890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0327  |
|    exploration_rate | 0.371    |
| time/               |          |
|    episodes         | 15336    |
|    fps              | 156      |
|    time_elapsed     | 1710     |
|    total_timesteps  | 267640   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00251  |
|    n_updates        | 56909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.371    |
| time/               |          |
|    episodes         | 15340    |
|    fps              | 156      |
|    time_elapsed     | 1710     |
|    total_timesteps  | 267717   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00305  |
|    n_updates        | 56929    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.371    |
| time/               |          |
|    episodes         | 15344    |
|    fps              | 156      |
|    time_elapsed     | 1710     |
|    total_timesteps  | 267778   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 56944    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.371    |
| time/               |          |
|    episodes         | 15348    |
|    fps              | 156      |
|    time_elapsed     | 1710     |
|    total_timesteps  | 267839   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0019   |
|    n_updates        | 56959    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0239  |
|    exploration_rate | 0.37     |
| time/               |          |
|    episodes         | 15352    |
|    fps              | 156      |
|    time_elapsed     | 1710     |
|    total_timesteps  | 267924   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 56980    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.37     |
| time/               |          |
|    episodes         | 15356    |
|    fps              | 156      |
|    time_elapsed     | 1710     |
|    total_timesteps  | 267983   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 56995    |
----------------------------------
Eval num_timesteps=268000, episode_reward=-0.03 +/- 0.20
Episode length: 16.84 +/- 4.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.8     |
|    mean_reward      | -0.0263  |
| rollout/            |          |
|    exploration_rate | 0.37     |
| time/               |          |
|    total_timesteps  | 268000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 56999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.37     |
| time/               |          |
|    episodes         | 15360    |
|    fps              | 156      |
|    time_elapsed     | 1711     |
|    total_timesteps  | 268051   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 57012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.014   |
|    exploration_rate | 0.369    |
| time/               |          |
|    episodes         | 15364    |
|    fps              | 156      |
|    time_elapsed     | 1711     |
|    total_timesteps  | 268118   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 57029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.369    |
| time/               |          |
|    episodes         | 15368    |
|    fps              | 156      |
|    time_elapsed     | 1711     |
|    total_timesteps  | 268178   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00286  |
|    n_updates        | 57044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.014   |
|    exploration_rate | 0.369    |
| time/               |          |
|    episodes         | 15372    |
|    fps              | 156      |
|    time_elapsed     | 1712     |
|    total_timesteps  | 268241   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 57060    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.369    |
| time/               |          |
|    episodes         | 15376    |
|    fps              | 156      |
|    time_elapsed     | 1712     |
|    total_timesteps  | 268309   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00378  |
|    n_updates        | 57077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.368    |
| time/               |          |
|    episodes         | 15380    |
|    fps              | 156      |
|    time_elapsed     | 1712     |
|    total_timesteps  | 268373   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 57093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 0.368    |
| time/               |          |
|    episodes         | 15384    |
|    fps              | 156      |
|    time_elapsed     | 1712     |
|    total_timesteps  | 268437   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 57109    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00406 |
|    exploration_rate | 0.368    |
| time/               |          |
|    episodes         | 15388    |
|    fps              | 156      |
|    time_elapsed     | 1712     |
|    total_timesteps  | 268494   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 57123    |
----------------------------------
Eval num_timesteps=268500, episode_reward=-0.02 +/- 0.20
Episode length: 14.90 +/- 0.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0186  |
| rollout/            |          |
|    exploration_rate | 0.368    |
| time/               |          |
|    total_timesteps  | 268500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00337  |
|    n_updates        | 57124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00382 |
|    exploration_rate | 0.368    |
| time/               |          |
|    episodes         | 15392    |
|    fps              | 156      |
|    time_elapsed     | 1713     |
|    total_timesteps  | 268556   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00203  |
|    n_updates        | 57138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00638  |
|    exploration_rate | 0.367    |
| time/               |          |
|    episodes         | 15396    |
|    fps              | 156      |
|    time_elapsed     | 1713     |
|    total_timesteps  | 268613   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 57153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00374 |
|    exploration_rate | 0.367    |
| time/               |          |
|    episodes         | 15400    |
|    fps              | 156      |
|    time_elapsed     | 1713     |
|    total_timesteps  | 268678   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 57169    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00652  |
|    exploration_rate | 0.367    |
| time/               |          |
|    episodes         | 15404    |
|    fps              | 156      |
|    time_elapsed     | 1714     |
|    total_timesteps  | 268738   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 57184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.367    |
| time/               |          |
|    episodes         | 15408    |
|    fps              | 156      |
|    time_elapsed     | 1714     |
|    total_timesteps  | 268799   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 57199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00337 |
|    exploration_rate | 0.366    |
| time/               |          |
|    episodes         | 15412    |
|    fps              | 156      |
|    time_elapsed     | 1714     |
|    total_timesteps  | 268859   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00363  |
|    n_updates        | 57214    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00345 |
|    exploration_rate | 0.366    |
| time/               |          |
|    episodes         | 15416    |
|    fps              | 156      |
|    time_elapsed     | 1714     |
|    total_timesteps  | 268926   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00684  |
|    n_updates        | 57231    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00337 |
|    exploration_rate | 0.366    |
| time/               |          |
|    episodes         | 15420    |
|    fps              | 156      |
|    time_elapsed     | 1714     |
|    total_timesteps  | 268986   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00191  |
|    n_updates        | 57246    |
----------------------------------
Eval num_timesteps=269000, episode_reward=0.00 +/- 0.24
Episode length: 14.84 +/- 1.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.0017   |
| rollout/            |          |
|    exploration_rate | 0.366    |
| time/               |          |
|    total_timesteps  | 269000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00427  |
|    n_updates        | 57249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00658  |
|    exploration_rate | 0.366    |
| time/               |          |
|    episodes         | 15424    |
|    fps              | 156      |
|    time_elapsed     | 1715     |
|    total_timesteps  | 269050   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00228  |
|    n_updates        | 57262    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00654  |
|    exploration_rate | 0.365    |
| time/               |          |
|    episodes         | 15428    |
|    fps              | 156      |
|    time_elapsed     | 1715     |
|    total_timesteps  | 269115   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 57278    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0065   |
|    exploration_rate | 0.365    |
| time/               |          |
|    episodes         | 15432    |
|    fps              | 156      |
|    time_elapsed     | 1715     |
|    total_timesteps  | 269178   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 57294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.365    |
| time/               |          |
|    episodes         | 15436    |
|    fps              | 156      |
|    time_elapsed     | 1715     |
|    total_timesteps  | 269248   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 57311    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00742  |
|    exploration_rate | 0.364    |
| time/               |          |
|    episodes         | 15440    |
|    fps              | 156      |
|    time_elapsed     | 1715     |
|    total_timesteps  | 269308   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 57326    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.364    |
| time/               |          |
|    episodes         | 15444    |
|    fps              | 156      |
|    time_elapsed     | 1716     |
|    total_timesteps  | 269365   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00742  |
|    n_updates        | 57341    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.364    |
| time/               |          |
|    episodes         | 15448    |
|    fps              | 156      |
|    time_elapsed     | 1716     |
|    total_timesteps  | 269425   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 57356    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.364    |
| time/               |          |
|    episodes         | 15452    |
|    fps              | 157      |
|    time_elapsed     | 1716     |
|    total_timesteps  | 269498   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00445  |
|    n_updates        | 57374    |
----------------------------------
Eval num_timesteps=269500, episode_reward=0.00 +/- 0.24
Episode length: 14.90 +/- 0.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.00142  |
| rollout/            |          |
|    exploration_rate | 0.364    |
| time/               |          |
|    total_timesteps  | 269500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00801  |
|    exploration_rate | 0.363    |
| time/               |          |
|    episodes         | 15456    |
|    fps              | 156      |
|    time_elapsed     | 1717     |
|    total_timesteps  | 269559   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00285  |
|    n_updates        | 57389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00809  |
|    exploration_rate | 0.363    |
| time/               |          |
|    episodes         | 15460    |
|    fps              | 156      |
|    time_elapsed     | 1717     |
|    total_timesteps  | 269625   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00224  |
|    n_updates        | 57406    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.363    |
| time/               |          |
|    episodes         | 15464    |
|    fps              | 157      |
|    time_elapsed     | 1717     |
|    total_timesteps  | 269684   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 57420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.363    |
| time/               |          |
|    episodes         | 15468    |
|    fps              | 157      |
|    time_elapsed     | 1717     |
|    total_timesteps  | 269761   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00278  |
|    n_updates        | 57440    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.362    |
| time/               |          |
|    episodes         | 15472    |
|    fps              | 157      |
|    time_elapsed     | 1717     |
|    total_timesteps  | 269822   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 57455    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.362    |
| time/               |          |
|    episodes         | 15476    |
|    fps              | 157      |
|    time_elapsed     | 1717     |
|    total_timesteps  | 269880   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00212  |
|    n_updates        | 57469    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.362    |
| time/               |          |
|    episodes         | 15480    |
|    fps              | 157      |
|    time_elapsed     | 1717     |
|    total_timesteps  | 269943   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00231  |
|    n_updates        | 57485    |
----------------------------------
Eval num_timesteps=270000, episode_reward=0.02 +/- 0.28
Episode length: 14.94 +/- 1.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.0212   |
| rollout/            |          |
|    exploration_rate | 0.362    |
| time/               |          |
|    total_timesteps  | 270000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 57499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0283   |
|    exploration_rate | 0.362    |
| time/               |          |
|    episodes         | 15484    |
|    fps              | 157      |
|    time_elapsed     | 1718     |
|    total_timesteps  | 270005   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 57501    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.361    |
| time/               |          |
|    episodes         | 15488    |
|    fps              | 157      |
|    time_elapsed     | 1719     |
|    total_timesteps  | 270066   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000866 |
|    n_updates        | 57516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.361    |
| time/               |          |
|    episodes         | 15492    |
|    fps              | 157      |
|    time_elapsed     | 1719     |
|    total_timesteps  | 270128   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00512  |
|    n_updates        | 57531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00796  |
|    exploration_rate | 0.361    |
| time/               |          |
|    episodes         | 15496    |
|    fps              | 157      |
|    time_elapsed     | 1719     |
|    total_timesteps  | 270190   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 57547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00808  |
|    exploration_rate | 0.361    |
| time/               |          |
|    episodes         | 15500    |
|    fps              | 157      |
|    time_elapsed     | 1719     |
|    total_timesteps  | 270252   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 57562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.00214 |
|    exploration_rate | 0.36     |
| time/               |          |
|    episodes         | 15504    |
|    fps              | 157      |
|    time_elapsed     | 1719     |
|    total_timesteps  | 270317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 57579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00805  |
|    exploration_rate | 0.36     |
| time/               |          |
|    episodes         | 15508    |
|    fps              | 157      |
|    time_elapsed     | 1719     |
|    total_timesteps  | 270373   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 57593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00806  |
|    exploration_rate | 0.36     |
| time/               |          |
|    episodes         | 15512    |
|    fps              | 157      |
|    time_elapsed     | 1719     |
|    total_timesteps  | 270432   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00431  |
|    n_updates        | 57607    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00806  |
|    exploration_rate | 0.359    |
| time/               |          |
|    episodes         | 15516    |
|    fps              | 157      |
|    time_elapsed     | 1719     |
|    total_timesteps  | 270499   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00935  |
|    n_updates        | 57624    |
----------------------------------
Eval num_timesteps=270500, episode_reward=0.00 +/- 0.24
Episode length: 14.78 +/- 0.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 14.8     |
|    mean_reward     | 0.00192  |
| time/              |          |
|    total_timesteps | 270500   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00786  |
|    exploration_rate | 0.359    |
| time/               |          |
|    episodes         | 15520    |
|    fps              | 157      |
|    time_elapsed     | 1720     |
|    total_timesteps  | 270564   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 57640    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.00221 |
|    exploration_rate | 0.359    |
| time/               |          |
|    episodes         | 15524    |
|    fps              | 157      |
|    time_elapsed     | 1721     |
|    total_timesteps  | 270630   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00421  |
|    n_updates        | 57657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.00217 |
|    exploration_rate | 0.359    |
| time/               |          |
|    episodes         | 15528    |
|    fps              | 157      |
|    time_elapsed     | 1721     |
|    total_timesteps  | 270694   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00431  |
|    n_updates        | 57673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00801  |
|    exploration_rate | 0.358    |
| time/               |          |
|    episodes         | 15532    |
|    fps              | 157      |
|    time_elapsed     | 1721     |
|    total_timesteps  | 270753   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 57688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.00169 |
|    exploration_rate | 0.358    |
| time/               |          |
|    episodes         | 15536    |
|    fps              | 157      |
|    time_elapsed     | 1721     |
|    total_timesteps  | 270815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 57703    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.00173 |
|    exploration_rate | 0.358    |
| time/               |          |
|    episodes         | 15540    |
|    fps              | 157      |
|    time_elapsed     | 1721     |
|    total_timesteps  | 270876   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00397  |
|    n_updates        | 57718    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.358    |
| time/               |          |
|    episodes         | 15544    |
|    fps              | 157      |
|    time_elapsed     | 1721     |
|    total_timesteps  | 270936   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00623  |
|    n_updates        | 57733    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.357    |
| time/               |          |
|    episodes         | 15548    |
|    fps              | 157      |
|    time_elapsed     | 1721     |
|    total_timesteps  | 270999   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00235  |
|    n_updates        | 57749    |
----------------------------------
Eval num_timesteps=271000, episode_reward=-0.02 +/- 0.20
Episode length: 15.26 +/- 1.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 15.3     |
|    mean_reward     | -0.02    |
| time/              |          |
|    total_timesteps | 271000   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.357    |
| time/               |          |
|    episodes         | 15552    |
|    fps              | 157      |
|    time_elapsed     | 1722     |
|    total_timesteps  | 271061   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 57765    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.357    |
| time/               |          |
|    episodes         | 15556    |
|    fps              | 157      |
|    time_elapsed     | 1722     |
|    total_timesteps  | 271126   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00463  |
|    n_updates        | 57781    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.357    |
| time/               |          |
|    episodes         | 15560    |
|    fps              | 157      |
|    time_elapsed     | 1723     |
|    total_timesteps  | 271190   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000852 |
|    n_updates        | 57797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.356    |
| time/               |          |
|    episodes         | 15564    |
|    fps              | 157      |
|    time_elapsed     | 1723     |
|    total_timesteps  | 271257   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 57814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 0.356    |
| time/               |          |
|    episodes         | 15568    |
|    fps              | 157      |
|    time_elapsed     | 1723     |
|    total_timesteps  | 271322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00281  |
|    n_updates        | 57830    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0215  |
|    exploration_rate | 0.356    |
| time/               |          |
|    episodes         | 15572    |
|    fps              | 157      |
|    time_elapsed     | 1723     |
|    total_timesteps  | 271384   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00276  |
|    n_updates        | 57845    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0216  |
|    exploration_rate | 0.356    |
| time/               |          |
|    episodes         | 15576    |
|    fps              | 157      |
|    time_elapsed     | 1723     |
|    total_timesteps  | 271445   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00272  |
|    n_updates        | 57861    |
----------------------------------
Eval num_timesteps=271500, episode_reward=-0.06 +/- 0.01
Episode length: 16.08 +/- 2.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0633  |
| rollout/            |          |
|    exploration_rate | 0.355    |
| time/               |          |
|    total_timesteps  | 271500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 57874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.355    |
| time/               |          |
|    episodes         | 15580    |
|    fps              | 157      |
|    time_elapsed     | 1724     |
|    total_timesteps  | 271509   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00842  |
|    n_updates        | 57877    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00832  |
|    exploration_rate | 0.355    |
| time/               |          |
|    episodes         | 15584    |
|    fps              | 157      |
|    time_elapsed     | 1724     |
|    total_timesteps  | 271573   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00268  |
|    n_updates        | 57893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00808  |
|    exploration_rate | 0.355    |
| time/               |          |
|    episodes         | 15588    |
|    fps              | 157      |
|    time_elapsed     | 1724     |
|    total_timesteps  | 271640   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00456  |
|    n_updates        | 57909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00764  |
|    exploration_rate | 0.354    |
| time/               |          |
|    episodes         | 15592    |
|    fps              | 157      |
|    time_elapsed     | 1724     |
|    total_timesteps  | 271713   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00278  |
|    n_updates        | 57928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00716  |
|    exploration_rate | 0.354    |
| time/               |          |
|    episodes         | 15596    |
|    fps              | 157      |
|    time_elapsed     | 1725     |
|    total_timesteps  | 271787   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 57946    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00712  |
|    exploration_rate | 0.354    |
| time/               |          |
|    episodes         | 15600    |
|    fps              | 157      |
|    time_elapsed     | 1725     |
|    total_timesteps  | 271850   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 57962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00732  |
|    exploration_rate | 0.354    |
| time/               |          |
|    episodes         | 15604    |
|    fps              | 157      |
|    time_elapsed     | 1725     |
|    total_timesteps  | 271910   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 57977    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.353    |
| time/               |          |
|    episodes         | 15608    |
|    fps              | 157      |
|    time_elapsed     | 1725     |
|    total_timesteps  | 271964   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00502  |
|    n_updates        | 57990    |
----------------------------------
Eval num_timesteps=272000, episode_reward=0.12 +/- 0.39
Episode length: 14.60 +/- 1.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.123    |
| rollout/            |          |
|    exploration_rate | 0.353    |
| time/               |          |
|    total_timesteps  | 272000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00246  |
|    n_updates        | 57999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.353    |
| time/               |          |
|    episodes         | 15612    |
|    fps              | 157      |
|    time_elapsed     | 1726     |
|    total_timesteps  | 272023   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00255  |
|    n_updates        | 58005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.353    |
| time/               |          |
|    episodes         | 15616    |
|    fps              | 157      |
|    time_elapsed     | 1726     |
|    total_timesteps  | 272090   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0037   |
|    n_updates        | 58022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.353    |
| time/               |          |
|    episodes         | 15620    |
|    fps              | 157      |
|    time_elapsed     | 1726     |
|    total_timesteps  | 272153   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00199  |
|    n_updates        | 58038    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 0.352    |
| time/               |          |
|    episodes         | 15624    |
|    fps              | 157      |
|    time_elapsed     | 1726     |
|    total_timesteps  | 272234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0026   |
|    n_updates        | 58058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.352    |
| time/               |          |
|    episodes         | 15628    |
|    fps              | 157      |
|    time_elapsed     | 1726     |
|    total_timesteps  | 272301   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00605  |
|    n_updates        | 58075    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0063   |
|    exploration_rate | 0.352    |
| time/               |          |
|    episodes         | 15632    |
|    fps              | 157      |
|    time_elapsed     | 1726     |
|    total_timesteps  | 272371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00311  |
|    n_updates        | 58092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0161   |
|    exploration_rate | 0.351    |
| time/               |          |
|    episodes         | 15636    |
|    fps              | 157      |
|    time_elapsed     | 1727     |
|    total_timesteps  | 272437   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 58109    |
----------------------------------
Eval num_timesteps=272500, episode_reward=0.04 +/- 0.30
Episode length: 15.26 +/- 2.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | 0.04     |
| rollout/            |          |
|    exploration_rate | 0.351    |
| time/               |          |
|    total_timesteps  | 272500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0103   |
|    n_updates        | 58124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.016    |
|    exploration_rate | 0.351    |
| time/               |          |
|    episodes         | 15640    |
|    fps              | 157      |
|    time_elapsed     | 1728     |
|    total_timesteps  | 272502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00368  |
|    n_updates        | 58125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0157   |
|    exploration_rate | 0.351    |
| time/               |          |
|    episodes         | 15644    |
|    fps              | 157      |
|    time_elapsed     | 1728     |
|    total_timesteps  | 272570   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0052   |
|    n_updates        | 58142    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0157   |
|    exploration_rate | 0.351    |
| time/               |          |
|    episodes         | 15648    |
|    fps              | 157      |
|    time_elapsed     | 1728     |
|    total_timesteps  | 272631   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 58157    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0349   |
|    exploration_rate | 0.35     |
| time/               |          |
|    episodes         | 15652    |
|    fps              | 157      |
|    time_elapsed     | 1728     |
|    total_timesteps  | 272713   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00287  |
|    n_updates        | 58178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.045    |
|    exploration_rate | 0.35     |
| time/               |          |
|    episodes         | 15656    |
|    fps              | 157      |
|    time_elapsed     | 1728     |
|    total_timesteps  | 272778   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 58194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0448   |
|    exploration_rate | 0.35     |
| time/               |          |
|    episodes         | 15660    |
|    fps              | 157      |
|    time_elapsed     | 1728     |
|    total_timesteps  | 272845   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 58211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0549   |
|    exploration_rate | 0.349    |
| time/               |          |
|    episodes         | 15664    |
|    fps              | 157      |
|    time_elapsed     | 1728     |
|    total_timesteps  | 272910   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 58227    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0548   |
|    exploration_rate | 0.349    |
| time/               |          |
|    episodes         | 15668    |
|    fps              | 157      |
|    time_elapsed     | 1729     |
|    total_timesteps  | 272977   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00269  |
|    n_updates        | 58244    |
----------------------------------
Eval num_timesteps=273000, episode_reward=-0.05 +/- 0.13
Episode length: 18.64 +/- 6.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.6     |
|    mean_reward      | -0.0535  |
| rollout/            |          |
|    exploration_rate | 0.349    |
| time/               |          |
|    total_timesteps  | 273000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00623  |
|    n_updates        | 58249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0548   |
|    exploration_rate | 0.349    |
| time/               |          |
|    episodes         | 15672    |
|    fps              | 157      |
|    time_elapsed     | 1730     |
|    total_timesteps  | 273039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 58259    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.055    |
|    exploration_rate | 0.349    |
| time/               |          |
|    episodes         | 15676    |
|    fps              | 157      |
|    time_elapsed     | 1730     |
|    total_timesteps  | 273095   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 58273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0452   |
|    exploration_rate | 0.348    |
| time/               |          |
|    episodes         | 15680    |
|    fps              | 157      |
|    time_elapsed     | 1730     |
|    total_timesteps  | 273156   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 58288    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.348    |
| time/               |          |
|    episodes         | 15684    |
|    fps              | 157      |
|    time_elapsed     | 1730     |
|    total_timesteps  | 273222   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00495  |
|    n_updates        | 58305    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.348    |
| time/               |          |
|    episodes         | 15688    |
|    fps              | 157      |
|    time_elapsed     | 1730     |
|    total_timesteps  | 273290   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00406  |
|    n_updates        | 58322    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0254   |
|    exploration_rate | 0.348    |
| time/               |          |
|    episodes         | 15692    |
|    fps              | 157      |
|    time_elapsed     | 1730     |
|    total_timesteps  | 273352   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0018   |
|    n_updates        | 58337    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0258   |
|    exploration_rate | 0.347    |
| time/               |          |
|    episodes         | 15696    |
|    fps              | 157      |
|    time_elapsed     | 1731     |
|    total_timesteps  | 273418   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00231  |
|    n_updates        | 58354    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0254   |
|    exploration_rate | 0.347    |
| time/               |          |
|    episodes         | 15700    |
|    fps              | 157      |
|    time_elapsed     | 1731     |
|    total_timesteps  | 273489   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 58372    |
----------------------------------
Eval num_timesteps=273500, episode_reward=-0.04 +/- 0.19
Episode length: 19.68 +/- 9.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.7     |
|    mean_reward      | -0.0377  |
| rollout/            |          |
|    exploration_rate | 0.347    |
| time/               |          |
|    total_timesteps  | 273500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0021   |
|    n_updates        | 58374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.347    |
| time/               |          |
|    episodes         | 15704    |
|    fps              | 157      |
|    time_elapsed     | 1732     |
|    total_timesteps  | 273553   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00213  |
|    n_updates        | 58388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00462  |
|    exploration_rate | 0.346    |
| time/               |          |
|    episodes         | 15708    |
|    fps              | 157      |
|    time_elapsed     | 1732     |
|    total_timesteps  | 273624   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 58405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00406  |
|    exploration_rate | 0.346    |
| time/               |          |
|    episodes         | 15712    |
|    fps              | 157      |
|    time_elapsed     | 1732     |
|    total_timesteps  | 273697   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 58424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00402  |
|    exploration_rate | 0.346    |
| time/               |          |
|    episodes         | 15716    |
|    fps              | 157      |
|    time_elapsed     | 1732     |
|    total_timesteps  | 273765   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 58441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0138   |
|    exploration_rate | 0.346    |
| time/               |          |
|    episodes         | 15720    |
|    fps              | 158      |
|    time_elapsed     | 1732     |
|    total_timesteps  | 273833   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 58458    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0141   |
|    exploration_rate | 0.345    |
| time/               |          |
|    episodes         | 15724    |
|    fps              | 158      |
|    time_elapsed     | 1733     |
|    total_timesteps  | 273907   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00191  |
|    n_updates        | 58476    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.345    |
| time/               |          |
|    episodes         | 15728    |
|    fps              | 158      |
|    time_elapsed     | 1733     |
|    total_timesteps  | 273979   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00257  |
|    n_updates        | 58494    |
----------------------------------
Eval num_timesteps=274000, episode_reward=-0.03 +/- 0.26
Episode length: 27.14 +/- 13.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 27.1     |
|    mean_reward      | -0.0276  |
| rollout/            |          |
|    exploration_rate | 0.345    |
| time/               |          |
|    total_timesteps  | 274000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 58499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.345    |
| time/               |          |
|    episodes         | 15732    |
|    fps              | 157      |
|    time_elapsed     | 1735     |
|    total_timesteps  | 274046   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.011    |
|    n_updates        | 58511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00391  |
|    exploration_rate | 0.344    |
| time/               |          |
|    episodes         | 15736    |
|    fps              | 157      |
|    time_elapsed     | 1735     |
|    total_timesteps  | 274115   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00282  |
|    n_updates        | 58528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00383  |
|    exploration_rate | 0.344    |
| time/               |          |
|    episodes         | 15740    |
|    fps              | 157      |
|    time_elapsed     | 1735     |
|    total_timesteps  | 274182   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 58545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00339  |
|    exploration_rate | 0.344    |
| time/               |          |
|    episodes         | 15744    |
|    fps              | 158      |
|    time_elapsed     | 1735     |
|    total_timesteps  | 274261   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 58565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00319  |
|    exploration_rate | 0.343    |
| time/               |          |
|    episodes         | 15748    |
|    fps              | 158      |
|    time_elapsed     | 1735     |
|    total_timesteps  | 274327   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 58581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.343    |
| time/               |          |
|    episodes         | 15752    |
|    fps              | 158      |
|    time_elapsed     | 1735     |
|    total_timesteps  | 274398   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 58599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0163  |
|    exploration_rate | 0.343    |
| time/               |          |
|    episodes         | 15756    |
|    fps              | 158      |
|    time_elapsed     | 1735     |
|    total_timesteps  | 274460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 58614    |
----------------------------------
Eval num_timesteps=274500, episode_reward=-0.07 +/- 0.01
Episode length: 17.20 +/- 3.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.2     |
|    mean_reward      | -0.0678  |
| rollout/            |          |
|    exploration_rate | 0.343    |
| time/               |          |
|    total_timesteps  | 274500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 58624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0165  |
|    exploration_rate | 0.343    |
| time/               |          |
|    episodes         | 15760    |
|    fps              | 158      |
|    time_elapsed     | 1737     |
|    total_timesteps  | 274532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00345  |
|    n_updates        | 58632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0163  |
|    exploration_rate | 0.342    |
| time/               |          |
|    episodes         | 15764    |
|    fps              | 158      |
|    time_elapsed     | 1737     |
|    total_timesteps  | 274594   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 58648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0161  |
|    exploration_rate | 0.342    |
| time/               |          |
|    episodes         | 15768    |
|    fps              | 158      |
|    time_elapsed     | 1737     |
|    total_timesteps  | 274655   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.003    |
|    n_updates        | 58663    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0161  |
|    exploration_rate | 0.342    |
| time/               |          |
|    episodes         | 15772    |
|    fps              | 158      |
|    time_elapsed     | 1737     |
|    total_timesteps  | 274718   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00242  |
|    n_updates        | 58679    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0264  |
|    exploration_rate | 0.342    |
| time/               |          |
|    episodes         | 15776    |
|    fps              | 158      |
|    time_elapsed     | 1737     |
|    total_timesteps  | 274781   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00338  |
|    n_updates        | 58695    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0265  |
|    exploration_rate | 0.341    |
| time/               |          |
|    episodes         | 15780    |
|    fps              | 158      |
|    time_elapsed     | 1737     |
|    total_timesteps  | 274843   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 58710    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0267  |
|    exploration_rate | 0.341    |
| time/               |          |
|    episodes         | 15784    |
|    fps              | 158      |
|    time_elapsed     | 1737     |
|    total_timesteps  | 274914   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 58728    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0266  |
|    exploration_rate | 0.341    |
| time/               |          |
|    episodes         | 15788    |
|    fps              | 158      |
|    time_elapsed     | 1737     |
|    total_timesteps  | 274981   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 58745    |
----------------------------------
Eval num_timesteps=275000, episode_reward=-0.02 +/- 0.20
Episode length: 15.48 +/- 1.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.5     |
|    mean_reward      | -0.0209  |
| rollout/            |          |
|    exploration_rate | 0.341    |
| time/               |          |
|    total_timesteps  | 275000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00283  |
|    n_updates        | 58749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.34     |
| time/               |          |
|    episodes         | 15792    |
|    fps              | 158      |
|    time_elapsed     | 1739     |
|    total_timesteps  | 275037   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 58759    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00614 |
|    exploration_rate | 0.34     |
| time/               |          |
|    episodes         | 15796    |
|    fps              | 158      |
|    time_elapsed     | 1739     |
|    total_timesteps  | 275097   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 58774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0044   |
|    exploration_rate | 0.34     |
| time/               |          |
|    episodes         | 15800    |
|    fps              | 158      |
|    time_elapsed     | 1739     |
|    total_timesteps  | 275155   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 58788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00448  |
|    exploration_rate | 0.34     |
| time/               |          |
|    episodes         | 15804    |
|    fps              | 158      |
|    time_elapsed     | 1739     |
|    total_timesteps  | 275217   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0043   |
|    n_updates        | 58804    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00476  |
|    exploration_rate | 0.339    |
| time/               |          |
|    episodes         | 15808    |
|    fps              | 158      |
|    time_elapsed     | 1739     |
|    total_timesteps  | 275281   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00432  |
|    n_updates        | 58820    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00476 |
|    exploration_rate | 0.339    |
| time/               |          |
|    episodes         | 15812    |
|    fps              | 158      |
|    time_elapsed     | 1739     |
|    total_timesteps  | 275342   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00225  |
|    n_updates        | 58835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00484 |
|    exploration_rate | 0.339    |
| time/               |          |
|    episodes         | 15816    |
|    fps              | 158      |
|    time_elapsed     | 1740     |
|    total_timesteps  | 275412   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00368  |
|    n_updates        | 58852    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.339    |
| time/               |          |
|    episodes         | 15820    |
|    fps              | 158      |
|    time_elapsed     | 1740     |
|    total_timesteps  | 275482   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 58870    |
----------------------------------
Eval num_timesteps=275500, episode_reward=-0.01 +/- 0.27
Episode length: 22.82 +/- 9.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22.8     |
|    mean_reward      | -0.0102  |
| rollout/            |          |
|    exploration_rate | 0.339    |
| time/               |          |
|    total_timesteps  | 275500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00307  |
|    n_updates        | 58874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00487 |
|    exploration_rate | 0.338    |
| time/               |          |
|    episodes         | 15824    |
|    fps              | 158      |
|    time_elapsed     | 1741     |
|    total_timesteps  | 275555   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00307  |
|    n_updates        | 58888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00463 |
|    exploration_rate | 0.338    |
| time/               |          |
|    episodes         | 15828    |
|    fps              | 158      |
|    time_elapsed     | 1741     |
|    total_timesteps  | 275621   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00692  |
|    n_updates        | 58905    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00475 |
|    exploration_rate | 0.338    |
| time/               |          |
|    episodes         | 15832    |
|    fps              | 158      |
|    time_elapsed     | 1741     |
|    total_timesteps  | 275691   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 58922    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00463 |
|    exploration_rate | 0.337    |
| time/               |          |
|    episodes         | 15836    |
|    fps              | 158      |
|    time_elapsed     | 1742     |
|    total_timesteps  | 275757   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 58939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00499 |
|    exploration_rate | 0.337    |
| time/               |          |
|    episodes         | 15840    |
|    fps              | 158      |
|    time_elapsed     | 1742     |
|    total_timesteps  | 275833   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 58958    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00439 |
|    exploration_rate | 0.337    |
| time/               |          |
|    episodes         | 15844    |
|    fps              | 158      |
|    time_elapsed     | 1742     |
|    total_timesteps  | 275897   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 58974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00419 |
|    exploration_rate | 0.337    |
| time/               |          |
|    episodes         | 15848    |
|    fps              | 158      |
|    time_elapsed     | 1742     |
|    total_timesteps  | 275958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 58989    |
----------------------------------
Eval num_timesteps=276000, episode_reward=-0.02 +/- 0.20
Episode length: 16.04 +/- 2.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.0232  |
| rollout/            |          |
|    exploration_rate | 0.336    |
| time/               |          |
|    total_timesteps  | 276000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00229  |
|    n_updates        | 58999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00383 |
|    exploration_rate | 0.336    |
| time/               |          |
|    episodes         | 15852    |
|    fps              | 158      |
|    time_elapsed     | 1743     |
|    total_timesteps  | 276020   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 59004    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.336    |
| time/               |          |
|    episodes         | 15856    |
|    fps              | 158      |
|    time_elapsed     | 1743     |
|    total_timesteps  | 276081   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000867 |
|    n_updates        | 59020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.336    |
| time/               |          |
|    episodes         | 15860    |
|    fps              | 158      |
|    time_elapsed     | 1743     |
|    total_timesteps  | 276150   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 59037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.335    |
| time/               |          |
|    episodes         | 15864    |
|    fps              | 158      |
|    time_elapsed     | 1744     |
|    total_timesteps  | 276231   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 59057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0249  |
|    exploration_rate | 0.335    |
| time/               |          |
|    episodes         | 15868    |
|    fps              | 158      |
|    time_elapsed     | 1744     |
|    total_timesteps  | 276303   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 59075    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0248  |
|    exploration_rate | 0.335    |
| time/               |          |
|    episodes         | 15872    |
|    fps              | 158      |
|    time_elapsed     | 1744     |
|    total_timesteps  | 276365   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 59091    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0247  |
|    exploration_rate | 0.335    |
| time/               |          |
|    episodes         | 15876    |
|    fps              | 158      |
|    time_elapsed     | 1744     |
|    total_timesteps  | 276425   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00251  |
|    n_updates        | 59106    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.334    |
| time/               |          |
|    episodes         | 15880    |
|    fps              | 158      |
|    time_elapsed     | 1744     |
|    total_timesteps  | 276485   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00309  |
|    n_updates        | 59121    |
----------------------------------
Eval num_timesteps=276500, episode_reward=-0.05 +/- 0.23
Episode length: 28.24 +/- 16.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28.2     |
|    mean_reward      | -0.0519  |
| rollout/            |          |
|    exploration_rate | 0.334    |
| time/               |          |
|    total_timesteps  | 276500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00375  |
|    n_updates        | 59124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0243  |
|    exploration_rate | 0.334    |
| time/               |          |
|    episodes         | 15884    |
|    fps              | 158      |
|    time_elapsed     | 1746     |
|    total_timesteps  | 276547   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00548  |
|    n_updates        | 59136    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.334    |
| time/               |          |
|    episodes         | 15888    |
|    fps              | 158      |
|    time_elapsed     | 1746     |
|    total_timesteps  | 276618   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 59154    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.334    |
| time/               |          |
|    episodes         | 15892    |
|    fps              | 158      |
|    time_elapsed     | 1746     |
|    total_timesteps  | 276681   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0084   |
|    n_updates        | 59170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0346  |
|    exploration_rate | 0.333    |
| time/               |          |
|    episodes         | 15896    |
|    fps              | 158      |
|    time_elapsed     | 1746     |
|    total_timesteps  | 276739   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 59184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0447  |
|    exploration_rate | 0.333    |
| time/               |          |
|    episodes         | 15900    |
|    fps              | 158      |
|    time_elapsed     | 1746     |
|    total_timesteps  | 276799   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00255  |
|    n_updates        | 59199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0448  |
|    exploration_rate | 0.333    |
| time/               |          |
|    episodes         | 15904    |
|    fps              | 158      |
|    time_elapsed     | 1746     |
|    total_timesteps  | 276864   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 59215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0447  |
|    exploration_rate | 0.333    |
| time/               |          |
|    episodes         | 15908    |
|    fps              | 158      |
|    time_elapsed     | 1747     |
|    total_timesteps  | 276925   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 59231    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.332    |
| time/               |          |
|    episodes         | 15912    |
|    fps              | 158      |
|    time_elapsed     | 1747     |
|    total_timesteps  | 276977   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 59244    |
----------------------------------
Eval num_timesteps=277000, episode_reward=0.02 +/- 0.27
Episode length: 16.00 +/- 2.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.017    |
| rollout/            |          |
|    exploration_rate | 0.332    |
| time/               |          |
|    total_timesteps  | 277000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00298  |
|    n_updates        | 59249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.332    |
| time/               |          |
|    episodes         | 15916    |
|    fps              | 158      |
|    time_elapsed     | 1748     |
|    total_timesteps  | 277034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00608  |
|    n_updates        | 59258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.332    |
| time/               |          |
|    episodes         | 15920    |
|    fps              | 158      |
|    time_elapsed     | 1748     |
|    total_timesteps  | 277103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 59275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.331    |
| time/               |          |
|    episodes         | 15924    |
|    fps              | 158      |
|    time_elapsed     | 1748     |
|    total_timesteps  | 277168   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00339  |
|    n_updates        | 59291    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.331    |
| time/               |          |
|    episodes         | 15928    |
|    fps              | 158      |
|    time_elapsed     | 1748     |
|    total_timesteps  | 277228   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 59306    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.331    |
| time/               |          |
|    episodes         | 15932    |
|    fps              | 158      |
|    time_elapsed     | 1748     |
|    total_timesteps  | 277297   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00438  |
|    n_updates        | 59324    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.331    |
| time/               |          |
|    episodes         | 15936    |
|    fps              | 158      |
|    time_elapsed     | 1748     |
|    total_timesteps  | 277358   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00211  |
|    n_updates        | 59339    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 0.33     |
| time/               |          |
|    episodes         | 15940    |
|    fps              | 158      |
|    time_elapsed     | 1748     |
|    total_timesteps  | 277419   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00326  |
|    n_updates        | 59354    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.33     |
| time/               |          |
|    episodes         | 15944    |
|    fps              | 158      |
|    time_elapsed     | 1749     |
|    total_timesteps  | 277489   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00332  |
|    n_updates        | 59372    |
----------------------------------
Eval num_timesteps=277500, episode_reward=0.02 +/- 0.28
Episode length: 19.04 +/- 6.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19       |
|    mean_reward      | 0.0248   |
| rollout/            |          |
|    exploration_rate | 0.33     |
| time/               |          |
|    total_timesteps  | 277500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 59374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.33     |
| time/               |          |
|    episodes         | 15948    |
|    fps              | 158      |
|    time_elapsed     | 1750     |
|    total_timesteps  | 277558   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00207  |
|    n_updates        | 59389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00296 |
|    exploration_rate | 0.33     |
| time/               |          |
|    episodes         | 15952    |
|    fps              | 158      |
|    time_elapsed     | 1750     |
|    total_timesteps  | 277619   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00191  |
|    n_updates        | 59404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00304 |
|    exploration_rate | 0.329    |
| time/               |          |
|    episodes         | 15956    |
|    fps              | 158      |
|    time_elapsed     | 1750     |
|    total_timesteps  | 277682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 59420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00276 |
|    exploration_rate | 0.329    |
| time/               |          |
|    episodes         | 15960    |
|    fps              | 158      |
|    time_elapsed     | 1750     |
|    total_timesteps  | 277744   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00284  |
|    n_updates        | 59435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.00192 |
|    exploration_rate | 0.329    |
| time/               |          |
|    episodes         | 15964    |
|    fps              | 158      |
|    time_elapsed     | 1750     |
|    total_timesteps  | 277804   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 59450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.00857  |
|    exploration_rate | 0.329    |
| time/               |          |
|    episodes         | 15968    |
|    fps              | 158      |
|    time_elapsed     | 1751     |
|    total_timesteps  | 277864   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00709  |
|    n_updates        | 59465    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.00853  |
|    exploration_rate | 0.328    |
| time/               |          |
|    episodes         | 15972    |
|    fps              | 158      |
|    time_elapsed     | 1751     |
|    total_timesteps  | 277927   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00245  |
|    n_updates        | 59481    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.00837  |
|    exploration_rate | 0.328    |
| time/               |          |
|    episodes         | 15976    |
|    fps              | 158      |
|    time_elapsed     | 1751     |
|    total_timesteps  | 277991   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00274  |
|    n_updates        | 59497    |
----------------------------------
Eval num_timesteps=278000, episode_reward=0.02 +/- 0.27
Episode length: 15.18 +/- 1.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.2     |
|    mean_reward      | 0.0203   |
| rollout/            |          |
|    exploration_rate | 0.328    |
| time/               |          |
|    total_timesteps  | 278000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 59499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 0.328    |
| time/               |          |
|    episodes         | 15980    |
|    fps              | 158      |
|    time_elapsed     | 1752     |
|    total_timesteps  | 278047   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00252  |
|    n_updates        | 59511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 0.328    |
| time/               |          |
|    episodes         | 15984    |
|    fps              | 158      |
|    time_elapsed     | 1752     |
|    total_timesteps  | 278110   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00484  |
|    n_updates        | 59527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.327    |
| time/               |          |
|    episodes         | 15988    |
|    fps              | 158      |
|    time_elapsed     | 1752     |
|    total_timesteps  | 278176   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00207  |
|    n_updates        | 59543    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.327    |
| time/               |          |
|    episodes         | 15992    |
|    fps              | 158      |
|    time_elapsed     | 1752     |
|    total_timesteps  | 278242   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 59560    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.00842  |
|    exploration_rate | 0.327    |
| time/               |          |
|    episodes         | 15996    |
|    fps              | 158      |
|    time_elapsed     | 1752     |
|    total_timesteps  | 278303   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 59575    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00782  |
|    exploration_rate | 0.326    |
| time/               |          |
|    episodes         | 16000    |
|    fps              | 158      |
|    time_elapsed     | 1752     |
|    total_timesteps  | 278378   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00766  |
|    n_updates        | 59594    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.326    |
| time/               |          |
|    episodes         | 16004    |
|    fps              | 158      |
|    time_elapsed     | 1753     |
|    total_timesteps  | 278436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00677  |
|    n_updates        | 59608    |
----------------------------------
Eval num_timesteps=278500, episode_reward=-0.05 +/- 0.15
Episode length: 17.72 +/- 8.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.7     |
|    mean_reward      | -0.0499  |
| rollout/            |          |
|    exploration_rate | 0.326    |
| time/               |          |
|    total_timesteps  | 278500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 59624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.326    |
| time/               |          |
|    episodes         | 16008    |
|    fps              | 158      |
|    time_elapsed     | 1754     |
|    total_timesteps  | 278500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00738  |
|    exploration_rate | 0.326    |
| time/               |          |
|    episodes         | 16012    |
|    fps              | 158      |
|    time_elapsed     | 1754     |
|    total_timesteps  | 278568   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00317  |
|    n_updates        | 59641    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00302 |
|    exploration_rate | 0.325    |
| time/               |          |
|    episodes         | 16016    |
|    fps              | 158      |
|    time_elapsed     | 1754     |
|    total_timesteps  | 278635   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 59658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0027  |
|    exploration_rate | 0.325    |
| time/               |          |
|    episodes         | 16020    |
|    fps              | 158      |
|    time_elapsed     | 1754     |
|    total_timesteps  | 278696   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 59673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00262 |
|    exploration_rate | 0.325    |
| time/               |          |
|    episodes         | 16024    |
|    fps              | 158      |
|    time_elapsed     | 1754     |
|    total_timesteps  | 278759   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 59689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00727  |
|    exploration_rate | 0.324    |
| time/               |          |
|    episodes         | 16028    |
|    fps              | 158      |
|    time_elapsed     | 1755     |
|    total_timesteps  | 278822   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 59705    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00747  |
|    exploration_rate | 0.324    |
| time/               |          |
|    episodes         | 16032    |
|    fps              | 158      |
|    time_elapsed     | 1755     |
|    total_timesteps  | 278886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00288  |
|    n_updates        | 59721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00257 |
|    exploration_rate | 0.324    |
| time/               |          |
|    episodes         | 16036    |
|    fps              | 158      |
|    time_elapsed     | 1755     |
|    total_timesteps  | 278948   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 59736    |
----------------------------------
Eval num_timesteps=279000, episode_reward=0.02 +/- 0.27
Episode length: 15.04 +/- 1.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | 0.0209   |
| rollout/            |          |
|    exploration_rate | 0.324    |
| time/               |          |
|    total_timesteps  | 279000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00189  |
|    n_updates        | 59749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00273 |
|    exploration_rate | 0.324    |
| time/               |          |
|    episodes         | 16040    |
|    fps              | 158      |
|    time_elapsed     | 1756     |
|    total_timesteps  | 279013   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00211  |
|    n_updates        | 59753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00253 |
|    exploration_rate | 0.323    |
| time/               |          |
|    episodes         | 16044    |
|    fps              | 158      |
|    time_elapsed     | 1756     |
|    total_timesteps  | 279078   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 59769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.00762  |
|    exploration_rate | 0.323    |
| time/               |          |
|    episodes         | 16048    |
|    fps              | 158      |
|    time_elapsed     | 1756     |
|    total_timesteps  | 279143   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00201  |
|    n_updates        | 59785    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00277 |
|    exploration_rate | 0.323    |
| time/               |          |
|    episodes         | 16052    |
|    fps              | 158      |
|    time_elapsed     | 1756     |
|    total_timesteps  | 279214   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 59803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00301 |
|    exploration_rate | 0.323    |
| time/               |          |
|    episodes         | 16056    |
|    fps              | 158      |
|    time_elapsed     | 1756     |
|    total_timesteps  | 279283   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 59820    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00313 |
|    exploration_rate | 0.322    |
| time/               |          |
|    episodes         | 16060    |
|    fps              | 158      |
|    time_elapsed     | 1757     |
|    total_timesteps  | 279348   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00261  |
|    n_updates        | 59836    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00696  |
|    exploration_rate | 0.322    |
| time/               |          |
|    episodes         | 16064    |
|    fps              | 159      |
|    time_elapsed     | 1757     |
|    total_timesteps  | 279406   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 59851    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00317 |
|    exploration_rate | 0.322    |
| time/               |          |
|    episodes         | 16068    |
|    fps              | 159      |
|    time_elapsed     | 1757     |
|    total_timesteps  | 279469   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00531  |
|    n_updates        | 59867    |
----------------------------------
Eval num_timesteps=279500, episode_reward=-0.05 +/- 0.13
Episode length: 17.64 +/- 4.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.6     |
|    mean_reward      | -0.0496  |
| rollout/            |          |
|    exploration_rate | 0.322    |
| time/               |          |
|    total_timesteps  | 279500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00302  |
|    n_updates        | 59874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00333 |
|    exploration_rate | 0.321    |
| time/               |          |
|    episodes         | 16072    |
|    fps              | 158      |
|    time_elapsed     | 1758     |
|    total_timesteps  | 279536   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 59883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00341 |
|    exploration_rate | 0.321    |
| time/               |          |
|    episodes         | 16076    |
|    fps              | 158      |
|    time_elapsed     | 1758     |
|    total_timesteps  | 279602   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 59900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.014   |
|    exploration_rate | 0.321    |
| time/               |          |
|    episodes         | 16080    |
|    fps              | 159      |
|    time_elapsed     | 1758     |
|    total_timesteps  | 279672   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00427  |
|    n_updates        | 59917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.014   |
|    exploration_rate | 0.321    |
| time/               |          |
|    episodes         | 16084    |
|    fps              | 159      |
|    time_elapsed     | 1758     |
|    total_timesteps  | 279737   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00724  |
|    n_updates        | 59934    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.32     |
| time/               |          |
|    episodes         | 16088    |
|    fps              | 159      |
|    time_elapsed     | 1758     |
|    total_timesteps  | 279806   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0095   |
|    n_updates        | 59951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00391 |
|    exploration_rate | 0.32     |
| time/               |          |
|    episodes         | 16092    |
|    fps              | 159      |
|    time_elapsed     | 1759     |
|    total_timesteps  | 279866   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00356  |
|    n_updates        | 59966    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00407 |
|    exploration_rate | 0.32     |
| time/               |          |
|    episodes         | 16096    |
|    fps              | 159      |
|    time_elapsed     | 1759     |
|    total_timesteps  | 279931   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 59982    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00371 |
|    exploration_rate | 0.319    |
| time/               |          |
|    episodes         | 16100    |
|    fps              | 159      |
|    time_elapsed     | 1759     |
|    total_timesteps  | 279997   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00468  |
|    n_updates        | 59999    |
----------------------------------
Eval num_timesteps=280000, episode_reward=-0.02 +/- 0.20
Episode length: 16.04 +/- 2.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.0231  |
| rollout/            |          |
|    exploration_rate | 0.319    |
| time/               |          |
|    total_timesteps  | 280000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 0.319    |
| time/               |          |
|    episodes         | 16104    |
|    fps              | 159      |
|    time_elapsed     | 1760     |
|    total_timesteps  | 280062   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00268  |
|    n_updates        | 60015    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 0.319    |
| time/               |          |
|    episodes         | 16108    |
|    fps              | 159      |
|    time_elapsed     | 1760     |
|    total_timesteps  | 280125   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00388  |
|    n_updates        | 60031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.319    |
| time/               |          |
|    episodes         | 16112    |
|    fps              | 159      |
|    time_elapsed     | 1760     |
|    total_timesteps  | 280187   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00338  |
|    n_updates        | 60046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.318    |
| time/               |          |
|    episodes         | 16116    |
|    fps              | 159      |
|    time_elapsed     | 1760     |
|    total_timesteps  | 280248   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00402  |
|    n_updates        | 60061    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.318    |
| time/               |          |
|    episodes         | 16120    |
|    fps              | 159      |
|    time_elapsed     | 1760     |
|    total_timesteps  | 280308   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0043   |
|    n_updates        | 60076    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.318    |
| time/               |          |
|    episodes         | 16124    |
|    fps              | 159      |
|    time_elapsed     | 1760     |
|    total_timesteps  | 280370   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 60092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.318    |
| time/               |          |
|    episodes         | 16128    |
|    fps              | 159      |
|    time_elapsed     | 1761     |
|    total_timesteps  | 280436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 60108    |
----------------------------------
Eval num_timesteps=280500, episode_reward=-0.07 +/- 0.21
Episode length: 26.54 +/- 18.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 26.5     |
|    mean_reward      | -0.0653  |
| rollout/            |          |
|    exploration_rate | 0.317    |
| time/               |          |
|    total_timesteps  | 280500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 60124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.317    |
| time/               |          |
|    episodes         | 16132    |
|    fps              | 159      |
|    time_elapsed     | 1762     |
|    total_timesteps  | 280506   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 60126    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.014   |
|    exploration_rate | 0.317    |
| time/               |          |
|    episodes         | 16136    |
|    fps              | 159      |
|    time_elapsed     | 1762     |
|    total_timesteps  | 280574   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00844  |
|    n_updates        | 60143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.317    |
| time/               |          |
|    episodes         | 16140    |
|    fps              | 159      |
|    time_elapsed     | 1762     |
|    total_timesteps  | 280635   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00254  |
|    n_updates        | 60158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.317    |
| time/               |          |
|    episodes         | 16144    |
|    fps              | 159      |
|    time_elapsed     | 1763     |
|    total_timesteps  | 280699   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0027   |
|    n_updates        | 60174    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.316    |
| time/               |          |
|    episodes         | 16148    |
|    fps              | 159      |
|    time_elapsed     | 1763     |
|    total_timesteps  | 280760   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00404  |
|    n_updates        | 60189    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0236  |
|    exploration_rate | 0.316    |
| time/               |          |
|    episodes         | 16152    |
|    fps              | 159      |
|    time_elapsed     | 1763     |
|    total_timesteps  | 280830   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00493  |
|    n_updates        | 60207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.316    |
| time/               |          |
|    episodes         | 16156    |
|    fps              | 159      |
|    time_elapsed     | 1763     |
|    total_timesteps  | 280890   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 60222    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.315    |
| time/               |          |
|    episodes         | 16160    |
|    fps              | 159      |
|    time_elapsed     | 1763     |
|    total_timesteps  | 280956   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 60238    |
----------------------------------
Eval num_timesteps=281000, episode_reward=0.04 +/- 0.30
Episode length: 14.68 +/- 1.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0423   |
| rollout/            |          |
|    exploration_rate | 0.315    |
| time/               |          |
|    total_timesteps  | 281000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00544  |
|    n_updates        | 60249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0334  |
|    exploration_rate | 0.315    |
| time/               |          |
|    episodes         | 16164    |
|    fps              | 159      |
|    time_elapsed     | 1764     |
|    total_timesteps  | 281016   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 60253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.315    |
| time/               |          |
|    episodes         | 16168    |
|    fps              | 159      |
|    time_elapsed     | 1764     |
|    total_timesteps  | 281073   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 60268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.315    |
| time/               |          |
|    episodes         | 16172    |
|    fps              | 159      |
|    time_elapsed     | 1764     |
|    total_timesteps  | 281149   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00388  |
|    n_updates        | 60287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.314    |
| time/               |          |
|    episodes         | 16176    |
|    fps              | 159      |
|    time_elapsed     | 1765     |
|    total_timesteps  | 281212   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00269  |
|    n_updates        | 60302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.314    |
| time/               |          |
|    episodes         | 16180    |
|    fps              | 159      |
|    time_elapsed     | 1765     |
|    total_timesteps  | 281281   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 60320    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.314    |
| time/               |          |
|    episodes         | 16184    |
|    fps              | 159      |
|    time_elapsed     | 1765     |
|    total_timesteps  | 281343   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 60335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.314    |
| time/               |          |
|    episodes         | 16188    |
|    fps              | 159      |
|    time_elapsed     | 1765     |
|    total_timesteps  | 281404   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 60350    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.313    |
| time/               |          |
|    episodes         | 16192    |
|    fps              | 159      |
|    time_elapsed     | 1765     |
|    total_timesteps  | 281468   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 60366    |
----------------------------------
Eval num_timesteps=281500, episode_reward=-0.05 +/- 0.14
Episode length: 16.52 +/- 3.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.5     |
|    mean_reward      | -0.045   |
| rollout/            |          |
|    exploration_rate | 0.313    |
| time/               |          |
|    total_timesteps  | 281500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 60374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.313    |
| time/               |          |
|    episodes         | 16196    |
|    fps              | 159      |
|    time_elapsed     | 1766     |
|    total_timesteps  | 281534   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 60383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0333  |
|    exploration_rate | 0.313    |
| time/               |          |
|    episodes         | 16200    |
|    fps              | 159      |
|    time_elapsed     | 1766     |
|    total_timesteps  | 281604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00297  |
|    n_updates        | 60400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.312    |
| time/               |          |
|    episodes         | 16204    |
|    fps              | 159      |
|    time_elapsed     | 1766     |
|    total_timesteps  | 281664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0024   |
|    n_updates        | 60415    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.312    |
| time/               |          |
|    episodes         | 16208    |
|    fps              | 159      |
|    time_elapsed     | 1766     |
|    total_timesteps  | 281724   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 60430    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.312    |
| time/               |          |
|    episodes         | 16212    |
|    fps              | 159      |
|    time_elapsed     | 1767     |
|    total_timesteps  | 281788   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 60446    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.312    |
| time/               |          |
|    episodes         | 16216    |
|    fps              | 159      |
|    time_elapsed     | 1767     |
|    total_timesteps  | 281852   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 60462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.311    |
| time/               |          |
|    episodes         | 16220    |
|    fps              | 159      |
|    time_elapsed     | 1767     |
|    total_timesteps  | 281916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00426  |
|    n_updates        | 60478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0236  |
|    exploration_rate | 0.311    |
| time/               |          |
|    episodes         | 16224    |
|    fps              | 159      |
|    time_elapsed     | 1767     |
|    total_timesteps  | 281985   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 60496    |
----------------------------------
Eval num_timesteps=282000, episode_reward=-0.06 +/- 0.01
Episode length: 15.26 +/- 1.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | -0.06    |
| rollout/            |          |
|    exploration_rate | 0.311    |
| time/               |          |
|    total_timesteps  | 282000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00227  |
|    n_updates        | 60499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0339  |
|    exploration_rate | 0.311    |
| time/               |          |
|    episodes         | 16228    |
|    fps              | 159      |
|    time_elapsed     | 1768     |
|    total_timesteps  | 282057   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0021   |
|    n_updates        | 60514    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0436  |
|    exploration_rate | 0.31     |
| time/               |          |
|    episodes         | 16232    |
|    fps              | 159      |
|    time_elapsed     | 1768     |
|    total_timesteps  | 282120   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00319  |
|    n_updates        | 60529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0436  |
|    exploration_rate | 0.31     |
| time/               |          |
|    episodes         | 16236    |
|    fps              | 159      |
|    time_elapsed     | 1768     |
|    total_timesteps  | 282189   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 60547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.31     |
| time/               |          |
|    episodes         | 16240    |
|    fps              | 159      |
|    time_elapsed     | 1768     |
|    total_timesteps  | 282248   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00199  |
|    n_updates        | 60561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.31     |
| time/               |          |
|    episodes         | 16244    |
|    fps              | 159      |
|    time_elapsed     | 1768     |
|    total_timesteps  | 282310   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 60577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0337  |
|    exploration_rate | 0.309    |
| time/               |          |
|    episodes         | 16248    |
|    fps              | 159      |
|    time_elapsed     | 1769     |
|    total_timesteps  | 282376   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 60593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0333  |
|    exploration_rate | 0.309    |
| time/               |          |
|    episodes         | 16252    |
|    fps              | 159      |
|    time_elapsed     | 1769     |
|    total_timesteps  | 282437   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 60609    |
----------------------------------
Eval num_timesteps=282500, episode_reward=0.03 +/- 0.29
Episode length: 16.60 +/- 7.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.6     |
|    mean_reward      | 0.0346   |
| rollout/            |          |
|    exploration_rate | 0.309    |
| time/               |          |
|    total_timesteps  | 282500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 60624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.309    |
| time/               |          |
|    episodes         | 16256    |
|    fps              | 159      |
|    time_elapsed     | 1770     |
|    total_timesteps  | 282501   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00303  |
|    n_updates        | 60625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.309    |
| time/               |          |
|    episodes         | 16260    |
|    fps              | 159      |
|    time_elapsed     | 1770     |
|    total_timesteps  | 282569   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00352  |
|    n_updates        | 60642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0337  |
|    exploration_rate | 0.308    |
| time/               |          |
|    episodes         | 16264    |
|    fps              | 159      |
|    time_elapsed     | 1770     |
|    total_timesteps  | 282634   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00224  |
|    n_updates        | 60658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0439  |
|    exploration_rate | 0.308    |
| time/               |          |
|    episodes         | 16268    |
|    fps              | 159      |
|    time_elapsed     | 1770     |
|    total_timesteps  | 282696   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00321  |
|    n_updates        | 60673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0434  |
|    exploration_rate | 0.308    |
| time/               |          |
|    episodes         | 16272    |
|    fps              | 159      |
|    time_elapsed     | 1770     |
|    total_timesteps  | 282759   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 60689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0435  |
|    exploration_rate | 0.307    |
| time/               |          |
|    episodes         | 16276    |
|    fps              | 159      |
|    time_elapsed     | 1770     |
|    total_timesteps  | 282825   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 60706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0432  |
|    exploration_rate | 0.307    |
| time/               |          |
|    episodes         | 16280    |
|    fps              | 159      |
|    time_elapsed     | 1771     |
|    total_timesteps  | 282886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 60721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0433  |
|    exploration_rate | 0.307    |
| time/               |          |
|    episodes         | 16284    |
|    fps              | 159      |
|    time_elapsed     | 1771     |
|    total_timesteps  | 282951   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 60737    |
----------------------------------
Eval num_timesteps=283000, episode_reward=0.01 +/- 0.27
Episode length: 17.30 +/- 7.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.3     |
|    mean_reward      | 0.0118   |
| rollout/            |          |
|    exploration_rate | 0.307    |
| time/               |          |
|    total_timesteps  | 283000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 60749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0436  |
|    exploration_rate | 0.307    |
| time/               |          |
|    episodes         | 16288    |
|    fps              | 159      |
|    time_elapsed     | 1772     |
|    total_timesteps  | 283019   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00302  |
|    n_updates        | 60754    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.306    |
| time/               |          |
|    episodes         | 16292    |
|    fps              | 159      |
|    time_elapsed     | 1772     |
|    total_timesteps  | 283093   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 60773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0439  |
|    exploration_rate | 0.306    |
| time/               |          |
|    episodes         | 16296    |
|    fps              | 159      |
|    time_elapsed     | 1772     |
|    total_timesteps  | 283156   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 60788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.306    |
| time/               |          |
|    episodes         | 16300    |
|    fps              | 159      |
|    time_elapsed     | 1772     |
|    total_timesteps  | 283216   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 60803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0338  |
|    exploration_rate | 0.305    |
| time/               |          |
|    episodes         | 16304    |
|    fps              | 159      |
|    time_elapsed     | 1772     |
|    total_timesteps  | 283285   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 60821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.034   |
|    exploration_rate | 0.305    |
| time/               |          |
|    episodes         | 16308    |
|    fps              | 159      |
|    time_elapsed     | 1773     |
|    total_timesteps  | 283349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 60837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.034   |
|    exploration_rate | 0.305    |
| time/               |          |
|    episodes         | 16312    |
|    fps              | 159      |
|    time_elapsed     | 1773     |
|    total_timesteps  | 283414   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 60853    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.034   |
|    exploration_rate | 0.305    |
| time/               |          |
|    episodes         | 16316    |
|    fps              | 159      |
|    time_elapsed     | 1773     |
|    total_timesteps  | 283477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 60869    |
----------------------------------
Eval num_timesteps=283500, episode_reward=0.00 +/- 0.24
Episode length: 14.84 +/- 0.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00172  |
| rollout/            |          |
|    exploration_rate | 0.305    |
| time/               |          |
|    total_timesteps  | 283500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 60874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0239  |
|    exploration_rate | 0.304    |
| time/               |          |
|    episodes         | 16320    |
|    fps              | 159      |
|    time_elapsed     | 1774     |
|    total_timesteps  | 283538   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 60884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0238  |
|    exploration_rate | 0.304    |
| time/               |          |
|    episodes         | 16324    |
|    fps              | 159      |
|    time_elapsed     | 1774     |
|    total_timesteps  | 283604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00389  |
|    n_updates        | 60900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.304    |
| time/               |          |
|    episodes         | 16328    |
|    fps              | 159      |
|    time_elapsed     | 1774     |
|    total_timesteps  | 283667   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 60916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.304    |
| time/               |          |
|    episodes         | 16332    |
|    fps              | 159      |
|    time_elapsed     | 1774     |
|    total_timesteps  | 283731   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 60932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.303    |
| time/               |          |
|    episodes         | 16336    |
|    fps              | 159      |
|    time_elapsed     | 1774     |
|    total_timesteps  | 283792   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 60947    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.303    |
| time/               |          |
|    episodes         | 16340    |
|    fps              | 159      |
|    time_elapsed     | 1774     |
|    total_timesteps  | 283854   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00453  |
|    n_updates        | 60963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.303    |
| time/               |          |
|    episodes         | 16344    |
|    fps              | 159      |
|    time_elapsed     | 1775     |
|    total_timesteps  | 283916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 60978    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.302    |
| time/               |          |
|    episodes         | 16348    |
|    fps              | 159      |
|    time_elapsed     | 1775     |
|    total_timesteps  | 283978   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000554 |
|    n_updates        | 60994    |
----------------------------------
Eval num_timesteps=284000, episode_reward=-0.02 +/- 0.20
Episode length: 15.44 +/- 1.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.4     |
|    mean_reward      | -0.0207  |
| rollout/            |          |
|    exploration_rate | 0.302    |
| time/               |          |
|    total_timesteps  | 284000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 60999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.302    |
| time/               |          |
|    episodes         | 16352    |
|    fps              | 159      |
|    time_elapsed     | 1776     |
|    total_timesteps  | 284040   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000903 |
|    n_updates        | 61009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.302    |
| time/               |          |
|    episodes         | 16356    |
|    fps              | 159      |
|    time_elapsed     | 1776     |
|    total_timesteps  | 284106   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00199  |
|    n_updates        | 61026    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.302    |
| time/               |          |
|    episodes         | 16360    |
|    fps              | 159      |
|    time_elapsed     | 1776     |
|    total_timesteps  | 284173   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00328  |
|    n_updates        | 61043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.301    |
| time/               |          |
|    episodes         | 16364    |
|    fps              | 159      |
|    time_elapsed     | 1776     |
|    total_timesteps  | 284239   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00324  |
|    n_updates        | 61059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0334  |
|    exploration_rate | 0.301    |
| time/               |          |
|    episodes         | 16368    |
|    fps              | 159      |
|    time_elapsed     | 1776     |
|    total_timesteps  | 284307   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00538  |
|    n_updates        | 61076    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0336  |
|    exploration_rate | 0.301    |
| time/               |          |
|    episodes         | 16372    |
|    fps              | 160      |
|    time_elapsed     | 1777     |
|    total_timesteps  | 284374   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00432  |
|    n_updates        | 61093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.301    |
| time/               |          |
|    episodes         | 16376    |
|    fps              | 160      |
|    time_elapsed     | 1777     |
|    total_timesteps  | 284438   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 61109    |
----------------------------------
Eval num_timesteps=284500, episode_reward=0.09 +/- 0.40
Episode length: 23.60 +/- 15.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 23.6     |
|    mean_reward      | 0.0867   |
| rollout/            |          |
|    exploration_rate | 0.3      |
| time/               |          |
|    total_timesteps  | 284500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 61124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0336  |
|    exploration_rate | 0.3      |
| time/               |          |
|    episodes         | 16380    |
|    fps              | 159      |
|    time_elapsed     | 1779     |
|    total_timesteps  | 284502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00263  |
|    n_updates        | 61125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.3      |
| time/               |          |
|    episodes         | 16384    |
|    fps              | 159      |
|    time_elapsed     | 1779     |
|    total_timesteps  | 284564   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 61140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.3      |
| time/               |          |
|    episodes         | 16388    |
|    fps              | 159      |
|    time_elapsed     | 1779     |
|    total_timesteps  | 284624   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00309  |
|    n_updates        | 61155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0337  |
|    exploration_rate | 0.299    |
| time/               |          |
|    episodes         | 16392    |
|    fps              | 159      |
|    time_elapsed     | 1779     |
|    total_timesteps  | 284710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00489  |
|    n_updates        | 61177    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0338  |
|    exploration_rate | 0.299    |
| time/               |          |
|    episodes         | 16396    |
|    fps              | 160      |
|    time_elapsed     | 1779     |
|    total_timesteps  | 284777   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 61194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.299    |
| time/               |          |
|    episodes         | 16400    |
|    fps              | 160      |
|    time_elapsed     | 1779     |
|    total_timesteps  | 284842   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 61210    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0438  |
|    exploration_rate | 0.299    |
| time/               |          |
|    episodes         | 16404    |
|    fps              | 160      |
|    time_elapsed     | 1779     |
|    total_timesteps  | 284904   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 61225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0338  |
|    exploration_rate | 0.298    |
| time/               |          |
|    episodes         | 16408    |
|    fps              | 160      |
|    time_elapsed     | 1780     |
|    total_timesteps  | 284970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 61242    |
----------------------------------
Eval num_timesteps=285000, episode_reward=0.05 +/- 0.32
Episode length: 18.28 +/- 7.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.3     |
|    mean_reward      | 0.048    |
| rollout/            |          |
|    exploration_rate | 0.298    |
| time/               |          |
|    total_timesteps  | 285000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0028   |
|    n_updates        | 61249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0238  |
|    exploration_rate | 0.298    |
| time/               |          |
|    episodes         | 16412    |
|    fps              | 159      |
|    time_elapsed     | 1781     |
|    total_timesteps  | 285034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000985 |
|    n_updates        | 61258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.298    |
| time/               |          |
|    episodes         | 16416    |
|    fps              | 160      |
|    time_elapsed     | 1781     |
|    total_timesteps  | 285108   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 61276    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0343  |
|    exploration_rate | 0.297    |
| time/               |          |
|    episodes         | 16420    |
|    fps              | 160      |
|    time_elapsed     | 1781     |
|    total_timesteps  | 285172   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 61292    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 0.297    |
| time/               |          |
|    episodes         | 16424    |
|    fps              | 160      |
|    time_elapsed     | 1781     |
|    total_timesteps  | 285239   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00244  |
|    n_updates        | 61309    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0248  |
|    exploration_rate | 0.297    |
| time/               |          |
|    episodes         | 16428    |
|    fps              | 160      |
|    time_elapsed     | 1782     |
|    total_timesteps  | 285313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 61328    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.025   |
|    exploration_rate | 0.296    |
| time/               |          |
|    episodes         | 16432    |
|    fps              | 160      |
|    time_elapsed     | 1782     |
|    total_timesteps  | 285381   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000942 |
|    n_updates        | 61345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0252  |
|    exploration_rate | 0.296    |
| time/               |          |
|    episodes         | 16436    |
|    fps              | 160      |
|    time_elapsed     | 1782     |
|    total_timesteps  | 285448   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 61361    |
----------------------------------
Eval num_timesteps=285500, episode_reward=-0.11 +/- 0.16
Episode length: 32.36 +/- 16.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 32.4     |
|    mean_reward      | -0.108   |
| rollout/            |          |
|    exploration_rate | 0.296    |
| time/               |          |
|    total_timesteps  | 285500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00268  |
|    n_updates        | 61374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0256  |
|    exploration_rate | 0.296    |
| time/               |          |
|    episodes         | 16440    |
|    fps              | 159      |
|    time_elapsed     | 1784     |
|    total_timesteps  | 285520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 61379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0264  |
|    exploration_rate | 0.296    |
| time/               |          |
|    episodes         | 16444    |
|    fps              | 160      |
|    time_elapsed     | 1784     |
|    total_timesteps  | 285602   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00335  |
|    n_updates        | 61400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0163  |
|    exploration_rate | 0.295    |
| time/               |          |
|    episodes         | 16448    |
|    fps              | 160      |
|    time_elapsed     | 1784     |
|    total_timesteps  | 285660   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 61414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00394  |
|    exploration_rate | 0.295    |
| time/               |          |
|    episodes         | 16452    |
|    fps              | 160      |
|    time_elapsed     | 1785     |
|    total_timesteps  | 285717   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00226  |
|    n_updates        | 61429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00386  |
|    exploration_rate | 0.295    |
| time/               |          |
|    episodes         | 16456    |
|    fps              | 160      |
|    time_elapsed     | 1785     |
|    total_timesteps  | 285785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 61446    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00406  |
|    exploration_rate | 0.294    |
| time/               |          |
|    episodes         | 16460    |
|    fps              | 160      |
|    time_elapsed     | 1785     |
|    total_timesteps  | 285847   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 61461    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00362  |
|    exploration_rate | 0.294    |
| time/               |          |
|    episodes         | 16464    |
|    fps              | 160      |
|    time_elapsed     | 1785     |
|    total_timesteps  | 285924   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00417  |
|    n_updates        | 61480    |
----------------------------------
Eval num_timesteps=286000, episode_reward=-0.05 +/- 0.25
Episode length: 28.04 +/- 14.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28       |
|    mean_reward      | -0.0511  |
| rollout/            |          |
|    exploration_rate | 0.294    |
| time/               |          |
|    total_timesteps  | 286000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0029   |
|    n_updates        | 61499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0132   |
|    exploration_rate | 0.294    |
| time/               |          |
|    episodes         | 16468    |
|    fps              | 160      |
|    time_elapsed     | 1787     |
|    total_timesteps  | 286004   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00269  |
|    n_updates        | 61500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0132   |
|    exploration_rate | 0.294    |
| time/               |          |
|    episodes         | 16472    |
|    fps              | 160      |
|    time_elapsed     | 1787     |
|    total_timesteps  | 286070   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 61517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.293    |
| time/               |          |
|    episodes         | 16476    |
|    fps              | 160      |
|    time_elapsed     | 1787     |
|    total_timesteps  | 286177   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 61544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0116   |
|    exploration_rate | 0.293    |
| time/               |          |
|    episodes         | 16480    |
|    fps              | 160      |
|    time_elapsed     | 1787     |
|    total_timesteps  | 286238   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00199  |
|    n_updates        | 61559    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0116   |
|    exploration_rate | 0.293    |
| time/               |          |
|    episodes         | 16484    |
|    fps              | 160      |
|    time_elapsed     | 1787     |
|    total_timesteps  | 286301   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00099  |
|    n_updates        | 61575    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.011    |
|    exploration_rate | 0.292    |
| time/               |          |
|    episodes         | 16488    |
|    fps              | 160      |
|    time_elapsed     | 1788     |
|    total_timesteps  | 286376   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00274  |
|    n_updates        | 61593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0116   |
|    exploration_rate | 0.292    |
| time/               |          |
|    episodes         | 16492    |
|    fps              | 160      |
|    time_elapsed     | 1788     |
|    total_timesteps  | 286446   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00218  |
|    n_updates        | 61611    |
----------------------------------
Eval num_timesteps=286500, episode_reward=-0.10 +/- 0.20
Episode length: 35.98 +/- 17.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36       |
|    mean_reward      | -0.103   |
| rollout/            |          |
|    exploration_rate | 0.292    |
| time/               |          |
|    total_timesteps  | 286500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 61624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.292    |
| time/               |          |
|    episodes         | 16496    |
|    fps              | 160      |
|    time_elapsed     | 1790     |
|    total_timesteps  | 286514   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000944 |
|    n_updates        | 61628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0112   |
|    exploration_rate | 0.291    |
| time/               |          |
|    episodes         | 16500    |
|    fps              | 160      |
|    time_elapsed     | 1790     |
|    total_timesteps  | 286587   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00285  |
|    n_updates        | 61646    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0112   |
|    exploration_rate | 0.291    |
| time/               |          |
|    episodes         | 16504    |
|    fps              | 160      |
|    time_elapsed     | 1790     |
|    total_timesteps  | 286650   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00272  |
|    n_updates        | 61662    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00121  |
|    exploration_rate | 0.291    |
| time/               |          |
|    episodes         | 16508    |
|    fps              | 160      |
|    time_elapsed     | 1790     |
|    total_timesteps  | 286716   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 61678    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00901 |
|    exploration_rate | 0.29     |
| time/               |          |
|    episodes         | 16512    |
|    fps              | 160      |
|    time_elapsed     | 1791     |
|    total_timesteps  | 286785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 61696    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00869 |
|    exploration_rate | 0.29     |
| time/               |          |
|    episodes         | 16516    |
|    fps              | 160      |
|    time_elapsed     | 1791     |
|    total_timesteps  | 286851   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 61712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00861 |
|    exploration_rate | 0.29     |
| time/               |          |
|    episodes         | 16520    |
|    fps              | 160      |
|    time_elapsed     | 1791     |
|    total_timesteps  | 286913   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00523  |
|    n_updates        | 61728    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00853 |
|    exploration_rate | 0.29     |
| time/               |          |
|    episodes         | 16524    |
|    fps              | 160      |
|    time_elapsed     | 1791     |
|    total_timesteps  | 286978   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 61744    |
----------------------------------
Eval num_timesteps=287000, episode_reward=-0.03 +/- 0.20
Episode length: 17.86 +/- 9.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.9     |
|    mean_reward      | -0.0304  |
| rollout/            |          |
|    exploration_rate | 0.289    |
| time/               |          |
|    total_timesteps  | 287000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00364  |
|    n_updates        | 61749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0185  |
|    exploration_rate | 0.289    |
| time/               |          |
|    episodes         | 16528    |
|    fps              | 160      |
|    time_elapsed     | 1792     |
|    total_timesteps  | 287051   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 61762    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0186  |
|    exploration_rate | 0.289    |
| time/               |          |
|    episodes         | 16532    |
|    fps              | 160      |
|    time_elapsed     | 1793     |
|    total_timesteps  | 287121   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00364  |
|    n_updates        | 61780    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0184  |
|    exploration_rate | 0.289    |
| time/               |          |
|    episodes         | 16536    |
|    fps              | 160      |
|    time_elapsed     | 1793     |
|    total_timesteps  | 287183   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000992 |
|    n_updates        | 61795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0187  |
|    exploration_rate | 0.288    |
| time/               |          |
|    episodes         | 16540    |
|    fps              | 160      |
|    time_elapsed     | 1793     |
|    total_timesteps  | 287264   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 61815    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0185  |
|    exploration_rate | 0.288    |
| time/               |          |
|    episodes         | 16544    |
|    fps              | 160      |
|    time_elapsed     | 1793     |
|    total_timesteps  | 287340   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 61834    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0286  |
|    exploration_rate | 0.288    |
| time/               |          |
|    episodes         | 16548    |
|    fps              | 160      |
|    time_elapsed     | 1793     |
|    total_timesteps  | 287402   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000832 |
|    n_updates        | 61850    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0493  |
|    exploration_rate | 0.287    |
| time/               |          |
|    episodes         | 16552    |
|    fps              | 160      |
|    time_elapsed     | 1793     |
|    total_timesteps  | 287474   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 61868    |
----------------------------------
Eval num_timesteps=287500, episode_reward=0.12 +/- 0.40
Episode length: 20.00 +/- 10.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20       |
|    mean_reward      | 0.121    |
| rollout/            |          |
|    exploration_rate | 0.287    |
| time/               |          |
|    total_timesteps  | 287500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00218  |
|    n_updates        | 61874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.039   |
|    exploration_rate | 0.287    |
| time/               |          |
|    episodes         | 16556    |
|    fps              | 160      |
|    time_elapsed     | 1795     |
|    total_timesteps  | 287537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 61884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0291  |
|    exploration_rate | 0.287    |
| time/               |          |
|    episodes         | 16560    |
|    fps              | 160      |
|    time_elapsed     | 1795     |
|    total_timesteps  | 287602   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00302  |
|    n_updates        | 61900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0292  |
|    exploration_rate | 0.287    |
| time/               |          |
|    episodes         | 16564    |
|    fps              | 160      |
|    time_elapsed     | 1795     |
|    total_timesteps  | 287680   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 61919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0287  |
|    exploration_rate | 0.286    |
| time/               |          |
|    episodes         | 16568    |
|    fps              | 160      |
|    time_elapsed     | 1795     |
|    total_timesteps  | 287748   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 61936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0188  |
|    exploration_rate | 0.286    |
| time/               |          |
|    episodes         | 16572    |
|    fps              | 160      |
|    time_elapsed     | 1795     |
|    total_timesteps  | 287817   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 61954    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0175  |
|    exploration_rate | 0.286    |
| time/               |          |
|    episodes         | 16576    |
|    fps              | 160      |
|    time_elapsed     | 1795     |
|    total_timesteps  | 287892   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 61972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0176  |
|    exploration_rate | 0.285    |
| time/               |          |
|    episodes         | 16580    |
|    fps              | 160      |
|    time_elapsed     | 1795     |
|    total_timesteps  | 287956   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 61988    |
----------------------------------
Eval num_timesteps=288000, episode_reward=-0.04 +/- 0.14
Episode length: 15.38 +/- 0.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.4     |
|    mean_reward      | -0.0405  |
| rollout/            |          |
|    exploration_rate | 0.285    |
| time/               |          |
|    total_timesteps  | 288000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00552  |
|    n_updates        | 61999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.285    |
| time/               |          |
|    episodes         | 16584    |
|    fps              | 160      |
|    time_elapsed     | 1797     |
|    total_timesteps  | 288021   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 62005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0172  |
|    exploration_rate | 0.285    |
| time/               |          |
|    episodes         | 16588    |
|    fps              | 160      |
|    time_elapsed     | 1797     |
|    total_timesteps  | 288084   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0023   |
|    n_updates        | 62020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.017   |
|    exploration_rate | 0.285    |
| time/               |          |
|    episodes         | 16592    |
|    fps              | 160      |
|    time_elapsed     | 1797     |
|    total_timesteps  | 288149   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 62037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00689 |
|    exploration_rate | 0.284    |
| time/               |          |
|    episodes         | 16596    |
|    fps              | 160      |
|    time_elapsed     | 1797     |
|    total_timesteps  | 288213   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00362  |
|    n_updates        | 62053    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00649 |
|    exploration_rate | 0.284    |
| time/               |          |
|    episodes         | 16600    |
|    fps              | 160      |
|    time_elapsed     | 1797     |
|    total_timesteps  | 288276   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 62068    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00627 |
|    exploration_rate | 0.284    |
| time/               |          |
|    episodes         | 16604    |
|    fps              | 160      |
|    time_elapsed     | 1797     |
|    total_timesteps  | 288333   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 62083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00623 |
|    exploration_rate | 0.283    |
| time/               |          |
|    episodes         | 16608    |
|    fps              | 160      |
|    time_elapsed     | 1797     |
|    total_timesteps  | 288398   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 62099    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00623 |
|    exploration_rate | 0.283    |
| time/               |          |
|    episodes         | 16612    |
|    fps              | 160      |
|    time_elapsed     | 1797     |
|    total_timesteps  | 288467   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00246  |
|    n_updates        | 62116    |
----------------------------------
Eval num_timesteps=288500, episode_reward=-0.00 +/- 0.24
Episode length: 15.76 +/- 1.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | -0.00196 |
| rollout/            |          |
|    exploration_rate | 0.283    |
| time/               |          |
|    total_timesteps  | 288500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 62124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00643 |
|    exploration_rate | 0.283    |
| time/               |          |
|    episodes         | 16616    |
|    fps              | 160      |
|    time_elapsed     | 1799     |
|    total_timesteps  | 288538   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 62134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00647 |
|    exploration_rate | 0.283    |
| time/               |          |
|    episodes         | 16620    |
|    fps              | 160      |
|    time_elapsed     | 1799     |
|    total_timesteps  | 288601   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00189  |
|    n_updates        | 62150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00643 |
|    exploration_rate | 0.282    |
| time/               |          |
|    episodes         | 16624    |
|    fps              | 160      |
|    time_elapsed     | 1799     |
|    total_timesteps  | 288665   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 62166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00603 |
|    exploration_rate | 0.282    |
| time/               |          |
|    episodes         | 16628    |
|    fps              | 160      |
|    time_elapsed     | 1799     |
|    total_timesteps  | 288728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00388  |
|    n_updates        | 62181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00603 |
|    exploration_rate | 0.282    |
| time/               |          |
|    episodes         | 16632    |
|    fps              | 160      |
|    time_elapsed     | 1799     |
|    total_timesteps  | 288798   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00262  |
|    n_updates        | 62199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00635 |
|    exploration_rate | 0.281    |
| time/               |          |
|    episodes         | 16636    |
|    fps              | 160      |
|    time_elapsed     | 1799     |
|    total_timesteps  | 288868   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00354  |
|    n_updates        | 62216    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00575 |
|    exploration_rate | 0.281    |
| time/               |          |
|    episodes         | 16640    |
|    fps              | 160      |
|    time_elapsed     | 1799     |
|    total_timesteps  | 288934   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 62233    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00519 |
|    exploration_rate | 0.281    |
| time/               |          |
|    episodes         | 16644    |
|    fps              | 160      |
|    time_elapsed     | 1800     |
|    total_timesteps  | 288996   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 62248    |
----------------------------------
Eval num_timesteps=289000, episode_reward=-0.04 +/- 0.14
Episode length: 15.88 +/- 1.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.0425  |
| rollout/            |          |
|    exploration_rate | 0.281    |
| time/               |          |
|    total_timesteps  | 289000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 62249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00493  |
|    exploration_rate | 0.281    |
| time/               |          |
|    episodes         | 16648    |
|    fps              | 160      |
|    time_elapsed     | 1801     |
|    total_timesteps  | 289055   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 62263    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00521  |
|    exploration_rate | 0.28     |
| time/               |          |
|    episodes         | 16652    |
|    fps              | 160      |
|    time_elapsed     | 1801     |
|    total_timesteps  | 289120   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 62279    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.00534  |
|    exploration_rate | 0.28     |
| time/               |          |
|    episodes         | 16656    |
|    fps              | 160      |
|    time_elapsed     | 1801     |
|    total_timesteps  | 289179   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00303  |
|    n_updates        | 62294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00459 |
|    exploration_rate | 0.28     |
| time/               |          |
|    episodes         | 16660    |
|    fps              | 160      |
|    time_elapsed     | 1801     |
|    total_timesteps  | 289242   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 62310    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00411 |
|    exploration_rate | 0.28     |
| time/               |          |
|    episodes         | 16664    |
|    fps              | 160      |
|    time_elapsed     | 1801     |
|    total_timesteps  | 289308   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0025   |
|    n_updates        | 62326    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 0.279    |
| time/               |          |
|    episodes         | 16668    |
|    fps              | 160      |
|    time_elapsed     | 1801     |
|    total_timesteps  | 289381   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 62345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00408 |
|    exploration_rate | 0.279    |
| time/               |          |
|    episodes         | 16672    |
|    fps              | 160      |
|    time_elapsed     | 1801     |
|    total_timesteps  | 289444   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00629  |
|    n_updates        | 62360    |
----------------------------------
Eval num_timesteps=289500, episode_reward=-0.01 +/- 0.33
Episode length: 32.60 +/- 18.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 32.6     |
|    mean_reward      | -0.0094  |
| rollout/            |          |
|    exploration_rate | 0.279    |
| time/               |          |
|    total_timesteps  | 289500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00267  |
|    n_updates        | 62374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00352 |
|    exploration_rate | 0.279    |
| time/               |          |
|    episodes         | 16676    |
|    fps              | 160      |
|    time_elapsed     | 1804     |
|    total_timesteps  | 289505   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00293  |
|    n_updates        | 62376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00408 |
|    exploration_rate | 0.278    |
| time/               |          |
|    episodes         | 16680    |
|    fps              | 160      |
|    time_elapsed     | 1804     |
|    total_timesteps  | 289583   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 62395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00404 |
|    exploration_rate | 0.278    |
| time/               |          |
|    episodes         | 16684    |
|    fps              | 160      |
|    time_elapsed     | 1804     |
|    total_timesteps  | 289647   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00339  |
|    n_updates        | 62411    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00412 |
|    exploration_rate | 0.278    |
| time/               |          |
|    episodes         | 16688    |
|    fps              | 160      |
|    time_elapsed     | 1804     |
|    total_timesteps  | 289712   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00271  |
|    n_updates        | 62427    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00408 |
|    exploration_rate | 0.277    |
| time/               |          |
|    episodes         | 16692    |
|    fps              | 160      |
|    time_elapsed     | 1804     |
|    total_timesteps  | 289776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00218  |
|    n_updates        | 62443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.277    |
| time/               |          |
|    episodes         | 16696    |
|    fps              | 160      |
|    time_elapsed     | 1804     |
|    total_timesteps  | 289848   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00329  |
|    n_updates        | 62461    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 0.277    |
| time/               |          |
|    episodes         | 16700    |
|    fps              | 160      |
|    time_elapsed     | 1804     |
|    total_timesteps  | 289909   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00264  |
|    n_updates        | 62477    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0245  |
|    exploration_rate | 0.277    |
| time/               |          |
|    episodes         | 16704    |
|    fps              | 160      |
|    time_elapsed     | 1805     |
|    total_timesteps  | 289972   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000658 |
|    n_updates        | 62492    |
----------------------------------
Eval num_timesteps=290000, episode_reward=-0.07 +/- 0.02
Episode length: 17.56 +/- 5.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.6     |
|    mean_reward      | -0.0692  |
| rollout/            |          |
|    exploration_rate | 0.277    |
| time/               |          |
|    total_timesteps  | 290000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 62499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0247  |
|    exploration_rate | 0.276    |
| time/               |          |
|    episodes         | 16708    |
|    fps              | 160      |
|    time_elapsed     | 1806     |
|    total_timesteps  | 290040   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 62509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0243  |
|    exploration_rate | 0.276    |
| time/               |          |
|    episodes         | 16712    |
|    fps              | 160      |
|    time_elapsed     | 1806     |
|    total_timesteps  | 290101   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00296  |
|    n_updates        | 62525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0241  |
|    exploration_rate | 0.276    |
| time/               |          |
|    episodes         | 16716    |
|    fps              | 160      |
|    time_elapsed     | 1806     |
|    total_timesteps  | 290166   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 62541    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00386 |
|    exploration_rate | 0.276    |
| time/               |          |
|    episodes         | 16720    |
|    fps              | 160      |
|    time_elapsed     | 1806     |
|    total_timesteps  | 290224   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00389  |
|    n_updates        | 62555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0064   |
|    exploration_rate | 0.275    |
| time/               |          |
|    episodes         | 16724    |
|    fps              | 160      |
|    time_elapsed     | 1806     |
|    total_timesteps  | 290282   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00478  |
|    n_updates        | 62570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0167   |
|    exploration_rate | 0.275    |
| time/               |          |
|    episodes         | 16728    |
|    fps              | 160      |
|    time_elapsed     | 1806     |
|    total_timesteps  | 290339   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 62584    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.275    |
| time/               |          |
|    episodes         | 16732    |
|    fps              | 160      |
|    time_elapsed     | 1806     |
|    total_timesteps  | 290398   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 62599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0275   |
|    exploration_rate | 0.275    |
| time/               |          |
|    episodes         | 16736    |
|    fps              | 160      |
|    time_elapsed     | 1807     |
|    total_timesteps  | 290459   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00251  |
|    n_updates        | 62614    |
----------------------------------
Eval num_timesteps=290500, episode_reward=-0.02 +/- 0.28
Episode length: 25.42 +/- 14.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 25.4     |
|    mean_reward      | -0.0206  |
| rollout/            |          |
|    exploration_rate | 0.274    |
| time/               |          |
|    total_timesteps  | 290500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00316  |
|    n_updates        | 62624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 0.274    |
| time/               |          |
|    episodes         | 16740    |
|    fps              | 160      |
|    time_elapsed     | 1808     |
|    total_timesteps  | 290522   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 62630    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0374   |
|    exploration_rate | 0.274    |
| time/               |          |
|    episodes         | 16744    |
|    fps              | 160      |
|    time_elapsed     | 1809     |
|    total_timesteps  | 290590   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 62647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0268   |
|    exploration_rate | 0.274    |
| time/               |          |
|    episodes         | 16748    |
|    fps              | 160      |
|    time_elapsed     | 1809     |
|    total_timesteps  | 290662   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 62665    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0265   |
|    exploration_rate | 0.273    |
| time/               |          |
|    episodes         | 16752    |
|    fps              | 160      |
|    time_elapsed     | 1809     |
|    total_timesteps  | 290735   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 62683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0368   |
|    exploration_rate | 0.273    |
| time/               |          |
|    episodes         | 16756    |
|    fps              | 160      |
|    time_elapsed     | 1809     |
|    total_timesteps  | 290788   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00429  |
|    n_updates        | 62696    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0367   |
|    exploration_rate | 0.273    |
| time/               |          |
|    episodes         | 16760    |
|    fps              | 160      |
|    time_elapsed     | 1809     |
|    total_timesteps  | 290854   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 62713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0368   |
|    exploration_rate | 0.273    |
| time/               |          |
|    episodes         | 16764    |
|    fps              | 160      |
|    time_elapsed     | 1809     |
|    total_timesteps  | 290916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00295  |
|    n_updates        | 62728    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.272    |
| time/               |          |
|    episodes         | 16768    |
|    fps              | 160      |
|    time_elapsed     | 1809     |
|    total_timesteps  | 290976   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00351  |
|    n_updates        | 62743    |
----------------------------------
Eval num_timesteps=291000, episode_reward=-0.02 +/- 0.20
Episode length: 15.36 +/- 0.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.4     |
|    mean_reward      | -0.0204  |
| rollout/            |          |
|    exploration_rate | 0.272    |
| time/               |          |
|    total_timesteps  | 291000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00514  |
|    n_updates        | 62749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.272    |
| time/               |          |
|    episodes         | 16772    |
|    fps              | 160      |
|    time_elapsed     | 1810     |
|    total_timesteps  | 291037   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 62759    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0273   |
|    exploration_rate | 0.272    |
| time/               |          |
|    episodes         | 16776    |
|    fps              | 160      |
|    time_elapsed     | 1810     |
|    total_timesteps  | 291101   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 62775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.271    |
| time/               |          |
|    episodes         | 16780    |
|    fps              | 160      |
|    time_elapsed     | 1810     |
|    total_timesteps  | 291169   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00236  |
|    n_updates        | 62792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.271    |
| time/               |          |
|    episodes         | 16784    |
|    fps              | 160      |
|    time_elapsed     | 1811     |
|    total_timesteps  | 291227   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00612  |
|    n_updates        | 62806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.271    |
| time/               |          |
|    episodes         | 16788    |
|    fps              | 160      |
|    time_elapsed     | 1811     |
|    total_timesteps  | 291296   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0036   |
|    n_updates        | 62823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.271    |
| time/               |          |
|    episodes         | 16792    |
|    fps              | 160      |
|    time_elapsed     | 1811     |
|    total_timesteps  | 291356   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 62838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0485   |
|    exploration_rate | 0.27     |
| time/               |          |
|    episodes         | 16796    |
|    fps              | 160      |
|    time_elapsed     | 1811     |
|    total_timesteps  | 291413   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00463  |
|    n_updates        | 62853    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0587   |
|    exploration_rate | 0.27     |
| time/               |          |
|    episodes         | 16800    |
|    fps              | 160      |
|    time_elapsed     | 1811     |
|    total_timesteps  | 291470   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 62867    |
----------------------------------
Eval num_timesteps=291500, episode_reward=0.02 +/- 0.28
Episode length: 14.88 +/- 1.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.0216   |
| rollout/            |          |
|    exploration_rate | 0.27     |
| time/               |          |
|    total_timesteps  | 291500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 62874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0584   |
|    exploration_rate | 0.27     |
| time/               |          |
|    episodes         | 16804    |
|    fps              | 160      |
|    time_elapsed     | 1812     |
|    total_timesteps  | 291540   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0034   |
|    n_updates        | 62884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.27     |
| time/               |          |
|    episodes         | 16808    |
|    fps              | 160      |
|    time_elapsed     | 1812     |
|    total_timesteps  | 291604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00436  |
|    n_updates        | 62900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0584   |
|    exploration_rate | 0.269    |
| time/               |          |
|    episodes         | 16812    |
|    fps              | 160      |
|    time_elapsed     | 1812     |
|    total_timesteps  | 291669   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 62917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0584   |
|    exploration_rate | 0.269    |
| time/               |          |
|    episodes         | 16816    |
|    fps              | 160      |
|    time_elapsed     | 1813     |
|    total_timesteps  | 291735   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.003    |
|    n_updates        | 62933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.269    |
| time/               |          |
|    episodes         | 16820    |
|    fps              | 160      |
|    time_elapsed     | 1813     |
|    total_timesteps  | 291806   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00313  |
|    n_updates        | 62951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.268    |
| time/               |          |
|    episodes         | 16824    |
|    fps              | 160      |
|    time_elapsed     | 1813     |
|    total_timesteps  | 291867   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 62966    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.268    |
| time/               |          |
|    episodes         | 16828    |
|    fps              | 160      |
|    time_elapsed     | 1813     |
|    total_timesteps  | 291927   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00221  |
|    n_updates        | 62981    |
----------------------------------
Eval num_timesteps=292000, episode_reward=-0.04 +/- 0.21
Episode length: 19.44 +/- 14.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.4     |
|    mean_reward      | -0.0368  |
| rollout/            |          |
|    exploration_rate | 0.268    |
| time/               |          |
|    total_timesteps  | 292000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 62999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00658  |
|    exploration_rate | 0.268    |
| time/               |          |
|    episodes         | 16832    |
|    fps              | 160      |
|    time_elapsed     | 1814     |
|    total_timesteps  | 292010   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000659 |
|    n_updates        | 63002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00658  |
|    exploration_rate | 0.268    |
| time/               |          |
|    episodes         | 16836    |
|    fps              | 160      |
|    time_elapsed     | 1814     |
|    total_timesteps  | 292071   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00415  |
|    n_updates        | 63017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00633  |
|    exploration_rate | 0.267    |
| time/               |          |
|    episodes         | 16840    |
|    fps              | 160      |
|    time_elapsed     | 1815     |
|    total_timesteps  | 292140   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00189  |
|    n_updates        | 63034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00609  |
|    exploration_rate | 0.267    |
| time/               |          |
|    episodes         | 16844    |
|    fps              | 160      |
|    time_elapsed     | 1815     |
|    total_timesteps  | 292214   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 63053    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00657  |
|    exploration_rate | 0.267    |
| time/               |          |
|    episodes         | 16848    |
|    fps              | 161      |
|    time_elapsed     | 1815     |
|    total_timesteps  | 292274   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 63068    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00697  |
|    exploration_rate | 0.266    |
| time/               |          |
|    episodes         | 16852    |
|    fps              | 161      |
|    time_elapsed     | 1815     |
|    total_timesteps  | 292337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00375  |
|    n_updates        | 63084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.266    |
| time/               |          |
|    episodes         | 16856    |
|    fps              | 161      |
|    time_elapsed     | 1815     |
|    total_timesteps  | 292397   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00334  |
|    n_updates        | 63099    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.266    |
| time/               |          |
|    episodes         | 16860    |
|    fps              | 161      |
|    time_elapsed     | 1815     |
|    total_timesteps  | 292457   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 63114    |
----------------------------------
Eval num_timesteps=292500, episode_reward=-0.06 +/- 0.00
Episode length: 15.10 +/- 0.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | -0.0594  |
| rollout/            |          |
|    exploration_rate | 0.266    |
| time/               |          |
|    total_timesteps  | 292500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00342  |
|    n_updates        | 63124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.266    |
| time/               |          |
|    episodes         | 16864    |
|    fps              | 161      |
|    time_elapsed     | 1816     |
|    total_timesteps  | 292518   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00714  |
|    n_updates        | 63129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.265    |
| time/               |          |
|    episodes         | 16868    |
|    fps              | 161      |
|    time_elapsed     | 1816     |
|    total_timesteps  | 292579   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00234  |
|    n_updates        | 63144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.265    |
| time/               |          |
|    episodes         | 16872    |
|    fps              | 161      |
|    time_elapsed     | 1816     |
|    total_timesteps  | 292643   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 63160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.265    |
| time/               |          |
|    episodes         | 16876    |
|    fps              | 161      |
|    time_elapsed     | 1817     |
|    total_timesteps  | 292704   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 63175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.264    |
| time/               |          |
|    episodes         | 16880    |
|    fps              | 161      |
|    time_elapsed     | 1817     |
|    total_timesteps  | 292761   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 63190    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.264    |
| time/               |          |
|    episodes         | 16884    |
|    fps              | 161      |
|    time_elapsed     | 1817     |
|    total_timesteps  | 292823   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00266  |
|    n_updates        | 63205    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.264    |
| time/               |          |
|    episodes         | 16888    |
|    fps              | 161      |
|    time_elapsed     | 1817     |
|    total_timesteps  | 292879   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00287  |
|    n_updates        | 63219    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.264    |
| time/               |          |
|    episodes         | 16892    |
|    fps              | 161      |
|    time_elapsed     | 1817     |
|    total_timesteps  | 292950   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 63237    |
----------------------------------
Eval num_timesteps=293000, episode_reward=-0.04 +/- 0.14
Episode length: 15.00 +/- 0.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.039   |
| rollout/            |          |
|    exploration_rate | 0.263    |
| time/               |          |
|    total_timesteps  | 293000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 63249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.263    |
| time/               |          |
|    episodes         | 16896    |
|    fps              | 161      |
|    time_elapsed     | 1818     |
|    total_timesteps  | 293013   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 63253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.263    |
| time/               |          |
|    episodes         | 16900    |
|    fps              | 161      |
|    time_elapsed     | 1818     |
|    total_timesteps  | 293074   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00303  |
|    n_updates        | 63268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0328  |
|    exploration_rate | 0.263    |
| time/               |          |
|    episodes         | 16904    |
|    fps              | 161      |
|    time_elapsed     | 1818     |
|    total_timesteps  | 293136   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 63283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.263    |
| time/               |          |
|    episodes         | 16908    |
|    fps              | 161      |
|    time_elapsed     | 1818     |
|    total_timesteps  | 293198   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 63299    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.262    |
| time/               |          |
|    episodes         | 16912    |
|    fps              | 161      |
|    time_elapsed     | 1819     |
|    total_timesteps  | 293261   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00275  |
|    n_updates        | 63315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0225  |
|    exploration_rate | 0.262    |
| time/               |          |
|    episodes         | 16916    |
|    fps              | 161      |
|    time_elapsed     | 1819     |
|    total_timesteps  | 293323   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00314  |
|    n_updates        | 63330    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.262    |
| time/               |          |
|    episodes         | 16920    |
|    fps              | 161      |
|    time_elapsed     | 1819     |
|    total_timesteps  | 293391   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 63347    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.261    |
| time/               |          |
|    episodes         | 16924    |
|    fps              | 161      |
|    time_elapsed     | 1819     |
|    total_timesteps  | 293452   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 63362    |
----------------------------------
Eval num_timesteps=293500, episode_reward=-0.09 +/- 0.15
Episode length: 26.70 +/- 16.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 26.7     |
|    mean_reward      | -0.0858  |
| rollout/            |          |
|    exploration_rate | 0.261    |
| time/               |          |
|    total_timesteps  | 293500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0017   |
|    n_updates        | 63374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.261    |
| time/               |          |
|    episodes         | 16928    |
|    fps              | 161      |
|    time_elapsed     | 1821     |
|    total_timesteps  | 293518   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 63379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.261    |
| time/               |          |
|    episodes         | 16932    |
|    fps              | 161      |
|    time_elapsed     | 1821     |
|    total_timesteps  | 293591   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00265  |
|    n_updates        | 63397    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.261    |
| time/               |          |
|    episodes         | 16936    |
|    fps              | 161      |
|    time_elapsed     | 1821     |
|    total_timesteps  | 293652   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 63412    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.26     |
| time/               |          |
|    episodes         | 16940    |
|    fps              | 161      |
|    time_elapsed     | 1821     |
|    total_timesteps  | 293716   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 63428    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.26     |
| time/               |          |
|    episodes         | 16944    |
|    fps              | 161      |
|    time_elapsed     | 1821     |
|    total_timesteps  | 293789   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00639  |
|    n_updates        | 63447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.26     |
| time/               |          |
|    episodes         | 16948    |
|    fps              | 161      |
|    time_elapsed     | 1821     |
|    total_timesteps  | 293849   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 63462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0319  |
|    exploration_rate | 0.259    |
| time/               |          |
|    episodes         | 16952    |
|    fps              | 161      |
|    time_elapsed     | 1821     |
|    total_timesteps  | 293909   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00349  |
|    n_updates        | 63477    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0319  |
|    exploration_rate | 0.259    |
| time/               |          |
|    episodes         | 16956    |
|    fps              | 161      |
|    time_elapsed     | 1821     |
|    total_timesteps  | 293970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00499  |
|    n_updates        | 63492    |
----------------------------------
Eval num_timesteps=294000, episode_reward=-0.04 +/- 0.14
Episode length: 14.96 +/- 0.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.0388  |
| rollout/            |          |
|    exploration_rate | 0.259    |
| time/               |          |
|    total_timesteps  | 294000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 63499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0322  |
|    exploration_rate | 0.259    |
| time/               |          |
|    episodes         | 16960    |
|    fps              | 161      |
|    time_elapsed     | 1822     |
|    total_timesteps  | 294036   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00367  |
|    n_updates        | 63508    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0322  |
|    exploration_rate | 0.259    |
| time/               |          |
|    episodes         | 16964    |
|    fps              | 161      |
|    time_elapsed     | 1822     |
|    total_timesteps  | 294099   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00459  |
|    n_updates        | 63524    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0322  |
|    exploration_rate | 0.258    |
| time/               |          |
|    episodes         | 16968    |
|    fps              | 161      |
|    time_elapsed     | 1823     |
|    total_timesteps  | 294159   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 63539    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.258    |
| time/               |          |
|    episodes         | 16972    |
|    fps              | 161      |
|    time_elapsed     | 1823     |
|    total_timesteps  | 294219   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 63554    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0322  |
|    exploration_rate | 0.258    |
| time/               |          |
|    episodes         | 16976    |
|    fps              | 161      |
|    time_elapsed     | 1823     |
|    total_timesteps  | 294283   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 63570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0423  |
|    exploration_rate | 0.258    |
| time/               |          |
|    episodes         | 16980    |
|    fps              | 161      |
|    time_elapsed     | 1823     |
|    total_timesteps  | 294343   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 63585    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0321  |
|    exploration_rate | 0.257    |
| time/               |          |
|    episodes         | 16984    |
|    fps              | 161      |
|    time_elapsed     | 1823     |
|    total_timesteps  | 294400   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 63599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0422  |
|    exploration_rate | 0.257    |
| time/               |          |
|    episodes         | 16988    |
|    fps              | 161      |
|    time_elapsed     | 1823     |
|    total_timesteps  | 294460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 63614    |
----------------------------------
Eval num_timesteps=294500, episode_reward=-0.06 +/- 0.00
Episode length: 15.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.059   |
| rollout/            |          |
|    exploration_rate | 0.257    |
| time/               |          |
|    total_timesteps  | 294500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00212  |
|    n_updates        | 63624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0418  |
|    exploration_rate | 0.257    |
| time/               |          |
|    episodes         | 16992    |
|    fps              | 161      |
|    time_elapsed     | 1824     |
|    total_timesteps  | 294521   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 63630    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0417  |
|    exploration_rate | 0.257    |
| time/               |          |
|    episodes         | 16996    |
|    fps              | 161      |
|    time_elapsed     | 1824     |
|    total_timesteps  | 294581   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 63645    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0316  |
|    exploration_rate | 0.256    |
| time/               |          |
|    episodes         | 17000    |
|    fps              | 161      |
|    time_elapsed     | 1825     |
|    total_timesteps  | 294639   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 63659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.256    |
| time/               |          |
|    episodes         | 17004    |
|    fps              | 161      |
|    time_elapsed     | 1825     |
|    total_timesteps  | 294710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 63677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0319  |
|    exploration_rate | 0.256    |
| time/               |          |
|    episodes         | 17008    |
|    fps              | 161      |
|    time_elapsed     | 1825     |
|    total_timesteps  | 294770   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0017   |
|    n_updates        | 63692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0318  |
|    exploration_rate | 0.255    |
| time/               |          |
|    episodes         | 17012    |
|    fps              | 161      |
|    time_elapsed     | 1825     |
|    total_timesteps  | 294831   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 63707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0317  |
|    exploration_rate | 0.255    |
| time/               |          |
|    episodes         | 17016    |
|    fps              | 161      |
|    time_elapsed     | 1825     |
|    total_timesteps  | 294891   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00322  |
|    n_updates        | 63722    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 0.255    |
| time/               |          |
|    episodes         | 17020    |
|    fps              | 161      |
|    time_elapsed     | 1825     |
|    total_timesteps  | 294949   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000867 |
|    n_updates        | 63737    |
----------------------------------
Eval num_timesteps=295000, episode_reward=-0.02 +/- 0.20
Episode length: 14.86 +/- 0.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0184  |
| rollout/            |          |
|    exploration_rate | 0.255    |
| time/               |          |
|    total_timesteps  | 295000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 63749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 0.255    |
| time/               |          |
|    episodes         | 17024    |
|    fps              | 161      |
|    time_elapsed     | 1826     |
|    total_timesteps  | 295010   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 63752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 0.254    |
| time/               |          |
|    episodes         | 17028    |
|    fps              | 161      |
|    time_elapsed     | 1826     |
|    total_timesteps  | 295071   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00294  |
|    n_updates        | 63767    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0108  |
|    exploration_rate | 0.254    |
| time/               |          |
|    episodes         | 17032    |
|    fps              | 161      |
|    time_elapsed     | 1827     |
|    total_timesteps  | 295134   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 63783    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.254    |
| time/               |          |
|    episodes         | 17036    |
|    fps              | 161      |
|    time_elapsed     | 1827     |
|    total_timesteps  | 295194   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0023   |
|    n_updates        | 63798    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.254    |
| time/               |          |
|    episodes         | 17040    |
|    fps              | 161      |
|    time_elapsed     | 1827     |
|    total_timesteps  | 295258   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 63814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 0.253    |
| time/               |          |
|    episodes         | 17044    |
|    fps              | 161      |
|    time_elapsed     | 1827     |
|    total_timesteps  | 295318   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 63829    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.253    |
| time/               |          |
|    episodes         | 17048    |
|    fps              | 161      |
|    time_elapsed     | 1827     |
|    total_timesteps  | 295382   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 63845    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.253    |
| time/               |          |
|    episodes         | 17052    |
|    fps              | 161      |
|    time_elapsed     | 1827     |
|    total_timesteps  | 295442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00257  |
|    n_updates        | 63860    |
----------------------------------
Eval num_timesteps=295500, episode_reward=-0.04 +/- 0.14
Episode length: 14.92 +/- 0.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0387  |
| rollout/            |          |
|    exploration_rate | 0.253    |
| time/               |          |
|    total_timesteps  | 295500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 63874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.252    |
| time/               |          |
|    episodes         | 17056    |
|    fps              | 161      |
|    time_elapsed     | 1828     |
|    total_timesteps  | 295502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 63875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 0.252    |
| time/               |          |
|    episodes         | 17060    |
|    fps              | 161      |
|    time_elapsed     | 1828     |
|    total_timesteps  | 295564   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00386  |
|    n_updates        | 63890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 0.252    |
| time/               |          |
|    episodes         | 17064    |
|    fps              | 161      |
|    time_elapsed     | 1829     |
|    total_timesteps  | 295625   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 63906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 0.252    |
| time/               |          |
|    episodes         | 17068    |
|    fps              | 161      |
|    time_elapsed     | 1829     |
|    total_timesteps  | 295686   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0019   |
|    n_updates        | 63921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 0.251    |
| time/               |          |
|    episodes         | 17072    |
|    fps              | 161      |
|    time_elapsed     | 1829     |
|    total_timesteps  | 295746   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00201  |
|    n_updates        | 63936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.01    |
|    exploration_rate | 0.251    |
| time/               |          |
|    episodes         | 17076    |
|    fps              | 161      |
|    time_elapsed     | 1829     |
|    total_timesteps  | 295807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 63951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00014  |
|    exploration_rate | 0.251    |
| time/               |          |
|    episodes         | 17080    |
|    fps              | 161      |
|    time_elapsed     | 1829     |
|    total_timesteps  | 295864   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00231  |
|    n_updates        | 63965    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.01    |
|    exploration_rate | 0.251    |
| time/               |          |
|    episodes         | 17084    |
|    fps              | 161      |
|    time_elapsed     | 1829     |
|    total_timesteps  | 295925   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 63981    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 3e-05    |
|    exploration_rate | 0.25     |
| time/               |          |
|    episodes         | 17088    |
|    fps              | 161      |
|    time_elapsed     | 1829     |
|    total_timesteps  | 295984   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00439  |
|    n_updates        | 63995    |
----------------------------------
Eval num_timesteps=296000, episode_reward=-0.05 +/- 0.15
Episode length: 17.48 +/- 7.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.5     |
|    mean_reward      | -0.0489  |
| rollout/            |          |
|    exploration_rate | 0.25     |
| time/               |          |
|    total_timesteps  | 296000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000896 |
|    n_updates        | 63999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 0.25     |
| time/               |          |
|    episodes         | 17092    |
|    fps              | 161      |
|    time_elapsed     | 1831     |
|    total_timesteps  | 296041   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 64010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 0.25     |
| time/               |          |
|    episodes         | 17096    |
|    fps              | 161      |
|    time_elapsed     | 1831     |
|    total_timesteps  | 296102   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 64025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -2e-05   |
|    exploration_rate | 0.25     |
| time/               |          |
|    episodes         | 17100    |
|    fps              | 161      |
|    time_elapsed     | 1831     |
|    total_timesteps  | 296165   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00236  |
|    n_updates        | 64041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00026  |
|    exploration_rate | 0.249    |
| time/               |          |
|    episodes         | 17104    |
|    fps              | 161      |
|    time_elapsed     | 1831     |
|    total_timesteps  | 296229   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00247  |
|    n_updates        | 64057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00981 |
|    exploration_rate | 0.249    |
| time/               |          |
|    episodes         | 17108    |
|    fps              | 161      |
|    time_elapsed     | 1831     |
|    total_timesteps  | 296291   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00249  |
|    n_updates        | 64072    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00981 |
|    exploration_rate | 0.249    |
| time/               |          |
|    episodes         | 17112    |
|    fps              | 161      |
|    time_elapsed     | 1831     |
|    total_timesteps  | 296352   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 64087    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00989 |
|    exploration_rate | 0.248    |
| time/               |          |
|    episodes         | 17116    |
|    fps              | 161      |
|    time_elapsed     | 1831     |
|    total_timesteps  | 296414   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 64103    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 0.248    |
| time/               |          |
|    episodes         | 17120    |
|    fps              | 161      |
|    time_elapsed     | 1831     |
|    total_timesteps  | 296474   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00234  |
|    n_updates        | 64118    |
----------------------------------
Eval num_timesteps=296500, episode_reward=-0.05 +/- 0.21
Episode length: 23.52 +/- 16.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 23.5     |
|    mean_reward      | -0.0531  |
| rollout/            |          |
|    exploration_rate | 0.248    |
| time/               |          |
|    total_timesteps  | 296500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 64124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 0.248    |
| time/               |          |
|    episodes         | 17124    |
|    fps              | 161      |
|    time_elapsed     | 1833     |
|    total_timesteps  | 296534   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 64133    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 0.248    |
| time/               |          |
|    episodes         | 17128    |
|    fps              | 161      |
|    time_elapsed     | 1833     |
|    total_timesteps  | 296597   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 64149    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0302  |
|    exploration_rate | 0.247    |
| time/               |          |
|    episodes         | 17132    |
|    fps              | 161      |
|    time_elapsed     | 1833     |
|    total_timesteps  | 296664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 64165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0303  |
|    exploration_rate | 0.247    |
| time/               |          |
|    episodes         | 17136    |
|    fps              | 161      |
|    time_elapsed     | 1834     |
|    total_timesteps  | 296728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00281  |
|    n_updates        | 64181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0305  |
|    exploration_rate | 0.247    |
| time/               |          |
|    episodes         | 17140    |
|    fps              | 161      |
|    time_elapsed     | 1834     |
|    total_timesteps  | 296797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 64199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0307  |
|    exploration_rate | 0.247    |
| time/               |          |
|    episodes         | 17144    |
|    fps              | 161      |
|    time_elapsed     | 1834     |
|    total_timesteps  | 296861   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000851 |
|    n_updates        | 64215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0311  |
|    exploration_rate | 0.246    |
| time/               |          |
|    episodes         | 17148    |
|    fps              | 161      |
|    time_elapsed     | 1834     |
|    total_timesteps  | 296935   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 64233    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0312  |
|    exploration_rate | 0.246    |
| time/               |          |
|    episodes         | 17152    |
|    fps              | 161      |
|    time_elapsed     | 1834     |
|    total_timesteps  | 296999   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00722  |
|    n_updates        | 64249    |
----------------------------------
Eval num_timesteps=297000, episode_reward=-0.02 +/- 0.20
Episode length: 14.84 +/- 0.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 14.8     |
|    mean_reward     | -0.0183  |
| time/              |          |
|    total_timesteps | 297000   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0313  |
|    exploration_rate | 0.246    |
| time/               |          |
|    episodes         | 17156    |
|    fps              | 161      |
|    time_elapsed     | 1835     |
|    total_timesteps  | 297060   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 64264    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0312  |
|    exploration_rate | 0.245    |
| time/               |          |
|    episodes         | 17160    |
|    fps              | 161      |
|    time_elapsed     | 1835     |
|    total_timesteps  | 297121   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 64280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0312  |
|    exploration_rate | 0.245    |
| time/               |          |
|    episodes         | 17164    |
|    fps              | 161      |
|    time_elapsed     | 1835     |
|    total_timesteps  | 297181   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00751  |
|    n_updates        | 64295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 0.245    |
| time/               |          |
|    episodes         | 17168    |
|    fps              | 161      |
|    time_elapsed     | 1836     |
|    total_timesteps  | 297239   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00265  |
|    n_updates        | 64309    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 0.245    |
| time/               |          |
|    episodes         | 17172    |
|    fps              | 161      |
|    time_elapsed     | 1836     |
|    total_timesteps  | 297301   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 64325    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.244    |
| time/               |          |
|    episodes         | 17176    |
|    fps              | 161      |
|    time_elapsed     | 1836     |
|    total_timesteps  | 297382   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00329  |
|    n_updates        | 64345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0322  |
|    exploration_rate | 0.244    |
| time/               |          |
|    episodes         | 17180    |
|    fps              | 161      |
|    time_elapsed     | 1836     |
|    total_timesteps  | 297445   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 64361    |
----------------------------------
Eval num_timesteps=297500, episode_reward=-0.04 +/- 0.14
Episode length: 14.92 +/- 0.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0387  |
| rollout/            |          |
|    exploration_rate | 0.244    |
| time/               |          |
|    total_timesteps  | 297500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 64374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.244    |
| time/               |          |
|    episodes         | 17184    |
|    fps              | 161      |
|    time_elapsed     | 1837     |
|    total_timesteps  | 297503   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 64375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0321  |
|    exploration_rate | 0.243    |
| time/               |          |
|    episodes         | 17188    |
|    fps              | 161      |
|    time_elapsed     | 1837     |
|    total_timesteps  | 297563   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00321  |
|    n_updates        | 64390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0425  |
|    exploration_rate | 0.243    |
| time/               |          |
|    episodes         | 17192    |
|    fps              | 161      |
|    time_elapsed     | 1837     |
|    total_timesteps  | 297629   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 64407    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0426  |
|    exploration_rate | 0.243    |
| time/               |          |
|    episodes         | 17196    |
|    fps              | 161      |
|    time_elapsed     | 1837     |
|    total_timesteps  | 297692   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00228  |
|    n_updates        | 64422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0427  |
|    exploration_rate | 0.243    |
| time/               |          |
|    episodes         | 17200    |
|    fps              | 161      |
|    time_elapsed     | 1838     |
|    total_timesteps  | 297758   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00461  |
|    n_updates        | 64439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0426  |
|    exploration_rate | 0.242    |
| time/               |          |
|    episodes         | 17204    |
|    fps              | 162      |
|    time_elapsed     | 1838     |
|    total_timesteps  | 297819   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 64454    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0425  |
|    exploration_rate | 0.242    |
| time/               |          |
|    episodes         | 17208    |
|    fps              | 162      |
|    time_elapsed     | 1838     |
|    total_timesteps  | 297879   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00203  |
|    n_updates        | 64469    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0433  |
|    exploration_rate | 0.242    |
| time/               |          |
|    episodes         | 17212    |
|    fps              | 162      |
|    time_elapsed     | 1838     |
|    total_timesteps  | 297959   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 64489    |
----------------------------------
Eval num_timesteps=298000, episode_reward=-0.06 +/- 0.00
Episode length: 15.04 +/- 0.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.0592  |
| rollout/            |          |
|    exploration_rate | 0.242    |
| time/               |          |
|    total_timesteps  | 298000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000745 |
|    n_updates        | 64499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0432  |
|    exploration_rate | 0.241    |
| time/               |          |
|    episodes         | 17216    |
|    fps              | 162      |
|    time_elapsed     | 1839     |
|    total_timesteps  | 298019   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 64504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0432  |
|    exploration_rate | 0.241    |
| time/               |          |
|    episodes         | 17220    |
|    fps              | 162      |
|    time_elapsed     | 1839     |
|    total_timesteps  | 298080   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 64519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0434  |
|    exploration_rate | 0.241    |
| time/               |          |
|    episodes         | 17224    |
|    fps              | 162      |
|    time_elapsed     | 1839     |
|    total_timesteps  | 298143   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 64535    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0434  |
|    exploration_rate | 0.241    |
| time/               |          |
|    episodes         | 17228    |
|    fps              | 162      |
|    time_elapsed     | 1840     |
|    total_timesteps  | 298208   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 64551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.24     |
| time/               |          |
|    episodes         | 17232    |
|    fps              | 162      |
|    time_elapsed     | 1840     |
|    total_timesteps  | 298265   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 64566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.24     |
| time/               |          |
|    episodes         | 17236    |
|    fps              | 162      |
|    time_elapsed     | 1840     |
|    total_timesteps  | 298322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 64580    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.24     |
| time/               |          |
|    episodes         | 17240    |
|    fps              | 162      |
|    time_elapsed     | 1840     |
|    total_timesteps  | 298383   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00254  |
|    n_updates        | 64595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 0.24     |
| time/               |          |
|    episodes         | 17244    |
|    fps              | 162      |
|    time_elapsed     | 1840     |
|    total_timesteps  | 298439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00424  |
|    n_updates        | 64609    |
----------------------------------
Eval num_timesteps=298500, episode_reward=-0.04 +/- 0.25
Episode length: 26.12 +/- 16.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 26.1     |
|    mean_reward      | -0.0435  |
| rollout/            |          |
|    exploration_rate | 0.239    |
| time/               |          |
|    total_timesteps  | 298500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 64624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.239    |
| time/               |          |
|    episodes         | 17248    |
|    fps              | 162      |
|    time_elapsed     | 1842     |
|    total_timesteps  | 298504   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 64625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 0.239    |
| time/               |          |
|    episodes         | 17252    |
|    fps              | 162      |
|    time_elapsed     | 1842     |
|    total_timesteps  | 298571   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 64642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 0.239    |
| time/               |          |
|    episodes         | 17256    |
|    fps              | 162      |
|    time_elapsed     | 1842     |
|    total_timesteps  | 298633   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00259  |
|    n_updates        | 64658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 0.238    |
| time/               |          |
|    episodes         | 17260    |
|    fps              | 162      |
|    time_elapsed     | 1842     |
|    total_timesteps  | 298693   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00468  |
|    n_updates        | 64673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.238    |
| time/               |          |
|    episodes         | 17264    |
|    fps              | 162      |
|    time_elapsed     | 1842     |
|    total_timesteps  | 298755   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 64688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.238    |
| time/               |          |
|    episodes         | 17268    |
|    fps              | 162      |
|    time_elapsed     | 1843     |
|    total_timesteps  | 298815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 64703    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.238    |
| time/               |          |
|    episodes         | 17272    |
|    fps              | 162      |
|    time_elapsed     | 1843     |
|    total_timesteps  | 298880   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00257  |
|    n_updates        | 64719    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.237    |
| time/               |          |
|    episodes         | 17276    |
|    fps              | 162      |
|    time_elapsed     | 1843     |
|    total_timesteps  | 298961   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 64740    |
----------------------------------
Eval num_timesteps=299000, episode_reward=-0.06 +/- 0.16
Episode length: 19.88 +/- 14.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.9     |
|    mean_reward      | -0.0586  |
| rollout/            |          |
|    exploration_rate | 0.237    |
| time/               |          |
|    total_timesteps  | 299000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 64749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.237    |
| time/               |          |
|    episodes         | 17280    |
|    fps              | 162      |
|    time_elapsed     | 1844     |
|    total_timesteps  | 299030   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 64757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0326  |
|    exploration_rate | 0.237    |
| time/               |          |
|    episodes         | 17284    |
|    fps              | 162      |
|    time_elapsed     | 1844     |
|    total_timesteps  | 299093   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 64773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.236    |
| time/               |          |
|    episodes         | 17288    |
|    fps              | 162      |
|    time_elapsed     | 1844     |
|    total_timesteps  | 299162   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 64790    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0327  |
|    exploration_rate | 0.236    |
| time/               |          |
|    episodes         | 17292    |
|    fps              | 162      |
|    time_elapsed     | 1845     |
|    total_timesteps  | 299222   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 64805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0327  |
|    exploration_rate | 0.236    |
| time/               |          |
|    episodes         | 17296    |
|    fps              | 162      |
|    time_elapsed     | 1845     |
|    total_timesteps  | 299285   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 64821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.236    |
| time/               |          |
|    episodes         | 17300    |
|    fps              | 162      |
|    time_elapsed     | 1845     |
|    total_timesteps  | 299358   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00437  |
|    n_updates        | 64839    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.235    |
| time/               |          |
|    episodes         | 17304    |
|    fps              | 162      |
|    time_elapsed     | 1845     |
|    total_timesteps  | 299413   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00315  |
|    n_updates        | 64853    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.235    |
| time/               |          |
|    episodes         | 17308    |
|    fps              | 162      |
|    time_elapsed     | 1845     |
|    total_timesteps  | 299484   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 64870    |
----------------------------------
Eval num_timesteps=299500, episode_reward=-0.07 +/- 0.19
Episode length: 28.56 +/- 14.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28.6     |
|    mean_reward      | -0.0732  |
| rollout/            |          |
|    exploration_rate | 0.235    |
| time/               |          |
|    total_timesteps  | 299500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 64874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.00274 |
|    exploration_rate | 0.235    |
| time/               |          |
|    episodes         | 17312    |
|    fps              | 162      |
|    time_elapsed     | 1847     |
|    total_timesteps  | 299552   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 64887    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00318 |
|    exploration_rate | 0.234    |
| time/               |          |
|    episodes         | 17316    |
|    fps              | 162      |
|    time_elapsed     | 1847     |
|    total_timesteps  | 299623   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00662  |
|    n_updates        | 64905    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00687  |
|    exploration_rate | 0.234    |
| time/               |          |
|    episodes         | 17320    |
|    fps              | 162      |
|    time_elapsed     | 1847     |
|    total_timesteps  | 299683   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 64920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00679  |
|    exploration_rate | 0.234    |
| time/               |          |
|    episodes         | 17324    |
|    fps              | 162      |
|    time_elapsed     | 1847     |
|    total_timesteps  | 299748   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00288  |
|    n_updates        | 64936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.234    |
| time/               |          |
|    episodes         | 17328    |
|    fps              | 162      |
|    time_elapsed     | 1847     |
|    total_timesteps  | 299806   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 64951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0068   |
|    exploration_rate | 0.233    |
| time/               |          |
|    episodes         | 17332    |
|    fps              | 162      |
|    time_elapsed     | 1848     |
|    total_timesteps  | 299870   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00309  |
|    n_updates        | 64967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00336 |
|    exploration_rate | 0.233    |
| time/               |          |
|    episodes         | 17336    |
|    fps              | 162      |
|    time_elapsed     | 1848     |
|    total_timesteps  | 299931   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000996 |
|    n_updates        | 64982    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00648  |
|    exploration_rate | 0.233    |
| time/               |          |
|    episodes         | 17340    |
|    fps              | 162      |
|    time_elapsed     | 1848     |
|    total_timesteps  | 299996   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 64998    |
----------------------------------
Eval num_timesteps=300000, episode_reward=-0.08 +/- 0.05
Episode length: 19.02 +/- 12.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19       |
|    mean_reward      | -0.0751  |
| rollout/            |          |
|    exploration_rate | 0.233    |
| time/               |          |
|    total_timesteps  | 300000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000816 |
|    n_updates        | 64999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00643  |
|    exploration_rate | 0.232    |
| time/               |          |
|    episodes         | 17344    |
|    fps              | 162      |
|    time_elapsed     | 1849     |
|    total_timesteps  | 300054   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00442  |
|    n_updates        | 65013    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.00579  |
|    exploration_rate | 0.232    |
| time/               |          |
|    episodes         | 17348    |
|    fps              | 162      |
|    time_elapsed     | 1850     |
|    total_timesteps  | 300135   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00297  |
|    n_updates        | 65033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.232    |
| time/               |          |
|    episodes         | 17352    |
|    fps              | 162      |
|    time_elapsed     | 1850     |
|    total_timesteps  | 300192   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00235  |
|    n_updates        | 65047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0263   |
|    exploration_rate | 0.232    |
| time/               |          |
|    episodes         | 17356    |
|    fps              | 162      |
|    time_elapsed     | 1850     |
|    total_timesteps  | 300253   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000929 |
|    n_updates        | 65063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0263   |
|    exploration_rate | 0.231    |
| time/               |          |
|    episodes         | 17360    |
|    fps              | 162      |
|    time_elapsed     | 1850     |
|    total_timesteps  | 300313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 65078    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0365   |
|    exploration_rate | 0.231    |
| time/               |          |
|    episodes         | 17364    |
|    fps              | 162      |
|    time_elapsed     | 1850     |
|    total_timesteps  | 300368   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 65091    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0365   |
|    exploration_rate | 0.231    |
| time/               |          |
|    episodes         | 17368    |
|    fps              | 162      |
|    time_elapsed     | 1850     |
|    total_timesteps  | 300428   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 65106    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0367   |
|    exploration_rate | 0.23     |
| time/               |          |
|    episodes         | 17372    |
|    fps              | 162      |
|    time_elapsed     | 1850     |
|    total_timesteps  | 300490   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00554  |
|    n_updates        | 65122    |
----------------------------------
Eval num_timesteps=300500, episode_reward=-0.04 +/- 0.14
Episode length: 14.96 +/- 0.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.0388  |
| rollout/            |          |
|    exploration_rate | 0.23     |
| time/               |          |
|    total_timesteps  | 300500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00226  |
|    n_updates        | 65124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0375   |
|    exploration_rate | 0.23     |
| time/               |          |
|    episodes         | 17376    |
|    fps              | 162      |
|    time_elapsed     | 1851     |
|    total_timesteps  | 300551   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 65137    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.23     |
| time/               |          |
|    episodes         | 17380    |
|    fps              | 162      |
|    time_elapsed     | 1851     |
|    total_timesteps  | 300614   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 65153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.23     |
| time/               |          |
|    episodes         | 17384    |
|    fps              | 162      |
|    time_elapsed     | 1852     |
|    total_timesteps  | 300677   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00436  |
|    n_updates        | 65169    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 0.229    |
| time/               |          |
|    episodes         | 17388    |
|    fps              | 162      |
|    time_elapsed     | 1852     |
|    total_timesteps  | 300739   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 65184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 0.229    |
| time/               |          |
|    episodes         | 17392    |
|    fps              | 162      |
|    time_elapsed     | 1852     |
|    total_timesteps  | 300799   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00265  |
|    n_updates        | 65199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0381   |
|    exploration_rate | 0.229    |
| time/               |          |
|    episodes         | 17396    |
|    fps              | 162      |
|    time_elapsed     | 1852     |
|    total_timesteps  | 300859   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 65214    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0385   |
|    exploration_rate | 0.229    |
| time/               |          |
|    episodes         | 17400    |
|    fps              | 162      |
|    time_elapsed     | 1852     |
|    total_timesteps  | 300921   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 65230    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0283   |
|    exploration_rate | 0.228    |
| time/               |          |
|    episodes         | 17404    |
|    fps              | 162      |
|    time_elapsed     | 1852     |
|    total_timesteps  | 300982   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 65245    |
----------------------------------
Eval num_timesteps=301000, episode_reward=0.00 +/- 0.24
Episode length: 14.82 +/- 0.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.0018   |
| rollout/            |          |
|    exploration_rate | 0.228    |
| time/               |          |
|    total_timesteps  | 301000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 65249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.228    |
| time/               |          |
|    episodes         | 17408    |
|    fps              | 162      |
|    time_elapsed     | 1853     |
|    total_timesteps  | 301043   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00278  |
|    n_updates        | 65260    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.228    |
| time/               |          |
|    episodes         | 17412    |
|    fps              | 162      |
|    time_elapsed     | 1853     |
|    total_timesteps  | 301104   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 65275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 0.228    |
| time/               |          |
|    episodes         | 17416    |
|    fps              | 162      |
|    time_elapsed     | 1853     |
|    total_timesteps  | 301161   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 65290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0195   |
|    exploration_rate | 0.227    |
| time/               |          |
|    episodes         | 17420    |
|    fps              | 162      |
|    time_elapsed     | 1853     |
|    total_timesteps  | 301222   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 65305    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 0.227    |
| time/               |          |
|    episodes         | 17424    |
|    fps              | 162      |
|    time_elapsed     | 1854     |
|    total_timesteps  | 301284   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 65320    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.00951  |
|    exploration_rate | 0.227    |
| time/               |          |
|    episodes         | 17428    |
|    fps              | 162      |
|    time_elapsed     | 1854     |
|    total_timesteps  | 301345   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 65336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.00955  |
|    exploration_rate | 0.226    |
| time/               |          |
|    episodes         | 17432    |
|    fps              | 162      |
|    time_elapsed     | 1854     |
|    total_timesteps  | 301408   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 65351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | 0.00951  |
|    exploration_rate | 0.226    |
| time/               |          |
|    episodes         | 17436    |
|    fps              | 162      |
|    time_elapsed     | 1854     |
|    total_timesteps  | 301470   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00322  |
|    n_updates        | 65367    |
----------------------------------
Eval num_timesteps=301500, episode_reward=0.00 +/- 0.24
Episode length: 14.80 +/- 0.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00184  |
| rollout/            |          |
|    exploration_rate | 0.226    |
| time/               |          |
|    total_timesteps  | 301500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00306  |
|    n_updates        | 65374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.00045 |
|    exploration_rate | 0.226    |
| time/               |          |
|    episodes         | 17440    |
|    fps              | 162      |
|    time_elapsed     | 1855     |
|    total_timesteps  | 301534   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0019   |
|    n_updates        | 65383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0106  |
|    exploration_rate | 0.226    |
| time/               |          |
|    episodes         | 17444    |
|    fps              | 162      |
|    time_elapsed     | 1855     |
|    total_timesteps  | 301596   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 65398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.00999 |
|    exploration_rate | 0.225    |
| time/               |          |
|    episodes         | 17448    |
|    fps              | 162      |
|    time_elapsed     | 1855     |
|    total_timesteps  | 301661   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00299  |
|    n_updates        | 65415    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.01    |
|    exploration_rate | 0.225    |
| time/               |          |
|    episodes         | 17452    |
|    fps              | 162      |
|    time_elapsed     | 1855     |
|    total_timesteps  | 301719   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 65429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 0.225    |
| time/               |          |
|    episodes         | 17456    |
|    fps              | 162      |
|    time_elapsed     | 1855     |
|    total_timesteps  | 301780   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 65444    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.225    |
| time/               |          |
|    episodes         | 17460    |
|    fps              | 162      |
|    time_elapsed     | 1856     |
|    total_timesteps  | 301841   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00188  |
|    n_updates        | 65460    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 0.224    |
| time/               |          |
|    episodes         | 17464    |
|    fps              | 162      |
|    time_elapsed     | 1856     |
|    total_timesteps  | 301900   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00227  |
|    n_updates        | 65474    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 0.224    |
| time/               |          |
|    episodes         | 17468    |
|    fps              | 162      |
|    time_elapsed     | 1856     |
|    total_timesteps  | 301960   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000932 |
|    n_updates        | 65489    |
----------------------------------
Eval num_timesteps=302000, episode_reward=-0.04 +/- 0.14
Episode length: 14.94 +/- 0.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0387  |
| rollout/            |          |
|    exploration_rate | 0.224    |
| time/               |          |
|    total_timesteps  | 302000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 65499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.224    |
| time/               |          |
|    episodes         | 17472    |
|    fps              | 162      |
|    time_elapsed     | 1857     |
|    total_timesteps  | 302020   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 65504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.223    |
| time/               |          |
|    episodes         | 17476    |
|    fps              | 162      |
|    time_elapsed     | 1857     |
|    total_timesteps  | 302080   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00292  |
|    n_updates        | 65519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.223    |
| time/               |          |
|    episodes         | 17480    |
|    fps              | 162      |
|    time_elapsed     | 1857     |
|    total_timesteps  | 302142   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000959 |
|    n_updates        | 65535    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.223    |
| time/               |          |
|    episodes         | 17484    |
|    fps              | 162      |
|    time_elapsed     | 1857     |
|    total_timesteps  | 302205   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 65551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0203  |
|    exploration_rate | 0.223    |
| time/               |          |
|    episodes         | 17488    |
|    fps              | 162      |
|    time_elapsed     | 1857     |
|    total_timesteps  | 302274   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 65568    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 0.222    |
| time/               |          |
|    episodes         | 17492    |
|    fps              | 162      |
|    time_elapsed     | 1857     |
|    total_timesteps  | 302335   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00369  |
|    n_updates        | 65583    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 0.222    |
| time/               |          |
|    episodes         | 17496    |
|    fps              | 162      |
|    time_elapsed     | 1858     |
|    total_timesteps  | 302398   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 65599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 0.222    |
| time/               |          |
|    episodes         | 17500    |
|    fps              | 162      |
|    time_elapsed     | 1858     |
|    total_timesteps  | 302462   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00323  |
|    n_updates        | 65615    |
----------------------------------
Eval num_timesteps=302500, episode_reward=0.00 +/- 0.24
Episode length: 14.78 +/- 0.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00188  |
| rollout/            |          |
|    exploration_rate | 0.222    |
| time/               |          |
|    total_timesteps  | 302500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00257  |
|    n_updates        | 65624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 0.221    |
| time/               |          |
|    episodes         | 17504    |
|    fps              | 162      |
|    time_elapsed     | 1859     |
|    total_timesteps  | 302520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 65629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 0.221    |
| time/               |          |
|    episodes         | 17508    |
|    fps              | 162      |
|    time_elapsed     | 1859     |
|    total_timesteps  | 302580   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000968 |
|    n_updates        | 65644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.221    |
| time/               |          |
|    episodes         | 17512    |
|    fps              | 162      |
|    time_elapsed     | 1859     |
|    total_timesteps  | 302636   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 65658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 0.221    |
| time/               |          |
|    episodes         | 17516    |
|    fps              | 162      |
|    time_elapsed     | 1859     |
|    total_timesteps  | 302698   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0042   |
|    n_updates        | 65674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 0.22     |
| time/               |          |
|    episodes         | 17520    |
|    fps              | 162      |
|    time_elapsed     | 1859     |
|    total_timesteps  | 302759   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000981 |
|    n_updates        | 65689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0207  |
|    exploration_rate | 0.22     |
| time/               |          |
|    episodes         | 17524    |
|    fps              | 162      |
|    time_elapsed     | 1859     |
|    total_timesteps  | 302826   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000955 |
|    n_updates        | 65706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 0.22     |
| time/               |          |
|    episodes         | 17528    |
|    fps              | 162      |
|    time_elapsed     | 1860     |
|    total_timesteps  | 302886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 65721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 0.22     |
| time/               |          |
|    episodes         | 17532    |
|    fps              | 162      |
|    time_elapsed     | 1860     |
|    total_timesteps  | 302948   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 65736    |
----------------------------------
Eval num_timesteps=303000, episode_reward=0.02 +/- 0.28
Episode length: 14.70 +/- 1.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0223   |
| rollout/            |          |
|    exploration_rate | 0.219    |
| time/               |          |
|    total_timesteps  | 303000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00283  |
|    n_updates        | 65749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 0.219    |
| time/               |          |
|    episodes         | 17536    |
|    fps              | 162      |
|    time_elapsed     | 1861     |
|    total_timesteps  | 303009   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0028   |
|    n_updates        | 65752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 0.219    |
| time/               |          |
|    episodes         | 17540    |
|    fps              | 162      |
|    time_elapsed     | 1861     |
|    total_timesteps  | 303071   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00309  |
|    n_updates        | 65767    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 0.219    |
| time/               |          |
|    episodes         | 17544    |
|    fps              | 162      |
|    time_elapsed     | 1861     |
|    total_timesteps  | 303132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 65782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 0.218    |
| time/               |          |
|    episodes         | 17548    |
|    fps              | 162      |
|    time_elapsed     | 1861     |
|    total_timesteps  | 303197   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0025   |
|    n_updates        | 65799    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0305  |
|    exploration_rate | 0.218    |
| time/               |          |
|    episodes         | 17552    |
|    fps              | 162      |
|    time_elapsed     | 1861     |
|    total_timesteps  | 303257   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 65814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 0.218    |
| time/               |          |
|    episodes         | 17556    |
|    fps              | 162      |
|    time_elapsed     | 1861     |
|    total_timesteps  | 303320   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 65829    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0307  |
|    exploration_rate | 0.218    |
| time/               |          |
|    episodes         | 17560    |
|    fps              | 162      |
|    time_elapsed     | 1861     |
|    total_timesteps  | 303383   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 65845    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0408  |
|    exploration_rate | 0.217    |
| time/               |          |
|    episodes         | 17564    |
|    fps              | 162      |
|    time_elapsed     | 1861     |
|    total_timesteps  | 303444   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 65860    |
----------------------------------
Eval num_timesteps=303500, episode_reward=0.02 +/- 0.28
Episode length: 14.72 +/- 0.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0222   |
| rollout/            |          |
|    exploration_rate | 0.217    |
| time/               |          |
|    total_timesteps  | 303500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00321  |
|    n_updates        | 65874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0307  |
|    exploration_rate | 0.217    |
| time/               |          |
|    episodes         | 17568    |
|    fps              | 162      |
|    time_elapsed     | 1863     |
|    total_timesteps  | 303502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 65875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0307  |
|    exploration_rate | 0.217    |
| time/               |          |
|    episodes         | 17572    |
|    fps              | 162      |
|    time_elapsed     | 1863     |
|    total_timesteps  | 303563   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 65890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0308  |
|    exploration_rate | 0.217    |
| time/               |          |
|    episodes         | 17576    |
|    fps              | 162      |
|    time_elapsed     | 1863     |
|    total_timesteps  | 303626   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00252  |
|    n_updates        | 65906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0308  |
|    exploration_rate | 0.216    |
| time/               |          |
|    episodes         | 17580    |
|    fps              | 162      |
|    time_elapsed     | 1863     |
|    total_timesteps  | 303686   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 65921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0307  |
|    exploration_rate | 0.216    |
| time/               |          |
|    episodes         | 17584    |
|    fps              | 162      |
|    time_elapsed     | 1863     |
|    total_timesteps  | 303747   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00178  |
|    n_updates        | 65936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0304  |
|    exploration_rate | 0.216    |
| time/               |          |
|    episodes         | 17588    |
|    fps              | 163      |
|    time_elapsed     | 1863     |
|    total_timesteps  | 303810   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 65952    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0304  |
|    exploration_rate | 0.215    |
| time/               |          |
|    episodes         | 17592    |
|    fps              | 163      |
|    time_elapsed     | 1863     |
|    total_timesteps  | 303870   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 65967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0303  |
|    exploration_rate | 0.215    |
| time/               |          |
|    episodes         | 17596    |
|    fps              | 163      |
|    time_elapsed     | 1863     |
|    total_timesteps  | 303930   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00182  |
|    n_updates        | 65982    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 0.215    |
| time/               |          |
|    episodes         | 17600    |
|    fps              | 163      |
|    time_elapsed     | 1864     |
|    total_timesteps  | 303987   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00329  |
|    n_updates        | 65996    |
----------------------------------
Eval num_timesteps=304000, episode_reward=0.00 +/- 0.24
Episode length: 14.82 +/- 0.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00182  |
| rollout/            |          |
|    exploration_rate | 0.215    |
| time/               |          |
|    total_timesteps  | 304000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00285  |
|    n_updates        | 65999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0301  |
|    exploration_rate | 0.215    |
| time/               |          |
|    episodes         | 17604    |
|    fps              | 163      |
|    time_elapsed     | 1865     |
|    total_timesteps  | 304047   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 66011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0301  |
|    exploration_rate | 0.214    |
| time/               |          |
|    episodes         | 17608    |
|    fps              | 163      |
|    time_elapsed     | 1865     |
|    total_timesteps  | 304108   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 66026    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0402  |
|    exploration_rate | 0.214    |
| time/               |          |
|    episodes         | 17612    |
|    fps              | 163      |
|    time_elapsed     | 1865     |
|    total_timesteps  | 304168   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00356  |
|    n_updates        | 66041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0402  |
|    exploration_rate | 0.214    |
| time/               |          |
|    episodes         | 17616    |
|    fps              | 163      |
|    time_elapsed     | 1865     |
|    total_timesteps  | 304229   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 66057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.03    |
|    exploration_rate | 0.214    |
| time/               |          |
|    episodes         | 17620    |
|    fps              | 163      |
|    time_elapsed     | 1865     |
|    total_timesteps  | 304285   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 66071    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0195  |
|    exploration_rate | 0.213    |
| time/               |          |
|    episodes         | 17624    |
|    fps              | 163      |
|    time_elapsed     | 1865     |
|    total_timesteps  | 304341   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00439  |
|    n_updates        | 66085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 0.213    |
| time/               |          |
|    episodes         | 17628    |
|    fps              | 163      |
|    time_elapsed     | 1865     |
|    total_timesteps  | 304406   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 66101    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00972 |
|    exploration_rate | 0.213    |
| time/               |          |
|    episodes         | 17632    |
|    fps              | 163      |
|    time_elapsed     | 1865     |
|    total_timesteps  | 304467   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 66116    |
----------------------------------
Eval num_timesteps=304500, episode_reward=0.00 +/- 0.24
Episode length: 14.76 +/- 0.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00198  |
| rollout/            |          |
|    exploration_rate | 0.213    |
| time/               |          |
|    total_timesteps  | 304500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 66124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00984 |
|    exploration_rate | 0.213    |
| time/               |          |
|    episodes         | 17636    |
|    fps              | 163      |
|    time_elapsed     | 1866     |
|    total_timesteps  | 304531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00193  |
|    n_updates        | 66132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0098  |
|    exploration_rate | 0.212    |
| time/               |          |
|    episodes         | 17640    |
|    fps              | 163      |
|    time_elapsed     | 1867     |
|    total_timesteps  | 304592   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00285  |
|    n_updates        | 66147    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00043  |
|    exploration_rate | 0.212    |
| time/               |          |
|    episodes         | 17644    |
|    fps              | 163      |
|    time_elapsed     | 1867     |
|    total_timesteps  | 304647   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 66161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00047  |
|    exploration_rate | 0.212    |
| time/               |          |
|    episodes         | 17648    |
|    fps              | 163      |
|    time_elapsed     | 1867     |
|    total_timesteps  | 304711   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 66177    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00031  |
|    exploration_rate | 0.211    |
| time/               |          |
|    episodes         | 17652    |
|    fps              | 163      |
|    time_elapsed     | 1867     |
|    total_timesteps  | 304775   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000939 |
|    n_updates        | 66193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00023  |
|    exploration_rate | 0.211    |
| time/               |          |
|    episodes         | 17656    |
|    fps              | 163      |
|    time_elapsed     | 1867     |
|    total_timesteps  | 304840   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00675  |
|    n_updates        | 66209    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00027  |
|    exploration_rate | 0.211    |
| time/               |          |
|    episodes         | 17660    |
|    fps              | 163      |
|    time_elapsed     | 1867     |
|    total_timesteps  | 304902   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 66225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00031  |
|    exploration_rate | 0.211    |
| time/               |          |
|    episodes         | 17664    |
|    fps              | 163      |
|    time_elapsed     | 1867     |
|    total_timesteps  | 304962   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000821 |
|    n_updates        | 66240    |
----------------------------------
Eval num_timesteps=305000, episode_reward=0.00 +/- 0.24
Episode length: 14.80 +/- 0.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00178  |
| rollout/            |          |
|    exploration_rate | 0.21     |
| time/               |          |
|    total_timesteps  | 305000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00293  |
|    n_updates        | 66249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00022  |
|    exploration_rate | 0.21     |
| time/               |          |
|    episodes         | 17668    |
|    fps              | 163      |
|    time_elapsed     | 1868     |
|    total_timesteps  | 305022   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00241  |
|    n_updates        | 66255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00018  |
|    exploration_rate | 0.21     |
| time/               |          |
|    episodes         | 17672    |
|    fps              | 163      |
|    time_elapsed     | 1869     |
|    total_timesteps  | 305084   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 66270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -2e-05   |
|    exploration_rate | 0.21     |
| time/               |          |
|    episodes         | 17676    |
|    fps              | 163      |
|    time_elapsed     | 1869     |
|    total_timesteps  | 305152   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 66287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 0.209    |
| time/               |          |
|    episodes         | 17680    |
|    fps              | 163      |
|    time_elapsed     | 1869     |
|    total_timesteps  | 305208   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 66301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 0.209    |
| time/               |          |
|    episodes         | 17684    |
|    fps              | 163      |
|    time_elapsed     | 1869     |
|    total_timesteps  | 305268   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00347  |
|    n_updates        | 66316    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.209    |
| time/               |          |
|    episodes         | 17688    |
|    fps              | 163      |
|    time_elapsed     | 1869     |
|    total_timesteps  | 305328   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 66331    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.209    |
| time/               |          |
|    episodes         | 17692    |
|    fps              | 163      |
|    time_elapsed     | 1869     |
|    total_timesteps  | 305388   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 66346    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 0.208    |
| time/               |          |
|    episodes         | 17696    |
|    fps              | 163      |
|    time_elapsed     | 1869     |
|    total_timesteps  | 305453   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00256  |
|    n_updates        | 66363    |
----------------------------------
Eval num_timesteps=305500, episode_reward=0.04 +/- 0.31
Episode length: 14.58 +/- 1.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0427   |
| rollout/            |          |
|    exploration_rate | 0.208    |
| time/               |          |
|    total_timesteps  | 305500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00162  |
|    n_updates        | 66374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.00013 |
|    exploration_rate | 0.208    |
| time/               |          |
|    episodes         | 17700    |
|    fps              | 163      |
|    time_elapsed     | 1870     |
|    total_timesteps  | 305515   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 66378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.208    |
| time/               |          |
|    episodes         | 17704    |
|    fps              | 163      |
|    time_elapsed     | 1871     |
|    total_timesteps  | 305572   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00259  |
|    n_updates        | 66392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | 0.00992  |
|    exploration_rate | 0.208    |
| time/               |          |
|    episodes         | 17708    |
|    fps              | 163      |
|    time_elapsed     | 1871     |
|    total_timesteps  | 305635   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 66408    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | 0.00984  |
|    exploration_rate | 0.207    |
| time/               |          |
|    episodes         | 17712    |
|    fps              | 163      |
|    time_elapsed     | 1871     |
|    total_timesteps  | 305697   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 66424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | 0.00988  |
|    exploration_rate | 0.207    |
| time/               |          |
|    episodes         | 17716    |
|    fps              | 163      |
|    time_elapsed     | 1871     |
|    total_timesteps  | 305757   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 66439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0003  |
|    exploration_rate | 0.207    |
| time/               |          |
|    episodes         | 17720    |
|    fps              | 163      |
|    time_elapsed     | 1871     |
|    total_timesteps  | 305817   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 66454    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0105  |
|    exploration_rate | 0.207    |
| time/               |          |
|    episodes         | 17724    |
|    fps              | 163      |
|    time_elapsed     | 1871     |
|    total_timesteps  | 305877   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00266  |
|    n_updates        | 66469    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0001  |
|    exploration_rate | 0.206    |
| time/               |          |
|    episodes         | 17728    |
|    fps              | 163      |
|    time_elapsed     | 1871     |
|    total_timesteps  | 305933   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00248  |
|    n_updates        | 66483    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 0.206    |
| time/               |          |
|    episodes         | 17732    |
|    fps              | 163      |
|    time_elapsed     | 1871     |
|    total_timesteps  | 305995   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0021   |
|    n_updates        | 66498    |
----------------------------------
Eval num_timesteps=306000, episode_reward=-0.04 +/- 0.14
Episode length: 14.92 +/- 0.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0387  |
| rollout/            |          |
|    exploration_rate | 0.206    |
| time/               |          |
|    total_timesteps  | 306000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 66499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.01    |
|    exploration_rate | 0.206    |
| time/               |          |
|    episodes         | 17736    |
|    fps              | 163      |
|    time_elapsed     | 1872     |
|    total_timesteps  | 306056   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 66513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 0.205    |
| time/               |          |
|    episodes         | 17740    |
|    fps              | 163      |
|    time_elapsed     | 1872     |
|    total_timesteps  | 306119   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 66529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 0.205    |
| time/               |          |
|    episodes         | 17744    |
|    fps              | 163      |
|    time_elapsed     | 1873     |
|    total_timesteps  | 306181   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 66545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 0.205    |
| time/               |          |
|    episodes         | 17748    |
|    fps              | 163      |
|    time_elapsed     | 1873     |
|    total_timesteps  | 306242   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00189  |
|    n_updates        | 66560    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.3     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 0.205    |
| time/               |          |
|    episodes         | 17752    |
|    fps              | 163      |
|    time_elapsed     | 1873     |
|    total_timesteps  | 306304   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 66575    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00981 |
|    exploration_rate | 0.204    |
| time/               |          |
|    episodes         | 17756    |
|    fps              | 163      |
|    time_elapsed     | 1873     |
|    total_timesteps  | 306360   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 66589    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00985 |
|    exploration_rate | 0.204    |
| time/               |          |
|    episodes         | 17760    |
|    fps              | 163      |
|    time_elapsed     | 1873     |
|    total_timesteps  | 306423   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00322  |
|    n_updates        | 66605    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00985 |
|    exploration_rate | 0.204    |
| time/               |          |
|    episodes         | 17764    |
|    fps              | 163      |
|    time_elapsed     | 1873     |
|    total_timesteps  | 306483   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 66620    |
----------------------------------
Eval num_timesteps=306500, episode_reward=0.02 +/- 0.27
Episode length: 14.78 +/- 0.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.022    |
| rollout/            |          |
|    exploration_rate | 0.204    |
| time/               |          |
|    total_timesteps  | 306500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000955 |
|    n_updates        | 66624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 0.204    |
| time/               |          |
|    episodes         | 17768    |
|    fps              | 163      |
|    time_elapsed     | 1874     |
|    total_timesteps  | 306545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 66636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 0.203    |
| time/               |          |
|    episodes         | 17772    |
|    fps              | 163      |
|    time_elapsed     | 1874     |
|    total_timesteps  | 306607   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.002    |
|    n_updates        | 66651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.203    |
| time/               |          |
|    episodes         | 17776    |
|    fps              | 163      |
|    time_elapsed     | 1874     |
|    total_timesteps  | 306668   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00191  |
|    n_updates        | 66666    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 0.203    |
| time/               |          |
|    episodes         | 17780    |
|    fps              | 163      |
|    time_elapsed     | 1875     |
|    total_timesteps  | 306726   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 66681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00066  |
|    exploration_rate | 0.202    |
| time/               |          |
|    episodes         | 17784    |
|    fps              | 163      |
|    time_elapsed     | 1875     |
|    total_timesteps  | 306777   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00283  |
|    n_updates        | 66694    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00066  |
|    exploration_rate | 0.202    |
| time/               |          |
|    episodes         | 17788    |
|    fps              | 163      |
|    time_elapsed     | 1875     |
|    total_timesteps  | 306837   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00295  |
|    n_updates        | 66709    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00058  |
|    exploration_rate | 0.202    |
| time/               |          |
|    episodes         | 17792    |
|    fps              | 163      |
|    time_elapsed     | 1875     |
|    total_timesteps  | 306899   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00268  |
|    n_updates        | 66724    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 0.202    |
| time/               |          |
|    episodes         | 17796    |
|    fps              | 163      |
|    time_elapsed     | 1875     |
|    total_timesteps  | 306955   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0018   |
|    n_updates        | 66738    |
----------------------------------
Eval num_timesteps=307000, episode_reward=0.00 +/- 0.24
Episode length: 14.80 +/- 0.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00184  |
| rollout/            |          |
|    exploration_rate | 0.201    |
| time/               |          |
|    total_timesteps  | 307000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000944 |
|    n_updates        | 66749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.011    |
|    exploration_rate | 0.201    |
| time/               |          |
|    episodes         | 17800    |
|    fps              | 163      |
|    time_elapsed     | 1876     |
|    total_timesteps  | 307015   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000906 |
|    n_updates        | 66753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00077  |
|    exploration_rate | 0.201    |
| time/               |          |
|    episodes         | 17804    |
|    fps              | 163      |
|    time_elapsed     | 1876     |
|    total_timesteps  | 307078   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 66769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 0.201    |
| time/               |          |
|    episodes         | 17808    |
|    fps              | 163      |
|    time_elapsed     | 1876     |
|    total_timesteps  | 307138   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00502  |
|    n_updates        | 66784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.201    |
| time/               |          |
|    episodes         | 17812    |
|    fps              | 163      |
|    time_elapsed     | 1876     |
|    total_timesteps  | 307195   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0028   |
|    n_updates        | 66798    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 17816    |
|    fps              | 163      |
|    time_elapsed     | 1877     |
|    total_timesteps  | 307256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 66813    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 17820    |
|    fps              | 163      |
|    time_elapsed     | 1877     |
|    total_timesteps  | 307322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 66830    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0309   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 17824    |
|    fps              | 163      |
|    time_elapsed     | 1877     |
|    total_timesteps  | 307379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 66844    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 17828    |
|    fps              | 163      |
|    time_elapsed     | 1877     |
|    total_timesteps  | 307439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 66859    |
----------------------------------
Eval num_timesteps=307500, episode_reward=-0.06 +/- 0.00
Episode length: 15.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.059   |
| rollout/            |          |
|    exploration_rate | 0.199    |
| time/               |          |
|    total_timesteps  | 307500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 66874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 0.199    |
| time/               |          |
|    episodes         | 17832    |
|    fps              | 163      |
|    time_elapsed     | 1878     |
|    total_timesteps  | 307500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0207   |
|    exploration_rate | 0.199    |
| time/               |          |
|    episodes         | 17836    |
|    fps              | 163      |
|    time_elapsed     | 1878     |
|    total_timesteps  | 307564   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 66890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 0.199    |
| time/               |          |
|    episodes         | 17840    |
|    fps              | 163      |
|    time_elapsed     | 1878     |
|    total_timesteps  | 307624   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 66905    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0209   |
|    exploration_rate | 0.198    |
| time/               |          |
|    episodes         | 17844    |
|    fps              | 163      |
|    time_elapsed     | 1878     |
|    total_timesteps  | 307685   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 66921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0209   |
|    exploration_rate | 0.198    |
| time/               |          |
|    episodes         | 17848    |
|    fps              | 163      |
|    time_elapsed     | 1879     |
|    total_timesteps  | 307745   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00303  |
|    n_updates        | 66936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.021    |
|    exploration_rate | 0.198    |
| time/               |          |
|    episodes         | 17852    |
|    fps              | 163      |
|    time_elapsed     | 1879     |
|    total_timesteps  | 307805   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000993 |
|    n_updates        | 66951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0108   |
|    exploration_rate | 0.198    |
| time/               |          |
|    episodes         | 17856    |
|    fps              | 163      |
|    time_elapsed     | 1879     |
|    total_timesteps  | 307865   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 66966    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.197    |
| time/               |          |
|    episodes         | 17860    |
|    fps              | 163      |
|    time_elapsed     | 1879     |
|    total_timesteps  | 307922   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 66980    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.197    |
| time/               |          |
|    episodes         | 17864    |
|    fps              | 163      |
|    time_elapsed     | 1879     |
|    total_timesteps  | 307982   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 66995    |
----------------------------------
Eval num_timesteps=308000, episode_reward=-0.02 +/- 0.20
Episode length: 14.86 +/- 0.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0184  |
| rollout/            |          |
|    exploration_rate | 0.197    |
| time/               |          |
|    total_timesteps  | 308000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 66999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0212   |
|    exploration_rate | 0.197    |
| time/               |          |
|    episodes         | 17868    |
|    fps              | 163      |
|    time_elapsed     | 1880     |
|    total_timesteps  | 308042   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 67010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.197    |
| time/               |          |
|    episodes         | 17872    |
|    fps              | 163      |
|    time_elapsed     | 1880     |
|    total_timesteps  | 308107   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 67026    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.196    |
| time/               |          |
|    episodes         | 17876    |
|    fps              | 163      |
|    time_elapsed     | 1880     |
|    total_timesteps  | 308168   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 67041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.011    |
|    exploration_rate | 0.196    |
| time/               |          |
|    episodes         | 17880    |
|    fps              | 163      |
|    time_elapsed     | 1881     |
|    total_timesteps  | 308228   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 67056    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00076  |
|    exploration_rate | 0.196    |
| time/               |          |
|    episodes         | 17884    |
|    fps              | 163      |
|    time_elapsed     | 1881     |
|    total_timesteps  | 308284   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 67070    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00076  |
|    exploration_rate | 0.195    |
| time/               |          |
|    episodes         | 17888    |
|    fps              | 163      |
|    time_elapsed     | 1881     |
|    total_timesteps  | 308344   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0023   |
|    n_updates        | 67085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00084  |
|    exploration_rate | 0.195    |
| time/               |          |
|    episodes         | 17892    |
|    fps              | 163      |
|    time_elapsed     | 1881     |
|    total_timesteps  | 308404   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 67100    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.00932 |
|    exploration_rate | 0.195    |
| time/               |          |
|    episodes         | 17896    |
|    fps              | 163      |
|    time_elapsed     | 1881     |
|    total_timesteps  | 308464   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 67115    |
----------------------------------
Eval num_timesteps=308500, episode_reward=-0.02 +/- 0.20
Episode length: 14.88 +/- 0.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0185  |
| rollout/            |          |
|    exploration_rate | 0.195    |
| time/               |          |
|    total_timesteps  | 308500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 67124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00956 |
|    exploration_rate | 0.195    |
| time/               |          |
|    episodes         | 17900    |
|    fps              | 163      |
|    time_elapsed     | 1882     |
|    total_timesteps  | 308530   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00367  |
|    n_updates        | 67132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0096  |
|    exploration_rate | 0.194    |
| time/               |          |
|    episodes         | 17904    |
|    fps              | 163      |
|    time_elapsed     | 1882     |
|    total_timesteps  | 308594   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00241  |
|    n_updates        | 67148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.0095  |
|    exploration_rate | 0.194    |
| time/               |          |
|    episodes         | 17908    |
|    fps              | 163      |
|    time_elapsed     | 1882     |
|    total_timesteps  | 308652   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0025   |
|    n_updates        | 67162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.194    |
| time/               |          |
|    episodes         | 17912    |
|    fps              | 163      |
|    time_elapsed     | 1882     |
|    total_timesteps  | 308712   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 67177    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0198  |
|    exploration_rate | 0.193    |
| time/               |          |
|    episodes         | 17916    |
|    fps              | 163      |
|    time_elapsed     | 1882     |
|    total_timesteps  | 308776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00592  |
|    n_updates        | 67193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.193    |
| time/               |          |
|    episodes         | 17920    |
|    fps              | 164      |
|    time_elapsed     | 1883     |
|    total_timesteps  | 308837   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 67209    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.193    |
| time/               |          |
|    episodes         | 17924    |
|    fps              | 164      |
|    time_elapsed     | 1883     |
|    total_timesteps  | 308900   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00459  |
|    n_updates        | 67224    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.193    |
| time/               |          |
|    episodes         | 17928    |
|    fps              | 164      |
|    time_elapsed     | 1883     |
|    total_timesteps  | 308961   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00229  |
|    n_updates        | 67240    |
----------------------------------
Eval num_timesteps=309000, episode_reward=-0.06 +/- 0.00
Episode length: 15.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15       |
|    mean_reward      | -0.059   |
| rollout/            |          |
|    exploration_rate | 0.192    |
| time/               |          |
|    total_timesteps  | 309000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00224  |
|    n_updates        | 67249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.192    |
| time/               |          |
|    episodes         | 17932    |
|    fps              | 163      |
|    time_elapsed     | 1884     |
|    total_timesteps  | 309021   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00274  |
|    n_updates        | 67255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0296  |
|    exploration_rate | 0.192    |
| time/               |          |
|    episodes         | 17936    |
|    fps              | 164      |
|    time_elapsed     | 1884     |
|    total_timesteps  | 309081   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 67270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.192    |
| time/               |          |
|    episodes         | 17940    |
|    fps              | 164      |
|    time_elapsed     | 1884     |
|    total_timesteps  | 309144   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 67285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0297  |
|    exploration_rate | 0.192    |
| time/               |          |
|    episodes         | 17944    |
|    fps              | 164      |
|    time_elapsed     | 1884     |
|    total_timesteps  | 309204   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 67300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0297  |
|    exploration_rate | 0.191    |
| time/               |          |
|    episodes         | 17948    |
|    fps              | 164      |
|    time_elapsed     | 1884     |
|    total_timesteps  | 309264   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 67315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.191    |
| time/               |          |
|    episodes         | 17952    |
|    fps              | 164      |
|    time_elapsed     | 1884     |
|    total_timesteps  | 309322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00363  |
|    n_updates        | 67330    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.00946 |
|    exploration_rate | 0.191    |
| time/               |          |
|    episodes         | 17956    |
|    fps              | 164      |
|    time_elapsed     | 1885     |
|    total_timesteps  | 309378   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000752 |
|    n_updates        | 67344    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.191    |
| time/               |          |
|    episodes         | 17960    |
|    fps              | 164      |
|    time_elapsed     | 1885     |
|    total_timesteps  | 309439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 67359    |
----------------------------------
Eval num_timesteps=309500, episode_reward=0.02 +/- 0.28
Episode length: 14.72 +/- 0.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.7     |
|    mean_reward      | 0.0222   |
| rollout/            |          |
|    exploration_rate | 0.19     |
| time/               |          |
|    total_timesteps  | 309500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 67374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 0.19     |
| time/               |          |
|    episodes         | 17964    |
|    fps              | 164      |
|    time_elapsed     | 1886     |
|    total_timesteps  | 309500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 0.19     |
| time/               |          |
|    episodes         | 17968    |
|    fps              | 164      |
|    time_elapsed     | 1886     |
|    total_timesteps  | 309560   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 67389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.19     |
| time/               |          |
|    episodes         | 17972    |
|    fps              | 164      |
|    time_elapsed     | 1886     |
|    total_timesteps  | 309623   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 67405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.189    |
| time/               |          |
|    episodes         | 17976    |
|    fps              | 164      |
|    time_elapsed     | 1886     |
|    total_timesteps  | 309683   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 67420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.00942 |
|    exploration_rate | 0.189    |
| time/               |          |
|    episodes         | 17980    |
|    fps              | 164      |
|    time_elapsed     | 1886     |
|    total_timesteps  | 309740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 67434    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.189    |
| time/               |          |
|    episodes         | 17984    |
|    fps              | 164      |
|    time_elapsed     | 1886     |
|    total_timesteps  | 309800   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0037   |
|    n_updates        | 67449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0196  |
|    exploration_rate | 0.189    |
| time/               |          |
|    episodes         | 17988    |
|    fps              | 164      |
|    time_elapsed     | 1886     |
|    total_timesteps  | 309861   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00413  |
|    n_updates        | 67465    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 0.188    |
| time/               |          |
|    episodes         | 17992    |
|    fps              | 164      |
|    time_elapsed     | 1887     |
|    total_timesteps  | 309922   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 67480    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00964 |
|    exploration_rate | 0.188    |
| time/               |          |
|    episodes         | 17996    |
|    fps              | 164      |
|    time_elapsed     | 1887     |
|    total_timesteps  | 309982   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 67495    |
----------------------------------
Eval num_timesteps=310000, episode_reward=0.00 +/- 0.24
Episode length: 14.82 +/- 0.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.00176  |
| rollout/            |          |
|    exploration_rate | 0.188    |
| time/               |          |
|    total_timesteps  | 310000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 67499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.00944 |
|    exploration_rate | 0.188    |
| time/               |          |
|    episodes         | 18000    |
|    fps              | 164      |
|    time_elapsed     | 1888     |
|    total_timesteps  | 310043   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 67510    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.00932 |
|    exploration_rate | 0.188    |
| time/               |          |
|    episodes         | 18004    |
|    fps              | 164      |
|    time_elapsed     | 1888     |
|    total_timesteps  | 310104   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 67525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.0194  |
|    exploration_rate | 0.187    |
| time/               |          |
|    episodes         | 18008    |
|    fps              | 164      |
|    time_elapsed     | 1888     |
|    total_timesteps  | 310164   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 67540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.0194  |
|    exploration_rate | 0.187    |
| time/               |          |
|    episodes         | 18012    |
|    fps              | 164      |
|    time_elapsed     | 1888     |
|    total_timesteps  | 310224   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00229  |
|    n_updates        | 67555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.0193  |
|    exploration_rate | 0.187    |
| time/               |          |
|    episodes         | 18016    |
|    fps              | 164      |
|    time_elapsed     | 1888     |
|    total_timesteps  | 310285   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00248  |
|    n_updates        | 67571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 0.186    |
| time/               |          |
|    episodes         | 18020    |
|    fps              | 164      |
|    time_elapsed     | 1888     |
|    total_timesteps  | 310345   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00322  |
|    n_updates        | 67586    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.0194  |
|    exploration_rate | 0.186    |
| time/               |          |
|    episodes         | 18024    |
|    fps              | 164      |
|    time_elapsed     | 1889     |
|    total_timesteps  | 310411   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000945 |
|    n_updates        | 67602    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | -0.00923 |
|    exploration_rate | 0.186    |
| time/               |          |
|    episodes         | 18028    |
|    fps              | 164      |
|    time_elapsed     | 1889     |
|    total_timesteps  | 310469   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 67617    |
----------------------------------
Eval num_timesteps=310500, episode_reward=-0.04 +/- 0.14
Episode length: 14.90 +/- 0.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0386  |
| rollout/            |          |
|    exploration_rate | 0.186    |
| time/               |          |
|    total_timesteps  | 310500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 67624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 0.186    |
| time/               |          |
|    episodes         | 18032    |
|    fps              | 164      |
|    time_elapsed     | 1890     |
|    total_timesteps  | 310526   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 67631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 0.185    |
| time/               |          |
|    episodes         | 18036    |
|    fps              | 164      |
|    time_elapsed     | 1890     |
|    total_timesteps  | 310587   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00249  |
|    n_updates        | 67646    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.185    |
| time/               |          |
|    episodes         | 18040    |
|    fps              | 164      |
|    time_elapsed     | 1890     |
|    total_timesteps  | 310643   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00524  |
|    n_updates        | 67660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.185    |
| time/               |          |
|    episodes         | 18044    |
|    fps              | 164      |
|    time_elapsed     | 1890     |
|    total_timesteps  | 310703   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00237  |
|    n_updates        | 67675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.185    |
| time/               |          |
|    episodes         | 18048    |
|    fps              | 164      |
|    time_elapsed     | 1890     |
|    total_timesteps  | 310763   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000971 |
|    n_updates        | 67690    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.0212   |
|    exploration_rate | 0.184    |
| time/               |          |
|    episodes         | 18052    |
|    fps              | 164      |
|    time_elapsed     | 1890     |
|    total_timesteps  | 310820   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 67704    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15       |
|    ep_rew_mean      | 0.011    |
|    exploration_rate | 0.184    |
| time/               |          |
|    episodes         | 18056    |
|    fps              | 164      |
|    time_elapsed     | 1890     |
|    total_timesteps  | 310881   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00149  |
|    n_updates        | 67720    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 0.184    |
| time/               |          |
|    episodes         | 18060    |
|    fps              | 164      |
|    time_elapsed     | 1890     |
|    total_timesteps  | 310944   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00199  |
|    n_updates        | 67735    |
----------------------------------
Eval num_timesteps=311000, episode_reward=-0.04 +/- 0.14
Episode length: 14.92 +/- 0.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0386  |
| rollout/            |          |
|    exploration_rate | 0.183    |
| time/               |          |
|    total_timesteps  | 311000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00209  |
|    n_updates        | 67749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 0.183    |
| time/               |          |
|    episodes         | 18064    |
|    fps              | 164      |
|    time_elapsed     | 1892     |
|    total_timesteps  | 311005   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00959  |
|    n_updates        | 67751    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0108   |
|    exploration_rate | 0.183    |
| time/               |          |
|    episodes         | 18068    |
|    fps              | 164      |
|    time_elapsed     | 1892     |
|    total_timesteps  | 311068   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00205  |
|    n_updates        | 67766    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0108   |
|    exploration_rate | 0.183    |
| time/               |          |
|    episodes         | 18072    |
|    fps              | 164      |
|    time_elapsed     | 1892     |
|    total_timesteps  | 311129   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000687 |
|    n_updates        | 67782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0108   |
|    exploration_rate | 0.183    |
| time/               |          |
|    episodes         | 18076    |
|    fps              | 164      |
|    time_elapsed     | 1892     |
|    total_timesteps  | 311189   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0026   |
|    n_updates        | 67797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00061  |
|    exploration_rate | 0.182    |
| time/               |          |
|    episodes         | 18080    |
|    fps              | 164      |
|    time_elapsed     | 1892     |
|    total_timesteps  | 311251   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 67812    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0107   |
|    exploration_rate | 0.182    |
| time/               |          |
|    episodes         | 18084    |
|    fps              | 164      |
|    time_elapsed     | 1892     |
|    total_timesteps  | 311309   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 67827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0107   |
|    exploration_rate | 0.182    |
| time/               |          |
|    episodes         | 18088    |
|    fps              | 164      |
|    time_elapsed     | 1892     |
|    total_timesteps  | 311371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000929 |
|    n_updates        | 67842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.0107   |
|    exploration_rate | 0.182    |
| time/               |          |
|    episodes         | 18092    |
|    fps              | 164      |
|    time_elapsed     | 1893     |
|    total_timesteps  | 311432   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 67857    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00056  |
|    exploration_rate | 0.181    |
| time/               |          |
|    episodes         | 18096    |
|    fps              | 164      |
|    time_elapsed     | 1893     |
|    total_timesteps  | 311494   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 67873    |
----------------------------------
Eval num_timesteps=311500, episode_reward=-0.04 +/- 0.14
Episode length: 15.10 +/- 0.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.1     |
|    mean_reward      | -0.0394  |
| rollout/            |          |
|    exploration_rate | 0.181    |
| time/               |          |
|    total_timesteps  | 311500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 67874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.1     |
|    ep_rew_mean      | 0.00056  |
|    exploration_rate | 0.181    |
| time/               |          |
|    episodes         | 18100    |
|    fps              | 164      |
|    time_elapsed     | 1894     |
|    total_timesteps  | 311555   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 67888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00044  |
|    exploration_rate | 0.181    |
| time/               |          |
|    episodes         | 18104    |
|    fps              | 164      |
|    time_elapsed     | 1894     |
|    total_timesteps  | 311619   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 67904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.0004   |
|    exploration_rate | 0.18     |
| time/               |          |
|    episodes         | 18108    |
|    fps              | 164      |
|    time_elapsed     | 1894     |
|    total_timesteps  | 311680   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 67919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.0004   |
|    exploration_rate | 0.18     |
| time/               |          |
|    episodes         | 18112    |
|    fps              | 164      |
|    time_elapsed     | 1894     |
|    total_timesteps  | 311740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 67934    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00016  |
|    exploration_rate | 0.18     |
| time/               |          |
|    episodes         | 18116    |
|    fps              | 164      |
|    time_elapsed     | 1894     |
|    total_timesteps  | 311807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00374  |
|    n_updates        | 67951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00016  |
|    exploration_rate | 0.18     |
| time/               |          |
|    episodes         | 18120    |
|    fps              | 164      |
|    time_elapsed     | 1894     |
|    total_timesteps  | 311867   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00285  |
|    n_updates        | 67966    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | 0.00028  |
|    exploration_rate | 0.179    |
| time/               |          |
|    episodes         | 18124    |
|    fps              | 164      |
|    time_elapsed     | 1895     |
|    total_timesteps  | 311930   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0048   |
|    n_updates        | 67982    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.2     |
|    ep_rew_mean      | -0.00982 |
|    exploration_rate | 0.179    |
| time/               |          |
|    episodes         | 18128    |
|    fps              | 164      |
|    time_elapsed     | 1895     |
|    total_timesteps  | 311990   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00384  |
|    n_updates        | 67997    |
----------------------------------
Eval num_timesteps=312000, episode_reward=-0.03 +/- 0.20
Episode length: 16.52 +/- 4.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.5     |
|    mean_reward      | -0.0251  |
| rollout/            |          |
|    exploration_rate | 0.179    |
| time/               |          |
|    total_timesteps  | 312000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0028   |
|    n_updates        | 67999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.4     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 0.179    |
| time/               |          |
|    episodes         | 18132    |
|    fps              | 164      |
|    time_elapsed     | 1896     |
|    total_timesteps  | 312066   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 68016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0309  |
|    exploration_rate | 0.178    |
| time/               |          |
|    episodes         | 18136    |
|    fps              | 164      |
|    time_elapsed     | 1896     |
|    total_timesteps  | 312135   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000999 |
|    n_updates        | 68033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | -0.0311  |
|    exploration_rate | 0.178    |
| time/               |          |
|    episodes         | 18140    |
|    fps              | 164      |
|    time_elapsed     | 1896     |
|    total_timesteps  | 312197   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 68049    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0325  |
|    exploration_rate | 0.178    |
| time/               |          |
|    episodes         | 18144    |
|    fps              | 164      |
|    time_elapsed     | 1896     |
|    total_timesteps  | 312290   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 68072    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0336  |
|    exploration_rate | 0.177    |
| time/               |          |
|    episodes         | 18148    |
|    fps              | 164      |
|    time_elapsed     | 1897     |
|    total_timesteps  | 312378   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 68094    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.177    |
| time/               |          |
|    episodes         | 18152    |
|    fps              | 164      |
|    time_elapsed     | 1897     |
|    total_timesteps  | 312446   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 68111    |
----------------------------------
Eval num_timesteps=312500, episode_reward=-0.07 +/- 0.20
Episode length: 28.40 +/- 18.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28.4     |
|    mean_reward      | -0.0727  |
| rollout/            |          |
|    exploration_rate | 0.177    |
| time/               |          |
|    total_timesteps  | 312500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 68124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 0.177    |
| time/               |          |
|    episodes         | 18156    |
|    fps              | 164      |
|    time_elapsed     | 1899     |
|    total_timesteps  | 312517   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 68129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.176    |
| time/               |          |
|    episodes         | 18160    |
|    fps              | 164      |
|    time_elapsed     | 1899     |
|    total_timesteps  | 312588   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.004    |
|    n_updates        | 68146    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.035   |
|    exploration_rate | 0.176    |
| time/               |          |
|    episodes         | 18164    |
|    fps              | 164      |
|    time_elapsed     | 1899     |
|    total_timesteps  | 312655   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0032   |
|    n_updates        | 68163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0264  |
|    exploration_rate | 0.176    |
| time/               |          |
|    episodes         | 18168    |
|    fps              | 164      |
|    time_elapsed     | 1899     |
|    total_timesteps  | 312753   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000922 |
|    n_updates        | 68188    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.175    |
| time/               |          |
|    episodes         | 18172    |
|    fps              | 164      |
|    time_elapsed     | 1899     |
|    total_timesteps  | 312829   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00093  |
|    n_updates        | 68207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0276  |
|    exploration_rate | 0.175    |
| time/               |          |
|    episodes         | 18176    |
|    fps              | 164      |
|    time_elapsed     | 1900     |
|    total_timesteps  | 312905   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000764 |
|    n_updates        | 68226    |
----------------------------------
Eval num_timesteps=313000, episode_reward=-0.11 +/- 0.07
Episode length: 28.50 +/- 16.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28.5     |
|    mean_reward      | -0.113   |
| rollout/            |          |
|    exploration_rate | 0.174    |
| time/               |          |
|    total_timesteps  | 313000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00243  |
|    n_updates        | 68249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0289  |
|    exploration_rate | 0.174    |
| time/               |          |
|    episodes         | 18180    |
|    fps              | 164      |
|    time_elapsed     | 1902     |
|    total_timesteps  | 313000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0393  |
|    exploration_rate | 0.174    |
| time/               |          |
|    episodes         | 18184    |
|    fps              | 164      |
|    time_elapsed     | 1902     |
|    total_timesteps  | 313067   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000913 |
|    n_updates        | 68266    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0396  |
|    exploration_rate | 0.174    |
| time/               |          |
|    episodes         | 18188    |
|    fps              | 164      |
|    time_elapsed     | 1902     |
|    total_timesteps  | 313137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00329  |
|    n_updates        | 68284    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0402  |
|    exploration_rate | 0.173    |
| time/               |          |
|    episodes         | 18192    |
|    fps              | 164      |
|    time_elapsed     | 1902     |
|    total_timesteps  | 313214   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 68303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0311  |
|    exploration_rate | 0.173    |
| time/               |          |
|    episodes         | 18196    |
|    fps              | 164      |
|    time_elapsed     | 1902     |
|    total_timesteps  | 313299   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00331  |
|    n_updates        | 68324    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0319  |
|    exploration_rate | 0.173    |
| time/               |          |
|    episodes         | 18200    |
|    fps              | 164      |
|    time_elapsed     | 1902     |
|    total_timesteps  | 313379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00092  |
|    n_updates        | 68344    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.172    |
| time/               |          |
|    episodes         | 18204    |
|    fps              | 164      |
|    time_elapsed     | 1902     |
|    total_timesteps  | 313476   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00259  |
|    n_updates        | 68368    |
----------------------------------
Eval num_timesteps=313500, episode_reward=-0.14 +/- 0.08
Episode length: 35.88 +/- 20.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 35.9     |
|    mean_reward      | -0.143   |
| rollout/            |          |
|    exploration_rate | 0.172    |
| time/               |          |
|    total_timesteps  | 313500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 68374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0333  |
|    exploration_rate | 0.172    |
| time/               |          |
|    episodes         | 18208    |
|    fps              | 164      |
|    time_elapsed     | 1905     |
|    total_timesteps  | 313539   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 68384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0338  |
|    exploration_rate | 0.172    |
| time/               |          |
|    episodes         | 18212    |
|    fps              | 164      |
|    time_elapsed     | 1905     |
|    total_timesteps  | 313612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 68402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0343  |
|    exploration_rate | 0.171    |
| time/               |          |
|    episodes         | 18216    |
|    fps              | 164      |
|    time_elapsed     | 1905     |
|    total_timesteps  | 313691   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 68422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0345  |
|    exploration_rate | 0.171    |
| time/               |          |
|    episodes         | 18220    |
|    fps              | 164      |
|    time_elapsed     | 1905     |
|    total_timesteps  | 313756   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000765 |
|    n_updates        | 68438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0367  |
|    exploration_rate | 0.17     |
| time/               |          |
|    episodes         | 18224    |
|    fps              | 164      |
|    time_elapsed     | 1906     |
|    total_timesteps  | 313874   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 68468    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0371  |
|    exploration_rate | 0.17     |
| time/               |          |
|    episodes         | 18228    |
|    fps              | 164      |
|    time_elapsed     | 1906     |
|    total_timesteps  | 313945   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000785 |
|    n_updates        | 68486    |
----------------------------------
Eval num_timesteps=314000, episode_reward=-0.15 +/- 0.08
Episode length: 37.60 +/- 20.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.6     |
|    mean_reward      | -0.149   |
| rollout/            |          |
|    exploration_rate | 0.17     |
| time/               |          |
|    total_timesteps  | 314000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000862 |
|    n_updates        | 68499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.037   |
|    exploration_rate | 0.17     |
| time/               |          |
|    episodes         | 18232    |
|    fps              | 164      |
|    time_elapsed     | 1908     |
|    total_timesteps  | 314017   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 68504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.0378  |
|    exploration_rate | 0.169    |
| time/               |          |
|    episodes         | 18236    |
|    fps              | 164      |
|    time_elapsed     | 1908     |
|    total_timesteps  | 314106   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 68526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0492  |
|    exploration_rate | 0.169    |
| time/               |          |
|    episodes         | 18240    |
|    fps              | 164      |
|    time_elapsed     | 1908     |
|    total_timesteps  | 314204   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000949 |
|    n_updates        | 68550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0485  |
|    exploration_rate | 0.169    |
| time/               |          |
|    episodes         | 18244    |
|    fps              | 164      |
|    time_elapsed     | 1909     |
|    total_timesteps  | 314279   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000987 |
|    n_updates        | 68569    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0486  |
|    exploration_rate | 0.168    |
| time/               |          |
|    episodes         | 18248    |
|    fps              | 164      |
|    time_elapsed     | 1909     |
|    total_timesteps  | 314369   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 68592    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.0489  |
|    exploration_rate | 0.168    |
| time/               |          |
|    episodes         | 18252    |
|    fps              | 164      |
|    time_elapsed     | 1909     |
|    total_timesteps  | 314445   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00439  |
|    n_updates        | 68611    |
----------------------------------
Eval num_timesteps=314500, episode_reward=-0.15 +/- 0.08
Episode length: 37.14 +/- 20.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.1     |
|    mean_reward      | -0.148   |
| rollout/            |          |
|    exploration_rate | 0.168    |
| time/               |          |
|    total_timesteps  | 314500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 68624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0599  |
|    exploration_rate | 0.167    |
| time/               |          |
|    episodes         | 18256    |
|    fps              | 164      |
|    time_elapsed     | 1911     |
|    total_timesteps  | 314540   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00155  |
|    n_updates        | 68634    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0606  |
|    exploration_rate | 0.167    |
| time/               |          |
|    episodes         | 18260    |
|    fps              | 164      |
|    time_elapsed     | 1912     |
|    total_timesteps  | 314629   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00346  |
|    n_updates        | 68657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0415  |
|    exploration_rate | 0.167    |
| time/               |          |
|    episodes         | 18264    |
|    fps              | 164      |
|    time_elapsed     | 1912     |
|    total_timesteps  | 314719   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000828 |
|    n_updates        | 68679    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0511  |
|    exploration_rate | 0.166    |
| time/               |          |
|    episodes         | 18268    |
|    fps              | 164      |
|    time_elapsed     | 1912     |
|    total_timesteps  | 314806   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000923 |
|    n_updates        | 68701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0512  |
|    exploration_rate | 0.166    |
| time/               |          |
|    episodes         | 18272    |
|    fps              | 164      |
|    time_elapsed     | 1912     |
|    total_timesteps  | 314884   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00254  |
|    n_updates        | 68720    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0512  |
|    exploration_rate | 0.165    |
| time/               |          |
|    episodes         | 18276    |
|    fps              | 164      |
|    time_elapsed     | 1912     |
|    total_timesteps  | 314960   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 68739    |
----------------------------------
Eval num_timesteps=315000, episode_reward=-0.16 +/- 0.16
Episode length: 45.78 +/- 23.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.8     |
|    mean_reward      | -0.162   |
| rollout/            |          |
|    exploration_rate | 0.165    |
| time/               |          |
|    total_timesteps  | 315000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 68749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0503  |
|    exploration_rate | 0.165    |
| time/               |          |
|    episodes         | 18280    |
|    fps              | 164      |
|    time_elapsed     | 1916     |
|    total_timesteps  | 315033   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00182  |
|    n_updates        | 68758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0503  |
|    exploration_rate | 0.165    |
| time/               |          |
|    episodes         | 18284    |
|    fps              | 164      |
|    time_elapsed     | 1916     |
|    total_timesteps  | 315101   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 68775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0506  |
|    exploration_rate | 0.165    |
| time/               |          |
|    episodes         | 18288    |
|    fps              | 164      |
|    time_elapsed     | 1916     |
|    total_timesteps  | 315177   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00241  |
|    n_updates        | 68794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0502  |
|    exploration_rate | 0.164    |
| time/               |          |
|    episodes         | 18292    |
|    fps              | 164      |
|    time_elapsed     | 1916     |
|    total_timesteps  | 315245   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 68811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0597  |
|    exploration_rate | 0.164    |
| time/               |          |
|    episodes         | 18296    |
|    fps              | 164      |
|    time_elapsed     | 1916     |
|    total_timesteps  | 315318   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00416  |
|    n_updates        | 68829    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.0491  |
|    exploration_rate | 0.164    |
| time/               |          |
|    episodes         | 18300    |
|    fps              | 164      |
|    time_elapsed     | 1916     |
|    total_timesteps  | 315382   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 68845    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.0491  |
|    exploration_rate | 0.163    |
| time/               |          |
|    episodes         | 18304    |
|    fps              | 164      |
|    time_elapsed     | 1916     |
|    total_timesteps  | 315480   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 68869    |
----------------------------------
Eval num_timesteps=315500, episode_reward=-0.14 +/- 0.17
Episode length: 41.04 +/- 26.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41       |
|    mean_reward      | -0.143   |
| rollout/            |          |
|    exploration_rate | 0.163    |
| time/               |          |
|    total_timesteps  | 315500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000948 |
|    n_updates        | 68874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0496  |
|    exploration_rate | 0.163    |
| time/               |          |
|    episodes         | 18308    |
|    fps              | 164      |
|    time_elapsed     | 1919     |
|    total_timesteps  | 315555   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 68888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0499  |
|    exploration_rate | 0.162    |
| time/               |          |
|    episodes         | 18312    |
|    fps              | 164      |
|    time_elapsed     | 1919     |
|    total_timesteps  | 315634   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0038   |
|    n_updates        | 68908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0405  |
|    exploration_rate | 0.162    |
| time/               |          |
|    episodes         | 18316    |
|    fps              | 164      |
|    time_elapsed     | 1919     |
|    total_timesteps  | 315728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 68931    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0406  |
|    exploration_rate | 0.162    |
| time/               |          |
|    episodes         | 18320    |
|    fps              | 164      |
|    time_elapsed     | 1919     |
|    total_timesteps  | 315797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 68949    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0399  |
|    exploration_rate | 0.161    |
| time/               |          |
|    episodes         | 18324    |
|    fps              | 164      |
|    time_elapsed     | 1920     |
|    total_timesteps  | 315896   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 68973    |
----------------------------------
Eval num_timesteps=316000, episode_reward=-0.21 +/- 0.18
Episode length: 56.68 +/- 24.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.7     |
|    mean_reward      | -0.206   |
| rollout/            |          |
|    exploration_rate | 0.161    |
| time/               |          |
|    total_timesteps  | 316000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00327  |
|    n_updates        | 68999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0313  |
|    exploration_rate | 0.161    |
| time/               |          |
|    episodes         | 18328    |
|    fps              | 164      |
|    time_elapsed     | 1923     |
|    total_timesteps  | 316002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 69000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0324  |
|    exploration_rate | 0.16     |
| time/               |          |
|    episodes         | 18332    |
|    fps              | 164      |
|    time_elapsed     | 1923     |
|    total_timesteps  | 316103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 69025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0316  |
|    exploration_rate | 0.16     |
| time/               |          |
|    episodes         | 18336    |
|    fps              | 164      |
|    time_elapsed     | 1923     |
|    total_timesteps  | 316172   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00171  |
|    n_updates        | 69042    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0315  |
|    exploration_rate | 0.16     |
| time/               |          |
|    episodes         | 18340    |
|    fps              | 164      |
|    time_elapsed     | 1924     |
|    total_timesteps  | 316266   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 69066    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0323  |
|    exploration_rate | 0.159    |
| time/               |          |
|    episodes         | 18344    |
|    fps              | 164      |
|    time_elapsed     | 1924     |
|    total_timesteps  | 316361   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0027   |
|    n_updates        | 69090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.022   |
|    exploration_rate | 0.159    |
| time/               |          |
|    episodes         | 18348    |
|    fps              | 164      |
|    time_elapsed     | 1924     |
|    total_timesteps  | 316445   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 69111    |
----------------------------------
Eval num_timesteps=316500, episode_reward=-0.20 +/- 0.10
Episode length: 49.62 +/- 25.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.6     |
|    mean_reward      | -0.198   |
| rollout/            |          |
|    exploration_rate | 0.158    |
| time/               |          |
|    total_timesteps  | 316500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00191  |
|    n_updates        | 69124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.158    |
| time/               |          |
|    episodes         | 18352    |
|    fps              | 164      |
|    time_elapsed     | 1927     |
|    total_timesteps  | 316525   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00403  |
|    n_updates        | 69131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 0.158    |
| time/               |          |
|    episodes         | 18356    |
|    fps              | 164      |
|    time_elapsed     | 1927     |
|    total_timesteps  | 316594   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000978 |
|    n_updates        | 69148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0208  |
|    exploration_rate | 0.158    |
| time/               |          |
|    episodes         | 18360    |
|    fps              | 164      |
|    time_elapsed     | 1928     |
|    total_timesteps  | 316676   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 69168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0403  |
|    exploration_rate | 0.157    |
| time/               |          |
|    episodes         | 18364    |
|    fps              | 164      |
|    time_elapsed     | 1928     |
|    total_timesteps  | 316751   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00153  |
|    n_updates        | 69187    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0409  |
|    exploration_rate | 0.157    |
| time/               |          |
|    episodes         | 18368    |
|    fps              | 164      |
|    time_elapsed     | 1928     |
|    total_timesteps  | 316853   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 69213    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0417  |
|    exploration_rate | 0.156    |
| time/               |          |
|    episodes         | 18372    |
|    fps              | 164      |
|    time_elapsed     | 1928     |
|    total_timesteps  | 316951   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 69237    |
----------------------------------
Eval num_timesteps=317000, episode_reward=-0.23 +/- 0.10
Episode length: 57.30 +/- 24.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.3     |
|    mean_reward      | -0.229   |
| rollout/            |          |
|    exploration_rate | 0.156    |
| time/               |          |
|    total_timesteps  | 317000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 69249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0419  |
|    exploration_rate | 0.156    |
| time/               |          |
|    episodes         | 18376    |
|    fps              | 164      |
|    time_elapsed     | 1932     |
|    total_timesteps  | 317034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 69258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0415  |
|    exploration_rate | 0.156    |
| time/               |          |
|    episodes         | 18380    |
|    fps              | 164      |
|    time_elapsed     | 1932     |
|    total_timesteps  | 317096   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00333  |
|    n_updates        | 69273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0421  |
|    exploration_rate | 0.155    |
| time/               |          |
|    episodes         | 18384    |
|    fps              | 164      |
|    time_elapsed     | 1932     |
|    total_timesteps  | 317180   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 69294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0436  |
|    exploration_rate | 0.155    |
| time/               |          |
|    episodes         | 18388    |
|    fps              | 164      |
|    time_elapsed     | 1932     |
|    total_timesteps  | 317292   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 69322    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0435  |
|    exploration_rate | 0.155    |
| time/               |          |
|    episodes         | 18392    |
|    fps              | 164      |
|    time_elapsed     | 1932     |
|    total_timesteps  | 317359   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 69339    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0438  |
|    exploration_rate | 0.154    |
| time/               |          |
|    episodes         | 18396    |
|    fps              | 164      |
|    time_elapsed     | 1932     |
|    total_timesteps  | 317439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 69359    |
----------------------------------
Eval num_timesteps=317500, episode_reward=-0.20 +/- 0.09
Episode length: 49.56 +/- 23.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.6     |
|    mean_reward      | -0.198   |
| rollout/            |          |
|    exploration_rate | 0.154    |
| time/               |          |
|    total_timesteps  | 317500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00423  |
|    n_updates        | 69374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0546  |
|    exploration_rate | 0.154    |
| time/               |          |
|    episodes         | 18400    |
|    fps              | 164      |
|    time_elapsed     | 1936     |
|    total_timesteps  | 317522   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00207  |
|    n_updates        | 69380    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0539  |
|    exploration_rate | 0.153    |
| time/               |          |
|    episodes         | 18404    |
|    fps              | 164      |
|    time_elapsed     | 1936     |
|    total_timesteps  | 317603   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00331  |
|    n_updates        | 69400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0544  |
|    exploration_rate | 0.153    |
| time/               |          |
|    episodes         | 18408    |
|    fps              | 164      |
|    time_elapsed     | 1936     |
|    total_timesteps  | 317691   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00166  |
|    n_updates        | 69422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0541  |
|    exploration_rate | 0.153    |
| time/               |          |
|    episodes         | 18412    |
|    fps              | 164      |
|    time_elapsed     | 1936     |
|    total_timesteps  | 317763   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00257  |
|    n_updates        | 69440    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0635  |
|    exploration_rate | 0.152    |
| time/               |          |
|    episodes         | 18416    |
|    fps              | 164      |
|    time_elapsed     | 1936     |
|    total_timesteps  | 317841   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000907 |
|    n_updates        | 69460    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0647  |
|    exploration_rate | 0.152    |
| time/               |          |
|    episodes         | 18420    |
|    fps              | 164      |
|    time_elapsed     | 1936     |
|    total_timesteps  | 317939   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000816 |
|    n_updates        | 69484    |
----------------------------------
Eval num_timesteps=318000, episode_reward=-0.13 +/- 0.16
Episode length: 37.60 +/- 22.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.6     |
|    mean_reward      | -0.13    |
| rollout/            |          |
|    exploration_rate | 0.152    |
| time/               |          |
|    total_timesteps  | 318000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 69499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0645  |
|    exploration_rate | 0.151    |
| time/               |          |
|    episodes         | 18424    |
|    fps              | 163      |
|    time_elapsed     | 1939     |
|    total_timesteps  | 318034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 69508    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0542  |
|    exploration_rate | 0.151    |
| time/               |          |
|    episodes         | 18428    |
|    fps              | 164      |
|    time_elapsed     | 1939     |
|    total_timesteps  | 318132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00268  |
|    n_updates        | 69532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0538  |
|    exploration_rate | 0.151    |
| time/               |          |
|    episodes         | 18432    |
|    fps              | 164      |
|    time_elapsed     | 1939     |
|    total_timesteps  | 318223   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00401  |
|    n_updates        | 69555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.15     |
| time/               |          |
|    episodes         | 18436    |
|    fps              | 164      |
|    time_elapsed     | 1939     |
|    total_timesteps  | 318296   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000876 |
|    n_updates        | 69573    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0431  |
|    exploration_rate | 0.15     |
| time/               |          |
|    episodes         | 18440    |
|    fps              | 164      |
|    time_elapsed     | 1939     |
|    total_timesteps  | 318369   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0041   |
|    n_updates        | 69592    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0427  |
|    exploration_rate | 0.15     |
| time/               |          |
|    episodes         | 18444    |
|    fps              | 164      |
|    time_elapsed     | 1940     |
|    total_timesteps  | 318453   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000555 |
|    n_updates        | 69613    |
----------------------------------
Eval num_timesteps=318500, episode_reward=-0.17 +/- 0.10
Episode length: 43.44 +/- 24.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.4     |
|    mean_reward      | -0.173   |
| rollout/            |          |
|    exploration_rate | 0.149    |
| time/               |          |
|    total_timesteps  | 318500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 69624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0531  |
|    exploration_rate | 0.149    |
| time/               |          |
|    episodes         | 18448    |
|    fps              | 163      |
|    time_elapsed     | 1942     |
|    total_timesteps  | 318548   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 69636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0532  |
|    exploration_rate | 0.149    |
| time/               |          |
|    episodes         | 18452    |
|    fps              | 163      |
|    time_elapsed     | 1943     |
|    total_timesteps  | 318630   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 69657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0531  |
|    exploration_rate | 0.148    |
| time/               |          |
|    episodes         | 18456    |
|    fps              | 164      |
|    time_elapsed     | 1943     |
|    total_timesteps  | 318697   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00369  |
|    n_updates        | 69674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0534  |
|    exploration_rate | 0.148    |
| time/               |          |
|    episodes         | 18460    |
|    fps              | 164      |
|    time_elapsed     | 1943     |
|    total_timesteps  | 318785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00196  |
|    n_updates        | 69696    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0538  |
|    exploration_rate | 0.148    |
| time/               |          |
|    episodes         | 18464    |
|    fps              | 164      |
|    time_elapsed     | 1943     |
|    total_timesteps  | 318872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 69717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0424  |
|    exploration_rate | 0.147    |
| time/               |          |
|    episodes         | 18468    |
|    fps              | 164      |
|    time_elapsed     | 1943     |
|    total_timesteps  | 318938   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00218  |
|    n_updates        | 69734    |
----------------------------------
Eval num_timesteps=319000, episode_reward=-0.17 +/- 0.09
Episode length: 42.62 +/- 22.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | -0.17    |
| rollout/            |          |
|    exploration_rate | 0.147    |
| time/               |          |
|    total_timesteps  | 319000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 69749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0429  |
|    exploration_rate | 0.147    |
| time/               |          |
|    episodes         | 18472    |
|    fps              | 163      |
|    time_elapsed     | 1946     |
|    total_timesteps  | 319047   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 69761    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0423  |
|    exploration_rate | 0.147    |
| time/               |          |
|    episodes         | 18476    |
|    fps              | 163      |
|    time_elapsed     | 1946     |
|    total_timesteps  | 319115   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00219  |
|    n_updates        | 69778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0429  |
|    exploration_rate | 0.146    |
| time/               |          |
|    episodes         | 18480    |
|    fps              | 163      |
|    time_elapsed     | 1946     |
|    total_timesteps  | 319193   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000785 |
|    n_updates        | 69798    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0425  |
|    exploration_rate | 0.146    |
| time/               |          |
|    episodes         | 18484    |
|    fps              | 163      |
|    time_elapsed     | 1947     |
|    total_timesteps  | 319267   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0072   |
|    n_updates        | 69816    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0414  |
|    exploration_rate | 0.145    |
| time/               |          |
|    episodes         | 18488    |
|    fps              | 164      |
|    time_elapsed     | 1947     |
|    total_timesteps  | 319352   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0101   |
|    n_updates        | 69837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0411  |
|    exploration_rate | 0.145    |
| time/               |          |
|    episodes         | 18492    |
|    fps              | 164      |
|    time_elapsed     | 1947     |
|    total_timesteps  | 319412   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 69852    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.031   |
|    exploration_rate | 0.145    |
| time/               |          |
|    episodes         | 18496    |
|    fps              | 164      |
|    time_elapsed     | 1947     |
|    total_timesteps  | 319488   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000847 |
|    n_updates        | 69871    |
----------------------------------
Eval num_timesteps=319500, episode_reward=-0.19 +/- 0.17
Episode length: 53.30 +/- 22.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.3     |
|    mean_reward      | -0.193   |
| rollout/            |          |
|    exploration_rate | 0.145    |
| time/               |          |
|    total_timesteps  | 319500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000962 |
|    n_updates        | 69874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0315  |
|    exploration_rate | 0.144    |
| time/               |          |
|    episodes         | 18500    |
|    fps              | 163      |
|    time_elapsed     | 1951     |
|    total_timesteps  | 319585   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00244  |
|    n_updates        | 69896    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0209  |
|    exploration_rate | 0.144    |
| time/               |          |
|    episodes         | 18504    |
|    fps              | 163      |
|    time_elapsed     | 1951     |
|    total_timesteps  | 319650   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 69912    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 0.144    |
| time/               |          |
|    episodes         | 18508    |
|    fps              | 163      |
|    time_elapsed     | 1951     |
|    total_timesteps  | 319741   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 69935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.143    |
| time/               |          |
|    episodes         | 18512    |
|    fps              | 163      |
|    time_elapsed     | 1951     |
|    total_timesteps  | 319830   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 69957    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.00139 |
|    exploration_rate | 0.143    |
| time/               |          |
|    episodes         | 18516    |
|    fps              | 163      |
|    time_elapsed     | 1951     |
|    total_timesteps  | 319901   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00261  |
|    n_updates        | 69975    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.00075 |
|    exploration_rate | 0.143    |
| time/               |          |
|    episodes         | 18520    |
|    fps              | 163      |
|    time_elapsed     | 1952     |
|    total_timesteps  | 319983   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 69995    |
----------------------------------
Eval num_timesteps=320000, episode_reward=-0.15 +/- 0.09
Episode length: 38.08 +/- 22.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.1     |
|    mean_reward      | -0.152   |
| rollout/            |          |
|    exploration_rate | 0.142    |
| time/               |          |
|    total_timesteps  | 320000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 69999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.00031 |
|    exploration_rate | 0.142    |
| time/               |          |
|    episodes         | 18524    |
|    fps              | 163      |
|    time_elapsed     | 1954     |
|    total_timesteps  | 320067   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 70016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.00974 |
|    exploration_rate | 0.142    |
| time/               |          |
|    episodes         | 18528    |
|    fps              | 163      |
|    time_elapsed     | 1954     |
|    total_timesteps  | 320151   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 70037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.00958 |
|    exploration_rate | 0.141    |
| time/               |          |
|    episodes         | 18532    |
|    fps              | 163      |
|    time_elapsed     | 1954     |
|    total_timesteps  | 320238   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00177  |
|    n_updates        | 70059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.141    |
| time/               |          |
|    episodes         | 18536    |
|    fps              | 163      |
|    time_elapsed     | 1955     |
|    total_timesteps  | 320324   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00311  |
|    n_updates        | 70080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 0.141    |
| time/               |          |
|    episodes         | 18540    |
|    fps              | 163      |
|    time_elapsed     | 1955     |
|    total_timesteps  | 320392   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00268  |
|    n_updates        | 70097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 0.14     |
| time/               |          |
|    episodes         | 18544    |
|    fps              | 163      |
|    time_elapsed     | 1955     |
|    total_timesteps  | 320472   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 70117    |
----------------------------------
Eval num_timesteps=320500, episode_reward=-0.21 +/- 0.09
Episode length: 51.58 +/- 21.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.6     |
|    mean_reward      | -0.206   |
| rollout/            |          |
|    exploration_rate | 0.14     |
| time/               |          |
|    total_timesteps  | 320500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 70124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0185  |
|    exploration_rate | 0.14     |
| time/               |          |
|    episodes         | 18548    |
|    fps              | 163      |
|    time_elapsed     | 1958     |
|    total_timesteps  | 320536   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 70133    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.0179  |
|    exploration_rate | 0.14     |
| time/               |          |
|    episodes         | 18552    |
|    fps              | 163      |
|    time_elapsed     | 1958     |
|    total_timesteps  | 320603   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 70150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0187  |
|    exploration_rate | 0.139    |
| time/               |          |
|    episodes         | 18556    |
|    fps              | 163      |
|    time_elapsed     | 1959     |
|    total_timesteps  | 320690   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00088  |
|    n_updates        | 70172    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.00829 |
|    exploration_rate | 0.139    |
| time/               |          |
|    episodes         | 18560    |
|    fps              | 163      |
|    time_elapsed     | 1959     |
|    total_timesteps  | 320768   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0017   |
|    n_updates        | 70191    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.00857 |
|    exploration_rate | 0.138    |
| time/               |          |
|    episodes         | 18564    |
|    fps              | 163      |
|    time_elapsed     | 1959     |
|    total_timesteps  | 320862   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 70215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 0.138    |
| time/               |          |
|    episodes         | 18568    |
|    fps              | 163      |
|    time_elapsed     | 1959     |
|    total_timesteps  | 320961   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 70240    |
----------------------------------
Eval num_timesteps=321000, episode_reward=-0.19 +/- 0.10
Episode length: 46.98 +/- 23.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47       |
|    mean_reward      | -0.187   |
| rollout/            |          |
|    exploration_rate | 0.138    |
| time/               |          |
|    total_timesteps  | 321000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000716 |
|    n_updates        | 70249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.00972 |
|    exploration_rate | 0.138    |
| time/               |          |
|    episodes         | 18572    |
|    fps              | 163      |
|    time_elapsed     | 1962     |
|    total_timesteps  | 321066   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0023   |
|    n_updates        | 70266    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.137    |
| time/               |          |
|    episodes         | 18576    |
|    fps              | 163      |
|    time_elapsed     | 1962     |
|    total_timesteps  | 321150   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000995 |
|    n_updates        | 70287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.137    |
| time/               |          |
|    episodes         | 18580    |
|    fps              | 163      |
|    time_elapsed     | 1963     |
|    total_timesteps  | 321270   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 70317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0122  |
|    exploration_rate | 0.136    |
| time/               |          |
|    episodes         | 18584    |
|    fps              | 163      |
|    time_elapsed     | 1963     |
|    total_timesteps  | 321349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 70337    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.136    |
| time/               |          |
|    episodes         | 18588    |
|    fps              | 163      |
|    time_elapsed     | 1963     |
|    total_timesteps  | 321442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00372  |
|    n_updates        | 70360    |
----------------------------------
Eval num_timesteps=321500, episode_reward=-0.20 +/- 0.10
Episode length: 49.40 +/- 24.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.4     |
|    mean_reward      | -0.197   |
| rollout/            |          |
|    exploration_rate | 0.136    |
| time/               |          |
|    total_timesteps  | 321500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000762 |
|    n_updates        | 70374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.0156  |
|    exploration_rate | 0.135    |
| time/               |          |
|    episodes         | 18592    |
|    fps              | 163      |
|    time_elapsed     | 1966     |
|    total_timesteps  | 321578   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000778 |
|    n_updates        | 70394    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.135    |
| time/               |          |
|    episodes         | 18596    |
|    fps              | 163      |
|    time_elapsed     | 1966     |
|    total_timesteps  | 321657   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 70414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | -0.0252  |
|    exploration_rate | 0.134    |
| time/               |          |
|    episodes         | 18600    |
|    fps              | 163      |
|    time_elapsed     | 1966     |
|    total_timesteps  | 321742   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 70435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.0357  |
|    exploration_rate | 0.134    |
| time/               |          |
|    episodes         | 18604    |
|    fps              | 163      |
|    time_elapsed     | 1967     |
|    total_timesteps  | 321818   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000941 |
|    n_updates        | 70454    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.134    |
| time/               |          |
|    episodes         | 18608    |
|    fps              | 163      |
|    time_elapsed     | 1967     |
|    total_timesteps  | 321885   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 70471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0446  |
|    exploration_rate | 0.133    |
| time/               |          |
|    episodes         | 18612    |
|    fps              | 163      |
|    time_elapsed     | 1967     |
|    total_timesteps  | 321970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 70492    |
----------------------------------
Eval num_timesteps=322000, episode_reward=-0.21 +/- 0.09
Episode length: 52.62 +/- 22.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.6     |
|    mean_reward      | -0.21    |
| rollout/            |          |
|    exploration_rate | 0.133    |
| time/               |          |
|    total_timesteps  | 322000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 70499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.0559  |
|    exploration_rate | 0.133    |
| time/               |          |
|    episodes         | 18616    |
|    fps              | 163      |
|    time_elapsed     | 1970     |
|    total_timesteps  | 322073   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00482  |
|    n_updates        | 70518    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | -0.0466  |
|    exploration_rate | 0.132    |
| time/               |          |
|    episodes         | 18620    |
|    fps              | 163      |
|    time_elapsed     | 1971     |
|    total_timesteps  | 322173   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 70543    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22       |
|    ep_rew_mean      | -0.047   |
|    exploration_rate | 0.132    |
| time/               |          |
|    episodes         | 18624    |
|    fps              | 163      |
|    time_elapsed     | 1971     |
|    total_timesteps  | 322267   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 70566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22       |
|    ep_rew_mean      | -0.057   |
|    exploration_rate | 0.132    |
| time/               |          |
|    episodes         | 18628    |
|    fps              | 163      |
|    time_elapsed     | 1971     |
|    total_timesteps  | 322352   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000948 |
|    n_updates        | 70587    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | -0.0562  |
|    exploration_rate | 0.131    |
| time/               |          |
|    episodes         | 18632    |
|    fps              | 163      |
|    time_elapsed     | 1971     |
|    total_timesteps  | 322419   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 70604    |
----------------------------------
Eval num_timesteps=322500, episode_reward=-0.25 +/- 0.07
Episode length: 63.70 +/- 17.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.7     |
|    mean_reward      | -0.254   |
| rollout/            |          |
|    exploration_rate | 0.131    |
| time/               |          |
|    total_timesteps  | 322500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00195  |
|    n_updates        | 70624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.1     |
|    ep_rew_mean      | -0.0573  |
|    exploration_rate | 0.131    |
| time/               |          |
|    episodes         | 18636    |
|    fps              | 163      |
|    time_elapsed     | 1975     |
|    total_timesteps  | 322531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000873 |
|    n_updates        | 70632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.1     |
|    ep_rew_mean      | -0.0575  |
|    exploration_rate | 0.13     |
| time/               |          |
|    episodes         | 18640    |
|    fps              | 163      |
|    time_elapsed     | 1975     |
|    total_timesteps  | 322606   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000898 |
|    n_updates        | 70651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.3     |
|    ep_rew_mean      | -0.0583  |
|    exploration_rate | 0.13     |
| time/               |          |
|    episodes         | 18644    |
|    fps              | 163      |
|    time_elapsed     | 1975     |
|    total_timesteps  | 322705   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 70676    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.6     |
|    ep_rew_mean      | -0.0595  |
|    exploration_rate | 0.13     |
| time/               |          |
|    episodes         | 18648    |
|    fps              | 163      |
|    time_elapsed     | 1976     |
|    total_timesteps  | 322798   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 70699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.7     |
|    ep_rew_mean      | -0.06    |
|    exploration_rate | 0.129    |
| time/               |          |
|    episodes         | 18652    |
|    fps              | 163      |
|    time_elapsed     | 1976     |
|    total_timesteps  | 322877   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 70719    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.6     |
|    ep_rew_mean      | -0.0594  |
|    exploration_rate | 0.129    |
| time/               |          |
|    episodes         | 18656    |
|    fps              | 163      |
|    time_elapsed     | 1976     |
|    total_timesteps  | 322951   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 70737    |
----------------------------------
Eval num_timesteps=323000, episode_reward=-0.23 +/- 0.08
Episode length: 56.68 +/- 19.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.7     |
|    mean_reward      | -0.226   |
| rollout/            |          |
|    exploration_rate | 0.129    |
| time/               |          |
|    total_timesteps  | 323000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00222  |
|    n_updates        | 70749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.8     |
|    ep_rew_mean      | -0.0701  |
|    exploration_rate | 0.128    |
| time/               |          |
|    episodes         | 18660    |
|    fps              | 163      |
|    time_elapsed     | 1980     |
|    total_timesteps  | 323045   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00078  |
|    n_updates        | 70761    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | -0.0714  |
|    exploration_rate | 0.128    |
| time/               |          |
|    episodes         | 18664    |
|    fps              | 163      |
|    time_elapsed     | 1980     |
|    total_timesteps  | 323172   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 70792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.2     |
|    ep_rew_mean      | -0.072   |
|    exploration_rate | 0.127    |
| time/               |          |
|    episodes         | 18668    |
|    fps              | 163      |
|    time_elapsed     | 1980     |
|    total_timesteps  | 323286   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000876 |
|    n_updates        | 70821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | -0.0704  |
|    exploration_rate | 0.127    |
| time/               |          |
|    episodes         | 18672    |
|    fps              | 163      |
|    time_elapsed     | 1980     |
|    total_timesteps  | 323351   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 70837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | -0.0708  |
|    exploration_rate | 0.127    |
| time/               |          |
|    episodes         | 18676    |
|    fps              | 163      |
|    time_elapsed     | 1981     |
|    total_timesteps  | 323445   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00254  |
|    n_updates        | 70861    |
----------------------------------
Eval num_timesteps=323500, episode_reward=-0.20 +/- 0.16
Episode length: 55.36 +/- 21.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.4     |
|    mean_reward      | -0.201   |
| rollout/            |          |
|    exploration_rate | 0.126    |
| time/               |          |
|    total_timesteps  | 323500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 70874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.6     |
|    ep_rew_mean      | -0.0693  |
|    exploration_rate | 0.126    |
| time/               |          |
|    episodes         | 18680    |
|    fps              | 162      |
|    time_elapsed     | 1984     |
|    total_timesteps  | 323527   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00281  |
|    n_updates        | 70881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.7     |
|    ep_rew_mean      | -0.0699  |
|    exploration_rate | 0.126    |
| time/               |          |
|    episodes         | 18684    |
|    fps              | 163      |
|    time_elapsed     | 1985     |
|    total_timesteps  | 323621   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000647 |
|    n_updates        | 70905    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.7     |
|    ep_rew_mean      | -0.0699  |
|    exploration_rate | 0.125    |
| time/               |          |
|    episodes         | 18688    |
|    fps              | 163      |
|    time_elapsed     | 1985     |
|    total_timesteps  | 323715   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00147  |
|    n_updates        | 70928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | -0.0689  |
|    exploration_rate | 0.125    |
| time/               |          |
|    episodes         | 18692    |
|    fps              | 163      |
|    time_elapsed     | 1985     |
|    total_timesteps  | 323824   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 70955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.7     |
|    ep_rew_mean      | -0.07    |
|    exploration_rate | 0.124    |
| time/               |          |
|    episodes         | 18696    |
|    fps              | 163      |
|    time_elapsed     | 1985     |
|    total_timesteps  | 323931   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 70982    |
----------------------------------
Eval num_timesteps=324000, episode_reward=-0.19 +/- 0.08
Episode length: 46.48 +/- 20.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.5     |
|    mean_reward      | -0.185   |
| rollout/            |          |
|    exploration_rate | 0.124    |
| time/               |          |
|    total_timesteps  | 324000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 70999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | -0.0706  |
|    exploration_rate | 0.124    |
| time/               |          |
|    episodes         | 18700    |
|    fps              | 162      |
|    time_elapsed     | 1988     |
|    total_timesteps  | 324031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00353  |
|    n_updates        | 71007    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | -0.0714  |
|    exploration_rate | 0.123    |
| time/               |          |
|    episodes         | 18704    |
|    fps              | 162      |
|    time_elapsed     | 1988     |
|    total_timesteps  | 324128   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000865 |
|    n_updates        | 71031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.2     |
|    ep_rew_mean      | -0.072   |
|    exploration_rate | 0.123    |
| time/               |          |
|    episodes         | 18708    |
|    fps              | 162      |
|    time_elapsed     | 1989     |
|    total_timesteps  | 324210   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00347  |
|    n_updates        | 71052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.2     |
|    ep_rew_mean      | -0.0717  |
|    exploration_rate | 0.123    |
| time/               |          |
|    episodes         | 18712    |
|    fps              | 163      |
|    time_elapsed     | 1989     |
|    total_timesteps  | 324288   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00161  |
|    n_updates        | 71071    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23       |
|    ep_rew_mean      | -0.0711  |
|    exploration_rate | 0.122    |
| time/               |          |
|    episodes         | 18716    |
|    fps              | 163      |
|    time_elapsed     | 1989     |
|    total_timesteps  | 324376   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00337  |
|    n_updates        | 71093    |
----------------------------------
Eval num_timesteps=324500, episode_reward=-0.15 +/- 0.25
Episode length: 51.62 +/- 20.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.6     |
|    mean_reward      | -0.146   |
| rollout/            |          |
|    exploration_rate | 0.122    |
| time/               |          |
|    total_timesteps  | 324500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 71124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | -0.0829  |
|    exploration_rate | 0.122    |
| time/               |          |
|    episodes         | 18720    |
|    fps              | 162      |
|    time_elapsed     | 1992     |
|    total_timesteps  | 324520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000942 |
|    n_updates        | 71129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.0839  |
|    exploration_rate | 0.121    |
| time/               |          |
|    episodes         | 18724    |
|    fps              | 162      |
|    time_elapsed     | 1993     |
|    total_timesteps  | 324639   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 71159    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.0856  |
|    exploration_rate | 0.12     |
| time/               |          |
|    episodes         | 18728    |
|    fps              | 162      |
|    time_elapsed     | 1993     |
|    total_timesteps  | 324767   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000839 |
|    n_updates        | 71191    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.4     |
|    ep_rew_mean      | -0.0865  |
|    exploration_rate | 0.12     |
| time/               |          |
|    episodes         | 18732    |
|    fps              | 162      |
|    time_elapsed     | 1993     |
|    total_timesteps  | 324857   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 71214    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.3     |
|    ep_rew_mean      | -0.0861  |
|    exploration_rate | 0.12     |
| time/               |          |
|    episodes         | 18736    |
|    fps              | 162      |
|    time_elapsed     | 1993     |
|    total_timesteps  | 324959   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 71239    |
----------------------------------
Eval num_timesteps=325000, episode_reward=-0.17 +/- 0.17
Episode length: 47.32 +/- 21.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | -0.168   |
| rollout/            |          |
|    exploration_rate | 0.119    |
| time/               |          |
|    total_timesteps  | 325000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000926 |
|    n_updates        | 71249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.9     |
|    ep_rew_mean      | -0.0888  |
|    exploration_rate | 0.119    |
| time/               |          |
|    episodes         | 18740    |
|    fps              | 162      |
|    time_elapsed     | 1996     |
|    total_timesteps  | 325100   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 71274    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | -0.089   |
|    exploration_rate | 0.118    |
| time/               |          |
|    episodes         | 18744    |
|    fps              | 162      |
|    time_elapsed     | 1996     |
|    total_timesteps  | 325205   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000673 |
|    n_updates        | 71301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0904  |
|    exploration_rate | 0.118    |
| time/               |          |
|    episodes         | 18748    |
|    fps              | 162      |
|    time_elapsed     | 1997     |
|    total_timesteps  | 325333   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000883 |
|    n_updates        | 71333    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.091   |
|    exploration_rate | 0.117    |
| time/               |          |
|    episodes         | 18752    |
|    fps              | 162      |
|    time_elapsed     | 1997     |
|    total_timesteps  | 325427   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 71356    |
----------------------------------
Eval num_timesteps=325500, episode_reward=-0.18 +/- 0.16
Episode length: 51.06 +/- 20.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.1     |
|    mean_reward      | -0.183   |
| rollout/            |          |
|    exploration_rate | 0.117    |
| time/               |          |
|    total_timesteps  | 325500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000718 |
|    n_updates        | 71374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0927  |
|    exploration_rate | 0.117    |
| time/               |          |
|    episodes         | 18756    |
|    fps              | 162      |
|    time_elapsed     | 2000     |
|    total_timesteps  | 325543   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000881 |
|    n_updates        | 71385    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0934  |
|    exploration_rate | 0.116    |
| time/               |          |
|    episodes         | 18760    |
|    fps              | 162      |
|    time_elapsed     | 2001     |
|    total_timesteps  | 325655   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0019   |
|    n_updates        | 71413    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0931  |
|    exploration_rate | 0.116    |
| time/               |          |
|    episodes         | 18764    |
|    fps              | 162      |
|    time_elapsed     | 2001     |
|    total_timesteps  | 325774   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 71443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0934  |
|    exploration_rate | 0.115    |
| time/               |          |
|    episodes         | 18768    |
|    fps              | 162      |
|    time_elapsed     | 2001     |
|    total_timesteps  | 325895   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000857 |
|    n_updates        | 71473    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.2     |
|    ep_rew_mean      | -0.104   |
|    exploration_rate | 0.115    |
| time/               |          |
|    episodes         | 18772    |
|    fps              | 162      |
|    time_elapsed     | 2001     |
|    total_timesteps  | 325970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000697 |
|    n_updates        | 71492    |
----------------------------------
Eval num_timesteps=326000, episode_reward=-0.21 +/- 0.08
Episode length: 51.70 +/- 20.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.7     |
|    mean_reward      | -0.206   |
| rollout/            |          |
|    exploration_rate | 0.115    |
| time/               |          |
|    total_timesteps  | 326000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 71499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0928  |
|    exploration_rate | 0.115    |
| time/               |          |
|    episodes         | 18776    |
|    fps              | 162      |
|    time_elapsed     | 2004     |
|    total_timesteps  | 326039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 71509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.2     |
|    ep_rew_mean      | -0.0938  |
|    exploration_rate | 0.114    |
| time/               |          |
|    episodes         | 18780    |
|    fps              | 162      |
|    time_elapsed     | 2005     |
|    total_timesteps  | 326146   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 71536    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.2     |
|    ep_rew_mean      | -0.084   |
|    exploration_rate | 0.114    |
| time/               |          |
|    episodes         | 18784    |
|    fps              | 162      |
|    time_elapsed     | 2005     |
|    total_timesteps  | 326245   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 71561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.2     |
|    ep_rew_mean      | -0.0837  |
|    exploration_rate | 0.113    |
| time/               |          |
|    episodes         | 18788    |
|    fps              | 162      |
|    time_elapsed     | 2005     |
|    total_timesteps  | 326331   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 71582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0824  |
|    exploration_rate | 0.113    |
| time/               |          |
|    episodes         | 18792    |
|    fps              | 162      |
|    time_elapsed     | 2005     |
|    total_timesteps  | 326409   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 71602    |
----------------------------------
Eval num_timesteps=326500, episode_reward=-0.17 +/- 0.15
Episode length: 46.90 +/- 22.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.9     |
|    mean_reward      | -0.167   |
| rollout/            |          |
|    exploration_rate | 0.112    |
| time/               |          |
|    total_timesteps  | 326500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000961 |
|    n_updates        | 71624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0823  |
|    exploration_rate | 0.112    |
| time/               |          |
|    episodes         | 18796    |
|    fps              | 162      |
|    time_elapsed     | 2008     |
|    total_timesteps  | 326512   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000935 |
|    n_updates        | 71627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0823  |
|    exploration_rate | 0.112    |
| time/               |          |
|    episodes         | 18800    |
|    fps              | 162      |
|    time_elapsed     | 2008     |
|    total_timesteps  | 326614   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000973 |
|    n_updates        | 71653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0835  |
|    exploration_rate | 0.111    |
| time/               |          |
|    episodes         | 18804    |
|    fps              | 162      |
|    time_elapsed     | 2009     |
|    total_timesteps  | 326740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 71684    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0833  |
|    exploration_rate | 0.111    |
| time/               |          |
|    episodes         | 18808    |
|    fps              | 162      |
|    time_elapsed     | 2009     |
|    total_timesteps  | 326818   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00233  |
|    n_updates        | 71704    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.4     |
|    ep_rew_mean      | -0.0745  |
|    exploration_rate | 0.11     |
| time/               |          |
|    episodes         | 18812    |
|    fps              | 162      |
|    time_elapsed     | 2009     |
|    total_timesteps  | 326926   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 71731    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.2     |
|    ep_rew_mean      | -0.0739  |
|    exploration_rate | 0.11     |
| time/               |          |
|    episodes         | 18816    |
|    fps              | 162      |
|    time_elapsed     | 2009     |
|    total_timesteps  | 326999   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0017   |
|    n_updates        | 71749    |
----------------------------------
Eval num_timesteps=327000, episode_reward=-0.20 +/- 0.08
Episode length: 51.14 +/- 20.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 51.1     |
|    mean_reward     | -0.204   |
| time/              |          |
|    total_timesteps | 327000   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0726  |
|    exploration_rate | 0.11     |
| time/               |          |
|    episodes         | 18820    |
|    fps              | 162      |
|    time_elapsed     | 2013     |
|    total_timesteps  | 327109   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000991 |
|    n_updates        | 71777    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0722  |
|    exploration_rate | 0.109    |
| time/               |          |
|    episodes         | 18824    |
|    fps              | 162      |
|    time_elapsed     | 2013     |
|    total_timesteps  | 327219   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 71804    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0722  |
|    exploration_rate | 0.108    |
| time/               |          |
|    episodes         | 18828    |
|    fps              | 162      |
|    time_elapsed     | 2013     |
|    total_timesteps  | 327347   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 71836    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.073   |
|    exploration_rate | 0.108    |
| time/               |          |
|    episodes         | 18832    |
|    fps              | 162      |
|    time_elapsed     | 2013     |
|    total_timesteps  | 327457   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 71864    |
----------------------------------
Eval num_timesteps=327500, episode_reward=-0.21 +/- 0.08
Episode length: 53.38 +/- 20.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.4     |
|    mean_reward      | -0.213   |
| rollout/            |          |
|    exploration_rate | 0.108    |
| time/               |          |
|    total_timesteps  | 327500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00445  |
|    n_updates        | 71874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0723  |
|    exploration_rate | 0.108    |
| time/               |          |
|    episodes         | 18836    |
|    fps              | 162      |
|    time_elapsed     | 2016     |
|    total_timesteps  | 327541   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000692 |
|    n_updates        | 71885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0605  |
|    exploration_rate | 0.107    |
| time/               |          |
|    episodes         | 18840    |
|    fps              | 162      |
|    time_elapsed     | 2017     |
|    total_timesteps  | 327639   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00255  |
|    n_updates        | 71909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0608  |
|    exploration_rate | 0.107    |
| time/               |          |
|    episodes         | 18844    |
|    fps              | 162      |
|    time_elapsed     | 2017     |
|    total_timesteps  | 327750   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000762 |
|    n_updates        | 71937    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0614  |
|    exploration_rate | 0.106    |
| time/               |          |
|    episodes         | 18848    |
|    fps              | 162      |
|    time_elapsed     | 2017     |
|    total_timesteps  | 327893   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 71973    |
----------------------------------
Eval num_timesteps=328000, episode_reward=-0.19 +/- 0.16
Episode length: 53.84 +/- 20.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.8     |
|    mean_reward      | -0.195   |
| rollout/            |          |
|    exploration_rate | 0.105    |
| time/               |          |
|    total_timesteps  | 328000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 71999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.4     |
|    ep_rew_mean      | -0.0645  |
|    exploration_rate | 0.105    |
| time/               |          |
|    episodes         | 18852    |
|    fps              | 162      |
|    time_elapsed     | 2021     |
|    total_timesteps  | 328064   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 72015    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0633  |
|    exploration_rate | 0.105    |
| time/               |          |
|    episodes         | 18856    |
|    fps              | 162      |
|    time_elapsed     | 2021     |
|    total_timesteps  | 328152   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 72037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0521  |
|    exploration_rate | 0.104    |
| time/               |          |
|    episodes         | 18860    |
|    fps              | 162      |
|    time_elapsed     | 2021     |
|    total_timesteps  | 328234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0012   |
|    n_updates        | 72058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.053   |
|    exploration_rate | 0.104    |
| time/               |          |
|    episodes         | 18864    |
|    fps              | 162      |
|    time_elapsed     | 2021     |
|    total_timesteps  | 328376   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00517  |
|    n_updates        | 72093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0508  |
|    exploration_rate | 0.103    |
| time/               |          |
|    episodes         | 18868    |
|    fps              | 162      |
|    time_elapsed     | 2022     |
|    total_timesteps  | 328440   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 72109    |
----------------------------------
Eval num_timesteps=328500, episode_reward=-0.20 +/- 0.16
Episode length: 55.20 +/- 19.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.2     |
|    mean_reward      | -0.2     |
| rollout/            |          |
|    exploration_rate | 0.103    |
| time/               |          |
|    total_timesteps  | 328500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0022   |
|    n_updates        | 72124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0516  |
|    exploration_rate | 0.103    |
| time/               |          |
|    episodes         | 18872    |
|    fps              | 162      |
|    time_elapsed     | 2025     |
|    total_timesteps  | 328537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00078  |
|    n_updates        | 72134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0631  |
|    exploration_rate | 0.102    |
| time/               |          |
|    episodes         | 18876    |
|    fps              | 162      |
|    time_elapsed     | 2025     |
|    total_timesteps  | 328644   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000896 |
|    n_updates        | 72160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0628  |
|    exploration_rate | 0.102    |
| time/               |          |
|    episodes         | 18880    |
|    fps              | 162      |
|    time_elapsed     | 2026     |
|    total_timesteps  | 328743   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 72185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0727  |
|    exploration_rate | 0.102    |
| time/               |          |
|    episodes         | 18884    |
|    fps              | 162      |
|    time_elapsed     | 2026     |
|    total_timesteps  | 328839   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 72209    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0754  |
|    exploration_rate | 0.101    |
| time/               |          |
|    episodes         | 18888    |
|    fps              | 162      |
|    time_elapsed     | 2026     |
|    total_timesteps  | 328992   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 72247    |
----------------------------------
Eval num_timesteps=329000, episode_reward=-0.22 +/- 0.08
Episode length: 56.34 +/- 19.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.3     |
|    mean_reward      | -0.225   |
| rollout/            |          |
|    exploration_rate | 0.101    |
| time/               |          |
|    total_timesteps  | 329000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000829 |
|    n_updates        | 72249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0767  |
|    exploration_rate | 0.1      |
| time/               |          |
|    episodes         | 18892    |
|    fps              | 162      |
|    time_elapsed     | 2030     |
|    total_timesteps  | 329104   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 72275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0758  |
|    exploration_rate | 0.0999   |
| time/               |          |
|    episodes         | 18896    |
|    fps              | 162      |
|    time_elapsed     | 2030     |
|    total_timesteps  | 329184   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 72295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0755  |
|    exploration_rate | 0.0995   |
| time/               |          |
|    episodes         | 18900    |
|    fps              | 162      |
|    time_elapsed     | 2030     |
|    total_timesteps  | 329279   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 72319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0753  |
|    exploration_rate | 0.0989   |
| time/               |          |
|    episodes         | 18904    |
|    fps              | 162      |
|    time_elapsed     | 2030     |
|    total_timesteps  | 329398   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 72349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0759  |
|    exploration_rate | 0.0985   |
| time/               |          |
|    episodes         | 18908    |
|    fps              | 162      |
|    time_elapsed     | 2031     |
|    total_timesteps  | 329491   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00416  |
|    n_updates        | 72372    |
----------------------------------
Eval num_timesteps=329500, episode_reward=-0.21 +/- 0.08
Episode length: 52.28 +/- 20.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.3     |
|    mean_reward      | -0.208   |
| rollout/            |          |
|    exploration_rate | 0.0984   |
| time/               |          |
|    total_timesteps  | 329500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00304  |
|    n_updates        | 72374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.0848  |
|    exploration_rate | 0.0981   |
| time/               |          |
|    episodes         | 18912    |
|    fps              | 161      |
|    time_elapsed     | 2034     |
|    total_timesteps  | 329572   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00133  |
|    n_updates        | 72392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0759  |
|    exploration_rate | 0.0976   |
| time/               |          |
|    episodes         | 18916    |
|    fps              | 162      |
|    time_elapsed     | 2034     |
|    total_timesteps  | 329673   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 72418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0652  |
|    exploration_rate | 0.0972   |
| time/               |          |
|    episodes         | 18920    |
|    fps              | 162      |
|    time_elapsed     | 2034     |
|    total_timesteps  | 329764   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000832 |
|    n_updates        | 72440    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.0649  |
|    exploration_rate | 0.0967   |
| time/               |          |
|    episodes         | 18924    |
|    fps              | 162      |
|    time_elapsed     | 2035     |
|    total_timesteps  | 329868   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00099  |
|    n_updates        | 72466    |
----------------------------------
Eval num_timesteps=330000, episode_reward=-0.17 +/- 0.16
Episode length: 48.46 +/- 18.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.5     |
|    mean_reward      | -0.173   |
| rollout/            |          |
|    exploration_rate | 0.0961   |
| time/               |          |
|    total_timesteps  | 330000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00116  |
|    n_updates        | 72499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0656  |
|    exploration_rate | 0.096    |
| time/               |          |
|    episodes         | 18928    |
|    fps              | 161      |
|    time_elapsed     | 2038     |
|    total_timesteps  | 330013   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0008   |
|    n_updates        | 72503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0653  |
|    exploration_rate | 0.0956   |
| time/               |          |
|    episodes         | 18932    |
|    fps              | 161      |
|    time_elapsed     | 2038     |
|    total_timesteps  | 330116   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 72528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0653  |
|    exploration_rate | 0.0952   |
| time/               |          |
|    episodes         | 18936    |
|    fps              | 161      |
|    time_elapsed     | 2038     |
|    total_timesteps  | 330200   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00254  |
|    n_updates        | 72549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0758  |
|    exploration_rate | 0.0947   |
| time/               |          |
|    episodes         | 18940    |
|    fps              | 162      |
|    time_elapsed     | 2038     |
|    total_timesteps  | 330310   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 72577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.065   |
|    exploration_rate | 0.0942   |
| time/               |          |
|    episodes         | 18944    |
|    fps              | 162      |
|    time_elapsed     | 2038     |
|    total_timesteps  | 330402   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 72600    |
----------------------------------
Eval num_timesteps=330500, episode_reward=-0.13 +/- 0.07
Episode length: 32.88 +/- 18.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 32.9     |
|    mean_reward      | -0.131   |
| rollout/            |          |
|    exploration_rate | 0.0938   |
| time/               |          |
|    total_timesteps  | 330500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000912 |
|    n_updates        | 72624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.2     |
|    ep_rew_mean      | -0.0637  |
|    exploration_rate | 0.0937   |
| time/               |          |
|    episodes         | 18948    |
|    fps              | 161      |
|    time_elapsed     | 2041     |
|    total_timesteps  | 330511   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00771  |
|    n_updates        | 72627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.0609  |
|    exploration_rate | 0.0932   |
| time/               |          |
|    episodes         | 18952    |
|    fps              | 161      |
|    time_elapsed     | 2041     |
|    total_timesteps  | 330613   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 72653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0612  |
|    exploration_rate | 0.0928   |
| time/               |          |
|    episodes         | 18956    |
|    fps              | 161      |
|    time_elapsed     | 2041     |
|    total_timesteps  | 330708   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 72676    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0713  |
|    exploration_rate | 0.0924   |
| time/               |          |
|    episodes         | 18960    |
|    fps              | 161      |
|    time_elapsed     | 2041     |
|    total_timesteps  | 330793   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 72698    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.07    |
|    exploration_rate | 0.0919   |
| time/               |          |
|    episodes         | 18964    |
|    fps              | 162      |
|    time_elapsed     | 2042     |
|    total_timesteps  | 330902   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000958 |
|    n_updates        | 72725    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0702  |
|    exploration_rate | 0.0916   |
| time/               |          |
|    episodes         | 18968    |
|    fps              | 162      |
|    time_elapsed     | 2042     |
|    total_timesteps  | 330971   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00096  |
|    n_updates        | 72742    |
----------------------------------
Eval num_timesteps=331000, episode_reward=-0.12 +/- 0.15
Episode length: 34.68 +/- 17.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.7     |
|    mean_reward      | -0.118   |
| rollout/            |          |
|    exploration_rate | 0.0914   |
| time/               |          |
|    total_timesteps  | 331000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 72749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | -0.0697  |
|    exploration_rate | 0.0912   |
| time/               |          |
|    episodes         | 18972    |
|    fps              | 161      |
|    time_elapsed     | 2044     |
|    total_timesteps  | 331055   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000913 |
|    n_updates        | 72763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | -0.0698  |
|    exploration_rate | 0.0907   |
| time/               |          |
|    episodes         | 18976    |
|    fps              | 161      |
|    time_elapsed     | 2044     |
|    total_timesteps  | 331164   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000548 |
|    n_updates        | 72790    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.9     |
|    ep_rew_mean      | -0.0485  |
|    exploration_rate | 0.0903   |
| time/               |          |
|    episodes         | 18980    |
|    fps              | 161      |
|    time_elapsed     | 2045     |
|    total_timesteps  | 331231   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 72807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.6     |
|    ep_rew_mean      | -0.0473  |
|    exploration_rate | 0.09     |
| time/               |          |
|    episodes         | 18984    |
|    fps              | 161      |
|    time_elapsed     | 2045     |
|    total_timesteps  | 331298   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00073  |
|    n_updates        | 72824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.4     |
|    ep_rew_mean      | -0.0464  |
|    exploration_rate | 0.0894   |
| time/               |          |
|    episodes         | 18988    |
|    fps              | 162      |
|    time_elapsed     | 2045     |
|    total_timesteps  | 331428   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000651 |
|    n_updates        | 72856    |
----------------------------------
Eval num_timesteps=331500, episode_reward=-0.13 +/- 0.16
Episode length: 38.10 +/- 17.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.1     |
|    mean_reward      | -0.131   |
| rollout/            |          |
|    exploration_rate | 0.0891   |
| time/               |          |
|    total_timesteps  | 331500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 72874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.2     |
|    ep_rew_mean      | -0.0457  |
|    exploration_rate | 0.089    |
| time/               |          |
|    episodes         | 18992    |
|    fps              | 161      |
|    time_elapsed     | 2047     |
|    total_timesteps  | 331521   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 72880    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.5     |
|    ep_rew_mean      | -0.0471  |
|    exploration_rate | 0.0884   |
| time/               |          |
|    episodes         | 18996    |
|    fps              | 161      |
|    time_elapsed     | 2048     |
|    total_timesteps  | 331637   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00495  |
|    n_updates        | 72909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.5     |
|    ep_rew_mean      | -0.0471  |
|    exploration_rate | 0.088    |
| time/               |          |
|    episodes         | 19000    |
|    fps              | 161      |
|    time_elapsed     | 2048     |
|    total_timesteps  | 331731   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 72932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.8     |
|    ep_rew_mean      | -0.0482  |
|    exploration_rate | 0.0873   |
| time/               |          |
|    episodes         | 19004    |
|    fps              | 162      |
|    time_elapsed     | 2048     |
|    total_timesteps  | 331878   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000564 |
|    n_updates        | 72969    |
----------------------------------
Eval num_timesteps=332000, episode_reward=-0.14 +/- 0.17
Episode length: 41.36 +/- 21.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.4     |
|    mean_reward      | -0.145   |
| rollout/            |          |
|    exploration_rate | 0.0867   |
| time/               |          |
|    total_timesteps  | 332000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 72999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | -0.0498  |
|    exploration_rate | 0.0867   |
| time/               |          |
|    episodes         | 19008    |
|    fps              | 161      |
|    time_elapsed     | 2051     |
|    total_timesteps  | 332011   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000823 |
|    n_updates        | 73002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.041   |
|    exploration_rate | 0.0862   |
| time/               |          |
|    episodes         | 19012    |
|    fps              | 161      |
|    time_elapsed     | 2051     |
|    total_timesteps  | 332123   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00276  |
|    n_updates        | 73030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | -0.0499  |
|    exploration_rate | 0.0858   |
| time/               |          |
|    episodes         | 19016    |
|    fps              | 161      |
|    time_elapsed     | 2051     |
|    total_timesteps  | 332196   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 73048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0606  |
|    exploration_rate | 0.0853   |
| time/               |          |
|    episodes         | 19020    |
|    fps              | 161      |
|    time_elapsed     | 2052     |
|    total_timesteps  | 332305   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000541 |
|    n_updates        | 73076    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.1     |
|    ep_rew_mean      | -0.0596  |
|    exploration_rate | 0.0849   |
| time/               |          |
|    episodes         | 19024    |
|    fps              | 161      |
|    time_elapsed     | 2052     |
|    total_timesteps  | 332383   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 73095    |
----------------------------------
Eval num_timesteps=332500, episode_reward=-0.10 +/- 0.21
Episode length: 34.08 +/- 18.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.1     |
|    mean_reward      | -0.0953  |
| rollout/            |          |
|    exploration_rate | 0.0844   |
| time/               |          |
|    total_timesteps  | 332500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 73124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.9     |
|    ep_rew_mean      | -0.0485  |
|    exploration_rate | 0.0844   |
| time/               |          |
|    episodes         | 19028    |
|    fps              | 161      |
|    time_elapsed     | 2054     |
|    total_timesteps  | 332500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.5     |
|    ep_rew_mean      | -0.047   |
|    exploration_rate | 0.0841   |
| time/               |          |
|    episodes         | 19032    |
|    fps              | 161      |
|    time_elapsed     | 2054     |
|    total_timesteps  | 332566   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000785 |
|    n_updates        | 73141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.4     |
|    ep_rew_mean      | -0.0466  |
|    exploration_rate | 0.0837   |
| time/               |          |
|    episodes         | 19036    |
|    fps              | 161      |
|    time_elapsed     | 2054     |
|    total_timesteps  | 332641   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000976 |
|    n_updates        | 73160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.0452  |
|    exploration_rate | 0.0834   |
| time/               |          |
|    episodes         | 19040    |
|    fps              | 161      |
|    time_elapsed     | 2054     |
|    total_timesteps  | 332715   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00186  |
|    n_updates        | 73178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.0455  |
|    exploration_rate | 0.0829   |
| time/               |          |
|    episodes         | 19044    |
|    fps              | 161      |
|    time_elapsed     | 2055     |
|    total_timesteps  | 332815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 73203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.8     |
|    ep_rew_mean      | -0.0442  |
|    exploration_rate | 0.0826   |
| time/               |          |
|    episodes         | 19048    |
|    fps              | 161      |
|    time_elapsed     | 2055     |
|    total_timesteps  | 332891   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00234  |
|    n_updates        | 73222    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | -0.0429  |
|    exploration_rate | 0.0822   |
| time/               |          |
|    episodes         | 19052    |
|    fps              | 161      |
|    time_elapsed     | 2055     |
|    total_timesteps  | 332960   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 73239    |
----------------------------------
Eval num_timesteps=333000, episode_reward=-0.16 +/- 0.08
Episode length: 40.72 +/- 20.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.7     |
|    mean_reward      | -0.162   |
| rollout/            |          |
|    exploration_rate | 0.082    |
| time/               |          |
|    total_timesteps  | 333000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00293  |
|    n_updates        | 73249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.6     |
|    ep_rew_mean      | -0.0434  |
|    exploration_rate | 0.0817   |
| time/               |          |
|    episodes         | 19056    |
|    fps              | 161      |
|    time_elapsed     | 2058     |
|    total_timesteps  | 333068   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00381  |
|    n_updates        | 73266    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.6     |
|    ep_rew_mean      | -0.0435  |
|    exploration_rate | 0.0813   |
| time/               |          |
|    episodes         | 19060    |
|    fps              | 161      |
|    time_elapsed     | 2058     |
|    total_timesteps  | 333156   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000567 |
|    n_updates        | 73288    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.3     |
|    ep_rew_mean      | -0.0323  |
|    exploration_rate | 0.0809   |
| time/               |          |
|    episodes         | 19064    |
|    fps              | 161      |
|    time_elapsed     | 2058     |
|    total_timesteps  | 333235   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 73308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.0805   |
| time/               |          |
|    episodes         | 19068    |
|    fps              | 161      |
|    time_elapsed     | 2058     |
|    total_timesteps  | 333321   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 73330    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.0799   |
| time/               |          |
|    episodes         | 19072    |
|    fps              | 161      |
|    time_elapsed     | 2058     |
|    total_timesteps  | 333447   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000891 |
|    n_updates        | 73361    |
----------------------------------
Eval num_timesteps=333500, episode_reward=-0.10 +/- 0.26
Episode length: 40.38 +/- 22.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.4     |
|    mean_reward      | -0.101   |
| rollout/            |          |
|    exploration_rate | 0.0797   |
| time/               |          |
|    total_timesteps  | 333500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 73374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.0337  |
|    exploration_rate | 0.0795   |
| time/               |          |
|    episodes         | 19076    |
|    fps              | 161      |
|    time_elapsed     | 2061     |
|    total_timesteps  | 333532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 73382    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.0537  |
|    exploration_rate | 0.0792   |
| time/               |          |
|    episodes         | 19080    |
|    fps              | 161      |
|    time_elapsed     | 2061     |
|    total_timesteps  | 333598   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000941 |
|    n_updates        | 73399    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.2     |
|    ep_rew_mean      | -0.0559  |
|    exploration_rate | 0.0787   |
| time/               |          |
|    episodes         | 19084    |
|    fps              | 161      |
|    time_elapsed     | 2061     |
|    total_timesteps  | 333719   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00142  |
|    n_updates        | 73429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.8     |
|    ep_rew_mean      | -0.0543  |
|    exploration_rate | 0.0782   |
| time/               |          |
|    episodes         | 19088    |
|    fps              | 161      |
|    time_elapsed     | 2061     |
|    total_timesteps  | 333810   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 73452    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.0549  |
|    exploration_rate | 0.0777   |
| time/               |          |
|    episodes         | 19092    |
|    fps              | 161      |
|    time_elapsed     | 2062     |
|    total_timesteps  | 333917   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000764 |
|    n_updates        | 73479    |
----------------------------------
Eval num_timesteps=334000, episode_reward=-0.12 +/- 0.22
Episode length: 39.04 +/- 20.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39       |
|    mean_reward      | -0.115   |
| rollout/            |          |
|    exploration_rate | 0.0773   |
| time/               |          |
|    total_timesteps  | 334000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 73499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.0538  |
|    exploration_rate | 0.0773   |
| time/               |          |
|    episodes         | 19096    |
|    fps              | 161      |
|    time_elapsed     | 2064     |
|    total_timesteps  | 334007   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000944 |
|    n_updates        | 73501    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | -0.053   |
|    exploration_rate | 0.077    |
| time/               |          |
|    episodes         | 19100    |
|    fps              | 161      |
|    time_elapsed     | 2064     |
|    total_timesteps  | 334081   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 73520    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | -0.0504  |
|    exploration_rate | 0.0766   |
| time/               |          |
|    episodes         | 19104    |
|    fps              | 161      |
|    time_elapsed     | 2065     |
|    total_timesteps  | 334163   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000913 |
|    n_updates        | 73540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.6     |
|    ep_rew_mean      | -0.0393  |
|    exploration_rate | 0.0761   |
| time/               |          |
|    episodes         | 19108    |
|    fps              | 161      |
|    time_elapsed     | 2065     |
|    total_timesteps  | 334268   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00524  |
|    n_updates        | 73566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.4     |
|    ep_rew_mean      | -0.0387  |
|    exploration_rate | 0.0756   |
| time/               |          |
|    episodes         | 19112    |
|    fps              | 161      |
|    time_elapsed     | 2065     |
|    total_timesteps  | 334366   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000992 |
|    n_updates        | 73591    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.8     |
|    ep_rew_mean      | -0.0302  |
|    exploration_rate | 0.0751   |
| time/               |          |
|    episodes         | 19116    |
|    fps              | 161      |
|    time_elapsed     | 2065     |
|    total_timesteps  | 334477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 73619    |
----------------------------------
Eval num_timesteps=334500, episode_reward=-0.11 +/- 0.16
Episode length: 33.24 +/- 19.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 33.2     |
|    mean_reward      | -0.112   |
| rollout/            |          |
|    exploration_rate | 0.075    |
| time/               |          |
|    total_timesteps  | 334500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 73624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.7     |
|    ep_rew_mean      | -0.0297  |
|    exploration_rate | 0.0746   |
| time/               |          |
|    episodes         | 19120    |
|    fps              | 161      |
|    time_elapsed     | 2067     |
|    total_timesteps  | 334572   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000525 |
|    n_updates        | 73642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.6     |
|    ep_rew_mean      | -0.0295  |
|    exploration_rate | 0.0743   |
| time/               |          |
|    episodes         | 19124    |
|    fps              | 161      |
|    time_elapsed     | 2067     |
|    total_timesteps  | 334646   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000883 |
|    n_updates        | 73661    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.3     |
|    ep_rew_mean      | -0.038   |
|    exploration_rate | 0.0739   |
| time/               |          |
|    episodes         | 19128    |
|    fps              | 161      |
|    time_elapsed     | 2067     |
|    total_timesteps  | 334726   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000739 |
|    n_updates        | 73681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | -0.0388  |
|    exploration_rate | 0.0735   |
| time/               |          |
|    episodes         | 19132    |
|    fps              | 161      |
|    time_elapsed     | 2067     |
|    total_timesteps  | 334812   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 73702    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | -0.0389  |
|    exploration_rate | 0.0732   |
| time/               |          |
|    episodes         | 19136    |
|    fps              | 161      |
|    time_elapsed     | 2068     |
|    total_timesteps  | 334888   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 73721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | -0.039   |
|    exploration_rate | 0.0728   |
| time/               |          |
|    episodes         | 19140    |
|    fps              | 161      |
|    time_elapsed     | 2068     |
|    total_timesteps  | 334966   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00087  |
|    n_updates        | 73741    |
----------------------------------
Eval num_timesteps=335000, episode_reward=-0.12 +/- 0.23
Episode length: 41.36 +/- 23.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.4     |
|    mean_reward      | -0.125   |
| rollout/            |          |
|    exploration_rate | 0.0726   |
| time/               |          |
|    total_timesteps  | 335000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000322 |
|    n_updates        | 73749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.7     |
|    ep_rew_mean      | -0.0398  |
|    exploration_rate | 0.0722   |
| time/               |          |
|    episodes         | 19144    |
|    fps              | 161      |
|    time_elapsed     | 2070     |
|    total_timesteps  | 335086   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000706 |
|    n_updates        | 73771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | -0.0328  |
|    exploration_rate | 0.0715   |
| time/               |          |
|    episodes         | 19148    |
|    fps              | 161      |
|    time_elapsed     | 2071     |
|    total_timesteps  | 335238   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000788 |
|    n_updates        | 73809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 0.071    |
| time/               |          |
|    episodes         | 19152    |
|    fps              | 161      |
|    time_elapsed     | 2071     |
|    total_timesteps  | 335345   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00404  |
|    n_updates        | 73836    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.6     |
|    ep_rew_mean      | -0.0333  |
|    exploration_rate | 0.0706   |
| time/               |          |
|    episodes         | 19156    |
|    fps              | 161      |
|    time_elapsed     | 2071     |
|    total_timesteps  | 335426   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 73856    |
----------------------------------
Eval num_timesteps=335500, episode_reward=-0.09 +/- 0.24
Episode length: 38.80 +/- 18.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.8     |
|    mean_reward      | -0.0942  |
| rollout/            |          |
|    exploration_rate | 0.0703   |
| time/               |          |
|    total_timesteps  | 335500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000764 |
|    n_updates        | 73874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.8     |
|    ep_rew_mean      | -0.0342  |
|    exploration_rate | 0.0701   |
| time/               |          |
|    episodes         | 19160    |
|    fps              | 161      |
|    time_elapsed     | 2073     |
|    total_timesteps  | 335536   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000825 |
|    n_updates        | 73883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.4     |
|    ep_rew_mean      | -0.0466  |
|    exploration_rate | 0.0694   |
| time/               |          |
|    episodes         | 19164    |
|    fps              | 161      |
|    time_elapsed     | 2074     |
|    total_timesteps  | 335677   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 73919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.9     |
|    ep_rew_mean      | -0.0484  |
|    exploration_rate | 0.0688   |
| time/               |          |
|    episodes         | 19168    |
|    fps              | 161      |
|    time_elapsed     | 2074     |
|    total_timesteps  | 335808   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000752 |
|    n_updates        | 73951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.3     |
|    ep_rew_mean      | -0.0462  |
|    exploration_rate | 0.0685   |
| time/               |          |
|    episodes         | 19172    |
|    fps              | 161      |
|    time_elapsed     | 2074     |
|    total_timesteps  | 335879   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000595 |
|    n_updates        | 73969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.2     |
|    ep_rew_mean      | -0.0457  |
|    exploration_rate | 0.0681   |
| time/               |          |
|    episodes         | 19176    |
|    fps              | 161      |
|    time_elapsed     | 2074     |
|    total_timesteps  | 335950   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000522 |
|    n_updates        | 73987    |
----------------------------------
Eval num_timesteps=336000, episode_reward=-0.09 +/- 0.25
Episode length: 37.20 +/- 20.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.2     |
|    mean_reward      | -0.0879  |
| rollout/            |          |
|    exploration_rate | 0.0679   |
| time/               |          |
|    total_timesteps  | 336000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 73999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.4     |
|    ep_rew_mean      | -0.0467  |
|    exploration_rate | 0.0677   |
| time/               |          |
|    episodes         | 19180    |
|    fps              | 161      |
|    time_elapsed     | 2077     |
|    total_timesteps  | 336042   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 74010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.3     |
|    ep_rew_mean      | -0.0462  |
|    exploration_rate | 0.0672   |
| time/               |          |
|    episodes         | 19184    |
|    fps              | 161      |
|    time_elapsed     | 2077     |
|    total_timesteps  | 336150   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 74037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | -0.0389  |
|    exploration_rate | 0.0664   |
| time/               |          |
|    episodes         | 19188    |
|    fps              | 161      |
|    time_elapsed     | 2077     |
|    total_timesteps  | 336308   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00254  |
|    n_updates        | 74076    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | -0.0389  |
|    exploration_rate | 0.0659   |
| time/               |          |
|    episodes         | 19192    |
|    fps              | 161      |
|    time_elapsed     | 2077     |
|    total_timesteps  | 336415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00202  |
|    n_updates        | 74103    |
----------------------------------
Eval num_timesteps=336500, episode_reward=-0.12 +/- 0.22
Episode length: 41.16 +/- 22.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.2     |
|    mean_reward      | -0.124   |
| rollout/            |          |
|    exploration_rate | 0.0655   |
| time/               |          |
|    total_timesteps  | 336500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00386  |
|    n_updates        | 74124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | -0.0299  |
|    exploration_rate | 0.0654   |
| time/               |          |
|    episodes         | 19196    |
|    fps              | 161      |
|    time_elapsed     | 2080     |
|    total_timesteps  | 336531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 74132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.0648   |
| time/               |          |
|    episodes         | 19200    |
|    fps              | 161      |
|    time_elapsed     | 2080     |
|    total_timesteps  | 336654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000793 |
|    n_updates        | 74163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.0643   |
| time/               |          |
|    episodes         | 19204    |
|    fps              | 161      |
|    time_elapsed     | 2080     |
|    total_timesteps  | 336773   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000842 |
|    n_updates        | 74193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0317  |
|    exploration_rate | 0.0639   |
| time/               |          |
|    episodes         | 19208    |
|    fps              | 161      |
|    time_elapsed     | 2081     |
|    total_timesteps  | 336837   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00412  |
|    n_updates        | 74209    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.041   |
|    exploration_rate | 0.0636   |
| time/               |          |
|    episodes         | 19212    |
|    fps              | 161      |
|    time_elapsed     | 2081     |
|    total_timesteps  | 336916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 74228    |
----------------------------------
Eval num_timesteps=337000, episode_reward=-0.11 +/- 0.21
Episode length: 36.50 +/- 20.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36.5     |
|    mean_reward      | -0.105   |
| rollout/            |          |
|    exploration_rate | 0.0632   |
| time/               |          |
|    total_timesteps  | 337000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000963 |
|    n_updates        | 74249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0506  |
|    exploration_rate | 0.0631   |
| time/               |          |
|    episodes         | 19216    |
|    fps              | 161      |
|    time_elapsed     | 2083     |
|    total_timesteps  | 337018   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 74254    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0512  |
|    exploration_rate | 0.0626   |
| time/               |          |
|    episodes         | 19220    |
|    fps              | 161      |
|    time_elapsed     | 2083     |
|    total_timesteps  | 337128   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000699 |
|    n_updates        | 74281    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0514  |
|    exploration_rate | 0.0622   |
| time/               |          |
|    episodes         | 19224    |
|    fps              | 161      |
|    time_elapsed     | 2083     |
|    total_timesteps  | 337206   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00236  |
|    n_updates        | 74301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0527  |
|    exploration_rate | 0.0617   |
| time/               |          |
|    episodes         | 19228    |
|    fps              | 161      |
|    time_elapsed     | 2083     |
|    total_timesteps  | 337319   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 74329    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0435  |
|    exploration_rate | 0.0612   |
| time/               |          |
|    episodes         | 19232    |
|    fps              | 161      |
|    time_elapsed     | 2084     |
|    total_timesteps  | 337425   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000974 |
|    n_updates        | 74356    |
----------------------------------
Eval num_timesteps=337500, episode_reward=-0.12 +/- 0.16
Episode length: 34.40 +/- 19.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.4     |
|    mean_reward      | -0.117   |
| rollout/            |          |
|    exploration_rate | 0.0608   |
| time/               |          |
|    total_timesteps  | 337500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000651 |
|    n_updates        | 74374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.8     |
|    ep_rew_mean      | -0.0462  |
|    exploration_rate | 0.0605   |
| time/               |          |
|    episodes         | 19236    |
|    fps              | 161      |
|    time_elapsed     | 2086     |
|    total_timesteps  | 337569   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00341  |
|    n_updates        | 74392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0366  |
|    exploration_rate | 0.0601   |
| time/               |          |
|    episodes         | 19240    |
|    fps              | 161      |
|    time_elapsed     | 2086     |
|    total_timesteps  | 337656   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000669 |
|    n_updates        | 74413    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27       |
|    ep_rew_mean      | -0.047   |
|    exploration_rate | 0.0595   |
| time/               |          |
|    episodes         | 19244    |
|    fps              | 161      |
|    time_elapsed     | 2087     |
|    total_timesteps  | 337785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000944 |
|    n_updates        | 74446    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0456  |
|    exploration_rate | 0.0589   |
| time/               |          |
|    episodes         | 19248    |
|    fps              | 161      |
|    time_elapsed     | 2087     |
|    total_timesteps  | 337903   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000576 |
|    n_updates        | 74475    |
----------------------------------
Eval num_timesteps=338000, episode_reward=-0.08 +/- 0.25
Episode length: 34.24 +/- 19.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.2     |
|    mean_reward      | -0.076   |
| rollout/            |          |
|    exploration_rate | 0.0584   |
| time/               |          |
|    total_timesteps  | 338000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00356  |
|    n_updates        | 74499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0457  |
|    exploration_rate | 0.0584   |
| time/               |          |
|    episodes         | 19252    |
|    fps              | 161      |
|    time_elapsed     | 2089     |
|    total_timesteps  | 338012   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000659 |
|    n_updates        | 74502    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0359  |
|    exploration_rate | 0.058    |
| time/               |          |
|    episodes         | 19256    |
|    fps              | 161      |
|    time_elapsed     | 2089     |
|    total_timesteps  | 338099   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 74524    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.0349  |
|    exploration_rate | 0.0576   |
| time/               |          |
|    episodes         | 19260    |
|    fps              | 161      |
|    time_elapsed     | 2089     |
|    total_timesteps  | 338183   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00332  |
|    n_updates        | 74545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.0571   |
| time/               |          |
|    episodes         | 19264    |
|    fps              | 161      |
|    time_elapsed     | 2090     |
|    total_timesteps  | 338279   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000879 |
|    n_updates        | 74569    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0318  |
|    exploration_rate | 0.0566   |
| time/               |          |
|    episodes         | 19268    |
|    fps              | 161      |
|    time_elapsed     | 2090     |
|    total_timesteps  | 338378   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 74594    |
----------------------------------
Eval num_timesteps=338500, episode_reward=-0.12 +/- 0.22
Episode length: 39.42 +/- 22.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.4     |
|    mean_reward      | -0.117   |
| rollout/            |          |
|    exploration_rate | 0.0561   |
| time/               |          |
|    total_timesteps  | 338500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000955 |
|    n_updates        | 74624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.3     |
|    ep_rew_mean      | -0.0343  |
|    exploration_rate | 0.056    |
| time/               |          |
|    episodes         | 19272    |
|    fps              | 161      |
|    time_elapsed     | 2093     |
|    total_timesteps  | 338513   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 74628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0364  |
|    exploration_rate | 0.0554   |
| time/               |          |
|    episodes         | 19276    |
|    fps              | 161      |
|    time_elapsed     | 2093     |
|    total_timesteps  | 338636   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000561 |
|    n_updates        | 74658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.1     |
|    ep_rew_mean      | -0.0372  |
|    exploration_rate | 0.0549   |
| time/               |          |
|    episodes         | 19280    |
|    fps              | 161      |
|    time_elapsed     | 2093     |
|    total_timesteps  | 338748   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000801 |
|    n_updates        | 74686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.8     |
|    ep_rew_mean      | -0.0262  |
|    exploration_rate | 0.0545   |
| time/               |          |
|    episodes         | 19284    |
|    fps              | 161      |
|    time_elapsed     | 2093     |
|    total_timesteps  | 338831   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000552 |
|    n_updates        | 74707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.2     |
|    ep_rew_mean      | -0.0337  |
|    exploration_rate | 0.054    |
| time/               |          |
|    episodes         | 19288    |
|    fps              | 161      |
|    time_elapsed     | 2093     |
|    total_timesteps  | 338927   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000871 |
|    n_updates        | 74731    |
----------------------------------
Eval num_timesteps=339000, episode_reward=-0.12 +/- 0.22
Episode length: 39.74 +/- 20.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.7     |
|    mean_reward      | -0.118   |
| rollout/            |          |
|    exploration_rate | 0.0537   |
| time/               |          |
|    total_timesteps  | 339000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000709 |
|    n_updates        | 74749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.0536   |
| time/               |          |
|    episodes         | 19292    |
|    fps              | 161      |
|    time_elapsed     | 2096     |
|    total_timesteps  | 339028   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00148  |
|    n_updates        | 74756    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0416  |
|    exploration_rate | 0.0532   |
| time/               |          |
|    episodes         | 19296    |
|    fps              | 161      |
|    time_elapsed     | 2096     |
|    total_timesteps  | 339096   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000998 |
|    n_updates        | 74773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0512  |
|    exploration_rate | 0.0527   |
| time/               |          |
|    episodes         | 19300    |
|    fps              | 161      |
|    time_elapsed     | 2096     |
|    total_timesteps  | 339209   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000895 |
|    n_updates        | 74802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.042   |
|    exploration_rate | 0.052    |
| time/               |          |
|    episodes         | 19304    |
|    fps              | 161      |
|    time_elapsed     | 2096     |
|    total_timesteps  | 339348   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0031   |
|    n_updates        | 74836    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.045   |
|    exploration_rate | 0.0514   |
| time/               |          |
|    episodes         | 19308    |
|    fps              | 161      |
|    time_elapsed     | 2097     |
|    total_timesteps  | 339486   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000868 |
|    n_updates        | 74871    |
----------------------------------
Eval num_timesteps=339500, episode_reward=-0.08 +/- 0.25
Episode length: 34.34 +/- 19.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.3     |
|    mean_reward      | -0.0763  |
| rollout/            |          |
|    exploration_rate | 0.0513   |
| time/               |          |
|    total_timesteps  | 339500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0015   |
|    n_updates        | 74874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0355  |
|    exploration_rate | 0.0509   |
| time/               |          |
|    episodes         | 19312    |
|    fps              | 161      |
|    time_elapsed     | 2099     |
|    total_timesteps  | 339580   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000814 |
|    n_updates        | 74894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.0503   |
| time/               |          |
|    episodes         | 19316    |
|    fps              | 161      |
|    time_elapsed     | 2099     |
|    total_timesteps  | 339719   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000758 |
|    n_updates        | 74929    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.5     |
|    ep_rew_mean      | -0.029   |
|    exploration_rate | 0.0495   |
| time/               |          |
|    episodes         | 19320    |
|    fps              | 161      |
|    time_elapsed     | 2100     |
|    total_timesteps  | 339878   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 74969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.7     |
|    ep_rew_mean      | -0.0299  |
|    exploration_rate | 0.0491   |
| time/               |          |
|    episodes         | 19324    |
|    fps              | 161      |
|    time_elapsed     | 2100     |
|    total_timesteps  | 339978   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00176  |
|    n_updates        | 74994    |
----------------------------------
Eval num_timesteps=340000, episode_reward=-0.07 +/- 0.25
Episode length: 33.68 +/- 19.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 33.7     |
|    mean_reward      | -0.0738  |
| rollout/            |          |
|    exploration_rate | 0.049    |
| time/               |          |
|    total_timesteps  | 340000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000951 |
|    n_updates        | 74999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.3     |
|    ep_rew_mean      | -0.0323  |
|    exploration_rate | 0.0482   |
| time/               |          |
|    episodes         | 19328    |
|    fps              | 161      |
|    time_elapsed     | 2102     |
|    total_timesteps  | 340152   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000832 |
|    n_updates        | 75037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.2     |
|    ep_rew_mean      | -0.0417  |
|    exploration_rate | 0.0478   |
| time/               |          |
|    episodes         | 19332    |
|    fps              | 161      |
|    time_elapsed     | 2102     |
|    total_timesteps  | 340244   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 75060    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.7     |
|    ep_rew_mean      | -0.0397  |
|    exploration_rate | 0.0473   |
| time/               |          |
|    episodes         | 19336    |
|    fps              | 161      |
|    time_elapsed     | 2102     |
|    total_timesteps  | 340338   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00457  |
|    n_updates        | 75084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.9     |
|    ep_rew_mean      | -0.0507  |
|    exploration_rate | 0.0468   |
| time/               |          |
|    episodes         | 19340    |
|    fps              | 161      |
|    time_elapsed     | 2103     |
|    total_timesteps  | 340450   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000972 |
|    n_updates        | 75112    |
----------------------------------
Eval num_timesteps=340500, episode_reward=-0.13 +/- 0.15
Episode length: 37.92 +/- 16.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.9     |
|    mean_reward      | -0.131   |
| rollout/            |          |
|    exploration_rate | 0.0466   |
| time/               |          |
|    total_timesteps  | 340500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 75124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28       |
|    ep_rew_mean      | -0.0508  |
|    exploration_rate | 0.0462   |
| time/               |          |
|    episodes         | 19344    |
|    fps              | 161      |
|    time_elapsed     | 2105     |
|    total_timesteps  | 340582   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000531 |
|    n_updates        | 75145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.6     |
|    ep_rew_mean      | -0.0593  |
|    exploration_rate | 0.0458   |
| time/               |          |
|    episodes         | 19348    |
|    fps              | 161      |
|    time_elapsed     | 2105     |
|    total_timesteps  | 340661   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000963 |
|    n_updates        | 75165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.7     |
|    ep_rew_mean      | -0.0597  |
|    exploration_rate | 0.0452   |
| time/               |          |
|    episodes         | 19352    |
|    fps              | 161      |
|    time_elapsed     | 2106     |
|    total_timesteps  | 340780   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00469  |
|    n_updates        | 75194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28       |
|    ep_rew_mean      | -0.0709  |
|    exploration_rate | 0.0447   |
| time/               |          |
|    episodes         | 19356    |
|    fps              | 161      |
|    time_elapsed     | 2106     |
|    total_timesteps  | 340898   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000982 |
|    n_updates        | 75224    |
----------------------------------
Eval num_timesteps=341000, episode_reward=-0.18 +/- 0.08
Episode length: 45.06 +/- 19.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.1     |
|    mean_reward      | -0.179   |
| rollout/            |          |
|    exploration_rate | 0.0442   |
| time/               |          |
|    total_timesteps  | 341000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 75249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.4     |
|    ep_rew_mean      | -0.0724  |
|    exploration_rate | 0.0441   |
| time/               |          |
|    episodes         | 19360    |
|    fps              | 161      |
|    time_elapsed     | 2109     |
|    total_timesteps  | 341018   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 75254    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.4     |
|    ep_rew_mean      | -0.0725  |
|    exploration_rate | 0.0436   |
| time/               |          |
|    episodes         | 19364    |
|    fps              | 161      |
|    time_elapsed     | 2109     |
|    total_timesteps  | 341117   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000799 |
|    n_updates        | 75279    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.6     |
|    ep_rew_mean      | -0.0633  |
|    exploration_rate | 0.0431   |
| time/               |          |
|    episodes         | 19368    |
|    fps              | 161      |
|    time_elapsed     | 2109     |
|    total_timesteps  | 341236   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000694 |
|    n_updates        | 75308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.7     |
|    ep_rew_mean      | -0.0538  |
|    exploration_rate | 0.0424   |
| time/               |          |
|    episodes         | 19372    |
|    fps              | 161      |
|    time_elapsed     | 2109     |
|    total_timesteps  | 341385   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0009   |
|    n_updates        | 75346    |
----------------------------------
Eval num_timesteps=341500, episode_reward=-0.16 +/- 0.21
Episode length: 50.88 +/- 17.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.9     |
|    mean_reward      | -0.163   |
| rollout/            |          |
|    exploration_rate | 0.0418   |
| time/               |          |
|    total_timesteps  | 341500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 75374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.2     |
|    ep_rew_mean      | -0.056   |
|    exploration_rate | 0.0415   |
| time/               |          |
|    episodes         | 19376    |
|    fps              | 161      |
|    time_elapsed     | 2113     |
|    total_timesteps  | 341561   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 75390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.3     |
|    ep_rew_mean      | -0.056   |
|    exploration_rate | 0.041    |
| time/               |          |
|    episodes         | 19380    |
|    fps              | 161      |
|    time_elapsed     | 2113     |
|    total_timesteps  | 341674   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 75418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.6     |
|    ep_rew_mean      | -0.0675  |
|    exploration_rate | 0.0404   |
| time/               |          |
|    episodes         | 19384    |
|    fps              | 161      |
|    time_elapsed     | 2113     |
|    total_timesteps  | 341794   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 75448    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.6     |
|    ep_rew_mean      | -0.0714  |
|    exploration_rate | 0.0395   |
| time/               |          |
|    episodes         | 19388    |
|    fps              | 161      |
|    time_elapsed     | 2114     |
|    total_timesteps  | 341989   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000626 |
|    n_updates        | 75497    |
----------------------------------
Eval num_timesteps=342000, episode_reward=-0.13 +/- 0.15
Episode length: 36.50 +/- 15.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36.5     |
|    mean_reward      | -0.125   |
| rollout/            |          |
|    exploration_rate | 0.0394   |
| time/               |          |
|    total_timesteps  | 342000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000774 |
|    n_updates        | 75499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.7     |
|    ep_rew_mean      | -0.0717  |
|    exploration_rate | 0.039    |
| time/               |          |
|    episodes         | 19392    |
|    fps              | 161      |
|    time_elapsed     | 2116     |
|    total_timesteps  | 342097   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 75524    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.1     |
|    ep_rew_mean      | -0.0735  |
|    exploration_rate | 0.0384   |
| time/               |          |
|    episodes         | 19396    |
|    fps              | 161      |
|    time_elapsed     | 2116     |
|    total_timesteps  | 342211   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00064  |
|    n_updates        | 75552    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.5     |
|    ep_rew_mean      | -0.0648  |
|    exploration_rate | 0.0377   |
| time/               |          |
|    episodes         | 19400    |
|    fps              | 161      |
|    time_elapsed     | 2117     |
|    total_timesteps  | 342355   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 75588    |
----------------------------------
Eval num_timesteps=342500, episode_reward=-0.16 +/- 0.07
Episode length: 39.46 +/- 16.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.5     |
|    mean_reward      | -0.157   |
| rollout/            |          |
|    exploration_rate | 0.037    |
| time/               |          |
|    total_timesteps  | 342500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000962 |
|    n_updates        | 75624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.7     |
|    ep_rew_mean      | -0.0756  |
|    exploration_rate | 0.037    |
| time/               |          |
|    episodes         | 19404    |
|    fps              | 161      |
|    time_elapsed     | 2119     |
|    total_timesteps  | 342515   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 75628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.5     |
|    ep_rew_mean      | -0.0749  |
|    exploration_rate | 0.0364   |
| time/               |          |
|    episodes         | 19408    |
|    fps              | 161      |
|    time_elapsed     | 2120     |
|    total_timesteps  | 342634   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000648 |
|    n_updates        | 75658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.6     |
|    ep_rew_mean      | -0.0754  |
|    exploration_rate | 0.0359   |
| time/               |          |
|    episodes         | 19412    |
|    fps              | 161      |
|    time_elapsed     | 2120     |
|    total_timesteps  | 342741   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000532 |
|    n_updates        | 75685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.2     |
|    ep_rew_mean      | -0.0776  |
|    exploration_rate | 0.035    |
| time/               |          |
|    episodes         | 19416    |
|    fps              | 161      |
|    time_elapsed     | 2120     |
|    total_timesteps  | 342935   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000921 |
|    n_updates        | 75733    |
----------------------------------
Eval num_timesteps=343000, episode_reward=-0.12 +/- 0.21
Episode length: 39.36 +/- 17.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.4     |
|    mean_reward      | -0.116   |
| rollout/            |          |
|    exploration_rate | 0.0347   |
| time/               |          |
|    total_timesteps  | 343000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000619 |
|    n_updates        | 75749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.9     |
|    ep_rew_mean      | -0.0665  |
|    exploration_rate | 0.0343   |
| time/               |          |
|    episodes         | 19420    |
|    fps              | 161      |
|    time_elapsed     | 2123     |
|    total_timesteps  | 343065   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00122  |
|    n_updates        | 75766    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.9     |
|    ep_rew_mean      | -0.0705  |
|    exploration_rate | 0.0334   |
| time/               |          |
|    episodes         | 19424    |
|    fps              | 161      |
|    time_elapsed     | 2123     |
|    total_timesteps  | 343265   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 75816    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.8     |
|    ep_rew_mean      | -0.0701  |
|    exploration_rate | 0.0326   |
| time/               |          |
|    episodes         | 19428    |
|    fps              | 161      |
|    time_elapsed     | 2123     |
|    total_timesteps  | 343429   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000923 |
|    n_updates        | 75857    |
----------------------------------
Eval num_timesteps=343500, episode_reward=-0.20 +/- 0.08
Episode length: 49.02 +/- 19.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49       |
|    mean_reward      | -0.195   |
| rollout/            |          |
|    exploration_rate | 0.0323   |
| time/               |          |
|    total_timesteps  | 343500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000966 |
|    n_updates        | 75874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.7     |
|    ep_rew_mean      | -0.0699  |
|    exploration_rate | 0.0322   |
| time/               |          |
|    episodes         | 19432    |
|    fps              | 161      |
|    time_elapsed     | 2126     |
|    total_timesteps  | 343516   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000846 |
|    n_updates        | 75878    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.3     |
|    ep_rew_mean      | -0.0722  |
|    exploration_rate | 0.0314   |
| time/               |          |
|    episodes         | 19436    |
|    fps              | 161      |
|    time_elapsed     | 2127     |
|    total_timesteps  | 343669   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000285 |
|    n_updates        | 75917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.5     |
|    ep_rew_mean      | -0.0729  |
|    exploration_rate | 0.0308   |
| time/               |          |
|    episodes         | 19440    |
|    fps              | 161      |
|    time_elapsed     | 2127     |
|    total_timesteps  | 343799   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000601 |
|    n_updates        | 75949    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.3     |
|    ep_rew_mean      | -0.0723  |
|    exploration_rate | 0.0303   |
| time/               |          |
|    episodes         | 19444    |
|    fps              | 161      |
|    time_elapsed     | 2127     |
|    total_timesteps  | 343915   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000792 |
|    n_updates        | 75978    |
----------------------------------
Eval num_timesteps=344000, episode_reward=-0.09 +/- 0.24
Episode length: 38.62 +/- 17.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.6     |
|    mean_reward      | -0.0935  |
| rollout/            |          |
|    exploration_rate | 0.0299   |
| time/               |          |
|    total_timesteps  | 344000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000408 |
|    n_updates        | 75999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.8     |
|    ep_rew_mean      | -0.0743  |
|    exploration_rate | 0.0297   |
| time/               |          |
|    episodes         | 19448    |
|    fps              | 161      |
|    time_elapsed     | 2130     |
|    total_timesteps  | 344043   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000512 |
|    n_updates        | 76010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34       |
|    ep_rew_mean      | -0.0751  |
|    exploration_rate | 0.029    |
| time/               |          |
|    episodes         | 19452    |
|    fps              | 161      |
|    time_elapsed     | 2130     |
|    total_timesteps  | 344182   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00146  |
|    n_updates        | 76045    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.9     |
|    ep_rew_mean      | -0.0747  |
|    exploration_rate | 0.0285   |
| time/               |          |
|    episodes         | 19456    |
|    fps              | 161      |
|    time_elapsed     | 2130     |
|    total_timesteps  | 344291   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000746 |
|    n_updates        | 76072    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.6     |
|    ep_rew_mean      | -0.0772  |
|    exploration_rate | 0.0276   |
| time/               |          |
|    episodes         | 19460    |
|    fps              | 161      |
|    time_elapsed     | 2131     |
|    total_timesteps  | 344474   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 76118    |
----------------------------------
Eval num_timesteps=344500, episode_reward=-0.14 +/- 0.21
Episode length: 44.38 +/- 18.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | -0.137   |
| rollout/            |          |
|    exploration_rate | 0.0275   |
| time/               |          |
|    total_timesteps  | 344500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 76124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.8     |
|    ep_rew_mean      | -0.082   |
|    exploration_rate | 0.0265   |
| time/               |          |
|    episodes         | 19464    |
|    fps              | 161      |
|    time_elapsed     | 2134     |
|    total_timesteps  | 344692   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000757 |
|    n_updates        | 76172    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.2     |
|    ep_rew_mean      | -0.0938  |
|    exploration_rate | 0.0258   |
| time/               |          |
|    episodes         | 19468    |
|    fps              | 161      |
|    time_elapsed     | 2134     |
|    total_timesteps  | 344855   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00323  |
|    n_updates        | 76213    |
----------------------------------
Eval num_timesteps=345000, episode_reward=-0.14 +/- 0.16
Episode length: 39.56 +/- 15.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.6     |
|    mean_reward      | -0.137   |
| rollout/            |          |
|    exploration_rate | 0.0251   |
| time/               |          |
|    total_timesteps  | 345000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000826 |
|    n_updates        | 76249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.4     |
|    ep_rew_mean      | -0.104   |
|    exploration_rate | 0.025    |
| time/               |          |
|    episodes         | 19472    |
|    fps              | 161      |
|    time_elapsed     | 2137     |
|    total_timesteps  | 345021   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 76255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.1     |
|    ep_rew_mean      | -0.103   |
|    exploration_rate | 0.0243   |
| time/               |          |
|    episodes         | 19476    |
|    fps              | 161      |
|    time_elapsed     | 2137     |
|    total_timesteps  | 345171   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000593 |
|    n_updates        | 76292    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.3     |
|    ep_rew_mean      | -0.104   |
|    exploration_rate | 0.0236   |
| time/               |          |
|    episodes         | 19480    |
|    fps              | 161      |
|    time_elapsed     | 2137     |
|    total_timesteps  | 345306   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000564 |
|    n_updates        | 76326    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.7     |
|    ep_rew_mean      | -0.106   |
|    exploration_rate | 0.0229   |
| time/               |          |
|    episodes         | 19484    |
|    fps              | 161      |
|    time_elapsed     | 2138     |
|    total_timesteps  | 345463   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000741 |
|    n_updates        | 76365    |
----------------------------------
Eval num_timesteps=345500, episode_reward=-0.12 +/- 0.20
Episode length: 41.20 +/- 15.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.2     |
|    mean_reward      | -0.124   |
| rollout/            |          |
|    exploration_rate | 0.0227   |
| time/               |          |
|    total_timesteps  | 345500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000807 |
|    n_updates        | 76374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.1     |
|    ep_rew_mean      | -0.0936  |
|    exploration_rate | 0.0222   |
| time/               |          |
|    episodes         | 19488    |
|    fps              | 161      |
|    time_elapsed     | 2141     |
|    total_timesteps  | 345604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 76400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.4     |
|    ep_rew_mean      | -0.0945  |
|    exploration_rate | 0.0216   |
| time/               |          |
|    episodes         | 19492    |
|    fps              | 161      |
|    time_elapsed     | 2141     |
|    total_timesteps  | 345734   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 76433    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.8     |
|    ep_rew_mean      | -0.086   |
|    exploration_rate | 0.0208   |
| time/               |          |
|    episodes         | 19496    |
|    fps              | 161      |
|    time_elapsed     | 2141     |
|    total_timesteps  | 345886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 76471    |
----------------------------------
Eval num_timesteps=346000, episode_reward=-0.18 +/- 0.07
Episode length: 45.36 +/- 16.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | -0.181   |
| rollout/            |          |
|    exploration_rate | 0.0203   |
| time/               |          |
|    total_timesteps  | 346000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000357 |
|    n_updates        | 76499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.9     |
|    ep_rew_mean      | -0.0964  |
|    exploration_rate | 0.0201   |
| time/               |          |
|    episodes         | 19500    |
|    fps              | 161      |
|    time_elapsed     | 2144     |
|    total_timesteps  | 346040   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000605 |
|    n_updates        | 76509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.8     |
|    ep_rew_mean      | -0.096   |
|    exploration_rate | 0.0194   |
| time/               |          |
|    episodes         | 19504    |
|    fps              | 161      |
|    time_elapsed     | 2144     |
|    total_timesteps  | 346190   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 76547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | -0.0979  |
|    exploration_rate | 0.0186   |
| time/               |          |
|    episodes         | 19508    |
|    fps              | 161      |
|    time_elapsed     | 2145     |
|    total_timesteps  | 346356   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00083  |
|    n_updates        | 76588    |
----------------------------------
Eval num_timesteps=346500, episode_reward=-0.15 +/- 0.21
Episode length: 47.02 +/- 17.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47       |
|    mean_reward      | -0.147   |
| rollout/            |          |
|    exploration_rate | 0.0179   |
| time/               |          |
|    total_timesteps  | 346500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000676 |
|    n_updates        | 76624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.1     |
|    ep_rew_mean      | -0.112   |
|    exploration_rate | 0.0176   |
| time/               |          |
|    episodes         | 19512    |
|    fps              | 161      |
|    time_elapsed     | 2148     |
|    total_timesteps  | 346554   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000897 |
|    n_updates        | 76638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.6     |
|    ep_rew_mean      | -0.119   |
|    exploration_rate | 0.017    |
| time/               |          |
|    episodes         | 19516    |
|    fps              | 161      |
|    time_elapsed     | 2148     |
|    total_timesteps  | 346691   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000537 |
|    n_updates        | 76672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.1     |
|    ep_rew_mean      | -0.132   |
|    exploration_rate | 0.016    |
| time/               |          |
|    episodes         | 19520    |
|    fps              | 161      |
|    time_elapsed     | 2149     |
|    total_timesteps  | 346880   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000851 |
|    n_updates        | 76719    |
----------------------------------
Eval num_timesteps=347000, episode_reward=-0.14 +/- 0.21
Episode length: 44.60 +/- 15.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.6     |
|    mean_reward      | -0.137   |
| rollout/            |          |
|    exploration_rate | 0.0155   |
| time/               |          |
|    total_timesteps  | 347000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000536 |
|    n_updates        | 76749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.5     |
|    ep_rew_mean      | -0.129   |
|    exploration_rate | 0.0154   |
| time/               |          |
|    episodes         | 19524    |
|    fps              | 161      |
|    time_elapsed     | 2151     |
|    total_timesteps  | 347014   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 76753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.6     |
|    ep_rew_mean      | -0.13    |
|    exploration_rate | 0.0145   |
| time/               |          |
|    episodes         | 19528    |
|    fps              | 161      |
|    time_elapsed     | 2152     |
|    total_timesteps  | 347192   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000404 |
|    n_updates        | 76797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.2     |
|    ep_rew_mean      | -0.132   |
|    exploration_rate | 0.0139   |
| time/               |          |
|    episodes         | 19532    |
|    fps              | 161      |
|    time_elapsed     | 2152     |
|    total_timesteps  | 347334   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000409 |
|    n_updates        | 76833    |
----------------------------------
Eval num_timesteps=347500, episode_reward=-0.16 +/- 0.08
Episode length: 41.40 +/- 18.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.4     |
|    mean_reward      | -0.165   |
| rollout/            |          |
|    exploration_rate | 0.0131   |
| time/               |          |
|    total_timesteps  | 347500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000695 |
|    n_updates        | 76874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.4     |
|    ep_rew_mean      | -0.133   |
|    exploration_rate | 0.013    |
| time/               |          |
|    episodes         | 19536    |
|    fps              | 161      |
|    time_elapsed     | 2155     |
|    total_timesteps  | 347508   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 76876    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.5     |
|    ep_rew_mean      | -0.133   |
|    exploration_rate | 0.0124   |
| time/               |          |
|    episodes         | 19540    |
|    fps              | 161      |
|    time_elapsed     | 2155     |
|    total_timesteps  | 347646   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00144  |
|    n_updates        | 76911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.4     |
|    ep_rew_mean      | -0.132   |
|    exploration_rate | 0.0119   |
| time/               |          |
|    episodes         | 19544    |
|    fps              | 161      |
|    time_elapsed     | 2155     |
|    total_timesteps  | 347750   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 76937    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.7     |
|    ep_rew_mean      | -0.134   |
|    exploration_rate | 0.0111   |
| time/               |          |
|    episodes         | 19548    |
|    fps              | 161      |
|    time_elapsed     | 2156     |
|    total_timesteps  | 347910   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 76977    |
----------------------------------
Eval num_timesteps=348000, episode_reward=-0.19 +/- 0.07
Episode length: 47.94 +/- 17.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.9     |
|    mean_reward      | -0.191   |
| rollout/            |          |
|    exploration_rate | 0.0107   |
| time/               |          |
|    total_timesteps  | 348000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00216  |
|    n_updates        | 76999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.6     |
|    ep_rew_mean      | -0.133   |
|    exploration_rate | 0.0104   |
| time/               |          |
|    episodes         | 19552    |
|    fps              | 161      |
|    time_elapsed     | 2159     |
|    total_timesteps  | 348042   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000786 |
|    n_updates        | 77010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.2     |
|    ep_rew_mean      | -0.136   |
|    exploration_rate | 0.00964  |
| time/               |          |
|    episodes         | 19556    |
|    fps              | 161      |
|    time_elapsed     | 2159     |
|    total_timesteps  | 348209   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000673 |
|    n_updates        | 77052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.8     |
|    ep_rew_mean      | -0.134   |
|    exploration_rate | 0.00896  |
| time/               |          |
|    episodes         | 19560    |
|    fps              | 161      |
|    time_elapsed     | 2159     |
|    total_timesteps  | 348352   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000743 |
|    n_updates        | 77087    |
----------------------------------
Eval num_timesteps=348500, episode_reward=-0.16 +/- 0.16
Episode length: 45.74 +/- 15.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.7     |
|    mean_reward      | -0.162   |
| rollout/            |          |
|    exploration_rate | 0.00825  |
| time/               |          |
|    total_timesteps  | 348500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00035  |
|    n_updates        | 77124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39       |
|    ep_rew_mean      | -0.135   |
|    exploration_rate | 0.00782  |
| time/               |          |
|    episodes         | 19564    |
|    fps              | 161      |
|    time_elapsed     | 2163     |
|    total_timesteps  | 348588   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 77146    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.9     |
|    ep_rew_mean      | -0.135   |
|    exploration_rate | 0.00704  |
| time/               |          |
|    episodes         | 19568    |
|    fps              | 161      |
|    time_elapsed     | 2163     |
|    total_timesteps  | 348749   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000468 |
|    n_updates        | 77187    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.5     |
|    ep_rew_mean      | -0.137   |
|    exploration_rate | 0.00597  |
| time/               |          |
|    episodes         | 19572    |
|    fps              | 161      |
|    time_elapsed     | 2163     |
|    total_timesteps  | 348972   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000763 |
|    n_updates        | 77242    |
----------------------------------
Eval num_timesteps=349000, episode_reward=-0.20 +/- 0.07
Episode length: 50.22 +/- 16.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.2     |
|    mean_reward      | -0.2     |
| rollout/            |          |
|    exploration_rate | 0.00583  |
| time/               |          |
|    total_timesteps  | 349000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000739 |
|    n_updates        | 77249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.7     |
|    ep_rew_mean      | -0.138   |
|    exploration_rate | 0.00515  |
| time/               |          |
|    episodes         | 19576    |
|    fps              | 161      |
|    time_elapsed     | 2167     |
|    total_timesteps  | 349141   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000479 |
|    n_updates        | 77285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.8     |
|    ep_rew_mean      | -0.138   |
|    exploration_rate | 0.00446  |
| time/               |          |
|    episodes         | 19580    |
|    fps              | 161      |
|    time_elapsed     | 2167     |
|    total_timesteps  | 349284   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000825 |
|    n_updates        | 77320    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.7     |
|    ep_rew_mean      | -0.138   |
|    exploration_rate | 0.00373  |
| time/               |          |
|    episodes         | 19584    |
|    fps              | 161      |
|    time_elapsed     | 2167     |
|    total_timesteps  | 349436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000388 |
|    n_updates        | 77358    |
----------------------------------
Eval num_timesteps=349500, episode_reward=-0.15 +/- 0.20
Episode length: 46.78 +/- 15.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.8     |
|    mean_reward      | -0.146   |
| rollout/            |          |
|    exploration_rate | 0.00342  |
| time/               |          |
|    total_timesteps  | 349500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 77374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.5     |
|    ep_rew_mean      | -0.151   |
|    exploration_rate | 0.0027   |
| time/               |          |
|    episodes         | 19588    |
|    fps              | 161      |
|    time_elapsed     | 2170     |
|    total_timesteps  | 349649   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000731 |
|    n_updates        | 77412    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.7     |
|    ep_rew_mean      | -0.142   |
|    exploration_rate | 0.00196  |
| time/               |          |
|    episodes         | 19592    |
|    fps              | 161      |
|    time_elapsed     | 2171     |
|    total_timesteps  | 349801   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000463 |
|    n_updates        | 77450    |
----------------------------------
Eval num_timesteps=350000, episode_reward=-0.11 +/- 0.24
Episode length: 41.86 +/- 17.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.9     |
|    mean_reward      | -0.106   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 350000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00194  |
|    n_updates        | 77499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.2     |
|    ep_rew_mean      | -0.154   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19596    |
|    fps              | 160      |
|    time_elapsed     | 2174     |
|    total_timesteps  | 350010   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00332  |
|    n_updates        | 77502    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.9     |
|    ep_rew_mean      | -0.153   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19600    |
|    fps              | 161      |
|    time_elapsed     | 2174     |
|    total_timesteps  | 350128   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000842 |
|    n_updates        | 77531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.4     |
|    ep_rew_mean      | -0.145   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19604    |
|    fps              | 161      |
|    time_elapsed     | 2174     |
|    total_timesteps  | 350326   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000679 |
|    n_updates        | 77581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.4     |
|    ep_rew_mean      | -0.145   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19608    |
|    fps              | 161      |
|    time_elapsed     | 2175     |
|    total_timesteps  | 350492   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000821 |
|    n_updates        | 77622    |
----------------------------------
Eval num_timesteps=350500, episode_reward=-0.08 +/- 0.28
Episode length: 40.96 +/- 20.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41       |
|    mean_reward      | -0.0829  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 350500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 77624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.2     |
|    ep_rew_mean      | -0.144   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19612    |
|    fps              | 161      |
|    time_elapsed     | 2177     |
|    total_timesteps  | 350671   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00198  |
|    n_updates        | 77667    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.9     |
|    ep_rew_mean      | -0.147   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19616    |
|    fps              | 161      |
|    time_elapsed     | 2178     |
|    total_timesteps  | 350883   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000535 |
|    n_updates        | 77720    |
----------------------------------
Eval num_timesteps=351000, episode_reward=-0.24 +/- 0.07
Episode length: 60.28 +/- 16.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60.3     |
|    mean_reward      | -0.241   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 351000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000595 |
|    n_updates        | 77749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.6     |
|    ep_rew_mean      | -0.149   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19620    |
|    fps              | 160      |
|    time_elapsed     | 2182     |
|    total_timesteps  | 351139   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000924 |
|    n_updates        | 77784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44       |
|    ep_rew_mean      | -0.155   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19624    |
|    fps              | 160      |
|    time_elapsed     | 2183     |
|    total_timesteps  | 351416   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000714 |
|    n_updates        | 77853    |
----------------------------------
Eval num_timesteps=351500, episode_reward=-0.26 +/- 0.05
Episode length: 64.84 +/- 13.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.8     |
|    mean_reward      | -0.259   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 351500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000522 |
|    n_updates        | 77874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.2     |
|    ep_rew_mean      | -0.156   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19628    |
|    fps              | 160      |
|    time_elapsed     | 2187     |
|    total_timesteps  | 351610   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 77902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45.2     |
|    ep_rew_mean      | -0.16    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19632    |
|    fps              | 160      |
|    time_elapsed     | 2188     |
|    total_timesteps  | 351858   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 77964    |
----------------------------------
Eval num_timesteps=352000, episode_reward=-0.27 +/- 0.04
Episode length: 67.82 +/- 10.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.8     |
|    mean_reward      | -0.271   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 352000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000426 |
|    n_updates        | 77999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.1     |
|    ep_rew_mean      | -0.164   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19636    |
|    fps              | 160      |
|    time_elapsed     | 2192     |
|    total_timesteps  | 352119   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000382 |
|    n_updates        | 78029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.7     |
|    ep_rew_mean      | -0.166   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19640    |
|    fps              | 160      |
|    time_elapsed     | 2193     |
|    total_timesteps  | 352320   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000736 |
|    n_updates        | 78079    |
----------------------------------
Eval num_timesteps=352500, episode_reward=-0.20 +/- 0.16
Episode length: 54.56 +/- 18.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.6     |
|    mean_reward      | -0.198   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 352500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000638 |
|    n_updates        | 78124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.3     |
|    ep_rew_mean      | -0.172   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19644    |
|    fps              | 160      |
|    time_elapsed     | 2196     |
|    total_timesteps  | 352581   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000416 |
|    n_updates        | 78145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.4     |
|    ep_rew_mean      | -0.177   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19648    |
|    fps              | 160      |
|    time_elapsed     | 2197     |
|    total_timesteps  | 352846   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000491 |
|    n_updates        | 78211    |
----------------------------------
Eval num_timesteps=353000, episode_reward=-0.22 +/- 0.23
Episode length: 64.62 +/- 15.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.6     |
|    mean_reward      | -0.218   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 353000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00042  |
|    n_updates        | 78249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50.7     |
|    ep_rew_mean      | -0.182   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19652    |
|    fps              | 160      |
|    time_elapsed     | 2201     |
|    total_timesteps  | 353109   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000773 |
|    n_updates        | 78277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52       |
|    ep_rew_mean      | -0.187   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19656    |
|    fps              | 160      |
|    time_elapsed     | 2202     |
|    total_timesteps  | 353409   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000539 |
|    n_updates        | 78352    |
----------------------------------
Eval num_timesteps=353500, episode_reward=-0.25 +/- 0.07
Episode length: 62.76 +/- 17.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.8     |
|    mean_reward      | -0.251   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 353500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000614 |
|    n_updates        | 78374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.2     |
|    ep_rew_mean      | -0.192   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19660    |
|    fps              | 160      |
|    time_elapsed     | 2206     |
|    total_timesteps  | 353675   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000304 |
|    n_updates        | 78418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.6     |
|    ep_rew_mean      | -0.194   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19664    |
|    fps              | 160      |
|    time_elapsed     | 2207     |
|    total_timesteps  | 353947   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000304 |
|    n_updates        | 78486    |
----------------------------------
Eval num_timesteps=354000, episode_reward=-0.25 +/- 0.06
Episode length: 62.60 +/- 15.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.6     |
|    mean_reward      | -0.25    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 354000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00046  |
|    n_updates        | 78499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.6     |
|    ep_rew_mean      | -0.198   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19668    |
|    fps              | 160      |
|    time_elapsed     | 2211     |
|    total_timesteps  | 354207   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00042  |
|    n_updates        | 78551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.6     |
|    ep_rew_mean      | -0.198   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19672    |
|    fps              | 160      |
|    time_elapsed     | 2212     |
|    total_timesteps  | 354433   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000466 |
|    n_updates        | 78608    |
----------------------------------
Eval num_timesteps=354500, episode_reward=-0.26 +/- 0.06
Episode length: 64.00 +/- 14.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64       |
|    mean_reward      | -0.256   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 354500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000733 |
|    n_updates        | 78624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.3     |
|    ep_rew_mean      | -0.201   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19676    |
|    fps              | 160      |
|    time_elapsed     | 2216     |
|    total_timesteps  | 354671   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 78667    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.2     |
|    ep_rew_mean      | -0.204   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19680    |
|    fps              | 160      |
|    time_elapsed     | 2216     |
|    total_timesteps  | 354900   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000731 |
|    n_updates        | 78724    |
----------------------------------
Eval num_timesteps=355000, episode_reward=-0.26 +/- 0.05
Episode length: 64.62 +/- 13.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.6     |
|    mean_reward      | -0.258   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 355000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000606 |
|    n_updates        | 78749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.5     |
|    ep_rew_mean      | -0.209   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19684    |
|    fps              | 159      |
|    time_elapsed     | 2221     |
|    total_timesteps  | 355185   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00204  |
|    n_updates        | 78796    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.8     |
|    ep_rew_mean      | -0.2     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19688    |
|    fps              | 159      |
|    time_elapsed     | 2221     |
|    total_timesteps  | 355425   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000529 |
|    n_updates        | 78856    |
----------------------------------
Eval num_timesteps=355500, episode_reward=-0.27 +/- 0.04
Episode length: 67.14 +/- 10.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.1     |
|    mean_reward      | -0.268   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 355500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000453 |
|    n_updates        | 78874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.8     |
|    ep_rew_mean      | -0.214   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19692    |
|    fps              | 159      |
|    time_elapsed     | 2226     |
|    total_timesteps  | 355678   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000426 |
|    n_updates        | 78919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.2     |
|    ep_rew_mean      | -0.216   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19696    |
|    fps              | 159      |
|    time_elapsed     | 2226     |
|    total_timesteps  | 355934   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 78983    |
----------------------------------
Eval num_timesteps=356000, episode_reward=-0.22 +/- 0.17
Episode length: 59.32 +/- 16.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.3     |
|    mean_reward      | -0.217   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 356000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 78999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.6     |
|    ep_rew_mean      | -0.222   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19700    |
|    fps              | 159      |
|    time_elapsed     | 2230     |
|    total_timesteps  | 356185   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000593 |
|    n_updates        | 79046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61       |
|    ep_rew_mean      | -0.233   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19704    |
|    fps              | 159      |
|    time_elapsed     | 2230     |
|    total_timesteps  | 356425   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00073  |
|    n_updates        | 79106    |
----------------------------------
Eval num_timesteps=356500, episode_reward=-0.26 +/- 0.05
Episode length: 64.58 +/- 13.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.6     |
|    mean_reward      | -0.258   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 356500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000908 |
|    n_updates        | 79124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.8     |
|    ep_rew_mean      | -0.237   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19708    |
|    fps              | 159      |
|    time_elapsed     | 2235     |
|    total_timesteps  | 356676   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000641 |
|    n_updates        | 79168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | -0.241   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19712    |
|    fps              | 159      |
|    time_elapsed     | 2235     |
|    total_timesteps  | 356970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 79242    |
----------------------------------
Eval num_timesteps=357000, episode_reward=-0.22 +/- 0.16
Episode length: 61.02 +/- 16.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61       |
|    mean_reward      | -0.224   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 357000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000682 |
|    n_updates        | 79249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.7     |
|    ep_rew_mean      | -0.244   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19716    |
|    fps              | 159      |
|    time_elapsed     | 2239     |
|    total_timesteps  | 357254   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 79313    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.5     |
|    ep_rew_mean      | -0.244   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19720    |
|    fps              | 159      |
|    time_elapsed     | 2240     |
|    total_timesteps  | 357490   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000767 |
|    n_updates        | 79372    |
----------------------------------
Eval num_timesteps=357500, episode_reward=-0.25 +/- 0.06
Episode length: 62.34 +/- 14.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.3     |
|    mean_reward      | -0.249   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 357500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000562 |
|    n_updates        | 79374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.1     |
|    ep_rew_mean      | -0.242   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19724    |
|    fps              | 159      |
|    time_elapsed     | 2244     |
|    total_timesteps  | 357727   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 79431    |
----------------------------------
Eval num_timesteps=358000, episode_reward=-0.25 +/- 0.06
Episode length: 62.58 +/- 16.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.6     |
|    mean_reward      | -0.25    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 358000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000786 |
|    n_updates        | 79499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64       |
|    ep_rew_mean      | -0.246   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19728    |
|    fps              | 159      |
|    time_elapsed     | 2248     |
|    total_timesteps  | 358012   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000681 |
|    n_updates        | 79502    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | -0.246   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19732    |
|    fps              | 159      |
|    time_elapsed     | 2249     |
|    total_timesteps  | 358272   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 79567    |
----------------------------------
Eval num_timesteps=358500, episode_reward=-0.25 +/- 0.06
Episode length: 62.94 +/- 14.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.9     |
|    mean_reward      | -0.251   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 358500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000811 |
|    n_updates        | 79624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | -0.246   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19736    |
|    fps              | 159      |
|    time_elapsed     | 2253     |
|    total_timesteps  | 358528   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000626 |
|    n_updates        | 79631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.6     |
|    ep_rew_mean      | -0.248   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19740    |
|    fps              | 159      |
|    time_elapsed     | 2254     |
|    total_timesteps  | 358777   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000975 |
|    n_updates        | 79694    |
----------------------------------
Eval num_timesteps=359000, episode_reward=-0.26 +/- 0.06
Episode length: 66.12 +/- 13.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.1     |
|    mean_reward      | -0.264   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 359000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 79749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | -0.249   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19744    |
|    fps              | 158      |
|    time_elapsed     | 2258     |
|    total_timesteps  | 359061   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 79765    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | -0.249   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19748    |
|    fps              | 159      |
|    time_elapsed     | 2258     |
|    total_timesteps  | 359323   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000771 |
|    n_updates        | 79830    |
----------------------------------
Eval num_timesteps=359500, episode_reward=-0.25 +/- 0.06
Episode length: 61.62 +/- 14.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.6     |
|    mean_reward      | -0.246   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 359500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00287  |
|    n_updates        | 79874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | -0.247   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19752    |
|    fps              | 158      |
|    time_elapsed     | 2262     |
|    total_timesteps  | 359543   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000748 |
|    n_updates        | 79885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.2     |
|    ep_rew_mean      | -0.246   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19756    |
|    fps              | 158      |
|    time_elapsed     | 2263     |
|    total_timesteps  | 359830   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000433 |
|    n_updates        | 79957    |
----------------------------------
Eval num_timesteps=360000, episode_reward=-0.23 +/- 0.07
Episode length: 56.86 +/- 17.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.9     |
|    mean_reward      | -0.227   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 360000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00277  |
|    n_updates        | 79999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | -0.247   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19760    |
|    fps              | 158      |
|    time_elapsed     | 2267     |
|    total_timesteps  | 360103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000702 |
|    n_updates        | 80025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.6     |
|    ep_rew_mean      | -0.248   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19764    |
|    fps              | 158      |
|    time_elapsed     | 2268     |
|    total_timesteps  | 360403   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000521 |
|    n_updates        | 80100    |
----------------------------------
Eval num_timesteps=360500, episode_reward=-0.26 +/- 0.15
Episode length: 71.20 +/- 10.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.2     |
|    mean_reward      | -0.265   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 360500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 80124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.5     |
|    ep_rew_mean      | -0.247   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19768    |
|    fps              | 158      |
|    time_elapsed     | 2272     |
|    total_timesteps  | 360653   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000518 |
|    n_updates        | 80163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.2     |
|    ep_rew_mean      | -0.25    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19772    |
|    fps              | 158      |
|    time_elapsed     | 2273     |
|    total_timesteps  | 360953   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000778 |
|    n_updates        | 80238    |
----------------------------------
Eval num_timesteps=361000, episode_reward=-0.28 +/- 0.05
Episode length: 69.34 +/- 12.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.3     |
|    mean_reward      | -0.277   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 361000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 80249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | -0.252   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19776    |
|    fps              | 158      |
|    time_elapsed     | 2278     |
|    total_timesteps  | 361242   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000824 |
|    n_updates        | 80310    |
----------------------------------
Eval num_timesteps=361500, episode_reward=-0.28 +/- 0.04
Episode length: 69.62 +/- 9.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.6     |
|    mean_reward      | -0.278   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 361500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000511 |
|    n_updates        | 80374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | -0.255   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19780    |
|    fps              | 158      |
|    time_elapsed     | 2282     |
|    total_timesteps  | 361525   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000411 |
|    n_updates        | 80381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | -0.255   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19784    |
|    fps              | 158      |
|    time_elapsed     | 2283     |
|    total_timesteps  | 361815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000415 |
|    n_updates        | 80453    |
----------------------------------
Eval num_timesteps=362000, episode_reward=-0.20 +/- 0.21
Episode length: 58.96 +/- 18.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59       |
|    mean_reward      | -0.195   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 362000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000398 |
|    n_updates        | 80499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.5     |
|    ep_rew_mean      | -0.266   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19788    |
|    fps              | 158      |
|    time_elapsed     | 2287     |
|    total_timesteps  | 362080   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000348 |
|    n_updates        | 80519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | -0.265   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19792    |
|    fps              | 158      |
|    time_elapsed     | 2287     |
|    total_timesteps  | 362303   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000571 |
|    n_updates        | 80575    |
----------------------------------
Eval num_timesteps=362500, episode_reward=-0.27 +/- 0.15
Episode length: 71.78 +/- 6.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.8     |
|    mean_reward      | -0.267   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 362500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000512 |
|    n_updates        | 80624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | -0.266   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19796    |
|    fps              | 158      |
|    time_elapsed     | 2292     |
|    total_timesteps  | 362591   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 80647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.8     |
|    ep_rew_mean      | -0.267   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19800    |
|    fps              | 158      |
|    time_elapsed     | 2292     |
|    total_timesteps  | 362869   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000251 |
|    n_updates        | 80717    |
----------------------------------
Eval num_timesteps=363000, episode_reward=-0.26 +/- 0.15
Episode length: 69.68 +/- 9.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.7     |
|    mean_reward      | -0.258   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 363000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00323  |
|    n_updates        | 80749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | -0.269   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19804    |
|    fps              | 158      |
|    time_elapsed     | 2297     |
|    total_timesteps  | 363162   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000473 |
|    n_updates        | 80790    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | -0.27    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19808    |
|    fps              | 158      |
|    time_elapsed     | 2298     |
|    total_timesteps  | 363424   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000361 |
|    n_updates        | 80855    |
----------------------------------
Eval num_timesteps=363500, episode_reward=-0.26 +/- 0.15
Episode length: 71.28 +/- 9.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.3     |
|    mean_reward      | -0.265   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 363500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000375 |
|    n_updates        | 80874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | -0.269   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19812    |
|    fps              | 157      |
|    time_elapsed     | 2303     |
|    total_timesteps  | 363699   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000816 |
|    n_updates        | 80924    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | -0.265   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19816    |
|    fps              | 157      |
|    time_elapsed     | 2303     |
|    total_timesteps  | 363895   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000366 |
|    n_updates        | 80973    |
----------------------------------
Eval num_timesteps=364000, episode_reward=-0.25 +/- 0.07
Episode length: 63.12 +/- 16.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.1     |
|    mean_reward      | -0.252   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 364000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000623 |
|    n_updates        | 80999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.8     |
|    ep_rew_mean      | -0.257   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19820    |
|    fps              | 157      |
|    time_elapsed     | 2307     |
|    total_timesteps  | 364166   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000695 |
|    n_updates        | 81041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | -0.255   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19824    |
|    fps              | 157      |
|    time_elapsed     | 2308     |
|    total_timesteps  | 364364   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000334 |
|    n_updates        | 81090    |
----------------------------------
Eval num_timesteps=364500, episode_reward=-0.28 +/- 0.05
Episode length: 70.76 +/- 11.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.8     |
|    mean_reward      | -0.283   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 364500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000583 |
|    n_updates        | 81124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.5     |
|    ep_rew_mean      | -0.256   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19828    |
|    fps              | 157      |
|    time_elapsed     | 2312     |
|    total_timesteps  | 364664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000398 |
|    n_updates        | 81165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | -0.257   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19832    |
|    fps              | 157      |
|    time_elapsed     | 2313     |
|    total_timesteps  | 364963   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000388 |
|    n_updates        | 81240    |
----------------------------------
Eval num_timesteps=365000, episode_reward=-0.28 +/- 0.05
Episode length: 70.66 +/- 12.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.7     |
|    mean_reward      | -0.282   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 365000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000472 |
|    n_updates        | 81249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | -0.259   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19836    |
|    fps              | 157      |
|    time_elapsed     | 2318     |
|    total_timesteps  | 365260   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000659 |
|    n_updates        | 81314    |
----------------------------------
Eval num_timesteps=365500, episode_reward=-0.27 +/- 0.06
Episode length: 68.36 +/- 15.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.4     |
|    mean_reward      | -0.273   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 365500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00032  |
|    n_updates        | 81374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | -0.261   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19840    |
|    fps              | 157      |
|    time_elapsed     | 2322     |
|    total_timesteps  | 365560   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000519 |
|    n_updates        | 81389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68       |
|    ep_rew_mean      | -0.262   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19844    |
|    fps              | 157      |
|    time_elapsed     | 2323     |
|    total_timesteps  | 365860   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00047  |
|    n_updates        | 81464    |
----------------------------------
Eval num_timesteps=366000, episode_reward=-0.28 +/- 0.03
Episode length: 71.22 +/- 8.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.2     |
|    mean_reward      | -0.285   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 366000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00173  |
|    n_updates        | 81499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.3     |
|    ep_rew_mean      | -0.263   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19848    |
|    fps              | 157      |
|    time_elapsed     | 2328     |
|    total_timesteps  | 366152   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000633 |
|    n_updates        | 81537    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.1     |
|    ep_rew_mean      | -0.266   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19852    |
|    fps              | 157      |
|    time_elapsed     | 2328     |
|    total_timesteps  | 366452   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00151  |
|    n_updates        | 81612    |
----------------------------------
Eval num_timesteps=366500, episode_reward=-0.29 +/- 0.04
Episode length: 71.44 +/- 8.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.4     |
|    mean_reward      | -0.286   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 366500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0029   |
|    n_updates        | 81624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.7     |
|    ep_rew_mean      | -0.264   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19856    |
|    fps              | 157      |
|    time_elapsed     | 2333     |
|    total_timesteps  | 366699   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000521 |
|    n_updates        | 81674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69       |
|    ep_rew_mean      | -0.266   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19860    |
|    fps              | 157      |
|    time_elapsed     | 2334     |
|    total_timesteps  | 366999   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00213  |
|    n_updates        | 81749    |
----------------------------------
Eval num_timesteps=367000, episode_reward=-0.29 +/- 0.02
Episode length: 71.96 +/- 5.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 72       |
|    mean_reward     | -0.288   |
| time/              |          |
|    total_timesteps | 367000   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.7     |
|    ep_rew_mean      | -0.265   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19864    |
|    fps              | 157      |
|    time_elapsed     | 2337     |
|    total_timesteps  | 367277   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00174  |
|    n_updates        | 81819    |
----------------------------------
Eval num_timesteps=367500, episode_reward=-0.28 +/- 0.05
Episode length: 70.06 +/- 11.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.1     |
|    mean_reward      | -0.28    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 367500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00038  |
|    n_updates        | 81874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | -0.265   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19868    |
|    fps              | 156      |
|    time_elapsed     | 2341     |
|    total_timesteps  | 367531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000815 |
|    n_updates        | 81882    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68       |
|    ep_rew_mean      | -0.262   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19872    |
|    fps              | 157      |
|    time_elapsed     | 2341     |
|    total_timesteps  | 367754   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000432 |
|    n_updates        | 81938    |
----------------------------------
Eval num_timesteps=368000, episode_reward=-0.29 +/- 0.03
Episode length: 72.52 +/- 8.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.5     |
|    mean_reward      | -0.29    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 368000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000512 |
|    n_updates        | 81999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.1     |
|    ep_rew_mean      | -0.262   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19876    |
|    fps              | 156      |
|    time_elapsed     | 2346     |
|    total_timesteps  | 368054   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000535 |
|    n_updates        | 82013    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | -0.261   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19880    |
|    fps              | 156      |
|    time_elapsed     | 2347     |
|    total_timesteps  | 368305   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000327 |
|    n_updates        | 82076    |
----------------------------------
Eval num_timesteps=368500, episode_reward=-0.26 +/- 0.05
Episode length: 66.18 +/- 13.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.2     |
|    mean_reward      | -0.264   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 368500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 82124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.6     |
|    ep_rew_mean      | -0.26    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19884    |
|    fps              | 156      |
|    time_elapsed     | 2351     |
|    total_timesteps  | 368575   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000888 |
|    n_updates        | 82143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.6     |
|    ep_rew_mean      | -0.26    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19888    |
|    fps              | 156      |
|    time_elapsed     | 2352     |
|    total_timesteps  | 368841   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00109  |
|    n_updates        | 82210    |
----------------------------------
Eval num_timesteps=369000, episode_reward=-0.26 +/- 0.15
Episode length: 70.18 +/- 11.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.2     |
|    mean_reward      | -0.261   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 369000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000945 |
|    n_updates        | 82249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.3     |
|    ep_rew_mean      | -0.263   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19892    |
|    fps              | 156      |
|    time_elapsed     | 2357     |
|    total_timesteps  | 369133   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 82283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.9     |
|    ep_rew_mean      | -0.261   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19896    |
|    fps              | 156      |
|    time_elapsed     | 2357     |
|    total_timesteps  | 369378   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00034  |
|    n_updates        | 82344    |
----------------------------------
Eval num_timesteps=369500, episode_reward=-0.28 +/- 0.04
Episode length: 71.28 +/- 9.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.3     |
|    mean_reward      | -0.285   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 369500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000456 |
|    n_updates        | 82374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.1     |
|    ep_rew_mean      | -0.262   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19900    |
|    fps              | 156      |
|    time_elapsed     | 2363     |
|    total_timesteps  | 369678   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 82419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.1     |
|    ep_rew_mean      | -0.262   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19904    |
|    fps              | 156      |
|    time_elapsed     | 2363     |
|    total_timesteps  | 369973   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000997 |
|    n_updates        | 82493    |
----------------------------------
Eval num_timesteps=370000, episode_reward=-0.26 +/- 0.14
Episode length: 70.16 +/- 9.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.2     |
|    mean_reward      | -0.26    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 370000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000285 |
|    n_updates        | 82499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.9     |
|    ep_rew_mean      | -0.261   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19908    |
|    fps              | 156      |
|    time_elapsed     | 2368     |
|    total_timesteps  | 370218   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00199  |
|    n_updates        | 82554    |
----------------------------------
Eval num_timesteps=370500, episode_reward=-0.29 +/- 0.03
Episode length: 72.08 +/- 6.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.1     |
|    mean_reward      | -0.288   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 370500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 82624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68       |
|    ep_rew_mean      | -0.262   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19912    |
|    fps              | 156      |
|    time_elapsed     | 2373     |
|    total_timesteps  | 370503   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000157 |
|    n_updates        | 82625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69       |
|    ep_rew_mean      | -0.266   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19916    |
|    fps              | 156      |
|    time_elapsed     | 2374     |
|    total_timesteps  | 370793   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000356 |
|    n_updates        | 82698    |
----------------------------------
Eval num_timesteps=371000, episode_reward=-0.28 +/- 0.16
Episode length: 73.96 +/- 4.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.276   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 371000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00182  |
|    n_updates        | 82749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19920    |
|    fps              | 155      |
|    time_elapsed     | 2379     |
|    total_timesteps  | 371084   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 82770    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19924    |
|    fps              | 156      |
|    time_elapsed     | 2379     |
|    total_timesteps  | 371384   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000385 |
|    n_updates        | 82845    |
----------------------------------
Eval num_timesteps=371500, episode_reward=-0.29 +/- 0.03
Episode length: 72.64 +/- 8.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.6     |
|    mean_reward      | -0.29    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 371500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 82874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19928    |
|    fps              | 155      |
|    time_elapsed     | 2384     |
|    total_timesteps  | 371684   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000239 |
|    n_updates        | 82920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19932    |
|    fps              | 155      |
|    time_elapsed     | 2385     |
|    total_timesteps  | 371984   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000828 |
|    n_updates        | 82995    |
----------------------------------
Eval num_timesteps=372000, episode_reward=-0.28 +/- 0.04
Episode length: 71.02 +/- 10.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71       |
|    mean_reward      | -0.284   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 372000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000111 |
|    n_updates        | 82999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19936    |
|    fps              | 155      |
|    time_elapsed     | 2390     |
|    total_timesteps  | 372284   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0018   |
|    n_updates        | 83070    |
----------------------------------
Eval num_timesteps=372500, episode_reward=-0.29 +/- 0.02
Episode length: 73.16 +/- 5.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.2     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 372500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 83124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | -0.28    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19940    |
|    fps              | 155      |
|    time_elapsed     | 2395     |
|    total_timesteps  | 372573   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000396 |
|    n_updates        | 83143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19944    |
|    fps              | 155      |
|    time_elapsed     | 2395     |
|    total_timesteps  | 372841   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 83210    |
----------------------------------
Eval num_timesteps=373000, episode_reward=-0.27 +/- 0.16
Episode length: 73.26 +/- 6.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.3     |
|    mean_reward      | -0.273   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 373000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00016  |
|    n_updates        | 83249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19948    |
|    fps              | 155      |
|    time_elapsed     | 2400     |
|    total_timesteps  | 373132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000391 |
|    n_updates        | 83282    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19952    |
|    fps              | 155      |
|    time_elapsed     | 2401     |
|    total_timesteps  | 373432   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000844 |
|    n_updates        | 83357    |
----------------------------------
Eval num_timesteps=373500, episode_reward=-0.23 +/- 0.15
Episode length: 62.82 +/- 16.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.8     |
|    mean_reward      | -0.231   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 373500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000915 |
|    n_updates        | 83374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.3     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19956    |
|    fps              | 155      |
|    time_elapsed     | 2405     |
|    total_timesteps  | 373732   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00165  |
|    n_updates        | 83432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19960    |
|    fps              | 155      |
|    time_elapsed     | 2406     |
|    total_timesteps  | 373979   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00121  |
|    n_updates        | 83494    |
----------------------------------
Eval num_timesteps=374000, episode_reward=-0.29 +/- 0.03
Episode length: 73.36 +/- 6.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.4     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 374000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000854 |
|    n_updates        | 83499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | -0.28    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19964    |
|    fps              | 155      |
|    time_elapsed     | 2411     |
|    total_timesteps  | 374279   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000307 |
|    n_updates        | 83569    |
----------------------------------
Eval num_timesteps=374500, episode_reward=-0.30 +/- 0.03
Episode length: 74.04 +/- 6.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 374500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00062  |
|    n_updates        | 83624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | -0.282   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19968    |
|    fps              | 154      |
|    time_elapsed     | 2416     |
|    total_timesteps  | 374579   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000533 |
|    n_updates        | 83644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19972    |
|    fps              | 155      |
|    time_elapsed     | 2417     |
|    total_timesteps  | 374872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00248  |
|    n_updates        | 83717    |
----------------------------------
Eval num_timesteps=375000, episode_reward=-0.29 +/- 0.03
Episode length: 72.18 +/- 7.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.2     |
|    mean_reward      | -0.289   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 375000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000196 |
|    n_updates        | 83749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | -0.284   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19976    |
|    fps              | 154      |
|    time_elapsed     | 2422     |
|    total_timesteps  | 375169   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000896 |
|    n_updates        | 83792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.4     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19980    |
|    fps              | 154      |
|    time_elapsed     | 2422     |
|    total_timesteps  | 375442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000356 |
|    n_updates        | 83860    |
----------------------------------
Eval num_timesteps=375500, episode_reward=-0.28 +/- 0.05
Episode length: 68.96 +/- 11.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69       |
|    mean_reward      | -0.276   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 375500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000338 |
|    n_updates        | 83874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | -0.286   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19984    |
|    fps              | 154      |
|    time_elapsed     | 2427     |
|    total_timesteps  | 375729   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000258 |
|    n_updates        | 83932    |
----------------------------------
Eval num_timesteps=376000, episode_reward=-0.29 +/- 0.02
Episode length: 73.24 +/- 5.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.2     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 376000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000244 |
|    n_updates        | 83999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19988    |
|    fps              | 154      |
|    time_elapsed     | 2432     |
|    total_timesteps  | 376029   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00103  |
|    n_updates        | 84007    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | -0.286   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19992    |
|    fps              | 154      |
|    time_elapsed     | 2432     |
|    total_timesteps  | 376278   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000413 |
|    n_updates        | 84069    |
----------------------------------
Eval num_timesteps=376500, episode_reward=-0.30 +/- 0.01
Episode length: 74.26 +/- 2.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.3     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 376500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00017  |
|    n_updates        | 84124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | -0.288   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 19996    |
|    fps              | 154      |
|    time_elapsed     | 2438     |
|    total_timesteps  | 376578   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00057  |
|    n_updates        | 84144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20000    |
|    fps              | 154      |
|    time_elapsed     | 2438     |
|    total_timesteps  | 376873   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000283 |
|    n_updates        | 84218    |
----------------------------------
Eval num_timesteps=377000, episode_reward=-0.29 +/- 0.03
Episode length: 72.52 +/- 7.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.5     |
|    mean_reward      | -0.29    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 377000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 84249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20004    |
|    fps              | 154      |
|    time_elapsed     | 2443     |
|    total_timesteps  | 377173   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000381 |
|    n_updates        | 84293    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20008    |
|    fps              | 154      |
|    time_elapsed     | 2444     |
|    total_timesteps  | 377453   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000725 |
|    n_updates        | 84363    |
----------------------------------
Eval num_timesteps=377500, episode_reward=-0.24 +/- 0.16
Episode length: 65.44 +/- 14.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.4     |
|    mean_reward      | -0.241   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 377500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000359 |
|    n_updates        | 84374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20012    |
|    fps              | 154      |
|    time_elapsed     | 2448     |
|    total_timesteps  | 377738   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000626 |
|    n_updates        | 84434    |
----------------------------------
Eval num_timesteps=378000, episode_reward=-0.27 +/- 0.06
Episode length: 66.66 +/- 14.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.7     |
|    mean_reward      | -0.266   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 378000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000293 |
|    n_updates        | 84499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | -0.28    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20016    |
|    fps              | 154      |
|    time_elapsed     | 2453     |
|    total_timesteps  | 378038   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00264  |
|    n_updates        | 84509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20020    |
|    fps              | 154      |
|    time_elapsed     | 2453     |
|    total_timesteps  | 378313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000651 |
|    n_updates        | 84578    |
----------------------------------
Eval num_timesteps=378500, episode_reward=-0.26 +/- 0.06
Episode length: 64.76 +/- 14.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.8     |
|    mean_reward      | -0.259   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 378500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000967 |
|    n_updates        | 84624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20024    |
|    fps              | 153      |
|    time_elapsed     | 2458     |
|    total_timesteps  | 378598   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000311 |
|    n_updates        | 84649    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20028    |
|    fps              | 154      |
|    time_elapsed     | 2459     |
|    total_timesteps  | 378898   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000304 |
|    n_updates        | 84724    |
----------------------------------
Eval num_timesteps=379000, episode_reward=-0.29 +/- 0.03
Episode length: 73.00 +/- 7.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73       |
|    mean_reward      | -0.292   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 379000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00172  |
|    n_updates        | 84749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20032    |
|    fps              | 153      |
|    time_elapsed     | 2464     |
|    total_timesteps  | 379183   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000547 |
|    n_updates        | 84795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20036    |
|    fps              | 153      |
|    time_elapsed     | 2464     |
|    total_timesteps  | 379483   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000436 |
|    n_updates        | 84870    |
----------------------------------
Eval num_timesteps=379500, episode_reward=-0.29 +/- 0.02
Episode length: 73.50 +/- 5.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.5     |
|    mean_reward      | -0.294   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 379500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000447 |
|    n_updates        | 84874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20040    |
|    fps              | 153      |
|    time_elapsed     | 2469     |
|    total_timesteps  | 379783   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000798 |
|    n_updates        | 84945    |
----------------------------------
Eval num_timesteps=380000, episode_reward=-0.28 +/- 0.04
Episode length: 70.86 +/- 9.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.9     |
|    mean_reward      | -0.283   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 380000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 84999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20044    |
|    fps              | 153      |
|    time_elapsed     | 2474     |
|    total_timesteps  | 380065   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000253 |
|    n_updates        | 85016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20048    |
|    fps              | 153      |
|    time_elapsed     | 2474     |
|    total_timesteps  | 380365   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000391 |
|    n_updates        | 85091    |
----------------------------------
Eval num_timesteps=380500, episode_reward=-0.29 +/- 0.02
Episode length: 73.68 +/- 5.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.7     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 380500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000769 |
|    n_updates        | 85124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20052    |
|    fps              | 153      |
|    time_elapsed     | 2480     |
|    total_timesteps  | 380663   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000737 |
|    n_updates        | 85165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20056    |
|    fps              | 153      |
|    time_elapsed     | 2480     |
|    total_timesteps  | 380963   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000975 |
|    n_updates        | 85240    |
----------------------------------
Eval num_timesteps=381000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 381000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 85249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20060    |
|    fps              | 153      |
|    time_elapsed     | 2486     |
|    total_timesteps  | 381263   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000116 |
|    n_updates        | 85315    |
----------------------------------
Eval num_timesteps=381500, episode_reward=-0.29 +/- 0.03
Episode length: 73.38 +/- 6.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.4     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 381500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00022  |
|    n_updates        | 85374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20064    |
|    fps              | 153      |
|    time_elapsed     | 2491     |
|    total_timesteps  | 381563   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000782 |
|    n_updates        | 85390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20068    |
|    fps              | 153      |
|    time_elapsed     | 2491     |
|    total_timesteps  | 381852   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 85462    |
----------------------------------
Eval num_timesteps=382000, episode_reward=-0.29 +/- 0.02
Episode length: 73.54 +/- 5.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.5     |
|    mean_reward      | -0.294   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 382000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000673 |
|    n_updates        | 85499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20072    |
|    fps              | 153      |
|    time_elapsed     | 2496     |
|    total_timesteps  | 382152   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000179 |
|    n_updates        | 85537    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20076    |
|    fps              | 153      |
|    time_elapsed     | 2497     |
|    total_timesteps  | 382452   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000257 |
|    n_updates        | 85612    |
----------------------------------
Eval num_timesteps=382500, episode_reward=-0.27 +/- 0.06
Episode length: 68.28 +/- 13.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.3     |
|    mean_reward      | -0.273   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 382500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 85624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | -0.282   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20080    |
|    fps              | 152      |
|    time_elapsed     | 2502     |
|    total_timesteps  | 382752   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000124 |
|    n_updates        | 85687    |
----------------------------------
Eval num_timesteps=383000, episode_reward=-0.30 +/- 0.00
Episode length: 74.84 +/- 1.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 383000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00183  |
|    n_updates        | 85749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.283   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20084    |
|    fps              | 152      |
|    time_elapsed     | 2508     |
|    total_timesteps  | 383052   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000891 |
|    n_updates        | 85762    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.283   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20088    |
|    fps              | 152      |
|    time_elapsed     | 2508     |
|    total_timesteps  | 383352   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000144 |
|    n_updates        | 85837    |
----------------------------------
Eval num_timesteps=383500, episode_reward=-0.29 +/- 0.03
Episode length: 73.06 +/- 6.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.1     |
|    mean_reward      | -0.292   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 383500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000268 |
|    n_updates        | 85874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20092    |
|    fps              | 152      |
|    time_elapsed     | 2513     |
|    total_timesteps  | 383645   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 85911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20096    |
|    fps              | 152      |
|    time_elapsed     | 2514     |
|    total_timesteps  | 383945   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 85986    |
----------------------------------
Eval num_timesteps=384000, episode_reward=-0.29 +/- 0.03
Episode length: 73.00 +/- 7.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73       |
|    mean_reward      | -0.292   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 384000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000253 |
|    n_updates        | 85999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20100    |
|    fps              | 152      |
|    time_elapsed     | 2519     |
|    total_timesteps  | 384245   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 86061    |
----------------------------------
Eval num_timesteps=384500, episode_reward=-0.29 +/- 0.02
Episode length: 73.60 +/- 5.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.6     |
|    mean_reward      | -0.294   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 384500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000153 |
|    n_updates        | 86124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20104    |
|    fps              | 152      |
|    time_elapsed     | 2524     |
|    total_timesteps  | 384545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000396 |
|    n_updates        | 86136    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20108    |
|    fps              | 152      |
|    time_elapsed     | 2524     |
|    total_timesteps  | 384836   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000112 |
|    n_updates        | 86208    |
----------------------------------
Eval num_timesteps=385000, episode_reward=-0.26 +/- 0.15
Episode length: 70.82 +/- 9.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.8     |
|    mean_reward      | -0.263   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 385000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 86249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20112    |
|    fps              | 152      |
|    time_elapsed     | 2529     |
|    total_timesteps  | 385136   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00126  |
|    n_updates        | 86283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20116    |
|    fps              | 152      |
|    time_elapsed     | 2530     |
|    total_timesteps  | 385384   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000819 |
|    n_updates        | 86345    |
----------------------------------
Eval num_timesteps=385500, episode_reward=-0.30 +/- 0.02
Episode length: 73.96 +/- 5.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 385500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000258 |
|    n_updates        | 86374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20120    |
|    fps              | 152      |
|    time_elapsed     | 2535     |
|    total_timesteps  | 385684   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000298 |
|    n_updates        | 86420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20124    |
|    fps              | 152      |
|    time_elapsed     | 2535     |
|    total_timesteps  | 385950   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000112 |
|    n_updates        | 86487    |
----------------------------------
Eval num_timesteps=386000, episode_reward=-0.29 +/- 0.04
Episode length: 71.64 +/- 8.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.6     |
|    mean_reward      | -0.286   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 386000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00115  |
|    n_updates        | 86499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20128    |
|    fps              | 152      |
|    time_elapsed     | 2540     |
|    total_timesteps  | 386250   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000343 |
|    n_updates        | 86562    |
----------------------------------
Eval num_timesteps=386500, episode_reward=-0.27 +/- 0.15
Episode length: 71.70 +/- 8.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.7     |
|    mean_reward      | -0.267   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 386500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00157  |
|    n_updates        | 86624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20132    |
|    fps              | 151      |
|    time_elapsed     | 2545     |
|    total_timesteps  | 386544   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00031  |
|    n_updates        | 86635    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20136    |
|    fps              | 151      |
|    time_elapsed     | 2546     |
|    total_timesteps  | 386793   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000112 |
|    n_updates        | 86698    |
----------------------------------
Eval num_timesteps=387000, episode_reward=-0.24 +/- 0.16
Episode length: 65.86 +/- 18.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.9     |
|    mean_reward      | -0.243   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 387000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.93e-05 |
|    n_updates        | 86749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20140    |
|    fps              | 151      |
|    time_elapsed     | 2551     |
|    total_timesteps  | 387084   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00242  |
|    n_updates        | 86770    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20144    |
|    fps              | 151      |
|    time_elapsed     | 2552     |
|    total_timesteps  | 387384   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00039  |
|    n_updates        | 86845    |
----------------------------------
Eval num_timesteps=387500, episode_reward=-0.30 +/- 0.02
Episode length: 74.02 +/- 4.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 387500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000692 |
|    n_updates        | 86874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20148    |
|    fps              | 151      |
|    time_elapsed     | 2557     |
|    total_timesteps  | 387645   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000228 |
|    n_updates        | 86911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20152    |
|    fps              | 151      |
|    time_elapsed     | 2558     |
|    total_timesteps  | 387945   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000813 |
|    n_updates        | 86986    |
----------------------------------
Eval num_timesteps=388000, episode_reward=-0.29 +/- 0.02
Episode length: 73.26 +/- 4.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.3     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 388000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 86999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20156    |
|    fps              | 151      |
|    time_elapsed     | 2563     |
|    total_timesteps  | 388239   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000211 |
|    n_updates        | 87059    |
----------------------------------
Eval num_timesteps=388500, episode_reward=-0.26 +/- 0.06
Episode length: 65.36 +/- 15.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.4     |
|    mean_reward      | -0.261   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 388500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000106 |
|    n_updates        | 87124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20160    |
|    fps              | 151      |
|    time_elapsed     | 2568     |
|    total_timesteps  | 388539   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.76e-05 |
|    n_updates        | 87134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.8     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20164    |
|    fps              | 151      |
|    time_elapsed     | 2569     |
|    total_timesteps  | 388738   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 87184    |
----------------------------------
Eval num_timesteps=389000, episode_reward=-0.29 +/- 0.02
Episode length: 73.40 +/- 5.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.4     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 389000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000363 |
|    n_updates        | 87249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20168    |
|    fps              | 151      |
|    time_elapsed     | 2574     |
|    total_timesteps  | 389038   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000921 |
|    n_updates        | 87259    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71       |
|    ep_rew_mean      | -0.284   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20172    |
|    fps              | 151      |
|    time_elapsed     | 2575     |
|    total_timesteps  | 389249   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00168  |
|    n_updates        | 87312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | -0.28    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20176    |
|    fps              | 151      |
|    time_elapsed     | 2575     |
|    total_timesteps  | 389463   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00038  |
|    n_updates        | 87365    |
----------------------------------
Eval num_timesteps=389500, episode_reward=-0.28 +/- 0.05
Episode length: 70.82 +/- 13.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.8     |
|    mean_reward      | -0.283   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 389500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000231 |
|    n_updates        | 87374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | -0.28    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20180    |
|    fps              | 151      |
|    time_elapsed     | 2580     |
|    total_timesteps  | 389763   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000202 |
|    n_updates        | 87440    |
----------------------------------
Eval num_timesteps=390000, episode_reward=-0.29 +/- 0.03
Episode length: 73.30 +/- 8.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.3     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 390000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 87499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | -0.28    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20184    |
|    fps              | 150      |
|    time_elapsed     | 2586     |
|    total_timesteps  | 390049   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000259 |
|    n_updates        | 87512    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.6     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20188    |
|    fps              | 150      |
|    time_elapsed     | 2586     |
|    total_timesteps  | 390315   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000243 |
|    n_updates        | 87578    |
----------------------------------
Eval num_timesteps=390500, episode_reward=-0.28 +/- 0.05
Episode length: 69.64 +/- 12.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.6     |
|    mean_reward      | -0.278   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 390500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 87624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.7     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20192    |
|    fps              | 150      |
|    time_elapsed     | 2591     |
|    total_timesteps  | 390615   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 87653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20196    |
|    fps              | 150      |
|    time_elapsed     | 2592     |
|    total_timesteps  | 390899   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00134  |
|    n_updates        | 87724    |
----------------------------------
Eval num_timesteps=391000, episode_reward=-0.28 +/- 0.06
Episode length: 69.26 +/- 13.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.3     |
|    mean_reward      | -0.277   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 391000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000691 |
|    n_updates        | 87749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20200    |
|    fps              | 150      |
|    time_elapsed     | 2597     |
|    total_timesteps  | 391199   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 87799    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69       |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20204    |
|    fps              | 150      |
|    time_elapsed     | 2597     |
|    total_timesteps  | 391446   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000126 |
|    n_updates        | 87861    |
----------------------------------
Eval num_timesteps=391500, episode_reward=-0.25 +/- 0.16
Episode length: 66.36 +/- 13.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.4     |
|    mean_reward      | -0.245   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 391500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 87874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.1     |
|    ep_rew_mean      | -0.272   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20208    |
|    fps              | 150      |
|    time_elapsed     | 2602     |
|    total_timesteps  | 391646   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 87911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | -0.26    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20212    |
|    fps              | 150      |
|    time_elapsed     | 2603     |
|    total_timesteps  | 391889   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000126 |
|    n_updates        | 87972    |
----------------------------------
Eval num_timesteps=392000, episode_reward=-0.24 +/- 0.21
Episode length: 71.26 +/- 10.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.3     |
|    mean_reward      | -0.245   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 392000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00131  |
|    n_updates        | 87999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | -0.26    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20216    |
|    fps              | 150      |
|    time_elapsed     | 2607     |
|    total_timesteps  | 392135   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 88033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | -0.259   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20220    |
|    fps              | 150      |
|    time_elapsed     | 2608     |
|    total_timesteps  | 392413   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00187  |
|    n_updates        | 88103    |
----------------------------------
Eval num_timesteps=392500, episode_reward=-0.27 +/- 0.06
Episode length: 67.96 +/- 15.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68       |
|    mean_reward      | -0.272   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 392500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000606 |
|    n_updates        | 88124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | -0.26    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20224    |
|    fps              | 150      |
|    time_elapsed     | 2613     |
|    total_timesteps  | 392702   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000236 |
|    n_updates        | 88175    |
----------------------------------
Eval num_timesteps=393000, episode_reward=-0.23 +/- 0.23
Episode length: 66.48 +/- 15.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.5     |
|    mean_reward      | -0.226   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 393000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000938 |
|    n_updates        | 88249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | -0.26    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20228    |
|    fps              | 150      |
|    time_elapsed     | 2618     |
|    total_timesteps  | 393002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 88250    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | -0.259   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20232    |
|    fps              | 150      |
|    time_elapsed     | 2619     |
|    total_timesteps  | 393287   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 88321    |
----------------------------------
Eval num_timesteps=393500, episode_reward=-0.22 +/- 0.15
Episode length: 60.96 +/- 18.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61       |
|    mean_reward      | -0.223   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 393500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000869 |
|    n_updates        | 88374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | -0.26    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20236    |
|    fps              | 149      |
|    time_elapsed     | 2623     |
|    total_timesteps  | 393540   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 88384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | -0.257   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20240    |
|    fps              | 150      |
|    time_elapsed     | 2624     |
|    total_timesteps  | 393777   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000339 |
|    n_updates        | 88444    |
----------------------------------
Eval num_timesteps=394000, episode_reward=-0.27 +/- 0.06
Episode length: 68.38 +/- 14.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.4     |
|    mean_reward      | -0.273   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 394000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000412 |
|    n_updates        | 88499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.8     |
|    ep_rew_mean      | -0.257   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20244    |
|    fps              | 149      |
|    time_elapsed     | 2629     |
|    total_timesteps  | 394059   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00117  |
|    n_updates        | 88514    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | -0.258   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20248    |
|    fps              | 149      |
|    time_elapsed     | 2629     |
|    total_timesteps  | 394350   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 88587    |
----------------------------------
Eval num_timesteps=394500, episode_reward=-0.26 +/- 0.06
Episode length: 65.04 +/- 15.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65       |
|    mean_reward      | -0.26    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 394500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000137 |
|    n_updates        | 88624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.5     |
|    ep_rew_mean      | -0.246   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20252    |
|    fps              | 149      |
|    time_elapsed     | 2634     |
|    total_timesteps  | 394599   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000409 |
|    n_updates        | 88649    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | -0.245   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20256    |
|    fps              | 149      |
|    time_elapsed     | 2635     |
|    total_timesteps  | 394868   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00014  |
|    n_updates        | 88716    |
----------------------------------
Eval num_timesteps=395000, episode_reward=-0.27 +/- 0.06
Episode length: 68.26 +/- 14.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.3     |
|    mean_reward      | -0.273   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 395000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000158 |
|    n_updates        | 88749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | -0.242   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20260    |
|    fps              | 149      |
|    time_elapsed     | 2639     |
|    total_timesteps  | 395108   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000638 |
|    n_updates        | 88776    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | -0.244   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20264    |
|    fps              | 149      |
|    time_elapsed     | 2640     |
|    total_timesteps  | 395336   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000236 |
|    n_updates        | 88833    |
----------------------------------
Eval num_timesteps=395500, episode_reward=-0.27 +/- 0.07
Episode length: 67.76 +/- 16.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.8     |
|    mean_reward      | -0.271   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 395500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000274 |
|    n_updates        | 88874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | -0.243   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20268    |
|    fps              | 149      |
|    time_elapsed     | 2645     |
|    total_timesteps  | 395620   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0016   |
|    n_updates        | 88904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | -0.245   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20272    |
|    fps              | 149      |
|    time_elapsed     | 2645     |
|    total_timesteps  | 395874   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00086  |
|    n_updates        | 88968    |
----------------------------------
Eval num_timesteps=396000, episode_reward=-0.28 +/- 0.05
Episode length: 70.70 +/- 12.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.7     |
|    mean_reward      | -0.283   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 396000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000734 |
|    n_updates        | 88999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | -0.246   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20276    |
|    fps              | 149      |
|    time_elapsed     | 2651     |
|    total_timesteps  | 396124   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 89030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | -0.244   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20280    |
|    fps              | 149      |
|    time_elapsed     | 2651     |
|    total_timesteps  | 396367   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000384 |
|    n_updates        | 89091    |
----------------------------------
Eval num_timesteps=396500, episode_reward=-0.27 +/- 0.07
Episode length: 67.54 +/- 16.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.5     |
|    mean_reward      | -0.27    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 396500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 89124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | -0.242   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20284    |
|    fps              | 149      |
|    time_elapsed     | 2656     |
|    total_timesteps  | 396608   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00143  |
|    n_updates        | 89151    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | -0.243   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20288    |
|    fps              | 149      |
|    time_elapsed     | 2657     |
|    total_timesteps  | 396894   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000184 |
|    n_updates        | 89223    |
----------------------------------
Eval num_timesteps=397000, episode_reward=-0.25 +/- 0.07
Episode length: 62.82 +/- 17.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.8     |
|    mean_reward      | -0.251   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 397000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000208 |
|    n_updates        | 89249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65       |
|    ep_rew_mean      | -0.24    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20292    |
|    fps              | 149      |
|    time_elapsed     | 2661     |
|    total_timesteps  | 397120   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000171 |
|    n_updates        | 89279    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.1     |
|    ep_rew_mean      | -0.24    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20296    |
|    fps              | 149      |
|    time_elapsed     | 2662     |
|    total_timesteps  | 397407   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 89351    |
----------------------------------
Eval num_timesteps=397500, episode_reward=-0.24 +/- 0.07
Episode length: 60.02 +/- 18.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60       |
|    mean_reward      | -0.24    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 397500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000224 |
|    n_updates        | 89374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.1     |
|    ep_rew_mean      | -0.24    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20300    |
|    fps              | 149      |
|    time_elapsed     | 2667     |
|    total_timesteps  | 397707   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000532 |
|    n_updates        | 89426    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.1     |
|    ep_rew_mean      | -0.24    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20304    |
|    fps              | 149      |
|    time_elapsed     | 2667     |
|    total_timesteps  | 397960   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000579 |
|    n_updates        | 89489    |
----------------------------------
Eval num_timesteps=398000, episode_reward=-0.24 +/- 0.16
Episode length: 66.12 +/- 13.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.1     |
|    mean_reward      | -0.244   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 398000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 89499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | -0.244   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20308    |
|    fps              | 149      |
|    time_elapsed     | 2672     |
|    total_timesteps  | 398252   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000221 |
|    n_updates        | 89562    |
----------------------------------
Eval num_timesteps=398500, episode_reward=-0.25 +/- 0.06
Episode length: 63.18 +/- 14.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.2     |
|    mean_reward      | -0.252   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 398500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000177 |
|    n_updates        | 89624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | -0.256   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20312    |
|    fps              | 148      |
|    time_elapsed     | 2677     |
|    total_timesteps  | 398547   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000198 |
|    n_updates        | 89636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.1     |
|    ep_rew_mean      | -0.258   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20316    |
|    fps              | 148      |
|    time_elapsed     | 2677     |
|    total_timesteps  | 398841   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000839 |
|    n_updates        | 89710    |
----------------------------------
Eval num_timesteps=399000, episode_reward=-0.29 +/- 0.02
Episode length: 73.00 +/- 5.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73       |
|    mean_reward      | -0.292   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 399000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.91e-05 |
|    n_updates        | 89749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.2     |
|    ep_rew_mean      | -0.258   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20320    |
|    fps              | 148      |
|    time_elapsed     | 2683     |
|    total_timesteps  | 399129   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 89782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | -0.254   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20324    |
|    fps              | 148      |
|    time_elapsed     | 2683     |
|    total_timesteps  | 399310   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 89827    |
----------------------------------
Eval num_timesteps=399500, episode_reward=-0.24 +/- 0.16
Episode length: 63.94 +/- 16.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.9     |
|    mean_reward      | -0.235   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 399500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000417 |
|    n_updates        | 89874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.3     |
|    ep_rew_mean      | -0.251   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20328    |
|    fps              | 148      |
|    time_elapsed     | 2687     |
|    total_timesteps  | 399528   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 89881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.4     |
|    ep_rew_mean      | -0.251   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20332    |
|    fps              | 148      |
|    time_elapsed     | 2688     |
|    total_timesteps  | 399825   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000141 |
|    n_updates        | 89956    |
----------------------------------
Eval num_timesteps=400000, episode_reward=-0.20 +/- 0.22
Episode length: 60.58 +/- 17.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60.6     |
|    mean_reward      | -0.202   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 400000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00107  |
|    n_updates        | 89999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | -0.252   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20336    |
|    fps              | 148      |
|    time_elapsed     | 2693     |
|    total_timesteps  | 400088   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000198 |
|    n_updates        | 90021    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | -0.254   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20340    |
|    fps              | 148      |
|    time_elapsed     | 2693     |
|    total_timesteps  | 400388   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000244 |
|    n_updates        | 90096    |
----------------------------------
Eval num_timesteps=400500, episode_reward=-0.27 +/- 0.16
Episode length: 71.84 +/- 10.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.8     |
|    mean_reward      | -0.267   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 400500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000405 |
|    n_updates        | 90124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | -0.254   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20344    |
|    fps              | 148      |
|    time_elapsed     | 2698     |
|    total_timesteps  | 400659   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000196 |
|    n_updates        | 90164    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.9     |
|    ep_rew_mean      | -0.253   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20348    |
|    fps              | 148      |
|    time_elapsed     | 2699     |
|    total_timesteps  | 400940   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00086  |
|    n_updates        | 90234    |
----------------------------------
Eval num_timesteps=401000, episode_reward=-0.29 +/- 0.02
Episode length: 73.66 +/- 4.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.7     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 401000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 90249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | -0.265   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20352    |
|    fps              | 148      |
|    time_elapsed     | 2704     |
|    total_timesteps  | 401231   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00158  |
|    n_updates        | 90307    |
----------------------------------
Eval num_timesteps=401500, episode_reward=-0.29 +/- 0.03
Episode length: 71.36 +/- 8.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.4     |
|    mean_reward      | -0.285   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 401500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000729 |
|    n_updates        | 90374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | -0.265   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20356    |
|    fps              | 148      |
|    time_elapsed     | 2710     |
|    total_timesteps  | 401504   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00189  |
|    n_updates        | 90375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | -0.268   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20360    |
|    fps              | 148      |
|    time_elapsed     | 2710     |
|    total_timesteps  | 401804   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000644 |
|    n_updates        | 90450    |
----------------------------------
Eval num_timesteps=402000, episode_reward=-0.30 +/- 0.02
Episode length: 73.82 +/- 4.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 402000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000179 |
|    n_updates        | 90499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.7     |
|    ep_rew_mean      | -0.27    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20364    |
|    fps              | 148      |
|    time_elapsed     | 2715     |
|    total_timesteps  | 402104   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000182 |
|    n_updates        | 90525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | -0.271   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20368    |
|    fps              | 148      |
|    time_elapsed     | 2716     |
|    total_timesteps  | 402404   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 90600    |
----------------------------------
Eval num_timesteps=402500, episode_reward=-0.28 +/- 0.05
Episode length: 71.22 +/- 12.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.2     |
|    mean_reward      | -0.285   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 402500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00318  |
|    n_updates        | 90624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.2     |
|    ep_rew_mean      | -0.273   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20372    |
|    fps              | 147      |
|    time_elapsed     | 2721     |
|    total_timesteps  | 402695   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.51e-05 |
|    n_updates        | 90673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.2     |
|    ep_rew_mean      | -0.272   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20376    |
|    fps              | 148      |
|    time_elapsed     | 2721     |
|    total_timesteps  | 402942   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000252 |
|    n_updates        | 90735    |
----------------------------------
Eval num_timesteps=403000, episode_reward=-0.22 +/- 0.21
Episode length: 65.68 +/- 15.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.7     |
|    mean_reward      | -0.222   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 403000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000157 |
|    n_updates        | 90749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | -0.275   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20380    |
|    fps              | 147      |
|    time_elapsed     | 2726     |
|    total_timesteps  | 403242   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000918 |
|    n_updates        | 90810    |
----------------------------------
Eval num_timesteps=403500, episode_reward=-0.30 +/- 0.02
Episode length: 73.82 +/- 4.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 403500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00169  |
|    n_updates        | 90874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69       |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20384    |
|    fps              | 147      |
|    time_elapsed     | 2731     |
|    total_timesteps  | 403511   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00215  |
|    n_updates        | 90877    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.9     |
|    ep_rew_mean      | -0.275   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20388    |
|    fps              | 147      |
|    time_elapsed     | 2731     |
|    total_timesteps  | 403788   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000127 |
|    n_updates        | 90946    |
----------------------------------
Eval num_timesteps=404000, episode_reward=-0.30 +/- 0.01
Episode length: 74.82 +/- 1.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 404000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000176 |
|    n_updates        | 90999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20392    |
|    fps              | 147      |
|    time_elapsed     | 2736     |
|    total_timesteps  | 404066   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000917 |
|    n_updates        | 91016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.3     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20396    |
|    fps              | 147      |
|    time_elapsed     | 2737     |
|    total_timesteps  | 404339   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000574 |
|    n_updates        | 91084    |
----------------------------------
Eval num_timesteps=404500, episode_reward=-0.30 +/- 0.01
Episode length: 74.32 +/- 2.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.3     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 404500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000124 |
|    n_updates        | 91124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | -0.275   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20400    |
|    fps              | 147      |
|    time_elapsed     | 2742     |
|    total_timesteps  | 404582   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000107 |
|    n_updates        | 91145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.1     |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20404    |
|    fps              | 147      |
|    time_elapsed     | 2742     |
|    total_timesteps  | 404872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.98e-05 |
|    n_updates        | 91217    |
----------------------------------
Eval num_timesteps=405000, episode_reward=-0.29 +/- 0.02
Episode length: 73.28 +/- 4.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.3     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 405000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 91249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.5     |
|    ep_rew_mean      | -0.264   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20408    |
|    fps              | 147      |
|    time_elapsed     | 2747     |
|    total_timesteps  | 405104   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000232 |
|    n_updates        | 91275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.6     |
|    ep_rew_mean      | -0.264   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20412    |
|    fps              | 147      |
|    time_elapsed     | 2748     |
|    total_timesteps  | 405404   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00191  |
|    n_updates        | 91350    |
----------------------------------
Eval num_timesteps=405500, episode_reward=-0.30 +/- 0.01
Episode length: 74.78 +/- 1.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 405500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000425 |
|    n_updates        | 91374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.6     |
|    ep_rew_mean      | -0.264   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20416    |
|    fps              | 147      |
|    time_elapsed     | 2753     |
|    total_timesteps  | 405698   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000939 |
|    n_updates        | 91424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.6     |
|    ep_rew_mean      | -0.264   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20420    |
|    fps              | 147      |
|    time_elapsed     | 2754     |
|    total_timesteps  | 405985   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000946 |
|    n_updates        | 91496    |
----------------------------------
Eval num_timesteps=406000, episode_reward=-0.30 +/- 0.01
Episode length: 74.64 +/- 1.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 406000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00026  |
|    n_updates        | 91499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | -0.269   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20424    |
|    fps              | 147      |
|    time_elapsed     | 2759     |
|    total_timesteps  | 406285   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000169 |
|    n_updates        | 91571    |
----------------------------------
Eval num_timesteps=406500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 406500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000344 |
|    n_updates        | 91624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.6     |
|    ep_rew_mean      | -0.272   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20428    |
|    fps              | 147      |
|    time_elapsed     | 2764     |
|    total_timesteps  | 406585   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000219 |
|    n_updates        | 91646    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.6     |
|    ep_rew_mean      | -0.272   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20432    |
|    fps              | 147      |
|    time_elapsed     | 2765     |
|    total_timesteps  | 406885   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000138 |
|    n_updates        | 91721    |
----------------------------------
Eval num_timesteps=407000, episode_reward=-0.29 +/- 0.03
Episode length: 73.56 +/- 7.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.6     |
|    mean_reward      | -0.294   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 407000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00192  |
|    n_updates        | 91749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | -0.273   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20436    |
|    fps              | 146      |
|    time_elapsed     | 2770     |
|    total_timesteps  | 407168   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00182  |
|    n_updates        | 91791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | -0.273   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20440    |
|    fps              | 147      |
|    time_elapsed     | 2770     |
|    total_timesteps  | 407468   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000172 |
|    n_updates        | 91866    |
----------------------------------
Eval num_timesteps=407500, episode_reward=-0.26 +/- 0.08
Episode length: 64.98 +/- 18.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65       |
|    mean_reward      | -0.26    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 407500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000155 |
|    n_updates        | 91874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | -0.274   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20444    |
|    fps              | 146      |
|    time_elapsed     | 2775     |
|    total_timesteps  | 407768   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000145 |
|    n_updates        | 91941    |
----------------------------------
Eval num_timesteps=408000, episode_reward=-0.30 +/- 0.00
Episode length: 74.84 +/- 1.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 408000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000185 |
|    n_updates        | 91999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.3     |
|    ep_rew_mean      | -0.275   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20448    |
|    fps              | 146      |
|    time_elapsed     | 2780     |
|    total_timesteps  | 408068   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000151 |
|    n_updates        | 92016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.4     |
|    ep_rew_mean      | -0.275   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20452    |
|    fps              | 146      |
|    time_elapsed     | 2781     |
|    total_timesteps  | 408368   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000185 |
|    n_updates        | 92091    |
----------------------------------
Eval num_timesteps=408500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 408500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000164 |
|    n_updates        | 92124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20456    |
|    fps              | 146      |
|    time_elapsed     | 2786     |
|    total_timesteps  | 408668   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000934 |
|    n_updates        | 92166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | -0.274   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20460    |
|    fps              | 146      |
|    time_elapsed     | 2786     |
|    total_timesteps  | 408912   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00214  |
|    n_updates        | 92227    |
----------------------------------
Eval num_timesteps=409000, episode_reward=-0.30 +/- 0.01
Episode length: 74.48 +/- 3.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 409000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00093  |
|    n_updates        | 92249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | -0.274   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20464    |
|    fps              | 146      |
|    time_elapsed     | 2792     |
|    total_timesteps  | 409212   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000466 |
|    n_updates        | 92302    |
----------------------------------
Eval num_timesteps=409500, episode_reward=-0.30 +/- 0.01
Episode length: 74.56 +/- 3.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 409500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000158 |
|    n_updates        | 92374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | -0.274   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20468    |
|    fps              | 146      |
|    time_elapsed     | 2797     |
|    total_timesteps  | 409512   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000153 |
|    n_updates        | 92377    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | -0.275   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20472    |
|    fps              | 146      |
|    time_elapsed     | 2798     |
|    total_timesteps  | 409812   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000183 |
|    n_updates        | 92452    |
----------------------------------
Eval num_timesteps=410000, episode_reward=-0.30 +/- 0.01
Episode length: 74.74 +/- 1.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 410000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000242 |
|    n_updates        | 92499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.7     |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20476    |
|    fps              | 146      |
|    time_elapsed     | 2803     |
|    total_timesteps  | 410107   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000231 |
|    n_updates        | 92526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.7     |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20480    |
|    fps              | 146      |
|    time_elapsed     | 2804     |
|    total_timesteps  | 410407   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00071  |
|    n_updates        | 92601    |
----------------------------------
Eval num_timesteps=410500, episode_reward=-0.28 +/- 0.15
Episode length: 74.06 +/- 4.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.1     |
|    mean_reward      | -0.276   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 410500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000142 |
|    n_updates        | 92624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.7     |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20484    |
|    fps              | 146      |
|    time_elapsed     | 2809     |
|    total_timesteps  | 410676   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000197 |
|    n_updates        | 92668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20488    |
|    fps              | 146      |
|    time_elapsed     | 2809     |
|    total_timesteps  | 410976   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000175 |
|    n_updates        | 92743    |
----------------------------------
Eval num_timesteps=411000, episode_reward=-0.30 +/- 0.01
Episode length: 74.36 +/- 3.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.4     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 411000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 92749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20492    |
|    fps              | 146      |
|    time_elapsed     | 2814     |
|    total_timesteps  | 411276   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.4e-05  |
|    n_updates        | 92818    |
----------------------------------
Eval num_timesteps=411500, episode_reward=-0.29 +/- 0.02
Episode length: 73.48 +/- 4.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.5     |
|    mean_reward      | -0.294   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 411500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000183 |
|    n_updates        | 92874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20496    |
|    fps              | 145      |
|    time_elapsed     | 2819     |
|    total_timesteps  | 411569   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000104 |
|    n_updates        | 92892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | -0.281   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20500    |
|    fps              | 146      |
|    time_elapsed     | 2820     |
|    total_timesteps  | 411869   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.52e-05 |
|    n_updates        | 92967    |
----------------------------------
Eval num_timesteps=412000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 412000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.76e-05 |
|    n_updates        | 92999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | -0.282   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20504    |
|    fps              | 145      |
|    time_elapsed     | 2825     |
|    total_timesteps  | 412169   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000873 |
|    n_updates        | 93042    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20508    |
|    fps              | 145      |
|    time_elapsed     | 2826     |
|    total_timesteps  | 412469   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00208  |
|    n_updates        | 93117    |
----------------------------------
Eval num_timesteps=412500, episode_reward=-0.30 +/- 0.00
Episode length: 74.96 +/- 0.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 412500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000275 |
|    n_updates        | 93124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20512    |
|    fps              | 145      |
|    time_elapsed     | 2831     |
|    total_timesteps  | 412732   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00083  |
|    n_updates        | 93182    |
----------------------------------
Eval num_timesteps=413000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 413000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000806 |
|    n_updates        | 93249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20516    |
|    fps              | 145      |
|    time_elapsed     | 2836     |
|    total_timesteps  | 413032   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000217 |
|    n_updates        | 93257    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20520    |
|    fps              | 145      |
|    time_elapsed     | 2837     |
|    total_timesteps  | 413332   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00123  |
|    n_updates        | 93332    |
----------------------------------
Eval num_timesteps=413500, episode_reward=-0.23 +/- 0.09
Episode length: 58.58 +/- 21.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.6     |
|    mean_reward      | -0.234   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 413500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000111 |
|    n_updates        | 93374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20524    |
|    fps              | 145      |
|    time_elapsed     | 2841     |
|    total_timesteps  | 413546   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00049  |
|    n_updates        | 93386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20528    |
|    fps              | 145      |
|    time_elapsed     | 2842     |
|    total_timesteps  | 413831   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000926 |
|    n_updates        | 93457    |
----------------------------------
Eval num_timesteps=414000, episode_reward=-0.30 +/- 0.00
Episode length: 74.86 +/- 0.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 414000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0001   |
|    n_updates        | 93499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20532    |
|    fps              | 145      |
|    time_elapsed     | 2847     |
|    total_timesteps  | 414131   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00163  |
|    n_updates        | 93532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20536    |
|    fps              | 145      |
|    time_elapsed     | 2847     |
|    total_timesteps  | 414431   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00125  |
|    n_updates        | 93607    |
----------------------------------
Eval num_timesteps=414500, episode_reward=-0.30 +/- 0.01
Episode length: 74.56 +/- 3.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 414500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00128  |
|    n_updates        | 93624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20540    |
|    fps              | 145      |
|    time_elapsed     | 2852     |
|    total_timesteps  | 414731   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000113 |
|    n_updates        | 93682    |
----------------------------------
Eval num_timesteps=415000, episode_reward=-0.30 +/- 0.01
Episode length: 74.46 +/- 2.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 415000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.07e-05 |
|    n_updates        | 93749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20544    |
|    fps              | 145      |
|    time_elapsed     | 2857     |
|    total_timesteps  | 415031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000789 |
|    n_updates        | 93757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20548    |
|    fps              | 145      |
|    time_elapsed     | 2858     |
|    total_timesteps  | 415331   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000813 |
|    n_updates        | 93832    |
----------------------------------
Eval num_timesteps=415500, episode_reward=-0.29 +/- 0.06
Episode length: 71.34 +/- 13.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.3     |
|    mean_reward      | -0.285   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 415500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000802 |
|    n_updates        | 93874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20552    |
|    fps              | 145      |
|    time_elapsed     | 2863     |
|    total_timesteps  | 415631   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000896 |
|    n_updates        | 93907    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20556    |
|    fps              | 145      |
|    time_elapsed     | 2864     |
|    total_timesteps  | 415931   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000181 |
|    n_updates        | 93982    |
----------------------------------
Eval num_timesteps=416000, episode_reward=-0.30 +/- 0.02
Episode length: 74.28 +/- 3.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.3     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 416000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000983 |
|    n_updates        | 93999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20560    |
|    fps              | 145      |
|    time_elapsed     | 2869     |
|    total_timesteps  | 416231   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000605 |
|    n_updates        | 94057    |
----------------------------------
Eval num_timesteps=416500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 416500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000165 |
|    n_updates        | 94124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20564    |
|    fps              | 144      |
|    time_elapsed     | 2873     |
|    total_timesteps  | 416531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000108 |
|    n_updates        | 94132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20568    |
|    fps              | 145      |
|    time_elapsed     | 2874     |
|    total_timesteps  | 416831   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000211 |
|    n_updates        | 94207    |
----------------------------------
Eval num_timesteps=417000, episode_reward=-0.27 +/- 0.18
Episode length: 71.54 +/- 13.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.5     |
|    mean_reward      | -0.266   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 417000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000206 |
|    n_updates        | 94249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20572    |
|    fps              | 144      |
|    time_elapsed     | 2879     |
|    total_timesteps  | 417131   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 94282    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20576    |
|    fps              | 144      |
|    time_elapsed     | 2879     |
|    total_timesteps  | 417431   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.99e-05 |
|    n_updates        | 94357    |
----------------------------------
Eval num_timesteps=417500, episode_reward=-0.29 +/- 0.03
Episode length: 73.74 +/- 8.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.7     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 417500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.83e-05 |
|    n_updates        | 94374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20580    |
|    fps              | 144      |
|    time_elapsed     | 2885     |
|    total_timesteps  | 417686   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000778 |
|    n_updates        | 94421    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20584    |
|    fps              | 144      |
|    time_elapsed     | 2885     |
|    total_timesteps  | 417986   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000439 |
|    n_updates        | 94496    |
----------------------------------
Eval num_timesteps=418000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 418000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 94499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20588    |
|    fps              | 144      |
|    time_elapsed     | 2890     |
|    total_timesteps  | 418286   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000208 |
|    n_updates        | 94571    |
----------------------------------
Eval num_timesteps=418500, episode_reward=-0.30 +/- 0.03
Episode length: 73.94 +/- 7.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 418500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000136 |
|    n_updates        | 94624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20592    |
|    fps              | 144      |
|    time_elapsed     | 2896     |
|    total_timesteps  | 418586   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000153 |
|    n_updates        | 94646    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20596    |
|    fps              | 144      |
|    time_elapsed     | 2896     |
|    total_timesteps  | 418886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000111 |
|    n_updates        | 94721    |
----------------------------------
Eval num_timesteps=419000, episode_reward=-0.29 +/- 0.03
Episode length: 73.76 +/- 8.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 419000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.31e-05 |
|    n_updates        | 94749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20600    |
|    fps              | 144      |
|    time_elapsed     | 2901     |
|    total_timesteps  | 419186   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000767 |
|    n_updates        | 94796    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20604    |
|    fps              | 144      |
|    time_elapsed     | 2902     |
|    total_timesteps  | 419429   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.19e-05 |
|    n_updates        | 94857    |
----------------------------------
Eval num_timesteps=419500, episode_reward=-0.30 +/- 0.03
Episode length: 73.90 +/- 7.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 419500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 94874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | -0.29    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20608    |
|    fps              | 144      |
|    time_elapsed     | 2907     |
|    total_timesteps  | 419729   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.43e-05 |
|    n_updates        | 94932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20612    |
|    fps              | 144      |
|    time_elapsed     | 2908     |
|    total_timesteps  | 419961   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000205 |
|    n_updates        | 94990    |
----------------------------------
Eval num_timesteps=420000, episode_reward=-0.28 +/- 0.15
Episode length: 74.10 +/- 3.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.1     |
|    mean_reward      | -0.276   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 420000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000924 |
|    n_updates        | 94999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20616    |
|    fps              | 144      |
|    time_elapsed     | 2913     |
|    total_timesteps  | 420261   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000815 |
|    n_updates        | 95065    |
----------------------------------
Eval num_timesteps=420500, episode_reward=-0.26 +/- 0.15
Episode length: 71.12 +/- 11.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.1     |
|    mean_reward      | -0.264   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 420500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000388 |
|    n_updates        | 95124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20620    |
|    fps              | 144      |
|    time_elapsed     | 2918     |
|    total_timesteps  | 420561   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000359 |
|    n_updates        | 95140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20624    |
|    fps              | 144      |
|    time_elapsed     | 2919     |
|    total_timesteps  | 420861   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.02e-05 |
|    n_updates        | 95215    |
----------------------------------
Eval num_timesteps=421000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 421000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000742 |
|    n_updates        | 95249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20628    |
|    fps              | 144      |
|    time_elapsed     | 2924     |
|    total_timesteps  | 421161   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.66e-05 |
|    n_updates        | 95290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20632    |
|    fps              | 144      |
|    time_elapsed     | 2925     |
|    total_timesteps  | 421461   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000767 |
|    n_updates        | 95365    |
----------------------------------
Eval num_timesteps=421500, episode_reward=-0.30 +/- 0.02
Episode length: 74.12 +/- 5.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.1     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 421500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0014   |
|    n_updates        | 95374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20636    |
|    fps              | 143      |
|    time_elapsed     | 2930     |
|    total_timesteps  | 421724   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000142 |
|    n_updates        | 95430    |
----------------------------------
Eval num_timesteps=422000, episode_reward=-0.29 +/- 0.03
Episode length: 72.90 +/- 8.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.9     |
|    mean_reward      | -0.292   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 422000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.04e-05 |
|    n_updates        | 95499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20640    |
|    fps              | 143      |
|    time_elapsed     | 2935     |
|    total_timesteps  | 422024   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.58e-05 |
|    n_updates        | 95505    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20644    |
|    fps              | 143      |
|    time_elapsed     | 2935     |
|    total_timesteps  | 422324   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 95580    |
----------------------------------
Eval num_timesteps=422500, episode_reward=-0.30 +/- 0.01
Episode length: 74.56 +/- 3.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 422500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00048  |
|    n_updates        | 95624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20648    |
|    fps              | 143      |
|    time_elapsed     | 2940     |
|    total_timesteps  | 422624   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000749 |
|    n_updates        | 95655    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20652    |
|    fps              | 143      |
|    time_elapsed     | 2941     |
|    total_timesteps  | 422924   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00011  |
|    n_updates        | 95730    |
----------------------------------
Eval num_timesteps=423000, episode_reward=-0.30 +/- 0.01
Episode length: 74.74 +/- 1.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 423000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000372 |
|    n_updates        | 95749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20656    |
|    fps              | 143      |
|    time_elapsed     | 2946     |
|    total_timesteps  | 423224   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00074  |
|    n_updates        | 95805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20660    |
|    fps              | 143      |
|    time_elapsed     | 2947     |
|    total_timesteps  | 423457   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.09e-05 |
|    n_updates        | 95864    |
----------------------------------
Eval num_timesteps=423500, episode_reward=-0.30 +/- 0.01
Episode length: 74.56 +/- 2.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 423500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0013   |
|    n_updates        | 95874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20664    |
|    fps              | 143      |
|    time_elapsed     | 2952     |
|    total_timesteps  | 423757   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.46e-05 |
|    n_updates        | 95939    |
----------------------------------
Eval num_timesteps=424000, episode_reward=-0.29 +/- 0.04
Episode length: 72.88 +/- 8.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.9     |
|    mean_reward      | -0.291   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 424000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 95999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20668    |
|    fps              | 143      |
|    time_elapsed     | 2957     |
|    total_timesteps  | 424057   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000743 |
|    n_updates        | 96014    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.8     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20672    |
|    fps              | 143      |
|    time_elapsed     | 2958     |
|    total_timesteps  | 424315   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000742 |
|    n_updates        | 96078    |
----------------------------------
Eval num_timesteps=424500, episode_reward=-0.30 +/- 0.03
Episode length: 73.96 +/- 7.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 424500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.47e-05 |
|    n_updates        | 96124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.8     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20676    |
|    fps              | 143      |
|    time_elapsed     | 2963     |
|    total_timesteps  | 424615   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.39e-05 |
|    n_updates        | 96153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20680    |
|    fps              | 143      |
|    time_elapsed     | 2964     |
|    total_timesteps  | 424915   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000614 |
|    n_updates        | 96228    |
----------------------------------
Eval num_timesteps=425000, episode_reward=-0.30 +/- 0.03
Episode length: 73.86 +/- 6.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 425000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000134 |
|    n_updates        | 96249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20684    |
|    fps              | 143      |
|    time_elapsed     | 2969     |
|    total_timesteps  | 425215   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00104  |
|    n_updates        | 96303    |
----------------------------------
Eval num_timesteps=425500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 425500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.81e-05 |
|    n_updates        | 96374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20688    |
|    fps              | 143      |
|    time_elapsed     | 2975     |
|    total_timesteps  | 425515   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000737 |
|    n_updates        | 96378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20692    |
|    fps              | 143      |
|    time_elapsed     | 2975     |
|    total_timesteps  | 425815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000125 |
|    n_updates        | 96453    |
----------------------------------
Eval num_timesteps=426000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 426000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000645 |
|    n_updates        | 96499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20696    |
|    fps              | 142      |
|    time_elapsed     | 2981     |
|    total_timesteps  | 426115   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000115 |
|    n_updates        | 96528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | -0.289   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20700    |
|    fps              | 143      |
|    time_elapsed     | 2981     |
|    total_timesteps  | 426415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.04e-05 |
|    n_updates        | 96603    |
----------------------------------
Eval num_timesteps=426500, episode_reward=-0.30 +/- 0.03
Episode length: 73.92 +/- 7.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 426500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000743 |
|    n_updates        | 96624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20704    |
|    fps              | 142      |
|    time_elapsed     | 2986     |
|    total_timesteps  | 426715   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000152 |
|    n_updates        | 96678    |
----------------------------------
Eval num_timesteps=427000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 427000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0011   |
|    n_updates        | 96749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20708    |
|    fps              | 142      |
|    time_elapsed     | 2992     |
|    total_timesteps  | 427015   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000392 |
|    n_updates        | 96753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20712    |
|    fps              | 142      |
|    time_elapsed     | 2992     |
|    total_timesteps  | 427315   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.71e-05 |
|    n_updates        | 96828    |
----------------------------------
Eval num_timesteps=427500, episode_reward=-0.30 +/- 0.01
Episode length: 74.36 +/- 2.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.4     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 427500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00069  |
|    n_updates        | 96874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20716    |
|    fps              | 142      |
|    time_elapsed     | 2997     |
|    total_timesteps  | 427615   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000481 |
|    n_updates        | 96903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20720    |
|    fps              | 142      |
|    time_elapsed     | 2998     |
|    total_timesteps  | 427915   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000542 |
|    n_updates        | 96978    |
----------------------------------
Eval num_timesteps=428000, episode_reward=-0.30 +/- 0.01
Episode length: 74.76 +/- 1.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 428000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000414 |
|    n_updates        | 96999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20724    |
|    fps              | 142      |
|    time_elapsed     | 3003     |
|    total_timesteps  | 428215   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000622 |
|    n_updates        | 97053    |
----------------------------------
Eval num_timesteps=428500, episode_reward=-0.28 +/- 0.15
Episode length: 74.44 +/- 2.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.4     |
|    mean_reward      | -0.278   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 428500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.31e-05 |
|    n_updates        | 97124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20728    |
|    fps              | 142      |
|    time_elapsed     | 3008     |
|    total_timesteps  | 428515   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000722 |
|    n_updates        | 97128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20732    |
|    fps              | 142      |
|    time_elapsed     | 3009     |
|    total_timesteps  | 428815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.71e-05 |
|    n_updates        | 97203    |
----------------------------------
Eval num_timesteps=429000, episode_reward=-0.30 +/- 0.00
Episode length: 74.98 +/- 0.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 429000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.94e-05 |
|    n_updates        | 97249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20736    |
|    fps              | 142      |
|    time_elapsed     | 3014     |
|    total_timesteps  | 429115   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000153 |
|    n_updates        | 97278    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20740    |
|    fps              | 142      |
|    time_elapsed     | 3015     |
|    total_timesteps  | 429415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00011  |
|    n_updates        | 97353    |
----------------------------------
Eval num_timesteps=429500, episode_reward=-0.30 +/- 0.01
Episode length: 74.42 +/- 2.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.4     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 429500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.12e-05 |
|    n_updates        | 97374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20744    |
|    fps              | 142      |
|    time_elapsed     | 3020     |
|    total_timesteps  | 429715   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000584 |
|    n_updates        | 97428    |
----------------------------------
Eval num_timesteps=430000, episode_reward=-0.30 +/- 0.01
Episode length: 74.54 +/- 3.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 430000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00139  |
|    n_updates        | 97499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20748    |
|    fps              | 142      |
|    time_elapsed     | 3025     |
|    total_timesteps  | 430015   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000555 |
|    n_updates        | 97503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20752    |
|    fps              | 142      |
|    time_elapsed     | 3025     |
|    total_timesteps  | 430271   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000468 |
|    n_updates        | 97567    |
----------------------------------
Eval num_timesteps=430500, episode_reward=-0.30 +/- 0.01
Episode length: 74.48 +/- 3.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 430500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.65e-05 |
|    n_updates        | 97624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20756    |
|    fps              | 142      |
|    time_elapsed     | 3031     |
|    total_timesteps  | 430571   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00118  |
|    n_updates        | 97642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20760    |
|    fps              | 142      |
|    time_elapsed     | 3031     |
|    total_timesteps  | 430871   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 97717    |
----------------------------------
Eval num_timesteps=431000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 431000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 97749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20764    |
|    fps              | 141      |
|    time_elapsed     | 3036     |
|    total_timesteps  | 431171   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000704 |
|    n_updates        | 97792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20768    |
|    fps              | 142      |
|    time_elapsed     | 3037     |
|    total_timesteps  | 431471   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.2e-05  |
|    n_updates        | 97867    |
----------------------------------
Eval num_timesteps=431500, episode_reward=-0.30 +/- 0.00
Episode length: 74.98 +/- 0.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 431500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000709 |
|    n_updates        | 97874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20772    |
|    fps              | 141      |
|    time_elapsed     | 3042     |
|    total_timesteps  | 431771   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 97942    |
----------------------------------
Eval num_timesteps=432000, episode_reward=-0.30 +/- 0.01
Episode length: 74.64 +/- 2.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 432000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.84e-05 |
|    n_updates        | 97999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20776    |
|    fps              | 141      |
|    time_elapsed     | 3047     |
|    total_timesteps  | 432071   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000675 |
|    n_updates        | 98017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20780    |
|    fps              | 141      |
|    time_elapsed     | 3048     |
|    total_timesteps  | 432371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000518 |
|    n_updates        | 98092    |
----------------------------------
Eval num_timesteps=432500, episode_reward=-0.29 +/- 0.03
Episode length: 71.68 +/- 8.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.7     |
|    mean_reward      | -0.287   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 432500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000167 |
|    n_updates        | 98124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20784    |
|    fps              | 141      |
|    time_elapsed     | 3053     |
|    total_timesteps  | 432671   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.33e-05 |
|    n_updates        | 98167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20788    |
|    fps              | 141      |
|    time_elapsed     | 3054     |
|    total_timesteps  | 432971   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00184  |
|    n_updates        | 98242    |
----------------------------------
Eval num_timesteps=433000, episode_reward=-0.30 +/- 0.00
Episode length: 74.84 +/- 0.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 433000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000752 |
|    n_updates        | 98249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20792    |
|    fps              | 141      |
|    time_elapsed     | 3059     |
|    total_timesteps  | 433231   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000689 |
|    n_updates        | 98307    |
----------------------------------
Eval num_timesteps=433500, episode_reward=-0.29 +/- 0.04
Episode length: 72.46 +/- 9.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.5     |
|    mean_reward      | -0.29    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 433500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00152  |
|    n_updates        | 98374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20796    |
|    fps              | 141      |
|    time_elapsed     | 3064     |
|    total_timesteps  | 433513   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000555 |
|    n_updates        | 98378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20800    |
|    fps              | 141      |
|    time_elapsed     | 3064     |
|    total_timesteps  | 433813   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 98453    |
----------------------------------
Eval num_timesteps=434000, episode_reward=-0.30 +/- 0.01
Episode length: 74.56 +/- 3.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 434000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000647 |
|    n_updates        | 98499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20804    |
|    fps              | 141      |
|    time_elapsed     | 3070     |
|    total_timesteps  | 434113   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00132  |
|    n_updates        | 98528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20808    |
|    fps              | 141      |
|    time_elapsed     | 3070     |
|    total_timesteps  | 434413   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 98603    |
----------------------------------
Eval num_timesteps=434500, episode_reward=-0.30 +/- 0.01
Episode length: 74.52 +/- 2.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 434500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00011  |
|    n_updates        | 98624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20812    |
|    fps              | 141      |
|    time_elapsed     | 3076     |
|    total_timesteps  | 434713   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.39e-05 |
|    n_updates        | 98678    |
----------------------------------
Eval num_timesteps=435000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 435000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.59e-05 |
|    n_updates        | 98749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20816    |
|    fps              | 141      |
|    time_elapsed     | 3081     |
|    total_timesteps  | 435013   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000953 |
|    n_updates        | 98753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20820    |
|    fps              | 141      |
|    time_elapsed     | 3082     |
|    total_timesteps  | 435313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00255  |
|    n_updates        | 98828    |
----------------------------------
Eval num_timesteps=435500, episode_reward=-0.30 +/- 0.01
Episode length: 74.58 +/- 2.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 435500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.26e-05 |
|    n_updates        | 98874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20824    |
|    fps              | 141      |
|    time_elapsed     | 3087     |
|    total_timesteps  | 435613   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00074  |
|    n_updates        | 98903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20828    |
|    fps              | 141      |
|    time_elapsed     | 3088     |
|    total_timesteps  | 435913   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000115 |
|    n_updates        | 98978    |
----------------------------------
Eval num_timesteps=436000, episode_reward=-0.30 +/- 0.01
Episode length: 74.74 +/- 1.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 436000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000292 |
|    n_updates        | 98999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20832    |
|    fps              | 141      |
|    time_elapsed     | 3093     |
|    total_timesteps  | 436213   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000905 |
|    n_updates        | 99053    |
----------------------------------
Eval num_timesteps=436500, episode_reward=-0.29 +/- 0.03
Episode length: 73.16 +/- 6.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.2     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 436500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000392 |
|    n_updates        | 99124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20836    |
|    fps              | 140      |
|    time_elapsed     | 3098     |
|    total_timesteps  | 436513   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00021  |
|    n_updates        | 99128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20840    |
|    fps              | 140      |
|    time_elapsed     | 3099     |
|    total_timesteps  | 436795   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000152 |
|    n_updates        | 99198    |
----------------------------------
Eval num_timesteps=437000, episode_reward=-0.30 +/- 0.01
Episode length: 74.56 +/- 2.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 437000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000637 |
|    n_updates        | 99249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20844    |
|    fps              | 140      |
|    time_elapsed     | 3104     |
|    total_timesteps  | 437049   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000985 |
|    n_updates        | 99262    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20848    |
|    fps              | 140      |
|    time_elapsed     | 3105     |
|    total_timesteps  | 437349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000273 |
|    n_updates        | 99337    |
----------------------------------
Eval num_timesteps=437500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 437500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000524 |
|    n_updates        | 99374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20852    |
|    fps              | 140      |
|    time_elapsed     | 3110     |
|    total_timesteps  | 437649   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000786 |
|    n_updates        | 99412    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20856    |
|    fps              | 140      |
|    time_elapsed     | 3110     |
|    total_timesteps  | 437914   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000112 |
|    n_updates        | 99478    |
----------------------------------
Eval num_timesteps=438000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 438000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.65e-05 |
|    n_updates        | 99499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20860    |
|    fps              | 140      |
|    time_elapsed     | 3115     |
|    total_timesteps  | 438214   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.66e-05 |
|    n_updates        | 99553    |
----------------------------------
Eval num_timesteps=438500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 438500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000936 |
|    n_updates        | 99624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20864    |
|    fps              | 140      |
|    time_elapsed     | 3120     |
|    total_timesteps  | 438514   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.06e-05 |
|    n_updates        | 99628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20868    |
|    fps              | 140      |
|    time_elapsed     | 3120     |
|    total_timesteps  | 438739   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000722 |
|    n_updates        | 99684    |
----------------------------------
Eval num_timesteps=439000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 439000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000109 |
|    n_updates        | 99749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20872    |
|    fps              | 140      |
|    time_elapsed     | 3125     |
|    total_timesteps  | 439039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000102 |
|    n_updates        | 99759    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20876    |
|    fps              | 140      |
|    time_elapsed     | 3126     |
|    total_timesteps  | 439339   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000717 |
|    n_updates        | 99834    |
----------------------------------
Eval num_timesteps=439500, episode_reward=-0.30 +/- 0.00
Episode length: 74.90 +/- 0.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 439500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000141 |
|    n_updates        | 99874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20880    |
|    fps              | 140      |
|    time_elapsed     | 3130     |
|    total_timesteps  | 439639   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000991 |
|    n_updates        | 99909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20884    |
|    fps              | 140      |
|    time_elapsed     | 3131     |
|    total_timesteps  | 439939   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000111 |
|    n_updates        | 99984    |
----------------------------------
Eval num_timesteps=440000, episode_reward=-0.29 +/- 0.03
Episode length: 73.64 +/- 6.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.6     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 440000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000814 |
|    n_updates        | 99999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | -0.291   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20888    |
|    fps              | 140      |
|    time_elapsed     | 3136     |
|    total_timesteps  | 440239   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000424 |
|    n_updates        | 100059   |
----------------------------------
Eval num_timesteps=440500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 440500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000177 |
|    n_updates        | 100124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | -0.292   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20892    |
|    fps              | 140      |
|    time_elapsed     | 3141     |
|    total_timesteps  | 440539   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000665 |
|    n_updates        | 100134   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20896    |
|    fps              | 140      |
|    time_elapsed     | 3142     |
|    total_timesteps  | 440839   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.65e-05 |
|    n_updates        | 100209   |
----------------------------------
Eval num_timesteps=441000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 441000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.68e-05 |
|    n_updates        | 100249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20900    |
|    fps              | 140      |
|    time_elapsed     | 3147     |
|    total_timesteps  | 441139   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00154  |
|    n_updates        | 100284   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20904    |
|    fps              | 140      |
|    time_elapsed     | 3147     |
|    total_timesteps  | 441439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00129  |
|    n_updates        | 100359   |
----------------------------------
Eval num_timesteps=441500, episode_reward=-0.29 +/- 0.02
Episode length: 73.46 +/- 5.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.5     |
|    mean_reward      | -0.294   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 441500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00179  |
|    n_updates        | 100374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20908    |
|    fps              | 140      |
|    time_elapsed     | 3152     |
|    total_timesteps  | 441739   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000352 |
|    n_updates        | 100434   |
----------------------------------
Eval num_timesteps=442000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 442000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00011  |
|    n_updates        | 100499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20912    |
|    fps              | 139      |
|    time_elapsed     | 3157     |
|    total_timesteps  | 442034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00064  |
|    n_updates        | 100508   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20916    |
|    fps              | 140      |
|    time_elapsed     | 3158     |
|    total_timesteps  | 442334   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000808 |
|    n_updates        | 100583   |
----------------------------------
Eval num_timesteps=442500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 442500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.02e-05 |
|    n_updates        | 100624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20920    |
|    fps              | 139      |
|    time_elapsed     | 3163     |
|    total_timesteps  | 442634   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00101  |
|    n_updates        | 100658   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20924    |
|    fps              | 140      |
|    time_elapsed     | 3163     |
|    total_timesteps  | 442934   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00024  |
|    n_updates        | 100733   |
----------------------------------
Eval num_timesteps=443000, episode_reward=-0.30 +/- 0.01
Episode length: 74.72 +/- 1.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 443000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000488 |
|    n_updates        | 100749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20928    |
|    fps              | 139      |
|    time_elapsed     | 3168     |
|    total_timesteps  | 443234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00012  |
|    n_updates        | 100808   |
----------------------------------
Eval num_timesteps=443500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 443500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000674 |
|    n_updates        | 100874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20932    |
|    fps              | 139      |
|    time_elapsed     | 3173     |
|    total_timesteps  | 443534   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000134 |
|    n_updates        | 100883   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | -0.293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20936    |
|    fps              | 139      |
|    time_elapsed     | 3174     |
|    total_timesteps  | 443834   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000138 |
|    n_updates        | 100958   |
----------------------------------
Eval num_timesteps=444000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 444000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000197 |
|    n_updates        | 100999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20940    |
|    fps              | 139      |
|    time_elapsed     | 3179     |
|    total_timesteps  | 444134   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.06e-05 |
|    n_updates        | 101033   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20944    |
|    fps              | 139      |
|    time_elapsed     | 3180     |
|    total_timesteps  | 444434   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000413 |
|    n_updates        | 101108   |
----------------------------------
Eval num_timesteps=444500, episode_reward=-0.30 +/- 0.01
Episode length: 74.60 +/- 2.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 444500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000101 |
|    n_updates        | 101124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20948    |
|    fps              | 139      |
|    time_elapsed     | 3184     |
|    total_timesteps  | 444734   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.57e-05 |
|    n_updates        | 101183   |
----------------------------------
Eval num_timesteps=445000, episode_reward=-0.30 +/- 0.01
Episode length: 74.60 +/- 2.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 445000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000103 |
|    n_updates        | 101249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20952    |
|    fps              | 139      |
|    time_elapsed     | 3190     |
|    total_timesteps  | 445034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000635 |
|    n_updates        | 101258   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20956    |
|    fps              | 139      |
|    time_elapsed     | 3190     |
|    total_timesteps  | 445334   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000682 |
|    n_updates        | 101333   |
----------------------------------
Eval num_timesteps=445500, episode_reward=-0.30 +/- 0.01
Episode length: 74.82 +/- 1.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 445500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000685 |
|    n_updates        | 101374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20960    |
|    fps              | 139      |
|    time_elapsed     | 3195     |
|    total_timesteps  | 445634   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00077  |
|    n_updates        | 101408   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20964    |
|    fps              | 139      |
|    time_elapsed     | 3196     |
|    total_timesteps  | 445934   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000414 |
|    n_updates        | 101483   |
----------------------------------
Eval num_timesteps=446000, episode_reward=-0.30 +/- 0.01
Episode length: 74.70 +/- 2.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 446000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 101499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20968    |
|    fps              | 139      |
|    time_elapsed     | 3201     |
|    total_timesteps  | 446234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000672 |
|    n_updates        | 101558   |
----------------------------------
Eval num_timesteps=446500, episode_reward=-0.30 +/- 0.01
Episode length: 74.72 +/- 1.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 446500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00013  |
|    n_updates        | 101624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20972    |
|    fps              | 139      |
|    time_elapsed     | 3206     |
|    total_timesteps  | 446534   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00223  |
|    n_updates        | 101633   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20976    |
|    fps              | 139      |
|    time_elapsed     | 3206     |
|    total_timesteps  | 446834   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000107 |
|    n_updates        | 101708   |
----------------------------------
Eval num_timesteps=447000, episode_reward=-0.30 +/- 0.02
Episode length: 73.92 +/- 5.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 447000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 101749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20980    |
|    fps              | 139      |
|    time_elapsed     | 3211     |
|    total_timesteps  | 447134   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00072  |
|    n_updates        | 101783   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20984    |
|    fps              | 139      |
|    time_elapsed     | 3212     |
|    total_timesteps  | 447434   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000395 |
|    n_updates        | 101858   |
----------------------------------
Eval num_timesteps=447500, episode_reward=-0.30 +/- 0.01
Episode length: 74.70 +/- 2.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 447500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00076  |
|    n_updates        | 101874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20988    |
|    fps              | 139      |
|    time_elapsed     | 3217     |
|    total_timesteps  | 447734   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000114 |
|    n_updates        | 101933   |
----------------------------------
Eval num_timesteps=448000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 448000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000762 |
|    n_updates        | 101999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20992    |
|    fps              | 139      |
|    time_elapsed     | 3222     |
|    total_timesteps  | 448034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000587 |
|    n_updates        | 102008   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 20996    |
|    fps              | 139      |
|    time_elapsed     | 3222     |
|    total_timesteps  | 448289   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000391 |
|    n_updates        | 102072   |
----------------------------------
Eval num_timesteps=448500, episode_reward=-0.30 +/- 0.01
Episode length: 74.76 +/- 1.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 448500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000155 |
|    n_updates        | 102124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21000    |
|    fps              | 138      |
|    time_elapsed     | 3227     |
|    total_timesteps  | 448589   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000406 |
|    n_updates        | 102147   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21004    |
|    fps              | 139      |
|    time_elapsed     | 3228     |
|    total_timesteps  | 448887   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000284 |
|    n_updates        | 102221   |
----------------------------------
Eval num_timesteps=449000, episode_reward=-0.30 +/- 0.01
Episode length: 74.60 +/- 2.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 449000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000898 |
|    n_updates        | 102249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21008    |
|    fps              | 138      |
|    time_elapsed     | 3233     |
|    total_timesteps  | 449141   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000384 |
|    n_updates        | 102285   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21012    |
|    fps              | 138      |
|    time_elapsed     | 3233     |
|    total_timesteps  | 449441   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.03e-05 |
|    n_updates        | 102360   |
----------------------------------
Eval num_timesteps=449500, episode_reward=-0.30 +/- 0.01
Episode length: 74.78 +/- 1.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 449500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00046  |
|    n_updates        | 102374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21016    |
|    fps              | 138      |
|    time_elapsed     | 3238     |
|    total_timesteps  | 449741   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000348 |
|    n_updates        | 102435   |
----------------------------------
Eval num_timesteps=450000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 450000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000302 |
|    n_updates        | 102499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21020    |
|    fps              | 138      |
|    time_elapsed     | 3243     |
|    total_timesteps  | 450041   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.72e-05 |
|    n_updates        | 102510   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21024    |
|    fps              | 138      |
|    time_elapsed     | 3244     |
|    total_timesteps  | 450341   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.07e-05 |
|    n_updates        | 102585   |
----------------------------------
Eval num_timesteps=450500, episode_reward=-0.30 +/- 0.02
Episode length: 74.28 +/- 4.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.3     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 450500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000412 |
|    n_updates        | 102624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21028    |
|    fps              | 138      |
|    time_elapsed     | 3249     |
|    total_timesteps  | 450628   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.39e-05 |
|    n_updates        | 102656   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21032    |
|    fps              | 138      |
|    time_elapsed     | 3249     |
|    total_timesteps  | 450928   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000553 |
|    n_updates        | 102731   |
----------------------------------
Eval num_timesteps=451000, episode_reward=-0.30 +/- 0.02
Episode length: 73.90 +/- 4.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 451000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000709 |
|    n_updates        | 102749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21036    |
|    fps              | 138      |
|    time_elapsed     | 3254     |
|    total_timesteps  | 451228   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.83e-05 |
|    n_updates        | 102806   |
----------------------------------
Eval num_timesteps=451500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 451500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000144 |
|    n_updates        | 102874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21040    |
|    fps              | 138      |
|    time_elapsed     | 3259     |
|    total_timesteps  | 451528   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00053  |
|    n_updates        | 102881   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21044    |
|    fps              | 138      |
|    time_elapsed     | 3260     |
|    total_timesteps  | 451828   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000196 |
|    n_updates        | 102956   |
----------------------------------
Eval num_timesteps=452000, episode_reward=-0.27 +/- 0.14
Episode length: 73.32 +/- 5.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.3     |
|    mean_reward      | -0.273   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 452000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 102999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21048    |
|    fps              | 138      |
|    time_elapsed     | 3264     |
|    total_timesteps  | 452118   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00114  |
|    n_updates        | 103029   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21052    |
|    fps              | 138      |
|    time_elapsed     | 3265     |
|    total_timesteps  | 452418   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000114 |
|    n_updates        | 103104   |
----------------------------------
Eval num_timesteps=452500, episode_reward=-0.30 +/- 0.00
Episode length: 74.90 +/- 0.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 452500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000941 |
|    n_updates        | 103124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21056    |
|    fps              | 138      |
|    time_elapsed     | 3270     |
|    total_timesteps  | 452711   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000439 |
|    n_updates        | 103177   |
----------------------------------
Eval num_timesteps=453000, episode_reward=-0.30 +/- 0.00
Episode length: 74.92 +/- 0.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 453000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000155 |
|    n_updates        | 103249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21060    |
|    fps              | 138      |
|    time_elapsed     | 3275     |
|    total_timesteps  | 453011   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.08e-05 |
|    n_updates        | 103252   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21064    |
|    fps              | 138      |
|    time_elapsed     | 3276     |
|    total_timesteps  | 453303   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000595 |
|    n_updates        | 103325   |
----------------------------------
Eval num_timesteps=453500, episode_reward=-0.30 +/- 0.02
Episode length: 74.08 +/- 3.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.1     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 453500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.01e-05 |
|    n_updates        | 103374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21068    |
|    fps              | 138      |
|    time_elapsed     | 3281     |
|    total_timesteps  | 453603   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00098  |
|    n_updates        | 103400   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21072    |
|    fps              | 138      |
|    time_elapsed     | 3281     |
|    total_timesteps  | 453903   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000552 |
|    n_updates        | 103475   |
----------------------------------
Eval num_timesteps=454000, episode_reward=-0.30 +/- 0.01
Episode length: 74.48 +/- 3.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 454000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000609 |
|    n_updates        | 103499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21076    |
|    fps              | 138      |
|    time_elapsed     | 3286     |
|    total_timesteps  | 454203   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00066  |
|    n_updates        | 103550   |
----------------------------------
Eval num_timesteps=454500, episode_reward=-0.30 +/- 0.00
Episode length: 74.92 +/- 0.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 454500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000283 |
|    n_updates        | 103624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21080    |
|    fps              | 138      |
|    time_elapsed     | 3291     |
|    total_timesteps  | 454503   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000174 |
|    n_updates        | 103625   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21084    |
|    fps              | 138      |
|    time_elapsed     | 3292     |
|    total_timesteps  | 454803   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6e-05    |
|    n_updates        | 103700   |
----------------------------------
Eval num_timesteps=455000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 455000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.51e-05 |
|    n_updates        | 103749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21088    |
|    fps              | 138      |
|    time_elapsed     | 3297     |
|    total_timesteps  | 455103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000101 |
|    n_updates        | 103775   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | -0.285   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21092    |
|    fps              | 138      |
|    time_elapsed     | 3297     |
|    total_timesteps  | 455403   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.71e-05 |
|    n_updates        | 103850   |
----------------------------------
Eval num_timesteps=455500, episode_reward=-0.30 +/- 0.01
Episode length: 74.74 +/- 1.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 455500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5e-05    |
|    n_updates        | 103874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | -0.286   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21096    |
|    fps              | 137      |
|    time_elapsed     | 3302     |
|    total_timesteps  | 455703   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000484 |
|    n_updates        | 103925   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21100    |
|    fps              | 138      |
|    time_elapsed     | 3303     |
|    total_timesteps  | 455989   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000658 |
|    n_updates        | 103997   |
----------------------------------
Eval num_timesteps=456000, episode_reward=-0.27 +/- 0.14
Episode length: 72.92 +/- 5.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.9     |
|    mean_reward      | -0.271   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 456000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.54e-05 |
|    n_updates        | 103999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21104    |
|    fps              | 137      |
|    time_elapsed     | 3308     |
|    total_timesteps  | 456289   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000586 |
|    n_updates        | 104072   |
----------------------------------
Eval num_timesteps=456500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 456500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00156  |
|    n_updates        | 104124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21108    |
|    fps              | 137      |
|    time_elapsed     | 3313     |
|    total_timesteps  | 456589   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.9e-05  |
|    n_updates        | 104147   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21112    |
|    fps              | 137      |
|    time_elapsed     | 3313     |
|    total_timesteps  | 456889   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000623 |
|    n_updates        | 104222   |
----------------------------------
Eval num_timesteps=457000, episode_reward=-0.30 +/- 0.01
Episode length: 74.62 +/- 2.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 457000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000109 |
|    n_updates        | 104249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21116    |
|    fps              | 137      |
|    time_elapsed     | 3318     |
|    total_timesteps  | 457157   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000639 |
|    n_updates        | 104289   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21120    |
|    fps              | 137      |
|    time_elapsed     | 3319     |
|    total_timesteps  | 457457   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00043  |
|    n_updates        | 104364   |
----------------------------------
Eval num_timesteps=457500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 457500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000734 |
|    n_updates        | 104374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21124    |
|    fps              | 137      |
|    time_elapsed     | 3324     |
|    total_timesteps  | 457757   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000129 |
|    n_updates        | 104439   |
----------------------------------
Eval num_timesteps=458000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 458000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000147 |
|    n_updates        | 104499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21128    |
|    fps              | 137      |
|    time_elapsed     | 3329     |
|    total_timesteps  | 458057   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 104514   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21132    |
|    fps              | 137      |
|    time_elapsed     | 3329     |
|    total_timesteps  | 458357   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000105 |
|    n_updates        | 104589   |
----------------------------------
Eval num_timesteps=458500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 458500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00049  |
|    n_updates        | 104624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21136    |
|    fps              | 137      |
|    time_elapsed     | 3334     |
|    total_timesteps  | 458657   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7e-05    |
|    n_updates        | 104664   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21140    |
|    fps              | 137      |
|    time_elapsed     | 3335     |
|    total_timesteps  | 458957   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.59e-05 |
|    n_updates        | 104739   |
----------------------------------
Eval num_timesteps=459000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 459000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0002   |
|    n_updates        | 104749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21144    |
|    fps              | 137      |
|    time_elapsed     | 3340     |
|    total_timesteps  | 459257   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.51e-05 |
|    n_updates        | 104814   |
----------------------------------
Eval num_timesteps=459500, episode_reward=-0.30 +/- 0.00
Episode length: 74.94 +/- 0.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 459500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.46e-05 |
|    n_updates        | 104874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21148    |
|    fps              | 137      |
|    time_elapsed     | 3346     |
|    total_timesteps  | 459557   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.25e-05 |
|    n_updates        | 104889   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21152    |
|    fps              | 137      |
|    time_elapsed     | 3346     |
|    total_timesteps  | 459857   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000135 |
|    n_updates        | 104964   |
----------------------------------
Eval num_timesteps=460000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 460000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.47e-05 |
|    n_updates        | 104999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21156    |
|    fps              | 137      |
|    time_elapsed     | 3351     |
|    total_timesteps  | 460157   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000131 |
|    n_updates        | 105039   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21160    |
|    fps              | 137      |
|    time_elapsed     | 3352     |
|    total_timesteps  | 460457   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000867 |
|    n_updates        | 105114   |
----------------------------------
Eval num_timesteps=460500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 460500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000253 |
|    n_updates        | 105124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21164    |
|    fps              | 137      |
|    time_elapsed     | 3356     |
|    total_timesteps  | 460737   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.59e-05 |
|    n_updates        | 105184   |
----------------------------------
Eval num_timesteps=461000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 461000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.61e-05 |
|    n_updates        | 105249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21168    |
|    fps              | 137      |
|    time_elapsed     | 3362     |
|    total_timesteps  | 461037   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.7e-05  |
|    n_updates        | 105259   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21172    |
|    fps              | 137      |
|    time_elapsed     | 3362     |
|    total_timesteps  | 461337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000553 |
|    n_updates        | 105334   |
----------------------------------
Eval num_timesteps=461500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 461500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.33e-05 |
|    n_updates        | 105374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21176    |
|    fps              | 137      |
|    time_elapsed     | 3368     |
|    total_timesteps  | 461637   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000647 |
|    n_updates        | 105409   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21180    |
|    fps              | 137      |
|    time_elapsed     | 3368     |
|    total_timesteps  | 461937   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.86e-05 |
|    n_updates        | 105484   |
----------------------------------
Eval num_timesteps=462000, episode_reward=-0.30 +/- 0.01
Episode length: 74.62 +/- 2.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 462000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000154 |
|    n_updates        | 105499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21184    |
|    fps              | 137      |
|    time_elapsed     | 3373     |
|    total_timesteps  | 462237   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000987 |
|    n_updates        | 105559   |
----------------------------------
Eval num_timesteps=462500, episode_reward=-0.30 +/- 0.01
Episode length: 74.48 +/- 2.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 462500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.89e-05 |
|    n_updates        | 105624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21188    |
|    fps              | 136      |
|    time_elapsed     | 3379     |
|    total_timesteps  | 462537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00102  |
|    n_updates        | 105634   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21192    |
|    fps              | 136      |
|    time_elapsed     | 3379     |
|    total_timesteps  | 462837   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000316 |
|    n_updates        | 105709   |
----------------------------------
Eval num_timesteps=463000, episode_reward=-0.30 +/- 0.00
Episode length: 74.98 +/- 0.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 463000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00066  |
|    n_updates        | 105749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.287   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21196    |
|    fps              | 136      |
|    time_elapsed     | 3384     |
|    total_timesteps  | 463137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.34e-05 |
|    n_updates        | 105784   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21200    |
|    fps              | 136      |
|    time_elapsed     | 3384     |
|    total_timesteps  | 463437   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000475 |
|    n_updates        | 105859   |
----------------------------------
Eval num_timesteps=463500, episode_reward=-0.30 +/- 0.00
Episode length: 74.84 +/- 1.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 463500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.19e-05 |
|    n_updates        | 105874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21204    |
|    fps              | 136      |
|    time_elapsed     | 3390     |
|    total_timesteps  | 463737   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000363 |
|    n_updates        | 105934   |
----------------------------------
Eval num_timesteps=464000, episode_reward=-0.30 +/- 0.01
Episode length: 74.76 +/- 1.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 464000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5e-05    |
|    n_updates        | 105999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21208    |
|    fps              | 136      |
|    time_elapsed     | 3395     |
|    total_timesteps  | 464037   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000588 |
|    n_updates        | 106009   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21212    |
|    fps              | 136      |
|    time_elapsed     | 3396     |
|    total_timesteps  | 464337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.001    |
|    n_updates        | 106084   |
----------------------------------
Eval num_timesteps=464500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 464500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000809 |
|    n_updates        | 106124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21216    |
|    fps              | 136      |
|    time_elapsed     | 3401     |
|    total_timesteps  | 464637   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.81e-05 |
|    n_updates        | 106159   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21220    |
|    fps              | 136      |
|    time_elapsed     | 3402     |
|    total_timesteps  | 464937   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000637 |
|    n_updates        | 106234   |
----------------------------------
Eval num_timesteps=465000, episode_reward=-0.30 +/- 0.01
Episode length: 74.76 +/- 1.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 465000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00048  |
|    n_updates        | 106249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21224    |
|    fps              | 136      |
|    time_elapsed     | 3407     |
|    total_timesteps  | 465237   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.56e-05 |
|    n_updates        | 106309   |
----------------------------------
Eval num_timesteps=465500, episode_reward=-0.30 +/- 0.01
Episode length: 74.40 +/- 2.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.4     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 465500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.85e-05 |
|    n_updates        | 106374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21228    |
|    fps              | 136      |
|    time_elapsed     | 3412     |
|    total_timesteps  | 465537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000116 |
|    n_updates        | 106384   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21232    |
|    fps              | 136      |
|    time_elapsed     | 3412     |
|    total_timesteps  | 465837   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000748 |
|    n_updates        | 106459   |
----------------------------------
Eval num_timesteps=466000, episode_reward=-0.30 +/- 0.00
Episode length: 74.92 +/- 0.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 466000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000302 |
|    n_updates        | 106499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21236    |
|    fps              | 136      |
|    time_elapsed     | 3418     |
|    total_timesteps  | 466137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000578 |
|    n_updates        | 106534   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21240    |
|    fps              | 136      |
|    time_elapsed     | 3418     |
|    total_timesteps  | 466406   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000128 |
|    n_updates        | 106601   |
----------------------------------
Eval num_timesteps=466500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 466500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000123 |
|    n_updates        | 106624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21244    |
|    fps              | 136      |
|    time_elapsed     | 3424     |
|    total_timesteps  | 466706   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000995 |
|    n_updates        | 106676   |
----------------------------------
Eval num_timesteps=467000, episode_reward=-0.30 +/- 0.00
Episode length: 74.94 +/- 0.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 467000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000327 |
|    n_updates        | 106749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21248    |
|    fps              | 136      |
|    time_elapsed     | 3429     |
|    total_timesteps  | 467006   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000644 |
|    n_updates        | 106751   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21252    |
|    fps              | 136      |
|    time_elapsed     | 3429     |
|    total_timesteps  | 467276   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000355 |
|    n_updates        | 106818   |
----------------------------------
Eval num_timesteps=467500, episode_reward=-0.30 +/- 0.01
Episode length: 74.24 +/- 3.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.2     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 467500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.13e-05 |
|    n_updates        | 106874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21256    |
|    fps              | 136      |
|    time_elapsed     | 3434     |
|    total_timesteps  | 467576   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000539 |
|    n_updates        | 106893   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21260    |
|    fps              | 136      |
|    time_elapsed     | 3435     |
|    total_timesteps  | 467853   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00049  |
|    n_updates        | 106963   |
----------------------------------
Eval num_timesteps=468000, episode_reward=-0.29 +/- 0.03
Episode length: 72.44 +/- 6.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.4     |
|    mean_reward      | -0.29    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 468000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000889 |
|    n_updates        | 106999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21264    |
|    fps              | 136      |
|    time_elapsed     | 3440     |
|    total_timesteps  | 468153   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000174 |
|    n_updates        | 107038   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21268    |
|    fps              | 136      |
|    time_elapsed     | 3441     |
|    total_timesteps  | 468453   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000514 |
|    n_updates        | 107113   |
----------------------------------
Eval num_timesteps=468500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 468500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000353 |
|    n_updates        | 107124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21272    |
|    fps              | 136      |
|    time_elapsed     | 3446     |
|    total_timesteps  | 468753   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.69e-05 |
|    n_updates        | 107188   |
----------------------------------
Eval num_timesteps=469000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 469000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000151 |
|    n_updates        | 107249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21276    |
|    fps              | 135      |
|    time_elapsed     | 3451     |
|    total_timesteps  | 469053   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000864 |
|    n_updates        | 107263   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21280    |
|    fps              | 135      |
|    time_elapsed     | 3452     |
|    total_timesteps  | 469340   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.52e-05 |
|    n_updates        | 107334   |
----------------------------------
Eval num_timesteps=469500, episode_reward=-0.30 +/- 0.01
Episode length: 74.44 +/- 2.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.4     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 469500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 107374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21284    |
|    fps              | 135      |
|    time_elapsed     | 3457     |
|    total_timesteps  | 469640   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000481 |
|    n_updates        | 107409   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21288    |
|    fps              | 135      |
|    time_elapsed     | 3458     |
|    total_timesteps  | 469940   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00136  |
|    n_updates        | 107484   |
----------------------------------
Eval num_timesteps=470000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 470000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000119 |
|    n_updates        | 107499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21292    |
|    fps              | 135      |
|    time_elapsed     | 3464     |
|    total_timesteps  | 470240   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.02e-05 |
|    n_updates        | 107559   |
----------------------------------
Eval num_timesteps=470500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 470500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00035  |
|    n_updates        | 107624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21296    |
|    fps              | 135      |
|    time_elapsed     | 3469     |
|    total_timesteps  | 470540   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000744 |
|    n_updates        | 107634   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21300    |
|    fps              | 135      |
|    time_elapsed     | 3469     |
|    total_timesteps  | 470840   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.1e-05  |
|    n_updates        | 107709   |
----------------------------------
Eval num_timesteps=471000, episode_reward=-0.30 +/- 0.01
Episode length: 74.48 +/- 3.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 471000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00108  |
|    n_updates        | 107749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21304    |
|    fps              | 135      |
|    time_elapsed     | 3474     |
|    total_timesteps  | 471139   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00049  |
|    n_updates        | 107784   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21308    |
|    fps              | 135      |
|    time_elapsed     | 3475     |
|    total_timesteps  | 471439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000621 |
|    n_updates        | 107859   |
----------------------------------
Eval num_timesteps=471500, episode_reward=-0.30 +/- 0.01
Episode length: 74.64 +/- 2.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 471500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000215 |
|    n_updates        | 107874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21312    |
|    fps              | 135      |
|    time_elapsed     | 3480     |
|    total_timesteps  | 471738   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000159 |
|    n_updates        | 107934   |
----------------------------------
Eval num_timesteps=472000, episode_reward=-0.29 +/- 0.02
Episode length: 73.68 +/- 6.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.7     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 472000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000453 |
|    n_updates        | 107999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21316    |
|    fps              | 135      |
|    time_elapsed     | 3485     |
|    total_timesteps  | 472038   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.33e-05 |
|    n_updates        | 108009   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21320    |
|    fps              | 135      |
|    time_elapsed     | 3486     |
|    total_timesteps  | 472338   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00056  |
|    n_updates        | 108084   |
----------------------------------
Eval num_timesteps=472500, episode_reward=-0.30 +/- 0.01
Episode length: 74.48 +/- 3.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 472500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000104 |
|    n_updates        | 108124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21324    |
|    fps              | 135      |
|    time_elapsed     | 3491     |
|    total_timesteps  | 472638   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00052  |
|    n_updates        | 108159   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21328    |
|    fps              | 135      |
|    time_elapsed     | 3491     |
|    total_timesteps  | 472886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00057  |
|    n_updates        | 108221   |
----------------------------------
Eval num_timesteps=473000, episode_reward=-0.29 +/- 0.03
Episode length: 73.40 +/- 6.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.4     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 473000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00079  |
|    n_updates        | 108249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21332    |
|    fps              | 135      |
|    time_elapsed     | 3497     |
|    total_timesteps  | 473186   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00111  |
|    n_updates        | 108296   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21336    |
|    fps              | 135      |
|    time_elapsed     | 3497     |
|    total_timesteps  | 473486   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.16e-05 |
|    n_updates        | 108371   |
----------------------------------
Eval num_timesteps=473500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 473500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000929 |
|    n_updates        | 108374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21340    |
|    fps              | 135      |
|    time_elapsed     | 3502     |
|    total_timesteps  | 473786   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.07e-05 |
|    n_updates        | 108446   |
----------------------------------
Eval num_timesteps=474000, episode_reward=-0.30 +/- 0.02
Episode length: 73.82 +/- 5.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 474000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.73e-05 |
|    n_updates        | 108499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21344    |
|    fps              | 135      |
|    time_elapsed     | 3507     |
|    total_timesteps  | 474086   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000584 |
|    n_updates        | 108521   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | -0.294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21348    |
|    fps              | 135      |
|    time_elapsed     | 3508     |
|    total_timesteps  | 474356   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000509 |
|    n_updates        | 108588   |
----------------------------------
Eval num_timesteps=474500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 474500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.9e-05  |
|    n_updates        | 108624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21352    |
|    fps              | 135      |
|    time_elapsed     | 3513     |
|    total_timesteps  | 474656   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000921 |
|    n_updates        | 108663   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21356    |
|    fps              | 135      |
|    time_elapsed     | 3513     |
|    total_timesteps  | 474956   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.13e-05 |
|    n_updates        | 108738   |
----------------------------------
Eval num_timesteps=475000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 475000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000532 |
|    n_updates        | 108749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21360    |
|    fps              | 135      |
|    time_elapsed     | 3518     |
|    total_timesteps  | 475256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00182  |
|    n_updates        | 108813   |
----------------------------------
Eval num_timesteps=475500, episode_reward=-0.30 +/- 0.00
Episode length: 74.94 +/- 0.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 475500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000603 |
|    n_updates        | 108874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21364    |
|    fps              | 134      |
|    time_elapsed     | 3524     |
|    total_timesteps  | 475556   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000102 |
|    n_updates        | 108888   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21368    |
|    fps              | 135      |
|    time_elapsed     | 3524     |
|    total_timesteps  | 475856   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000729 |
|    n_updates        | 108963   |
----------------------------------
Eval num_timesteps=476000, episode_reward=-0.30 +/- 0.02
Episode length: 74.22 +/- 4.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.2     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 476000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000552 |
|    n_updates        | 108999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21372    |
|    fps              | 134      |
|    time_elapsed     | 3530     |
|    total_timesteps  | 476156   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000968 |
|    n_updates        | 109038   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21376    |
|    fps              | 134      |
|    time_elapsed     | 3531     |
|    total_timesteps  | 476456   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000457 |
|    n_updates        | 109113   |
----------------------------------
Eval num_timesteps=476500, episode_reward=-0.30 +/- 0.02
Episode length: 73.92 +/- 4.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 476500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000516 |
|    n_updates        | 109124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21380    |
|    fps              | 134      |
|    time_elapsed     | 3536     |
|    total_timesteps  | 476756   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000253 |
|    n_updates        | 109188   |
----------------------------------
Eval num_timesteps=477000, episode_reward=-0.30 +/- 0.02
Episode length: 73.86 +/- 5.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 477000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000948 |
|    n_updates        | 109249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21384    |
|    fps              | 134      |
|    time_elapsed     | 3541     |
|    total_timesteps  | 477033   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.2e-05  |
|    n_updates        | 109258   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21388    |
|    fps              | 134      |
|    time_elapsed     | 3542     |
|    total_timesteps  | 477333   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000292 |
|    n_updates        | 109333   |
----------------------------------
Eval num_timesteps=477500, episode_reward=-0.29 +/- 0.03
Episode length: 73.70 +/- 6.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.7     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 477500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.48e-05 |
|    n_updates        | 109374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21392    |
|    fps              | 134      |
|    time_elapsed     | 3547     |
|    total_timesteps  | 477633   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.28e-05 |
|    n_updates        | 109408   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21396    |
|    fps              | 134      |
|    time_elapsed     | 3548     |
|    total_timesteps  | 477933   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00127  |
|    n_updates        | 109483   |
----------------------------------
Eval num_timesteps=478000, episode_reward=-0.30 +/- 0.02
Episode length: 73.88 +/- 5.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 478000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000107 |
|    n_updates        | 109499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21400    |
|    fps              | 134      |
|    time_elapsed     | 3553     |
|    total_timesteps  | 478233   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.55e-05 |
|    n_updates        | 109558   |
----------------------------------
Eval num_timesteps=478500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 478500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000237 |
|    n_updates        | 109624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21404    |
|    fps              | 134      |
|    time_elapsed     | 3559     |
|    total_timesteps  | 478533   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00137  |
|    n_updates        | 109633   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21408    |
|    fps              | 134      |
|    time_elapsed     | 3559     |
|    total_timesteps  | 478833   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.86e-05 |
|    n_updates        | 109708   |
----------------------------------
Eval num_timesteps=479000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 479000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000117 |
|    n_updates        | 109749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21412    |
|    fps              | 134      |
|    time_elapsed     | 3564     |
|    total_timesteps  | 479116   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.66e-05 |
|    n_updates        | 109778   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21416    |
|    fps              | 134      |
|    time_elapsed     | 3565     |
|    total_timesteps  | 479416   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.09e-05 |
|    n_updates        | 109853   |
----------------------------------
Eval num_timesteps=479500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 479500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000798 |
|    n_updates        | 109874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21420    |
|    fps              | 134      |
|    time_elapsed     | 3571     |
|    total_timesteps  | 479716   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000196 |
|    n_updates        | 109928   |
----------------------------------
Eval num_timesteps=480000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 480000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000474 |
|    n_updates        | 109999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | -0.295   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21424    |
|    fps              | 134      |
|    time_elapsed     | 3576     |
|    total_timesteps  | 480016   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000123 |
|    n_updates        | 110003   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21428    |
|    fps              | 134      |
|    time_elapsed     | 3577     |
|    total_timesteps  | 480316   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000156 |
|    n_updates        | 110078   |
----------------------------------
Eval num_timesteps=480500, episode_reward=-0.30 +/- 0.01
Episode length: 74.62 +/- 1.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 480500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000457 |
|    n_updates        | 110124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21432    |
|    fps              | 134      |
|    time_elapsed     | 3582     |
|    total_timesteps  | 480616   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.67e-05 |
|    n_updates        | 110153   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21436    |
|    fps              | 134      |
|    time_elapsed     | 3583     |
|    total_timesteps  | 480916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000969 |
|    n_updates        | 110228   |
----------------------------------
Eval num_timesteps=481000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 481000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000307 |
|    n_updates        | 110249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21440    |
|    fps              | 134      |
|    time_elapsed     | 3588     |
|    total_timesteps  | 481216   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.25e-05 |
|    n_updates        | 110303   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | -0.296   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21444    |
|    fps              | 134      |
|    time_elapsed     | 3588     |
|    total_timesteps  | 481494   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.93e-05 |
|    n_updates        | 110373   |
----------------------------------
Eval num_timesteps=481500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 481500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.52e-05 |
|    n_updates        | 110374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21448    |
|    fps              | 134      |
|    time_elapsed     | 3594     |
|    total_timesteps  | 481794   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00056  |
|    n_updates        | 110448   |
----------------------------------
Eval num_timesteps=482000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 482000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.41e-05 |
|    n_updates        | 110499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21452    |
|    fps              | 133      |
|    time_elapsed     | 3599     |
|    total_timesteps  | 482094   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.16e-05 |
|    n_updates        | 110523   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21456    |
|    fps              | 134      |
|    time_elapsed     | 3599     |
|    total_timesteps  | 482394   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.53e-05 |
|    n_updates        | 110598   |
----------------------------------
Eval num_timesteps=482500, episode_reward=-0.30 +/- 0.01
Episode length: 74.48 +/- 2.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 482500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000976 |
|    n_updates        | 110624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21460    |
|    fps              | 133      |
|    time_elapsed     | 3605     |
|    total_timesteps  | 482694   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.19e-05 |
|    n_updates        | 110673   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21464    |
|    fps              | 133      |
|    time_elapsed     | 3605     |
|    total_timesteps  | 482994   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000959 |
|    n_updates        | 110748   |
----------------------------------
Eval num_timesteps=483000, episode_reward=-0.30 +/- 0.02
Episode length: 73.84 +/- 5.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 483000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000132 |
|    n_updates        | 110749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21468    |
|    fps              | 133      |
|    time_elapsed     | 3611     |
|    total_timesteps  | 483294   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000499 |
|    n_updates        | 110823   |
----------------------------------
Eval num_timesteps=483500, episode_reward=-0.30 +/- 0.01
Episode length: 74.70 +/- 2.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 483500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.92e-05 |
|    n_updates        | 110874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21472    |
|    fps              | 133      |
|    time_elapsed     | 3616     |
|    total_timesteps  | 483594   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.07e-05 |
|    n_updates        | 110898   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21476    |
|    fps              | 133      |
|    time_elapsed     | 3616     |
|    total_timesteps  | 483894   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.89e-05 |
|    n_updates        | 110973   |
----------------------------------
Eval num_timesteps=484000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 484000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.69e-05 |
|    n_updates        | 110999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21480    |
|    fps              | 133      |
|    time_elapsed     | 3622     |
|    total_timesteps  | 484193   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00028  |
|    n_updates        | 111048   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21484    |
|    fps              | 133      |
|    time_elapsed     | 3622     |
|    total_timesteps  | 484493   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000546 |
|    n_updates        | 111123   |
----------------------------------
Eval num_timesteps=484500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 484500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.84e-05 |
|    n_updates        | 111124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21488    |
|    fps              | 133      |
|    time_elapsed     | 3628     |
|    total_timesteps  | 484793   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000252 |
|    n_updates        | 111198   |
----------------------------------
Eval num_timesteps=485000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 485000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.27e-05 |
|    n_updates        | 111249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21492    |
|    fps              | 133      |
|    time_elapsed     | 3633     |
|    total_timesteps  | 485093   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000499 |
|    n_updates        | 111273   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21496    |
|    fps              | 133      |
|    time_elapsed     | 3633     |
|    total_timesteps  | 485393   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000127 |
|    n_updates        | 111348   |
----------------------------------
Eval num_timesteps=485500, episode_reward=-0.30 +/- 0.01
Episode length: 74.82 +/- 1.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 485500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.09e-05 |
|    n_updates        | 111374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21500    |
|    fps              | 133      |
|    time_elapsed     | 3639     |
|    total_timesteps  | 485693   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000108 |
|    n_updates        | 111423   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21504    |
|    fps              | 133      |
|    time_elapsed     | 3639     |
|    total_timesteps  | 485993   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000454 |
|    n_updates        | 111498   |
----------------------------------
Eval num_timesteps=486000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 486000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.74e-05 |
|    n_updates        | 111499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21508    |
|    fps              | 133      |
|    time_elapsed     | 3645     |
|    total_timesteps  | 486293   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000448 |
|    n_updates        | 111573   |
----------------------------------
Eval num_timesteps=486500, episode_reward=-0.28 +/- 0.14
Episode length: 74.92 +/- 0.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.28    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 486500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.59e-05 |
|    n_updates        | 111624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21512    |
|    fps              | 133      |
|    time_elapsed     | 3650     |
|    total_timesteps  | 486593   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00032  |
|    n_updates        | 111648   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21516    |
|    fps              | 133      |
|    time_elapsed     | 3650     |
|    total_timesteps  | 486838   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000397 |
|    n_updates        | 111709   |
----------------------------------
Eval num_timesteps=487000, episode_reward=-0.30 +/- 0.01
Episode length: 74.74 +/- 1.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 487000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000609 |
|    n_updates        | 111749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21520    |
|    fps              | 133      |
|    time_elapsed     | 3655     |
|    total_timesteps  | 487138   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000121 |
|    n_updates        | 111784   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21524    |
|    fps              | 133      |
|    time_elapsed     | 3656     |
|    total_timesteps  | 487438   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000137 |
|    n_updates        | 111859   |
----------------------------------
Eval num_timesteps=487500, episode_reward=-0.25 +/- 0.21
Episode length: 72.56 +/- 6.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.6     |
|    mean_reward      | -0.25    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 487500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.56e-05 |
|    n_updates        | 111874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21528    |
|    fps              | 133      |
|    time_elapsed     | 3661     |
|    total_timesteps  | 487738   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000934 |
|    n_updates        | 111934   |
----------------------------------
Eval num_timesteps=488000, episode_reward=-0.30 +/- 0.01
Episode length: 74.58 +/- 2.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 488000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.03e-05 |
|    n_updates        | 111999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21532    |
|    fps              | 133      |
|    time_elapsed     | 3666     |
|    total_timesteps  | 488038   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000622 |
|    n_updates        | 112009   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21536    |
|    fps              | 133      |
|    time_elapsed     | 3667     |
|    total_timesteps  | 488338   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0001   |
|    n_updates        | 112084   |
----------------------------------
Eval num_timesteps=488500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 488500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.5e-05  |
|    n_updates        | 112124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21540    |
|    fps              | 133      |
|    time_elapsed     | 3672     |
|    total_timesteps  | 488638   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.89e-05 |
|    n_updates        | 112159   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | -0.298   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21544    |
|    fps              | 133      |
|    time_elapsed     | 3673     |
|    total_timesteps  | 488938   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000496 |
|    n_updates        | 112234   |
----------------------------------
Eval num_timesteps=489000, episode_reward=-0.29 +/- 0.02
Episode length: 73.44 +/- 5.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.4     |
|    mean_reward      | -0.294   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 489000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000832 |
|    n_updates        | 112249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21548    |
|    fps              | 132      |
|    time_elapsed     | 3678     |
|    total_timesteps  | 489217   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.73e-05 |
|    n_updates        | 112304   |
----------------------------------
Eval num_timesteps=489500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 489500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.64e-05 |
|    n_updates        | 112374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21552    |
|    fps              | 132      |
|    time_elapsed     | 3684     |
|    total_timesteps  | 489517   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00081  |
|    n_updates        | 112379   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21556    |
|    fps              | 132      |
|    time_elapsed     | 3684     |
|    total_timesteps  | 489817   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000563 |
|    n_updates        | 112454   |
----------------------------------
Eval num_timesteps=490000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 490000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.5e-05  |
|    n_updates        | 112499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21560    |
|    fps              | 132      |
|    time_elapsed     | 3689     |
|    total_timesteps  | 490117   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000109 |
|    n_updates        | 112529   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21564    |
|    fps              | 132      |
|    time_elapsed     | 3690     |
|    total_timesteps  | 490417   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.93e-05 |
|    n_updates        | 112604   |
----------------------------------
Eval num_timesteps=490500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 490500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.66e-05 |
|    n_updates        | 112624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21568    |
|    fps              | 132      |
|    time_elapsed     | 3695     |
|    total_timesteps  | 490717   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000328 |
|    n_updates        | 112679   |
----------------------------------
Eval num_timesteps=491000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 491000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.68e-05 |
|    n_updates        | 112749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21572    |
|    fps              | 132      |
|    time_elapsed     | 3700     |
|    total_timesteps  | 491017   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000795 |
|    n_updates        | 112754   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21576    |
|    fps              | 132      |
|    time_elapsed     | 3701     |
|    total_timesteps  | 491317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000446 |
|    n_updates        | 112829   |
----------------------------------
Eval num_timesteps=491500, episode_reward=-0.28 +/- 0.16
Episode length: 74.36 +/- 4.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.4     |
|    mean_reward      | -0.277   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 491500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.02e-05 |
|    n_updates        | 112874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21580    |
|    fps              | 132      |
|    time_elapsed     | 3706     |
|    total_timesteps  | 491617   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.81e-05 |
|    n_updates        | 112904   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21584    |
|    fps              | 132      |
|    time_elapsed     | 3706     |
|    total_timesteps  | 491917   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000325 |
|    n_updates        | 112979   |
----------------------------------
Eval num_timesteps=492000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 492000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000717 |
|    n_updates        | 112999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21588    |
|    fps              | 132      |
|    time_elapsed     | 3712     |
|    total_timesteps  | 492217   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.81e-05 |
|    n_updates        | 113054   |
----------------------------------
Eval num_timesteps=492500, episode_reward=-0.30 +/- 0.01
Episode length: 74.68 +/- 1.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 492500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.07e-05 |
|    n_updates        | 113124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21592    |
|    fps              | 132      |
|    time_elapsed     | 3717     |
|    total_timesteps  | 492517   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.52e-05 |
|    n_updates        | 113129   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21596    |
|    fps              | 132      |
|    time_elapsed     | 3717     |
|    total_timesteps  | 492817   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.33e-05 |
|    n_updates        | 113204   |
----------------------------------
Eval num_timesteps=493000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 493000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.36e-05 |
|    n_updates        | 113249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21600    |
|    fps              | 132      |
|    time_elapsed     | 3723     |
|    total_timesteps  | 493117   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.25e-05 |
|    n_updates        | 113279   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21604    |
|    fps              | 132      |
|    time_elapsed     | 3723     |
|    total_timesteps  | 493417   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000666 |
|    n_updates        | 113354   |
----------------------------------
Eval num_timesteps=493500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 493500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000617 |
|    n_updates        | 113374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21608    |
|    fps              | 132      |
|    time_elapsed     | 3728     |
|    total_timesteps  | 493717   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000729 |
|    n_updates        | 113429   |
----------------------------------
Eval num_timesteps=494000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 494000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000275 |
|    n_updates        | 113499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | -0.297   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21612    |
|    fps              | 132      |
|    time_elapsed     | 3733     |
|    total_timesteps  | 494017   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.74e-05 |
|    n_updates        | 113504   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21616    |
|    fps              | 132      |
|    time_elapsed     | 3734     |
|    total_timesteps  | 494317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.41e-05 |
|    n_updates        | 113579   |
----------------------------------
Eval num_timesteps=494500, episode_reward=-0.30 +/- 0.01
Episode length: 74.74 +/- 1.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 494500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.23e-05 |
|    n_updates        | 113624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21620    |
|    fps              | 132      |
|    time_elapsed     | 3739     |
|    total_timesteps  | 494617   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.46e-05 |
|    n_updates        | 113654   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21624    |
|    fps              | 132      |
|    time_elapsed     | 3740     |
|    total_timesteps  | 494917   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000427 |
|    n_updates        | 113729   |
----------------------------------
Eval num_timesteps=495000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 495000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000172 |
|    n_updates        | 113749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21628    |
|    fps              | 132      |
|    time_elapsed     | 3745     |
|    total_timesteps  | 495217   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.03e-05 |
|    n_updates        | 113804   |
----------------------------------
Eval num_timesteps=495500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 495500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000331 |
|    n_updates        | 113874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21632    |
|    fps              | 132      |
|    time_elapsed     | 3751     |
|    total_timesteps  | 495517   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000859 |
|    n_updates        | 113879   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21636    |
|    fps              | 132      |
|    time_elapsed     | 3751     |
|    total_timesteps  | 495817   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00034  |
|    n_updates        | 113954   |
----------------------------------
Eval num_timesteps=496000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 496000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.82e-05 |
|    n_updates        | 113999   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21640    |
|    fps              | 132      |
|    time_elapsed     | 3756     |
|    total_timesteps  | 496117   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000754 |
|    n_updates        | 114029   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | -0.299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21644    |
|    fps              | 132      |
|    time_elapsed     | 3757     |
|    total_timesteps  | 496417   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.25e-05 |
|    n_updates        | 114104   |
----------------------------------
Eval num_timesteps=496500, episode_reward=-0.30 +/- 0.01
Episode length: 74.78 +/- 1.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.8     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 496500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.39e-05 |
|    n_updates        | 114124   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21648    |
|    fps              | 132      |
|    time_elapsed     | 3762     |
|    total_timesteps  | 496717   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000172 |
|    n_updates        | 114179   |
----------------------------------
Eval num_timesteps=497000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 497000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000227 |
|    n_updates        | 114249   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21652    |
|    fps              | 131      |
|    time_elapsed     | 3767     |
|    total_timesteps  | 497017   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.21e-05 |
|    n_updates        | 114254   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21656    |
|    fps              | 131      |
|    time_elapsed     | 3768     |
|    total_timesteps  | 497317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000454 |
|    n_updates        | 114329   |
----------------------------------
Eval num_timesteps=497500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 497500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.22e-05 |
|    n_updates        | 114374   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21660    |
|    fps              | 131      |
|    time_elapsed     | 3773     |
|    total_timesteps  | 497617   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000333 |
|    n_updates        | 114404   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21664    |
|    fps              | 131      |
|    time_elapsed     | 3774     |
|    total_timesteps  | 497917   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000608 |
|    n_updates        | 114479   |
----------------------------------
Eval num_timesteps=498000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 498000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000342 |
|    n_updates        | 114499   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21668    |
|    fps              | 131      |
|    time_elapsed     | 3779     |
|    total_timesteps  | 498217   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000358 |
|    n_updates        | 114554   |
----------------------------------
Eval num_timesteps=498500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 498500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.98e-05 |
|    n_updates        | 114624   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21672    |
|    fps              | 131      |
|    time_elapsed     | 3784     |
|    total_timesteps  | 498517   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.64e-05 |
|    n_updates        | 114629   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21676    |
|    fps              | 131      |
|    time_elapsed     | 3785     |
|    total_timesteps  | 498817   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000353 |
|    n_updates        | 114704   |
----------------------------------
Eval num_timesteps=499000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 499000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000109 |
|    n_updates        | 114749   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21680    |
|    fps              | 131      |
|    time_elapsed     | 3790     |
|    total_timesteps  | 499117   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.59e-05 |
|    n_updates        | 114779   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21684    |
|    fps              | 131      |
|    time_elapsed     | 3791     |
|    total_timesteps  | 499417   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00119  |
|    n_updates        | 114854   |
----------------------------------
Eval num_timesteps=499500, episode_reward=-0.30 +/- 0.02
Episode length: 74.10 +/- 3.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.1     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 499500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.28e-05 |
|    n_updates        | 114874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | -0.3     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 21688    |
|    fps              | 131      |
|    time_elapsed     | 3796     |
|    total_timesteps  | 499717   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000399 |
|    n_updates        | 114929   |
----------------------------------
Eval num_timesteps=500000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 500000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000268 |
|    n_updates        | 114999   |
----------------------------------
/home/miguelvilla/anaconda3/envs/doom/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'trains/predict-position/dqn-6/saves' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
/home/miguelvilla/anaconda3/envs/doom/lib/python3.12/site-packages/vizdoom/gymnasium_wrapper/base_gymnasium_env.py:84: UserWarning: Detected screen format CRCGCB. Only RGB24 and GRAY8 are supported in the Gymnasium wrapper. Forcing RGB24.
  warnings.warn(
Using cuda device
Eval num_timesteps=500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 500      |
---------------------------------
New best mean reward!
Eval num_timesteps=1000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 1000     |
---------------------------------
Eval num_timesteps=1500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 1500     |
---------------------------------
Eval num_timesteps=2000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 2000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.6     |
|    ep_rew_mean     | 0.0505   |
| time/              |          |
|    fps             | 66       |
|    iterations      | 1        |
|    time_elapsed    | 30       |
|    total_timesteps | 2048     |
---------------------------------
Eval num_timesteps=2500, episode_reward=0.04 +/- 0.30
Episode length: 15.70 +/- 0.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 15.7        |
|    mean_reward          | 0.0383      |
| time/                   |             |
|    total_timesteps      | 2500        |
| train/                  |             |
|    approx_kl            | 0.012890431 |
|    clip_fraction        | 0.0264      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | -0.125      |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0262      |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00494    |
|    value_loss           | 0.0465      |
-----------------------------------------
New best mean reward!
Eval num_timesteps=3000, episode_reward=0.08 +/- 0.35
Episode length: 15.52 +/- 1.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 15.5     |
|    mean_reward     | 0.079    |
| time/              |          |
|    total_timesteps | 3000     |
---------------------------------
New best mean reward!
Eval num_timesteps=3500, episode_reward=0.08 +/- 0.35
Episode length: 15.50 +/- 1.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 15.5     |
|    mean_reward     | 0.0791   |
| time/              |          |
|    total_timesteps | 3500     |
---------------------------------
New best mean reward!
Eval num_timesteps=4000, episode_reward=-0.04 +/- 0.14
Episode length: 15.92 +/- 0.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 15.9     |
|    mean_reward     | -0.0426  |
| time/              |          |
|    total_timesteps | 4000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 0.00138  |
| time/              |          |
|    fps             | 91       |
|    iterations      | 2        |
|    time_elapsed    | 44       |
|    total_timesteps | 4096     |
---------------------------------
Eval num_timesteps=4500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 4500        |
| train/                  |             |
|    approx_kl            | 0.011092419 |
|    clip_fraction        | 0.0485      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.36       |
|    explained_variance   | -0.162      |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0243      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00434    |
|    value_loss           | 0.0315      |
-----------------------------------------
Eval num_timesteps=5000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 5000     |
---------------------------------
Eval num_timesteps=5500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 5500     |
---------------------------------
Eval num_timesteps=6000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 6000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.2     |
|    ep_rew_mean     | -0.00761 |
| time/              |          |
|    fps             | 77       |
|    iterations      | 3        |
|    time_elapsed    | 79       |
|    total_timesteps | 6144     |
---------------------------------
Eval num_timesteps=6500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 6500        |
| train/                  |             |
|    approx_kl            | 0.008404786 |
|    clip_fraction        | 0.0559      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -0.0344     |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00777    |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00766    |
|    value_loss           | 0.0228      |
-----------------------------------------
Eval num_timesteps=7000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 7000     |
---------------------------------
Eval num_timesteps=7500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 7500     |
---------------------------------
Eval num_timesteps=8000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 8000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.8     |
|    ep_rew_mean     | 0.0539   |
| time/              |          |
|    fps             | 72       |
|    iterations      | 4        |
|    time_elapsed    | 112      |
|    total_timesteps | 8192     |
---------------------------------
Eval num_timesteps=8500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 8500        |
| train/                  |             |
|    approx_kl            | 0.008146308 |
|    clip_fraction        | 0.0925      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.00705     |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0303      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.0402      |
-----------------------------------------
Eval num_timesteps=9000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 9000     |
---------------------------------
Eval num_timesteps=9500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 9500     |
---------------------------------
Eval num_timesteps=10000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | -0.00855 |
| time/              |          |
|    fps             | 69       |
|    iterations      | 5        |
|    time_elapsed    | 146      |
|    total_timesteps | 10240    |
---------------------------------
Eval num_timesteps=10500, episode_reward=-0.27 +/- 0.18
Episode length: 71.34 +/- 14.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 71.3        |
|    mean_reward          | -0.265      |
| time/                   |             |
|    total_timesteps      | 10500       |
| train/                  |             |
|    approx_kl            | 0.009527905 |
|    clip_fraction        | 0.0858      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -0.0672     |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0236     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0132     |
|    value_loss           | 0.0265      |
-----------------------------------------
Eval num_timesteps=11000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 11000    |
---------------------------------
Eval num_timesteps=11500, episode_reward=-0.25 +/- 0.25
Episode length: 72.48 +/- 12.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 72.5     |
|    mean_reward     | -0.25    |
| time/              |          |
|    total_timesteps | 11500    |
---------------------------------
Eval num_timesteps=12000, episode_reward=-0.27 +/- 0.18
Episode length: 72.52 +/- 12.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 72.5     |
|    mean_reward     | -0.27    |
| time/              |          |
|    total_timesteps | 12000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 0.00138  |
| time/              |          |
|    fps             | 68       |
|    iterations      | 6        |
|    time_elapsed    | 180      |
|    total_timesteps | 12288    |
---------------------------------
Eval num_timesteps=12500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 12500       |
| train/                  |             |
|    approx_kl            | 0.009804374 |
|    clip_fraction        | 0.0917      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.35       |
|    explained_variance   | -0.0607     |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00204     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.025       |
-----------------------------------------
Eval num_timesteps=13000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 13000    |
---------------------------------
Eval num_timesteps=13500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 13500    |
---------------------------------
Eval num_timesteps=14000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 14000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.1     |
|    ep_rew_mean     | 0.0228   |
| time/              |          |
|    fps             | 66       |
|    iterations      | 7        |
|    time_elapsed    | 214      |
|    total_timesteps | 14336    |
---------------------------------
Eval num_timesteps=14500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 14500       |
| train/                  |             |
|    approx_kl            | 0.010246351 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -0.0501     |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0368     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.0275      |
-----------------------------------------
Eval num_timesteps=15000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 15000    |
---------------------------------
Eval num_timesteps=15500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 15500    |
---------------------------------
Eval num_timesteps=16000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 16000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.6     |
|    ep_rew_mean     | 0.0206   |
| time/              |          |
|    fps             | 66       |
|    iterations      | 8        |
|    time_elapsed    | 247      |
|    total_timesteps | 16384    |
---------------------------------
Eval num_timesteps=16500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 16500       |
| train/                  |             |
|    approx_kl            | 0.010814723 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | -0.184      |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00293    |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 0.0324      |
-----------------------------------------
Eval num_timesteps=17000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 17000    |
---------------------------------
Eval num_timesteps=17500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 17500    |
---------------------------------
Eval num_timesteps=18000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 18000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.7     |
|    ep_rew_mean     | 0.00026  |
| time/              |          |
|    fps             | 65       |
|    iterations      | 9        |
|    time_elapsed    | 279      |
|    total_timesteps | 18432    |
---------------------------------
Eval num_timesteps=18500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 18500       |
| train/                  |             |
|    approx_kl            | 0.012570372 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | -0.109      |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00786     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0147     |
|    value_loss           | 0.0238      |
-----------------------------------------
Eval num_timesteps=19000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 19000    |
---------------------------------
Eval num_timesteps=19500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 19500    |
---------------------------------
Eval num_timesteps=20000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 20000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18       |
|    ep_rew_mean     | 0.0192   |
| time/              |          |
|    fps             | 65       |
|    iterations      | 10       |
|    time_elapsed    | 313      |
|    total_timesteps | 20480    |
---------------------------------
Eval num_timesteps=20500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 75         |
|    mean_reward          | -0.3       |
| time/                   |            |
|    total_timesteps      | 20500      |
| train/                  |            |
|    approx_kl            | 0.01219894 |
|    clip_fraction        | 0.141      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.26      |
|    explained_variance   | -0.0164    |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0212    |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.0172    |
|    value_loss           | 0.0335     |
----------------------------------------
Eval num_timesteps=21000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 21000    |
---------------------------------
Eval num_timesteps=21500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 21500    |
---------------------------------
Eval num_timesteps=22000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 22000    |
---------------------------------
Eval num_timesteps=22500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 22500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.9     |
|    ep_rew_mean     | -0.0504  |
| time/              |          |
|    fps             | 63       |
|    iterations      | 11       |
|    time_elapsed    | 352      |
|    total_timesteps | 22528    |
---------------------------------
Eval num_timesteps=23000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 23000       |
| train/                  |             |
|    approx_kl            | 0.013156032 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.387      |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0142     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0152     |
|    value_loss           | 0.0101      |
-----------------------------------------
Eval num_timesteps=23500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 23500    |
---------------------------------
Eval num_timesteps=24000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 24000    |
---------------------------------
Eval num_timesteps=24500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 24500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.6     |
|    ep_rew_mean     | 0.0104   |
| time/              |          |
|    fps             | 63       |
|    iterations      | 12       |
|    time_elapsed    | 384      |
|    total_timesteps | 24576    |
---------------------------------
Eval num_timesteps=25000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 25000       |
| train/                  |             |
|    approx_kl            | 0.009027909 |
|    clip_fraction        | 0.0742      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | 0.0028      |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0199     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0127     |
|    value_loss           | 0.0284      |
-----------------------------------------
Eval num_timesteps=25500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 25500    |
---------------------------------
Eval num_timesteps=26000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 26000    |
---------------------------------
Eval num_timesteps=26500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 26500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.5     |
|    ep_rew_mean     | 0.0071   |
| time/              |          |
|    fps             | 63       |
|    iterations      | 13       |
|    time_elapsed    | 418      |
|    total_timesteps | 26624    |
---------------------------------
Eval num_timesteps=27000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 27000       |
| train/                  |             |
|    approx_kl            | 0.014040938 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | -0.0716     |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000656    |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0168     |
|    value_loss           | 0.0343      |
-----------------------------------------
Eval num_timesteps=27500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 27500    |
---------------------------------
Eval num_timesteps=28000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 28000    |
---------------------------------
Eval num_timesteps=28500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 28500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.7     |
|    ep_rew_mean     | 0.0202   |
| time/              |          |
|    fps             | 63       |
|    iterations      | 14       |
|    time_elapsed    | 452      |
|    total_timesteps | 28672    |
---------------------------------
Eval num_timesteps=29000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 29000       |
| train/                  |             |
|    approx_kl            | 0.011444463 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.2        |
|    explained_variance   | -0.0613     |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0035      |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0172     |
|    value_loss           | 0.0348      |
-----------------------------------------
Eval num_timesteps=29500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 29500    |
---------------------------------
Eval num_timesteps=30000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 30000    |
---------------------------------
Eval num_timesteps=30500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 30500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.5     |
|    ep_rew_mean     | 0.0171   |
| time/              |          |
|    fps             | 63       |
|    iterations      | 15       |
|    time_elapsed    | 487      |
|    total_timesteps | 30720    |
---------------------------------
Eval num_timesteps=31000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 31000       |
| train/                  |             |
|    approx_kl            | 0.013009391 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | -0.11       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.011       |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0161     |
|    value_loss           | 0.0334      |
-----------------------------------------
Eval num_timesteps=31500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 31500    |
---------------------------------
Eval num_timesteps=32000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 32000    |
---------------------------------
Eval num_timesteps=32500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 32500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | -0.0135  |
| time/              |          |
|    fps             | 62       |
|    iterations      | 16       |
|    time_elapsed    | 521      |
|    total_timesteps | 32768    |
---------------------------------
Eval num_timesteps=33000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 75           |
|    mean_reward          | -0.3         |
| time/                   |              |
|    total_timesteps      | 33000        |
| train/                  |              |
|    approx_kl            | 0.0105397925 |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.0487      |
|    learning_rate        | 0.0001       |
|    loss                 | -0.014       |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.0155      |
|    value_loss           | 0.0237       |
------------------------------------------
Eval num_timesteps=33500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 33500    |
---------------------------------
Eval num_timesteps=34000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 34000    |
---------------------------------
Eval num_timesteps=34500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 34500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 0.0614   |
| time/              |          |
|    fps             | 62       |
|    iterations      | 17       |
|    time_elapsed    | 556      |
|    total_timesteps | 34816    |
---------------------------------
Eval num_timesteps=35000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 75         |
|    mean_reward          | -0.3       |
| time/                   |            |
|    total_timesteps      | 35000      |
| train/                  |            |
|    approx_kl            | 0.01445203 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.06      |
|    explained_variance   | 0.00526    |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0144    |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.0172    |
|    value_loss           | 0.0383     |
----------------------------------------
Eval num_timesteps=35500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 35500    |
---------------------------------
Eval num_timesteps=36000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 36000    |
---------------------------------
Eval num_timesteps=36500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 36500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 0.0113   |
| time/              |          |
|    fps             | 62       |
|    iterations      | 18       |
|    time_elapsed    | 591      |
|    total_timesteps | 36864    |
---------------------------------
Eval num_timesteps=37000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 37000       |
| train/                  |             |
|    approx_kl            | 0.009924673 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | -0.0852     |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0289     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.0253      |
-----------------------------------------
Eval num_timesteps=37500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 37500    |
---------------------------------
Eval num_timesteps=38000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 38000    |
---------------------------------
Eval num_timesteps=38500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 38500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.6     |
|    ep_rew_mean     | -0.00917 |
| time/              |          |
|    fps             | 62       |
|    iterations      | 19       |
|    time_elapsed    | 625      |
|    total_timesteps | 38912    |
---------------------------------
Eval num_timesteps=39000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | -0.3        |
| time/                   |             |
|    total_timesteps      | 39000       |
| train/                  |             |
|    approx_kl            | 0.012349065 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | -0.0152     |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0127     |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.0235      |
-----------------------------------------
Eval num_timesteps=39500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 39500    |
---------------------------------
Eval num_timesteps=40000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 40000    |
---------------------------------
Eval num_timesteps=40500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 40500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.3     |
|    ep_rew_mean     | -0.0121  |
| time/              |          |
|    fps             | 61       |
|    iterations      | 20       |
|    time_elapsed    | 661      |
|    total_timesteps | 40960    |
---------------------------------
Eval num_timesteps=41000, episode_reward=-0.26 +/- 0.15
Episode length: 69.76 +/- 14.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 69.8        |
|    mean_reward          | -0.259      |
| time/                   |             |
|    total_timesteps      | 41000       |
| train/                  |             |
|    approx_kl            | 0.011017514 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | -0.161      |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0146     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 0.0256      |
-----------------------------------------
Eval num_timesteps=41500, episode_reward=-0.27 +/- 0.16
Episode length: 71.54 +/- 12.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 71.5     |
|    mean_reward     | -0.266   |
| time/              |          |
|    total_timesteps | 41500    |
---------------------------------
Eval num_timesteps=42000, episode_reward=-0.26 +/- 0.15
Episode length: 69.44 +/- 14.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 69.4     |
|    mean_reward     | -0.258   |
| time/              |          |
|    total_timesteps | 42000    |
---------------------------------
Eval num_timesteps=42500, episode_reward=-0.28 +/- 0.06
Episode length: 69.44 +/- 15.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 69.4     |
|    mean_reward     | -0.278   |
| time/              |          |
|    total_timesteps | 42500    |
---------------------------------
Eval num_timesteps=43000, episode_reward=-0.29 +/- 0.03
Episode length: 73.16 +/- 6.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 73.2     |
|    mean_reward     | -0.293   |
| time/              |          |
|    total_timesteps | 43000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.6     |
|    ep_rew_mean     | -0.00913 |
| time/              |          |
|    fps             | 61       |
|    iterations      | 21       |
|    time_elapsed    | 701      |
|    total_timesteps | 43008    |
---------------------------------
Eval num_timesteps=43500, episode_reward=-0.21 +/- 0.27
Episode length: 66.70 +/- 17.24
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 66.7       |
|    mean_reward          | -0.207     |
| time/                   |            |
|    total_timesteps      | 43500      |
| train/                  |            |
|    approx_kl            | 0.01169117 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.03      |
|    explained_variance   | -0.0454    |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0178    |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.0155    |
|    value_loss           | 0.0285     |
----------------------------------------
Eval num_timesteps=44000, episode_reward=-0.25 +/- 0.16
Episode length: 68.70 +/- 15.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 68.7     |
|    mean_reward     | -0.255   |
| time/              |          |
|    total_timesteps | 44000    |
---------------------------------
Eval num_timesteps=44500, episode_reward=-0.23 +/- 0.21
Episode length: 66.72 +/- 17.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 66.7     |
|    mean_reward     | -0.227   |
| time/              |          |
|    total_timesteps | 44500    |
---------------------------------
Eval num_timesteps=45000, episode_reward=-0.20 +/- 0.27
Episode length: 64.60 +/- 18.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 64.6     |
|    mean_reward     | -0.198   |
| time/              |          |
|    total_timesteps | 45000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 0.0413   |
| time/              |          |
|    fps             | 61       |
|    iterations      | 22       |
|    time_elapsed    | 734      |
|    total_timesteps | 45056    |
---------------------------------
Eval num_timesteps=45500, episode_reward=-0.19 +/- 0.22
Episode length: 57.50 +/- 20.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 57.5        |
|    mean_reward          | -0.189      |
| time/                   |             |
|    total_timesteps      | 45500       |
| train/                  |             |
|    approx_kl            | 0.008745265 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.0215      |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0119      |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0104     |
|    value_loss           | 0.0356      |
-----------------------------------------
Eval num_timesteps=46000, episode_reward=-0.16 +/- 0.22
Episode length: 50.84 +/- 23.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 50.8     |
|    mean_reward     | -0.163   |
| time/              |          |
|    total_timesteps | 46000    |
---------------------------------
Eval num_timesteps=46500, episode_reward=-0.09 +/- 0.32
Episode length: 48.12 +/- 21.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 48.1     |
|    mean_reward     | -0.0917  |
| time/              |          |
|    total_timesteps | 46500    |
---------------------------------
Eval num_timesteps=47000, episode_reward=-0.18 +/- 0.22
Episode length: 54.60 +/- 22.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 54.6     |
|    mean_reward     | -0.178   |
| time/              |          |
|    total_timesteps | 47000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17       |
|    ep_rew_mean     | -0.00704 |
| time/              |          |
|    fps             | 61       |
|    iterations      | 23       |
|    time_elapsed    | 761      |
|    total_timesteps | 47104    |
---------------------------------
Eval num_timesteps=47500, episode_reward=-0.14 +/- 0.22
Episode length: 44.02 +/- 24.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 44          |
|    mean_reward          | -0.135      |
| time/                   |             |
|    total_timesteps      | 47500       |
| train/                  |             |
|    approx_kl            | 0.015849974 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.987      |
|    explained_variance   | -0.0354     |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0237     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0152     |
|    value_loss           | 0.025       |
-----------------------------------------
Eval num_timesteps=48000, episode_reward=-0.11 +/- 0.32
Episode length: 53.38 +/- 22.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 53.4     |
|    mean_reward     | -0.113   |
| time/              |          |
|    total_timesteps | 48000    |
---------------------------------
Eval num_timesteps=48500, episode_reward=-0.13 +/- 0.29
Episode length: 53.04 +/- 22.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 53       |
|    mean_reward     | -0.131   |
| time/              |          |
|    total_timesteps | 48500    |
---------------------------------
Eval num_timesteps=49000, episode_reward=-0.17 +/- 0.17
Episode length: 48.46 +/- 23.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 48.5     |
|    mean_reward     | -0.173   |
| time/              |          |
|    total_timesteps | 49000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | -0.00846 |
| time/              |          |
|    fps             | 62       |
|    iterations      | 24       |
|    time_elapsed    | 788      |
|    total_timesteps | 49152    |
---------------------------------
Eval num_timesteps=49500, episode_reward=-0.19 +/- 0.23
Episode length: 57.94 +/- 24.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.9       |
|    mean_reward          | -0.191     |
| time/                   |            |
|    total_timesteps      | 49500      |
| train/                  |            |
|    approx_kl            | 0.01623412 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.896     |
|    explained_variance   | 0.0203     |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00888    |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.0135    |
|    value_loss           | 0.0227     |
----------------------------------------
Eval num_timesteps=50000, episode_reward=-0.18 +/- 0.22
Episode length: 56.04 +/- 21.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 56       |
|    mean_reward     | -0.184   |
| time/              |          |
|    total_timesteps | 50000    |
---------------------------------
Eval num_timesteps=50500, episode_reward=-0.22 +/- 0.18
Episode length: 59.20 +/- 22.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 59.2     |
|    mean_reward     | -0.216   |
| time/              |          |
|    total_timesteps | 50500    |
---------------------------------
Eval num_timesteps=51000, episode_reward=-0.18 +/- 0.22
Episode length: 54.62 +/- 22.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 54.6     |
|    mean_reward     | -0.178   |
| time/              |          |
|    total_timesteps | 51000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 0.0368   |
| time/              |          |
|    fps             | 62       |
|    iterations      | 25       |
|    time_elapsed    | 817      |
|    total_timesteps | 51200    |
---------------------------------
Eval num_timesteps=51500, episode_reward=0.08 +/- 0.48
Episode length: 44.20 +/- 22.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 44.2        |
|    mean_reward          | 0.0842      |
| time/                   |             |
|    total_timesteps      | 51500       |
| train/                  |             |
|    approx_kl            | 0.013641803 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.821      |
|    explained_variance   | 0.115       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0205     |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0143     |
|    value_loss           | 0.0368      |
-----------------------------------------
New best mean reward!
Eval num_timesteps=52000, episode_reward=0.05 +/- 0.45
Episode length: 47.18 +/- 21.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 47.2     |
|    mean_reward     | 0.052    |
| time/              |          |
|    total_timesteps | 52000    |
---------------------------------
Eval num_timesteps=52500, episode_reward=-0.06 +/- 0.36
Episode length: 46.36 +/- 23.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 46.4     |
|    mean_reward     | -0.0647  |
| time/              |          |
|    total_timesteps | 52500    |
---------------------------------
Eval num_timesteps=53000, episode_reward=0.12 +/- 0.49
Episode length: 44.52 +/- 20.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 44.5     |
|    mean_reward     | 0.123    |
| time/              |          |
|    total_timesteps | 53000    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.8     |
|    ep_rew_mean     | 0.0699   |
| time/              |          |
|    fps             | 63       |
|    iterations      | 26       |
|    time_elapsed    | 843      |
|    total_timesteps | 53248    |
---------------------------------
Eval num_timesteps=53500, episode_reward=0.06 +/- 0.48
Episode length: 45.24 +/- 22.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 45.2        |
|    mean_reward          | 0.06        |
| time/                   |             |
|    total_timesteps      | 53500       |
| train/                  |             |
|    approx_kl            | 0.014083393 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.804      |
|    explained_variance   | 0.0883      |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00523    |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0127     |
|    value_loss           | 0.0446      |
-----------------------------------------
Eval num_timesteps=54000, episode_reward=-0.06 +/- 0.38
Episode length: 50.22 +/- 20.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 50.2     |
|    mean_reward     | -0.0602  |
| time/              |          |
|    total_timesteps | 54000    |
---------------------------------
Eval num_timesteps=54500, episode_reward=0.10 +/- 0.51
Episode length: 45.24 +/- 23.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 45.2     |
|    mean_reward     | 0.0998   |
| time/              |          |
|    total_timesteps | 54500    |
---------------------------------
Eval num_timesteps=55000, episode_reward=0.01 +/- 0.45
Episode length: 48.62 +/- 21.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 48.6     |
|    mean_reward     | 0.0063   |
| time/              |          |
|    total_timesteps | 55000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 0.0568   |
| time/              |          |
|    fps             | 63       |
|    iterations      | 27       |
|    time_elapsed    | 869      |
|    total_timesteps | 55296    |
---------------------------------
Eval num_timesteps=55500, episode_reward=0.02 +/- 0.47
Episode length: 49.68 +/- 23.83
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 49.7        |
|    mean_reward          | 0.022       |
| time/                   |             |
|    total_timesteps      | 55500       |
| train/                  |             |
|    approx_kl            | 0.010312758 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.772      |
|    explained_variance   | 0.0922      |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00525    |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0107     |
|    value_loss           | 0.0418      |
-----------------------------------------
Eval num_timesteps=56000, episode_reward=0.05 +/- 0.48
Episode length: 46.74 +/- 23.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 46.7     |
|    mean_reward     | 0.0538   |
| time/              |          |
|    total_timesteps | 56000    |
---------------------------------
Eval num_timesteps=56500, episode_reward=-0.03 +/- 0.41
Episode length: 48.62 +/- 22.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 48.6     |
|    mean_reward     | -0.0337  |
| time/              |          |
|    total_timesteps | 56500    |
---------------------------------
Eval num_timesteps=57000, episode_reward=0.03 +/- 0.47
Episode length: 52.00 +/- 21.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 52       |
|    mean_reward     | 0.0328   |
| time/              |          |
|    total_timesteps | 57000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.7     |
|    ep_rew_mean     | 0.056    |
| time/              |          |
|    fps             | 63       |
|    iterations      | 28       |
|    time_elapsed    | 896      |
|    total_timesteps | 57344    |
---------------------------------
Eval num_timesteps=57500, episode_reward=0.12 +/- 0.50
Episode length: 44.48 +/- 21.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 44.5        |
|    mean_reward          | 0.123       |
| time/                   |             |
|    total_timesteps      | 57500       |
| train/                  |             |
|    approx_kl            | 0.011046705 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.713      |
|    explained_variance   | 0.0537      |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0141      |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0103     |
|    value_loss           | 0.0398      |
-----------------------------------------
Eval num_timesteps=58000, episode_reward=0.09 +/- 0.50
Episode length: 43.60 +/- 22.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 43.6     |
|    mean_reward     | 0.0865   |
| time/              |          |
|    total_timesteps | 58000    |
---------------------------------
Eval num_timesteps=58500, episode_reward=0.02 +/- 0.44
Episode length: 45.90 +/- 22.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 45.9     |
|    mean_reward     | 0.0174   |
| time/              |          |
|    total_timesteps | 58500    |
---------------------------------
Eval num_timesteps=59000, episode_reward=0.15 +/- 0.52
Episode length: 48.74 +/- 22.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 48.7     |
|    mean_reward     | 0.146    |
| time/              |          |
|    total_timesteps | 59000    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 0.129    |
| time/              |          |
|    fps             | 64       |
|    iterations      | 29       |
|    time_elapsed    | 921      |
|    total_timesteps | 59392    |
---------------------------------
Eval num_timesteps=59500, episode_reward=0.20 +/- 0.53
Episode length: 41.38 +/- 21.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.4        |
|    mean_reward          | 0.196       |
| time/                   |             |
|    total_timesteps      | 59500       |
| train/                  |             |
|    approx_kl            | 0.009079855 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.657      |
|    explained_variance   | 0.186       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0102      |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.012      |
|    value_loss           | 0.0552      |
-----------------------------------------
New best mean reward!
Eval num_timesteps=60000, episode_reward=0.09 +/- 0.48
Episode length: 41.98 +/- 21.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 42       |
|    mean_reward     | 0.0932   |
| time/              |          |
|    total_timesteps | 60000    |
---------------------------------
Eval num_timesteps=60500, episode_reward=0.15 +/- 0.49
Episode length: 38.78 +/- 19.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 38.8     |
|    mean_reward     | 0.146    |
| time/              |          |
|    total_timesteps | 60500    |
---------------------------------
Eval num_timesteps=61000, episode_reward=0.13 +/- 0.50
Episode length: 41.58 +/- 22.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 41.6     |
|    mean_reward     | 0.135    |
| time/              |          |
|    total_timesteps | 61000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.5     |
|    ep_rew_mean     | 0.0933   |
| time/              |          |
|    fps             | 65       |
|    iterations      | 30       |
|    time_elapsed    | 945      |
|    total_timesteps | 61440    |
---------------------------------
Eval num_timesteps=61500, episode_reward=0.12 +/- 0.52
Episode length: 44.92 +/- 22.44
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 44.9        |
|    mean_reward          | 0.121       |
| time/                   |             |
|    total_timesteps      | 61500       |
| train/                  |             |
|    approx_kl            | 0.012067044 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.67       |
|    explained_variance   | 0.191       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00869    |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0138     |
|    value_loss           | 0.0471      |
-----------------------------------------
Eval num_timesteps=62000, episode_reward=0.12 +/- 0.48
Episode length: 40.92 +/- 20.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 40.9     |
|    mean_reward     | 0.117    |
| time/              |          |
|    total_timesteps | 62000    |
---------------------------------
Eval num_timesteps=62500, episode_reward=0.18 +/- 0.52
Episode length: 40.06 +/- 22.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 40.1     |
|    mean_reward     | 0.181    |
| time/              |          |
|    total_timesteps | 62500    |
---------------------------------
Eval num_timesteps=63000, episode_reward=0.13 +/- 0.50
Episode length: 41.70 +/- 20.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 41.7     |
|    mean_reward     | 0.134    |
| time/              |          |
|    total_timesteps | 63000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 0.113    |
| time/              |          |
|    fps             | 65       |
|    iterations      | 31       |
|    time_elapsed    | 968      |
|    total_timesteps | 63488    |
---------------------------------
Eval num_timesteps=63500, episode_reward=0.36 +/- 0.53
Episode length: 31.16 +/- 18.90
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.2        |
|    mean_reward          | 0.357       |
| time/                   |             |
|    total_timesteps      | 63500       |
| train/                  |             |
|    approx_kl            | 0.015434675 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.665      |
|    explained_variance   | 0.245       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0567      |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.0448      |
-----------------------------------------
New best mean reward!
Eval num_timesteps=64000, episode_reward=0.32 +/- 0.52
Episode length: 30.06 +/- 17.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.321    |
| time/              |          |
|    total_timesteps | 64000    |
---------------------------------
Eval num_timesteps=64500, episode_reward=0.41 +/- 0.52
Episode length: 28.14 +/- 16.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.1     |
|    mean_reward     | 0.409    |
| time/              |          |
|    total_timesteps | 64500    |
---------------------------------
New best mean reward!
Eval num_timesteps=65000, episode_reward=0.12 +/- 0.45
Episode length: 34.42 +/- 18.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.4     |
|    mean_reward     | 0.123    |
| time/              |          |
|    total_timesteps | 65000    |
---------------------------------
Eval num_timesteps=65500, episode_reward=0.22 +/- 0.50
Episode length: 35.06 +/- 19.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 35.1     |
|    mean_reward     | 0.221    |
| time/              |          |
|    total_timesteps | 65500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.1     |
|    ep_rew_mean     | 0.0985   |
| time/              |          |
|    fps             | 66       |
|    iterations      | 32       |
|    time_elapsed    | 991      |
|    total_timesteps | 65536    |
---------------------------------
Eval num_timesteps=66000, episode_reward=0.19 +/- 0.50
Episode length: 36.98 +/- 20.22
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 37          |
|    mean_reward          | 0.193       |
| time/                   |             |
|    total_timesteps      | 66000       |
| train/                  |             |
|    approx_kl            | 0.015365783 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.728      |
|    explained_variance   | 0.119       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00281    |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.0463      |
-----------------------------------------
Eval num_timesteps=66500, episode_reward=0.20 +/- 0.50
Episode length: 36.20 +/- 20.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 36.2     |
|    mean_reward     | 0.196    |
| time/              |          |
|    total_timesteps | 66500    |
---------------------------------
Eval num_timesteps=67000, episode_reward=0.22 +/- 0.50
Episode length: 29.32 +/- 16.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.224    |
| time/              |          |
|    total_timesteps | 67000    |
---------------------------------
Eval num_timesteps=67500, episode_reward=0.37 +/- 0.52
Episode length: 31.62 +/- 15.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.6     |
|    mean_reward     | 0.375    |
| time/              |          |
|    total_timesteps | 67500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19       |
|    ep_rew_mean     | 0.0951   |
| time/              |          |
|    fps             | 66       |
|    iterations      | 33       |
|    time_elapsed    | 1012     |
|    total_timesteps | 67584    |
---------------------------------
Eval num_timesteps=68000, episode_reward=0.14 +/- 0.47
Episode length: 34.10 +/- 19.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 34.1        |
|    mean_reward          | 0.145       |
| time/                   |             |
|    total_timesteps      | 68000       |
| train/                  |             |
|    approx_kl            | 0.014663095 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.714      |
|    explained_variance   | 0.152       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0156     |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0104     |
|    value_loss           | 0.0453      |
-----------------------------------------
Eval num_timesteps=68500, episode_reward=0.34 +/- 0.51
Episode length: 30.08 +/- 16.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.341    |
| time/              |          |
|    total_timesteps | 68500    |
---------------------------------
Eval num_timesteps=69000, episode_reward=0.34 +/- 0.53
Episode length: 30.66 +/- 19.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.7     |
|    mean_reward     | 0.338    |
| time/              |          |
|    total_timesteps | 69000    |
---------------------------------
Eval num_timesteps=69500, episode_reward=0.17 +/- 0.47
Episode length: 29.02 +/- 19.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29       |
|    mean_reward     | 0.165    |
| time/              |          |
|    total_timesteps | 69500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.9     |
|    ep_rew_mean     | 0.129    |
| time/              |          |
|    fps             | 67       |
|    iterations      | 34       |
|    time_elapsed    | 1032     |
|    total_timesteps | 69632    |
---------------------------------
Eval num_timesteps=70000, episode_reward=0.18 +/- 0.49
Episode length: 34.40 +/- 19.42
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 34.4        |
|    mean_reward          | 0.184       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.009513863 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | 0.293       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0203     |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.0468      |
-----------------------------------------
Eval num_timesteps=70500, episode_reward=0.22 +/- 0.50
Episode length: 29.56 +/- 19.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.6     |
|    mean_reward     | 0.223    |
| time/              |          |
|    total_timesteps | 70500    |
---------------------------------
Eval num_timesteps=71000, episode_reward=0.28 +/- 0.50
Episode length: 29.56 +/- 19.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.6     |
|    mean_reward     | 0.283    |
| time/              |          |
|    total_timesteps | 71000    |
---------------------------------
Eval num_timesteps=71500, episode_reward=0.32 +/- 0.50
Episode length: 26.50 +/- 13.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.315    |
| time/              |          |
|    total_timesteps | 71500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.5     |
|    ep_rew_mean     | 0.107    |
| time/              |          |
|    fps             | 68       |
|    iterations      | 35       |
|    time_elapsed    | 1052     |
|    total_timesteps | 71680    |
---------------------------------
Eval num_timesteps=72000, episode_reward=0.25 +/- 0.52
Episode length: 32.56 +/- 18.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.6        |
|    mean_reward          | 0.251       |
| time/                   |             |
|    total_timesteps      | 72000       |
| train/                  |             |
|    approx_kl            | 0.014676085 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | 0.188       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00884     |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00954    |
|    value_loss           | 0.0475      |
-----------------------------------------
Eval num_timesteps=72500, episode_reward=0.38 +/- 0.52
Episode length: 30.26 +/- 17.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.38     |
| time/              |          |
|    total_timesteps | 72500    |
---------------------------------
Eval num_timesteps=73000, episode_reward=0.23 +/- 0.52
Episode length: 38.28 +/- 20.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 38.3     |
|    mean_reward     | 0.228    |
| time/              |          |
|    total_timesteps | 73000    |
---------------------------------
Eval num_timesteps=73500, episode_reward=0.33 +/- 0.53
Episode length: 37.36 +/- 19.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 37.4     |
|    mean_reward     | 0.332    |
| time/              |          |
|    total_timesteps | 73500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.9     |
|    ep_rew_mean     | 0.165    |
| time/              |          |
|    fps             | 68       |
|    iterations      | 36       |
|    time_elapsed    | 1073     |
|    total_timesteps | 73728    |
---------------------------------
Eval num_timesteps=74000, episode_reward=0.37 +/- 0.54
Episode length: 32.86 +/- 20.33
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.9        |
|    mean_reward          | 0.369       |
| time/                   |             |
|    total_timesteps      | 74000       |
| train/                  |             |
|    approx_kl            | 0.013466932 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.589      |
|    explained_variance   | 0.395       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0216     |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0134     |
|    value_loss           | 0.0484      |
-----------------------------------------
Eval num_timesteps=74500, episode_reward=0.20 +/- 0.52
Episode length: 39.92 +/- 22.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 39.9     |
|    mean_reward     | 0.201    |
| time/              |          |
|    total_timesteps | 74500    |
---------------------------------
Eval num_timesteps=75000, episode_reward=0.16 +/- 0.49
Episode length: 34.78 +/- 21.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.8     |
|    mean_reward     | 0.162    |
| time/              |          |
|    total_timesteps | 75000    |
---------------------------------
Eval num_timesteps=75500, episode_reward=0.30 +/- 0.54
Episode length: 39.18 +/- 21.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 39.2     |
|    mean_reward     | 0.304    |
| time/              |          |
|    total_timesteps | 75500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 0.179    |
| time/              |          |
|    fps             | 69       |
|    iterations      | 37       |
|    time_elapsed    | 1095     |
|    total_timesteps | 75776    |
---------------------------------
Eval num_timesteps=76000, episode_reward=0.29 +/- 0.53
Episode length: 33.50 +/- 21.88
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.5        |
|    mean_reward          | 0.287       |
| time/                   |             |
|    total_timesteps      | 76000       |
| train/                  |             |
|    approx_kl            | 0.009976578 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.571      |
|    explained_variance   | 0.413       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0153     |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0103     |
|    value_loss           | 0.0537      |
-----------------------------------------
Eval num_timesteps=76500, episode_reward=0.38 +/- 0.53
Episode length: 35.98 +/- 18.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 36       |
|    mean_reward     | 0.377    |
| time/              |          |
|    total_timesteps | 76500    |
---------------------------------
Eval num_timesteps=77000, episode_reward=0.13 +/- 0.45
Episode length: 31.70 +/- 18.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.7     |
|    mean_reward     | 0.134    |
| time/              |          |
|    total_timesteps | 77000    |
---------------------------------
Eval num_timesteps=77500, episode_reward=0.19 +/- 0.51
Episode length: 36.64 +/- 21.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 36.6     |
|    mean_reward     | 0.194    |
| time/              |          |
|    total_timesteps | 77500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.5     |
|    ep_rew_mean     | 0.0833   |
| time/              |          |
|    fps             | 69       |
|    iterations      | 38       |
|    time_elapsed    | 1115     |
|    total_timesteps | 77824    |
---------------------------------
Eval num_timesteps=78000, episode_reward=0.37 +/- 0.51
Episode length: 33.18 +/- 18.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.2        |
|    mean_reward          | 0.368       |
| time/                   |             |
|    total_timesteps      | 78000       |
| train/                  |             |
|    approx_kl            | 0.015693046 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.558      |
|    explained_variance   | 0.417       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.003      |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00832    |
|    value_loss           | 0.0399      |
-----------------------------------------
Eval num_timesteps=78500, episode_reward=0.24 +/- 0.51
Episode length: 30.94 +/- 19.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.9     |
|    mean_reward     | 0.238    |
| time/              |          |
|    total_timesteps | 78500    |
---------------------------------
Eval num_timesteps=79000, episode_reward=0.27 +/- 0.51
Episode length: 32.26 +/- 16.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.3     |
|    mean_reward     | 0.272    |
| time/              |          |
|    total_timesteps | 79000    |
---------------------------------
Eval num_timesteps=79500, episode_reward=0.22 +/- 0.48
Episode length: 29.52 +/- 16.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.223    |
| time/              |          |
|    total_timesteps | 79500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.9     |
|    ep_rew_mean     | 0.145    |
| time/              |          |
|    fps             | 70       |
|    iterations      | 39       |
|    time_elapsed    | 1135     |
|    total_timesteps | 79872    |
---------------------------------
Eval num_timesteps=80000, episode_reward=0.36 +/- 0.52
Episode length: 31.16 +/- 15.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.2        |
|    mean_reward          | 0.357       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.012641078 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.562      |
|    explained_variance   | 0.373       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0317      |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0112     |
|    value_loss           | 0.0509      |
-----------------------------------------
Eval num_timesteps=80500, episode_reward=0.21 +/- 0.50
Episode length: 33.24 +/- 21.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.2     |
|    mean_reward     | 0.208    |
| time/              |          |
|    total_timesteps | 80500    |
---------------------------------
Eval num_timesteps=81000, episode_reward=0.34 +/- 0.51
Episode length: 31.42 +/- 17.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.336    |
| time/              |          |
|    total_timesteps | 81000    |
---------------------------------
Eval num_timesteps=81500, episode_reward=0.25 +/- 0.52
Episode length: 38.48 +/- 23.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 38.5     |
|    mean_reward     | 0.247    |
| time/              |          |
|    total_timesteps | 81500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.7     |
|    ep_rew_mean     | 0.162    |
| time/              |          |
|    fps             | 70       |
|    iterations      | 40       |
|    time_elapsed    | 1156     |
|    total_timesteps | 81920    |
---------------------------------
Eval num_timesteps=82000, episode_reward=0.32 +/- 0.52
Episode length: 34.24 +/- 18.67
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 34.2        |
|    mean_reward          | 0.324       |
| time/                   |             |
|    total_timesteps      | 82000       |
| train/                  |             |
|    approx_kl            | 0.014920592 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.476      |
|    explained_variance   | 0.525       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00278    |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00871    |
|    value_loss           | 0.0424      |
-----------------------------------------
Eval num_timesteps=82500, episode_reward=0.29 +/- 0.54
Episode length: 37.52 +/- 19.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 37.5     |
|    mean_reward     | 0.291    |
| time/              |          |
|    total_timesteps | 82500    |
---------------------------------
Eval num_timesteps=83000, episode_reward=0.19 +/- 0.50
Episode length: 33.86 +/- 19.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.9     |
|    mean_reward     | 0.186    |
| time/              |          |
|    total_timesteps | 83000    |
---------------------------------
Eval num_timesteps=83500, episode_reward=0.20 +/- 0.52
Episode length: 40.06 +/- 22.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 40.1     |
|    mean_reward     | 0.201    |
| time/              |          |
|    total_timesteps | 83500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23       |
|    ep_rew_mean     | 0.0989   |
| time/              |          |
|    fps             | 71       |
|    iterations      | 41       |
|    time_elapsed    | 1177     |
|    total_timesteps | 83968    |
---------------------------------
Eval num_timesteps=84000, episode_reward=0.34 +/- 0.52
Episode length: 30.06 +/- 16.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.341       |
| time/                   |             |
|    total_timesteps      | 84000       |
| train/                  |             |
|    approx_kl            | 0.010429025 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.446      |
|    explained_variance   | 0.384       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00978    |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00663    |
|    value_loss           | 0.0358      |
-----------------------------------------
Eval num_timesteps=84500, episode_reward=0.24 +/- 0.49
Episode length: 31.24 +/- 17.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.236    |
| time/              |          |
|    total_timesteps | 84500    |
---------------------------------
Eval num_timesteps=85000, episode_reward=0.34 +/- 0.53
Episode length: 29.22 +/- 17.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.344    |
| time/              |          |
|    total_timesteps | 85000    |
---------------------------------
Eval num_timesteps=85500, episode_reward=0.30 +/- 0.51
Episode length: 29.32 +/- 13.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.304    |
| time/              |          |
|    total_timesteps | 85500    |
---------------------------------
Eval num_timesteps=86000, episode_reward=0.15 +/- 0.47
Episode length: 31.60 +/- 16.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.6     |
|    mean_reward     | 0.155    |
| time/              |          |
|    total_timesteps | 86000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 0.156    |
| time/              |          |
|    fps             | 71       |
|    iterations      | 42       |
|    time_elapsed    | 1199     |
|    total_timesteps | 86016    |
---------------------------------
Eval num_timesteps=86500, episode_reward=0.34 +/- 0.52
Episode length: 29.50 +/- 18.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.5        |
|    mean_reward          | 0.343       |
| time/                   |             |
|    total_timesteps      | 86500       |
| train/                  |             |
|    approx_kl            | 0.016813122 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.44       |
|    explained_variance   | 0.406       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0179      |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.0492      |
-----------------------------------------
Eval num_timesteps=87000, episode_reward=0.35 +/- 0.51
Episode length: 28.56 +/- 16.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.347    |
| time/              |          |
|    total_timesteps | 87000    |
---------------------------------
Eval num_timesteps=87500, episode_reward=0.37 +/- 0.51
Episode length: 27.02 +/- 12.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.373    |
| time/              |          |
|    total_timesteps | 87500    |
---------------------------------
Eval num_timesteps=88000, episode_reward=0.36 +/- 0.52
Episode length: 31.38 +/- 16.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.356    |
| time/              |          |
|    total_timesteps | 88000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.9     |
|    ep_rew_mean     | 0.252    |
| time/              |          |
|    fps             | 72       |
|    iterations      | 43       |
|    time_elapsed    | 1219     |
|    total_timesteps | 88064    |
---------------------------------
Eval num_timesteps=88500, episode_reward=0.25 +/- 0.51
Episode length: 33.20 +/- 16.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.2        |
|    mean_reward          | 0.248       |
| time/                   |             |
|    total_timesteps      | 88500       |
| train/                  |             |
|    approx_kl            | 0.012208535 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.432      |
|    explained_variance   | 0.541       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00108    |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00829    |
|    value_loss           | 0.0517      |
-----------------------------------------
Eval num_timesteps=89000, episode_reward=0.44 +/- 0.53
Episode length: 35.06 +/- 18.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 35.1     |
|    mean_reward     | 0.441    |
| time/              |          |
|    total_timesteps | 89000    |
---------------------------------
New best mean reward!
Eval num_timesteps=89500, episode_reward=0.34 +/- 0.53
Episode length: 30.88 +/- 19.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.9     |
|    mean_reward     | 0.337    |
| time/              |          |
|    total_timesteps | 89500    |
---------------------------------
Eval num_timesteps=90000, episode_reward=0.31 +/- 0.51
Episode length: 33.34 +/- 18.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.3     |
|    mean_reward     | 0.308    |
| time/              |          |
|    total_timesteps | 90000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.6     |
|    ep_rew_mean     | 0.227    |
| time/              |          |
|    fps             | 72       |
|    iterations      | 44       |
|    time_elapsed    | 1240     |
|    total_timesteps | 90112    |
---------------------------------
Eval num_timesteps=90500, episode_reward=0.16 +/- 0.50
Episode length: 39.54 +/- 19.06
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 39.5         |
|    mean_reward          | 0.163        |
| time/                   |              |
|    total_timesteps      | 90500        |
| train/                  |              |
|    approx_kl            | 0.0154445395 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.325       |
|    explained_variance   | 0.335        |
|    learning_rate        | 0.0001       |
|    loss                 | 0.0115       |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00879     |
|    value_loss           | 0.0596       |
------------------------------------------
Eval num_timesteps=91000, episode_reward=0.35 +/- 0.51
Episode length: 32.84 +/- 15.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.8     |
|    mean_reward     | 0.35     |
| time/              |          |
|    total_timesteps | 91000    |
---------------------------------
Eval num_timesteps=91500, episode_reward=0.14 +/- 0.45
Episode length: 29.06 +/- 14.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.145    |
| time/              |          |
|    total_timesteps | 91500    |
---------------------------------
Eval num_timesteps=92000, episode_reward=0.27 +/- 0.50
Episode length: 33.80 +/- 18.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.8     |
|    mean_reward     | 0.266    |
| time/              |          |
|    total_timesteps | 92000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.3     |
|    ep_rew_mean     | 0.262    |
| time/              |          |
|    fps             | 73       |
|    iterations      | 45       |
|    time_elapsed    | 1261     |
|    total_timesteps | 92160    |
---------------------------------
Eval num_timesteps=92500, episode_reward=0.41 +/- 0.52
Episode length: 31.88 +/- 16.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.9        |
|    mean_reward          | 0.414       |
| time/                   |             |
|    total_timesteps      | 92500       |
| train/                  |             |
|    approx_kl            | 0.010537635 |
|    clip_fraction        | 0.0826      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.246      |
|    explained_variance   | 0.405       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00685     |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00781    |
|    value_loss           | 0.053       |
-----------------------------------------
Eval num_timesteps=93000, episode_reward=0.33 +/- 0.52
Episode length: 33.50 +/- 18.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.5     |
|    mean_reward     | 0.327    |
| time/              |          |
|    total_timesteps | 93000    |
---------------------------------
Eval num_timesteps=93500, episode_reward=0.39 +/- 0.52
Episode length: 27.92 +/- 17.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.9     |
|    mean_reward     | 0.389    |
| time/              |          |
|    total_timesteps | 93500    |
---------------------------------
Eval num_timesteps=94000, episode_reward=0.31 +/- 0.52
Episode length: 28.50 +/- 16.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.5     |
|    mean_reward     | 0.307    |
| time/              |          |
|    total_timesteps | 94000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.1     |
|    ep_rew_mean     | 0.301    |
| time/              |          |
|    fps             | 73       |
|    iterations      | 46       |
|    time_elapsed    | 1281     |
|    total_timesteps | 94208    |
---------------------------------
Eval num_timesteps=94500, episode_reward=0.45 +/- 0.51
Episode length: 27.28 +/- 14.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.3        |
|    mean_reward          | 0.452       |
| time/                   |             |
|    total_timesteps      | 94500       |
| train/                  |             |
|    approx_kl            | 0.011596989 |
|    clip_fraction        | 0.0928      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.271      |
|    explained_variance   | 0.409       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0256      |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00962    |
|    value_loss           | 0.0581      |
-----------------------------------------
New best mean reward!
Eval num_timesteps=95000, episode_reward=0.45 +/- 0.53
Episode length: 32.92 +/- 19.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.9     |
|    mean_reward     | 0.449    |
| time/              |          |
|    total_timesteps | 95000    |
---------------------------------
Eval num_timesteps=95500, episode_reward=0.35 +/- 0.51
Episode length: 28.20 +/- 15.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.348    |
| time/              |          |
|    total_timesteps | 95500    |
---------------------------------
Eval num_timesteps=96000, episode_reward=0.26 +/- 0.50
Episode length: 30.58 +/- 17.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.259    |
| time/              |          |
|    total_timesteps | 96000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.7     |
|    ep_rew_mean     | 0.256    |
| time/              |          |
|    fps             | 73       |
|    iterations      | 47       |
|    time_elapsed    | 1300     |
|    total_timesteps | 96256    |
---------------------------------
Eval num_timesteps=96500, episode_reward=0.27 +/- 0.50
Episode length: 28.62 +/- 15.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.6       |
|    mean_reward          | 0.266      |
| time/                   |            |
|    total_timesteps      | 96500      |
| train/                  |            |
|    approx_kl            | 0.01551538 |
|    clip_fraction        | 0.116      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.283     |
|    explained_variance   | 0.306      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0155     |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.0132    |
|    value_loss           | 0.0572     |
----------------------------------------
Eval num_timesteps=97000, episode_reward=0.47 +/- 0.51
Episode length: 27.02 +/- 14.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.473    |
| time/              |          |
|    total_timesteps | 97000    |
---------------------------------
New best mean reward!
Eval num_timesteps=97500, episode_reward=0.36 +/- 0.53
Episode length: 30.78 +/- 19.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.8     |
|    mean_reward     | 0.358    |
| time/              |          |
|    total_timesteps | 97500    |
---------------------------------
Eval num_timesteps=98000, episode_reward=0.36 +/- 0.52
Episode length: 31.22 +/- 15.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.356    |
| time/              |          |
|    total_timesteps | 98000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.9     |
|    ep_rew_mean     | 0.314    |
| time/              |          |
|    fps             | 74       |
|    iterations      | 48       |
|    time_elapsed    | 1319     |
|    total_timesteps | 98304    |
---------------------------------
Eval num_timesteps=98500, episode_reward=0.26 +/- 0.52
Episode length: 34.42 +/- 21.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 34.4        |
|    mean_reward          | 0.263       |
| time/                   |             |
|    total_timesteps      | 98500       |
| train/                  |             |
|    approx_kl            | 0.006477332 |
|    clip_fraction        | 0.0517      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.201      |
|    explained_variance   | 0.462       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0197      |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00442    |
|    value_loss           | 0.0528      |
-----------------------------------------
Eval num_timesteps=99000, episode_reward=0.39 +/- 0.53
Episode length: 33.20 +/- 19.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.2     |
|    mean_reward     | 0.388    |
| time/              |          |
|    total_timesteps | 99000    |
---------------------------------
Eval num_timesteps=99500, episode_reward=0.30 +/- 0.50
Episode length: 30.20 +/- 15.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 99500    |
---------------------------------
Eval num_timesteps=100000, episode_reward=0.31 +/- 0.51
Episode length: 28.66 +/- 16.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.7     |
|    mean_reward     | 0.306    |
| time/              |          |
|    total_timesteps | 100000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 0.353    |
| time/              |          |
|    fps             | 74       |
|    iterations      | 49       |
|    time_elapsed    | 1338     |
|    total_timesteps | 100352   |
---------------------------------
Eval num_timesteps=100500, episode_reward=0.33 +/- 0.50
Episode length: 27.14 +/- 16.22
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.1        |
|    mean_reward          | 0.333       |
| time/                   |             |
|    total_timesteps      | 100500      |
| train/                  |             |
|    approx_kl            | 0.009417039 |
|    clip_fraction        | 0.0782      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.221      |
|    explained_variance   | 0.434       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00214    |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00904    |
|    value_loss           | 0.0539      |
-----------------------------------------
Eval num_timesteps=101000, episode_reward=0.42 +/- 0.50
Episode length: 25.68 +/- 13.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.7     |
|    mean_reward     | 0.419    |
| time/              |          |
|    total_timesteps | 101000   |
---------------------------------
Eval num_timesteps=101500, episode_reward=0.31 +/- 0.49
Episode length: 27.76 +/- 14.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.31     |
| time/              |          |
|    total_timesteps | 101500   |
---------------------------------
Eval num_timesteps=102000, episode_reward=0.33 +/- 0.50
Episode length: 26.68 +/- 13.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.7     |
|    mean_reward     | 0.334    |
| time/              |          |
|    total_timesteps | 102000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 0.387    |
| time/              |          |
|    fps             | 75       |
|    iterations      | 50       |
|    time_elapsed    | 1356     |
|    total_timesteps | 102400   |
---------------------------------
Eval num_timesteps=102500, episode_reward=0.47 +/- 0.50
Episode length: 29.00 +/- 16.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29          |
|    mean_reward          | 0.465       |
| time/                   |             |
|    total_timesteps      | 102500      |
| train/                  |             |
|    approx_kl            | 0.011713909 |
|    clip_fraction        | 0.0651      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.175      |
|    explained_variance   | 0.527       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0115      |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.00449    |
|    value_loss           | 0.0462      |
-----------------------------------------
Eval num_timesteps=103000, episode_reward=0.41 +/- 0.51
Episode length: 27.64 +/- 14.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.6     |
|    mean_reward     | 0.411    |
| time/              |          |
|    total_timesteps | 103000   |
---------------------------------
Eval num_timesteps=103500, episode_reward=0.30 +/- 0.50
Episode length: 30.26 +/- 17.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 103500   |
---------------------------------
Eval num_timesteps=104000, episode_reward=0.53 +/- 0.49
Episode length: 28.62 +/- 15.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.526    |
| time/              |          |
|    total_timesteps | 104000   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 0.277    |
| time/              |          |
|    fps             | 75       |
|    iterations      | 51       |
|    time_elapsed    | 1375     |
|    total_timesteps | 104448   |
---------------------------------
Eval num_timesteps=104500, episode_reward=0.40 +/- 0.50
Episode length: 26.46 +/- 14.18
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.5        |
|    mean_reward          | 0.395       |
| time/                   |             |
|    total_timesteps      | 104500      |
| train/                  |             |
|    approx_kl            | 0.007691749 |
|    clip_fraction        | 0.0568      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.158      |
|    explained_variance   | 0.433       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0148      |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00409    |
|    value_loss           | 0.0502      |
-----------------------------------------
Eval num_timesteps=105000, episode_reward=0.44 +/- 0.50
Episode length: 29.32 +/- 16.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.444    |
| time/              |          |
|    total_timesteps | 105000   |
---------------------------------
Eval num_timesteps=105500, episode_reward=0.46 +/- 0.50
Episode length: 25.86 +/- 13.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.9     |
|    mean_reward     | 0.458    |
| time/              |          |
|    total_timesteps | 105500   |
---------------------------------
Eval num_timesteps=106000, episode_reward=0.43 +/- 0.51
Episode length: 28.90 +/- 17.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.9     |
|    mean_reward     | 0.426    |
| time/              |          |
|    total_timesteps | 106000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.8     |
|    ep_rew_mean     | 0.368    |
| time/              |          |
|    fps             | 76       |
|    iterations      | 52       |
|    time_elapsed    | 1392     |
|    total_timesteps | 106496   |
---------------------------------
Eval num_timesteps=106500, episode_reward=0.47 +/- 0.50
Episode length: 28.54 +/- 16.72
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 28.5         |
|    mean_reward          | 0.467        |
| time/                   |              |
|    total_timesteps      | 106500       |
| train/                  |              |
|    approx_kl            | 0.0068061687 |
|    clip_fraction        | 0.0509       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.159       |
|    explained_variance   | 0.374        |
|    learning_rate        | 0.0001       |
|    loss                 | 0.0179       |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00689     |
|    value_loss           | 0.0516       |
------------------------------------------
Eval num_timesteps=107000, episode_reward=0.34 +/- 0.50
Episode length: 24.52 +/- 13.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.5     |
|    mean_reward     | 0.343    |
| time/              |          |
|    total_timesteps | 107000   |
---------------------------------
Eval num_timesteps=107500, episode_reward=0.36 +/- 0.49
Episode length: 29.16 +/- 13.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.365    |
| time/              |          |
|    total_timesteps | 107500   |
---------------------------------
Eval num_timesteps=108000, episode_reward=0.37 +/- 0.51
Episode length: 28.62 +/- 13.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.367    |
| time/              |          |
|    total_timesteps | 108000   |
---------------------------------
Eval num_timesteps=108500, episode_reward=0.42 +/- 0.49
Episode length: 29.70 +/- 13.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.7     |
|    mean_reward     | 0.422    |
| time/              |          |
|    total_timesteps | 108500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.5     |
|    ep_rew_mean     | 0.377    |
| time/              |          |
|    fps             | 76       |
|    iterations      | 53       |
|    time_elapsed    | 1413     |
|    total_timesteps | 108544   |
---------------------------------
Eval num_timesteps=109000, episode_reward=0.36 +/- 0.49
Episode length: 25.02 +/- 11.72
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25          |
|    mean_reward          | 0.361       |
| time/                   |             |
|    total_timesteps      | 109000      |
| train/                  |             |
|    approx_kl            | 0.010122089 |
|    clip_fraction        | 0.0643      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.169      |
|    explained_variance   | 0.457       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.011       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00615    |
|    value_loss           | 0.0497      |
-----------------------------------------
Eval num_timesteps=109500, episode_reward=0.25 +/- 0.49
Episode length: 28.22 +/- 16.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.248    |
| time/              |          |
|    total_timesteps | 109500   |
---------------------------------
Eval num_timesteps=110000, episode_reward=0.34 +/- 0.52
Episode length: 30.04 +/- 19.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30       |
|    mean_reward     | 0.341    |
| time/              |          |
|    total_timesteps | 110000   |
---------------------------------
Eval num_timesteps=110500, episode_reward=0.32 +/- 0.51
Episode length: 31.04 +/- 17.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31       |
|    mean_reward     | 0.317    |
| time/              |          |
|    total_timesteps | 110500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 0.313    |
| time/              |          |
|    fps             | 77       |
|    iterations      | 54       |
|    time_elapsed    | 1431     |
|    total_timesteps | 110592   |
---------------------------------
Eval num_timesteps=111000, episode_reward=0.32 +/- 0.50
Episode length: 25.56 +/- 15.69
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.6        |
|    mean_reward          | 0.319       |
| time/                   |             |
|    total_timesteps      | 111000      |
| train/                  |             |
|    approx_kl            | 0.014285755 |
|    clip_fraction        | 0.0784      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.191      |
|    explained_variance   | 0.415       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0154      |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00975    |
|    value_loss           | 0.0473      |
-----------------------------------------
Eval num_timesteps=111500, episode_reward=0.38 +/- 0.50
Episode length: 24.84 +/- 12.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.8     |
|    mean_reward     | 0.382    |
| time/              |          |
|    total_timesteps | 111500   |
---------------------------------
Eval num_timesteps=112000, episode_reward=0.41 +/- 0.51
Episode length: 32.42 +/- 17.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.4     |
|    mean_reward     | 0.411    |
| time/              |          |
|    total_timesteps | 112000   |
---------------------------------
Eval num_timesteps=112500, episode_reward=0.53 +/- 0.48
Episode length: 27.86 +/- 15.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.9     |
|    mean_reward     | 0.53     |
| time/              |          |
|    total_timesteps | 112500   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.5     |
|    ep_rew_mean     | 0.335    |
| time/              |          |
|    fps             | 77       |
|    iterations      | 55       |
|    time_elapsed    | 1449     |
|    total_timesteps | 112640   |
---------------------------------
Eval num_timesteps=113000, episode_reward=0.45 +/- 0.51
Episode length: 27.46 +/- 13.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.5        |
|    mean_reward          | 0.451       |
| time/                   |             |
|    total_timesteps      | 113000      |
| train/                  |             |
|    approx_kl            | 0.011559509 |
|    clip_fraction        | 0.0785      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.21       |
|    explained_variance   | 0.394       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0317      |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00727    |
|    value_loss           | 0.0585      |
-----------------------------------------
Eval num_timesteps=113500, episode_reward=0.37 +/- 0.49
Episode length: 27.76 +/- 15.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.37     |
| time/              |          |
|    total_timesteps | 113500   |
---------------------------------
Eval num_timesteps=114000, episode_reward=0.40 +/- 0.51
Episode length: 26.48 +/- 13.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.395    |
| time/              |          |
|    total_timesteps | 114000   |
---------------------------------
Eval num_timesteps=114500, episode_reward=0.51 +/- 0.50
Episode length: 28.60 +/- 16.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.507    |
| time/              |          |
|    total_timesteps | 114500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.9     |
|    ep_rew_mean     | 0.391    |
| time/              |          |
|    fps             | 78       |
|    iterations      | 56       |
|    time_elapsed    | 1466     |
|    total_timesteps | 114688   |
---------------------------------
Eval num_timesteps=115000, episode_reward=0.48 +/- 0.49
Episode length: 25.84 +/- 14.62
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 25.8         |
|    mean_reward          | 0.478        |
| time/                   |              |
|    total_timesteps      | 115000       |
| train/                  |              |
|    approx_kl            | 0.0109532885 |
|    clip_fraction        | 0.0893       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.245       |
|    explained_variance   | 0.514        |
|    learning_rate        | 0.0001       |
|    loss                 | 0.00938      |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.0105      |
|    value_loss           | 0.0545       |
------------------------------------------
Eval num_timesteps=115500, episode_reward=0.37 +/- 0.50
Episode length: 24.06 +/- 13.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.1     |
|    mean_reward     | 0.365    |
| time/              |          |
|    total_timesteps | 115500   |
---------------------------------
Eval num_timesteps=116000, episode_reward=0.49 +/- 0.49
Episode length: 23.18 +/- 13.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.2     |
|    mean_reward     | 0.488    |
| time/              |          |
|    total_timesteps | 116000   |
---------------------------------
Eval num_timesteps=116500, episode_reward=0.36 +/- 0.51
Episode length: 26.12 +/- 15.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.1     |
|    mean_reward     | 0.357    |
| time/              |          |
|    total_timesteps | 116500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.4     |
|    ep_rew_mean     | 0.304    |
| time/              |          |
|    fps             | 78       |
|    iterations      | 57       |
|    time_elapsed    | 1484     |
|    total_timesteps | 116736   |
---------------------------------
Eval num_timesteps=117000, episode_reward=0.48 +/- 0.49
Episode length: 26.30 +/- 14.25
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.3        |
|    mean_reward          | 0.476       |
| time/                   |             |
|    total_timesteps      | 117000      |
| train/                  |             |
|    approx_kl            | 0.013305029 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.301      |
|    explained_variance   | 0.412       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00166     |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.0528      |
-----------------------------------------
Eval num_timesteps=117500, episode_reward=0.45 +/- 0.49
Episode length: 27.70 +/- 15.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.45     |
| time/              |          |
|    total_timesteps | 117500   |
---------------------------------
Eval num_timesteps=118000, episode_reward=0.38 +/- 0.51
Episode length: 26.14 +/- 14.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.1     |
|    mean_reward     | 0.377    |
| time/              |          |
|    total_timesteps | 118000   |
---------------------------------
Eval num_timesteps=118500, episode_reward=0.45 +/- 0.51
Episode length: 23.66 +/- 13.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.7     |
|    mean_reward     | 0.446    |
| time/              |          |
|    total_timesteps | 118500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.4     |
|    ep_rew_mean     | 0.392    |
| time/              |          |
|    fps             | 79       |
|    iterations      | 58       |
|    time_elapsed    | 1502     |
|    total_timesteps | 118784   |
---------------------------------
Eval num_timesteps=119000, episode_reward=0.42 +/- 0.51
Episode length: 31.34 +/- 19.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.3        |
|    mean_reward          | 0.416       |
| time/                   |             |
|    total_timesteps      | 119000      |
| train/                  |             |
|    approx_kl            | 0.014068808 |
|    clip_fraction        | 0.0908      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.254      |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0182      |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 0.0482      |
-----------------------------------------
Eval num_timesteps=119500, episode_reward=0.34 +/- 0.51
Episode length: 30.62 +/- 17.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.339    |
| time/              |          |
|    total_timesteps | 119500   |
---------------------------------
Eval num_timesteps=120000, episode_reward=0.50 +/- 0.49
Episode length: 26.56 +/- 14.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.6     |
|    mean_reward     | 0.495    |
| time/              |          |
|    total_timesteps | 120000   |
---------------------------------
Eval num_timesteps=120500, episode_reward=0.39 +/- 0.52
Episode length: 28.42 +/- 18.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.4     |
|    mean_reward     | 0.387    |
| time/              |          |
|    total_timesteps | 120500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.1     |
|    ep_rew_mean     | 0.435    |
| time/              |          |
|    fps             | 79       |
|    iterations      | 59       |
|    time_elapsed    | 1521     |
|    total_timesteps | 120832   |
---------------------------------
Eval num_timesteps=121000, episode_reward=0.42 +/- 0.50
Episode length: 29.94 +/- 15.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.421       |
| time/                   |             |
|    total_timesteps      | 121000      |
| train/                  |             |
|    approx_kl            | 0.016867105 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.228      |
|    explained_variance   | 0.5         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00582     |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.045       |
-----------------------------------------
Eval num_timesteps=121500, episode_reward=0.47 +/- 0.51
Episode length: 28.22 +/- 16.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.468    |
| time/              |          |
|    total_timesteps | 121500   |
---------------------------------
Eval num_timesteps=122000, episode_reward=0.47 +/- 0.50
Episode length: 23.74 +/- 12.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.7     |
|    mean_reward     | 0.466    |
| time/              |          |
|    total_timesteps | 122000   |
---------------------------------
Eval num_timesteps=122500, episode_reward=0.33 +/- 0.50
Episode length: 28.34 +/- 14.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.3     |
|    mean_reward     | 0.328    |
| time/              |          |
|    total_timesteps | 122500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.7     |
|    ep_rew_mean     | 0.336    |
| time/              |          |
|    fps             | 79       |
|    iterations      | 60       |
|    time_elapsed    | 1540     |
|    total_timesteps | 122880   |
---------------------------------
Eval num_timesteps=123000, episode_reward=0.36 +/- 0.50
Episode length: 26.36 +/- 14.66
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26.4       |
|    mean_reward          | 0.356      |
| time/                   |            |
|    total_timesteps      | 123000     |
| train/                  |            |
|    approx_kl            | 0.00996398 |
|    clip_fraction        | 0.0889     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.246     |
|    explained_variance   | 0.457      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.000613   |
|    n_updates            | 600        |
|    policy_gradient_loss | -0.0111    |
|    value_loss           | 0.0496     |
----------------------------------------
Eval num_timesteps=123500, episode_reward=0.53 +/- 0.48
Episode length: 28.88 +/- 16.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.9     |
|    mean_reward     | 0.526    |
| time/              |          |
|    total_timesteps | 123500   |
---------------------------------
Eval num_timesteps=124000, episode_reward=0.35 +/- 0.50
Episode length: 27.50 +/- 15.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.351    |
| time/              |          |
|    total_timesteps | 124000   |
---------------------------------
Eval num_timesteps=124500, episode_reward=0.42 +/- 0.50
Episode length: 25.92 +/- 14.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.9     |
|    mean_reward     | 0.417    |
| time/              |          |
|    total_timesteps | 124500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.7     |
|    ep_rew_mean     | 0.445    |
| time/              |          |
|    fps             | 80       |
|    iterations      | 61       |
|    time_elapsed    | 1558     |
|    total_timesteps | 124928   |
---------------------------------
Eval num_timesteps=125000, episode_reward=0.32 +/- 0.50
Episode length: 35.42 +/- 17.07
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 35.4        |
|    mean_reward          | 0.319       |
| time/                   |             |
|    total_timesteps      | 125000      |
| train/                  |             |
|    approx_kl            | 0.011507936 |
|    clip_fraction        | 0.0812      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.247      |
|    explained_variance   | 0.577       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0593      |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00814    |
|    value_loss           | 0.0474      |
-----------------------------------------
Eval num_timesteps=125500, episode_reward=0.40 +/- 0.51
Episode length: 30.18 +/- 15.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.401    |
| time/              |          |
|    total_timesteps | 125500   |
---------------------------------
Eval num_timesteps=126000, episode_reward=0.38 +/- 0.52
Episode length: 25.28 +/- 14.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.3     |
|    mean_reward     | 0.38     |
| time/              |          |
|    total_timesteps | 126000   |
---------------------------------
Eval num_timesteps=126500, episode_reward=0.34 +/- 0.50
Episode length: 29.34 +/- 15.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.344    |
| time/              |          |
|    total_timesteps | 126500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.9     |
|    ep_rew_mean     | 0.373    |
| time/              |          |
|    fps             | 80       |
|    iterations      | 62       |
|    time_elapsed    | 1578     |
|    total_timesteps | 126976   |
---------------------------------
Eval num_timesteps=127000, episode_reward=0.54 +/- 0.48
Episode length: 29.68 +/- 14.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.7        |
|    mean_reward          | 0.543       |
| time/                   |             |
|    total_timesteps      | 127000      |
| train/                  |             |
|    approx_kl            | 0.011767883 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.289      |
|    explained_variance   | 0.422       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00364    |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0113     |
|    value_loss           | 0.0536      |
-----------------------------------------
New best mean reward!
Eval num_timesteps=127500, episode_reward=0.43 +/- 0.51
Episode length: 27.06 +/- 15.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.1     |
|    mean_reward     | 0.433    |
| time/              |          |
|    total_timesteps | 127500   |
---------------------------------
Eval num_timesteps=128000, episode_reward=0.47 +/- 0.50
Episode length: 28.36 +/- 14.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.4     |
|    mean_reward     | 0.468    |
| time/              |          |
|    total_timesteps | 128000   |
---------------------------------
Eval num_timesteps=128500, episode_reward=0.37 +/- 0.52
Episode length: 28.18 +/- 17.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.369    |
| time/              |          |
|    total_timesteps | 128500   |
---------------------------------
Eval num_timesteps=129000, episode_reward=0.28 +/- 0.51
Episode length: 30.80 +/- 17.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.8     |
|    mean_reward     | 0.278    |
| time/              |          |
|    total_timesteps | 129000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.8     |
|    ep_rew_mean     | 0.444    |
| time/              |          |
|    fps             | 80       |
|    iterations      | 63       |
|    time_elapsed    | 1600     |
|    total_timesteps | 129024   |
---------------------------------
Eval num_timesteps=129500, episode_reward=0.44 +/- 0.50
Episode length: 24.52 +/- 11.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.5       |
|    mean_reward          | 0.443      |
| time/                   |            |
|    total_timesteps      | 129500     |
| train/                  |            |
|    approx_kl            | 0.01171721 |
|    clip_fraction        | 0.0944     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.298     |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0331     |
|    n_updates            | 630        |
|    policy_gradient_loss | -0.0139    |
|    value_loss           | 0.0519     |
----------------------------------------
Eval num_timesteps=130000, episode_reward=0.47 +/- 0.50
Episode length: 28.00 +/- 14.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28       |
|    mean_reward     | 0.469    |
| time/              |          |
|    total_timesteps | 130000   |
---------------------------------
Eval num_timesteps=130500, episode_reward=0.44 +/- 0.51
Episode length: 29.96 +/- 15.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30       |
|    mean_reward     | 0.441    |
| time/              |          |
|    total_timesteps | 130500   |
---------------------------------
Eval num_timesteps=131000, episode_reward=0.37 +/- 0.52
Episode length: 27.76 +/- 15.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.37     |
| time/              |          |
|    total_timesteps | 131000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.331    |
| time/              |          |
|    fps             | 80       |
|    iterations      | 64       |
|    time_elapsed    | 1618     |
|    total_timesteps | 131072   |
---------------------------------
Eval num_timesteps=131500, episode_reward=0.44 +/- 0.49
Episode length: 29.54 +/- 15.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.5        |
|    mean_reward          | 0.443       |
| time/                   |             |
|    total_timesteps      | 131500      |
| train/                  |             |
|    approx_kl            | 0.013076002 |
|    clip_fraction        | 0.087       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.269      |
|    explained_variance   | 0.384       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00951    |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.0483      |
-----------------------------------------
Eval num_timesteps=132000, episode_reward=0.35 +/- 0.51
Episode length: 27.02 +/- 15.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.353    |
| time/              |          |
|    total_timesteps | 132000   |
---------------------------------
Eval num_timesteps=132500, episode_reward=0.52 +/- 0.49
Episode length: 30.20 +/- 17.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.521    |
| time/              |          |
|    total_timesteps | 132500   |
---------------------------------
Eval num_timesteps=133000, episode_reward=0.40 +/- 0.50
Episode length: 24.50 +/- 15.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.5     |
|    mean_reward     | 0.403    |
| time/              |          |
|    total_timesteps | 133000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.7     |
|    ep_rew_mean     | 0.365    |
| time/              |          |
|    fps             | 81       |
|    iterations      | 65       |
|    time_elapsed    | 1637     |
|    total_timesteps | 133120   |
---------------------------------
Eval num_timesteps=133500, episode_reward=0.48 +/- 0.48
Episode length: 29.72 +/- 15.99
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.7        |
|    mean_reward          | 0.483       |
| time/                   |             |
|    total_timesteps      | 133500      |
| train/                  |             |
|    approx_kl            | 0.014645879 |
|    clip_fraction        | 0.0887      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.289      |
|    explained_variance   | 0.436       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00772     |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0121     |
|    value_loss           | 0.0534      |
-----------------------------------------
Eval num_timesteps=134000, episode_reward=0.36 +/- 0.53
Episode length: 29.80 +/- 18.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.362    |
| time/              |          |
|    total_timesteps | 134000   |
---------------------------------
Eval num_timesteps=134500, episode_reward=0.42 +/- 0.51
Episode length: 26.32 +/- 15.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.3     |
|    mean_reward     | 0.416    |
| time/              |          |
|    total_timesteps | 134500   |
---------------------------------
Eval num_timesteps=135000, episode_reward=0.35 +/- 0.50
Episode length: 27.80 +/- 15.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.35     |
| time/              |          |
|    total_timesteps | 135000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 0.338    |
| time/              |          |
|    fps             | 81       |
|    iterations      | 66       |
|    time_elapsed    | 1657     |
|    total_timesteps | 135168   |
---------------------------------
Eval num_timesteps=135500, episode_reward=0.44 +/- 0.51
Episode length: 26.04 +/- 16.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26          |
|    mean_reward          | 0.437       |
| time/                   |             |
|    total_timesteps      | 135500      |
| train/                  |             |
|    approx_kl            | 0.010775026 |
|    clip_fraction        | 0.0813      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.261      |
|    explained_variance   | 0.493       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0019     |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0132     |
|    value_loss           | 0.0474      |
-----------------------------------------
Eval num_timesteps=136000, episode_reward=0.47 +/- 0.50
Episode length: 26.96 +/- 15.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.473    |
| time/              |          |
|    total_timesteps | 136000   |
---------------------------------
Eval num_timesteps=136500, episode_reward=0.49 +/- 0.49
Episode length: 32.34 +/- 18.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.3     |
|    mean_reward     | 0.492    |
| time/              |          |
|    total_timesteps | 136500   |
---------------------------------
Eval num_timesteps=137000, episode_reward=0.46 +/- 0.51
Episode length: 26.14 +/- 15.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.1     |
|    mean_reward     | 0.457    |
| time/              |          |
|    total_timesteps | 137000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.8     |
|    ep_rew_mean     | 0.428    |
| time/              |          |
|    fps             | 81       |
|    iterations      | 67       |
|    time_elapsed    | 1676     |
|    total_timesteps | 137216   |
---------------------------------
Eval num_timesteps=137500, episode_reward=0.32 +/- 0.51
Episode length: 30.50 +/- 18.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.5        |
|    mean_reward          | 0.319       |
| time/                   |             |
|    total_timesteps      | 137500      |
| train/                  |             |
|    approx_kl            | 0.009092328 |
|    clip_fraction        | 0.0857      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.298      |
|    explained_variance   | 0.449       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0351      |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00956    |
|    value_loss           | 0.0526      |
-----------------------------------------
Eval num_timesteps=138000, episode_reward=0.27 +/- 0.50
Episode length: 28.48 +/- 16.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.5     |
|    mean_reward     | 0.267    |
| time/              |          |
|    total_timesteps | 138000   |
---------------------------------
Eval num_timesteps=138500, episode_reward=0.31 +/- 0.49
Episode length: 26.70 +/- 14.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.7     |
|    mean_reward     | 0.314    |
| time/              |          |
|    total_timesteps | 138500   |
---------------------------------
Eval num_timesteps=139000, episode_reward=0.50 +/- 0.52
Episode length: 34.82 +/- 21.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.8     |
|    mean_reward     | 0.502    |
| time/              |          |
|    total_timesteps | 139000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.4     |
|    ep_rew_mean     | 0.319    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 68       |
|    time_elapsed    | 1693     |
|    total_timesteps | 139264   |
---------------------------------
Eval num_timesteps=139500, episode_reward=0.44 +/- 0.52
Episode length: 34.04 +/- 19.78
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 34          |
|    mean_reward          | 0.445       |
| time/                   |             |
|    total_timesteps      | 139500      |
| train/                  |             |
|    approx_kl            | 0.014717881 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.386      |
|    explained_variance   | 0.392       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00252    |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0173     |
|    value_loss           | 0.053       |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=0.48 +/- 0.52
Episode length: 30.72 +/- 18.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.7     |
|    mean_reward     | 0.478    |
| time/              |          |
|    total_timesteps | 140000   |
---------------------------------
Eval num_timesteps=140500, episode_reward=0.40 +/- 0.50
Episode length: 34.72 +/- 18.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.7     |
|    mean_reward     | 0.402    |
| time/              |          |
|    total_timesteps | 140500   |
---------------------------------
Eval num_timesteps=141000, episode_reward=0.36 +/- 0.51
Episode length: 31.42 +/- 18.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.355    |
| time/              |          |
|    total_timesteps | 141000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.4     |
|    ep_rew_mean     | 0.372    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 69       |
|    time_elapsed    | 1714     |
|    total_timesteps | 141312   |
---------------------------------
Eval num_timesteps=141500, episode_reward=0.41 +/- 0.53
Episode length: 32.84 +/- 19.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.8        |
|    mean_reward          | 0.41        |
| time/                   |             |
|    total_timesteps      | 141500      |
| train/                  |             |
|    approx_kl            | 0.009921084 |
|    clip_fraction        | 0.0951      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.31       |
|    explained_variance   | 0.411       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0104      |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.0525      |
-----------------------------------------
Eval num_timesteps=142000, episode_reward=0.39 +/- 0.52
Episode length: 37.74 +/- 18.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 37.7     |
|    mean_reward     | 0.39     |
| time/              |          |
|    total_timesteps | 142000   |
---------------------------------
Eval num_timesteps=142500, episode_reward=0.41 +/- 0.54
Episode length: 32.44 +/- 22.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.4     |
|    mean_reward     | 0.411    |
| time/              |          |
|    total_timesteps | 142500   |
---------------------------------
Eval num_timesteps=143000, episode_reward=0.34 +/- 0.54
Episode length: 40.34 +/- 21.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 40.3     |
|    mean_reward     | 0.34     |
| time/              |          |
|    total_timesteps | 143000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.6     |
|    ep_rew_mean     | 0.383    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 70       |
|    time_elapsed    | 1735     |
|    total_timesteps | 143360   |
---------------------------------
Eval num_timesteps=143500, episode_reward=0.46 +/- 0.51
Episode length: 30.10 +/- 17.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.461       |
| time/                   |             |
|    total_timesteps      | 143500      |
| train/                  |             |
|    approx_kl            | 0.010010684 |
|    clip_fraction        | 0.0953      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.314      |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00111     |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.0143     |
|    value_loss           | 0.0389      |
-----------------------------------------
Eval num_timesteps=144000, episode_reward=0.52 +/- 0.51
Episode length: 29.10 +/- 17.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.525    |
| time/              |          |
|    total_timesteps | 144000   |
---------------------------------
Eval num_timesteps=144500, episode_reward=0.36 +/- 0.51
Episode length: 34.08 +/- 17.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.1     |
|    mean_reward     | 0.365    |
| time/              |          |
|    total_timesteps | 144500   |
---------------------------------
Eval num_timesteps=145000, episode_reward=0.36 +/- 0.52
Episode length: 30.56 +/- 18.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.359    |
| time/              |          |
|    total_timesteps | 145000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.9     |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 71       |
|    time_elapsed    | 1754     |
|    total_timesteps | 145408   |
---------------------------------
Eval num_timesteps=145500, episode_reward=0.54 +/- 0.50
Episode length: 31.22 +/- 19.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.2        |
|    mean_reward          | 0.536       |
| time/                   |             |
|    total_timesteps      | 145500      |
| train/                  |             |
|    approx_kl            | 0.010088528 |
|    clip_fraction        | 0.0945      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.343      |
|    explained_variance   | 0.528       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00427    |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.048       |
-----------------------------------------
Eval num_timesteps=146000, episode_reward=0.49 +/- 0.50
Episode length: 33.82 +/- 19.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.8     |
|    mean_reward     | 0.486    |
| time/              |          |
|    total_timesteps | 146000   |
---------------------------------
Eval num_timesteps=146500, episode_reward=0.48 +/- 0.50
Episode length: 30.72 +/- 19.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.7     |
|    mean_reward     | 0.478    |
| time/              |          |
|    total_timesteps | 146500   |
---------------------------------
Eval num_timesteps=147000, episode_reward=0.39 +/- 0.52
Episode length: 32.36 +/- 18.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.4     |
|    mean_reward     | 0.392    |
| time/              |          |
|    total_timesteps | 147000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 0.491    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 72       |
|    time_elapsed    | 1774     |
|    total_timesteps | 147456   |
---------------------------------
Eval num_timesteps=147500, episode_reward=0.36 +/- 0.52
Episode length: 31.18 +/- 19.08
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.2        |
|    mean_reward          | 0.357       |
| time/                   |             |
|    total_timesteps      | 147500      |
| train/                  |             |
|    approx_kl            | 0.010806844 |
|    clip_fraction        | 0.0889      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.324      |
|    explained_variance   | 0.527       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00549     |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 0.0462      |
-----------------------------------------
Eval num_timesteps=148000, episode_reward=0.42 +/- 0.53
Episode length: 30.70 +/- 21.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.7     |
|    mean_reward     | 0.418    |
| time/              |          |
|    total_timesteps | 148000   |
---------------------------------
Eval num_timesteps=148500, episode_reward=0.43 +/- 0.51
Episode length: 28.82 +/- 17.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.8     |
|    mean_reward     | 0.426    |
| time/              |          |
|    total_timesteps | 148500   |
---------------------------------
Eval num_timesteps=149000, episode_reward=0.38 +/- 0.53
Episode length: 35.30 +/- 21.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 35.3     |
|    mean_reward     | 0.38     |
| time/              |          |
|    total_timesteps | 149000   |
---------------------------------
Eval num_timesteps=149500, episode_reward=0.33 +/- 0.52
Episode length: 28.92 +/- 18.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.9     |
|    mean_reward     | 0.325    |
| time/              |          |
|    total_timesteps | 149500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.4     |
|    ep_rew_mean     | 0.402    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 73       |
|    time_elapsed    | 1796     |
|    total_timesteps | 149504   |
---------------------------------
Eval num_timesteps=150000, episode_reward=0.40 +/- 0.51
Episode length: 29.48 +/- 17.62
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.5        |
|    mean_reward          | 0.403       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.009644762 |
|    clip_fraction        | 0.0868      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.317      |
|    explained_variance   | 0.491       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00798     |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.0473      |
-----------------------------------------
Eval num_timesteps=150500, episode_reward=0.49 +/- 0.50
Episode length: 27.08 +/- 16.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.1     |
|    mean_reward     | 0.493    |
| time/              |          |
|    total_timesteps | 150500   |
---------------------------------
Eval num_timesteps=151000, episode_reward=0.28 +/- 0.50
Episode length: 30.18 +/- 17.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.28     |
| time/              |          |
|    total_timesteps | 151000   |
---------------------------------
Eval num_timesteps=151500, episode_reward=0.37 +/- 0.50
Episode length: 31.90 +/- 19.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.9     |
|    mean_reward     | 0.374    |
| time/              |          |
|    total_timesteps | 151500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.8     |
|    ep_rew_mean     | 0.342    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 74       |
|    time_elapsed    | 1816     |
|    total_timesteps | 151552   |
---------------------------------
Eval num_timesteps=152000, episode_reward=0.28 +/- 0.50
Episode length: 29.30 +/- 19.35
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.3        |
|    mean_reward          | 0.284       |
| time/                   |             |
|    total_timesteps      | 152000      |
| train/                  |             |
|    approx_kl            | 0.010531603 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.404      |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00353     |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0147     |
|    value_loss           | 0.0513      |
-----------------------------------------
Eval num_timesteps=152500, episode_reward=0.48 +/- 0.50
Episode length: 25.66 +/- 16.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.7     |
|    mean_reward     | 0.478    |
| time/              |          |
|    total_timesteps | 152500   |
---------------------------------
Eval num_timesteps=153000, episode_reward=0.55 +/- 0.51
Episode length: 27.72 +/- 18.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.55     |
| time/              |          |
|    total_timesteps | 153000   |
---------------------------------
New best mean reward!
Eval num_timesteps=153500, episode_reward=0.42 +/- 0.51
Episode length: 29.68 +/- 16.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.7     |
|    mean_reward     | 0.423    |
| time/              |          |
|    total_timesteps | 153500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | 0.308    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 75       |
|    time_elapsed    | 1835     |
|    total_timesteps | 153600   |
---------------------------------
Eval num_timesteps=154000, episode_reward=0.43 +/- 0.52
Episode length: 32.72 +/- 20.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.7        |
|    mean_reward          | 0.43        |
| time/                   |             |
|    total_timesteps      | 154000      |
| train/                  |             |
|    approx_kl            | 0.011261384 |
|    clip_fraction        | 0.0958      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.394      |
|    explained_variance   | 0.484       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0251     |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0153     |
|    value_loss           | 0.0482      |
-----------------------------------------
Eval num_timesteps=154500, episode_reward=0.41 +/- 0.52
Episode length: 27.56 +/- 18.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.6     |
|    mean_reward     | 0.411    |
| time/              |          |
|    total_timesteps | 154500   |
---------------------------------
Eval num_timesteps=155000, episode_reward=0.56 +/- 0.47
Episode length: 26.52 +/- 15.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.555    |
| time/              |          |
|    total_timesteps | 155000   |
---------------------------------
New best mean reward!
Eval num_timesteps=155500, episode_reward=0.49 +/- 0.50
Episode length: 28.24 +/- 17.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.488    |
| time/              |          |
|    total_timesteps | 155500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 0.353    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 76       |
|    time_elapsed    | 1854     |
|    total_timesteps | 155648   |
---------------------------------
Eval num_timesteps=156000, episode_reward=0.34 +/- 0.51
Episode length: 29.30 +/- 16.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.3        |
|    mean_reward          | 0.344       |
| time/                   |             |
|    total_timesteps      | 156000      |
| train/                  |             |
|    approx_kl            | 0.011796586 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.354      |
|    explained_variance   | 0.339       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0427      |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.0595      |
-----------------------------------------
Eval num_timesteps=156500, episode_reward=0.47 +/- 0.51
Episode length: 27.54 +/- 16.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.471    |
| time/              |          |
|    total_timesteps | 156500   |
---------------------------------
Eval num_timesteps=157000, episode_reward=0.44 +/- 0.49
Episode length: 30.56 +/- 16.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.439    |
| time/              |          |
|    total_timesteps | 157000   |
---------------------------------
Eval num_timesteps=157500, episode_reward=0.47 +/- 0.52
Episode length: 33.06 +/- 18.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.1     |
|    mean_reward     | 0.469    |
| time/              |          |
|    total_timesteps | 157500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.6     |
|    ep_rew_mean     | 0.389    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 77       |
|    time_elapsed    | 1874     |
|    total_timesteps | 157696   |
---------------------------------
Eval num_timesteps=158000, episode_reward=0.41 +/- 0.52
Episode length: 27.80 +/- 16.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.8        |
|    mean_reward          | 0.41        |
| time/                   |             |
|    total_timesteps      | 158000      |
| train/                  |             |
|    approx_kl            | 0.011748868 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.38       |
|    explained_variance   | 0.424       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00228     |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0185     |
|    value_loss           | 0.0525      |
-----------------------------------------
Eval num_timesteps=158500, episode_reward=0.52 +/- 0.48
Episode length: 25.58 +/- 13.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.6     |
|    mean_reward     | 0.519    |
| time/              |          |
|    total_timesteps | 158500   |
---------------------------------
Eval num_timesteps=159000, episode_reward=0.42 +/- 0.50
Episode length: 26.44 +/- 14.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.4     |
|    mean_reward     | 0.415    |
| time/              |          |
|    total_timesteps | 159000   |
---------------------------------
Eval num_timesteps=159500, episode_reward=0.41 +/- 0.48
Episode length: 27.72 +/- 14.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.41     |
| time/              |          |
|    total_timesteps | 159500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.1     |
|    ep_rew_mean     | 0.351    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 78       |
|    time_elapsed    | 1892     |
|    total_timesteps | 159744   |
---------------------------------
Eval num_timesteps=160000, episode_reward=0.35 +/- 0.51
Episode length: 26.56 +/- 16.13
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.6        |
|    mean_reward          | 0.355       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.019836996 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.401      |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0164      |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0163     |
|    value_loss           | 0.0439      |
-----------------------------------------
Eval num_timesteps=160500, episode_reward=0.35 +/- 0.52
Episode length: 33.18 +/- 20.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.2     |
|    mean_reward     | 0.349    |
| time/              |          |
|    total_timesteps | 160500   |
---------------------------------
Eval num_timesteps=161000, episode_reward=0.34 +/- 0.50
Episode length: 26.50 +/- 16.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.335    |
| time/              |          |
|    total_timesteps | 161000   |
---------------------------------
Eval num_timesteps=161500, episode_reward=0.38 +/- 0.52
Episode length: 31.24 +/- 19.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.376    |
| time/              |          |
|    total_timesteps | 161500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 0.391    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 79       |
|    time_elapsed    | 1911     |
|    total_timesteps | 161792   |
---------------------------------
Eval num_timesteps=162000, episode_reward=0.44 +/- 0.51
Episode length: 30.04 +/- 18.12
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 30           |
|    mean_reward          | 0.441        |
| time/                   |              |
|    total_timesteps      | 162000       |
| train/                  |              |
|    approx_kl            | 0.0071308757 |
|    clip_fraction        | 0.091        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.331       |
|    explained_variance   | 0.404        |
|    learning_rate        | 0.0001       |
|    loss                 | -0.00752     |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.013       |
|    value_loss           | 0.0533       |
------------------------------------------
Eval num_timesteps=162500, episode_reward=0.40 +/- 0.50
Episode length: 24.76 +/- 15.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.8     |
|    mean_reward     | 0.402    |
| time/              |          |
|    total_timesteps | 162500   |
---------------------------------
Eval num_timesteps=163000, episode_reward=0.41 +/- 0.50
Episode length: 31.80 +/- 17.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.8     |
|    mean_reward     | 0.414    |
| time/              |          |
|    total_timesteps | 163000   |
---------------------------------
Eval num_timesteps=163500, episode_reward=0.46 +/- 0.51
Episode length: 24.76 +/- 14.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.8     |
|    mean_reward     | 0.462    |
| time/              |          |
|    total_timesteps | 163500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 0.36     |
| time/              |          |
|    fps             | 84       |
|    iterations      | 80       |
|    time_elapsed    | 1930     |
|    total_timesteps | 163840   |
---------------------------------
Eval num_timesteps=164000, episode_reward=0.58 +/- 0.46
Episode length: 25.66 +/- 13.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.7        |
|    mean_reward          | 0.579       |
| time/                   |             |
|    total_timesteps      | 164000      |
| train/                  |             |
|    approx_kl            | 0.010385433 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.351      |
|    explained_variance   | 0.422       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.000593   |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.0443      |
-----------------------------------------
New best mean reward!
Eval num_timesteps=164500, episode_reward=0.35 +/- 0.51
Episode length: 28.08 +/- 15.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.1     |
|    mean_reward     | 0.349    |
| time/              |          |
|    total_timesteps | 164500   |
---------------------------------
Eval num_timesteps=165000, episode_reward=0.33 +/- 0.49
Episode length: 27.14 +/- 14.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.1     |
|    mean_reward     | 0.333    |
| time/              |          |
|    total_timesteps | 165000   |
---------------------------------
Eval num_timesteps=165500, episode_reward=0.44 +/- 0.50
Episode length: 24.76 +/- 14.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.8     |
|    mean_reward     | 0.442    |
| time/              |          |
|    total_timesteps | 165500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.5     |
|    ep_rew_mean     | 0.341    |
| time/              |          |
|    fps             | 85       |
|    iterations      | 81       |
|    time_elapsed    | 1947     |
|    total_timesteps | 165888   |
---------------------------------
Eval num_timesteps=166000, episode_reward=0.40 +/- 0.51
Episode length: 29.10 +/- 17.90
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.1        |
|    mean_reward          | 0.405       |
| time/                   |             |
|    total_timesteps      | 166000      |
| train/                  |             |
|    approx_kl            | 0.010936885 |
|    clip_fraction        | 0.0997      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.316      |
|    explained_variance   | 0.553       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0145      |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.0454      |
-----------------------------------------
Eval num_timesteps=166500, episode_reward=0.46 +/- 0.51
Episode length: 29.72 +/- 16.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.7     |
|    mean_reward     | 0.462    |
| time/              |          |
|    total_timesteps | 166500   |
---------------------------------
Eval num_timesteps=167000, episode_reward=0.46 +/- 0.50
Episode length: 29.72 +/- 16.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.7     |
|    mean_reward     | 0.462    |
| time/              |          |
|    total_timesteps | 167000   |
---------------------------------
Eval num_timesteps=167500, episode_reward=0.30 +/- 0.51
Episode length: 31.14 +/- 18.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.1     |
|    mean_reward     | 0.296    |
| time/              |          |
|    total_timesteps | 167500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.2     |
|    ep_rew_mean     | 0.392    |
| time/              |          |
|    fps             | 85       |
|    iterations      | 82       |
|    time_elapsed    | 1966     |
|    total_timesteps | 167936   |
---------------------------------
Eval num_timesteps=168000, episode_reward=0.31 +/- 0.50
Episode length: 27.32 +/- 16.66
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.3        |
|    mean_reward          | 0.312       |
| time/                   |             |
|    total_timesteps      | 168000      |
| train/                  |             |
|    approx_kl            | 0.008512736 |
|    clip_fraction        | 0.0879      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.302      |
|    explained_variance   | 0.462       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0121     |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.0534      |
-----------------------------------------
Eval num_timesteps=168500, episode_reward=0.46 +/- 0.51
Episode length: 26.18 +/- 14.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.2     |
|    mean_reward     | 0.456    |
| time/              |          |
|    total_timesteps | 168500   |
---------------------------------
Eval num_timesteps=169000, episode_reward=0.37 +/- 0.50
Episode length: 26.70 +/- 15.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.7     |
|    mean_reward     | 0.374    |
| time/              |          |
|    total_timesteps | 169000   |
---------------------------------
Eval num_timesteps=169500, episode_reward=0.46 +/- 0.48
Episode length: 29.76 +/- 14.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.462    |
| time/              |          |
|    total_timesteps | 169500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23       |
|    ep_rew_mean     | 0.429    |
| time/              |          |
|    fps             | 85       |
|    iterations      | 83       |
|    time_elapsed    | 1984     |
|    total_timesteps | 169984   |
---------------------------------
Eval num_timesteps=170000, episode_reward=0.42 +/- 0.51
Episode length: 25.62 +/- 14.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.6        |
|    mean_reward          | 0.419       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.011544112 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.351      |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0146      |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.048       |
-----------------------------------------
Eval num_timesteps=170500, episode_reward=0.46 +/- 0.50
Episode length: 24.62 +/- 13.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.6     |
|    mean_reward     | 0.463    |
| time/              |          |
|    total_timesteps | 170500   |
---------------------------------
Eval num_timesteps=171000, episode_reward=0.42 +/- 0.51
Episode length: 30.84 +/- 16.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.8     |
|    mean_reward     | 0.418    |
| time/              |          |
|    total_timesteps | 171000   |
---------------------------------
Eval num_timesteps=171500, episode_reward=0.27 +/- 0.49
Episode length: 26.66 +/- 15.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.7     |
|    mean_reward     | 0.274    |
| time/              |          |
|    total_timesteps | 171500   |
---------------------------------
Eval num_timesteps=172000, episode_reward=0.49 +/- 0.49
Episode length: 27.50 +/- 14.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.491    |
| time/              |          |
|    total_timesteps | 172000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.7     |
|    ep_rew_mean     | 0.386    |
| time/              |          |
|    fps             | 85       |
|    iterations      | 84       |
|    time_elapsed    | 2004     |
|    total_timesteps | 172032   |
---------------------------------
Eval num_timesteps=172500, episode_reward=0.64 +/- 0.44
Episode length: 26.06 +/- 12.95
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.1        |
|    mean_reward          | 0.637       |
| time/                   |             |
|    total_timesteps      | 172500      |
| train/                  |             |
|    approx_kl            | 0.011717118 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.368      |
|    explained_variance   | 0.511       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0051     |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 0.0545      |
-----------------------------------------
New best mean reward!
Eval num_timesteps=173000, episode_reward=0.52 +/- 0.49
Episode length: 30.50 +/- 16.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.5     |
|    mean_reward     | 0.519    |
| time/              |          |
|    total_timesteps | 173000   |
---------------------------------
Eval num_timesteps=173500, episode_reward=0.39 +/- 0.50
Episode length: 26.58 +/- 14.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.6     |
|    mean_reward     | 0.395    |
| time/              |          |
|    total_timesteps | 173500   |
---------------------------------
Eval num_timesteps=174000, episode_reward=0.50 +/- 0.49
Episode length: 25.56 +/- 12.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.6     |
|    mean_reward     | 0.499    |
| time/              |          |
|    total_timesteps | 174000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.2     |
|    ep_rew_mean     | 0.428    |
| time/              |          |
|    fps             | 86       |
|    iterations      | 85       |
|    time_elapsed    | 2023     |
|    total_timesteps | 174080   |
---------------------------------
Eval num_timesteps=174500, episode_reward=0.44 +/- 0.51
Episode length: 29.48 +/- 17.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.5        |
|    mean_reward          | 0.443       |
| time/                   |             |
|    total_timesteps      | 174500      |
| train/                  |             |
|    approx_kl            | 0.009683419 |
|    clip_fraction        | 0.0792      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.226      |
|    explained_variance   | 0.476       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00741     |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.0442      |
-----------------------------------------
Eval num_timesteps=175000, episode_reward=0.52 +/- 0.48
Episode length: 30.44 +/- 15.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.4     |
|    mean_reward     | 0.519    |
| time/              |          |
|    total_timesteps | 175000   |
---------------------------------
Eval num_timesteps=175500, episode_reward=0.54 +/- 0.48
Episode length: 26.44 +/- 14.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.4     |
|    mean_reward     | 0.536    |
| time/              |          |
|    total_timesteps | 175500   |
---------------------------------
Eval num_timesteps=176000, episode_reward=0.33 +/- 0.51
Episode length: 27.00 +/- 17.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.333    |
| time/              |          |
|    total_timesteps | 176000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 0.287    |
| time/              |          |
|    fps             | 86       |
|    iterations      | 86       |
|    time_elapsed    | 2043     |
|    total_timesteps | 176128   |
---------------------------------
Eval num_timesteps=176500, episode_reward=0.53 +/- 0.48
Episode length: 27.38 +/- 14.42
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.4        |
|    mean_reward          | 0.532       |
| time/                   |             |
|    total_timesteps      | 176500      |
| train/                  |             |
|    approx_kl            | 0.018423334 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.307      |
|    explained_variance   | 0.54        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0115      |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.0422      |
-----------------------------------------
Eval num_timesteps=177000, episode_reward=0.44 +/- 0.51
Episode length: 24.74 +/- 14.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.7     |
|    mean_reward     | 0.442    |
| time/              |          |
|    total_timesteps | 177000   |
---------------------------------
Eval num_timesteps=177500, episode_reward=0.44 +/- 0.51
Episode length: 26.36 +/- 16.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.4     |
|    mean_reward     | 0.436    |
| time/              |          |
|    total_timesteps | 177500   |
---------------------------------
Eval num_timesteps=178000, episode_reward=0.35 +/- 0.50
Episode length: 24.04 +/- 13.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24       |
|    mean_reward     | 0.345    |
| time/              |          |
|    total_timesteps | 178000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.8     |
|    ep_rew_mean     | 0.366    |
| time/              |          |
|    fps             | 86       |
|    iterations      | 87       |
|    time_elapsed    | 2060     |
|    total_timesteps | 178176   |
---------------------------------
Eval num_timesteps=178500, episode_reward=0.54 +/- 0.49
Episode length: 25.48 +/- 15.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.5        |
|    mean_reward          | 0.539       |
| time/                   |             |
|    total_timesteps      | 178500      |
| train/                  |             |
|    approx_kl            | 0.017008848 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.24       |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0047     |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.0385      |
-----------------------------------------
Eval num_timesteps=179000, episode_reward=0.36 +/- 0.51
Episode length: 29.80 +/- 18.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.362    |
| time/              |          |
|    total_timesteps | 179000   |
---------------------------------
Eval num_timesteps=179500, episode_reward=0.42 +/- 0.50
Episode length: 25.36 +/- 15.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.4     |
|    mean_reward     | 0.42     |
| time/              |          |
|    total_timesteps | 179500   |
---------------------------------
Eval num_timesteps=180000, episode_reward=0.49 +/- 0.49
Episode length: 27.50 +/- 14.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.491    |
| time/              |          |
|    total_timesteps | 180000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    fps             | 86       |
|    iterations      | 88       |
|    time_elapsed    | 2079     |
|    total_timesteps | 180224   |
---------------------------------
Eval num_timesteps=180500, episode_reward=0.45 +/- 0.49
Episode length: 27.44 +/- 15.33
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.4        |
|    mean_reward          | 0.451       |
| time/                   |             |
|    total_timesteps      | 180500      |
| train/                  |             |
|    approx_kl            | 0.016013408 |
|    clip_fraction        | 0.0941      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.256      |
|    explained_variance   | 0.598       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00184     |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.0145     |
|    value_loss           | 0.0366      |
-----------------------------------------
Eval num_timesteps=181000, episode_reward=0.49 +/- 0.51
Episode length: 27.54 +/- 16.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.491    |
| time/              |          |
|    total_timesteps | 181000   |
---------------------------------
Eval num_timesteps=181500, episode_reward=0.41 +/- 0.51
Episode length: 31.90 +/- 19.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.9     |
|    mean_reward     | 0.413    |
| time/              |          |
|    total_timesteps | 181500   |
---------------------------------
Eval num_timesteps=182000, episode_reward=0.36 +/- 0.50
Episode length: 30.60 +/- 15.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.359    |
| time/              |          |
|    total_timesteps | 182000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.4     |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    fps             | 86       |
|    iterations      | 89       |
|    time_elapsed    | 2098     |
|    total_timesteps | 182272   |
---------------------------------
Eval num_timesteps=182500, episode_reward=0.42 +/- 0.49
Episode length: 29.44 +/- 14.64
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 29.4      |
|    mean_reward          | 0.423     |
| time/                   |           |
|    total_timesteps      | 182500    |
| train/                  |           |
|    approx_kl            | 0.0136788 |
|    clip_fraction        | 0.111     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.344    |
|    explained_variance   | 0.516     |
|    learning_rate        | 0.0001    |
|    loss                 | 0.00104   |
|    n_updates            | 890       |
|    policy_gradient_loss | -0.016    |
|    value_loss           | 0.0496    |
---------------------------------------
Eval num_timesteps=183000, episode_reward=0.46 +/- 0.51
Episode length: 25.08 +/- 15.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.1     |
|    mean_reward     | 0.461    |
| time/              |          |
|    total_timesteps | 183000   |
---------------------------------
Eval num_timesteps=183500, episode_reward=0.38 +/- 0.50
Episode length: 25.84 +/- 13.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.8     |
|    mean_reward     | 0.378    |
| time/              |          |
|    total_timesteps | 183500   |
---------------------------------
Eval num_timesteps=184000, episode_reward=0.30 +/- 0.50
Episode length: 29.72 +/- 16.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.7     |
|    mean_reward     | 0.302    |
| time/              |          |
|    total_timesteps | 184000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.3     |
|    ep_rew_mean     | 0.326    |
| time/              |          |
|    fps             | 87       |
|    iterations      | 90       |
|    time_elapsed    | 2117     |
|    total_timesteps | 184320   |
---------------------------------
Eval num_timesteps=184500, episode_reward=0.41 +/- 0.52
Episode length: 28.88 +/- 16.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.9        |
|    mean_reward          | 0.406       |
| time/                   |             |
|    total_timesteps      | 184500      |
| train/                  |             |
|    approx_kl            | 0.012079741 |
|    clip_fraction        | 0.0994      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.322      |
|    explained_variance   | 0.468       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0178      |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0121     |
|    value_loss           | 0.0448      |
-----------------------------------------
Eval num_timesteps=185000, episode_reward=0.50 +/- 0.50
Episode length: 24.54 +/- 14.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.5     |
|    mean_reward     | 0.503    |
| time/              |          |
|    total_timesteps | 185000   |
---------------------------------
Eval num_timesteps=185500, episode_reward=0.55 +/- 0.50
Episode length: 28.18 +/- 15.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.549    |
| time/              |          |
|    total_timesteps | 185500   |
---------------------------------
Eval num_timesteps=186000, episode_reward=0.37 +/- 0.50
Episode length: 26.88 +/- 14.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.9     |
|    mean_reward     | 0.374    |
| time/              |          |
|    total_timesteps | 186000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    fps             | 87       |
|    iterations      | 91       |
|    time_elapsed    | 2135     |
|    total_timesteps | 186368   |
---------------------------------
Eval num_timesteps=186500, episode_reward=0.54 +/- 0.48
Episode length: 26.32 +/- 13.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.3        |
|    mean_reward          | 0.536       |
| time/                   |             |
|    total_timesteps      | 186500      |
| train/                  |             |
|    approx_kl            | 0.011999614 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.279      |
|    explained_variance   | 0.429       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00329    |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.0495      |
-----------------------------------------
Eval num_timesteps=187000, episode_reward=0.40 +/- 0.51
Episode length: 29.40 +/- 17.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.4     |
|    mean_reward     | 0.403    |
| time/              |          |
|    total_timesteps | 187000   |
---------------------------------
Eval num_timesteps=187500, episode_reward=0.48 +/- 0.50
Episode length: 24.70 +/- 13.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.7     |
|    mean_reward     | 0.482    |
| time/              |          |
|    total_timesteps | 187500   |
---------------------------------
Eval num_timesteps=188000, episode_reward=0.33 +/- 0.50
Episode length: 27.64 +/- 16.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.6     |
|    mean_reward     | 0.331    |
| time/              |          |
|    total_timesteps | 188000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.6     |
|    ep_rew_mean     | 0.435    |
| time/              |          |
|    fps             | 87       |
|    iterations      | 92       |
|    time_elapsed    | 2153     |
|    total_timesteps | 188416   |
---------------------------------
Eval num_timesteps=188500, episode_reward=0.40 +/- 0.49
Episode length: 25.62 +/- 12.46
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.6        |
|    mean_reward          | 0.399       |
| time/                   |             |
|    total_timesteps      | 188500      |
| train/                  |             |
|    approx_kl            | 0.009742063 |
|    clip_fraction        | 0.0946      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.281      |
|    explained_variance   | 0.512       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0154      |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 0.045       |
-----------------------------------------
Eval num_timesteps=189000, episode_reward=0.37 +/- 0.51
Episode length: 28.32 +/- 17.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.3     |
|    mean_reward     | 0.368    |
| time/              |          |
|    total_timesteps | 189000   |
---------------------------------
Eval num_timesteps=189500, episode_reward=0.42 +/- 0.51
Episode length: 30.28 +/- 16.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.42     |
| time/              |          |
|    total_timesteps | 189500   |
---------------------------------
Eval num_timesteps=190000, episode_reward=0.52 +/- 0.50
Episode length: 30.70 +/- 16.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.7     |
|    mean_reward     | 0.518    |
| time/              |          |
|    total_timesteps | 190000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.3     |
|    ep_rew_mean     | 0.4      |
| time/              |          |
|    fps             | 87       |
|    iterations      | 93       |
|    time_elapsed    | 2172     |
|    total_timesteps | 190464   |
---------------------------------
Eval num_timesteps=190500, episode_reward=0.46 +/- 0.48
Episode length: 30.86 +/- 16.14
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 30.9         |
|    mean_reward          | 0.458        |
| time/                   |              |
|    total_timesteps      | 190500       |
| train/                  |              |
|    approx_kl            | 0.0130439205 |
|    clip_fraction        | 0.0977       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.299       |
|    explained_variance   | 0.406        |
|    learning_rate        | 0.0001       |
|    loss                 | 0.0228       |
|    n_updates            | 930          |
|    policy_gradient_loss | -0.0138      |
|    value_loss           | 0.058        |
------------------------------------------
Eval num_timesteps=191000, episode_reward=0.45 +/- 0.49
Episode length: 27.74 +/- 12.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.45     |
| time/              |          |
|    total_timesteps | 191000   |
---------------------------------
Eval num_timesteps=191500, episode_reward=0.44 +/- 0.51
Episode length: 26.12 +/- 14.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.1     |
|    mean_reward     | 0.436    |
| time/              |          |
|    total_timesteps | 191500   |
---------------------------------
Eval num_timesteps=192000, episode_reward=0.45 +/- 0.51
Episode length: 26.60 +/- 16.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.6     |
|    mean_reward     | 0.455    |
| time/              |          |
|    total_timesteps | 192000   |
---------------------------------
Eval num_timesteps=192500, episode_reward=0.46 +/- 0.49
Episode length: 31.22 +/- 15.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.456    |
| time/              |          |
|    total_timesteps | 192500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.8     |
|    ep_rew_mean     | 0.35     |
| time/              |          |
|    fps             | 87       |
|    iterations      | 94       |
|    time_elapsed    | 2193     |
|    total_timesteps | 192512   |
---------------------------------
Eval num_timesteps=193000, episode_reward=0.63 +/- 0.46
Episode length: 27.24 +/- 15.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.2        |
|    mean_reward          | 0.632       |
| time/                   |             |
|    total_timesteps      | 193000      |
| train/                  |             |
|    approx_kl            | 0.013095963 |
|    clip_fraction        | 0.0919      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.3        |
|    explained_variance   | 0.496       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0488      |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.00885    |
|    value_loss           | 0.0536      |
-----------------------------------------
Eval num_timesteps=193500, episode_reward=0.60 +/- 0.46
Episode length: 26.32 +/- 14.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.3     |
|    mean_reward     | 0.596    |
| time/              |          |
|    total_timesteps | 193500   |
---------------------------------
Eval num_timesteps=194000, episode_reward=0.36 +/- 0.52
Episode length: 29.74 +/- 17.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.7     |
|    mean_reward     | 0.362    |
| time/              |          |
|    total_timesteps | 194000   |
---------------------------------
Eval num_timesteps=194500, episode_reward=0.41 +/- 0.52
Episode length: 28.74 +/- 17.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.7     |
|    mean_reward     | 0.406    |
| time/              |          |
|    total_timesteps | 194500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.6     |
|    ep_rew_mean     | 0.313    |
| time/              |          |
|    fps             | 87       |
|    iterations      | 95       |
|    time_elapsed    | 2211     |
|    total_timesteps | 194560   |
---------------------------------
Eval num_timesteps=195000, episode_reward=0.56 +/- 0.49
Episode length: 29.72 +/- 19.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.7        |
|    mean_reward          | 0.562       |
| time/                   |             |
|    total_timesteps      | 195000      |
| train/                  |             |
|    approx_kl            | 0.013453539 |
|    clip_fraction        | 0.0839      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.256      |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00652     |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.0439      |
-----------------------------------------
Eval num_timesteps=195500, episode_reward=0.54 +/- 0.49
Episode length: 30.12 +/- 16.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.541    |
| time/              |          |
|    total_timesteps | 195500   |
---------------------------------
Eval num_timesteps=196000, episode_reward=0.56 +/- 0.47
Episode length: 29.58 +/- 15.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.6     |
|    mean_reward     | 0.563    |
| time/              |          |
|    total_timesteps | 196000   |
---------------------------------
Eval num_timesteps=196500, episode_reward=0.52 +/- 0.50
Episode length: 29.30 +/- 16.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.524    |
| time/              |          |
|    total_timesteps | 196500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.4     |
|    ep_rew_mean     | 0.362    |
| time/              |          |
|    fps             | 88       |
|    iterations      | 96       |
|    time_elapsed    | 2230     |
|    total_timesteps | 196608   |
---------------------------------
Eval num_timesteps=197000, episode_reward=0.31 +/- 0.51
Episode length: 31.64 +/- 16.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.6        |
|    mean_reward          | 0.315       |
| time/                   |             |
|    total_timesteps      | 197000      |
| train/                  |             |
|    approx_kl            | 0.014283796 |
|    clip_fraction        | 0.0647      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.152      |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0124      |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 0.0464      |
-----------------------------------------
Eval num_timesteps=197500, episode_reward=0.56 +/- 0.47
Episode length: 30.54 +/- 16.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.5     |
|    mean_reward     | 0.559    |
| time/              |          |
|    total_timesteps | 197500   |
---------------------------------
Eval num_timesteps=198000, episode_reward=0.47 +/- 0.50
Episode length: 33.86 +/- 16.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.9     |
|    mean_reward     | 0.466    |
| time/              |          |
|    total_timesteps | 198000   |
---------------------------------
Eval num_timesteps=198500, episode_reward=0.43 +/- 0.51
Episode length: 28.26 +/- 17.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.3     |
|    mean_reward     | 0.428    |
| time/              |          |
|    total_timesteps | 198500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.1     |
|    ep_rew_mean     | 0.513    |
| time/              |          |
|    fps             | 88       |
|    iterations      | 97       |
|    time_elapsed    | 2249     |
|    total_timesteps | 198656   |
---------------------------------
Eval num_timesteps=199000, episode_reward=0.51 +/- 0.48
Episode length: 27.96 +/- 13.62
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28          |
|    mean_reward          | 0.51        |
| time/                   |             |
|    total_timesteps      | 199000      |
| train/                  |             |
|    approx_kl            | 0.015507208 |
|    clip_fraction        | 0.0822      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.183      |
|    explained_variance   | 0.488       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0204     |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.0466      |
-----------------------------------------
Eval num_timesteps=199500, episode_reward=0.47 +/- 0.50
Episode length: 31.86 +/- 16.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.9     |
|    mean_reward     | 0.474    |
| time/              |          |
|    total_timesteps | 199500   |
---------------------------------
Eval num_timesteps=200000, episode_reward=0.36 +/- 0.50
Episode length: 29.20 +/- 15.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.364    |
| time/              |          |
|    total_timesteps | 200000   |
---------------------------------
Eval num_timesteps=200500, episode_reward=0.50 +/- 0.52
Episode length: 30.12 +/- 18.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.501    |
| time/              |          |
|    total_timesteps | 200500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.1     |
|    ep_rew_mean     | 0.475    |
| time/              |          |
|    fps             | 88       |
|    iterations      | 98       |
|    time_elapsed    | 2268     |
|    total_timesteps | 200704   |
---------------------------------
Eval num_timesteps=201000, episode_reward=0.59 +/- 0.47
Episode length: 28.38 +/- 14.46
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.4        |
|    mean_reward          | 0.588       |
| time/                   |             |
|    total_timesteps      | 201000      |
| train/                  |             |
|    approx_kl            | 0.012707501 |
|    clip_fraction        | 0.0837      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.225      |
|    explained_variance   | 0.464       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00246    |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.0463      |
-----------------------------------------
Eval num_timesteps=201500, episode_reward=0.44 +/- 0.52
Episode length: 26.52 +/- 15.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.435    |
| time/              |          |
|    total_timesteps | 201500   |
---------------------------------
Eval num_timesteps=202000, episode_reward=0.56 +/- 0.47
Episode length: 29.76 +/- 15.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.562    |
| time/              |          |
|    total_timesteps | 202000   |
---------------------------------
Eval num_timesteps=202500, episode_reward=0.55 +/- 0.48
Episode length: 21.62 +/- 10.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 21.6     |
|    mean_reward     | 0.555    |
| time/              |          |
|    total_timesteps | 202500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 0.458    |
| time/              |          |
|    fps             | 88       |
|    iterations      | 99       |
|    time_elapsed    | 2286     |
|    total_timesteps | 202752   |
---------------------------------
Eval num_timesteps=203000, episode_reward=0.66 +/- 0.43
Episode length: 29.32 +/- 15.23
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.3        |
|    mean_reward          | 0.664       |
| time/                   |             |
|    total_timesteps      | 203000      |
| train/                  |             |
|    approx_kl            | 0.015073206 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.29       |
|    explained_variance   | 0.38        |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00673    |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0185     |
|    value_loss           | 0.0574      |
-----------------------------------------
New best mean reward!
Eval num_timesteps=203500, episode_reward=0.50 +/- 0.49
Episode length: 31.12 +/- 19.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.1     |
|    mean_reward     | 0.497    |
| time/              |          |
|    total_timesteps | 203500   |
---------------------------------
Eval num_timesteps=204000, episode_reward=0.35 +/- 0.52
Episode length: 28.56 +/- 16.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.347    |
| time/              |          |
|    total_timesteps | 204000   |
---------------------------------
Eval num_timesteps=204500, episode_reward=0.53 +/- 0.51
Episode length: 27.76 +/- 17.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.53     |
| time/              |          |
|    total_timesteps | 204500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.421    |
| time/              |          |
|    fps             | 88       |
|    iterations      | 100      |
|    time_elapsed    | 2305     |
|    total_timesteps | 204800   |
---------------------------------
Eval num_timesteps=205000, episode_reward=0.51 +/- 0.49
Episode length: 32.40 +/- 17.67
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 32.4      |
|    mean_reward          | 0.511     |
| time/                   |           |
|    total_timesteps      | 205000    |
| train/                  |           |
|    approx_kl            | 0.0133811 |
|    clip_fraction        | 0.0708    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.233    |
|    explained_variance   | 0.401     |
|    learning_rate        | 0.0001    |
|    loss                 | -0.0101   |
|    n_updates            | 1000      |
|    policy_gradient_loss | -0.0122   |
|    value_loss           | 0.0493    |
---------------------------------------
Eval num_timesteps=205500, episode_reward=0.68 +/- 0.41
Episode length: 25.22 +/- 13.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.2     |
|    mean_reward     | 0.68     |
| time/              |          |
|    total_timesteps | 205500   |
---------------------------------
New best mean reward!
Eval num_timesteps=206000, episode_reward=0.55 +/- 0.47
Episode length: 27.32 +/- 15.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.3     |
|    mean_reward     | 0.552    |
| time/              |          |
|    total_timesteps | 206000   |
---------------------------------
Eval num_timesteps=206500, episode_reward=0.42 +/- 0.51
Episode length: 29.82 +/- 16.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.422    |
| time/              |          |
|    total_timesteps | 206500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.9     |
|    ep_rew_mean     | 0.368    |
| time/              |          |
|    fps             | 89       |
|    iterations      | 101      |
|    time_elapsed    | 2323     |
|    total_timesteps | 206848   |
---------------------------------
Eval num_timesteps=207000, episode_reward=0.48 +/- 0.51
Episode length: 25.84 +/- 15.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 25.8       |
|    mean_reward          | 0.478      |
| time/                   |            |
|    total_timesteps      | 207000     |
| train/                  |            |
|    approx_kl            | 0.01017031 |
|    clip_fraction        | 0.0907     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.283     |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0107    |
|    n_updates            | 1010       |
|    policy_gradient_loss | -0.0137    |
|    value_loss           | 0.0479     |
----------------------------------------
Eval num_timesteps=207500, episode_reward=0.45 +/- 0.51
Episode length: 26.74 +/- 13.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.7     |
|    mean_reward     | 0.454    |
| time/              |          |
|    total_timesteps | 207500   |
---------------------------------
Eval num_timesteps=208000, episode_reward=0.50 +/- 0.49
Episode length: 30.82 +/- 14.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.8     |
|    mean_reward     | 0.498    |
| time/              |          |
|    total_timesteps | 208000   |
---------------------------------
Eval num_timesteps=208500, episode_reward=0.44 +/- 0.52
Episode length: 30.50 +/- 18.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.5     |
|    mean_reward     | 0.439    |
| time/              |          |
|    total_timesteps | 208500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.8     |
|    ep_rew_mean     | 0.394    |
| time/              |          |
|    fps             | 89       |
|    iterations      | 102      |
|    time_elapsed    | 2342     |
|    total_timesteps | 208896   |
---------------------------------
Eval num_timesteps=209000, episode_reward=0.56 +/- 0.49
Episode length: 25.64 +/- 15.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.6        |
|    mean_reward          | 0.559       |
| time/                   |             |
|    total_timesteps      | 209000      |
| train/                  |             |
|    approx_kl            | 0.012801704 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.279      |
|    explained_variance   | 0.501       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00871     |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0166     |
|    value_loss           | 0.0405      |
-----------------------------------------
Eval num_timesteps=209500, episode_reward=0.51 +/- 0.50
Episode length: 26.98 +/- 16.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.513    |
| time/              |          |
|    total_timesteps | 209500   |
---------------------------------
Eval num_timesteps=210000, episode_reward=0.54 +/- 0.48
Episode length: 29.22 +/- 16.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.544    |
| time/              |          |
|    total_timesteps | 210000   |
---------------------------------
Eval num_timesteps=210500, episode_reward=0.50 +/- 0.50
Episode length: 31.06 +/- 18.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.1     |
|    mean_reward     | 0.497    |
| time/              |          |
|    total_timesteps | 210500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 0.453    |
| time/              |          |
|    fps             | 89       |
|    iterations      | 103      |
|    time_elapsed    | 2360     |
|    total_timesteps | 210944   |
---------------------------------
Eval num_timesteps=211000, episode_reward=0.60 +/- 0.45
Episode length: 29.26 +/- 14.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.3        |
|    mean_reward          | 0.604       |
| time/                   |             |
|    total_timesteps      | 211000      |
| train/                  |             |
|    approx_kl            | 0.014113359 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.275      |
|    explained_variance   | 0.525       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00777    |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.0475      |
-----------------------------------------
Eval num_timesteps=211500, episode_reward=0.42 +/- 0.53
Episode length: 31.38 +/- 18.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.416    |
| time/              |          |
|    total_timesteps | 211500   |
---------------------------------
Eval num_timesteps=212000, episode_reward=0.47 +/- 0.50
Episode length: 28.12 +/- 15.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.1     |
|    mean_reward     | 0.469    |
| time/              |          |
|    total_timesteps | 212000   |
---------------------------------
Eval num_timesteps=212500, episode_reward=0.51 +/- 0.49
Episode length: 27.44 +/- 16.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.4     |
|    mean_reward     | 0.511    |
| time/              |          |
|    total_timesteps | 212500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.9     |
|    ep_rew_mean     | 0.534    |
| time/              |          |
|    fps             | 89       |
|    iterations      | 104      |
|    time_elapsed    | 2379     |
|    total_timesteps | 212992   |
---------------------------------
Eval num_timesteps=213000, episode_reward=0.50 +/- 0.51
Episode length: 31.52 +/- 18.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.5        |
|    mean_reward          | 0.495       |
| time/                   |             |
|    total_timesteps      | 213000      |
| train/                  |             |
|    approx_kl            | 0.013466282 |
|    clip_fraction        | 0.0926      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.237      |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0272      |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0123     |
|    value_loss           | 0.0462      |
-----------------------------------------
Eval num_timesteps=213500, episode_reward=0.51 +/- 0.50
Episode length: 27.76 +/- 16.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.51     |
| time/              |          |
|    total_timesteps | 213500   |
---------------------------------
Eval num_timesteps=214000, episode_reward=0.46 +/- 0.51
Episode length: 31.30 +/- 17.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.3     |
|    mean_reward     | 0.456    |
| time/              |          |
|    total_timesteps | 214000   |
---------------------------------
Eval num_timesteps=214500, episode_reward=0.47 +/- 0.50
Episode length: 31.94 +/- 15.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.9     |
|    mean_reward     | 0.474    |
| time/              |          |
|    total_timesteps | 214500   |
---------------------------------
Eval num_timesteps=215000, episode_reward=0.61 +/- 0.44
Episode length: 31.66 +/- 16.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.7     |
|    mean_reward     | 0.615    |
| time/              |          |
|    total_timesteps | 215000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.4     |
|    ep_rew_mean     | 0.484    |
| time/              |          |
|    fps             | 89       |
|    iterations      | 105      |
|    time_elapsed    | 2401     |
|    total_timesteps | 215040   |
---------------------------------
Eval num_timesteps=215500, episode_reward=0.44 +/- 0.50
Episode length: 29.52 +/- 14.77
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.5        |
|    mean_reward          | 0.443       |
| time/                   |             |
|    total_timesteps      | 215500      |
| train/                  |             |
|    approx_kl            | 0.013203112 |
|    clip_fraction        | 0.0891      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.22       |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00509     |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.0114     |
|    value_loss           | 0.0527      |
-----------------------------------------
Eval num_timesteps=216000, episode_reward=0.51 +/- 0.49
Episode length: 28.38 +/- 14.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.4     |
|    mean_reward     | 0.508    |
| time/              |          |
|    total_timesteps | 216000   |
---------------------------------
Eval num_timesteps=216500, episode_reward=0.39 +/- 0.52
Episode length: 32.76 +/- 18.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.8     |
|    mean_reward     | 0.39     |
| time/              |          |
|    total_timesteps | 216500   |
---------------------------------
Eval num_timesteps=217000, episode_reward=0.55 +/- 0.49
Episode length: 28.36 +/- 17.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.4     |
|    mean_reward     | 0.548    |
| time/              |          |
|    total_timesteps | 217000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    fps             | 89       |
|    iterations      | 106      |
|    time_elapsed    | 2420     |
|    total_timesteps | 217088   |
---------------------------------
Eval num_timesteps=217500, episode_reward=0.51 +/- 0.50
Episode length: 26.90 +/- 14.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.9        |
|    mean_reward          | 0.514       |
| time/                   |             |
|    total_timesteps      | 217500      |
| train/                  |             |
|    approx_kl            | 0.013290295 |
|    clip_fraction        | 0.0912      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.256      |
|    explained_variance   | 0.524       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00184     |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.0442      |
-----------------------------------------
Eval num_timesteps=218000, episode_reward=0.60 +/- 0.47
Episode length: 30.26 +/- 15.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 218000   |
---------------------------------
Eval num_timesteps=218500, episode_reward=0.55 +/- 0.49
Episode length: 23.04 +/- 12.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23       |
|    mean_reward     | 0.549    |
| time/              |          |
|    total_timesteps | 218500   |
---------------------------------
Eval num_timesteps=219000, episode_reward=0.59 +/- 0.46
Episode length: 28.04 +/- 16.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28       |
|    mean_reward     | 0.589    |
| time/              |          |
|    total_timesteps | 219000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.9     |
|    ep_rew_mean     | 0.515    |
| time/              |          |
|    fps             | 89       |
|    iterations      | 107      |
|    time_elapsed    | 2436     |
|    total_timesteps | 219136   |
---------------------------------
Eval num_timesteps=219500, episode_reward=0.53 +/- 0.48
Episode length: 27.40 +/- 14.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.4        |
|    mean_reward          | 0.532       |
| time/                   |             |
|    total_timesteps      | 219500      |
| train/                  |             |
|    approx_kl            | 0.014503501 |
|    clip_fraction        | 0.061       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.161      |
|    explained_variance   | 0.577       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00535    |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.00992    |
|    value_loss           | 0.0426      |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=0.53 +/- 0.48
Episode length: 27.14 +/- 14.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.1     |
|    mean_reward     | 0.533    |
| time/              |          |
|    total_timesteps | 220000   |
---------------------------------
Eval num_timesteps=220500, episode_reward=0.38 +/- 0.51
Episode length: 24.04 +/- 14.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24       |
|    mean_reward     | 0.385    |
| time/              |          |
|    total_timesteps | 220500   |
---------------------------------
Eval num_timesteps=221000, episode_reward=0.66 +/- 0.43
Episode length: 24.78 +/- 12.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.8     |
|    mean_reward     | 0.662    |
| time/              |          |
|    total_timesteps | 221000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27       |
|    ep_rew_mean     | 0.513    |
| time/              |          |
|    fps             | 90       |
|    iterations      | 108      |
|    time_elapsed    | 2454     |
|    total_timesteps | 221184   |
---------------------------------
Eval num_timesteps=221500, episode_reward=0.43 +/- 0.51
Episode length: 29.02 +/- 16.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29          |
|    mean_reward          | 0.425       |
| time/                   |             |
|    total_timesteps      | 221500      |
| train/                  |             |
|    approx_kl            | 0.016709462 |
|    clip_fraction        | 0.0919      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.229      |
|    explained_variance   | 0.503       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00256     |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.0102     |
|    value_loss           | 0.0517      |
-----------------------------------------
Eval num_timesteps=222000, episode_reward=0.45 +/- 0.50
Episode length: 27.54 +/- 15.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.451    |
| time/              |          |
|    total_timesteps | 222000   |
---------------------------------
Eval num_timesteps=222500, episode_reward=0.54 +/- 0.48
Episode length: 29.10 +/- 16.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.545    |
| time/              |          |
|    total_timesteps | 222500   |
---------------------------------
Eval num_timesteps=223000, episode_reward=0.64 +/- 0.45
Episode length: 26.16 +/- 14.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.2     |
|    mean_reward     | 0.637    |
| time/              |          |
|    total_timesteps | 223000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.1     |
|    ep_rew_mean     | 0.595    |
| time/              |          |
|    fps             | 90       |
|    iterations      | 109      |
|    time_elapsed    | 2471     |
|    total_timesteps | 223232   |
---------------------------------
Eval num_timesteps=223500, episode_reward=0.47 +/- 0.51
Episode length: 28.26 +/- 17.13
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.3        |
|    mean_reward          | 0.468       |
| time/                   |             |
|    total_timesteps      | 223500      |
| train/                  |             |
|    approx_kl            | 0.019149985 |
|    clip_fraction        | 0.0995      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.247      |
|    explained_variance   | 0.554       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00705     |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0143     |
|    value_loss           | 0.0453      |
-----------------------------------------
Eval num_timesteps=224000, episode_reward=0.52 +/- 0.49
Episode length: 26.34 +/- 13.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.3     |
|    mean_reward     | 0.516    |
| time/              |          |
|    total_timesteps | 224000   |
---------------------------------
Eval num_timesteps=224500, episode_reward=0.46 +/- 0.50
Episode length: 25.72 +/- 12.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.7     |
|    mean_reward     | 0.458    |
| time/              |          |
|    total_timesteps | 224500   |
---------------------------------
Eval num_timesteps=225000, episode_reward=0.48 +/- 0.50
Episode length: 26.02 +/- 13.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26       |
|    mean_reward     | 0.477    |
| time/              |          |
|    total_timesteps | 225000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.6     |
|    ep_rew_mean     | 0.495    |
| time/              |          |
|    fps             | 90       |
|    iterations      | 110      |
|    time_elapsed    | 2489     |
|    total_timesteps | 225280   |
---------------------------------
Eval num_timesteps=225500, episode_reward=0.55 +/- 0.49
Episode length: 33.86 +/- 18.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 33.9       |
|    mean_reward          | 0.546      |
| time/                   |            |
|    total_timesteps      | 225500     |
| train/                  |            |
|    approx_kl            | 0.01621981 |
|    clip_fraction        | 0.0959     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.233     |
|    explained_variance   | 0.418      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00821   |
|    n_updates            | 1100       |
|    policy_gradient_loss | -0.012     |
|    value_loss           | 0.0476     |
----------------------------------------
Eval num_timesteps=226000, episode_reward=0.51 +/- 0.49
Episode length: 33.02 +/- 17.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33       |
|    mean_reward     | 0.509    |
| time/              |          |
|    total_timesteps | 226000   |
---------------------------------
Eval num_timesteps=226500, episode_reward=0.60 +/- 0.46
Episode length: 29.52 +/- 13.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.603    |
| time/              |          |
|    total_timesteps | 226500   |
---------------------------------
Eval num_timesteps=227000, episode_reward=0.58 +/- 0.48
Episode length: 31.42 +/- 18.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.576    |
| time/              |          |
|    total_timesteps | 227000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 0.457    |
| time/              |          |
|    fps             | 90       |
|    iterations      | 111      |
|    time_elapsed    | 2508     |
|    total_timesteps | 227328   |
---------------------------------
Eval num_timesteps=227500, episode_reward=0.56 +/- 0.50
Episode length: 30.26 +/- 18.89
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.3        |
|    mean_reward          | 0.56        |
| time/                   |             |
|    total_timesteps      | 227500      |
| train/                  |             |
|    approx_kl            | 0.016874164 |
|    clip_fraction        | 0.0993      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.294      |
|    explained_variance   | 0.5         |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00521    |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0131     |
|    value_loss           | 0.05        |
-----------------------------------------
Eval num_timesteps=228000, episode_reward=0.54 +/- 0.47
Episode length: 31.28 +/- 14.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.3     |
|    mean_reward     | 0.536    |
| time/              |          |
|    total_timesteps | 228000   |
---------------------------------
Eval num_timesteps=228500, episode_reward=0.61 +/- 0.47
Episode length: 32.06 +/- 17.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.1     |
|    mean_reward     | 0.613    |
| time/              |          |
|    total_timesteps | 228500   |
---------------------------------
Eval num_timesteps=229000, episode_reward=0.60 +/- 0.47
Episode length: 26.18 +/- 14.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.2     |
|    mean_reward     | 0.596    |
| time/              |          |
|    total_timesteps | 229000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.3     |
|    ep_rew_mean     | 0.384    |
| time/              |          |
|    fps             | 90       |
|    iterations      | 112      |
|    time_elapsed    | 2525     |
|    total_timesteps | 229376   |
---------------------------------
Eval num_timesteps=229500, episode_reward=0.58 +/- 0.48
Episode length: 29.98 +/- 15.88
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.581       |
| time/                   |             |
|    total_timesteps      | 229500      |
| train/                  |             |
|    approx_kl            | 0.010111696 |
|    clip_fraction        | 0.0688      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.195      |
|    explained_variance   | 0.557       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.000919   |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 0.0383      |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=0.51 +/- 0.48
Episode length: 32.08 +/- 17.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.1     |
|    mean_reward     | 0.513    |
| time/              |          |
|    total_timesteps | 230000   |
---------------------------------
Eval num_timesteps=230500, episode_reward=0.61 +/- 0.45
Episode length: 32.32 +/- 16.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.3     |
|    mean_reward     | 0.612    |
| time/              |          |
|    total_timesteps | 230500   |
---------------------------------
Eval num_timesteps=231000, episode_reward=0.53 +/- 0.48
Episode length: 28.34 +/- 14.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.3     |
|    mean_reward     | 0.528    |
| time/              |          |
|    total_timesteps | 231000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.7     |
|    ep_rew_mean     | 0.324    |
| time/              |          |
|    fps             | 90       |
|    iterations      | 113      |
|    time_elapsed    | 2544     |
|    total_timesteps | 231424   |
---------------------------------
Eval num_timesteps=231500, episode_reward=0.67 +/- 0.43
Episode length: 28.76 +/- 16.14
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.8       |
|    mean_reward          | 0.666      |
| time/                   |            |
|    total_timesteps      | 231500     |
| train/                  |            |
|    approx_kl            | 0.01565207 |
|    clip_fraction        | 0.0995     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.228     |
|    explained_variance   | 0.557      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00391    |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.0161    |
|    value_loss           | 0.0414     |
----------------------------------------
Eval num_timesteps=232000, episode_reward=0.59 +/- 0.48
Episode length: 27.28 +/- 16.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.3     |
|    mean_reward     | 0.592    |
| time/              |          |
|    total_timesteps | 232000   |
---------------------------------
Eval num_timesteps=232500, episode_reward=0.50 +/- 0.50
Episode length: 29.10 +/- 16.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.505    |
| time/              |          |
|    total_timesteps | 232500   |
---------------------------------
Eval num_timesteps=233000, episode_reward=0.43 +/- 0.52
Episode length: 32.46 +/- 15.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.5     |
|    mean_reward     | 0.431    |
| time/              |          |
|    total_timesteps | 233000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.8     |
|    ep_rew_mean     | 0.5      |
| time/              |          |
|    fps             | 91       |
|    iterations      | 114      |
|    time_elapsed    | 2563     |
|    total_timesteps | 233472   |
---------------------------------
Eval num_timesteps=233500, episode_reward=0.63 +/- 0.46
Episode length: 28.82 +/- 16.34
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.8        |
|    mean_reward          | 0.626       |
| time/                   |             |
|    total_timesteps      | 233500      |
| train/                  |             |
|    approx_kl            | 0.016203348 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.252      |
|    explained_variance   | 0.448       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0035      |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0175     |
|    value_loss           | 0.0569      |
-----------------------------------------
Eval num_timesteps=234000, episode_reward=0.54 +/- 0.50
Episode length: 30.22 +/- 17.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.54     |
| time/              |          |
|    total_timesteps | 234000   |
---------------------------------
Eval num_timesteps=234500, episode_reward=0.57 +/- 0.47
Episode length: 27.42 +/- 16.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.4     |
|    mean_reward     | 0.572    |
| time/              |          |
|    total_timesteps | 234500   |
---------------------------------
Eval num_timesteps=235000, episode_reward=0.53 +/- 0.51
Episode length: 32.80 +/- 18.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.8     |
|    mean_reward     | 0.53     |
| time/              |          |
|    total_timesteps | 235000   |
---------------------------------
Eval num_timesteps=235500, episode_reward=0.50 +/- 0.50
Episode length: 29.46 +/- 17.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.503    |
| time/              |          |
|    total_timesteps | 235500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27       |
|    ep_rew_mean     | 0.523    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 115      |
|    time_elapsed    | 2584     |
|    total_timesteps | 235520   |
---------------------------------
Eval num_timesteps=236000, episode_reward=0.53 +/- 0.49
Episode length: 28.90 +/- 17.22
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.9        |
|    mean_reward          | 0.526       |
| time/                   |             |
|    total_timesteps      | 236000      |
| train/                  |             |
|    approx_kl            | 0.019939722 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.275      |
|    explained_variance   | 0.515       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0133     |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0186     |
|    value_loss           | 0.0428      |
-----------------------------------------
Eval num_timesteps=236500, episode_reward=0.57 +/- 0.47
Episode length: 27.52 +/- 17.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.571    |
| time/              |          |
|    total_timesteps | 236500   |
---------------------------------
Eval num_timesteps=237000, episode_reward=0.61 +/- 0.46
Episode length: 27.62 +/- 17.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.6     |
|    mean_reward     | 0.611    |
| time/              |          |
|    total_timesteps | 237000   |
---------------------------------
Eval num_timesteps=237500, episode_reward=0.44 +/- 0.53
Episode length: 30.72 +/- 18.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.7     |
|    mean_reward     | 0.439    |
| time/              |          |
|    total_timesteps | 237500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31       |
|    ep_rew_mean     | 0.457    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 116      |
|    time_elapsed    | 2603     |
|    total_timesteps | 237568   |
---------------------------------
Eval num_timesteps=238000, episode_reward=0.46 +/- 0.52
Episode length: 30.38 +/- 16.99
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.4        |
|    mean_reward          | 0.46        |
| time/                   |             |
|    total_timesteps      | 238000      |
| train/                  |             |
|    approx_kl            | 0.013416537 |
|    clip_fraction        | 0.0777      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.21       |
|    explained_variance   | 0.496       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0115     |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0146     |
|    value_loss           | 0.0417      |
-----------------------------------------
Eval num_timesteps=238500, episode_reward=0.47 +/- 0.53
Episode length: 33.70 +/- 20.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.7     |
|    mean_reward     | 0.466    |
| time/              |          |
|    total_timesteps | 238500   |
---------------------------------
Eval num_timesteps=239000, episode_reward=0.60 +/- 0.46
Episode length: 29.96 +/- 15.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30       |
|    mean_reward     | 0.602    |
| time/              |          |
|    total_timesteps | 239000   |
---------------------------------
Eval num_timesteps=239500, episode_reward=0.52 +/- 0.48
Episode length: 30.34 +/- 16.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.52     |
| time/              |          |
|    total_timesteps | 239500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.6     |
|    ep_rew_mean     | 0.423    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 117      |
|    time_elapsed    | 2623     |
|    total_timesteps | 239616   |
---------------------------------
Eval num_timesteps=240000, episode_reward=0.56 +/- 0.49
Episode length: 31.60 +/- 16.19
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.6        |
|    mean_reward          | 0.555       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.013226882 |
|    clip_fraction        | 0.0987      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.29       |
|    explained_variance   | 0.384       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0137      |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0163     |
|    value_loss           | 0.0547      |
-----------------------------------------
Eval num_timesteps=240500, episode_reward=0.55 +/- 0.49
Episode length: 34.02 +/- 17.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34       |
|    mean_reward     | 0.545    |
| time/              |          |
|    total_timesteps | 240500   |
---------------------------------
Eval num_timesteps=241000, episode_reward=0.61 +/- 0.48
Episode length: 33.38 +/- 18.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.4     |
|    mean_reward     | 0.608    |
| time/              |          |
|    total_timesteps | 241000   |
---------------------------------
Eval num_timesteps=241500, episode_reward=0.52 +/- 0.51
Episode length: 29.86 +/- 18.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.9     |
|    mean_reward     | 0.522    |
| time/              |          |
|    total_timesteps | 241500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.4     |
|    ep_rew_mean     | 0.524    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 118      |
|    time_elapsed    | 2644     |
|    total_timesteps | 241664   |
---------------------------------
Eval num_timesteps=242000, episode_reward=0.54 +/- 0.49
Episode length: 25.40 +/- 14.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.4        |
|    mean_reward          | 0.54        |
| time/                   |             |
|    total_timesteps      | 242000      |
| train/                  |             |
|    approx_kl            | 0.017608255 |
|    clip_fraction        | 0.0973      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.242      |
|    explained_variance   | 0.496       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00566    |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0151     |
|    value_loss           | 0.0435      |
-----------------------------------------
Eval num_timesteps=242500, episode_reward=0.56 +/- 0.49
Episode length: 24.84 +/- 14.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.8     |
|    mean_reward     | 0.562    |
| time/              |          |
|    total_timesteps | 242500   |
---------------------------------
Eval num_timesteps=243000, episode_reward=0.54 +/- 0.49
Episode length: 29.88 +/- 17.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.9     |
|    mean_reward     | 0.542    |
| time/              |          |
|    total_timesteps | 243000   |
---------------------------------
Eval num_timesteps=243500, episode_reward=0.44 +/- 0.54
Episode length: 31.16 +/- 19.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.436    |
| time/              |          |
|    total_timesteps | 243500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29       |
|    ep_rew_mean     | 0.465    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 119      |
|    time_elapsed    | 2662     |
|    total_timesteps | 243712   |
---------------------------------
Eval num_timesteps=244000, episode_reward=0.54 +/- 0.48
Episode length: 34.18 +/- 17.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 34.2        |
|    mean_reward          | 0.545       |
| time/                   |             |
|    total_timesteps      | 244000      |
| train/                  |             |
|    approx_kl            | 0.014031586 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.23       |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00127    |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0138     |
|    value_loss           | 0.0424      |
-----------------------------------------
Eval num_timesteps=244500, episode_reward=0.54 +/- 0.47
Episode length: 29.12 +/- 15.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.545    |
| time/              |          |
|    total_timesteps | 244500   |
---------------------------------
Eval num_timesteps=245000, episode_reward=0.53 +/- 0.52
Episode length: 26.62 +/- 16.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.6     |
|    mean_reward     | 0.535    |
| time/              |          |
|    total_timesteps | 245000   |
---------------------------------
Eval num_timesteps=245500, episode_reward=0.64 +/- 0.45
Episode length: 25.50 +/- 15.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.5     |
|    mean_reward     | 0.639    |
| time/              |          |
|    total_timesteps | 245500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32       |
|    ep_rew_mean     | 0.443    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 120      |
|    time_elapsed    | 2682     |
|    total_timesteps | 245760   |
---------------------------------
Eval num_timesteps=246000, episode_reward=0.57 +/- 0.50
Episode length: 27.76 +/- 16.22
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.8        |
|    mean_reward          | 0.57        |
| time/                   |             |
|    total_timesteps      | 246000      |
| train/                  |             |
|    approx_kl            | 0.014738876 |
|    clip_fraction        | 0.0829      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.214      |
|    explained_variance   | 0.416       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0177      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0155     |
|    value_loss           | 0.0461      |
-----------------------------------------
Eval num_timesteps=246500, episode_reward=0.64 +/- 0.45
Episode length: 31.24 +/- 15.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.636    |
| time/              |          |
|    total_timesteps | 246500   |
---------------------------------
Eval num_timesteps=247000, episode_reward=0.44 +/- 0.52
Episode length: 29.44 +/- 17.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.4     |
|    mean_reward     | 0.443    |
| time/              |          |
|    total_timesteps | 247000   |
---------------------------------
Eval num_timesteps=247500, episode_reward=0.64 +/- 0.44
Episode length: 29.42 +/- 14.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.4     |
|    mean_reward     | 0.644    |
| time/              |          |
|    total_timesteps | 247500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.7     |
|    ep_rew_mean     | 0.451    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 121      |
|    time_elapsed    | 2701     |
|    total_timesteps | 247808   |
---------------------------------
Eval num_timesteps=248000, episode_reward=0.52 +/- 0.49
Episode length: 29.36 +/- 16.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.4        |
|    mean_reward          | 0.524       |
| time/                   |             |
|    total_timesteps      | 248000      |
| train/                  |             |
|    approx_kl            | 0.010713153 |
|    clip_fraction        | 0.0784      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.195      |
|    explained_variance   | 0.486       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.015      |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.0464      |
-----------------------------------------
Eval num_timesteps=248500, episode_reward=0.60 +/- 0.48
Episode length: 29.18 +/- 14.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.604    |
| time/              |          |
|    total_timesteps | 248500   |
---------------------------------
Eval num_timesteps=249000, episode_reward=0.39 +/- 0.53
Episode length: 32.00 +/- 21.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32       |
|    mean_reward     | 0.393    |
| time/              |          |
|    total_timesteps | 249000   |
---------------------------------
Eval num_timesteps=249500, episode_reward=0.51 +/- 0.50
Episode length: 32.04 +/- 17.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32       |
|    mean_reward     | 0.513    |
| time/              |          |
|    total_timesteps | 249500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.6     |
|    ep_rew_mean     | 0.457    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 122      |
|    time_elapsed    | 2720     |
|    total_timesteps | 249856   |
---------------------------------
Eval num_timesteps=250000, episode_reward=0.60 +/- 0.46
Episode length: 24.92 +/- 13.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24.9        |
|    mean_reward          | 0.602       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.013705216 |
|    clip_fraction        | 0.0945      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.237      |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00144    |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.0441      |
-----------------------------------------
Eval num_timesteps=250500, episode_reward=0.52 +/- 0.50
Episode length: 29.16 +/- 16.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.524    |
| time/              |          |
|    total_timesteps | 250500   |
---------------------------------
Eval num_timesteps=251000, episode_reward=0.43 +/- 0.53
Episode length: 33.10 +/- 21.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.1     |
|    mean_reward     | 0.429    |
| time/              |          |
|    total_timesteps | 251000   |
---------------------------------
Eval num_timesteps=251500, episode_reward=0.54 +/- 0.50
Episode length: 29.64 +/- 18.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.6     |
|    mean_reward     | 0.543    |
| time/              |          |
|    total_timesteps | 251500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.5     |
|    ep_rew_mean     | 0.347    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 123      |
|    time_elapsed    | 2740     |
|    total_timesteps | 251904   |
---------------------------------
Eval num_timesteps=252000, episode_reward=0.54 +/- 0.50
Episode length: 29.96 +/- 17.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.541       |
| time/                   |             |
|    total_timesteps      | 252000      |
| train/                  |             |
|    approx_kl            | 0.018621637 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.258      |
|    explained_variance   | 0.441       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00651    |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0188     |
|    value_loss           | 0.051       |
-----------------------------------------
Eval num_timesteps=252500, episode_reward=0.61 +/- 0.45
Episode length: 32.08 +/- 16.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.1     |
|    mean_reward     | 0.613    |
| time/              |          |
|    total_timesteps | 252500   |
---------------------------------
Eval num_timesteps=253000, episode_reward=0.49 +/- 0.48
Episode length: 32.88 +/- 15.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.9     |
|    mean_reward     | 0.49     |
| time/              |          |
|    total_timesteps | 253000   |
---------------------------------
Eval num_timesteps=253500, episode_reward=0.54 +/- 0.49
Episode length: 30.50 +/- 17.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.5     |
|    mean_reward     | 0.539    |
| time/              |          |
|    total_timesteps | 253500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.8     |
|    ep_rew_mean     | 0.456    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 124      |
|    time_elapsed    | 2761     |
|    total_timesteps | 253952   |
---------------------------------
Eval num_timesteps=254000, episode_reward=0.53 +/- 0.50
Episode length: 32.92 +/- 18.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.9        |
|    mean_reward          | 0.53        |
| time/                   |             |
|    total_timesteps      | 254000      |
| train/                  |             |
|    approx_kl            | 0.013153186 |
|    clip_fraction        | 0.09        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.219      |
|    explained_variance   | 0.516       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00592     |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.0499      |
-----------------------------------------
Eval num_timesteps=254500, episode_reward=0.59 +/- 0.47
Episode length: 28.18 +/- 16.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.588    |
| time/              |          |
|    total_timesteps | 254500   |
---------------------------------
Eval num_timesteps=255000, episode_reward=0.51 +/- 0.50
Episode length: 27.52 +/- 16.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.511    |
| time/              |          |
|    total_timesteps | 255000   |
---------------------------------
Eval num_timesteps=255500, episode_reward=0.51 +/- 0.50
Episode length: 32.94 +/- 18.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.9     |
|    mean_reward     | 0.509    |
| time/              |          |
|    total_timesteps | 255500   |
---------------------------------
Eval num_timesteps=256000, episode_reward=0.68 +/- 0.43
Episode length: 31.54 +/- 17.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.5     |
|    mean_reward     | 0.675    |
| time/              |          |
|    total_timesteps | 256000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.2     |
|    ep_rew_mean     | 0.569    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 125      |
|    time_elapsed    | 2784     |
|    total_timesteps | 256000   |
---------------------------------
Eval num_timesteps=256500, episode_reward=0.58 +/- 0.46
Episode length: 30.52 +/- 16.75
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30.5       |
|    mean_reward          | 0.579      |
| time/                   |            |
|    total_timesteps      | 256500     |
| train/                  |            |
|    approx_kl            | 0.02014289 |
|    clip_fraction        | 0.11       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.239     |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0154     |
|    n_updates            | 1250       |
|    policy_gradient_loss | -0.0159    |
|    value_loss           | 0.0474     |
----------------------------------------
Eval num_timesteps=257000, episode_reward=0.58 +/- 0.47
Episode length: 30.56 +/- 15.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.579    |
| time/              |          |
|    total_timesteps | 257000   |
---------------------------------
Eval num_timesteps=257500, episode_reward=0.57 +/- 0.48
Episode length: 28.42 +/- 16.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.4     |
|    mean_reward     | 0.567    |
| time/              |          |
|    total_timesteps | 257500   |
---------------------------------
Eval num_timesteps=258000, episode_reward=0.52 +/- 0.49
Episode length: 30.52 +/- 16.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.5     |
|    mean_reward     | 0.519    |
| time/              |          |
|    total_timesteps | 258000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.6     |
|    ep_rew_mean     | 0.571    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 126      |
|    time_elapsed    | 2801     |
|    total_timesteps | 258048   |
---------------------------------
Eval num_timesteps=258500, episode_reward=0.42 +/- 0.50
Episode length: 30.90 +/- 16.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30.9       |
|    mean_reward          | 0.418      |
| time/                   |            |
|    total_timesteps      | 258500     |
| train/                  |            |
|    approx_kl            | 0.02162651 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.245     |
|    explained_variance   | 0.45       |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0234    |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0164    |
|    value_loss           | 0.0468     |
----------------------------------------
Eval num_timesteps=259000, episode_reward=0.55 +/- 0.48
Episode length: 28.16 +/- 16.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.549    |
| time/              |          |
|    total_timesteps | 259000   |
---------------------------------
Eval num_timesteps=259500, episode_reward=0.49 +/- 0.49
Episode length: 33.26 +/- 15.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.3     |
|    mean_reward     | 0.488    |
| time/              |          |
|    total_timesteps | 259500   |
---------------------------------
Eval num_timesteps=260000, episode_reward=0.55 +/- 0.48
Episode length: 28.58 +/- 16.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.547    |
| time/              |          |
|    total_timesteps | 260000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.6     |
|    ep_rew_mean     | 0.457    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 127      |
|    time_elapsed    | 2821     |
|    total_timesteps | 260096   |
---------------------------------
Eval num_timesteps=260500, episode_reward=0.50 +/- 0.51
Episode length: 34.28 +/- 20.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 34.3        |
|    mean_reward          | 0.504       |
| time/                   |             |
|    total_timesteps      | 260500      |
| train/                  |             |
|    approx_kl            | 0.022292417 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.242      |
|    explained_variance   | 0.423       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0145      |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.016      |
|    value_loss           | 0.0545      |
-----------------------------------------
Eval num_timesteps=261000, episode_reward=0.55 +/- 0.49
Episode length: 31.78 +/- 20.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.8     |
|    mean_reward     | 0.554    |
| time/              |          |
|    total_timesteps | 261000   |
---------------------------------
Eval num_timesteps=261500, episode_reward=0.49 +/- 0.50
Episode length: 36.64 +/- 20.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 36.6     |
|    mean_reward     | 0.495    |
| time/              |          |
|    total_timesteps | 261500   |
---------------------------------
Eval num_timesteps=262000, episode_reward=0.46 +/- 0.53
Episode length: 34.50 +/- 20.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.5     |
|    mean_reward     | 0.463    |
| time/              |          |
|    total_timesteps | 262000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.6     |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    fps             | 92       |
|    iterations      | 128      |
|    time_elapsed    | 2842     |
|    total_timesteps | 262144   |
---------------------------------
Eval num_timesteps=262500, episode_reward=0.65 +/- 0.44
Episode length: 32.90 +/- 17.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.9        |
|    mean_reward          | 0.65        |
| time/                   |             |
|    total_timesteps      | 262500      |
| train/                  |             |
|    approx_kl            | 0.017371887 |
|    clip_fraction        | 0.0822      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.213      |
|    explained_variance   | 0.545       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0168     |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0132     |
|    value_loss           | 0.0402      |
-----------------------------------------
Eval num_timesteps=263000, episode_reward=0.71 +/- 0.39
Episode length: 27.42 +/- 16.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.4     |
|    mean_reward     | 0.712    |
| time/              |          |
|    total_timesteps | 263000   |
---------------------------------
New best mean reward!
Eval num_timesteps=263500, episode_reward=0.56 +/- 0.49
Episode length: 30.34 +/- 18.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.56     |
| time/              |          |
|    total_timesteps | 263500   |
---------------------------------
Eval num_timesteps=264000, episode_reward=0.55 +/- 0.48
Episode length: 32.56 +/- 16.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.6     |
|    mean_reward     | 0.551    |
| time/              |          |
|    total_timesteps | 264000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.6     |
|    ep_rew_mean     | 0.461    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 129      |
|    time_elapsed    | 2861     |
|    total_timesteps | 264192   |
---------------------------------
Eval num_timesteps=264500, episode_reward=0.53 +/- 0.50
Episode length: 26.94 +/- 15.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.9        |
|    mean_reward          | 0.533       |
| time/                   |             |
|    total_timesteps      | 264500      |
| train/                  |             |
|    approx_kl            | 0.011222603 |
|    clip_fraction        | 0.089       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.274      |
|    explained_variance   | 0.513       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0135      |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0163     |
|    value_loss           | 0.048       |
-----------------------------------------
Eval num_timesteps=265000, episode_reward=0.55 +/- 0.49
Episode length: 28.42 +/- 15.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.4     |
|    mean_reward     | 0.548    |
| time/              |          |
|    total_timesteps | 265000   |
---------------------------------
Eval num_timesteps=265500, episode_reward=0.63 +/- 0.45
Episode length: 28.94 +/- 16.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.9     |
|    mean_reward     | 0.625    |
| time/              |          |
|    total_timesteps | 265500   |
---------------------------------
Eval num_timesteps=266000, episode_reward=0.50 +/- 0.50
Episode length: 30.50 +/- 16.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.5     |
|    mean_reward     | 0.499    |
| time/              |          |
|    total_timesteps | 266000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.391    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 130      |
|    time_elapsed    | 2880     |
|    total_timesteps | 266240   |
---------------------------------
Eval num_timesteps=266500, episode_reward=0.57 +/- 0.48
Episode length: 27.32 +/- 13.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.3        |
|    mean_reward          | 0.572       |
| time/                   |             |
|    total_timesteps      | 266500      |
| train/                  |             |
|    approx_kl            | 0.020142555 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.251      |
|    explained_variance   | 0.416       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0163     |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.0197     |
|    value_loss           | 0.0497      |
-----------------------------------------
Eval num_timesteps=267000, episode_reward=0.61 +/- 0.46
Episode length: 28.50 +/- 15.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.5     |
|    mean_reward     | 0.607    |
| time/              |          |
|    total_timesteps | 267000   |
---------------------------------
Eval num_timesteps=267500, episode_reward=0.60 +/- 0.47
Episode length: 30.36 +/- 17.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.4     |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 267500   |
---------------------------------
Eval num_timesteps=268000, episode_reward=0.51 +/- 0.49
Episode length: 31.88 +/- 18.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.9     |
|    mean_reward     | 0.514    |
| time/              |          |
|    total_timesteps | 268000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33       |
|    ep_rew_mean     | 0.439    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 131      |
|    time_elapsed    | 2900     |
|    total_timesteps | 268288   |
---------------------------------
Eval num_timesteps=268500, episode_reward=0.41 +/- 0.52
Episode length: 28.52 +/- 17.30
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.5        |
|    mean_reward          | 0.407       |
| time/                   |             |
|    total_timesteps      | 268500      |
| train/                  |             |
|    approx_kl            | 0.012108684 |
|    clip_fraction        | 0.0898      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.233      |
|    explained_variance   | 0.324       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0053      |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.0147     |
|    value_loss           | 0.0486      |
-----------------------------------------
Eval num_timesteps=269000, episode_reward=0.54 +/- 0.48
Episode length: 31.28 +/- 14.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.3     |
|    mean_reward     | 0.536    |
| time/              |          |
|    total_timesteps | 269000   |
---------------------------------
Eval num_timesteps=269500, episode_reward=0.60 +/- 0.46
Episode length: 29.68 +/- 17.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.7     |
|    mean_reward     | 0.602    |
| time/              |          |
|    total_timesteps | 269500   |
---------------------------------
Eval num_timesteps=270000, episode_reward=0.41 +/- 0.51
Episode length: 32.10 +/- 17.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.1     |
|    mean_reward     | 0.413    |
| time/              |          |
|    total_timesteps | 270000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.9     |
|    ep_rew_mean     | 0.503    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 132      |
|    time_elapsed    | 2919     |
|    total_timesteps | 270336   |
---------------------------------
Eval num_timesteps=270500, episode_reward=0.55 +/- 0.49
Episode length: 32.78 +/- 20.77
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.8        |
|    mean_reward          | 0.55        |
| time/                   |             |
|    total_timesteps      | 270500      |
| train/                  |             |
|    approx_kl            | 0.019029805 |
|    clip_fraction        | 0.0995      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.256      |
|    explained_variance   | 0.411       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0228      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0212     |
|    value_loss           | 0.0456      |
-----------------------------------------
Eval num_timesteps=271000, episode_reward=0.66 +/- 0.42
Episode length: 30.22 +/- 15.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.661    |
| time/              |          |
|    total_timesteps | 271000   |
---------------------------------
Eval num_timesteps=271500, episode_reward=0.56 +/- 0.51
Episode length: 30.28 +/- 19.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.56     |
| time/              |          |
|    total_timesteps | 271500   |
---------------------------------
Eval num_timesteps=272000, episode_reward=0.59 +/- 0.46
Episode length: 33.10 +/- 15.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.1     |
|    mean_reward     | 0.589    |
| time/              |          |
|    total_timesteps | 272000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.7     |
|    ep_rew_mean     | 0.508    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 133      |
|    time_elapsed    | 2939     |
|    total_timesteps | 272384   |
---------------------------------
Eval num_timesteps=272500, episode_reward=0.57 +/- 0.47
Episode length: 33.84 +/- 19.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.8        |
|    mean_reward          | 0.566       |
| time/                   |             |
|    total_timesteps      | 272500      |
| train/                  |             |
|    approx_kl            | 0.014339031 |
|    clip_fraction        | 0.0939      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.242      |
|    explained_variance   | 0.5         |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0188     |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.0171     |
|    value_loss           | 0.045       |
-----------------------------------------
Eval num_timesteps=273000, episode_reward=0.58 +/- 0.46
Episode length: 35.12 +/- 19.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 35.1     |
|    mean_reward     | 0.581    |
| time/              |          |
|    total_timesteps | 273000   |
---------------------------------
Eval num_timesteps=273500, episode_reward=0.59 +/- 0.46
Episode length: 37.40 +/- 16.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 37.4     |
|    mean_reward     | 0.592    |
| time/              |          |
|    total_timesteps | 273500   |
---------------------------------
Eval num_timesteps=274000, episode_reward=0.54 +/- 0.48
Episode length: 31.24 +/- 17.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.536    |
| time/              |          |
|    total_timesteps | 274000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28       |
|    ep_rew_mean     | 0.609    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 134      |
|    time_elapsed    | 2960     |
|    total_timesteps | 274432   |
---------------------------------
Eval num_timesteps=274500, episode_reward=0.59 +/- 0.47
Episode length: 33.32 +/- 19.25
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.3        |
|    mean_reward          | 0.588       |
| time/                   |             |
|    total_timesteps      | 274500      |
| train/                  |             |
|    approx_kl            | 0.011663749 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.259      |
|    explained_variance   | 0.529       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0143      |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0171     |
|    value_loss           | 0.0382      |
-----------------------------------------
Eval num_timesteps=275000, episode_reward=0.49 +/- 0.51
Episode length: 32.24 +/- 18.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.2     |
|    mean_reward     | 0.493    |
| time/              |          |
|    total_timesteps | 275000   |
---------------------------------
Eval num_timesteps=275500, episode_reward=0.71 +/- 0.40
Episode length: 28.10 +/- 14.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.1     |
|    mean_reward     | 0.709    |
| time/              |          |
|    total_timesteps | 275500   |
---------------------------------
Eval num_timesteps=276000, episode_reward=0.68 +/- 0.41
Episode length: 30.46 +/- 19.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.5     |
|    mean_reward     | 0.68     |
| time/              |          |
|    total_timesteps | 276000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.1     |
|    ep_rew_mean     | 0.555    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 135      |
|    time_elapsed    | 2979     |
|    total_timesteps | 276480   |
---------------------------------
Eval num_timesteps=276500, episode_reward=0.49 +/- 0.53
Episode length: 32.72 +/- 19.51
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 32.7       |
|    mean_reward          | 0.49       |
| time/                   |            |
|    total_timesteps      | 276500     |
| train/                  |            |
|    approx_kl            | 0.01253658 |
|    clip_fraction        | 0.091      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.25      |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00738    |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.0156    |
|    value_loss           | 0.0367     |
----------------------------------------
Eval num_timesteps=277000, episode_reward=0.47 +/- 0.53
Episode length: 34.00 +/- 20.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34       |
|    mean_reward     | 0.465    |
| time/              |          |
|    total_timesteps | 277000   |
---------------------------------
Eval num_timesteps=277500, episode_reward=0.52 +/- 0.50
Episode length: 29.60 +/- 17.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.6     |
|    mean_reward     | 0.523    |
| time/              |          |
|    total_timesteps | 277500   |
---------------------------------
Eval num_timesteps=278000, episode_reward=0.56 +/- 0.49
Episode length: 31.24 +/- 17.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.556    |
| time/              |          |
|    total_timesteps | 278000   |
---------------------------------
Eval num_timesteps=278500, episode_reward=0.53 +/- 0.49
Episode length: 33.02 +/- 18.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33       |
|    mean_reward     | 0.53     |
| time/              |          |
|    total_timesteps | 278500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33.2     |
|    ep_rew_mean     | 0.498    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 136      |
|    time_elapsed    | 3002     |
|    total_timesteps | 278528   |
---------------------------------
Eval num_timesteps=279000, episode_reward=0.55 +/- 0.50
Episode length: 33.28 +/- 19.18
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.3        |
|    mean_reward          | 0.548       |
| time/                   |             |
|    total_timesteps      | 279000      |
| train/                  |             |
|    approx_kl            | 0.016738303 |
|    clip_fraction        | 0.0872      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.188      |
|    explained_variance   | 0.466       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0098     |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0147     |
|    value_loss           | 0.0432      |
-----------------------------------------
Eval num_timesteps=279500, episode_reward=0.59 +/- 0.48
Episode length: 33.72 +/- 19.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.7     |
|    mean_reward     | 0.586    |
| time/              |          |
|    total_timesteps | 279500   |
---------------------------------
Eval num_timesteps=280000, episode_reward=0.60 +/- 0.47
Episode length: 34.64 +/- 18.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.6     |
|    mean_reward     | 0.603    |
| time/              |          |
|    total_timesteps | 280000   |
---------------------------------
Eval num_timesteps=280500, episode_reward=0.57 +/- 0.48
Episode length: 36.58 +/- 20.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 36.6     |
|    mean_reward     | 0.575    |
| time/              |          |
|    total_timesteps | 280500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.9     |
|    ep_rew_mean     | 0.504    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 137      |
|    time_elapsed    | 3023     |
|    total_timesteps | 280576   |
---------------------------------
Eval num_timesteps=281000, episode_reward=0.55 +/- 0.49
Episode length: 32.84 +/- 16.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.8        |
|    mean_reward          | 0.55        |
| time/                   |             |
|    total_timesteps      | 281000      |
| train/                  |             |
|    approx_kl            | 0.013923418 |
|    clip_fraction        | 0.0793      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.191      |
|    explained_variance   | 0.589       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.015      |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.0394      |
-----------------------------------------
Eval num_timesteps=281500, episode_reward=0.50 +/- 0.51
Episode length: 30.72 +/- 18.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.7     |
|    mean_reward     | 0.498    |
| time/              |          |
|    total_timesteps | 281500   |
---------------------------------
Eval num_timesteps=282000, episode_reward=0.49 +/- 0.51
Episode length: 32.12 +/- 16.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.1     |
|    mean_reward     | 0.493    |
| time/              |          |
|    total_timesteps | 282000   |
---------------------------------
Eval num_timesteps=282500, episode_reward=0.47 +/- 0.51
Episode length: 31.80 +/- 18.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.8     |
|    mean_reward     | 0.474    |
| time/              |          |
|    total_timesteps | 282500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.8     |
|    ep_rew_mean     | 0.636    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 138      |
|    time_elapsed    | 3043     |
|    total_timesteps | 282624   |
---------------------------------
Eval num_timesteps=283000, episode_reward=0.55 +/- 0.50
Episode length: 27.40 +/- 17.78
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.4        |
|    mean_reward          | 0.552       |
| time/                   |             |
|    total_timesteps      | 283000      |
| train/                  |             |
|    approx_kl            | 0.019666351 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.218      |
|    explained_variance   | 0.527       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00466     |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.043       |
-----------------------------------------
Eval num_timesteps=283500, episode_reward=0.54 +/- 0.51
Episode length: 29.84 +/- 17.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.542    |
| time/              |          |
|    total_timesteps | 283500   |
---------------------------------
Eval num_timesteps=284000, episode_reward=0.64 +/- 0.45
Episode length: 30.94 +/- 18.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.9     |
|    mean_reward     | 0.638    |
| time/              |          |
|    total_timesteps | 284000   |
---------------------------------
Eval num_timesteps=284500, episode_reward=0.66 +/- 0.43
Episode length: 25.46 +/- 13.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.5     |
|    mean_reward     | 0.66     |
| time/              |          |
|    total_timesteps | 284500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.9     |
|    ep_rew_mean     | 0.508    |
| time/              |          |
|    fps             | 92       |
|    iterations      | 139      |
|    time_elapsed    | 3061     |
|    total_timesteps | 284672   |
---------------------------------
Eval num_timesteps=285000, episode_reward=0.58 +/- 0.46
Episode length: 30.92 +/- 14.34
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.9        |
|    mean_reward          | 0.578       |
| time/                   |             |
|    total_timesteps      | 285000      |
| train/                  |             |
|    approx_kl            | 0.014193028 |
|    clip_fraction        | 0.0943      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.209      |
|    explained_variance   | 0.505       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0208     |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.0151     |
|    value_loss           | 0.0416      |
-----------------------------------------
Eval num_timesteps=285500, episode_reward=0.57 +/- 0.48
Episode length: 26.78 +/- 14.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.8     |
|    mean_reward     | 0.574    |
| time/              |          |
|    total_timesteps | 285500   |
---------------------------------
Eval num_timesteps=286000, episode_reward=0.61 +/- 0.47
Episode length: 32.62 +/- 18.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.6     |
|    mean_reward     | 0.611    |
| time/              |          |
|    total_timesteps | 286000   |
---------------------------------
Eval num_timesteps=286500, episode_reward=0.52 +/- 0.51
Episode length: 30.56 +/- 19.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.519    |
| time/              |          |
|    total_timesteps | 286500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.7     |
|    ep_rew_mean     | 0.491    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 140      |
|    time_elapsed    | 3080     |
|    total_timesteps | 286720   |
---------------------------------
Eval num_timesteps=287000, episode_reward=0.52 +/- 0.51
Episode length: 31.00 +/- 20.21
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31          |
|    mean_reward          | 0.517       |
| time/                   |             |
|    total_timesteps      | 287000      |
| train/                  |             |
|    approx_kl            | 0.011671379 |
|    clip_fraction        | 0.0771      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.179      |
|    explained_variance   | 0.491       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00127    |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.0407      |
-----------------------------------------
Eval num_timesteps=287500, episode_reward=0.70 +/- 0.41
Episode length: 30.48 +/- 16.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.5     |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 287500   |
---------------------------------
Eval num_timesteps=288000, episode_reward=0.57 +/- 0.48
Episode length: 33.10 +/- 17.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.1     |
|    mean_reward     | 0.569    |
| time/              |          |
|    total_timesteps | 288000   |
---------------------------------
Eval num_timesteps=288500, episode_reward=0.46 +/- 0.50
Episode length: 34.52 +/- 17.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.5     |
|    mean_reward     | 0.463    |
| time/              |          |
|    total_timesteps | 288500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.9     |
|    ep_rew_mean     | 0.554    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 141      |
|    time_elapsed    | 3100     |
|    total_timesteps | 288768   |
---------------------------------
Eval num_timesteps=289000, episode_reward=0.51 +/- 0.50
Episode length: 33.78 +/- 18.03
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.8        |
|    mean_reward          | 0.506       |
| time/                   |             |
|    total_timesteps      | 289000      |
| train/                  |             |
|    approx_kl            | 0.015425334 |
|    clip_fraction        | 0.0996      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.202      |
|    explained_variance   | 0.496       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00712    |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.044       |
-----------------------------------------
Eval num_timesteps=289500, episode_reward=0.57 +/- 0.48
Episode length: 32.32 +/- 18.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.3     |
|    mean_reward     | 0.572    |
| time/              |          |
|    total_timesteps | 289500   |
---------------------------------
Eval num_timesteps=290000, episode_reward=0.52 +/- 0.50
Episode length: 34.56 +/- 19.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.6     |
|    mean_reward     | 0.523    |
| time/              |          |
|    total_timesteps | 290000   |
---------------------------------
Eval num_timesteps=290500, episode_reward=0.58 +/- 0.49
Episode length: 29.76 +/- 18.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.582    |
| time/              |          |
|    total_timesteps | 290500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.6     |
|    ep_rew_mean     | 0.515    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 142      |
|    time_elapsed    | 3121     |
|    total_timesteps | 290816   |
---------------------------------
Eval num_timesteps=291000, episode_reward=0.58 +/- 0.50
Episode length: 29.08 +/- 18.99
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 29.1      |
|    mean_reward          | 0.585     |
| time/                   |           |
|    total_timesteps      | 291000    |
| train/                  |           |
|    approx_kl            | 0.0160421 |
|    clip_fraction        | 0.0848    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.201    |
|    explained_variance   | 0.393     |
|    learning_rate        | 0.0001    |
|    loss                 | -0.0138   |
|    n_updates            | 1420      |
|    policy_gradient_loss | -0.0114   |
|    value_loss           | 0.0499    |
---------------------------------------
Eval num_timesteps=291500, episode_reward=0.69 +/- 0.42
Episode length: 32.06 +/- 18.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.1     |
|    mean_reward     | 0.693    |
| time/              |          |
|    total_timesteps | 291500   |
---------------------------------
Eval num_timesteps=292000, episode_reward=0.51 +/- 0.52
Episode length: 36.62 +/- 21.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 36.6     |
|    mean_reward     | 0.515    |
| time/              |          |
|    total_timesteps | 292000   |
---------------------------------
Eval num_timesteps=292500, episode_reward=0.58 +/- 0.47
Episode length: 29.78 +/- 17.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.582    |
| time/              |          |
|    total_timesteps | 292500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33.7     |
|    ep_rew_mean     | 0.406    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 143      |
|    time_elapsed    | 3141     |
|    total_timesteps | 292864   |
---------------------------------
Eval num_timesteps=293000, episode_reward=0.60 +/- 0.46
Episode length: 30.02 +/- 15.87
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.601       |
| time/                   |             |
|    total_timesteps      | 293000      |
| train/                  |             |
|    approx_kl            | 0.014548666 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.21       |
|    explained_variance   | 0.445       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000834    |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.0185     |
|    value_loss           | 0.043       |
-----------------------------------------
Eval num_timesteps=293500, episode_reward=0.54 +/- 0.50
Episode length: 30.42 +/- 18.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.4     |
|    mean_reward     | 0.54     |
| time/              |          |
|    total_timesteps | 293500   |
---------------------------------
Eval num_timesteps=294000, episode_reward=0.47 +/- 0.51
Episode length: 32.36 +/- 18.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.4     |
|    mean_reward     | 0.472    |
| time/              |          |
|    total_timesteps | 294000   |
---------------------------------
Eval num_timesteps=294500, episode_reward=0.46 +/- 0.54
Episode length: 34.58 +/- 19.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.6     |
|    mean_reward     | 0.463    |
| time/              |          |
|    total_timesteps | 294500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.491    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 144      |
|    time_elapsed    | 3161     |
|    total_timesteps | 294912   |
---------------------------------
Eval num_timesteps=295000, episode_reward=0.65 +/- 0.43
Episode length: 28.98 +/- 15.28
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29          |
|    mean_reward          | 0.645       |
| time/                   |             |
|    total_timesteps      | 295000      |
| train/                  |             |
|    approx_kl            | 0.014318686 |
|    clip_fraction        | 0.0966      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.232      |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00139     |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.0487      |
-----------------------------------------
Eval num_timesteps=295500, episode_reward=0.56 +/- 0.51
Episode length: 30.86 +/- 18.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.9     |
|    mean_reward     | 0.558    |
| time/              |          |
|    total_timesteps | 295500   |
---------------------------------
Eval num_timesteps=296000, episode_reward=0.59 +/- 0.47
Episode length: 34.06 +/- 17.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.1     |
|    mean_reward     | 0.585    |
| time/              |          |
|    total_timesteps | 296000   |
---------------------------------
Eval num_timesteps=296500, episode_reward=0.55 +/- 0.50
Episode length: 29.04 +/- 15.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29       |
|    mean_reward     | 0.545    |
| time/              |          |
|    total_timesteps | 296500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.2     |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    fps             | 93       |
|    iterations      | 145      |
|    time_elapsed    | 3180     |
|    total_timesteps | 296960   |
---------------------------------
Eval num_timesteps=297000, episode_reward=0.48 +/- 0.51
Episode length: 31.10 +/- 18.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.1        |
|    mean_reward          | 0.477       |
| time/                   |             |
|    total_timesteps      | 297000      |
| train/                  |             |
|    approx_kl            | 0.016977174 |
|    clip_fraction        | 0.0989      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.228      |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0214     |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0152     |
|    value_loss           | 0.0363      |
-----------------------------------------
Eval num_timesteps=297500, episode_reward=0.61 +/- 0.45
Episode length: 32.20 +/- 17.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.2     |
|    mean_reward     | 0.613    |
| time/              |          |
|    total_timesteps | 297500   |
---------------------------------
Eval num_timesteps=298000, episode_reward=0.63 +/- 0.44
Episode length: 32.28 +/- 17.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.3     |
|    mean_reward     | 0.632    |
| time/              |          |
|    total_timesteps | 298000   |
---------------------------------
Eval num_timesteps=298500, episode_reward=0.46 +/- 0.51
Episode length: 30.18 +/- 17.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.461    |
| time/              |          |
|    total_timesteps | 298500   |
---------------------------------
Eval num_timesteps=299000, episode_reward=0.51 +/- 0.49
Episode length: 32.58 +/- 18.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.6     |
|    mean_reward     | 0.511    |
| time/              |          |
|    total_timesteps | 299000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32       |
|    ep_rew_mean     | 0.563    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 146      |
|    time_elapsed    | 3201     |
|    total_timesteps | 299008   |
---------------------------------
Eval num_timesteps=299500, episode_reward=0.63 +/- 0.43
Episode length: 33.18 +/- 16.42
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.2        |
|    mean_reward          | 0.629       |
| time/                   |             |
|    total_timesteps      | 299500      |
| train/                  |             |
|    approx_kl            | 0.021611324 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.233      |
|    explained_variance   | 0.386       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00191     |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0166     |
|    value_loss           | 0.0471      |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=0.68 +/- 0.40
Episode length: 29.10 +/- 16.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.685    |
| time/              |          |
|    total_timesteps | 300000   |
---------------------------------
Eval num_timesteps=300500, episode_reward=0.55 +/- 0.50
Episode length: 27.78 +/- 17.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.55     |
| time/              |          |
|    total_timesteps | 300500   |
---------------------------------
Eval num_timesteps=301000, episode_reward=0.46 +/- 0.51
Episode length: 34.12 +/- 17.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.1     |
|    mean_reward     | 0.465    |
| time/              |          |
|    total_timesteps | 301000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31       |
|    ep_rew_mean     | 0.547    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 147      |
|    time_elapsed    | 3221     |
|    total_timesteps | 301056   |
---------------------------------
Eval num_timesteps=301500, episode_reward=0.58 +/- 0.47
Episode length: 30.56 +/- 15.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.6        |
|    mean_reward          | 0.579       |
| time/                   |             |
|    total_timesteps      | 301500      |
| train/                  |             |
|    approx_kl            | 0.012010362 |
|    clip_fraction        | 0.0939      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.257      |
|    explained_variance   | 0.506       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0261     |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0158     |
|    value_loss           | 0.0441      |
-----------------------------------------
Eval num_timesteps=302000, episode_reward=0.69 +/- 0.41
Episode length: 28.88 +/- 15.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.9     |
|    mean_reward     | 0.686    |
| time/              |          |
|    total_timesteps | 302000   |
---------------------------------
Eval num_timesteps=302500, episode_reward=0.63 +/- 0.46
Episode length: 33.04 +/- 17.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33       |
|    mean_reward     | 0.629    |
| time/              |          |
|    total_timesteps | 302500   |
---------------------------------
Eval num_timesteps=303000, episode_reward=0.55 +/- 0.49
Episode length: 33.22 +/- 17.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.2     |
|    mean_reward     | 0.548    |
| time/              |          |
|    total_timesteps | 303000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.4     |
|    ep_rew_mean     | 0.484    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 148      |
|    time_elapsed    | 3239     |
|    total_timesteps | 303104   |
---------------------------------
Eval num_timesteps=303500, episode_reward=0.54 +/- 0.49
Episode length: 29.24 +/- 16.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.2        |
|    mean_reward          | 0.545       |
| time/                   |             |
|    total_timesteps      | 303500      |
| train/                  |             |
|    approx_kl            | 0.014293502 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.268      |
|    explained_variance   | 0.285       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0199     |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.0205     |
|    value_loss           | 0.0515      |
-----------------------------------------
Eval num_timesteps=304000, episode_reward=0.55 +/- 0.48
Episode length: 33.66 +/- 19.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.7     |
|    mean_reward     | 0.546    |
| time/              |          |
|    total_timesteps | 304000   |
---------------------------------
Eval num_timesteps=304500, episode_reward=0.70 +/- 0.40
Episode length: 29.20 +/- 15.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.704    |
| time/              |          |
|    total_timesteps | 304500   |
---------------------------------
Eval num_timesteps=305000, episode_reward=0.51 +/- 0.49
Episode length: 31.98 +/- 15.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32       |
|    mean_reward     | 0.513    |
| time/              |          |
|    total_timesteps | 305000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.7     |
|    ep_rew_mean     | 0.422    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 149      |
|    time_elapsed    | 3258     |
|    total_timesteps | 305152   |
---------------------------------
Eval num_timesteps=305500, episode_reward=0.67 +/- 0.41
Episode length: 31.88 +/- 16.95
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.9        |
|    mean_reward          | 0.674       |
| time/                   |             |
|    total_timesteps      | 305500      |
| train/                  |             |
|    approx_kl            | 0.015418062 |
|    clip_fraction        | 0.0855      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.229      |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00299    |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.0175     |
|    value_loss           | 0.0434      |
-----------------------------------------
Eval num_timesteps=306000, episode_reward=0.63 +/- 0.44
Episode length: 29.10 +/- 13.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.625    |
| time/              |          |
|    total_timesteps | 306000   |
---------------------------------
Eval num_timesteps=306500, episode_reward=0.55 +/- 0.48
Episode length: 33.42 +/- 16.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.4     |
|    mean_reward     | 0.547    |
| time/              |          |
|    total_timesteps | 306500   |
---------------------------------
Eval num_timesteps=307000, episode_reward=0.51 +/- 0.49
Episode length: 31.74 +/- 18.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.7     |
|    mean_reward     | 0.514    |
| time/              |          |
|    total_timesteps | 307000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33.4     |
|    ep_rew_mean     | 0.378    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 150      |
|    time_elapsed    | 3277     |
|    total_timesteps | 307200   |
---------------------------------
Eval num_timesteps=307500, episode_reward=0.69 +/- 0.40
Episode length: 28.92 +/- 14.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.9       |
|    mean_reward          | 0.686      |
| time/                   |            |
|    total_timesteps      | 307500     |
| train/                  |            |
|    approx_kl            | 0.01938717 |
|    clip_fraction        | 0.0966     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.237     |
|    explained_variance   | 0.444      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00093   |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.0172    |
|    value_loss           | 0.0425     |
----------------------------------------
Eval num_timesteps=308000, episode_reward=0.53 +/- 0.50
Episode length: 27.50 +/- 15.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.531    |
| time/              |          |
|    total_timesteps | 308000   |
---------------------------------
Eval num_timesteps=308500, episode_reward=0.55 +/- 0.49
Episode length: 32.88 +/- 19.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.9     |
|    mean_reward     | 0.55     |
| time/              |          |
|    total_timesteps | 308500   |
---------------------------------
Eval num_timesteps=309000, episode_reward=0.48 +/- 0.51
Episode length: 31.40 +/- 18.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.476    |
| time/              |          |
|    total_timesteps | 309000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.8     |
|    ep_rew_mean     | 0.562    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 151      |
|    time_elapsed    | 3296     |
|    total_timesteps | 309248   |
---------------------------------
Eval num_timesteps=309500, episode_reward=0.64 +/- 0.44
Episode length: 30.50 +/- 14.33
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.5        |
|    mean_reward          | 0.639       |
| time/                   |             |
|    total_timesteps      | 309500      |
| train/                  |             |
|    approx_kl            | 0.013796165 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.238      |
|    explained_variance   | 0.388       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00874    |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.0181     |
|    value_loss           | 0.0462      |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=0.53 +/- 0.49
Episode length: 32.34 +/- 17.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.3     |
|    mean_reward     | 0.532    |
| time/              |          |
|    total_timesteps | 310000   |
---------------------------------
Eval num_timesteps=310500, episode_reward=0.56 +/- 0.50
Episode length: 29.42 +/- 16.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.4     |
|    mean_reward     | 0.564    |
| time/              |          |
|    total_timesteps | 310500   |
---------------------------------
Eval num_timesteps=311000, episode_reward=0.61 +/- 0.48
Episode length: 31.98 +/- 19.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32       |
|    mean_reward     | 0.614    |
| time/              |          |
|    total_timesteps | 311000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.7     |
|    ep_rew_mean     | 0.553    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 152      |
|    time_elapsed    | 3315     |
|    total_timesteps | 311296   |
---------------------------------
Eval num_timesteps=311500, episode_reward=0.51 +/- 0.50
Episode length: 31.88 +/- 18.25
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.9        |
|    mean_reward          | 0.514       |
| time/                   |             |
|    total_timesteps      | 311500      |
| train/                  |             |
|    approx_kl            | 0.015773801 |
|    clip_fraction        | 0.0997      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.202      |
|    explained_variance   | 0.439       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00423    |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.0165     |
|    value_loss           | 0.0468      |
-----------------------------------------
Eval num_timesteps=312000, episode_reward=0.59 +/- 0.47
Episode length: 27.80 +/- 15.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.59     |
| time/              |          |
|    total_timesteps | 312000   |
---------------------------------
Eval num_timesteps=312500, episode_reward=0.65 +/- 0.43
Episode length: 27.94 +/- 14.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.9     |
|    mean_reward     | 0.649    |
| time/              |          |
|    total_timesteps | 312500   |
---------------------------------
Eval num_timesteps=313000, episode_reward=0.57 +/- 0.47
Episode length: 28.56 +/- 15.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.567    |
| time/              |          |
|    total_timesteps | 313000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.9     |
|    ep_rew_mean     | 0.536    |
| time/              |          |
|    fps             | 93       |
|    iterations      | 153      |
|    time_elapsed    | 3334     |
|    total_timesteps | 313344   |
---------------------------------
Eval num_timesteps=313500, episode_reward=0.53 +/- 0.49
Episode length: 28.78 +/- 15.03
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.8        |
|    mean_reward          | 0.526       |
| time/                   |             |
|    total_timesteps      | 313500      |
| train/                  |             |
|    approx_kl            | 0.025638953 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.216      |
|    explained_variance   | 0.425       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00874     |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.0191     |
|    value_loss           | 0.0472      |
-----------------------------------------
Eval num_timesteps=314000, episode_reward=0.50 +/- 0.51
Episode length: 31.32 +/- 17.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.3     |
|    mean_reward     | 0.496    |
| time/              |          |
|    total_timesteps | 314000   |
---------------------------------
Eval num_timesteps=314500, episode_reward=0.37 +/- 0.51
Episode length: 27.70 +/- 16.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.37     |
| time/              |          |
|    total_timesteps | 314500   |
---------------------------------
Eval num_timesteps=315000, episode_reward=0.52 +/- 0.49
Episode length: 29.20 +/- 15.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.524    |
| time/              |          |
|    total_timesteps | 315000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | 0.467    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 154      |
|    time_elapsed    | 3352     |
|    total_timesteps | 315392   |
---------------------------------
Eval num_timesteps=315500, episode_reward=0.62 +/- 0.44
Episode length: 30.68 +/- 16.16
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.7        |
|    mean_reward          | 0.618       |
| time/                   |             |
|    total_timesteps      | 315500      |
| train/                  |             |
|    approx_kl            | 0.014979948 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.292      |
|    explained_variance   | 0.381       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0108      |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.0528      |
-----------------------------------------
Eval num_timesteps=316000, episode_reward=0.50 +/- 0.51
Episode length: 29.20 +/- 17.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.504    |
| time/              |          |
|    total_timesteps | 316000   |
---------------------------------
Eval num_timesteps=316500, episode_reward=0.60 +/- 0.46
Episode length: 30.86 +/- 15.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.9     |
|    mean_reward     | 0.598    |
| time/              |          |
|    total_timesteps | 316500   |
---------------------------------
Eval num_timesteps=317000, episode_reward=0.53 +/- 0.50
Episode length: 32.06 +/- 17.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.1     |
|    mean_reward     | 0.533    |
| time/              |          |
|    total_timesteps | 317000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 0.478    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 155      |
|    time_elapsed    | 3371     |
|    total_timesteps | 317440   |
---------------------------------
Eval num_timesteps=317500, episode_reward=0.36 +/- 0.52
Episode length: 30.22 +/- 17.38
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.2        |
|    mean_reward          | 0.36        |
| time/                   |             |
|    total_timesteps      | 317500      |
| train/                  |             |
|    approx_kl            | 0.012624106 |
|    clip_fraction        | 0.0953      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.246      |
|    explained_variance   | 0.454       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0019      |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.0173     |
|    value_loss           | 0.0446      |
-----------------------------------------
Eval num_timesteps=318000, episode_reward=0.57 +/- 0.48
Episode length: 27.00 +/- 16.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.573    |
| time/              |          |
|    total_timesteps | 318000   |
---------------------------------
Eval num_timesteps=318500, episode_reward=0.49 +/- 0.49
Episode length: 33.92 +/- 16.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.9     |
|    mean_reward     | 0.486    |
| time/              |          |
|    total_timesteps | 318500   |
---------------------------------
Eval num_timesteps=319000, episode_reward=0.54 +/- 0.50
Episode length: 30.12 +/- 18.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.541    |
| time/              |          |
|    total_timesteps | 319000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29       |
|    ep_rew_mean     | 0.565    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 156      |
|    time_elapsed    | 3388     |
|    total_timesteps | 319488   |
---------------------------------
Eval num_timesteps=319500, episode_reward=0.44 +/- 0.52
Episode length: 29.66 +/- 16.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.7        |
|    mean_reward          | 0.443       |
| time/                   |             |
|    total_timesteps      | 319500      |
| train/                  |             |
|    approx_kl            | 0.012771923 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.224      |
|    explained_variance   | 0.342       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00368    |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0167     |
|    value_loss           | 0.0488      |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=0.48 +/- 0.50
Episode length: 29.54 +/- 17.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.483    |
| time/              |          |
|    total_timesteps | 320000   |
---------------------------------
Eval num_timesteps=320500, episode_reward=0.49 +/- 0.51
Episode length: 27.56 +/- 17.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.6     |
|    mean_reward     | 0.491    |
| time/              |          |
|    total_timesteps | 320500   |
---------------------------------
Eval num_timesteps=321000, episode_reward=0.56 +/- 0.48
Episode length: 29.32 +/- 16.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.564    |
| time/              |          |
|    total_timesteps | 321000   |
---------------------------------
Eval num_timesteps=321500, episode_reward=0.59 +/- 0.47
Episode length: 27.24 +/- 15.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.2     |
|    mean_reward     | 0.592    |
| time/              |          |
|    total_timesteps | 321500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | 0.578    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 157      |
|    time_elapsed    | 3410     |
|    total_timesteps | 321536   |
---------------------------------
Eval num_timesteps=322000, episode_reward=0.66 +/- 0.44
Episode length: 30.74 +/- 17.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.7        |
|    mean_reward          | 0.658       |
| time/                   |             |
|    total_timesteps      | 322000      |
| train/                  |             |
|    approx_kl            | 0.015191242 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.282      |
|    explained_variance   | 0.433       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0191      |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.0174     |
|    value_loss           | 0.0493      |
-----------------------------------------
Eval num_timesteps=322500, episode_reward=0.51 +/- 0.50
Episode length: 33.48 +/- 17.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.5     |
|    mean_reward     | 0.508    |
| time/              |          |
|    total_timesteps | 322500   |
---------------------------------
Eval num_timesteps=323000, episode_reward=0.52 +/- 0.50
Episode length: 29.52 +/- 16.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.523    |
| time/              |          |
|    total_timesteps | 323000   |
---------------------------------
Eval num_timesteps=323500, episode_reward=0.50 +/- 0.50
Episode length: 30.86 +/- 16.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.9     |
|    mean_reward     | 0.498    |
| time/              |          |
|    total_timesteps | 323500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.542    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 158      |
|    time_elapsed    | 3429     |
|    total_timesteps | 323584   |
---------------------------------
Eval num_timesteps=324000, episode_reward=0.53 +/- 0.50
Episode length: 27.62 +/- 16.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.6        |
|    mean_reward          | 0.531       |
| time/                   |             |
|    total_timesteps      | 324000      |
| train/                  |             |
|    approx_kl            | 0.014394736 |
|    clip_fraction        | 0.0992      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.239      |
|    explained_variance   | 0.358       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00994    |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.0458      |
-----------------------------------------
Eval num_timesteps=324500, episode_reward=0.65 +/- 0.44
Episode length: 26.72 +/- 14.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.7     |
|    mean_reward     | 0.654    |
| time/              |          |
|    total_timesteps | 324500   |
---------------------------------
Eval num_timesteps=325000, episode_reward=0.49 +/- 0.50
Episode length: 31.96 +/- 19.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32       |
|    mean_reward     | 0.493    |
| time/              |          |
|    total_timesteps | 325000   |
---------------------------------
Eval num_timesteps=325500, episode_reward=0.49 +/- 0.53
Episode length: 32.98 +/- 19.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33       |
|    mean_reward     | 0.489    |
| time/              |          |
|    total_timesteps | 325500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.1     |
|    ep_rew_mean     | 0.483    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 159      |
|    time_elapsed    | 3449     |
|    total_timesteps | 325632   |
---------------------------------
Eval num_timesteps=326000, episode_reward=0.63 +/- 0.45
Episode length: 33.16 +/- 17.27
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.2        |
|    mean_reward          | 0.629       |
| time/                   |             |
|    total_timesteps      | 326000      |
| train/                  |             |
|    approx_kl            | 0.010919069 |
|    clip_fraction        | 0.0857      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.229      |
|    explained_variance   | 0.413       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0176      |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.016      |
|    value_loss           | 0.0456      |
-----------------------------------------
Eval num_timesteps=326500, episode_reward=0.50 +/- 0.51
Episode length: 30.26 +/- 16.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 326500   |
---------------------------------
Eval num_timesteps=327000, episode_reward=0.47 +/- 0.50
Episode length: 33.42 +/- 18.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.4     |
|    mean_reward     | 0.468    |
| time/              |          |
|    total_timesteps | 327000   |
---------------------------------
Eval num_timesteps=327500, episode_reward=0.61 +/- 0.46
Episode length: 27.06 +/- 15.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.1     |
|    mean_reward     | 0.613    |
| time/              |          |
|    total_timesteps | 327500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.3     |
|    ep_rew_mean     | 0.432    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 160      |
|    time_elapsed    | 3469     |
|    total_timesteps | 327680   |
---------------------------------
Eval num_timesteps=328000, episode_reward=0.52 +/- 0.51
Episode length: 30.84 +/- 18.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.8        |
|    mean_reward          | 0.518       |
| time/                   |             |
|    total_timesteps      | 328000      |
| train/                  |             |
|    approx_kl            | 0.014335603 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.255      |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0111     |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.0444      |
-----------------------------------------
Eval num_timesteps=328500, episode_reward=0.62 +/- 0.47
Episode length: 30.36 +/- 18.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.4     |
|    mean_reward     | 0.62     |
| time/              |          |
|    total_timesteps | 328500   |
---------------------------------
Eval num_timesteps=329000, episode_reward=0.44 +/- 0.53
Episode length: 35.78 +/- 20.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 35.8     |
|    mean_reward     | 0.438    |
| time/              |          |
|    total_timesteps | 329000   |
---------------------------------
Eval num_timesteps=329500, episode_reward=0.60 +/- 0.46
Episode length: 29.32 +/- 15.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.604    |
| time/              |          |
|    total_timesteps | 329500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.8     |
|    ep_rew_mean     | 0.494    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 161      |
|    time_elapsed    | 3487     |
|    total_timesteps | 329728   |
---------------------------------
Eval num_timesteps=330000, episode_reward=0.60 +/- 0.48
Episode length: 29.86 +/- 18.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.602       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.012825573 |
|    clip_fraction        | 0.0988      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.227      |
|    explained_variance   | 0.4         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0149      |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.0165     |
|    value_loss           | 0.0483      |
-----------------------------------------
Eval num_timesteps=330500, episode_reward=0.57 +/- 0.48
Episode length: 28.96 +/- 14.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29       |
|    mean_reward     | 0.565    |
| time/              |          |
|    total_timesteps | 330500   |
---------------------------------
Eval num_timesteps=331000, episode_reward=0.43 +/- 0.53
Episode length: 32.42 +/- 18.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.4     |
|    mean_reward     | 0.431    |
| time/              |          |
|    total_timesteps | 331000   |
---------------------------------
Eval num_timesteps=331500, episode_reward=0.53 +/- 0.48
Episode length: 31.94 +/- 16.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.9     |
|    mean_reward     | 0.533    |
| time/              |          |
|    total_timesteps | 331500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.441    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 162      |
|    time_elapsed    | 3507     |
|    total_timesteps | 331776   |
---------------------------------
Eval num_timesteps=332000, episode_reward=0.56 +/- 0.48
Episode length: 25.34 +/- 14.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.3        |
|    mean_reward          | 0.56        |
| time/                   |             |
|    total_timesteps      | 332000      |
| train/                  |             |
|    approx_kl            | 0.014750119 |
|    clip_fraction        | 0.0955      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.253      |
|    explained_variance   | 0.455       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0165     |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.0194     |
|    value_loss           | 0.049       |
-----------------------------------------
Eval num_timesteps=332500, episode_reward=0.66 +/- 0.42
Episode length: 25.14 +/- 13.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.1     |
|    mean_reward     | 0.661    |
| time/              |          |
|    total_timesteps | 332500   |
---------------------------------
Eval num_timesteps=333000, episode_reward=0.65 +/- 0.44
Episode length: 32.02 +/- 17.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32       |
|    mean_reward     | 0.653    |
| time/              |          |
|    total_timesteps | 333000   |
---------------------------------
Eval num_timesteps=333500, episode_reward=0.58 +/- 0.46
Episode length: 31.48 +/- 14.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.5     |
|    mean_reward     | 0.575    |
| time/              |          |
|    total_timesteps | 333500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.9     |
|    ep_rew_mean     | 0.515    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 163      |
|    time_elapsed    | 3526     |
|    total_timesteps | 333824   |
---------------------------------
Eval num_timesteps=334000, episode_reward=0.63 +/- 0.46
Episode length: 26.96 +/- 15.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27          |
|    mean_reward          | 0.634       |
| time/                   |             |
|    total_timesteps      | 334000      |
| train/                  |             |
|    approx_kl            | 0.014000619 |
|    clip_fraction        | 0.0892      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.222      |
|    explained_variance   | 0.497       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0037     |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0121     |
|    value_loss           | 0.0424      |
-----------------------------------------
Eval num_timesteps=334500, episode_reward=0.63 +/- 0.46
Episode length: 31.70 +/- 18.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.7     |
|    mean_reward     | 0.634    |
| time/              |          |
|    total_timesteps | 334500   |
---------------------------------
Eval num_timesteps=335000, episode_reward=0.53 +/- 0.50
Episode length: 31.80 +/- 17.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.8     |
|    mean_reward     | 0.534    |
| time/              |          |
|    total_timesteps | 335000   |
---------------------------------
Eval num_timesteps=335500, episode_reward=0.58 +/- 0.50
Episode length: 31.44 +/- 19.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.575    |
| time/              |          |
|    total_timesteps | 335500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.2     |
|    ep_rew_mean     | 0.48     |
| time/              |          |
|    fps             | 94       |
|    iterations      | 164      |
|    time_elapsed    | 3546     |
|    total_timesteps | 335872   |
---------------------------------
Eval num_timesteps=336000, episode_reward=0.66 +/- 0.42
Episode length: 31.06 +/- 14.25
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.1        |
|    mean_reward          | 0.657       |
| time/                   |             |
|    total_timesteps      | 336000      |
| train/                  |             |
|    approx_kl            | 0.015847892 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.237      |
|    explained_variance   | 0.602       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0301     |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.0358      |
-----------------------------------------
Eval num_timesteps=336500, episode_reward=0.60 +/- 0.47
Episode length: 25.60 +/- 13.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.6     |
|    mean_reward     | 0.599    |
| time/              |          |
|    total_timesteps | 336500   |
---------------------------------
Eval num_timesteps=337000, episode_reward=0.49 +/- 0.48
Episode length: 28.82 +/- 15.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.8     |
|    mean_reward     | 0.486    |
| time/              |          |
|    total_timesteps | 337000   |
---------------------------------
Eval num_timesteps=337500, episode_reward=0.56 +/- 0.49
Episode length: 29.60 +/- 18.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.6     |
|    mean_reward     | 0.563    |
| time/              |          |
|    total_timesteps | 337500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.8     |
|    ep_rew_mean     | 0.408    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 165      |
|    time_elapsed    | 3565     |
|    total_timesteps | 337920   |
---------------------------------
Eval num_timesteps=338000, episode_reward=0.60 +/- 0.48
Episode length: 31.46 +/- 18.42
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 31.5         |
|    mean_reward          | 0.595        |
| time/                   |              |
|    total_timesteps      | 338000       |
| train/                  |              |
|    approx_kl            | 0.0126164025 |
|    clip_fraction        | 0.0902       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.242       |
|    explained_variance   | 0.458        |
|    learning_rate        | 0.0001       |
|    loss                 | -0.0184      |
|    n_updates            | 1650         |
|    policy_gradient_loss | -0.014       |
|    value_loss           | 0.0429       |
------------------------------------------
Eval num_timesteps=338500, episode_reward=0.56 +/- 0.47
Episode length: 31.42 +/- 16.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.555    |
| time/              |          |
|    total_timesteps | 338500   |
---------------------------------
Eval num_timesteps=339000, episode_reward=0.59 +/- 0.47
Episode length: 26.80 +/- 15.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.8     |
|    mean_reward     | 0.594    |
| time/              |          |
|    total_timesteps | 339000   |
---------------------------------
Eval num_timesteps=339500, episode_reward=0.45 +/- 0.52
Episode length: 32.84 +/- 19.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.8     |
|    mean_reward     | 0.45     |
| time/              |          |
|    total_timesteps | 339500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.8     |
|    ep_rew_mean     | 0.402    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 166      |
|    time_elapsed    | 3585     |
|    total_timesteps | 339968   |
---------------------------------
Eval num_timesteps=340000, episode_reward=0.57 +/- 0.48
Episode length: 32.06 +/- 18.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.1        |
|    mean_reward          | 0.573       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.014928605 |
|    clip_fraction        | 0.098       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.249      |
|    explained_variance   | 0.567       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0267     |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.018      |
|    value_loss           | 0.043       |
-----------------------------------------
Eval num_timesteps=340500, episode_reward=0.51 +/- 0.50
Episode length: 33.72 +/- 19.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.7     |
|    mean_reward     | 0.506    |
| time/              |          |
|    total_timesteps | 340500   |
---------------------------------
Eval num_timesteps=341000, episode_reward=0.63 +/- 0.45
Episode length: 28.86 +/- 15.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.9     |
|    mean_reward     | 0.626    |
| time/              |          |
|    total_timesteps | 341000   |
---------------------------------
Eval num_timesteps=341500, episode_reward=0.55 +/- 0.49
Episode length: 32.40 +/- 18.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.4     |
|    mean_reward     | 0.551    |
| time/              |          |
|    total_timesteps | 341500   |
---------------------------------
Eval num_timesteps=342000, episode_reward=0.55 +/- 0.49
Episode length: 28.98 +/- 16.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29       |
|    mean_reward     | 0.545    |
| time/              |          |
|    total_timesteps | 342000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.6     |
|    ep_rew_mean     | 0.481    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 167      |
|    time_elapsed    | 3609     |
|    total_timesteps | 342016   |
---------------------------------
Eval num_timesteps=342500, episode_reward=0.57 +/- 0.49
Episode length: 27.86 +/- 16.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.9        |
|    mean_reward          | 0.57        |
| time/                   |             |
|    total_timesteps      | 342500      |
| train/                  |             |
|    approx_kl            | 0.012978099 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.264      |
|    explained_variance   | 0.472       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00932    |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.0464      |
-----------------------------------------
Eval num_timesteps=343000, episode_reward=0.59 +/- 0.47
Episode length: 26.74 +/- 16.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.7     |
|    mean_reward     | 0.594    |
| time/              |          |
|    total_timesteps | 343000   |
---------------------------------
Eval num_timesteps=343500, episode_reward=0.49 +/- 0.51
Episode length: 33.82 +/- 19.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.8     |
|    mean_reward     | 0.486    |
| time/              |          |
|    total_timesteps | 343500   |
---------------------------------
Eval num_timesteps=344000, episode_reward=0.63 +/- 0.44
Episode length: 27.94 +/- 13.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.9     |
|    mean_reward     | 0.629    |
| time/              |          |
|    total_timesteps | 344000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 0.523    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 168      |
|    time_elapsed    | 3628     |
|    total_timesteps | 344064   |
---------------------------------
Eval num_timesteps=344500, episode_reward=0.49 +/- 0.52
Episode length: 32.52 +/- 18.66
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.5        |
|    mean_reward          | 0.491       |
| time/                   |             |
|    total_timesteps      | 344500      |
| train/                  |             |
|    approx_kl            | 0.020939438 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.242      |
|    explained_variance   | 0.449       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.000885   |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0151     |
|    value_loss           | 0.0445      |
-----------------------------------------
Eval num_timesteps=345000, episode_reward=0.47 +/- 0.51
Episode length: 33.32 +/- 17.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.3     |
|    mean_reward     | 0.468    |
| time/              |          |
|    total_timesteps | 345000   |
---------------------------------
Eval num_timesteps=345500, episode_reward=0.51 +/- 0.50
Episode length: 32.04 +/- 17.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32       |
|    mean_reward     | 0.513    |
| time/              |          |
|    total_timesteps | 345500   |
---------------------------------
Eval num_timesteps=346000, episode_reward=0.61 +/- 0.47
Episode length: 27.80 +/- 16.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.61     |
| time/              |          |
|    total_timesteps | 346000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.1     |
|    ep_rew_mean     | 0.519    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 169      |
|    time_elapsed    | 3647     |
|    total_timesteps | 346112   |
---------------------------------
Eval num_timesteps=346500, episode_reward=0.47 +/- 0.51
Episode length: 37.10 +/- 19.77
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 37.1        |
|    mean_reward          | 0.473       |
| time/                   |             |
|    total_timesteps      | 346500      |
| train/                  |             |
|    approx_kl            | 0.013033945 |
|    clip_fraction        | 0.09        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.21       |
|    explained_variance   | 0.483       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0177      |
|    n_updates            | 1690        |
|    policy_gradient_loss | -0.0107     |
|    value_loss           | 0.0443      |
-----------------------------------------
Eval num_timesteps=347000, episode_reward=0.62 +/- 0.46
Episode length: 29.32 +/- 16.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.624    |
| time/              |          |
|    total_timesteps | 347000   |
---------------------------------
Eval num_timesteps=347500, episode_reward=0.57 +/- 0.49
Episode length: 28.92 +/- 14.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.9     |
|    mean_reward     | 0.566    |
| time/              |          |
|    total_timesteps | 347500   |
---------------------------------
Eval num_timesteps=348000, episode_reward=0.64 +/- 0.46
Episode length: 29.94 +/- 17.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.9     |
|    mean_reward     | 0.642    |
| time/              |          |
|    total_timesteps | 348000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.1     |
|    ep_rew_mean     | 0.423    |
| time/              |          |
|    fps             | 94       |
|    iterations      | 170      |
|    time_elapsed    | 3666     |
|    total_timesteps | 348160   |
---------------------------------
Eval num_timesteps=348500, episode_reward=0.59 +/- 0.48
Episode length: 26.72 +/- 16.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.7        |
|    mean_reward          | 0.594       |
| time/                   |             |
|    total_timesteps      | 348500      |
| train/                  |             |
|    approx_kl            | 0.017356435 |
|    clip_fraction        | 0.0853      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.181      |
|    explained_variance   | 0.465       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0107     |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.0444      |
-----------------------------------------
Eval num_timesteps=349000, episode_reward=0.58 +/- 0.48
Episode length: 25.34 +/- 15.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.3     |
|    mean_reward     | 0.58     |
| time/              |          |
|    total_timesteps | 349000   |
---------------------------------
Eval num_timesteps=349500, episode_reward=0.44 +/- 0.51
Episode length: 30.18 +/- 17.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.44     |
| time/              |          |
|    total_timesteps | 349500   |
---------------------------------
Eval num_timesteps=350000, episode_reward=0.64 +/- 0.46
Episode length: 25.72 +/- 16.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.7     |
|    mean_reward     | 0.638    |
| time/              |          |
|    total_timesteps | 350000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 0.51     |
| time/              |          |
|    fps             | 95       |
|    iterations      | 171      |
|    time_elapsed    | 3684     |
|    total_timesteps | 350208   |
---------------------------------
Eval num_timesteps=350500, episode_reward=0.61 +/- 0.47
Episode length: 27.28 +/- 13.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.3        |
|    mean_reward          | 0.612       |
| time/                   |             |
|    total_timesteps      | 350500      |
| train/                  |             |
|    approx_kl            | 0.014801129 |
|    clip_fraction        | 0.0948      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.241      |
|    explained_variance   | 0.505       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0156     |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.016      |
|    value_loss           | 0.0416      |
-----------------------------------------
Eval num_timesteps=351000, episode_reward=0.61 +/- 0.46
Episode length: 26.94 +/- 16.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.9     |
|    mean_reward     | 0.613    |
| time/              |          |
|    total_timesteps | 351000   |
---------------------------------
Eval num_timesteps=351500, episode_reward=0.46 +/- 0.51
Episode length: 31.22 +/- 19.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.456    |
| time/              |          |
|    total_timesteps | 351500   |
---------------------------------
Eval num_timesteps=352000, episode_reward=0.41 +/- 0.50
Episode length: 27.80 +/- 14.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.41     |
| time/              |          |
|    total_timesteps | 352000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.6     |
|    ep_rew_mean     | 0.537    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 172      |
|    time_elapsed    | 3702     |
|    total_timesteps | 352256   |
---------------------------------
Eval num_timesteps=352500, episode_reward=0.54 +/- 0.49
Episode length: 30.30 +/- 17.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30.3       |
|    mean_reward          | 0.54       |
| time/                   |            |
|    total_timesteps      | 352500     |
| train/                  |            |
|    approx_kl            | 0.01400182 |
|    clip_fraction        | 0.0792     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.195     |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0172     |
|    n_updates            | 1720       |
|    policy_gradient_loss | -0.0138    |
|    value_loss           | 0.0419     |
----------------------------------------
Eval num_timesteps=353000, episode_reward=0.52 +/- 0.50
Episode length: 30.44 +/- 15.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.4     |
|    mean_reward     | 0.519    |
| time/              |          |
|    total_timesteps | 353000   |
---------------------------------
Eval num_timesteps=353500, episode_reward=0.54 +/- 0.49
Episode length: 29.54 +/- 15.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.543    |
| time/              |          |
|    total_timesteps | 353500   |
---------------------------------
Eval num_timesteps=354000, episode_reward=0.55 +/- 0.48
Episode length: 31.58 +/- 17.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.6     |
|    mean_reward     | 0.555    |
| time/              |          |
|    total_timesteps | 354000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.5     |
|    ep_rew_mean     | 0.503    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 173      |
|    time_elapsed    | 3721     |
|    total_timesteps | 354304   |
---------------------------------
Eval num_timesteps=354500, episode_reward=0.54 +/- 0.48
Episode length: 26.04 +/- 13.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26          |
|    mean_reward          | 0.537       |
| time/                   |             |
|    total_timesteps      | 354500      |
| train/                  |             |
|    approx_kl            | 0.017823601 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.225      |
|    explained_variance   | 0.495       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0331     |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 0.0411      |
-----------------------------------------
Eval num_timesteps=355000, episode_reward=0.59 +/- 0.47
Episode length: 27.52 +/- 13.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.591    |
| time/              |          |
|    total_timesteps | 355000   |
---------------------------------
Eval num_timesteps=355500, episode_reward=0.60 +/- 0.47
Episode length: 29.46 +/- 16.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.603    |
| time/              |          |
|    total_timesteps | 355500   |
---------------------------------
Eval num_timesteps=356000, episode_reward=0.61 +/- 0.46
Episode length: 26.88 +/- 14.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.9     |
|    mean_reward     | 0.614    |
| time/              |          |
|    total_timesteps | 356000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.7     |
|    ep_rew_mean     | 0.545    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 174      |
|    time_elapsed    | 3740     |
|    total_timesteps | 356352   |
---------------------------------
Eval num_timesteps=356500, episode_reward=0.60 +/- 0.47
Episode length: 30.06 +/- 15.67
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.601       |
| time/                   |             |
|    total_timesteps      | 356500      |
| train/                  |             |
|    approx_kl            | 0.015138476 |
|    clip_fraction        | 0.0939      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.242      |
|    explained_variance   | 0.445       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0155     |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0136     |
|    value_loss           | 0.0473      |
-----------------------------------------
Eval num_timesteps=357000, episode_reward=0.51 +/- 0.48
Episode length: 27.58 +/- 13.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.6     |
|    mean_reward     | 0.511    |
| time/              |          |
|    total_timesteps | 357000   |
---------------------------------
Eval num_timesteps=357500, episode_reward=0.48 +/- 0.48
Episode length: 29.32 +/- 15.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.484    |
| time/              |          |
|    total_timesteps | 357500   |
---------------------------------
Eval num_timesteps=358000, episode_reward=0.59 +/- 0.45
Episode length: 27.30 +/- 13.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.3     |
|    mean_reward     | 0.592    |
| time/              |          |
|    total_timesteps | 358000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.8     |
|    ep_rew_mean     | 0.636    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 175      |
|    time_elapsed    | 3759     |
|    total_timesteps | 358400   |
---------------------------------
Eval num_timesteps=358500, episode_reward=0.55 +/- 0.49
Episode length: 27.30 +/- 16.45
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27.3       |
|    mean_reward          | 0.552      |
| time/                   |            |
|    total_timesteps      | 358500     |
| train/                  |            |
|    approx_kl            | 0.02251239 |
|    clip_fraction        | 0.111      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.229     |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0217    |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.0157    |
|    value_loss           | 0.033      |
----------------------------------------
Eval num_timesteps=359000, episode_reward=0.58 +/- 0.48
Episode length: 24.62 +/- 13.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.6     |
|    mean_reward     | 0.583    |
| time/              |          |
|    total_timesteps | 359000   |
---------------------------------
Eval num_timesteps=359500, episode_reward=0.62 +/- 0.45
Episode length: 30.90 +/- 17.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.9     |
|    mean_reward     | 0.618    |
| time/              |          |
|    total_timesteps | 359500   |
---------------------------------
Eval num_timesteps=360000, episode_reward=0.49 +/- 0.51
Episode length: 26.92 +/- 17.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.9     |
|    mean_reward     | 0.494    |
| time/              |          |
|    total_timesteps | 360000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.5     |
|    ep_rew_mean     | 0.561    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 176      |
|    time_elapsed    | 3776     |
|    total_timesteps | 360448   |
---------------------------------
Eval num_timesteps=360500, episode_reward=0.62 +/- 0.45
Episode length: 29.36 +/- 16.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.4        |
|    mean_reward          | 0.624       |
| time/                   |             |
|    total_timesteps      | 360500      |
| train/                  |             |
|    approx_kl            | 0.015919419 |
|    clip_fraction        | 0.0999      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.236      |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0261     |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.0177     |
|    value_loss           | 0.043       |
-----------------------------------------
Eval num_timesteps=361000, episode_reward=0.73 +/- 0.36
Episode length: 27.04 +/- 13.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.733    |
| time/              |          |
|    total_timesteps | 361000   |
---------------------------------
New best mean reward!
Eval num_timesteps=361500, episode_reward=0.58 +/- 0.46
Episode length: 25.16 +/- 12.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.2     |
|    mean_reward     | 0.581    |
| time/              |          |
|    total_timesteps | 361500   |
---------------------------------
Eval num_timesteps=362000, episode_reward=0.45 +/- 0.49
Episode length: 32.24 +/- 16.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.2     |
|    mean_reward     | 0.452    |
| time/              |          |
|    total_timesteps | 362000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.4     |
|    ep_rew_mean     | 0.464    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 177      |
|    time_elapsed    | 3795     |
|    total_timesteps | 362496   |
---------------------------------
Eval num_timesteps=362500, episode_reward=0.51 +/- 0.50
Episode length: 28.90 +/- 16.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.9        |
|    mean_reward          | 0.506       |
| time/                   |             |
|    total_timesteps      | 362500      |
| train/                  |             |
|    approx_kl            | 0.014257569 |
|    clip_fraction        | 0.0862      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.207      |
|    explained_variance   | 0.579       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00454     |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0138     |
|    value_loss           | 0.0384      |
-----------------------------------------
Eval num_timesteps=363000, episode_reward=0.67 +/- 0.43
Episode length: 28.48 +/- 15.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.5     |
|    mean_reward     | 0.667    |
| time/              |          |
|    total_timesteps | 363000   |
---------------------------------
Eval num_timesteps=363500, episode_reward=0.54 +/- 0.49
Episode length: 25.98 +/- 13.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26       |
|    mean_reward     | 0.537    |
| time/              |          |
|    total_timesteps | 363500   |
---------------------------------
Eval num_timesteps=364000, episode_reward=0.60 +/- 0.46
Episode length: 31.42 +/- 16.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.596    |
| time/              |          |
|    total_timesteps | 364000   |
---------------------------------
Eval num_timesteps=364500, episode_reward=0.57 +/- 0.47
Episode length: 28.76 +/- 15.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.8     |
|    mean_reward     | 0.566    |
| time/              |          |
|    total_timesteps | 364500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.5     |
|    ep_rew_mean     | 0.507    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 178      |
|    time_elapsed    | 3815     |
|    total_timesteps | 364544   |
---------------------------------
Eval num_timesteps=365000, episode_reward=0.50 +/- 0.49
Episode length: 26.42 +/- 13.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.4        |
|    mean_reward          | 0.496       |
| time/                   |             |
|    total_timesteps      | 365000      |
| train/                  |             |
|    approx_kl            | 0.022387648 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.226      |
|    explained_variance   | 0.54        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000678    |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.0172     |
|    value_loss           | 0.0442      |
-----------------------------------------
Eval num_timesteps=365500, episode_reward=0.51 +/- 0.49
Episode length: 32.42 +/- 17.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.4     |
|    mean_reward     | 0.511    |
| time/              |          |
|    total_timesteps | 365500   |
---------------------------------
Eval num_timesteps=366000, episode_reward=0.49 +/- 0.49
Episode length: 27.90 +/- 13.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.9     |
|    mean_reward     | 0.49     |
| time/              |          |
|    total_timesteps | 366000   |
---------------------------------
Eval num_timesteps=366500, episode_reward=0.60 +/- 0.47
Episode length: 25.94 +/- 14.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.9     |
|    mean_reward     | 0.598    |
| time/              |          |
|    total_timesteps | 366500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 0.481    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 179      |
|    time_elapsed    | 3834     |
|    total_timesteps | 366592   |
---------------------------------
Eval num_timesteps=367000, episode_reward=0.55 +/- 0.48
Episode length: 26.56 +/- 13.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.6        |
|    mean_reward          | 0.555       |
| time/                   |             |
|    total_timesteps      | 367000      |
| train/                  |             |
|    approx_kl            | 0.012405735 |
|    clip_fraction        | 0.0897      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.206      |
|    explained_variance   | 0.547       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0108      |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.0122     |
|    value_loss           | 0.0429      |
-----------------------------------------
Eval num_timesteps=367500, episode_reward=0.64 +/- 0.44
Episode length: 26.30 +/- 13.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.3     |
|    mean_reward     | 0.636    |
| time/              |          |
|    total_timesteps | 367500   |
---------------------------------
Eval num_timesteps=368000, episode_reward=0.51 +/- 0.49
Episode length: 28.40 +/- 14.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.4     |
|    mean_reward     | 0.508    |
| time/              |          |
|    total_timesteps | 368000   |
---------------------------------
Eval num_timesteps=368500, episode_reward=0.52 +/- 0.50
Episode length: 30.56 +/- 17.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.519    |
| time/              |          |
|    total_timesteps | 368500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.3     |
|    ep_rew_mean     | 0.516    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 180      |
|    time_elapsed    | 3851     |
|    total_timesteps | 368640   |
---------------------------------
Eval num_timesteps=369000, episode_reward=0.53 +/- 0.49
Episode length: 27.40 +/- 16.46
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.4        |
|    mean_reward          | 0.532       |
| time/                   |             |
|    total_timesteps      | 369000      |
| train/                  |             |
|    approx_kl            | 0.016862381 |
|    clip_fraction        | 0.0982      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.214      |
|    explained_variance   | 0.49        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00166     |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.0442      |
-----------------------------------------
Eval num_timesteps=369500, episode_reward=0.52 +/- 0.50
Episode length: 30.12 +/- 18.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.521    |
| time/              |          |
|    total_timesteps | 369500   |
---------------------------------
Eval num_timesteps=370000, episode_reward=0.54 +/- 0.50
Episode length: 29.18 +/- 17.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.544    |
| time/              |          |
|    total_timesteps | 370000   |
---------------------------------
Eval num_timesteps=370500, episode_reward=0.57 +/- 0.48
Episode length: 27.78 +/- 17.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.57     |
| time/              |          |
|    total_timesteps | 370500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.3     |
|    ep_rew_mean     | 0.632    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 181      |
|    time_elapsed    | 3870     |
|    total_timesteps | 370688   |
---------------------------------
Eval num_timesteps=371000, episode_reward=0.60 +/- 0.46
Episode length: 29.92 +/- 17.98
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 29.9       |
|    mean_reward          | 0.601      |
| time/                   |            |
|    total_timesteps      | 371000     |
| train/                  |            |
|    approx_kl            | 0.01456702 |
|    clip_fraction        | 0.104      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.216     |
|    explained_variance   | 0.396      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.000681   |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.0162    |
|    value_loss           | 0.0437     |
----------------------------------------
Eval num_timesteps=371500, episode_reward=0.59 +/- 0.46
Episode length: 28.58 +/- 16.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.587    |
| time/              |          |
|    total_timesteps | 371500   |
---------------------------------
Eval num_timesteps=372000, episode_reward=0.61 +/- 0.45
Episode length: 27.56 +/- 15.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.6     |
|    mean_reward     | 0.611    |
| time/              |          |
|    total_timesteps | 372000   |
---------------------------------
Eval num_timesteps=372500, episode_reward=0.46 +/- 0.51
Episode length: 31.02 +/- 18.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31       |
|    mean_reward     | 0.457    |
| time/              |          |
|    total_timesteps | 372500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.6     |
|    ep_rew_mean     | 0.613    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 182      |
|    time_elapsed    | 3889     |
|    total_timesteps | 372736   |
---------------------------------
Eval num_timesteps=373000, episode_reward=0.55 +/- 0.51
Episode length: 28.98 +/- 17.46
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29          |
|    mean_reward          | 0.545       |
| time/                   |             |
|    total_timesteps      | 373000      |
| train/                  |             |
|    approx_kl            | 0.017605834 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.219      |
|    explained_variance   | 0.537       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.013       |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.0151     |
|    value_loss           | 0.0412      |
-----------------------------------------
Eval num_timesteps=373500, episode_reward=0.54 +/- 0.48
Episode length: 25.16 +/- 13.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.2     |
|    mean_reward     | 0.54     |
| time/              |          |
|    total_timesteps | 373500   |
---------------------------------
Eval num_timesteps=374000, episode_reward=0.55 +/- 0.49
Episode length: 28.54 +/- 17.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.5     |
|    mean_reward     | 0.547    |
| time/              |          |
|    total_timesteps | 374000   |
---------------------------------
Eval num_timesteps=374500, episode_reward=0.47 +/- 0.49
Episode length: 27.12 +/- 15.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.1     |
|    mean_reward     | 0.473    |
| time/              |          |
|    total_timesteps | 374500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.6     |
|    ep_rew_mean     | 0.533    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 183      |
|    time_elapsed    | 3908     |
|    total_timesteps | 374784   |
---------------------------------
Eval num_timesteps=375000, episode_reward=0.59 +/- 0.47
Episode length: 29.10 +/- 15.13
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.1        |
|    mean_reward          | 0.585       |
| time/                   |             |
|    total_timesteps      | 375000      |
| train/                  |             |
|    approx_kl            | 0.015174301 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.22       |
|    explained_variance   | 0.594       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0109      |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0121     |
|    value_loss           | 0.043       |
-----------------------------------------
Eval num_timesteps=375500, episode_reward=0.61 +/- 0.46
Episode length: 26.60 +/- 15.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.6     |
|    mean_reward     | 0.615    |
| time/              |          |
|    total_timesteps | 375500   |
---------------------------------
Eval num_timesteps=376000, episode_reward=0.64 +/- 0.45
Episode length: 25.96 +/- 14.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26       |
|    mean_reward     | 0.637    |
| time/              |          |
|    total_timesteps | 376000   |
---------------------------------
Eval num_timesteps=376500, episode_reward=0.63 +/- 0.45
Episode length: 26.64 +/- 15.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.6     |
|    mean_reward     | 0.635    |
| time/              |          |
|    total_timesteps | 376500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.8     |
|    ep_rew_mean     | 0.536    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 184      |
|    time_elapsed    | 3927     |
|    total_timesteps | 376832   |
---------------------------------
Eval num_timesteps=377000, episode_reward=0.53 +/- 0.48
Episode length: 28.92 +/- 14.67
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.9        |
|    mean_reward          | 0.526       |
| time/                   |             |
|    total_timesteps      | 377000      |
| train/                  |             |
|    approx_kl            | 0.018356718 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.21       |
|    explained_variance   | 0.474       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0069      |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.0161     |
|    value_loss           | 0.0424      |
-----------------------------------------
Eval num_timesteps=377500, episode_reward=0.54 +/- 0.50
Episode length: 30.12 +/- 17.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.541    |
| time/              |          |
|    total_timesteps | 377500   |
---------------------------------
Eval num_timesteps=378000, episode_reward=0.51 +/- 0.50
Episode length: 28.56 +/- 17.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.507    |
| time/              |          |
|    total_timesteps | 378000   |
---------------------------------
Eval num_timesteps=378500, episode_reward=0.64 +/- 0.44
Episode length: 29.34 +/- 14.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.644    |
| time/              |          |
|    total_timesteps | 378500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.7     |
|    ep_rew_mean     | 0.504    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 185      |
|    time_elapsed    | 3945     |
|    total_timesteps | 378880   |
---------------------------------
Eval num_timesteps=379000, episode_reward=0.57 +/- 0.47
Episode length: 27.14 +/- 14.70
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.1        |
|    mean_reward          | 0.573       |
| time/                   |             |
|    total_timesteps      | 379000      |
| train/                  |             |
|    approx_kl            | 0.019984115 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.238      |
|    explained_variance   | 0.505       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00971    |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.0153     |
|    value_loss           | 0.0419      |
-----------------------------------------
Eval num_timesteps=379500, episode_reward=0.51 +/- 0.49
Episode length: 33.72 +/- 15.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.7     |
|    mean_reward     | 0.506    |
| time/              |          |
|    total_timesteps | 379500   |
---------------------------------
Eval num_timesteps=380000, episode_reward=0.42 +/- 0.51
Episode length: 29.40 +/- 17.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.4     |
|    mean_reward     | 0.424    |
| time/              |          |
|    total_timesteps | 380000   |
---------------------------------
Eval num_timesteps=380500, episode_reward=0.58 +/- 0.47
Episode length: 24.38 +/- 13.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.4     |
|    mean_reward     | 0.584    |
| time/              |          |
|    total_timesteps | 380500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.9     |
|    ep_rew_mean     | 0.596    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 186      |
|    time_elapsed    | 3964     |
|    total_timesteps | 380928   |
---------------------------------
Eval num_timesteps=381000, episode_reward=0.48 +/- 0.52
Episode length: 30.46 +/- 19.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30.5       |
|    mean_reward          | 0.48       |
| time/                   |            |
|    total_timesteps      | 381000     |
| train/                  |            |
|    approx_kl            | 0.01739324 |
|    clip_fraction        | 0.0955     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.205     |
|    explained_variance   | 0.414      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0135    |
|    n_updates            | 1860       |
|    policy_gradient_loss | -0.0148    |
|    value_loss           | 0.0484     |
----------------------------------------
Eval num_timesteps=381500, episode_reward=0.52 +/- 0.49
Episode length: 29.28 +/- 15.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.3     |
|    mean_reward     | 0.524    |
| time/              |          |
|    total_timesteps | 381500   |
---------------------------------
Eval num_timesteps=382000, episode_reward=0.39 +/- 0.54
Episode length: 33.18 +/- 21.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.2     |
|    mean_reward     | 0.388    |
| time/              |          |
|    total_timesteps | 382000   |
---------------------------------
Eval num_timesteps=382500, episode_reward=0.64 +/- 0.45
Episode length: 26.20 +/- 14.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.2     |
|    mean_reward     | 0.637    |
| time/              |          |
|    total_timesteps | 382500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.1     |
|    ep_rew_mean     | 0.579    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 187      |
|    time_elapsed    | 3984     |
|    total_timesteps | 382976   |
---------------------------------
Eval num_timesteps=383000, episode_reward=0.61 +/- 0.45
Episode length: 26.92 +/- 15.08
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.9        |
|    mean_reward          | 0.614       |
| time/                   |             |
|    total_timesteps      | 383000      |
| train/                  |             |
|    approx_kl            | 0.018781763 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.213      |
|    explained_variance   | 0.432       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0207     |
|    n_updates            | 1870        |
|    policy_gradient_loss | -0.016      |
|    value_loss           | 0.0403      |
-----------------------------------------
Eval num_timesteps=383500, episode_reward=0.61 +/- 0.46
Episode length: 27.82 +/- 17.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.61     |
| time/              |          |
|    total_timesteps | 383500   |
---------------------------------
Eval num_timesteps=384000, episode_reward=0.56 +/- 0.48
Episode length: 26.04 +/- 14.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26       |
|    mean_reward     | 0.557    |
| time/              |          |
|    total_timesteps | 384000   |
---------------------------------
Eval num_timesteps=384500, episode_reward=0.60 +/- 0.47
Episode length: 29.20 +/- 18.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.604    |
| time/              |          |
|    total_timesteps | 384500   |
---------------------------------
Eval num_timesteps=385000, episode_reward=0.57 +/- 0.49
Episode length: 27.68 +/- 16.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.57     |
| time/              |          |
|    total_timesteps | 385000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.9     |
|    ep_rew_mean     | 0.634    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 188      |
|    time_elapsed    | 4004     |
|    total_timesteps | 385024   |
---------------------------------
Eval num_timesteps=385500, episode_reward=0.49 +/- 0.50
Episode length: 26.92 +/- 14.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.9        |
|    mean_reward          | 0.494       |
| time/                   |             |
|    total_timesteps      | 385500      |
| train/                  |             |
|    approx_kl            | 0.024460297 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.214      |
|    explained_variance   | 0.404       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0198     |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.021      |
|    value_loss           | 0.0451      |
-----------------------------------------
Eval num_timesteps=386000, episode_reward=0.58 +/- 0.47
Episode length: 24.18 +/- 11.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.2     |
|    mean_reward     | 0.584    |
| time/              |          |
|    total_timesteps | 386000   |
---------------------------------
Eval num_timesteps=386500, episode_reward=0.62 +/- 0.45
Episode length: 26.08 +/- 14.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.1     |
|    mean_reward     | 0.617    |
| time/              |          |
|    total_timesteps | 386500   |
---------------------------------
Eval num_timesteps=387000, episode_reward=0.58 +/- 0.46
Episode length: 30.20 +/- 17.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.58     |
| time/              |          |
|    total_timesteps | 387000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 0.56     |
| time/              |          |
|    fps             | 96       |
|    iterations      | 189      |
|    time_elapsed    | 4021     |
|    total_timesteps | 387072   |
---------------------------------
Eval num_timesteps=387500, episode_reward=0.55 +/- 0.49
Episode length: 28.94 +/- 17.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.9        |
|    mean_reward          | 0.545       |
| time/                   |             |
|    total_timesteps      | 387500      |
| train/                  |             |
|    approx_kl            | 0.022716735 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.214      |
|    explained_variance   | 0.503       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00529    |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 0.0418      |
-----------------------------------------
Eval num_timesteps=388000, episode_reward=0.53 +/- 0.48
Episode length: 27.26 +/- 15.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.3     |
|    mean_reward     | 0.532    |
| time/              |          |
|    total_timesteps | 388000   |
---------------------------------
Eval num_timesteps=388500, episode_reward=0.50 +/- 0.51
Episode length: 29.78 +/- 16.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.502    |
| time/              |          |
|    total_timesteps | 388500   |
---------------------------------
Eval num_timesteps=389000, episode_reward=0.77 +/- 0.34
Episode length: 24.06 +/- 13.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.1     |
|    mean_reward     | 0.765    |
| time/              |          |
|    total_timesteps | 389000   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.9     |
|    ep_rew_mean     | 0.532    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 190      |
|    time_elapsed    | 4038     |
|    total_timesteps | 389120   |
---------------------------------
Eval num_timesteps=389500, episode_reward=0.57 +/- 0.47
Episode length: 27.58 +/- 13.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.6        |
|    mean_reward          | 0.571       |
| time/                   |             |
|    total_timesteps      | 389500      |
| train/                  |             |
|    approx_kl            | 0.017468542 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.271      |
|    explained_variance   | 0.384       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00084     |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.057       |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=0.51 +/- 0.49
Episode length: 23.12 +/- 13.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.1     |
|    mean_reward     | 0.509    |
| time/              |          |
|    total_timesteps | 390000   |
---------------------------------
Eval num_timesteps=390500, episode_reward=0.50 +/- 0.50
Episode length: 30.64 +/- 17.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.499    |
| time/              |          |
|    total_timesteps | 390500   |
---------------------------------
Eval num_timesteps=391000, episode_reward=0.62 +/- 0.46
Episode length: 26.22 +/- 15.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.2     |
|    mean_reward     | 0.616    |
| time/              |          |
|    total_timesteps | 391000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.3     |
|    ep_rew_mean     | 0.576    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 191      |
|    time_elapsed    | 4056     |
|    total_timesteps | 391168   |
---------------------------------
Eval num_timesteps=391500, episode_reward=0.58 +/- 0.47
Episode length: 24.22 +/- 15.32
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24.2        |
|    mean_reward          | 0.585       |
| time/                   |             |
|    total_timesteps      | 391500      |
| train/                  |             |
|    approx_kl            | 0.018663831 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.253      |
|    explained_variance   | 0.585       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0137     |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0184     |
|    value_loss           | 0.0336      |
-----------------------------------------
Eval num_timesteps=392000, episode_reward=0.42 +/- 0.51
Episode length: 25.12 +/- 16.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.1     |
|    mean_reward     | 0.421    |
| time/              |          |
|    total_timesteps | 392000   |
---------------------------------
Eval num_timesteps=392500, episode_reward=0.59 +/- 0.45
Episode length: 28.12 +/- 16.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.1     |
|    mean_reward     | 0.589    |
| time/              |          |
|    total_timesteps | 392500   |
---------------------------------
Eval num_timesteps=393000, episode_reward=0.52 +/- 0.50
Episode length: 24.18 +/- 14.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.2     |
|    mean_reward     | 0.524    |
| time/              |          |
|    total_timesteps | 393000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.1     |
|    ep_rew_mean     | 0.479    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 192      |
|    time_elapsed    | 4073     |
|    total_timesteps | 393216   |
---------------------------------
Eval num_timesteps=393500, episode_reward=0.56 +/- 0.48
Episode length: 30.16 +/- 16.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.2        |
|    mean_reward          | 0.561       |
| time/                   |             |
|    total_timesteps      | 393500      |
| train/                  |             |
|    approx_kl            | 0.022595944 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.266      |
|    explained_variance   | 0.453       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0297     |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0227     |
|    value_loss           | 0.0441      |
-----------------------------------------
Eval num_timesteps=394000, episode_reward=0.51 +/- 0.51
Episode length: 33.90 +/- 20.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.9     |
|    mean_reward     | 0.506    |
| time/              |          |
|    total_timesteps | 394000   |
---------------------------------
Eval num_timesteps=394500, episode_reward=0.52 +/- 0.51
Episode length: 31.16 +/- 20.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.517    |
| time/              |          |
|    total_timesteps | 394500   |
---------------------------------
Eval num_timesteps=395000, episode_reward=0.67 +/- 0.42
Episode length: 23.76 +/- 11.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.8     |
|    mean_reward     | 0.666    |
| time/              |          |
|    total_timesteps | 395000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.2     |
|    ep_rew_mean     | 0.442    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 193      |
|    time_elapsed    | 4092     |
|    total_timesteps | 395264   |
---------------------------------
Eval num_timesteps=395500, episode_reward=0.52 +/- 0.47
Episode length: 25.28 +/- 12.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.3        |
|    mean_reward          | 0.52        |
| time/                   |             |
|    total_timesteps      | 395500      |
| train/                  |             |
|    approx_kl            | 0.017068904 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.26       |
|    explained_variance   | 0.583       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0159     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.0409      |
-----------------------------------------
Eval num_timesteps=396000, episode_reward=0.54 +/- 0.49
Episode length: 25.96 +/- 16.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26       |
|    mean_reward     | 0.538    |
| time/              |          |
|    total_timesteps | 396000   |
---------------------------------
Eval num_timesteps=396500, episode_reward=0.57 +/- 0.47
Episode length: 23.62 +/- 13.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.6     |
|    mean_reward     | 0.567    |
| time/              |          |
|    total_timesteps | 396500   |
---------------------------------
Eval num_timesteps=397000, episode_reward=0.46 +/- 0.50
Episode length: 24.96 +/- 14.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25       |
|    mean_reward     | 0.462    |
| time/              |          |
|    total_timesteps | 397000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.6     |
|    ep_rew_mean     | 0.515    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 194      |
|    time_elapsed    | 4106     |
|    total_timesteps | 397312   |
---------------------------------
Eval num_timesteps=397500, episode_reward=0.54 +/- 0.50
Episode length: 30.00 +/- 18.70
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.541       |
| time/                   |             |
|    total_timesteps      | 397500      |
| train/                  |             |
|    approx_kl            | 0.021070426 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.249      |
|    explained_variance   | 0.429       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0159      |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.0218     |
|    value_loss           | 0.0497      |
-----------------------------------------
Eval num_timesteps=398000, episode_reward=0.61 +/- 0.46
Episode length: 29.04 +/- 15.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29       |
|    mean_reward     | 0.605    |
| time/              |          |
|    total_timesteps | 398000   |
---------------------------------
Eval num_timesteps=398500, episode_reward=0.65 +/- 0.44
Episode length: 23.48 +/- 11.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.5     |
|    mean_reward     | 0.647    |
| time/              |          |
|    total_timesteps | 398500   |
---------------------------------
Eval num_timesteps=399000, episode_reward=0.63 +/- 0.47
Episode length: 28.48 +/- 18.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.5     |
|    mean_reward     | 0.627    |
| time/              |          |
|    total_timesteps | 399000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.4     |
|    ep_rew_mean     | 0.566    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 195      |
|    time_elapsed    | 4124     |
|    total_timesteps | 399360   |
---------------------------------
Eval num_timesteps=399500, episode_reward=0.56 +/- 0.49
Episode length: 25.76 +/- 14.89
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.8        |
|    mean_reward          | 0.558       |
| time/                   |             |
|    total_timesteps      | 399500      |
| train/                  |             |
|    approx_kl            | 0.015130439 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.257      |
|    explained_variance   | 0.588       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0116     |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.02       |
|    value_loss           | 0.0377      |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=0.59 +/- 0.46
Episode length: 27.80 +/- 15.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.59     |
| time/              |          |
|    total_timesteps | 400000   |
---------------------------------
Eval num_timesteps=400500, episode_reward=0.51 +/- 0.49
Episode length: 27.36 +/- 15.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.4     |
|    mean_reward     | 0.512    |
| time/              |          |
|    total_timesteps | 400500   |
---------------------------------
Eval num_timesteps=401000, episode_reward=0.50 +/- 0.51
Episode length: 29.84 +/- 18.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.502    |
| time/              |          |
|    total_timesteps | 401000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.3     |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    fps             | 96       |
|    iterations      | 196      |
|    time_elapsed    | 4143     |
|    total_timesteps | 401408   |
---------------------------------
Eval num_timesteps=401500, episode_reward=0.51 +/- 0.50
Episode length: 27.60 +/- 17.70
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.6        |
|    mean_reward          | 0.511       |
| time/                   |             |
|    total_timesteps      | 401500      |
| train/                  |             |
|    approx_kl            | 0.019135598 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.247      |
|    explained_variance   | 0.529       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00184    |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.0205     |
|    value_loss           | 0.0453      |
-----------------------------------------
Eval num_timesteps=402000, episode_reward=0.54 +/- 0.50
Episode length: 30.82 +/- 18.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.8     |
|    mean_reward     | 0.538    |
| time/              |          |
|    total_timesteps | 402000   |
---------------------------------
Eval num_timesteps=402500, episode_reward=0.56 +/- 0.49
Episode length: 30.98 +/- 18.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31       |
|    mean_reward     | 0.557    |
| time/              |          |
|    total_timesteps | 402500   |
---------------------------------
Eval num_timesteps=403000, episode_reward=0.60 +/- 0.47
Episode length: 26.08 +/- 16.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.1     |
|    mean_reward     | 0.597    |
| time/              |          |
|    total_timesteps | 403000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.4     |
|    ep_rew_mean     | 0.574    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 197      |
|    time_elapsed    | 4162     |
|    total_timesteps | 403456   |
---------------------------------
Eval num_timesteps=403500, episode_reward=0.61 +/- 0.46
Episode length: 28.00 +/- 15.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28          |
|    mean_reward          | 0.61        |
| time/                   |             |
|    total_timesteps      | 403500      |
| train/                  |             |
|    approx_kl            | 0.016065856 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.239      |
|    explained_variance   | 0.574       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0238     |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.0172     |
|    value_loss           | 0.0402      |
-----------------------------------------
Eval num_timesteps=404000, episode_reward=0.56 +/- 0.47
Episode length: 29.08 +/- 17.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.565    |
| time/              |          |
|    total_timesteps | 404000   |
---------------------------------
Eval num_timesteps=404500, episode_reward=0.53 +/- 0.50
Episode length: 28.06 +/- 16.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.1     |
|    mean_reward     | 0.529    |
| time/              |          |
|    total_timesteps | 404500   |
---------------------------------
Eval num_timesteps=405000, episode_reward=0.62 +/- 0.45
Episode length: 25.14 +/- 15.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.1     |
|    mean_reward     | 0.621    |
| time/              |          |
|    total_timesteps | 405000   |
---------------------------------
Eval num_timesteps=405500, episode_reward=0.52 +/- 0.49
Episode length: 24.20 +/- 12.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.2     |
|    mean_reward     | 0.524    |
| time/              |          |
|    total_timesteps | 405500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.1     |
|    ep_rew_mean     | 0.551    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 198      |
|    time_elapsed    | 4182     |
|    total_timesteps | 405504   |
---------------------------------
Eval num_timesteps=406000, episode_reward=0.61 +/- 0.45
Episode length: 23.06 +/- 13.07
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 23.1        |
|    mean_reward          | 0.609       |
| time/                   |             |
|    total_timesteps      | 406000      |
| train/                  |             |
|    approx_kl            | 0.016768375 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.249      |
|    explained_variance   | 0.52        |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0223     |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 0.0443      |
-----------------------------------------
Eval num_timesteps=406500, episode_reward=0.54 +/- 0.49
Episode length: 26.56 +/- 14.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.6     |
|    mean_reward     | 0.535    |
| time/              |          |
|    total_timesteps | 406500   |
---------------------------------
Eval num_timesteps=407000, episode_reward=0.65 +/- 0.44
Episode length: 23.82 +/- 13.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.8     |
|    mean_reward     | 0.646    |
| time/              |          |
|    total_timesteps | 407000   |
---------------------------------
Eval num_timesteps=407500, episode_reward=0.54 +/- 0.49
Episode length: 25.10 +/- 14.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.1     |
|    mean_reward     | 0.541    |
| time/              |          |
|    total_timesteps | 407500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.7     |
|    ep_rew_mean     | 0.549    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 199      |
|    time_elapsed    | 4200     |
|    total_timesteps | 407552   |
---------------------------------
Eval num_timesteps=408000, episode_reward=0.52 +/- 0.49
Episode length: 24.10 +/- 14.07
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.1       |
|    mean_reward          | 0.525      |
| time/                   |            |
|    total_timesteps      | 408000     |
| train/                  |            |
|    approx_kl            | 0.01644419 |
|    clip_fraction        | 0.112      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.258     |
|    explained_variance   | 0.447      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0198     |
|    n_updates            | 1990       |
|    policy_gradient_loss | -0.0189    |
|    value_loss           | 0.0494     |
----------------------------------------
Eval num_timesteps=408500, episode_reward=0.56 +/- 0.48
Episode length: 26.48 +/- 15.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.555    |
| time/              |          |
|    total_timesteps | 408500   |
---------------------------------
Eval num_timesteps=409000, episode_reward=0.57 +/- 0.48
Episode length: 27.08 +/- 16.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.1     |
|    mean_reward     | 0.573    |
| time/              |          |
|    total_timesteps | 409000   |
---------------------------------
Eval num_timesteps=409500, episode_reward=0.50 +/- 0.49
Episode length: 25.12 +/- 12.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.1     |
|    mean_reward     | 0.501    |
| time/              |          |
|    total_timesteps | 409500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 0.51     |
| time/              |          |
|    fps             | 97       |
|    iterations      | 200      |
|    time_elapsed    | 4219     |
|    total_timesteps | 409600   |
---------------------------------
Eval num_timesteps=410000, episode_reward=0.56 +/- 0.49
Episode length: 30.30 +/- 19.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.3        |
|    mean_reward          | 0.56        |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.014947396 |
|    clip_fraction        | 0.0991      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.231      |
|    explained_variance   | 0.516       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0193     |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.0392      |
-----------------------------------------
Eval num_timesteps=410500, episode_reward=0.52 +/- 0.50
Episode length: 26.50 +/- 16.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.515    |
| time/              |          |
|    total_timesteps | 410500   |
---------------------------------
Eval num_timesteps=411000, episode_reward=0.58 +/- 0.47
Episode length: 29.08 +/- 16.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.585    |
| time/              |          |
|    total_timesteps | 411000   |
---------------------------------
Eval num_timesteps=411500, episode_reward=0.62 +/- 0.46
Episode length: 26.14 +/- 16.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.1     |
|    mean_reward     | 0.617    |
| time/              |          |
|    total_timesteps | 411500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.2     |
|    ep_rew_mean     | 0.517    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 201      |
|    time_elapsed    | 4238     |
|    total_timesteps | 411648   |
---------------------------------
Eval num_timesteps=412000, episode_reward=0.62 +/- 0.47
Episode length: 25.24 +/- 16.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.2        |
|    mean_reward          | 0.62        |
| time/                   |             |
|    total_timesteps      | 412000      |
| train/                  |             |
|    approx_kl            | 0.019005332 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.251      |
|    explained_variance   | 0.511       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000431    |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.0198     |
|    value_loss           | 0.0405      |
-----------------------------------------
Eval num_timesteps=412500, episode_reward=0.40 +/- 0.52
Episode length: 30.82 +/- 19.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.8     |
|    mean_reward     | 0.398    |
| time/              |          |
|    total_timesteps | 412500   |
---------------------------------
Eval num_timesteps=413000, episode_reward=0.57 +/- 0.47
Episode length: 28.02 +/- 15.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28       |
|    mean_reward     | 0.569    |
| time/              |          |
|    total_timesteps | 413000   |
---------------------------------
Eval num_timesteps=413500, episode_reward=0.59 +/- 0.47
Episode length: 28.38 +/- 17.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.4     |
|    mean_reward     | 0.588    |
| time/              |          |
|    total_timesteps | 413500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.6     |
|    ep_rew_mean     | 0.475    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 202      |
|    time_elapsed    | 4257     |
|    total_timesteps | 413696   |
---------------------------------
Eval num_timesteps=414000, episode_reward=0.48 +/- 0.49
Episode length: 30.80 +/- 17.13
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.8        |
|    mean_reward          | 0.478       |
| time/                   |             |
|    total_timesteps      | 414000      |
| train/                  |             |
|    approx_kl            | 0.016102122 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.262      |
|    explained_variance   | 0.479       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0258     |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.018      |
|    value_loss           | 0.0483      |
-----------------------------------------
Eval num_timesteps=414500, episode_reward=0.56 +/- 0.49
Episode length: 29.92 +/- 15.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.9     |
|    mean_reward     | 0.561    |
| time/              |          |
|    total_timesteps | 414500   |
---------------------------------
Eval num_timesteps=415000, episode_reward=0.62 +/- 0.45
Episode length: 24.82 +/- 12.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.8     |
|    mean_reward     | 0.622    |
| time/              |          |
|    total_timesteps | 415000   |
---------------------------------
Eval num_timesteps=415500, episode_reward=0.49 +/- 0.50
Episode length: 27.90 +/- 18.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.9     |
|    mean_reward     | 0.489    |
| time/              |          |
|    total_timesteps | 415500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.7     |
|    ep_rew_mean     | 0.467    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 203      |
|    time_elapsed    | 4275     |
|    total_timesteps | 415744   |
---------------------------------
Eval num_timesteps=416000, episode_reward=0.70 +/- 0.39
Episode length: 24.98 +/- 13.57
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 25         |
|    mean_reward          | 0.702      |
| time/                   |            |
|    total_timesteps      | 416000     |
| train/                  |            |
|    approx_kl            | 0.01632227 |
|    clip_fraction        | 0.104      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.25      |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00891    |
|    n_updates            | 2030       |
|    policy_gradient_loss | -0.0189    |
|    value_loss           | 0.042      |
----------------------------------------
Eval num_timesteps=416500, episode_reward=0.55 +/- 0.48
Episode length: 28.64 +/- 15.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.6     |
|    mean_reward     | 0.547    |
| time/              |          |
|    total_timesteps | 416500   |
---------------------------------
Eval num_timesteps=417000, episode_reward=0.59 +/- 0.48
Episode length: 28.92 +/- 15.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.9     |
|    mean_reward     | 0.586    |
| time/              |          |
|    total_timesteps | 417000   |
---------------------------------
Eval num_timesteps=417500, episode_reward=0.56 +/- 0.47
Episode length: 30.06 +/- 15.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.561    |
| time/              |          |
|    total_timesteps | 417500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.4     |
|    ep_rew_mean     | 0.511    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 204      |
|    time_elapsed    | 4293     |
|    total_timesteps | 417792   |
---------------------------------
Eval num_timesteps=418000, episode_reward=0.53 +/- 0.51
Episode length: 28.74 +/- 19.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.7       |
|    mean_reward          | 0.526      |
| time/                   |            |
|    total_timesteps      | 418000     |
| train/                  |            |
|    approx_kl            | 0.02131856 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.232     |
|    explained_variance   | 0.478      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0077    |
|    n_updates            | 2040       |
|    policy_gradient_loss | -0.019     |
|    value_loss           | 0.0441     |
----------------------------------------
Eval num_timesteps=418500, episode_reward=0.61 +/- 0.45
Episode length: 23.46 +/- 12.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.5     |
|    mean_reward     | 0.608    |
| time/              |          |
|    total_timesteps | 418500   |
---------------------------------
Eval num_timesteps=419000, episode_reward=0.65 +/- 0.43
Episode length: 27.14 +/- 14.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.1     |
|    mean_reward     | 0.653    |
| time/              |          |
|    total_timesteps | 419000   |
---------------------------------
Eval num_timesteps=419500, episode_reward=0.63 +/- 0.45
Episode length: 27.64 +/- 16.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.6     |
|    mean_reward     | 0.631    |
| time/              |          |
|    total_timesteps | 419500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.9     |
|    ep_rew_mean     | 0.543    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 205      |
|    time_elapsed    | 4312     |
|    total_timesteps | 419840   |
---------------------------------
Eval num_timesteps=420000, episode_reward=0.55 +/- 0.48
Episode length: 26.84 +/- 14.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.8        |
|    mean_reward          | 0.554       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.024907518 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.236      |
|    explained_variance   | 0.473       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0151     |
|    n_updates            | 2050        |
|    policy_gradient_loss | -0.0213     |
|    value_loss           | 0.0435      |
-----------------------------------------
Eval num_timesteps=420500, episode_reward=0.56 +/- 0.49
Episode length: 25.76 +/- 16.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.8     |
|    mean_reward     | 0.558    |
| time/              |          |
|    total_timesteps | 420500   |
---------------------------------
Eval num_timesteps=421000, episode_reward=0.63 +/- 0.45
Episode length: 23.58 +/- 13.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.6     |
|    mean_reward     | 0.627    |
| time/              |          |
|    total_timesteps | 421000   |
---------------------------------
Eval num_timesteps=421500, episode_reward=0.65 +/- 0.45
Episode length: 27.76 +/- 15.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.65     |
| time/              |          |
|    total_timesteps | 421500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | 0.527    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 206      |
|    time_elapsed    | 4328     |
|    total_timesteps | 421888   |
---------------------------------
Eval num_timesteps=422000, episode_reward=0.56 +/- 0.47
Episode length: 25.74 +/- 14.33
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.7        |
|    mean_reward          | 0.558       |
| time/                   |             |
|    total_timesteps      | 422000      |
| train/                  |             |
|    approx_kl            | 0.017391957 |
|    clip_fraction        | 0.0982      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.224      |
|    explained_variance   | 0.495       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0107      |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.0467      |
-----------------------------------------
Eval num_timesteps=422500, episode_reward=0.69 +/- 0.42
Episode length: 27.26 +/- 16.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.3     |
|    mean_reward     | 0.692    |
| time/              |          |
|    total_timesteps | 422500   |
---------------------------------
Eval num_timesteps=423000, episode_reward=0.54 +/- 0.49
Episode length: 24.12 +/- 11.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.1     |
|    mean_reward     | 0.545    |
| time/              |          |
|    total_timesteps | 423000   |
---------------------------------
Eval num_timesteps=423500, episode_reward=0.62 +/- 0.45
Episode length: 29.12 +/- 15.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.625    |
| time/              |          |
|    total_timesteps | 423500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.5     |
|    ep_rew_mean     | 0.535    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 207      |
|    time_elapsed    | 4348     |
|    total_timesteps | 423936   |
---------------------------------
Eval num_timesteps=424000, episode_reward=0.51 +/- 0.50
Episode length: 26.76 +/- 12.46
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.8        |
|    mean_reward          | 0.514       |
| time/                   |             |
|    total_timesteps      | 424000      |
| train/                  |             |
|    approx_kl            | 0.020395674 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.24       |
|    explained_variance   | 0.448       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0112     |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.0185     |
|    value_loss           | 0.0453      |
-----------------------------------------
Eval num_timesteps=424500, episode_reward=0.60 +/- 0.46
Episode length: 25.56 +/- 12.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.6     |
|    mean_reward     | 0.599    |
| time/              |          |
|    total_timesteps | 424500   |
---------------------------------
Eval num_timesteps=425000, episode_reward=0.62 +/- 0.45
Episode length: 30.26 +/- 16.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.62     |
| time/              |          |
|    total_timesteps | 425000   |
---------------------------------
Eval num_timesteps=425500, episode_reward=0.55 +/- 0.49
Episode length: 28.72 +/- 16.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.7     |
|    mean_reward     | 0.546    |
| time/              |          |
|    total_timesteps | 425500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.5     |
|    ep_rew_mean     | 0.491    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 208      |
|    time_elapsed    | 4367     |
|    total_timesteps | 425984   |
---------------------------------
Eval num_timesteps=426000, episode_reward=0.65 +/- 0.43
Episode length: 26.88 +/- 14.91
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.9        |
|    mean_reward          | 0.654       |
| time/                   |             |
|    total_timesteps      | 426000      |
| train/                  |             |
|    approx_kl            | 0.018991686 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.263      |
|    explained_variance   | 0.549       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0162      |
|    n_updates            | 2080        |
|    policy_gradient_loss | -0.0182     |
|    value_loss           | 0.0448      |
-----------------------------------------
Eval num_timesteps=426500, episode_reward=0.61 +/- 0.47
Episode length: 33.28 +/- 16.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 33.3     |
|    mean_reward     | 0.608    |
| time/              |          |
|    total_timesteps | 426500   |
---------------------------------
Eval num_timesteps=427000, episode_reward=0.57 +/- 0.48
Episode length: 26.96 +/- 17.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.573    |
| time/              |          |
|    total_timesteps | 427000   |
---------------------------------
Eval num_timesteps=427500, episode_reward=0.59 +/- 0.47
Episode length: 23.90 +/- 12.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.9     |
|    mean_reward     | 0.586    |
| time/              |          |
|    total_timesteps | 427500   |
---------------------------------
Eval num_timesteps=428000, episode_reward=0.50 +/- 0.51
Episode length: 26.56 +/- 15.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.6     |
|    mean_reward     | 0.495    |
| time/              |          |
|    total_timesteps | 428000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.6     |
|    ep_rew_mean     | 0.609    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 209      |
|    time_elapsed    | 4389     |
|    total_timesteps | 428032   |
---------------------------------
Eval num_timesteps=428500, episode_reward=0.67 +/- 0.42
Episode length: 32.90 +/- 19.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.9        |
|    mean_reward          | 0.67        |
| time/                   |             |
|    total_timesteps      | 428500      |
| train/                  |             |
|    approx_kl            | 0.017683618 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.218      |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0313     |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.0178     |
|    value_loss           | 0.0358      |
-----------------------------------------
Eval num_timesteps=429000, episode_reward=0.60 +/- 0.46
Episode length: 29.14 +/- 17.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.1     |
|    mean_reward     | 0.605    |
| time/              |          |
|    total_timesteps | 429000   |
---------------------------------
Eval num_timesteps=429500, episode_reward=0.60 +/- 0.46
Episode length: 25.36 +/- 13.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.4     |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 429500   |
---------------------------------
Eval num_timesteps=430000, episode_reward=0.54 +/- 0.50
Episode length: 29.72 +/- 16.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.7     |
|    mean_reward     | 0.543    |
| time/              |          |
|    total_timesteps | 430000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.5     |
|    ep_rew_mean     | 0.549    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 210      |
|    time_elapsed    | 4410     |
|    total_timesteps | 430080   |
---------------------------------
Eval num_timesteps=430500, episode_reward=0.65 +/- 0.46
Episode length: 28.66 +/- 17.43
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.7       |
|    mean_reward          | 0.647      |
| time/                   |            |
|    total_timesteps      | 430500     |
| train/                  |            |
|    approx_kl            | 0.01799502 |
|    clip_fraction        | 0.104      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.261     |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0154     |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.0141    |
|    value_loss           | 0.0375     |
----------------------------------------
Eval num_timesteps=431000, episode_reward=0.56 +/- 0.50
Episode length: 30.24 +/- 19.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.56     |
| time/              |          |
|    total_timesteps | 431000   |
---------------------------------
Eval num_timesteps=431500, episode_reward=0.62 +/- 0.47
Episode length: 30.60 +/- 18.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.6     |
|    mean_reward     | 0.619    |
| time/              |          |
|    total_timesteps | 431500   |
---------------------------------
Eval num_timesteps=432000, episode_reward=0.51 +/- 0.53
Episode length: 31.62 +/- 19.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.6     |
|    mean_reward     | 0.515    |
| time/              |          |
|    total_timesteps | 432000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28       |
|    ep_rew_mean     | 0.509    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 211      |
|    time_elapsed    | 4428     |
|    total_timesteps | 432128   |
---------------------------------
Eval num_timesteps=432500, episode_reward=0.71 +/- 0.39
Episode length: 27.24 +/- 12.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.2        |
|    mean_reward          | 0.712       |
| time/                   |             |
|    total_timesteps      | 432500      |
| train/                  |             |
|    approx_kl            | 0.030154902 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.266      |
|    explained_variance   | 0.615       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00376    |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0224     |
|    value_loss           | 0.0398      |
-----------------------------------------
Eval num_timesteps=433000, episode_reward=0.46 +/- 0.51
Episode length: 31.38 +/- 18.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.455    |
| time/              |          |
|    total_timesteps | 433000   |
---------------------------------
Eval num_timesteps=433500, episode_reward=0.54 +/- 0.48
Episode length: 29.36 +/- 16.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.4     |
|    mean_reward     | 0.544    |
| time/              |          |
|    total_timesteps | 433500   |
---------------------------------
Eval num_timesteps=434000, episode_reward=0.56 +/- 0.46
Episode length: 30.02 +/- 16.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30       |
|    mean_reward     | 0.561    |
| time/              |          |
|    total_timesteps | 434000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.3     |
|    ep_rew_mean     | 0.524    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 212      |
|    time_elapsed    | 4447     |
|    total_timesteps | 434176   |
---------------------------------
Eval num_timesteps=434500, episode_reward=0.61 +/- 0.47
Episode length: 28.08 +/- 16.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.1        |
|    mean_reward          | 0.609       |
| time/                   |             |
|    total_timesteps      | 434500      |
| train/                  |             |
|    approx_kl            | 0.017446455 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.222      |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00213    |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.0189     |
|    value_loss           | 0.0401      |
-----------------------------------------
Eval num_timesteps=435000, episode_reward=0.62 +/- 0.47
Episode length: 25.14 +/- 15.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.1     |
|    mean_reward     | 0.621    |
| time/              |          |
|    total_timesteps | 435000   |
---------------------------------
Eval num_timesteps=435500, episode_reward=0.53 +/- 0.50
Episode length: 28.16 +/- 16.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.528    |
| time/              |          |
|    total_timesteps | 435500   |
---------------------------------
Eval num_timesteps=436000, episode_reward=0.62 +/- 0.46
Episode length: 30.86 +/- 16.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.9     |
|    mean_reward     | 0.618    |
| time/              |          |
|    total_timesteps | 436000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.2     |
|    ep_rew_mean     | 0.498    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 213      |
|    time_elapsed    | 4467     |
|    total_timesteps | 436224   |
---------------------------------
Eval num_timesteps=436500, episode_reward=0.63 +/- 0.44
Episode length: 28.84 +/- 15.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.8        |
|    mean_reward          | 0.626       |
| time/                   |             |
|    total_timesteps      | 436500      |
| train/                  |             |
|    approx_kl            | 0.020185882 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.207      |
|    explained_variance   | 0.564       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.017      |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0226     |
|    value_loss           | 0.0406      |
-----------------------------------------
Eval num_timesteps=437000, episode_reward=0.51 +/- 0.51
Episode length: 32.16 +/- 16.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 32.2     |
|    mean_reward     | 0.513    |
| time/              |          |
|    total_timesteps | 437000   |
---------------------------------
Eval num_timesteps=437500, episode_reward=0.50 +/- 0.51
Episode length: 35.78 +/- 17.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 35.8     |
|    mean_reward     | 0.498    |
| time/              |          |
|    total_timesteps | 437500   |
---------------------------------
Eval num_timesteps=438000, episode_reward=0.56 +/- 0.50
Episode length: 35.32 +/- 20.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 35.3     |
|    mean_reward     | 0.56     |
| time/              |          |
|    total_timesteps | 438000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.1     |
|    ep_rew_mean     | 0.469    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 214      |
|    time_elapsed    | 4486     |
|    total_timesteps | 438272   |
---------------------------------
Eval num_timesteps=438500, episode_reward=0.55 +/- 0.48
Episode length: 27.14 +/- 15.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.1        |
|    mean_reward          | 0.553       |
| time/                   |             |
|    total_timesteps      | 438500      |
| train/                  |             |
|    approx_kl            | 0.018752981 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.24       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0351     |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.0189     |
|    value_loss           | 0.0412      |
-----------------------------------------
Eval num_timesteps=439000, episode_reward=0.57 +/- 0.48
Episode length: 27.76 +/- 15.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.57     |
| time/              |          |
|    total_timesteps | 439000   |
---------------------------------
Eval num_timesteps=439500, episode_reward=0.64 +/- 0.44
Episode length: 24.22 +/- 12.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.2     |
|    mean_reward     | 0.644    |
| time/              |          |
|    total_timesteps | 439500   |
---------------------------------
Eval num_timesteps=440000, episode_reward=0.61 +/- 0.46
Episode length: 27.36 +/- 16.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.4     |
|    mean_reward     | 0.612    |
| time/              |          |
|    total_timesteps | 440000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.2     |
|    ep_rew_mean     | 0.548    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 215      |
|    time_elapsed    | 4505     |
|    total_timesteps | 440320   |
---------------------------------
Eval num_timesteps=440500, episode_reward=0.63 +/- 0.45
Episode length: 28.32 +/- 16.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.3        |
|    mean_reward          | 0.628       |
| time/                   |             |
|    total_timesteps      | 440500      |
| train/                  |             |
|    approx_kl            | 0.017130155 |
|    clip_fraction        | 0.0998      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.213      |
|    explained_variance   | 0.431       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0238     |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.0191     |
|    value_loss           | 0.0485      |
-----------------------------------------
Eval num_timesteps=441000, episode_reward=0.46 +/- 0.51
Episode length: 26.38 +/- 16.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.4     |
|    mean_reward     | 0.456    |
| time/              |          |
|    total_timesteps | 441000   |
---------------------------------
Eval num_timesteps=441500, episode_reward=0.44 +/- 0.50
Episode length: 29.16 +/- 15.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.2     |
|    mean_reward     | 0.445    |
| time/              |          |
|    total_timesteps | 441500   |
---------------------------------
Eval num_timesteps=442000, episode_reward=0.62 +/- 0.44
Episode length: 31.14 +/- 15.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.1     |
|    mean_reward     | 0.617    |
| time/              |          |
|    total_timesteps | 442000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 0.608    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 216      |
|    time_elapsed    | 4524     |
|    total_timesteps | 442368   |
---------------------------------
Eval num_timesteps=442500, episode_reward=0.68 +/- 0.44
Episode length: 25.06 +/- 16.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.1        |
|    mean_reward          | 0.681       |
| time/                   |             |
|    total_timesteps      | 442500      |
| train/                  |             |
|    approx_kl            | 0.016467286 |
|    clip_fraction        | 0.0965      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.215      |
|    explained_variance   | 0.338       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00413    |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.0182     |
|    value_loss           | 0.0428      |
-----------------------------------------
Eval num_timesteps=443000, episode_reward=0.72 +/- 0.37
Episode length: 30.76 +/- 16.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.8     |
|    mean_reward     | 0.718    |
| time/              |          |
|    total_timesteps | 443000   |
---------------------------------
Eval num_timesteps=443500, episode_reward=0.61 +/- 0.47
Episode length: 26.70 +/- 17.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.7     |
|    mean_reward     | 0.614    |
| time/              |          |
|    total_timesteps | 443500   |
---------------------------------
Eval num_timesteps=444000, episode_reward=0.62 +/- 0.45
Episode length: 25.72 +/- 15.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.7     |
|    mean_reward     | 0.619    |
| time/              |          |
|    total_timesteps | 444000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.6     |
|    ep_rew_mean     | 0.601    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 217      |
|    time_elapsed    | 4542     |
|    total_timesteps | 444416   |
---------------------------------
Eval num_timesteps=444500, episode_reward=0.59 +/- 0.47
Episode length: 26.62 +/- 15.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.6        |
|    mean_reward          | 0.595       |
| time/                   |             |
|    total_timesteps      | 444500      |
| train/                  |             |
|    approx_kl            | 0.021226186 |
|    clip_fraction        | 0.0998      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.205      |
|    explained_variance   | 0.514       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0125      |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0188     |
|    value_loss           | 0.0387      |
-----------------------------------------
Eval num_timesteps=445000, episode_reward=0.55 +/- 0.49
Episode length: 31.80 +/- 20.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.8     |
|    mean_reward     | 0.554    |
| time/              |          |
|    total_timesteps | 445000   |
---------------------------------
Eval num_timesteps=445500, episode_reward=0.58 +/- 0.49
Episode length: 31.12 +/- 20.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.1     |
|    mean_reward     | 0.577    |
| time/              |          |
|    total_timesteps | 445500   |
---------------------------------
Eval num_timesteps=446000, episode_reward=0.58 +/- 0.46
Episode length: 30.10 +/- 15.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.581    |
| time/              |          |
|    total_timesteps | 446000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28       |
|    ep_rew_mean     | 0.559    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 218      |
|    time_elapsed    | 4560     |
|    total_timesteps | 446464   |
---------------------------------
Eval num_timesteps=446500, episode_reward=0.57 +/- 0.47
Episode length: 26.60 +/- 15.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.6        |
|    mean_reward          | 0.575       |
| time/                   |             |
|    total_timesteps      | 446500      |
| train/                  |             |
|    approx_kl            | 0.018211517 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.228      |
|    explained_variance   | 0.503       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0217     |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.0199     |
|    value_loss           | 0.0411      |
-----------------------------------------
Eval num_timesteps=447000, episode_reward=0.66 +/- 0.43
Episode length: 26.50 +/- 15.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.655    |
| time/              |          |
|    total_timesteps | 447000   |
---------------------------------
Eval num_timesteps=447500, episode_reward=0.63 +/- 0.48
Episode length: 27.82 +/- 19.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.8     |
|    mean_reward     | 0.63     |
| time/              |          |
|    total_timesteps | 447500   |
---------------------------------
Eval num_timesteps=448000, episode_reward=0.52 +/- 0.50
Episode length: 29.60 +/- 16.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.6     |
|    mean_reward     | 0.523    |
| time/              |          |
|    total_timesteps | 448000   |
---------------------------------
Eval num_timesteps=448500, episode_reward=0.68 +/- 0.42
Episode length: 30.42 +/- 16.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.4     |
|    mean_reward     | 0.68     |
| time/              |          |
|    total_timesteps | 448500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.2     |
|    ep_rew_mean     | 0.572    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 219      |
|    time_elapsed    | 4582     |
|    total_timesteps | 448512   |
---------------------------------
Eval num_timesteps=449000, episode_reward=0.57 +/- 0.48
Episode length: 28.08 +/- 17.16
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.1        |
|    mean_reward          | 0.569       |
| time/                   |             |
|    total_timesteps      | 449000      |
| train/                  |             |
|    approx_kl            | 0.020822702 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.243      |
|    explained_variance   | 0.466       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0329      |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.0235     |
|    value_loss           | 0.0429      |
-----------------------------------------
Eval num_timesteps=449500, episode_reward=0.67 +/- 0.40
Episode length: 26.96 +/- 14.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27       |
|    mean_reward     | 0.673    |
| time/              |          |
|    total_timesteps | 449500   |
---------------------------------
Eval num_timesteps=450000, episode_reward=0.61 +/- 0.46
Episode length: 27.86 +/- 16.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.9     |
|    mean_reward     | 0.61     |
| time/              |          |
|    total_timesteps | 450000   |
---------------------------------
Eval num_timesteps=450500, episode_reward=0.56 +/- 0.49
Episode length: 26.10 +/- 15.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.1     |
|    mean_reward     | 0.557    |
| time/              |          |
|    total_timesteps | 450500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.4     |
|    ep_rew_mean     | 0.636    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 220      |
|    time_elapsed    | 4601     |
|    total_timesteps | 450560   |
---------------------------------
Eval num_timesteps=451000, episode_reward=0.57 +/- 0.48
Episode length: 31.92 +/- 17.87
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.9        |
|    mean_reward          | 0.574       |
| time/                   |             |
|    total_timesteps      | 451000      |
| train/                  |             |
|    approx_kl            | 0.026035016 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.196      |
|    explained_variance   | 0.463       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0295     |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.0175     |
|    value_loss           | 0.0391      |
-----------------------------------------
Eval num_timesteps=451500, episode_reward=0.48 +/- 0.51
Episode length: 29.54 +/- 18.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.483    |
| time/              |          |
|    total_timesteps | 451500   |
---------------------------------
Eval num_timesteps=452000, episode_reward=0.62 +/- 0.45
Episode length: 29.54 +/- 14.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.623    |
| time/              |          |
|    total_timesteps | 452000   |
---------------------------------
Eval num_timesteps=452500, episode_reward=0.65 +/- 0.43
Episode length: 27.54 +/- 16.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.651    |
| time/              |          |
|    total_timesteps | 452500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.4     |
|    ep_rew_mean     | 0.592    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 221      |
|    time_elapsed    | 4621     |
|    total_timesteps | 452608   |
---------------------------------
Eval num_timesteps=453000, episode_reward=0.57 +/- 0.49
Episode length: 27.78 +/- 17.79
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27.8       |
|    mean_reward          | 0.57       |
| time/                   |            |
|    total_timesteps      | 453000     |
| train/                  |            |
|    approx_kl            | 0.01708297 |
|    clip_fraction        | 0.0968     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.209     |
|    explained_variance   | 0.351      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00188    |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.0196    |
|    value_loss           | 0.0426     |
----------------------------------------
Eval num_timesteps=453500, episode_reward=0.56 +/- 0.46
Episode length: 29.48 +/- 14.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.563    |
| time/              |          |
|    total_timesteps | 453500   |
---------------------------------
Eval num_timesteps=454000, episode_reward=0.56 +/- 0.47
Episode length: 31.16 +/- 16.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.557    |
| time/              |          |
|    total_timesteps | 454000   |
---------------------------------
Eval num_timesteps=454500, episode_reward=0.44 +/- 0.52
Episode length: 34.64 +/- 18.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.6     |
|    mean_reward     | 0.443    |
| time/              |          |
|    total_timesteps | 454500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.531    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 222      |
|    time_elapsed    | 4641     |
|    total_timesteps | 454656   |
---------------------------------
Eval num_timesteps=455000, episode_reward=0.64 +/- 0.44
Episode length: 30.50 +/- 16.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30.5       |
|    mean_reward          | 0.64       |
| time/                   |            |
|    total_timesteps      | 455000     |
| train/                  |            |
|    approx_kl            | 0.03623621 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.245     |
|    explained_variance   | 0.519      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0128     |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0194    |
|    value_loss           | 0.0327     |
----------------------------------------
Eval num_timesteps=455500, episode_reward=0.53 +/- 0.49
Episode length: 27.08 +/- 17.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.1     |
|    mean_reward     | 0.533    |
| time/              |          |
|    total_timesteps | 455500   |
---------------------------------
Eval num_timesteps=456000, episode_reward=0.56 +/- 0.50
Episode length: 31.44 +/- 19.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.4     |
|    mean_reward     | 0.556    |
| time/              |          |
|    total_timesteps | 456000   |
---------------------------------
Eval num_timesteps=456500, episode_reward=0.59 +/- 0.45
Episode length: 31.72 +/- 16.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.7     |
|    mean_reward     | 0.594    |
| time/              |          |
|    total_timesteps | 456500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 0.387    |
| time/              |          |
|    fps             | 97       |
|    iterations      | 223      |
|    time_elapsed    | 4661     |
|    total_timesteps | 456704   |
---------------------------------
Eval num_timesteps=457000, episode_reward=0.57 +/- 0.48
Episode length: 27.58 +/- 17.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.6        |
|    mean_reward          | 0.571       |
| time/                   |             |
|    total_timesteps      | 457000      |
| train/                  |             |
|    approx_kl            | 0.022499112 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.389      |
|    explained_variance   | 0.517       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00541    |
|    n_updates            | 2230        |
|    policy_gradient_loss | -0.0221     |
|    value_loss           | 0.0496      |
-----------------------------------------
Eval num_timesteps=457500, episode_reward=0.54 +/- 0.48
Episode length: 30.24 +/- 17.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.2     |
|    mean_reward     | 0.54     |
| time/              |          |
|    total_timesteps | 457500   |
---------------------------------
Eval num_timesteps=458000, episode_reward=0.64 +/- 0.46
Episode length: 29.70 +/- 16.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.7     |
|    mean_reward     | 0.642    |
| time/              |          |
|    total_timesteps | 458000   |
---------------------------------
Eval num_timesteps=458500, episode_reward=0.60 +/- 0.48
Episode length: 26.50 +/- 16.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.595    |
| time/              |          |
|    total_timesteps | 458500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.6     |
|    ep_rew_mean     | 0.375    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 224      |
|    time_elapsed    | 4680     |
|    total_timesteps | 458752   |
---------------------------------
Eval num_timesteps=459000, episode_reward=0.67 +/- 0.42
Episode length: 23.84 +/- 12.81
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 23.8        |
|    mean_reward          | 0.666       |
| time/                   |             |
|    total_timesteps      | 459000      |
| train/                  |             |
|    approx_kl            | 0.024247201 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.369      |
|    explained_variance   | 0.555       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00562     |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.0211     |
|    value_loss           | 0.0494      |
-----------------------------------------
Eval num_timesteps=459500, episode_reward=0.67 +/- 0.43
Episode length: 22.90 +/- 12.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 22.9     |
|    mean_reward     | 0.67     |
| time/              |          |
|    total_timesteps | 459500   |
---------------------------------
Eval num_timesteps=460000, episode_reward=0.55 +/- 0.48
Episode length: 29.02 +/- 14.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29       |
|    mean_reward     | 0.545    |
| time/              |          |
|    total_timesteps | 460000   |
---------------------------------
Eval num_timesteps=460500, episode_reward=0.63 +/- 0.45
Episode length: 21.64 +/- 11.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 21.6     |
|    mean_reward     | 0.635    |
| time/              |          |
|    total_timesteps | 460500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.1     |
|    ep_rew_mean     | 0.515    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 225      |
|    time_elapsed    | 4697     |
|    total_timesteps | 460800   |
---------------------------------
Eval num_timesteps=461000, episode_reward=0.67 +/- 0.43
Episode length: 27.98 +/- 15.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28         |
|    mean_reward          | 0.67       |
| time/                   |            |
|    total_timesteps      | 461000     |
| train/                  |            |
|    approx_kl            | 0.02851716 |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.266     |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00135   |
|    n_updates            | 2250       |
|    policy_gradient_loss | -0.0208    |
|    value_loss           | 0.0496     |
----------------------------------------
Eval num_timesteps=461500, episode_reward=0.45 +/- 0.50
Episode length: 27.52 +/- 16.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.451    |
| time/              |          |
|    total_timesteps | 461500   |
---------------------------------
Eval num_timesteps=462000, episode_reward=0.59 +/- 0.49
Episode length: 29.02 +/- 18.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29       |
|    mean_reward     | 0.585    |
| time/              |          |
|    total_timesteps | 462000   |
---------------------------------
Eval num_timesteps=462500, episode_reward=0.62 +/- 0.44
Episode length: 30.66 +/- 16.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.7     |
|    mean_reward     | 0.619    |
| time/              |          |
|    total_timesteps | 462500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.5     |
|    ep_rew_mean     | 0.585    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 226      |
|    time_elapsed    | 4716     |
|    total_timesteps | 462848   |
---------------------------------
Eval num_timesteps=463000, episode_reward=0.56 +/- 0.49
Episode length: 24.32 +/- 16.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24.3        |
|    mean_reward          | 0.564       |
| time/                   |             |
|    total_timesteps      | 463000      |
| train/                  |             |
|    approx_kl            | 0.019507522 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.243      |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0155     |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.0204     |
|    value_loss           | 0.0416      |
-----------------------------------------
Eval num_timesteps=463500, episode_reward=0.61 +/- 0.44
Episode length: 27.22 +/- 14.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.2     |
|    mean_reward     | 0.612    |
| time/              |          |
|    total_timesteps | 463500   |
---------------------------------
Eval num_timesteps=464000, episode_reward=0.54 +/- 0.49
Episode length: 31.14 +/- 17.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.1     |
|    mean_reward     | 0.537    |
| time/              |          |
|    total_timesteps | 464000   |
---------------------------------
Eval num_timesteps=464500, episode_reward=0.51 +/- 0.49
Episode length: 27.62 +/- 15.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.6     |
|    mean_reward     | 0.511    |
| time/              |          |
|    total_timesteps | 464500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.4     |
|    ep_rew_mean     | 0.536    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 227      |
|    time_elapsed    | 4734     |
|    total_timesteps | 464896   |
---------------------------------
Eval num_timesteps=465000, episode_reward=0.63 +/- 0.44
Episode length: 27.02 +/- 15.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27          |
|    mean_reward          | 0.633       |
| time/                   |             |
|    total_timesteps      | 465000      |
| train/                  |             |
|    approx_kl            | 0.023270136 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.262      |
|    explained_variance   | 0.473       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0263      |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.02       |
|    value_loss           | 0.0465      |
-----------------------------------------
Eval num_timesteps=465500, episode_reward=0.44 +/- 0.49
Episode length: 25.80 +/- 14.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.8     |
|    mean_reward     | 0.438    |
| time/              |          |
|    total_timesteps | 465500   |
---------------------------------
Eval num_timesteps=466000, episode_reward=0.56 +/- 0.47
Episode length: 30.90 +/- 16.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.9     |
|    mean_reward     | 0.558    |
| time/              |          |
|    total_timesteps | 466000   |
---------------------------------
Eval num_timesteps=466500, episode_reward=0.57 +/- 0.45
Episode length: 27.52 +/- 15.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.571    |
| time/              |          |
|    total_timesteps | 466500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 0.547    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 228      |
|    time_elapsed    | 4752     |
|    total_timesteps | 466944   |
---------------------------------
Eval num_timesteps=467000, episode_reward=0.63 +/- 0.45
Episode length: 27.42 +/- 15.34
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27.4       |
|    mean_reward          | 0.632      |
| time/                   |            |
|    total_timesteps      | 467000     |
| train/                  |            |
|    approx_kl            | 0.02107817 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.217     |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0255    |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.0168    |
|    value_loss           | 0.044      |
----------------------------------------
Eval num_timesteps=467500, episode_reward=0.58 +/- 0.48
Episode length: 31.04 +/- 18.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31       |
|    mean_reward     | 0.577    |
| time/              |          |
|    total_timesteps | 467500   |
---------------------------------
Eval num_timesteps=468000, episode_reward=0.73 +/- 0.37
Episode length: 28.16 +/- 16.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.729    |
| time/              |          |
|    total_timesteps | 468000   |
---------------------------------
Eval num_timesteps=468500, episode_reward=0.62 +/- 0.44
Episode length: 29.54 +/- 16.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.5     |
|    mean_reward     | 0.623    |
| time/              |          |
|    total_timesteps | 468500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.4     |
|    ep_rew_mean     | 0.552    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 229      |
|    time_elapsed    | 4770     |
|    total_timesteps | 468992   |
---------------------------------
Eval num_timesteps=469000, episode_reward=0.64 +/- 0.45
Episode length: 29.74 +/- 16.89
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 29.7       |
|    mean_reward          | 0.642      |
| time/                   |            |
|    total_timesteps      | 469000     |
| train/                  |            |
|    approx_kl            | 0.01622495 |
|    clip_fraction        | 0.098      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.231     |
|    explained_variance   | 0.583      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0211    |
|    n_updates            | 2290       |
|    policy_gradient_loss | -0.0186    |
|    value_loss           | 0.0375     |
----------------------------------------
Eval num_timesteps=469500, episode_reward=0.67 +/- 0.44
Episode length: 27.74 +/- 18.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.67     |
| time/              |          |
|    total_timesteps | 469500   |
---------------------------------
Eval num_timesteps=470000, episode_reward=0.68 +/- 0.42
Episode length: 24.90 +/- 14.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.9     |
|    mean_reward     | 0.682    |
| time/              |          |
|    total_timesteps | 470000   |
---------------------------------
Eval num_timesteps=470500, episode_reward=0.60 +/- 0.46
Episode length: 26.38 +/- 14.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.4     |
|    mean_reward     | 0.596    |
| time/              |          |
|    total_timesteps | 470500   |
---------------------------------
Eval num_timesteps=471000, episode_reward=0.59 +/- 0.47
Episode length: 31.86 +/- 19.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.9     |
|    mean_reward     | 0.594    |
| time/              |          |
|    total_timesteps | 471000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.3     |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    fps             | 98       |
|    iterations      | 230      |
|    time_elapsed    | 4791     |
|    total_timesteps | 471040   |
---------------------------------
Eval num_timesteps=471500, episode_reward=0.70 +/- 0.41
Episode length: 26.24 +/- 16.25
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.2        |
|    mean_reward          | 0.696       |
| time/                   |             |
|    total_timesteps      | 471500      |
| train/                  |             |
|    approx_kl            | 0.017945286 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.274      |
|    explained_variance   | 0.469       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0315     |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.0182     |
|    value_loss           | 0.0443      |
-----------------------------------------
Eval num_timesteps=472000, episode_reward=0.55 +/- 0.47
Episode length: 28.24 +/- 16.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.548    |
| time/              |          |
|    total_timesteps | 472000   |
---------------------------------
Eval num_timesteps=472500, episode_reward=0.59 +/- 0.47
Episode length: 28.50 +/- 17.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.5     |
|    mean_reward     | 0.587    |
| time/              |          |
|    total_timesteps | 472500   |
---------------------------------
Eval num_timesteps=473000, episode_reward=0.57 +/- 0.47
Episode length: 28.96 +/- 17.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29       |
|    mean_reward     | 0.565    |
| time/              |          |
|    total_timesteps | 473000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.4     |
|    ep_rew_mean     | 0.632    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 231      |
|    time_elapsed    | 4810     |
|    total_timesteps | 473088   |
---------------------------------
Eval num_timesteps=473500, episode_reward=0.59 +/- 0.47
Episode length: 28.20 +/- 16.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.2       |
|    mean_reward          | 0.589      |
| time/                   |            |
|    total_timesteps      | 473500     |
| train/                  |            |
|    approx_kl            | 0.01714534 |
|    clip_fraction        | 0.0994     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.187     |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0129    |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0182    |
|    value_loss           | 0.0233     |
----------------------------------------
Eval num_timesteps=474000, episode_reward=0.67 +/- 0.43
Episode length: 28.32 +/- 15.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.3     |
|    mean_reward     | 0.668    |
| time/              |          |
|    total_timesteps | 474000   |
---------------------------------
Eval num_timesteps=474500, episode_reward=0.70 +/- 0.42
Episode length: 26.52 +/- 16.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.5     |
|    mean_reward     | 0.695    |
| time/              |          |
|    total_timesteps | 474500   |
---------------------------------
Eval num_timesteps=475000, episode_reward=0.64 +/- 0.45
Episode length: 26.08 +/- 16.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.1     |
|    mean_reward     | 0.637    |
| time/              |          |
|    total_timesteps | 475000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 0.567    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 232      |
|    time_elapsed    | 4828     |
|    total_timesteps | 475136   |
---------------------------------
Eval num_timesteps=475500, episode_reward=0.72 +/- 0.38
Episode length: 30.22 +/- 17.28
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.2        |
|    mean_reward          | 0.72        |
| time/                   |             |
|    total_timesteps      | 475500      |
| train/                  |             |
|    approx_kl            | 0.027188182 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.231      |
|    explained_variance   | 0.532       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000125    |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.0191     |
|    value_loss           | 0.0374      |
-----------------------------------------
Eval num_timesteps=476000, episode_reward=0.66 +/- 0.43
Episode length: 24.26 +/- 13.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.3     |
|    mean_reward     | 0.664    |
| time/              |          |
|    total_timesteps | 476000   |
---------------------------------
Eval num_timesteps=476500, episode_reward=0.65 +/- 0.43
Episode length: 23.16 +/- 12.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.2     |
|    mean_reward     | 0.649    |
| time/              |          |
|    total_timesteps | 476500   |
---------------------------------
Eval num_timesteps=477000, episode_reward=0.71 +/- 0.42
Episode length: 27.70 +/- 17.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.711    |
| time/              |          |
|    total_timesteps | 477000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.8     |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    fps             | 98       |
|    iterations      | 233      |
|    time_elapsed    | 4844     |
|    total_timesteps | 477184   |
---------------------------------
Eval num_timesteps=477500, episode_reward=0.61 +/- 0.46
Episode length: 26.68 +/- 16.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.7        |
|    mean_reward          | 0.614       |
| time/                   |             |
|    total_timesteps      | 477500      |
| train/                  |             |
|    approx_kl            | 0.025349667 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.202      |
|    explained_variance   | 0.536       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00587     |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.0193     |
|    value_loss           | 0.0377      |
-----------------------------------------
Eval num_timesteps=478000, episode_reward=0.70 +/- 0.38
Episode length: 30.52 +/- 16.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.5     |
|    mean_reward     | 0.699    |
| time/              |          |
|    total_timesteps | 478000   |
---------------------------------
Eval num_timesteps=478500, episode_reward=0.55 +/- 0.50
Episode length: 31.62 +/- 20.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.6     |
|    mean_reward     | 0.555    |
| time/              |          |
|    total_timesteps | 478500   |
---------------------------------
Eval num_timesteps=479000, episode_reward=0.58 +/- 0.47
Episode length: 29.38 +/- 16.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.4     |
|    mean_reward     | 0.584    |
| time/              |          |
|    total_timesteps | 479000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28       |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    fps             | 98       |
|    iterations      | 234      |
|    time_elapsed    | 4864     |
|    total_timesteps | 479232   |
---------------------------------
Eval num_timesteps=479500, episode_reward=0.56 +/- 0.50
Episode length: 26.26 +/- 15.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.3        |
|    mean_reward          | 0.556       |
| time/                   |             |
|    total_timesteps      | 479500      |
| train/                  |             |
|    approx_kl            | 0.017642116 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.193      |
|    explained_variance   | 0.52        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0023      |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.0188     |
|    value_loss           | 0.039       |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=0.67 +/- 0.43
Episode length: 27.30 +/- 14.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.3     |
|    mean_reward     | 0.672    |
| time/              |          |
|    total_timesteps | 480000   |
---------------------------------
Eval num_timesteps=480500, episode_reward=0.60 +/- 0.45
Episode length: 29.58 +/- 15.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.6     |
|    mean_reward     | 0.603    |
| time/              |          |
|    total_timesteps | 480500   |
---------------------------------
Eval num_timesteps=481000, episode_reward=0.69 +/- 0.40
Episode length: 33.98 +/- 17.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34       |
|    mean_reward     | 0.686    |
| time/              |          |
|    total_timesteps | 481000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.8     |
|    ep_rew_mean     | 0.634    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 235      |
|    time_elapsed    | 4884     |
|    total_timesteps | 481280   |
---------------------------------
Eval num_timesteps=481500, episode_reward=0.59 +/- 0.48
Episode length: 27.76 +/- 17.44
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.8        |
|    mean_reward          | 0.59        |
| time/                   |             |
|    total_timesteps      | 481500      |
| train/                  |             |
|    approx_kl            | 0.017722923 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.206      |
|    explained_variance   | 0.509       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0033      |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.0175     |
|    value_loss           | 0.0387      |
-----------------------------------------
Eval num_timesteps=482000, episode_reward=0.59 +/- 0.48
Episode length: 28.26 +/- 17.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.3     |
|    mean_reward     | 0.588    |
| time/              |          |
|    total_timesteps | 482000   |
---------------------------------
Eval num_timesteps=482500, episode_reward=0.66 +/- 0.43
Episode length: 30.98 +/- 16.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31       |
|    mean_reward     | 0.657    |
| time/              |          |
|    total_timesteps | 482500   |
---------------------------------
Eval num_timesteps=483000, episode_reward=0.61 +/- 0.46
Episode length: 21.84 +/- 12.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 21.8     |
|    mean_reward     | 0.614    |
| time/              |          |
|    total_timesteps | 483000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28       |
|    ep_rew_mean     | 0.539    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 236      |
|    time_elapsed    | 4903     |
|    total_timesteps | 483328   |
---------------------------------
Eval num_timesteps=483500, episode_reward=0.58 +/- 0.49
Episode length: 30.88 +/- 18.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.9        |
|    mean_reward          | 0.578       |
| time/                   |             |
|    total_timesteps      | 483500      |
| train/                  |             |
|    approx_kl            | 0.017543193 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.204      |
|    explained_variance   | 0.508       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0019     |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.0168     |
|    value_loss           | 0.0393      |
-----------------------------------------
Eval num_timesteps=484000, episode_reward=0.48 +/- 0.50
Episode length: 30.68 +/- 17.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.7     |
|    mean_reward     | 0.479    |
| time/              |          |
|    total_timesteps | 484000   |
---------------------------------
Eval num_timesteps=484500, episode_reward=0.59 +/- 0.44
Episode length: 27.34 +/- 14.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.3     |
|    mean_reward     | 0.592    |
| time/              |          |
|    total_timesteps | 484500   |
---------------------------------
Eval num_timesteps=485000, episode_reward=0.63 +/- 0.46
Episode length: 28.46 +/- 16.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.5     |
|    mean_reward     | 0.628    |
| time/              |          |
|    total_timesteps | 485000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.2     |
|    ep_rew_mean     | 0.475    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 237      |
|    time_elapsed    | 4923     |
|    total_timesteps | 485376   |
---------------------------------
Eval num_timesteps=485500, episode_reward=0.63 +/- 0.46
Episode length: 27.40 +/- 14.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.4        |
|    mean_reward          | 0.632       |
| time/                   |             |
|    total_timesteps      | 485500      |
| train/                  |             |
|    approx_kl            | 0.021369372 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.236      |
|    explained_variance   | 0.511       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00439     |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.0188     |
|    value_loss           | 0.0431      |
-----------------------------------------
Eval num_timesteps=486000, episode_reward=0.61 +/- 0.46
Episode length: 23.80 +/- 14.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 23.8     |
|    mean_reward     | 0.606    |
| time/              |          |
|    total_timesteps | 486000   |
---------------------------------
Eval num_timesteps=486500, episode_reward=0.58 +/- 0.46
Episode length: 24.48 +/- 13.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 24.5     |
|    mean_reward     | 0.583    |
| time/              |          |
|    total_timesteps | 486500   |
---------------------------------
Eval num_timesteps=487000, episode_reward=0.62 +/- 0.46
Episode length: 31.16 +/- 16.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.617    |
| time/              |          |
|    total_timesteps | 487000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | 0.508    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 238      |
|    time_elapsed    | 4940     |
|    total_timesteps | 487424   |
---------------------------------
Eval num_timesteps=487500, episode_reward=0.60 +/- 0.46
Episode length: 29.18 +/- 17.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.2        |
|    mean_reward          | 0.604       |
| time/                   |             |
|    total_timesteps      | 487500      |
| train/                  |             |
|    approx_kl            | 0.018553585 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.222      |
|    explained_variance   | 0.519       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0027      |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.0169     |
|    value_loss           | 0.0413      |
-----------------------------------------
Eval num_timesteps=488000, episode_reward=0.60 +/- 0.46
Episode length: 29.88 +/- 14.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.9     |
|    mean_reward     | 0.602    |
| time/              |          |
|    total_timesteps | 488000   |
---------------------------------
Eval num_timesteps=488500, episode_reward=0.64 +/- 0.44
Episode length: 29.76 +/- 15.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.8     |
|    mean_reward     | 0.642    |
| time/              |          |
|    total_timesteps | 488500   |
---------------------------------
Eval num_timesteps=489000, episode_reward=0.52 +/- 0.49
Episode length: 29.36 +/- 18.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 29.4     |
|    mean_reward     | 0.524    |
| time/              |          |
|    total_timesteps | 489000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.9     |
|    ep_rew_mean     | 0.569    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 239      |
|    time_elapsed    | 4958     |
|    total_timesteps | 489472   |
---------------------------------
Eval num_timesteps=489500, episode_reward=0.61 +/- 0.45
Episode length: 28.58 +/- 15.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.6        |
|    mean_reward          | 0.607       |
| time/                   |             |
|    total_timesteps      | 489500      |
| train/                  |             |
|    approx_kl            | 0.013212852 |
|    clip_fraction        | 0.091       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.204      |
|    explained_variance   | 0.409       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00498     |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.045       |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=0.54 +/- 0.50
Episode length: 34.14 +/- 19.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 34.1     |
|    mean_reward     | 0.545    |
| time/              |          |
|    total_timesteps | 490000   |
---------------------------------
Eval num_timesteps=490500, episode_reward=0.68 +/- 0.43
Episode length: 31.08 +/- 17.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.1     |
|    mean_reward     | 0.677    |
| time/              |          |
|    total_timesteps | 490500   |
---------------------------------
Eval num_timesteps=491000, episode_reward=0.61 +/- 0.47
Episode length: 27.52 +/- 18.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.5     |
|    mean_reward     | 0.611    |
| time/              |          |
|    total_timesteps | 491000   |
---------------------------------
Eval num_timesteps=491500, episode_reward=0.64 +/- 0.45
Episode length: 30.28 +/- 19.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.64     |
| time/              |          |
|    total_timesteps | 491500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.4     |
|    ep_rew_mean     | 0.564    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 240      |
|    time_elapsed    | 4981     |
|    total_timesteps | 491520   |
---------------------------------
Eval num_timesteps=492000, episode_reward=0.56 +/- 0.50
Episode length: 30.98 +/- 19.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31          |
|    mean_reward          | 0.557       |
| time/                   |             |
|    total_timesteps      | 492000      |
| train/                  |             |
|    approx_kl            | 0.023979742 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.186      |
|    explained_variance   | 0.415       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0146      |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.0392      |
-----------------------------------------
Eval num_timesteps=492500, episode_reward=0.62 +/- 0.47
Episode length: 30.06 +/- 19.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.1     |
|    mean_reward     | 0.621    |
| time/              |          |
|    total_timesteps | 492500   |
---------------------------------
Eval num_timesteps=493000, episode_reward=0.71 +/- 0.40
Episode length: 28.08 +/- 16.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.1     |
|    mean_reward     | 0.709    |
| time/              |          |
|    total_timesteps | 493000   |
---------------------------------
Eval num_timesteps=493500, episode_reward=0.62 +/- 0.48
Episode length: 31.16 +/- 20.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.617    |
| time/              |          |
|    total_timesteps | 493500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29       |
|    ep_rew_mean     | 0.555    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 241      |
|    time_elapsed    | 5000     |
|    total_timesteps | 493568   |
---------------------------------
Eval num_timesteps=494000, episode_reward=0.70 +/- 0.41
Episode length: 30.06 +/- 16.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.701       |
| time/                   |             |
|    total_timesteps      | 494000      |
| train/                  |             |
|    approx_kl            | 0.025345014 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.2        |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0174     |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.0183     |
|    value_loss           | 0.0367      |
-----------------------------------------
Eval num_timesteps=494500, episode_reward=0.73 +/- 0.39
Episode length: 27.72 +/- 18.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.73     |
| time/              |          |
|    total_timesteps | 494500   |
---------------------------------
Eval num_timesteps=495000, episode_reward=0.57 +/- 0.48
Episode length: 31.72 +/- 17.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.7     |
|    mean_reward     | 0.574    |
| time/              |          |
|    total_timesteps | 495000   |
---------------------------------
Eval num_timesteps=495500, episode_reward=0.64 +/- 0.46
Episode length: 31.16 +/- 18.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 31.2     |
|    mean_reward     | 0.637    |
| time/              |          |
|    total_timesteps | 495500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.1     |
|    ep_rew_mean     | 0.619    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 242      |
|    time_elapsed    | 5020     |
|    total_timesteps | 495616   |
---------------------------------
Eval num_timesteps=496000, episode_reward=0.63 +/- 0.45
Episode length: 28.94 +/- 15.44
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 28.9      |
|    mean_reward          | 0.626     |
| time/                   |           |
|    total_timesteps      | 496000    |
| train/                  |           |
|    approx_kl            | 0.0252668 |
|    clip_fraction        | 0.113     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.195    |
|    explained_variance   | 0.492     |
|    learning_rate        | 0.0001    |
|    loss                 | -0.0236   |
|    n_updates            | 2420      |
|    policy_gradient_loss | -0.0202   |
|    value_loss           | 0.0442    |
---------------------------------------
Eval num_timesteps=496500, episode_reward=0.62 +/- 0.48
Episode length: 25.48 +/- 16.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 25.5     |
|    mean_reward     | 0.619    |
| time/              |          |
|    total_timesteps | 496500   |
---------------------------------
Eval num_timesteps=497000, episode_reward=0.57 +/- 0.48
Episode length: 26.74 +/- 15.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.7     |
|    mean_reward     | 0.574    |
| time/              |          |
|    total_timesteps | 497000   |
---------------------------------
Eval num_timesteps=497500, episode_reward=0.63 +/- 0.45
Episode length: 27.22 +/- 16.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.2     |
|    mean_reward     | 0.633    |
| time/              |          |
|    total_timesteps | 497500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 0.587    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 243      |
|    time_elapsed    | 5039     |
|    total_timesteps | 497664   |
---------------------------------
Eval num_timesteps=498000, episode_reward=0.54 +/- 0.49
Episode length: 35.24 +/- 20.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 35.2        |
|    mean_reward          | 0.54        |
| time/                   |             |
|    total_timesteps      | 498000      |
| train/                  |             |
|    approx_kl            | 0.021833355 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.212      |
|    explained_variance   | 0.595       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0295     |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0239     |
|    value_loss           | 0.0339      |
-----------------------------------------
Eval num_timesteps=498500, episode_reward=0.52 +/- 0.51
Episode length: 30.34 +/- 19.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30.3     |
|    mean_reward     | 0.52     |
| time/              |          |
|    total_timesteps | 498500   |
---------------------------------
Eval num_timesteps=499000, episode_reward=0.71 +/- 0.39
Episode length: 27.72 +/- 16.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 27.7     |
|    mean_reward     | 0.711    |
| time/              |          |
|    total_timesteps | 499000   |
---------------------------------
Eval num_timesteps=499500, episode_reward=0.46 +/- 0.52
Episode length: 29.98 +/- 17.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 30       |
|    mean_reward     | 0.461    |
| time/              |          |
|    total_timesteps | 499500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    fps             | 98       |
|    iterations      | 244      |
|    time_elapsed    | 5058     |
|    total_timesteps | 499712   |
---------------------------------
Eval num_timesteps=500000, episode_reward=0.53 +/- 0.50
Episode length: 26.80 +/- 16.50
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26.8       |
|    mean_reward          | 0.534      |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.03449996 |
|    clip_fraction        | 0.115      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.216     |
|    explained_variance   | 0.488      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0226    |
|    n_updates            | 2440       |
|    policy_gradient_loss | -0.0187    |
|    value_loss           | 0.0337     |
----------------------------------------
Eval num_timesteps=500500, episode_reward=0.65 +/- 0.45
Episode length: 28.50 +/- 14.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.5     |
|    mean_reward     | 0.647    |
| time/              |          |
|    total_timesteps | 500500   |
---------------------------------
Eval num_timesteps=501000, episode_reward=0.51 +/- 0.48
Episode length: 26.88 +/- 13.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 26.9     |
|    mean_reward     | 0.514    |
| time/              |          |
|    total_timesteps | 501000   |
---------------------------------
Eval num_timesteps=501500, episode_reward=0.59 +/- 0.45
Episode length: 28.18 +/- 15.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 28.2     |
|    mean_reward     | 0.589    |
| time/              |          |
|    total_timesteps | 501500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 0.583    |
| time/              |          |
|    fps             | 98       |
|    iterations      | 245      |
|    time_elapsed    | 5075     |
|    total_timesteps | 501760   |
---------------------------------
/home/miguelvilla/anaconda3/envs/doom/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'trains/predict-position/ppo-6/saves' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
