2024-09-02 00:31:24.810316: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-02 00:31:30.373209: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-02 00:31:42.390169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/mnt/c/Proyecto/.venv/lib/python3.10/site-packages/vizdoom/gymnasium_wrapper/base_gymnasium_env.py:84: UserWarning: Detected screen format CRCGCB. Only RGB24 and GRAY8 are supported in the Gymnasium wrapper. Forcing RGB24.
  warnings.warn(
Using cuda device
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.189    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 4        |
|    fps              | 267      |
|    time_elapsed     | 0        |
|    total_timesteps  | 62       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0561   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 8        |
|    fps              | 321      |
|    time_elapsed     | 0        |
|    total_timesteps  | 140      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0121   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 12       |
|    fps              | 343      |
|    time_elapsed     | 0        |
|    total_timesteps  | 217      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 16       |
|    fps              | 347      |
|    time_elapsed     | 0        |
|    total_timesteps  | 301      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 20       |
|    fps              | 355      |
|    time_elapsed     | 1        |
|    total_timesteps  | 376      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0326  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 24       |
|    fps              | 363      |
|    time_elapsed     | 1        |
|    total_timesteps  | 452      |
----------------------------------
Eval num_timesteps=500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 500      |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00143 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 28       |
|    fps              | 31       |
|    time_elapsed     | 16       |
|    total_timesteps  | 517      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 32       |
|    fps              | 35       |
|    time_elapsed     | 16       |
|    total_timesteps  | 600      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0189  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 36       |
|    fps              | 39       |
|    time_elapsed     | 17       |
|    total_timesteps  | 679      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00207  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 40       |
|    fps              | 42       |
|    time_elapsed     | 17       |
|    total_timesteps  | 739      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00375 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 44       |
|    fps              | 45       |
|    time_elapsed     | 17       |
|    total_timesteps  | 802      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00952 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 48       |
|    fps              | 49       |
|    time_elapsed     | 17       |
|    total_timesteps  | 876      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00506  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 52       |
|    fps              | 52       |
|    time_elapsed     | 17       |
|    total_timesteps  | 947      |
----------------------------------
Eval num_timesteps=1000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 1000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 56       |
|    fps              | 30       |
|    time_elapsed     | 33       |
|    total_timesteps  | 1013     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0118   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 60       |
|    fps              | 32       |
|    time_elapsed     | 33       |
|    total_timesteps  | 1087     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00666  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 64       |
|    fps              | 34       |
|    time_elapsed     | 33       |
|    total_timesteps  | 1159     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00244  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 68       |
|    fps              | 36       |
|    time_elapsed     | 33       |
|    total_timesteps  | 1225     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0122   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 72       |
|    fps              | 38       |
|    time_elapsed     | 33       |
|    total_timesteps  | 1299     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 76       |
|    fps              | 40       |
|    time_elapsed     | 34       |
|    total_timesteps  | 1367     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0167   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 80       |
|    fps              | 41       |
|    time_elapsed     | 34       |
|    total_timesteps  | 1435     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 84       |
|    fps              | 43       |
|    time_elapsed     | 34       |
|    total_timesteps  | 1499     |
----------------------------------
Eval num_timesteps=1500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 1500     |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00908  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 88       |
|    fps              | 31       |
|    time_elapsed     | 50       |
|    total_timesteps  | 1572     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00577  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 92       |
|    fps              | 32       |
|    time_elapsed     | 50       |
|    total_timesteps  | 1640     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00282  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 96       |
|    fps              | 33       |
|    time_elapsed     | 50       |
|    total_timesteps  | 1706     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 100      |
|    fps              | 35       |
|    time_elapsed     | 50       |
|    total_timesteps  | 1770     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00013 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 104      |
|    fps              | 36       |
|    time_elapsed     | 50       |
|    total_timesteps  | 1840     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00027  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 108      |
|    fps              | 37       |
|    time_elapsed     | 50       |
|    total_timesteps  | 1908     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00027  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 112      |
|    fps              | 38       |
|    time_elapsed     | 51       |
|    total_timesteps  | 1985     |
----------------------------------
Eval num_timesteps=2000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 2000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00051  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 116      |
|    fps              | 31       |
|    time_elapsed     | 66       |
|    total_timesteps  | 2063     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00071  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 120      |
|    fps              | 32       |
|    time_elapsed     | 66       |
|    total_timesteps  | 2133     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00083  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 124      |
|    fps              | 33       |
|    time_elapsed     | 66       |
|    total_timesteps  | 2206     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00924 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 128      |
|    fps              | 34       |
|    time_elapsed     | 66       |
|    total_timesteps  | 2273     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0084  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 132      |
|    fps              | 34       |
|    time_elapsed     | 67       |
|    total_timesteps  | 2335     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00188  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 136      |
|    fps              | 35       |
|    time_elapsed     | 67       |
|    total_timesteps  | 2407     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00851 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 140      |
|    fps              | 36       |
|    time_elapsed     | 67       |
|    total_timesteps  | 2477     |
----------------------------------
Eval num_timesteps=2500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 2500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00116  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 144      |
|    fps              | 30       |
|    time_elapsed     | 84       |
|    total_timesteps  | 2548     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0116   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 148      |
|    fps              | 30       |
|    time_elapsed     | 84       |
|    total_timesteps  | 2610     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.012    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 152      |
|    fps              | 31       |
|    time_elapsed     | 84       |
|    total_timesteps  | 2671     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0016   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 156      |
|    fps              | 32       |
|    time_elapsed     | 84       |
|    total_timesteps  | 2748     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0014   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 160      |
|    fps              | 33       |
|    time_elapsed     | 84       |
|    total_timesteps  | 2827     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00152  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 164      |
|    fps              | 34       |
|    time_elapsed     | 85       |
|    total_timesteps  | 2896     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0012   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 168      |
|    fps              | 34       |
|    time_elapsed     | 85       |
|    total_timesteps  | 2970     |
----------------------------------
Eval num_timesteps=3000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 3000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00874 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 172      |
|    fps              | 30       |
|    time_elapsed     | 100      |
|    total_timesteps  | 3042     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0187  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 176      |
|    fps              | 30       |
|    time_elapsed     | 101      |
|    total_timesteps  | 3110     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.019   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 180      |
|    fps              | 31       |
|    time_elapsed     | 101      |
|    total_timesteps  | 3185     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0089  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 184      |
|    fps              | 32       |
|    time_elapsed     | 101      |
|    total_timesteps  | 3246     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0085  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 188      |
|    fps              | 32       |
|    time_elapsed     | 101      |
|    total_timesteps  | 3309     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00866 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 192      |
|    fps              | 33       |
|    time_elapsed     | 101      |
|    total_timesteps  | 3381     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0087  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 196      |
|    fps              | 33       |
|    time_elapsed     | 101      |
|    total_timesteps  | 3448     |
----------------------------------
Eval num_timesteps=3500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 3500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0189  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 200      |
|    fps              | 29       |
|    time_elapsed     | 117      |
|    total_timesteps  | 3517     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.019   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 204      |
|    fps              | 30       |
|    time_elapsed     | 117      |
|    total_timesteps  | 3589     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0194  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 208      |
|    fps              | 31       |
|    time_elapsed     | 117      |
|    total_timesteps  | 3668     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00897 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 212      |
|    fps              | 31       |
|    time_elapsed     | 117      |
|    total_timesteps  | 3734     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 216      |
|    fps              | 32       |
|    time_elapsed     | 118      |
|    total_timesteps  | 3796     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 220      |
|    fps              | 32       |
|    time_elapsed     | 118      |
|    total_timesteps  | 3872     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 224      |
|    fps              | 33       |
|    time_elapsed     | 118      |
|    total_timesteps  | 3943     |
----------------------------------
Eval num_timesteps=4000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 4000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0212   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 228      |
|    fps              | 30       |
|    time_elapsed     | 133      |
|    total_timesteps  | 4018     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 232      |
|    fps              | 30       |
|    time_elapsed     | 133      |
|    total_timesteps  | 4101     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0204   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 236      |
|    fps              | 31       |
|    time_elapsed     | 134      |
|    total_timesteps  | 4173     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0302   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 240      |
|    fps              | 31       |
|    time_elapsed     | 134      |
|    total_timesteps  | 4246     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 244      |
|    fps              | 32       |
|    time_elapsed     | 134      |
|    total_timesteps  | 4311     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 248      |
|    fps              | 32       |
|    time_elapsed     | 134      |
|    total_timesteps  | 4383     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00062 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 252      |
|    fps              | 33       |
|    time_elapsed     | 134      |
|    total_timesteps  | 4462     |
----------------------------------
Eval num_timesteps=4500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 4500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0005  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 256      |
|    fps              | 30       |
|    time_elapsed     | 150      |
|    total_timesteps  | 4536     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00014 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 260      |
|    fps              | 30       |
|    time_elapsed     | 150      |
|    total_timesteps  | 4606     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0003  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 264      |
|    fps              | 31       |
|    time_elapsed     | 150      |
|    total_timesteps  | 4679     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 268      |
|    fps              | 31       |
|    time_elapsed     | 150      |
|    total_timesteps  | 4742     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0203   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 272      |
|    fps              | 31       |
|    time_elapsed     | 150      |
|    total_timesteps  | 4811     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 276      |
|    fps              | 32       |
|    time_elapsed     | 151      |
|    total_timesteps  | 4883     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0199   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 280      |
|    fps              | 32       |
|    time_elapsed     | 151      |
|    total_timesteps  | 4963     |
----------------------------------
Eval num_timesteps=5000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 5000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00963  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 284      |
|    fps              | 30       |
|    time_elapsed     | 166      |
|    total_timesteps  | 5032     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00931  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 288      |
|    fps              | 30       |
|    time_elapsed     | 166      |
|    total_timesteps  | 5103     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00903  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 292      |
|    fps              | 30       |
|    time_elapsed     | 167      |
|    total_timesteps  | 5182     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00867  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 296      |
|    fps              | 31       |
|    time_elapsed     | 167      |
|    total_timesteps  | 5258     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 300      |
|    fps              | 31       |
|    time_elapsed     | 167      |
|    total_timesteps  | 5335     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 304      |
|    fps              | 32       |
|    time_elapsed     | 167      |
|    total_timesteps  | 5409     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0289   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 308      |
|    fps              | 32       |
|    time_elapsed     | 167      |
|    total_timesteps  | 5473     |
----------------------------------
Eval num_timesteps=5500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 5500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 312      |
|    fps              | 30       |
|    time_elapsed     | 183      |
|    total_timesteps  | 5545     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00146 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 316      |
|    fps              | 30       |
|    time_elapsed     | 183      |
|    total_timesteps  | 5609     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00202 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 320      |
|    fps              | 31       |
|    time_elapsed     | 183      |
|    total_timesteps  | 5699     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00771  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 324      |
|    fps              | 31       |
|    time_elapsed     | 183      |
|    total_timesteps  | 5777     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00253 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 328      |
|    fps              | 31       |
|    time_elapsed     | 184      |
|    total_timesteps  | 5858     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 332      |
|    fps              | 32       |
|    time_elapsed     | 184      |
|    total_timesteps  | 5931     |
----------------------------------
Eval num_timesteps=6000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 6000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 336      |
|    fps              | 30       |
|    time_elapsed     | 199      |
|    total_timesteps  | 6001     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 340      |
|    fps              | 30       |
|    time_elapsed     | 199      |
|    total_timesteps  | 6063     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 344      |
|    fps              | 30       |
|    time_elapsed     | 199      |
|    total_timesteps  | 6128     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 348      |
|    fps              | 31       |
|    time_elapsed     | 200      |
|    total_timesteps  | 6201     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00188 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 352      |
|    fps              | 31       |
|    time_elapsed     | 200      |
|    total_timesteps  | 6287     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00208 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 356      |
|    fps              | 31       |
|    time_elapsed     | 200      |
|    total_timesteps  | 6366     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00834  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 360      |
|    fps              | 32       |
|    time_elapsed     | 200      |
|    total_timesteps  | 6426     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00866  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 364      |
|    fps              | 32       |
|    time_elapsed     | 200      |
|    total_timesteps  | 6491     |
----------------------------------
Eval num_timesteps=6500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 6500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00192 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 368      |
|    fps              | 30       |
|    time_elapsed     | 216      |
|    total_timesteps  | 6568     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00223 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 372      |
|    fps              | 30       |
|    time_elapsed     | 216      |
|    total_timesteps  | 6644     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00215 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 376      |
|    fps              | 31       |
|    time_elapsed     | 216      |
|    total_timesteps  | 6714     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00243 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 380      |
|    fps              | 31       |
|    time_elapsed     | 216      |
|    total_timesteps  | 6801     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 384      |
|    fps              | 31       |
|    time_elapsed     | 216      |
|    total_timesteps  | 6865     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 388      |
|    fps              | 31       |
|    time_elapsed     | 217      |
|    total_timesteps  | 6940     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 392      |
|    fps              | 32       |
|    time_elapsed     | 217      |
|    total_timesteps  | 6995     |
----------------------------------
Eval num_timesteps=7000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 7000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0488   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 396      |
|    fps              | 30       |
|    time_elapsed     | 232      |
|    total_timesteps  | 7067     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 400      |
|    fps              | 30       |
|    time_elapsed     | 232      |
|    total_timesteps  | 7135     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0485   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 404      |
|    fps              | 31       |
|    time_elapsed     | 232      |
|    total_timesteps  | 7224     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 408      |
|    fps              | 31       |
|    time_elapsed     | 233      |
|    total_timesteps  | 7294     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 412      |
|    fps              | 31       |
|    time_elapsed     | 233      |
|    total_timesteps  | 7358     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0481   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 416      |
|    fps              | 31       |
|    time_elapsed     | 233      |
|    total_timesteps  | 7434     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0492   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 420      |
|    fps              | 32       |
|    time_elapsed     | 233      |
|    total_timesteps  | 7497     |
----------------------------------
Eval num_timesteps=7500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 7500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0393   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 424      |
|    fps              | 30       |
|    time_elapsed     | 248      |
|    total_timesteps  | 7572     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0501   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 428      |
|    fps              | 30       |
|    time_elapsed     | 249      |
|    total_timesteps  | 7633     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0604   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 432      |
|    fps              | 30       |
|    time_elapsed     | 249      |
|    total_timesteps  | 7700     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0604   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 436      |
|    fps              | 31       |
|    time_elapsed     | 249      |
|    total_timesteps  | 7768     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0501   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 440      |
|    fps              | 31       |
|    time_elapsed     | 249      |
|    total_timesteps  | 7837     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0499   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 444      |
|    fps              | 31       |
|    time_elapsed     | 249      |
|    total_timesteps  | 7909     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0499   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 448      |
|    fps              | 31       |
|    time_elapsed     | 249      |
|    total_timesteps  | 7982     |
----------------------------------
Eval num_timesteps=8000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 8000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0407   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 452      |
|    fps              | 30       |
|    time_elapsed     | 265      |
|    total_timesteps  | 8047     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0406   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 456      |
|    fps              | 30       |
|    time_elapsed     | 265      |
|    total_timesteps  | 8127     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0403   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 460      |
|    fps              | 30       |
|    time_elapsed     | 265      |
|    total_timesteps  | 8196     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0402   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 464      |
|    fps              | 31       |
|    time_elapsed     | 265      |
|    total_timesteps  | 8263     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0502   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 468      |
|    fps              | 31       |
|    time_elapsed     | 265      |
|    total_timesteps  | 8340     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0401   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 472      |
|    fps              | 31       |
|    time_elapsed     | 266      |
|    total_timesteps  | 8418     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 476      |
|    fps              | 31       |
|    time_elapsed     | 266      |
|    total_timesteps  | 8498     |
----------------------------------
Eval num_timesteps=8500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 8500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0405   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 480      |
|    fps              | 30       |
|    time_elapsed     | 281      |
|    total_timesteps  | 8567     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 484      |
|    fps              | 30       |
|    time_elapsed     | 281      |
|    total_timesteps  | 8631     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0106   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 488      |
|    fps              | 30       |
|    time_elapsed     | 281      |
|    total_timesteps  | 8703     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00996 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 492      |
|    fps              | 31       |
|    time_elapsed     | 282      |
|    total_timesteps  | 8770     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 496      |
|    fps              | 31       |
|    time_elapsed     | 282      |
|    total_timesteps  | 8837     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 500      |
|    fps              | 31       |
|    time_elapsed     | 282      |
|    total_timesteps  | 8908     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0107   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 504      |
|    fps              | 31       |
|    time_elapsed     | 282      |
|    total_timesteps  | 8983     |
----------------------------------
Eval num_timesteps=9000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 9000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00998  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 508      |
|    fps              | 30       |
|    time_elapsed     | 297      |
|    total_timesteps  | 9070     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00987  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 512      |
|    fps              | 30       |
|    time_elapsed     | 298      |
|    total_timesteps  | 9137     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 516      |
|    fps              | 30       |
|    time_elapsed     | 298      |
|    total_timesteps  | 9229     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 520      |
|    fps              | 31       |
|    time_elapsed     | 298      |
|    total_timesteps  | 9305     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 524      |
|    fps              | 31       |
|    time_elapsed     | 298      |
|    total_timesteps  | 9388     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 528      |
|    fps              | 31       |
|    time_elapsed     | 298      |
|    total_timesteps  | 9456     |
----------------------------------
Eval num_timesteps=9500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 9500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00805  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 532      |
|    fps              | 30       |
|    time_elapsed     | 314      |
|    total_timesteps  | 9524     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00801  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 536      |
|    fps              | 30       |
|    time_elapsed     | 314      |
|    total_timesteps  | 9593     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 540      |
|    fps              | 30       |
|    time_elapsed     | 314      |
|    total_timesteps  | 9656     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 544      |
|    fps              | 30       |
|    time_elapsed     | 314      |
|    total_timesteps  | 9729     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 548      |
|    fps              | 31       |
|    time_elapsed     | 315      |
|    total_timesteps  | 9810     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 552      |
|    fps              | 31       |
|    time_elapsed     | 315      |
|    total_timesteps  | 9882     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 556      |
|    fps              | 31       |
|    time_elapsed     | 315      |
|    total_timesteps  | 9961     |
----------------------------------
Eval num_timesteps=10000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 10000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 560      |
|    fps              | 30       |
|    time_elapsed     | 331      |
|    total_timesteps  | 10031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 564      |
|    fps              | 30       |
|    time_elapsed     | 331      |
|    total_timesteps  | 10115    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 568      |
|    fps              | 30       |
|    time_elapsed     | 331      |
|    total_timesteps  | 10179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 572      |
|    fps              | 30       |
|    time_elapsed     | 331      |
|    total_timesteps  | 10260    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 576      |
|    fps              | 31       |
|    time_elapsed     | 332      |
|    total_timesteps  | 10344    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 580      |
|    fps              | 31       |
|    time_elapsed     | 332      |
|    total_timesteps  | 10411    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0368   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 584      |
|    fps              | 31       |
|    time_elapsed     | 332      |
|    total_timesteps  | 10487    |
----------------------------------
Eval num_timesteps=10500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 10500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0469   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 588      |
|    fps              | 30       |
|    time_elapsed     | 347      |
|    total_timesteps  | 10556    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0466   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 592      |
|    fps              | 30       |
|    time_elapsed     | 348      |
|    total_timesteps  | 10631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0263   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 596      |
|    fps              | 30       |
|    time_elapsed     | 348      |
|    total_timesteps  | 10706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0264   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 600      |
|    fps              | 30       |
|    time_elapsed     | 348      |
|    total_timesteps  | 10775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0267   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 604      |
|    fps              | 31       |
|    time_elapsed     | 348      |
|    total_timesteps  | 10843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 608      |
|    fps              | 31       |
|    time_elapsed     | 348      |
|    total_timesteps  | 10911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 612      |
|    fps              | 31       |
|    time_elapsed     | 348      |
|    total_timesteps  | 10985    |
----------------------------------
Eval num_timesteps=11000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 11000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 616      |
|    fps              | 30       |
|    time_elapsed     | 364      |
|    total_timesteps  | 11048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0283   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 620      |
|    fps              | 30       |
|    time_elapsed     | 364      |
|    total_timesteps  | 11125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0388   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 624      |
|    fps              | 30       |
|    time_elapsed     | 364      |
|    total_timesteps  | 11194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0491   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 628      |
|    fps              | 30       |
|    time_elapsed     | 364      |
|    total_timesteps  | 11256    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0492   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 632      |
|    fps              | 31       |
|    time_elapsed     | 364      |
|    total_timesteps  | 11320    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0488   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 636      |
|    fps              | 31       |
|    time_elapsed     | 365      |
|    total_timesteps  | 11401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0387   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 640      |
|    fps              | 31       |
|    time_elapsed     | 365      |
|    total_timesteps  | 11466    |
----------------------------------
Eval num_timesteps=11500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 11500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0286   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 644      |
|    fps              | 30       |
|    time_elapsed     | 381      |
|    total_timesteps  | 11540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0288   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 648      |
|    fps              | 30       |
|    time_elapsed     | 381      |
|    total_timesteps  | 11617    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 652      |
|    fps              | 30       |
|    time_elapsed     | 381      |
|    total_timesteps  | 11693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.049    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 656      |
|    fps              | 30       |
|    time_elapsed     | 381      |
|    total_timesteps  | 11763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0491   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 660      |
|    fps              | 30       |
|    time_elapsed     | 381      |
|    total_timesteps  | 11830    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 664      |
|    fps              | 31       |
|    time_elapsed     | 382      |
|    total_timesteps  | 11891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 668      |
|    fps              | 31       |
|    time_elapsed     | 382      |
|    total_timesteps  | 11968    |
----------------------------------
Eval num_timesteps=12000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 12000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 672      |
|    fps              | 30       |
|    time_elapsed     | 398      |
|    total_timesteps  | 12043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0405   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 676      |
|    fps              | 30       |
|    time_elapsed     | 398      |
|    total_timesteps  | 12109    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 680      |
|    fps              | 30       |
|    time_elapsed     | 399      |
|    total_timesteps  | 12178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 684      |
|    fps              | 30       |
|    time_elapsed     | 399      |
|    total_timesteps  | 12261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00988  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 688      |
|    fps              | 30       |
|    time_elapsed     | 399      |
|    total_timesteps  | 12335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 692      |
|    fps              | 31       |
|    time_elapsed     | 399      |
|    total_timesteps  | 12403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 696      |
|    fps              | 31       |
|    time_elapsed     | 399      |
|    total_timesteps  | 12469    |
----------------------------------
Eval num_timesteps=12500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 12500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0098   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 700      |
|    fps              | 30       |
|    time_elapsed     | 416      |
|    total_timesteps  | 12556    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00016 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 704      |
|    fps              | 30       |
|    time_elapsed     | 416      |
|    total_timesteps  | 12623    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00012 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 708      |
|    fps              | 30       |
|    time_elapsed     | 416      |
|    total_timesteps  | 12690    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00012 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 712      |
|    fps              | 30       |
|    time_elapsed     | 416      |
|    total_timesteps  | 12764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0105  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 716      |
|    fps              | 30       |
|    time_elapsed     | 416      |
|    total_timesteps  | 12837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0203  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 720      |
|    fps              | 30       |
|    time_elapsed     | 417      |
|    total_timesteps  | 12908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 724      |
|    fps              | 31       |
|    time_elapsed     | 417      |
|    total_timesteps  | 12970    |
----------------------------------
Eval num_timesteps=13000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 13000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0404  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 728      |
|    fps              | 30       |
|    time_elapsed     | 432      |
|    total_timesteps  | 13041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0407  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 732      |
|    fps              | 30       |
|    time_elapsed     | 432      |
|    total_timesteps  | 13112    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0405  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 736      |
|    fps              | 30       |
|    time_elapsed     | 433      |
|    total_timesteps  | 13190    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0304  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 740      |
|    fps              | 30       |
|    time_elapsed     | 433      |
|    total_timesteps  | 13251    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0203  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 744      |
|    fps              | 30       |
|    time_elapsed     | 433      |
|    total_timesteps  | 13323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 748      |
|    fps              | 30       |
|    time_elapsed     | 433      |
|    total_timesteps  | 13395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0397  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 752      |
|    fps              | 31       |
|    time_elapsed     | 433      |
|    total_timesteps  | 13460    |
----------------------------------
Eval num_timesteps=13500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 13500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0396  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 756      |
|    fps              | 30       |
|    time_elapsed     | 449      |
|    total_timesteps  | 13529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 760      |
|    fps              | 30       |
|    time_elapsed     | 449      |
|    total_timesteps  | 13601    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0301  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 764      |
|    fps              | 30       |
|    time_elapsed     | 449      |
|    total_timesteps  | 13668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 768      |
|    fps              | 30       |
|    time_elapsed     | 449      |
|    total_timesteps  | 13741    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 772      |
|    fps              | 30       |
|    time_elapsed     | 449      |
|    total_timesteps  | 13823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 776      |
|    fps              | 30       |
|    time_elapsed     | 450      |
|    total_timesteps  | 13895    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 780      |
|    fps              | 31       |
|    time_elapsed     | 450      |
|    total_timesteps  | 13970    |
----------------------------------
Eval num_timesteps=14000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 14000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 784      |
|    fps              | 30       |
|    time_elapsed     | 465      |
|    total_timesteps  | 14044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 788      |
|    fps              | 30       |
|    time_elapsed     | 465      |
|    total_timesteps  | 14112    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 792      |
|    fps              | 30       |
|    time_elapsed     | 466      |
|    total_timesteps  | 14181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00034 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 796      |
|    fps              | 30       |
|    time_elapsed     | 466      |
|    total_timesteps  | 14253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00046  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 800      |
|    fps              | 30       |
|    time_elapsed     | 466      |
|    total_timesteps  | 14320    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00042  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 804      |
|    fps              | 30       |
|    time_elapsed     | 466      |
|    total_timesteps  | 14388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 808      |
|    fps              | 30       |
|    time_elapsed     | 466      |
|    total_timesteps  | 14461    |
----------------------------------
Eval num_timesteps=14500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 14500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 812      |
|    fps              | 30       |
|    time_elapsed     | 482      |
|    total_timesteps  | 14534    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 816      |
|    fps              | 30       |
|    time_elapsed     | 482      |
|    total_timesteps  | 14608    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 820      |
|    fps              | 30       |
|    time_elapsed     | 482      |
|    total_timesteps  | 14681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0001  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 824      |
|    fps              | 30       |
|    time_elapsed     | 482      |
|    total_timesteps  | 14748    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00014 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 828      |
|    fps              | 30       |
|    time_elapsed     | 482      |
|    total_timesteps  | 14820    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.00991  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 832      |
|    fps              | 30       |
|    time_elapsed     | 483      |
|    total_timesteps  | 14890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 836      |
|    fps              | 30       |
|    time_elapsed     | 483      |
|    total_timesteps  | 14953    |
----------------------------------
Eval num_timesteps=15000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 15000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0104   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 840      |
|    fps              | 30       |
|    time_elapsed     | 498      |
|    total_timesteps  | 15017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00067  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 844      |
|    fps              | 30       |
|    time_elapsed     | 498      |
|    total_timesteps  | 15082    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 848      |
|    fps              | 30       |
|    time_elapsed     | 498      |
|    total_timesteps  | 15159    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 852      |
|    fps              | 30       |
|    time_elapsed     | 499      |
|    total_timesteps  | 15225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 856      |
|    fps              | 30       |
|    time_elapsed     | 499      |
|    total_timesteps  | 15301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 860      |
|    fps              | 30       |
|    time_elapsed     | 499      |
|    total_timesteps  | 15365    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 864      |
|    fps              | 30       |
|    time_elapsed     | 499      |
|    total_timesteps  | 15435    |
----------------------------------
Eval num_timesteps=15500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 15500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 868      |
|    fps              | 30       |
|    time_elapsed     | 514      |
|    total_timesteps  | 15503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0207   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 872      |
|    fps              | 30       |
|    time_elapsed     | 515      |
|    total_timesteps  | 15583    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 876      |
|    fps              | 30       |
|    time_elapsed     | 515      |
|    total_timesteps  | 15653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0309   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 880      |
|    fps              | 30       |
|    time_elapsed     | 515      |
|    total_timesteps  | 15726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0309   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 884      |
|    fps              | 30       |
|    time_elapsed     | 515      |
|    total_timesteps  | 15800    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0307   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 888      |
|    fps              | 30       |
|    time_elapsed     | 515      |
|    total_timesteps  | 15873    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 892      |
|    fps              | 30       |
|    time_elapsed     | 516      |
|    total_timesteps  | 15945    |
----------------------------------
Eval num_timesteps=16000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 16000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 896      |
|    fps              | 30       |
|    time_elapsed     | 531      |
|    total_timesteps  | 16024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 900      |
|    fps              | 30       |
|    time_elapsed     | 531      |
|    total_timesteps  | 16096    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0298   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 904      |
|    fps              | 30       |
|    time_elapsed     | 531      |
|    total_timesteps  | 16170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0297   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 908      |
|    fps              | 30       |
|    time_elapsed     | 532      |
|    total_timesteps  | 16245    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0401   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 912      |
|    fps              | 30       |
|    time_elapsed     | 532      |
|    total_timesteps  | 16309    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 916      |
|    fps              | 30       |
|    time_elapsed     | 532      |
|    total_timesteps  | 16390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 920      |
|    fps              | 30       |
|    time_elapsed     | 532      |
|    total_timesteps  | 16463    |
----------------------------------
Eval num_timesteps=16500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 16500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0497   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 924      |
|    fps              | 30       |
|    time_elapsed     | 548      |
|    total_timesteps  | 16533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0501   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 928      |
|    fps              | 30       |
|    time_elapsed     | 548      |
|    total_timesteps  | 16596    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0401   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 932      |
|    fps              | 30       |
|    time_elapsed     | 548      |
|    total_timesteps  | 16664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 936      |
|    fps              | 30       |
|    time_elapsed     | 548      |
|    total_timesteps  | 16745    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0392   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 940      |
|    fps              | 30       |
|    time_elapsed     | 548      |
|    total_timesteps  | 16814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 944      |
|    fps              | 30       |
|    time_elapsed     | 549      |
|    total_timesteps  | 16894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0385   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 948      |
|    fps              | 30       |
|    time_elapsed     | 549      |
|    total_timesteps  | 16974    |
----------------------------------
Eval num_timesteps=17000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 17000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 952      |
|    fps              | 30       |
|    time_elapsed     | 564      |
|    total_timesteps  | 17048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 956      |
|    fps              | 30       |
|    time_elapsed     | 564      |
|    total_timesteps  | 17123    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 960      |
|    fps              | 30       |
|    time_elapsed     | 565      |
|    total_timesteps  | 17187    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00845  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 964      |
|    fps              | 30       |
|    time_elapsed     | 565      |
|    total_timesteps  | 17250    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00821  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 968      |
|    fps              | 30       |
|    time_elapsed     | 565      |
|    total_timesteps  | 17324    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00113 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 972      |
|    fps              | 30       |
|    time_elapsed     | 565      |
|    total_timesteps  | 17387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00149 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 976      |
|    fps              | 30       |
|    time_elapsed     | 565      |
|    total_timesteps  | 17466    |
----------------------------------
Eval num_timesteps=17500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 17500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 980      |
|    fps              | 30       |
|    time_elapsed     | 581      |
|    total_timesteps  | 17541    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 984      |
|    fps              | 30       |
|    time_elapsed     | 581      |
|    total_timesteps  | 17612    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00153 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 988      |
|    fps              | 30       |
|    time_elapsed     | 581      |
|    total_timesteps  | 17687    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00851  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 992      |
|    fps              | 30       |
|    time_elapsed     | 581      |
|    total_timesteps  | 17758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00879  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 996      |
|    fps              | 30       |
|    time_elapsed     | 582      |
|    total_timesteps  | 17830    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00839  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1000     |
|    fps              | 30       |
|    time_elapsed     | 582      |
|    total_timesteps  | 17912    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0014  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1004     |
|    fps              | 30       |
|    time_elapsed     | 582      |
|    total_timesteps  | 17981    |
----------------------------------
Eval num_timesteps=18000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 18000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.011   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1008     |
|    fps              | 30       |
|    time_elapsed     | 598      |
|    total_timesteps  | 18047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1012     |
|    fps              | 30       |
|    time_elapsed     | 598      |
|    total_timesteps  | 18115    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1016     |
|    fps              | 30       |
|    time_elapsed     | 598      |
|    total_timesteps  | 18200    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1020     |
|    fps              | 30       |
|    time_elapsed     | 598      |
|    total_timesteps  | 18268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1024     |
|    fps              | 30       |
|    time_elapsed     | 598      |
|    total_timesteps  | 18341    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1028     |
|    fps              | 30       |
|    time_elapsed     | 598      |
|    total_timesteps  | 18404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0216  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1032     |
|    fps              | 30       |
|    time_elapsed     | 599      |
|    total_timesteps  | 18480    |
----------------------------------
Eval num_timesteps=18500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 18500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1036     |
|    fps              | 30       |
|    time_elapsed     | 614      |
|    total_timesteps  | 18554    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0318  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1040     |
|    fps              | 30       |
|    time_elapsed     | 615      |
|    total_timesteps  | 18633    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0315  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1044     |
|    fps              | 30       |
|    time_elapsed     | 615      |
|    total_timesteps  | 18707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0209  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1048     |
|    fps              | 30       |
|    time_elapsed     | 615      |
|    total_timesteps  | 18772    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1052     |
|    fps              | 30       |
|    time_elapsed     | 615      |
|    total_timesteps  | 18839    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1056     |
|    fps              | 30       |
|    time_elapsed     | 615      |
|    total_timesteps  | 18915    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1060     |
|    fps              | 30       |
|    time_elapsed     | 616      |
|    total_timesteps  | 18989    |
----------------------------------
Eval num_timesteps=19000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 19000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1064     |
|    fps              | 30       |
|    time_elapsed     | 632      |
|    total_timesteps  | 19054    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1068     |
|    fps              | 30       |
|    time_elapsed     | 632      |
|    total_timesteps  | 19134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1072     |
|    fps              | 30       |
|    time_elapsed     | 632      |
|    total_timesteps  | 19199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0111  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1076     |
|    fps              | 30       |
|    time_elapsed     | 632      |
|    total_timesteps  | 19271    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0109  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1080     |
|    fps              | 30       |
|    time_elapsed     | 632      |
|    total_timesteps  | 19340    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00151 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1084     |
|    fps              | 30       |
|    time_elapsed     | 633      |
|    total_timesteps  | 19426    |
----------------------------------
Eval num_timesteps=19500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 19500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1088     |
|    fps              | 30       |
|    time_elapsed     | 649      |
|    total_timesteps  | 19500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1092     |
|    fps              | 30       |
|    time_elapsed     | 649      |
|    total_timesteps  | 19565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1096     |
|    fps              | 30       |
|    time_elapsed     | 649      |
|    total_timesteps  | 19659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00163 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1100     |
|    fps              | 30       |
|    time_elapsed     | 649      |
|    total_timesteps  | 19729    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00191 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1104     |
|    fps              | 30       |
|    time_elapsed     | 650      |
|    total_timesteps  | 19805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00814  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1108     |
|    fps              | 30       |
|    time_elapsed     | 650      |
|    total_timesteps  | 19870    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00774  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1112     |
|    fps              | 30       |
|    time_elapsed     | 650      |
|    total_timesteps  | 19948    |
----------------------------------
Eval num_timesteps=20000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 20000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00207 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1116     |
|    fps              | 30       |
|    time_elapsed     | 666      |
|    total_timesteps  | 20028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00791  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1120     |
|    fps              | 30       |
|    time_elapsed     | 666      |
|    total_timesteps  | 20097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00779  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1124     |
|    fps              | 30       |
|    time_elapsed     | 667      |
|    total_timesteps  | 20173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00727  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1128     |
|    fps              | 30       |
|    time_elapsed     | 667      |
|    total_timesteps  | 20249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1132     |
|    fps              | 30       |
|    time_elapsed     | 667      |
|    total_timesteps  | 20317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1136     |
|    fps              | 30       |
|    time_elapsed     | 667      |
|    total_timesteps  | 20386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1140     |
|    fps              | 30       |
|    time_elapsed     | 667      |
|    total_timesteps  | 20456    |
----------------------------------
Eval num_timesteps=20500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 20500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00837  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1144     |
|    fps              | 30       |
|    time_elapsed     | 683      |
|    total_timesteps  | 20524    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00177 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1148     |
|    fps              | 30       |
|    time_elapsed     | 683      |
|    total_timesteps  | 20592    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00177 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1152     |
|    fps              | 30       |
|    time_elapsed     | 683      |
|    total_timesteps  | 20659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00157 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1156     |
|    fps              | 30       |
|    time_elapsed     | 683      |
|    total_timesteps  | 20730    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00181 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1160     |
|    fps              | 30       |
|    time_elapsed     | 684      |
|    total_timesteps  | 20810    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00221 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1164     |
|    fps              | 30       |
|    time_elapsed     | 684      |
|    total_timesteps  | 20885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00201 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1168     |
|    fps              | 30       |
|    time_elapsed     | 684      |
|    total_timesteps  | 20960    |
----------------------------------
Eval num_timesteps=21000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 21000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00812  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1172     |
|    fps              | 30       |
|    time_elapsed     | 699      |
|    total_timesteps  | 21022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00186 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1176     |
|    fps              | 30       |
|    time_elapsed     | 700      |
|    total_timesteps  | 21093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00198 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1180     |
|    fps              | 30       |
|    time_elapsed     | 700      |
|    total_timesteps  | 21165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1184     |
|    fps              | 30       |
|    time_elapsed     | 700      |
|    total_timesteps  | 21239    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1188     |
|    fps              | 30       |
|    time_elapsed     | 700      |
|    total_timesteps  | 21308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1192     |
|    fps              | 30       |
|    time_elapsed     | 700      |
|    total_timesteps  | 21375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1196     |
|    fps              | 30       |
|    time_elapsed     | 701      |
|    total_timesteps  | 21444    |
----------------------------------
Eval num_timesteps=21500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 21500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1200     |
|    fps              | 30       |
|    time_elapsed     | 716      |
|    total_timesteps  | 21531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0205  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1204     |
|    fps              | 30       |
|    time_elapsed     | 716      |
|    total_timesteps  | 21594    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0309  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1208     |
|    fps              | 30       |
|    time_elapsed     | 717      |
|    total_timesteps  | 21669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.031   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1212     |
|    fps              | 30       |
|    time_elapsed     | 717      |
|    total_timesteps  | 21749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1216     |
|    fps              | 30       |
|    time_elapsed     | 717      |
|    total_timesteps  | 21819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1220     |
|    fps              | 30       |
|    time_elapsed     | 717      |
|    total_timesteps  | 21889    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0305  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1224     |
|    fps              | 30       |
|    time_elapsed     | 717      |
|    total_timesteps  | 21962    |
----------------------------------
Eval num_timesteps=22000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 22000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0301  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1228     |
|    fps              | 30       |
|    time_elapsed     | 733      |
|    total_timesteps  | 22028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0299  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1232     |
|    fps              | 30       |
|    time_elapsed     | 733      |
|    total_timesteps  | 22090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1236     |
|    fps              | 30       |
|    time_elapsed     | 733      |
|    total_timesteps  | 22172    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1240     |
|    fps              | 30       |
|    time_elapsed     | 733      |
|    total_timesteps  | 22236    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0209  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1244     |
|    fps              | 30       |
|    time_elapsed     | 734      |
|    total_timesteps  | 22323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0208  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1248     |
|    fps              | 30       |
|    time_elapsed     | 734      |
|    total_timesteps  | 22388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1252     |
|    fps              | 30       |
|    time_elapsed     | 734      |
|    total_timesteps  | 22464    |
----------------------------------
Eval num_timesteps=22500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 22500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.011   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1256     |
|    fps              | 30       |
|    time_elapsed     | 749      |
|    total_timesteps  | 22531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1260     |
|    fps              | 30       |
|    time_elapsed     | 750      |
|    total_timesteps  | 22602    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0108  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1264     |
|    fps              | 30       |
|    time_elapsed     | 750      |
|    total_timesteps  | 22681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0009  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1268     |
|    fps              | 30       |
|    time_elapsed     | 750      |
|    total_timesteps  | 22758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1272     |
|    fps              | 30       |
|    time_elapsed     | 750      |
|    total_timesteps  | 22850    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1276     |
|    fps              | 30       |
|    time_elapsed     | 750      |
|    total_timesteps  | 22917    |
----------------------------------
Eval num_timesteps=23000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 23000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00337 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1280     |
|    fps              | 30       |
|    time_elapsed     | 766      |
|    total_timesteps  | 23025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00297 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1284     |
|    fps              | 30       |
|    time_elapsed     | 766      |
|    total_timesteps  | 23089    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00726  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1288     |
|    fps              | 30       |
|    time_elapsed     | 766      |
|    total_timesteps  | 23152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00686  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1292     |
|    fps              | 30       |
|    time_elapsed     | 766      |
|    total_timesteps  | 23229    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00335 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1296     |
|    fps              | 30       |
|    time_elapsed     | 767      |
|    total_timesteps  | 23303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00691  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1300     |
|    fps              | 30       |
|    time_elapsed     | 767      |
|    total_timesteps  | 23384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00679  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1304     |
|    fps              | 30       |
|    time_elapsed     | 767      |
|    total_timesteps  | 23450    |
----------------------------------
Eval num_timesteps=23500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 23500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00687  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1308     |
|    fps              | 30       |
|    time_elapsed     | 782      |
|    total_timesteps  | 23523    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00719  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1312     |
|    fps              | 30       |
|    time_elapsed     | 782      |
|    total_timesteps  | 23595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00287 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1316     |
|    fps              | 30       |
|    time_elapsed     | 783      |
|    total_timesteps  | 23666    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00287 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1320     |
|    fps              | 30       |
|    time_elapsed     | 783      |
|    total_timesteps  | 23736    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00271 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1324     |
|    fps              | 30       |
|    time_elapsed     | 783      |
|    total_timesteps  | 23805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00706  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1328     |
|    fps              | 30       |
|    time_elapsed     | 783      |
|    total_timesteps  | 23877    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00449 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1332     |
|    fps              | 30       |
|    time_elapsed     | 783      |
|    total_timesteps  | 23978    |
----------------------------------
Eval num_timesteps=24000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 24000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1336     |
|    fps              | 30       |
|    time_elapsed     | 799      |
|    total_timesteps  | 24053    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00468 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1340     |
|    fps              | 30       |
|    time_elapsed     | 799      |
|    total_timesteps  | 24129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0042  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1344     |
|    fps              | 30       |
|    time_elapsed     | 799      |
|    total_timesteps  | 24204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.004   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1348     |
|    fps              | 30       |
|    time_elapsed     | 799      |
|    total_timesteps  | 24264    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1352     |
|    fps              | 30       |
|    time_elapsed     | 800      |
|    total_timesteps  | 24328    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1356     |
|    fps              | 30       |
|    time_elapsed     | 800      |
|    total_timesteps  | 24402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00348 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1360     |
|    fps              | 30       |
|    time_elapsed     | 800      |
|    total_timesteps  | 24465    |
----------------------------------
Eval num_timesteps=24500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 24500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1364     |
|    fps              | 30       |
|    time_elapsed     | 815      |
|    total_timesteps  | 24536    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00729  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1368     |
|    fps              | 30       |
|    time_elapsed     | 816      |
|    total_timesteps  | 24602    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00789  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1372     |
|    fps              | 30       |
|    time_elapsed     | 816      |
|    total_timesteps  | 24679    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00725  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1376     |
|    fps              | 30       |
|    time_elapsed     | 816      |
|    total_timesteps  | 24762    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00169 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1380     |
|    fps              | 30       |
|    time_elapsed     | 816      |
|    total_timesteps  | 24843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00805  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1384     |
|    fps              | 30       |
|    time_elapsed     | 816      |
|    total_timesteps  | 24914    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00811  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1388     |
|    fps              | 30       |
|    time_elapsed     | 817      |
|    total_timesteps  | 24976    |
----------------------------------
Eval num_timesteps=25000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 25000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00787  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1392     |
|    fps              | 30       |
|    time_elapsed     | 832      |
|    total_timesteps  | 25059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1396     |
|    fps              | 30       |
|    time_elapsed     | 832      |
|    total_timesteps  | 25132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1400     |
|    fps              | 30       |
|    time_elapsed     | 832      |
|    total_timesteps  | 25207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1404     |
|    fps              | 30       |
|    time_elapsed     | 833      |
|    total_timesteps  | 25291    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1408     |
|    fps              | 30       |
|    time_elapsed     | 833      |
|    total_timesteps  | 25360    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1412     |
|    fps              | 30       |
|    time_elapsed     | 833      |
|    total_timesteps  | 25436    |
----------------------------------
Eval num_timesteps=25500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 25500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1416     |
|    fps              | 30       |
|    time_elapsed     | 848      |
|    total_timesteps  | 25516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0371   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1420     |
|    fps              | 30       |
|    time_elapsed     | 849      |
|    total_timesteps  | 25586    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0372   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1424     |
|    fps              | 30       |
|    time_elapsed     | 849      |
|    total_timesteps  | 25651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1428     |
|    fps              | 30       |
|    time_elapsed     | 849      |
|    total_timesteps  | 25726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1432     |
|    fps              | 30       |
|    time_elapsed     | 849      |
|    total_timesteps  | 25805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1436     |
|    fps              | 30       |
|    time_elapsed     | 849      |
|    total_timesteps  | 25890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1440     |
|    fps              | 30       |
|    time_elapsed     | 849      |
|    total_timesteps  | 25960    |
----------------------------------
Eval num_timesteps=26000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 26000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1444     |
|    fps              | 30       |
|    time_elapsed     | 865      |
|    total_timesteps  | 26022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0483   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1448     |
|    fps              | 30       |
|    time_elapsed     | 865      |
|    total_timesteps  | 26084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0475   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1452     |
|    fps              | 30       |
|    time_elapsed     | 866      |
|    total_timesteps  | 26166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0475   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1456     |
|    fps              | 30       |
|    time_elapsed     | 866      |
|    total_timesteps  | 26240    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0468   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1460     |
|    fps              | 30       |
|    time_elapsed     | 866      |
|    total_timesteps  | 26322    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0268   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1464     |
|    fps              | 30       |
|    time_elapsed     | 866      |
|    total_timesteps  | 26392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0265   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1468     |
|    fps              | 30       |
|    time_elapsed     | 866      |
|    total_timesteps  | 26465    |
----------------------------------
Eval num_timesteps=26500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 26500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0264   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1472     |
|    fps              | 30       |
|    time_elapsed     | 882      |
|    total_timesteps  | 26546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0372   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1476     |
|    fps              | 30       |
|    time_elapsed     | 882      |
|    total_timesteps  | 26608    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1480     |
|    fps              | 30       |
|    time_elapsed     | 882      |
|    total_timesteps  | 26677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1484     |
|    fps              | 30       |
|    time_elapsed     | 882      |
|    total_timesteps  | 26749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1488     |
|    fps              | 30       |
|    time_elapsed     | 883      |
|    total_timesteps  | 26828    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1492     |
|    fps              | 30       |
|    time_elapsed     | 883      |
|    total_timesteps  | 26894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1496     |
|    fps              | 30       |
|    time_elapsed     | 883      |
|    total_timesteps  | 26968    |
----------------------------------
Eval num_timesteps=27000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 27000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00789  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1500     |
|    fps              | 30       |
|    time_elapsed     | 898      |
|    total_timesteps  | 27035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00845  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1504     |
|    fps              | 30       |
|    time_elapsed     | 899      |
|    total_timesteps  | 27105    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00856  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1508     |
|    fps              | 30       |
|    time_elapsed     | 899      |
|    total_timesteps  | 27171    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0086   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1512     |
|    fps              | 30       |
|    time_elapsed     | 899      |
|    total_timesteps  | 27246    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00888  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1516     |
|    fps              | 30       |
|    time_elapsed     | 899      |
|    total_timesteps  | 27319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00117 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1520     |
|    fps              | 30       |
|    time_elapsed     | 899      |
|    total_timesteps  | 27390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00129 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1524     |
|    fps              | 30       |
|    time_elapsed     | 900      |
|    total_timesteps  | 27458    |
----------------------------------
Eval num_timesteps=27500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 27500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00097 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1528     |
|    fps              | 30       |
|    time_elapsed     | 915      |
|    total_timesteps  | 27525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00085 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1532     |
|    fps              | 30       |
|    time_elapsed     | 915      |
|    total_timesteps  | 27601    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00953  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1536     |
|    fps              | 30       |
|    time_elapsed     | 915      |
|    total_timesteps  | 27677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00031 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1540     |
|    fps              | 30       |
|    time_elapsed     | 916      |
|    total_timesteps  | 27743    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0105  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1544     |
|    fps              | 30       |
|    time_elapsed     | 916      |
|    total_timesteps  | 27809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00047 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1548     |
|    fps              | 30       |
|    time_elapsed     | 916      |
|    total_timesteps  | 27871    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1552     |
|    fps              | 30       |
|    time_elapsed     | 916      |
|    total_timesteps  | 27939    |
----------------------------------
Eval num_timesteps=28000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 28000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1556     |
|    fps              | 30       |
|    time_elapsed     | 931      |
|    total_timesteps  | 28003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0108   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1560     |
|    fps              | 30       |
|    time_elapsed     | 932      |
|    total_timesteps  | 28077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0107   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1564     |
|    fps              | 30       |
|    time_elapsed     | 932      |
|    total_timesteps  | 28150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1568     |
|    fps              | 30       |
|    time_elapsed     | 932      |
|    total_timesteps  | 28227    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0209   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1572     |
|    fps              | 30       |
|    time_elapsed     | 932      |
|    total_timesteps  | 28298    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0209   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1576     |
|    fps              | 30       |
|    time_elapsed     | 932      |
|    total_timesteps  | 28362    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0208   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1580     |
|    fps              | 30       |
|    time_elapsed     | 933      |
|    total_timesteps  | 28432    |
----------------------------------
Eval num_timesteps=28500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 28500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0204   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1584     |
|    fps              | 30       |
|    time_elapsed     | 948      |
|    total_timesteps  | 28514    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0106   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1588     |
|    fps              | 30       |
|    time_elapsed     | 948      |
|    total_timesteps  | 28589    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0106   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1592     |
|    fps              | 30       |
|    time_elapsed     | 948      |
|    total_timesteps  | 28656    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1596     |
|    fps              | 30       |
|    time_elapsed     | 949      |
|    total_timesteps  | 28732    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1600     |
|    fps              | 30       |
|    time_elapsed     | 949      |
|    total_timesteps  | 28809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1604     |
|    fps              | 30       |
|    time_elapsed     | 949      |
|    total_timesteps  | 28879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -7e-05   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1608     |
|    fps              | 30       |
|    time_elapsed     | 949      |
|    total_timesteps  | 28949    |
----------------------------------
Eval num_timesteps=29000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 29000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00011 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1612     |
|    fps              | 30       |
|    time_elapsed     | 964      |
|    total_timesteps  | 29025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00043 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1616     |
|    fps              | 30       |
|    time_elapsed     | 965      |
|    total_timesteps  | 29106    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00051 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1620     |
|    fps              | 30       |
|    time_elapsed     | 965      |
|    total_timesteps  | 29179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00095 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1624     |
|    fps              | 30       |
|    time_elapsed     | 965      |
|    total_timesteps  | 29258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00103 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1628     |
|    fps              | 30       |
|    time_elapsed     | 965      |
|    total_timesteps  | 29327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1632     |
|    fps              | 30       |
|    time_elapsed     | 965      |
|    total_timesteps  | 29399    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0195   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1636     |
|    fps              | 30       |
|    time_elapsed     | 966      |
|    total_timesteps  | 29466    |
----------------------------------
Eval num_timesteps=29500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 29500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1640     |
|    fps              | 30       |
|    time_elapsed     | 981      |
|    total_timesteps  | 29524    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1644     |
|    fps              | 30       |
|    time_elapsed     | 981      |
|    total_timesteps  | 29591    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1648     |
|    fps              | 30       |
|    time_elapsed     | 981      |
|    total_timesteps  | 29665    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1652     |
|    fps              | 30       |
|    time_elapsed     | 981      |
|    total_timesteps  | 29737    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00866  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1656     |
|    fps              | 30       |
|    time_elapsed     | 982      |
|    total_timesteps  | 29812    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00878  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1660     |
|    fps              | 30       |
|    time_elapsed     | 982      |
|    total_timesteps  | 29883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1664     |
|    fps              | 30       |
|    time_elapsed     | 982      |
|    total_timesteps  | 29951    |
----------------------------------
Eval num_timesteps=30000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 30000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00939  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1668     |
|    fps              | 30       |
|    time_elapsed     | 997      |
|    total_timesteps  | 30018    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0195   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1672     |
|    fps              | 30       |
|    time_elapsed     | 997      |
|    total_timesteps  | 30087    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1676     |
|    fps              | 30       |
|    time_elapsed     | 998      |
|    total_timesteps  | 30158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1680     |
|    fps              | 30       |
|    time_elapsed     | 998      |
|    total_timesteps  | 30224    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0198   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1684     |
|    fps              | 30       |
|    time_elapsed     | 998      |
|    total_timesteps  | 30296    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1688     |
|    fps              | 30       |
|    time_elapsed     | 998      |
|    total_timesteps  | 30365    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1692     |
|    fps              | 30       |
|    time_elapsed     | 998      |
|    total_timesteps  | 30430    |
----------------------------------
Eval num_timesteps=30500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 30500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1696     |
|    fps              | 30       |
|    time_elapsed     | 1015     |
|    total_timesteps  | 30509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1700     |
|    fps              | 30       |
|    time_elapsed     | 1015     |
|    total_timesteps  | 30585    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0199   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1704     |
|    fps              | 30       |
|    time_elapsed     | 1015     |
|    total_timesteps  | 30658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1708     |
|    fps              | 30       |
|    time_elapsed     | 1015     |
|    total_timesteps  | 30739    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1712     |
|    fps              | 30       |
|    time_elapsed     | 1015     |
|    total_timesteps  | 30812    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0297   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1716     |
|    fps              | 30       |
|    time_elapsed     | 1016     |
|    total_timesteps  | 30889    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1720     |
|    fps              | 30       |
|    time_elapsed     | 1016     |
|    total_timesteps  | 30976    |
----------------------------------
Eval num_timesteps=31000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 31000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1724     |
|    fps              | 30       |
|    time_elapsed     | 1033     |
|    total_timesteps  | 31058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0386   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1728     |
|    fps              | 30       |
|    time_elapsed     | 1033     |
|    total_timesteps  | 31137    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0385   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1732     |
|    fps              | 30       |
|    time_elapsed     | 1033     |
|    total_timesteps  | 31214    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1736     |
|    fps              | 30       |
|    time_elapsed     | 1033     |
|    total_timesteps  | 31299    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00688  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1740     |
|    fps              | 30       |
|    time_elapsed     | 1034     |
|    total_timesteps  | 31378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1744     |
|    fps              | 30       |
|    time_elapsed     | 1034     |
|    total_timesteps  | 31440    |
----------------------------------
Eval num_timesteps=31500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 31500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1748     |
|    fps              | 30       |
|    time_elapsed     | 1049     |
|    total_timesteps  | 31516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1752     |
|    fps              | 30       |
|    time_elapsed     | 1050     |
|    total_timesteps  | 31590    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1756     |
|    fps              | 30       |
|    time_elapsed     | 1050     |
|    total_timesteps  | 31655    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1760     |
|    fps              | 30       |
|    time_elapsed     | 1050     |
|    total_timesteps  | 31732    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1764     |
|    fps              | 30       |
|    time_elapsed     | 1050     |
|    total_timesteps  | 31798    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1768     |
|    fps              | 30       |
|    time_elapsed     | 1050     |
|    total_timesteps  | 31871    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1772     |
|    fps              | 30       |
|    time_elapsed     | 1051     |
|    total_timesteps  | 31924    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1776     |
|    fps              | 30       |
|    time_elapsed     | 1051     |
|    total_timesteps  | 31995    |
----------------------------------
Eval num_timesteps=32000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 32000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0375   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1780     |
|    fps              | 30       |
|    time_elapsed     | 1066     |
|    total_timesteps  | 32063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1784     |
|    fps              | 30       |
|    time_elapsed     | 1067     |
|    total_timesteps  | 32129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1788     |
|    fps              | 30       |
|    time_elapsed     | 1067     |
|    total_timesteps  | 32191    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0481   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1792     |
|    fps              | 30       |
|    time_elapsed     | 1067     |
|    total_timesteps  | 32253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0587   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1796     |
|    fps              | 30       |
|    time_elapsed     | 1067     |
|    total_timesteps  | 32317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0692   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1800     |
|    fps              | 30       |
|    time_elapsed     | 1067     |
|    total_timesteps  | 32381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0796   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1804     |
|    fps              | 30       |
|    time_elapsed     | 1068     |
|    total_timesteps  | 32445    |
----------------------------------
Eval num_timesteps=32500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 32500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0698   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1808     |
|    fps              | 30       |
|    time_elapsed     | 1083     |
|    total_timesteps  | 32522    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0697   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1812     |
|    fps              | 30       |
|    time_elapsed     | 1083     |
|    total_timesteps  | 32598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0798   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1816     |
|    fps              | 30       |
|    time_elapsed     | 1084     |
|    total_timesteps  | 32673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0804   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1820     |
|    fps              | 30       |
|    time_elapsed     | 1084     |
|    total_timesteps  | 32743    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0705   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1824     |
|    fps              | 30       |
|    time_elapsed     | 1084     |
|    total_timesteps  | 32823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0709   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1828     |
|    fps              | 30       |
|    time_elapsed     | 1084     |
|    total_timesteps  | 32893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0615   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1832     |
|    fps              | 30       |
|    time_elapsed     | 1084     |
|    total_timesteps  | 32955    |
----------------------------------
Eval num_timesteps=33000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 33000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.062    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1836     |
|    fps              | 30       |
|    time_elapsed     | 1100     |
|    total_timesteps  | 33026    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0624   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1840     |
|    fps              | 30       |
|    time_elapsed     | 1100     |
|    total_timesteps  | 33095    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0416   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1844     |
|    fps              | 30       |
|    time_elapsed     | 1100     |
|    total_timesteps  | 33176    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0421   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1848     |
|    fps              | 30       |
|    time_elapsed     | 1100     |
|    total_timesteps  | 33241    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0426   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1852     |
|    fps              | 30       |
|    time_elapsed     | 1100     |
|    total_timesteps  | 33303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0528   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1856     |
|    fps              | 30       |
|    time_elapsed     | 1101     |
|    total_timesteps  | 33363    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0431   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1860     |
|    fps              | 30       |
|    time_elapsed     | 1101     |
|    total_timesteps  | 33431    |
----------------------------------
Eval num_timesteps=33500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 33500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0326   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1864     |
|    fps              | 29       |
|    time_elapsed     | 1116     |
|    total_timesteps  | 33509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0328   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1868     |
|    fps              | 30       |
|    time_elapsed     | 1117     |
|    total_timesteps  | 33578    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0124   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1872     |
|    fps              | 30       |
|    time_elapsed     | 1117     |
|    total_timesteps  | 33640    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0126   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1876     |
|    fps              | 30       |
|    time_elapsed     | 1117     |
|    total_timesteps  | 33707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0124   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1880     |
|    fps              | 30       |
|    time_elapsed     | 1117     |
|    total_timesteps  | 33780    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.0122   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1884     |
|    fps              | 30       |
|    time_elapsed     | 1117     |
|    total_timesteps  | 33850    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1888     |
|    fps              | 30       |
|    time_elapsed     | 1118     |
|    total_timesteps  | 33925    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00144  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1892     |
|    fps              | 30       |
|    time_elapsed     | 1118     |
|    total_timesteps  | 33994    |
----------------------------------
Eval num_timesteps=34000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 34000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00936 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1896     |
|    fps              | 30       |
|    time_elapsed     | 1134     |
|    total_timesteps  | 34078    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0195  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1900     |
|    fps              | 30       |
|    time_elapsed     | 1134     |
|    total_timesteps  | 34145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0296  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1904     |
|    fps              | 30       |
|    time_elapsed     | 1134     |
|    total_timesteps  | 34212    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.03    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1908     |
|    fps              | 30       |
|    time_elapsed     | 1134     |
|    total_timesteps  | 34297    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1912     |
|    fps              | 30       |
|    time_elapsed     | 1134     |
|    total_timesteps  | 34367    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0195  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1916     |
|    fps              | 30       |
|    time_elapsed     | 1135     |
|    total_timesteps  | 34436    |
----------------------------------
Eval num_timesteps=34500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 34500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1920     |
|    fps              | 30       |
|    time_elapsed     | 1150     |
|    total_timesteps  | 34525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1924     |
|    fps              | 30       |
|    time_elapsed     | 1150     |
|    total_timesteps  | 34603    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1928     |
|    fps              | 30       |
|    time_elapsed     | 1150     |
|    total_timesteps  | 34671    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0303  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1932     |
|    fps              | 30       |
|    time_elapsed     | 1150     |
|    total_timesteps  | 34739    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0209  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1936     |
|    fps              | 30       |
|    time_elapsed     | 1151     |
|    total_timesteps  | 34823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1940     |
|    fps              | 30       |
|    time_elapsed     | 1151     |
|    total_timesteps  | 34898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1944     |
|    fps              | 30       |
|    time_elapsed     | 1151     |
|    total_timesteps  | 34961    |
----------------------------------
Eval num_timesteps=35000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 35000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0106  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1948     |
|    fps              | 30       |
|    time_elapsed     | 1167     |
|    total_timesteps  | 35032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0109  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1952     |
|    fps              | 30       |
|    time_elapsed     | 1167     |
|    total_timesteps  | 35100    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1956     |
|    fps              | 30       |
|    time_elapsed     | 1167     |
|    total_timesteps  | 35171    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1960     |
|    fps              | 30       |
|    time_elapsed     | 1167     |
|    total_timesteps  | 35243    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1964     |
|    fps              | 30       |
|    time_elapsed     | 1167     |
|    total_timesteps  | 35315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1968     |
|    fps              | 30       |
|    time_elapsed     | 1167     |
|    total_timesteps  | 35389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0216  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1972     |
|    fps              | 30       |
|    time_elapsed     | 1168     |
|    total_timesteps  | 35455    |
----------------------------------
Eval num_timesteps=35500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 35500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1976     |
|    fps              | 29       |
|    time_elapsed     | 1184     |
|    total_timesteps  | 35515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1980     |
|    fps              | 30       |
|    time_elapsed     | 1184     |
|    total_timesteps  | 35587    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0108  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1984     |
|    fps              | 30       |
|    time_elapsed     | 1184     |
|    total_timesteps  | 35646    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1988     |
|    fps              | 30       |
|    time_elapsed     | 1184     |
|    total_timesteps  | 35719    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0106  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1992     |
|    fps              | 30       |
|    time_elapsed     | 1184     |
|    total_timesteps  | 35785    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.01    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 1996     |
|    fps              | 30       |
|    time_elapsed     | 1185     |
|    total_timesteps  | 35854    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2000     |
|    fps              | 30       |
|    time_elapsed     | 1185     |
|    total_timesteps  | 35937    |
----------------------------------
Eval num_timesteps=36000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 36000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00875  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2004     |
|    fps              | 29       |
|    time_elapsed     | 1201     |
|    total_timesteps  | 36019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00955  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2008     |
|    fps              | 30       |
|    time_elapsed     | 1202     |
|    total_timesteps  | 36084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00956  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2012     |
|    fps              | 30       |
|    time_elapsed     | 1202     |
|    total_timesteps  | 36154    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00049 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2016     |
|    fps              | 30       |
|    time_elapsed     | 1202     |
|    total_timesteps  | 36224    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00013 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2020     |
|    fps              | 30       |
|    time_elapsed     | 1202     |
|    total_timesteps  | 36304    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -1e-05   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2024     |
|    fps              | 30       |
|    time_elapsed     | 1202     |
|    total_timesteps  | 36379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00017 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2028     |
|    fps              | 30       |
|    time_elapsed     | 1203     |
|    total_timesteps  | 36451    |
----------------------------------
Eval num_timesteps=36500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 36500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -9e-05   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2032     |
|    fps              | 29       |
|    time_elapsed     | 1218     |
|    total_timesteps  | 36517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00944 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2036     |
|    fps              | 30       |
|    time_elapsed     | 1218     |
|    total_timesteps  | 36585    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0092  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2040     |
|    fps              | 30       |
|    time_elapsed     | 1218     |
|    total_timesteps  | 36654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00936 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2044     |
|    fps              | 30       |
|    time_elapsed     | 1219     |
|    total_timesteps  | 36721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2048     |
|    fps              | 30       |
|    time_elapsed     | 1219     |
|    total_timesteps  | 36787    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0198  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2052     |
|    fps              | 30       |
|    time_elapsed     | 1219     |
|    total_timesteps  | 36871    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00975 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2056     |
|    fps              | 30       |
|    time_elapsed     | 1219     |
|    total_timesteps  | 36941    |
----------------------------------
Eval num_timesteps=37000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 37000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00959 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2060     |
|    fps              | 29       |
|    time_elapsed     | 1235     |
|    total_timesteps  | 37009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00061  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2064     |
|    fps              | 30       |
|    time_elapsed     | 1235     |
|    total_timesteps  | 37076    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0111   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2068     |
|    fps              | 30       |
|    time_elapsed     | 1235     |
|    total_timesteps  | 37137    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.021    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2072     |
|    fps              | 30       |
|    time_elapsed     | 1235     |
|    total_timesteps  | 37206    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0209   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2076     |
|    fps              | 30       |
|    time_elapsed     | 1235     |
|    total_timesteps  | 37269    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2080     |
|    fps              | 30       |
|    time_elapsed     | 1236     |
|    total_timesteps  | 37358    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2084     |
|    fps              | 30       |
|    time_elapsed     | 1236     |
|    total_timesteps  | 37422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2088     |
|    fps              | 30       |
|    time_elapsed     | 1236     |
|    total_timesteps  | 37484    |
----------------------------------
Eval num_timesteps=37500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 37500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2092     |
|    fps              | 29       |
|    time_elapsed     | 1252     |
|    total_timesteps  | 37557    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0198   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2096     |
|    fps              | 30       |
|    time_elapsed     | 1252     |
|    total_timesteps  | 37637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2100     |
|    fps              | 30       |
|    time_elapsed     | 1253     |
|    total_timesteps  | 37722    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0003   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2104     |
|    fps              | 30       |
|    time_elapsed     | 1253     |
|    total_timesteps  | 37788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 6e-05    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2108     |
|    fps              | 30       |
|    time_elapsed     | 1253     |
|    total_timesteps  | 37859    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2112     |
|    fps              | 30       |
|    time_elapsed     | 1253     |
|    total_timesteps  | 37923    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2116     |
|    fps              | 30       |
|    time_elapsed     | 1253     |
|    total_timesteps  | 37989    |
----------------------------------
Eval num_timesteps=38000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 38000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0193   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2120     |
|    fps              | 30       |
|    time_elapsed     | 1269     |
|    total_timesteps  | 38098    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0193   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2124     |
|    fps              | 30       |
|    time_elapsed     | 1269     |
|    total_timesteps  | 38172    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0193   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2128     |
|    fps              | 30       |
|    time_elapsed     | 1269     |
|    total_timesteps  | 38246    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0189   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2132     |
|    fps              | 30       |
|    time_elapsed     | 1269     |
|    total_timesteps  | 38321    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2136     |
|    fps              | 30       |
|    time_elapsed     | 1270     |
|    total_timesteps  | 38395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0284   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2140     |
|    fps              | 30       |
|    time_elapsed     | 1270     |
|    total_timesteps  | 38470    |
----------------------------------
Eval num_timesteps=38500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 38500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2144     |
|    fps              | 29       |
|    time_elapsed     | 1285     |
|    total_timesteps  | 38547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2148     |
|    fps              | 30       |
|    time_elapsed     | 1285     |
|    total_timesteps  | 38619    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2152     |
|    fps              | 30       |
|    time_elapsed     | 1286     |
|    total_timesteps  | 38695    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2156     |
|    fps              | 30       |
|    time_elapsed     | 1286     |
|    total_timesteps  | 38763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2160     |
|    fps              | 30       |
|    time_elapsed     | 1286     |
|    total_timesteps  | 38828    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00777  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2164     |
|    fps              | 30       |
|    time_elapsed     | 1286     |
|    total_timesteps  | 38908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00235 |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2168     |
|    fps              | 30       |
|    time_elapsed     | 1286     |
|    total_timesteps  | 38972    |
----------------------------------
Eval num_timesteps=39000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 39000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2172     |
|    fps              | 29       |
|    time_elapsed     | 1302     |
|    total_timesteps  | 39043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2176     |
|    fps              | 30       |
|    time_elapsed     | 1303     |
|    total_timesteps  | 39114    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.022   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2180     |
|    fps              | 30       |
|    time_elapsed     | 1303     |
|    total_timesteps  | 39184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2184     |
|    fps              | 30       |
|    time_elapsed     | 1303     |
|    total_timesteps  | 39247    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0322  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2188     |
|    fps              | 30       |
|    time_elapsed     | 1303     |
|    total_timesteps  | 39314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0323  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2192     |
|    fps              | 30       |
|    time_elapsed     | 1303     |
|    total_timesteps  | 39390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2196     |
|    fps              | 30       |
|    time_elapsed     | 1303     |
|    total_timesteps  | 39455    |
----------------------------------
Eval num_timesteps=39500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 39500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2200     |
|    fps              | 29       |
|    time_elapsed     | 1319     |
|    total_timesteps  | 39524    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2204     |
|    fps              | 29       |
|    time_elapsed     | 1319     |
|    total_timesteps  | 39595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2208     |
|    fps              | 30       |
|    time_elapsed     | 1320     |
|    total_timesteps  | 39665    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0419  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2212     |
|    fps              | 30       |
|    time_elapsed     | 1320     |
|    total_timesteps  | 39747    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0323  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2216     |
|    fps              | 30       |
|    time_elapsed     | 1320     |
|    total_timesteps  | 39822    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.041   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2220     |
|    fps              | 30       |
|    time_elapsed     | 1320     |
|    total_timesteps  | 39898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0309  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2224     |
|    fps              | 30       |
|    time_elapsed     | 1320     |
|    total_timesteps  | 39969    |
----------------------------------
Eval num_timesteps=40000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 40000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2228     |
|    fps              | 29       |
|    time_elapsed     | 1343     |
|    total_timesteps  | 40037    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00791  |
|    n_updates        | 9        |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0308  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2232     |
|    fps              | 29       |
|    time_elapsed     | 1343     |
|    total_timesteps  | 40116    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00758  |
|    n_updates        | 28       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0404  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2236     |
|    fps              | 29       |
|    time_elapsed     | 1344     |
|    total_timesteps  | 40181    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.72e-05 |
|    n_updates        | 45       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.03    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2240     |
|    fps              | 29       |
|    time_elapsed     | 1344     |
|    total_timesteps  | 40246    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.59e-05 |
|    n_updates        | 61       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0195  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2244     |
|    fps              | 29       |
|    time_elapsed     | 1344     |
|    total_timesteps  | 40310    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.14e-05 |
|    n_updates        | 77       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2248     |
|    fps              | 30       |
|    time_elapsed     | 1345     |
|    total_timesteps  | 40394    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.55e-05 |
|    n_updates        | 98       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2252     |
|    fps              | 30       |
|    time_elapsed     | 1345     |
|    total_timesteps  | 40470    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00731  |
|    n_updates        | 117      |
----------------------------------
Eval num_timesteps=40500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 40500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.14e-05 |
|    n_updates        | 124      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0203  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2256     |
|    fps              | 29       |
|    time_elapsed     | 1358     |
|    total_timesteps  | 40547    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.46e-05 |
|    n_updates        | 136      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2260     |
|    fps              | 29       |
|    time_elapsed     | 1358     |
|    total_timesteps  | 40634    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0074   |
|    n_updates        | 158      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2264     |
|    fps              | 29       |
|    time_elapsed     | 1359     |
|    total_timesteps  | 40714    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5e-05    |
|    n_updates        | 178      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2268     |
|    fps              | 29       |
|    time_elapsed     | 1359     |
|    total_timesteps  | 40780    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00734  |
|    n_updates        | 194      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2272     |
|    fps              | 30       |
|    time_elapsed     | 1359     |
|    total_timesteps  | 40852    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.67e-05 |
|    n_updates        | 212      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0212  |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2276     |
|    fps              | 30       |
|    time_elapsed     | 1360     |
|    total_timesteps  | 40920    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.13e-05 |
|    n_updates        | 229      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 2280     |
|    fps              | 30       |
|    time_elapsed     | 1360     |
|    total_timesteps  | 40985    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.19e-05 |
|    n_updates        | 246      |
----------------------------------
Eval num_timesteps=41000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 41000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.54e-05 |
|    n_updates        | 249      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2284     |
|    fps              | 29       |
|    time_elapsed     | 1373     |
|    total_timesteps  | 41063    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 265      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2288     |
|    fps              | 29       |
|    time_elapsed     | 1373     |
|    total_timesteps  | 41140    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.16e-05 |
|    n_updates        | 284      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2292     |
|    fps              | 29       |
|    time_elapsed     | 1373     |
|    total_timesteps  | 41211    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 302      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0223  |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2296     |
|    fps              | 30       |
|    time_elapsed     | 1374     |
|    total_timesteps  | 41286    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.75e-06 |
|    n_updates        | 321      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2300     |
|    fps              | 30       |
|    time_elapsed     | 1374     |
|    total_timesteps  | 41348    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 336      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2304     |
|    fps              | 30       |
|    time_elapsed     | 1374     |
|    total_timesteps  | 41415    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.58e-05 |
|    n_updates        | 353      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00795  |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2308     |
|    fps              | 30       |
|    time_elapsed     | 1375     |
|    total_timesteps  | 41492    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00731  |
|    n_updates        | 372      |
----------------------------------
Eval num_timesteps=41500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.999    |
| time/               |          |
|    total_timesteps  | 41500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0153   |
|    n_updates        | 374      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00827  |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2312     |
|    fps              | 29       |
|    time_elapsed     | 1387     |
|    total_timesteps  | 41566    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.35e-05 |
|    n_updates        | 391      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00837  |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2316     |
|    fps              | 30       |
|    time_elapsed     | 1387     |
|    total_timesteps  | 41639    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.02e-05 |
|    n_updates        | 409      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00817  |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2320     |
|    fps              | 30       |
|    time_elapsed     | 1387     |
|    total_timesteps  | 41720    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.05e-05 |
|    n_updates        | 429      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00167 |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2324     |
|    fps              | 30       |
|    time_elapsed     | 1388     |
|    total_timesteps  | 41787    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.52e-05 |
|    n_updates        | 446      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0078   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2328     |
|    fps              | 30       |
|    time_elapsed     | 1388     |
|    total_timesteps  | 41868    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.73e-05 |
|    n_updates        | 466      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2332     |
|    fps              | 30       |
|    time_elapsed     | 1388     |
|    total_timesteps  | 41924    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.02e-05 |
|    n_updates        | 480      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2336     |
|    fps              | 30       |
|    time_elapsed     | 1389     |
|    total_timesteps  | 41983    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.99e-05 |
|    n_updates        | 495      |
----------------------------------
Eval num_timesteps=42000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.999    |
| time/               |          |
|    total_timesteps  | 42000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.65e-05 |
|    n_updates        | 499      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0289   |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 2340     |
|    fps              | 30       |
|    time_elapsed     | 1401     |
|    total_timesteps  | 42051    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00742  |
|    n_updates        | 512      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2344     |
|    fps              | 30       |
|    time_elapsed     | 1401     |
|    total_timesteps  | 42124    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.07e-05 |
|    n_updates        | 530      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0289   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2348     |
|    fps              | 30       |
|    time_elapsed     | 1402     |
|    total_timesteps  | 42198    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.78e-05 |
|    n_updates        | 549      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2352     |
|    fps              | 30       |
|    time_elapsed     | 1402     |
|    total_timesteps  | 42278    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00772  |
|    n_updates        | 569      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2356     |
|    fps              | 30       |
|    time_elapsed     | 1402     |
|    total_timesteps  | 42357    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.59e-05 |
|    n_updates        | 589      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0393   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2360     |
|    fps              | 30       |
|    time_elapsed     | 1403     |
|    total_timesteps  | 42427    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.61e-05 |
|    n_updates        | 606      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0501   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2364     |
|    fps              | 30       |
|    time_elapsed     | 1403     |
|    total_timesteps  | 42487    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.022    |
|    n_updates        | 621      |
----------------------------------
Eval num_timesteps=42500, episode_reward=-0.24 +/- 0.08
Episode length: 60.72 +/- 19.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60.7     |
|    mean_reward      | -0.242   |
| rollout/            |          |
|    exploration_rate | 0.998    |
| time/               |          |
|    total_timesteps  | 42500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.31e-05 |
|    n_updates        | 624      |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0603   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2368     |
|    fps              | 30       |
|    time_elapsed     | 1415     |
|    total_timesteps  | 42549    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.8e-05  |
|    n_updates        | 637      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0605   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2372     |
|    fps              | 30       |
|    time_elapsed     | 1416     |
|    total_timesteps  | 42614    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00779  |
|    n_updates        | 653      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0807   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2376     |
|    fps              | 30       |
|    time_elapsed     | 1416     |
|    total_timesteps  | 42678    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.5e-05  |
|    n_updates        | 669      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0797   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2380     |
|    fps              | 30       |
|    time_elapsed     | 1416     |
|    total_timesteps  | 42769    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 692      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0704   |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2384     |
|    fps              | 30       |
|    time_elapsed     | 1417     |
|    total_timesteps  | 42829    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.98e-05 |
|    n_updates        | 707      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.071    |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 2388     |
|    fps              | 30       |
|    time_elapsed     | 1417     |
|    total_timesteps  | 42891    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00727  |
|    n_updates        | 722      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0707   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2392     |
|    fps              | 30       |
|    time_elapsed     | 1417     |
|    total_timesteps  | 42970    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.33e-05 |
|    n_updates        | 742      |
----------------------------------
Eval num_timesteps=43000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.997    |
| time/               |          |
|    total_timesteps  | 43000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.8e-05  |
|    n_updates        | 749      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0704   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2396     |
|    fps              | 30       |
|    time_elapsed     | 1433     |
|    total_timesteps  | 43053    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.22e-05 |
|    n_updates        | 763      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0696   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2400     |
|    fps              | 30       |
|    time_elapsed     | 1433     |
|    total_timesteps  | 43135    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00741  |
|    n_updates        | 783      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0695   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2404     |
|    fps              | 30       |
|    time_elapsed     | 1434     |
|    total_timesteps  | 43203    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.38e-05 |
|    n_updates        | 800      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0494   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2408     |
|    fps              | 30       |
|    time_elapsed     | 1434     |
|    total_timesteps  | 43282    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.1e-05  |
|    n_updates        | 820      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.049    |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2412     |
|    fps              | 30       |
|    time_elapsed     | 1434     |
|    total_timesteps  | 43367    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00741  |
|    n_updates        | 841      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2416     |
|    fps              | 30       |
|    time_elapsed     | 1435     |
|    total_timesteps  | 43436    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.74e-05 |
|    n_updates        | 858      |
----------------------------------
Eval num_timesteps=43500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.997    |
| time/               |          |
|    total_timesteps  | 43500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.97e-05 |
|    n_updates        | 874      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0392   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2420     |
|    fps              | 29       |
|    time_elapsed     | 1450     |
|    total_timesteps  | 43516    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.03e-05 |
|    n_updates        | 878      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2424     |
|    fps              | 30       |
|    time_elapsed     | 1450     |
|    total_timesteps  | 43588    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0152   |
|    n_updates        | 896      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0295   |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 2428     |
|    fps              | 30       |
|    time_elapsed     | 1451     |
|    total_timesteps  | 43656    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.62e-05 |
|    n_updates        | 913      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2432     |
|    fps              | 30       |
|    time_elapsed     | 1451     |
|    total_timesteps  | 43732    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.78e-05 |
|    n_updates        | 932      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00823  |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2436     |
|    fps              | 30       |
|    time_elapsed     | 1451     |
|    total_timesteps  | 43802    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.44e-05 |
|    n_updates        | 950      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00771  |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2440     |
|    fps              | 30       |
|    time_elapsed     | 1452     |
|    total_timesteps  | 43883    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.31e-05 |
|    n_updates        | 970      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00803  |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2444     |
|    fps              | 30       |
|    time_elapsed     | 1452     |
|    total_timesteps  | 43948    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.2e-05  |
|    n_updates        | 986      |
----------------------------------
Eval num_timesteps=44000, episode_reward=-0.07 +/- 0.00
Episode length: 18.56 +/- 1.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.6     |
|    mean_reward      | -0.0732  |
| rollout/            |          |
|    exploration_rate | 0.996    |
| time/               |          |
|    total_timesteps  | 44000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00737  |
|    n_updates        | 999      |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00169 |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2448     |
|    fps              | 30       |
|    time_elapsed     | 1457     |
|    total_timesteps  | 44015    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.29e-05 |
|    n_updates        | 1003     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00177 |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2452     |
|    fps              | 30       |
|    time_elapsed     | 1457     |
|    total_timesteps  | 44097    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.98e-05 |
|    n_updates        | 1024     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00153 |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2456     |
|    fps              | 30       |
|    time_elapsed     | 1457     |
|    total_timesteps  | 44170    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.93e-05 |
|    n_updates        | 1042     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2460     |
|    fps              | 30       |
|    time_elapsed     | 1458     |
|    total_timesteps  | 44238    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.98e-06 |
|    n_updates        | 1059     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 2464     |
|    fps              | 30       |
|    time_elapsed     | 1458     |
|    total_timesteps  | 44315    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.07e-05 |
|    n_updates        | 1078     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0324  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2468     |
|    fps              | 30       |
|    time_elapsed     | 1458     |
|    total_timesteps  | 44385    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 1096     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0327  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2472     |
|    fps              | 30       |
|    time_elapsed     | 1459     |
|    total_timesteps  | 44456    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.02e-05 |
|    n_updates        | 1113     |
----------------------------------
Eval num_timesteps=44500, episode_reward=-0.05 +/- 0.14
Episode length: 18.72 +/- 0.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.7     |
|    mean_reward      | -0.0539  |
| rollout/            |          |
|    exploration_rate | 0.995    |
| time/               |          |
|    total_timesteps  | 44500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.21e-05 |
|    n_updates        | 1124     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0528  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2476     |
|    fps              | 30       |
|    time_elapsed     | 1463     |
|    total_timesteps  | 44524    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.92e-05 |
|    n_updates        | 1130     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0521  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2480     |
|    fps              | 30       |
|    time_elapsed     | 1464     |
|    total_timesteps  | 44597    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.25e-05 |
|    n_updates        | 1149     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0525  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2484     |
|    fps              | 30       |
|    time_elapsed     | 1464     |
|    total_timesteps  | 44666    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.42e-05 |
|    n_updates        | 1166     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0526  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2488     |
|    fps              | 30       |
|    time_elapsed     | 1464     |
|    total_timesteps  | 44731    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.04e-05 |
|    n_updates        | 1182     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0524  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2492     |
|    fps              | 30       |
|    time_elapsed     | 1465     |
|    total_timesteps  | 44805    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.64e-06 |
|    n_updates        | 1201     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0416  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2496     |
|    fps              | 30       |
|    time_elapsed     | 1465     |
|    total_timesteps  | 44867    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.09e-05 |
|    n_updates        | 1216     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0517  |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 2500     |
|    fps              | 30       |
|    time_elapsed     | 1465     |
|    total_timesteps  | 44951    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.78e-06 |
|    n_updates        | 1237     |
----------------------------------
Eval num_timesteps=45000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.994    |
| time/               |          |
|    total_timesteps  | 45000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.96e-05 |
|    n_updates        | 1249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0521  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2504     |
|    fps              | 30       |
|    time_elapsed     | 1481     |
|    total_timesteps  | 45030    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.28e-05 |
|    n_updates        | 1257     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0516  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2508     |
|    fps              | 30       |
|    time_elapsed     | 1481     |
|    total_timesteps  | 45097    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 1274     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0408  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2512     |
|    fps              | 30       |
|    time_elapsed     | 1482     |
|    total_timesteps  | 45161    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.02e-05 |
|    n_updates        | 1290     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0407  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2516     |
|    fps              | 30       |
|    time_elapsed     | 1482     |
|    total_timesteps  | 45228    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.35e-05 |
|    n_updates        | 1306     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0302  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2520     |
|    fps              | 30       |
|    time_elapsed     | 1482     |
|    total_timesteps  | 45296    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.02e-05 |
|    n_updates        | 1323     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0303  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2524     |
|    fps              | 30       |
|    time_elapsed     | 1483     |
|    total_timesteps  | 45370    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.44e-05 |
|    n_updates        | 1342     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0304  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2528     |
|    fps              | 30       |
|    time_elapsed     | 1483     |
|    total_timesteps  | 45441    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.05e-05 |
|    n_updates        | 1360     |
----------------------------------
Eval num_timesteps=45500, episode_reward=-0.18 +/- 0.09
Episode length: 44.16 +/- 23.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | -0.176   |
| rollout/            |          |
|    exploration_rate | 0.994    |
| time/               |          |
|    total_timesteps  | 45500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.23e-05 |
|    n_updates        | 1374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0402  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2532     |
|    fps              | 30       |
|    time_elapsed     | 1491     |
|    total_timesteps  | 45512    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.26e-05 |
|    n_updates        | 1377     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0399  |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 2536     |
|    fps              | 30       |
|    time_elapsed     | 1491     |
|    total_timesteps  | 45574    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.96e-05 |
|    n_updates        | 1393     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0393  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2540     |
|    fps              | 30       |
|    time_elapsed     | 1491     |
|    total_timesteps  | 45641    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.91e-05 |
|    n_updates        | 1410     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0293  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2544     |
|    fps              | 30       |
|    time_elapsed     | 1492     |
|    total_timesteps  | 45707    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.52e-05 |
|    n_updates        | 1426     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2548     |
|    fps              | 30       |
|    time_elapsed     | 1492     |
|    total_timesteps  | 45786    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.21e-05 |
|    n_updates        | 1446     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0291  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2552     |
|    fps              | 30       |
|    time_elapsed     | 1492     |
|    total_timesteps  | 45851    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.41e-05 |
|    n_updates        | 1462     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0186  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2556     |
|    fps              | 30       |
|    time_elapsed     | 1493     |
|    total_timesteps  | 45912    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.32e-05 |
|    n_updates        | 1477     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0185  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2560     |
|    fps              | 30       |
|    time_elapsed     | 1493     |
|    total_timesteps  | 45976    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00788  |
|    n_updates        | 1493     |
----------------------------------
Eval num_timesteps=46000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.993    |
| time/               |          |
|    total_timesteps  | 46000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.65e-05 |
|    n_updates        | 1499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0184  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2564     |
|    fps              | 30       |
|    time_elapsed     | 1505     |
|    total_timesteps  | 46051    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00785  |
|    n_updates        | 1512     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0187  |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 2568     |
|    fps              | 30       |
|    time_elapsed     | 1505     |
|    total_timesteps  | 46128    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00767  |
|    n_updates        | 1531     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00831 |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2572     |
|    fps              | 30       |
|    time_elapsed     | 1505     |
|    total_timesteps  | 46190    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0147   |
|    n_updates        | 1547     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00851 |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2576     |
|    fps              | 30       |
|    time_elapsed     | 1505     |
|    total_timesteps  | 46263    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.44e-05 |
|    n_updates        | 1565     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0113   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2580     |
|    fps              | 30       |
|    time_elapsed     | 1506     |
|    total_timesteps  | 46340    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.47e-05 |
|    n_updates        | 1584     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0111   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2584     |
|    fps              | 30       |
|    time_elapsed     | 1506     |
|    total_timesteps  | 46416    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.12e-05 |
|    n_updates        | 1603     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.0209   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2588     |
|    fps              | 30       |
|    time_elapsed     | 1507     |
|    total_timesteps  | 46484    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00731  |
|    n_updates        | 1620     |
----------------------------------
Eval num_timesteps=46500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.992    |
| time/               |          |
|    total_timesteps  | 46500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.03e-05 |
|    n_updates        | 1624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0204   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2592     |
|    fps              | 30       |
|    time_elapsed     | 1519     |
|    total_timesteps  | 46572    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.3e-05  |
|    n_updates        | 1642     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0299   |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 2596     |
|    fps              | 30       |
|    time_elapsed     | 1519     |
|    total_timesteps  | 46648    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.98e-05 |
|    n_updates        | 1661     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0302   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2600     |
|    fps              | 30       |
|    time_elapsed     | 1520     |
|    total_timesteps  | 46723    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.01e-05 |
|    n_updates        | 1680     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0408   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2604     |
|    fps              | 30       |
|    time_elapsed     | 1520     |
|    total_timesteps  | 46786    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 1696     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0406   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2608     |
|    fps              | 30       |
|    time_elapsed     | 1520     |
|    total_timesteps  | 46859    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00769  |
|    n_updates        | 1714     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0303   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2612     |
|    fps              | 30       |
|    time_elapsed     | 1521     |
|    total_timesteps  | 46932    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.37e-05 |
|    n_updates        | 1732     |
----------------------------------
Eval num_timesteps=47000, episode_reward=-0.30 +/- 0.03
Episode length: 74.02 +/- 6.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.991    |
| time/               |          |
|    total_timesteps  | 47000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.68e-05 |
|    n_updates        | 1749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0296   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2616     |
|    fps              | 30       |
|    time_elapsed     | 1533     |
|    total_timesteps  | 47015    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.57e-05 |
|    n_updates        | 1753     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0195   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2620     |
|    fps              | 30       |
|    time_elapsed     | 1533     |
|    total_timesteps  | 47086    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00739  |
|    n_updates        | 1771     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0195   |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 2624     |
|    fps              | 30       |
|    time_elapsed     | 1533     |
|    total_timesteps  | 47159    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2e-05    |
|    n_updates        | 1789     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0399   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 2628     |
|    fps              | 30       |
|    time_elapsed     | 1534     |
|    total_timesteps  | 47219    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.59e-05 |
|    n_updates        | 1804     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 2632     |
|    fps              | 30       |
|    time_elapsed     | 1534     |
|    total_timesteps  | 47289    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0152   |
|    n_updates        | 1822     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0399   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 2636     |
|    fps              | 30       |
|    time_elapsed     | 1534     |
|    total_timesteps  | 47354    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.99e-05 |
|    n_updates        | 1838     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 2640     |
|    fps              | 30       |
|    time_elapsed     | 1535     |
|    total_timesteps  | 47429    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.6e-05  |
|    n_updates        | 1857     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 2644     |
|    fps              | 30       |
|    time_elapsed     | 1535     |
|    total_timesteps  | 47499    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.55e-05 |
|    n_updates        | 1874     |
----------------------------------
Eval num_timesteps=47500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 47500    |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 2648     |
|    fps              | 30       |
|    time_elapsed     | 1550     |
|    total_timesteps  | 47583    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.29e-05 |
|    n_updates        | 1895     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 2652     |
|    fps              | 30       |
|    time_elapsed     | 1551     |
|    total_timesteps  | 47652    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.43e-05 |
|    n_updates        | 1912     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 2656     |
|    fps              | 30       |
|    time_elapsed     | 1551     |
|    total_timesteps  | 47726    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00733  |
|    n_updates        | 1931     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 2660     |
|    fps              | 30       |
|    time_elapsed     | 1551     |
|    total_timesteps  | 47800    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.78e-05 |
|    n_updates        | 1949     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 2664     |
|    fps              | 30       |
|    time_elapsed     | 1552     |
|    total_timesteps  | 47878    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.12e-05 |
|    n_updates        | 1969     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 2668     |
|    fps              | 30       |
|    time_elapsed     | 1552     |
|    total_timesteps  | 47947    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.73e-05 |
|    n_updates        | 1986     |
----------------------------------
Eval num_timesteps=48000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.989    |
| time/               |          |
|    total_timesteps  | 48000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.13e-05 |
|    n_updates        | 1999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 2672     |
|    fps              | 30       |
|    time_elapsed     | 1564     |
|    total_timesteps  | 48017    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 2004     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 2676     |
|    fps              | 30       |
|    time_elapsed     | 1564     |
|    total_timesteps  | 48099    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.55e-05 |
|    n_updates        | 2024     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 2680     |
|    fps              | 30       |
|    time_elapsed     | 1564     |
|    total_timesteps  | 48163    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.52e-05 |
|    n_updates        | 2040     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 2684     |
|    fps              | 30       |
|    time_elapsed     | 1565     |
|    total_timesteps  | 48235    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.28e-05 |
|    n_updates        | 2058     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00791  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 2688     |
|    fps              | 30       |
|    time_elapsed     | 1565     |
|    total_timesteps  | 48312    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.2e-05  |
|    n_updates        | 2077     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00851  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 2692     |
|    fps              | 30       |
|    time_elapsed     | 1565     |
|    total_timesteps  | 48385    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.1e-06  |
|    n_updates        | 2096     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 2696     |
|    fps              | 30       |
|    time_elapsed     | 1566     |
|    total_timesteps  | 48460    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.17e-05 |
|    n_updates        | 2114     |
----------------------------------
Eval num_timesteps=48500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.988    |
| time/               |          |
|    total_timesteps  | 48500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.34e-05 |
|    n_updates        | 2124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 2700     |
|    fps              | 30       |
|    time_elapsed     | 1577     |
|    total_timesteps  | 48542    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.71e-05 |
|    n_updates        | 2135     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 2704     |
|    fps              | 30       |
|    time_elapsed     | 1578     |
|    total_timesteps  | 48606    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.17e-05 |
|    n_updates        | 2151     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 2708     |
|    fps              | 30       |
|    time_elapsed     | 1578     |
|    total_timesteps  | 48679    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.25e-05 |
|    n_updates        | 2169     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 2712     |
|    fps              | 30       |
|    time_elapsed     | 1578     |
|    total_timesteps  | 48751    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00745  |
|    n_updates        | 2187     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00107 |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 2716     |
|    fps              | 30       |
|    time_elapsed     | 1579     |
|    total_timesteps  | 48817    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.68e-05 |
|    n_updates        | 2204     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00115 |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 2720     |
|    fps              | 30       |
|    time_elapsed     | 1579     |
|    total_timesteps  | 48890    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.12e-05 |
|    n_updates        | 2222     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00911  |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 2724     |
|    fps              | 30       |
|    time_elapsed     | 1579     |
|    total_timesteps  | 48957    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.71e-05 |
|    n_updates        | 2239     |
----------------------------------
Eval num_timesteps=49000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.987    |
| time/               |          |
|    total_timesteps  | 49000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 2249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 2728     |
|    fps              | 30       |
|    time_elapsed     | 1595     |
|    total_timesteps  | 49038    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.15e-05 |
|    n_updates        | 2259     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 2732     |
|    fps              | 30       |
|    time_elapsed     | 1596     |
|    total_timesteps  | 49115    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.42e-05 |
|    n_updates        | 2278     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 2736     |
|    fps              | 30       |
|    time_elapsed     | 1596     |
|    total_timesteps  | 49187    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.97e-06 |
|    n_updates        | 2296     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00199 |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 2740     |
|    fps              | 30       |
|    time_elapsed     | 1596     |
|    total_timesteps  | 49255    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.7e-05  |
|    n_updates        | 2313     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00794  |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 2744     |
|    fps              | 30       |
|    time_elapsed     | 1597     |
|    total_timesteps  | 49327    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.19e-05 |
|    n_updates        | 2331     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0083   |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 2748     |
|    fps              | 30       |
|    time_elapsed     | 1597     |
|    total_timesteps  | 49402    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00729  |
|    n_updates        | 2350     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00175 |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 2752     |
|    fps              | 30       |
|    time_elapsed     | 1597     |
|    total_timesteps  | 49472    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00734  |
|    n_updates        | 2367     |
----------------------------------
Eval num_timesteps=49500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.986    |
| time/               |          |
|    total_timesteps  | 49500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00766  |
|    n_updates        | 2374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00155 |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 2756     |
|    fps              | 30       |
|    time_elapsed     | 1613     |
|    total_timesteps  | 49541    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.42e-05 |
|    n_updates        | 2385     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00851  |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 2760     |
|    fps              | 30       |
|    time_elapsed     | 1613     |
|    total_timesteps  | 49614    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.75e-05 |
|    n_updates        | 2403     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00895  |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 2764     |
|    fps              | 30       |
|    time_elapsed     | 1613     |
|    total_timesteps  | 49681    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.97e-05 |
|    n_updates        | 2420     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00891  |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 2768     |
|    fps              | 30       |
|    time_elapsed     | 1614     |
|    total_timesteps  | 49751    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.33e-05 |
|    n_updates        | 2437     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00855  |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 2772     |
|    fps              | 30       |
|    time_elapsed     | 1614     |
|    total_timesteps  | 49830    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.23e-05 |
|    n_updates        | 2457     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00895  |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 2776     |
|    fps              | 30       |
|    time_elapsed     | 1614     |
|    total_timesteps  | 49902    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.75e-05 |
|    n_updates        | 2475     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00858  |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 2780     |
|    fps              | 30       |
|    time_elapsed     | 1615     |
|    total_timesteps  | 49975    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.51e-05 |
|    n_updates        | 2493     |
----------------------------------
Eval num_timesteps=50000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.984    |
| time/               |          |
|    total_timesteps  | 50000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.68e-05 |
|    n_updates        | 2499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00882  |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 2784     |
|    fps              | 30       |
|    time_elapsed     | 1630     |
|    total_timesteps  | 50041    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.8e-05  |
|    n_updates        | 2510     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 2788     |
|    fps              | 30       |
|    time_elapsed     | 1631     |
|    total_timesteps  | 50125    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.63e-05 |
|    n_updates        | 2531     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 2792     |
|    fps              | 30       |
|    time_elapsed     | 1631     |
|    total_timesteps  | 50195    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.36e-05 |
|    n_updates        | 2548     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 2796     |
|    fps              | 30       |
|    time_elapsed     | 1631     |
|    total_timesteps  | 50271    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00734  |
|    n_updates        | 2567     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0185   |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 2800     |
|    fps              | 30       |
|    time_elapsed     | 1632     |
|    total_timesteps  | 50355    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.18e-05 |
|    n_updates        | 2588     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00768  |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 2804     |
|    fps              | 30       |
|    time_elapsed     | 1632     |
|    total_timesteps  | 50440    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.54e-05 |
|    n_updates        | 2609     |
----------------------------------
Eval num_timesteps=50500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.983    |
| time/               |          |
|    total_timesteps  | 50500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.53e-05 |
|    n_updates        | 2624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00772  |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 2808     |
|    fps              | 30       |
|    time_elapsed     | 1647     |
|    total_timesteps  | 50512    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.59e-05 |
|    n_updates        | 2627     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00784  |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 2812     |
|    fps              | 30       |
|    time_elapsed     | 1648     |
|    total_timesteps  | 50581    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.36e-05 |
|    n_updates        | 2645     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00216 |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 2816     |
|    fps              | 30       |
|    time_elapsed     | 1648     |
|    total_timesteps  | 50647    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.13e-05 |
|    n_updates        | 2661     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00212 |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 2820     |
|    fps              | 30       |
|    time_elapsed     | 1648     |
|    total_timesteps  | 50719    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.46e-05 |
|    n_updates        | 2679     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 2824     |
|    fps              | 30       |
|    time_elapsed     | 1649     |
|    total_timesteps  | 50803    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.96e-05 |
|    n_updates        | 2700     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 2828     |
|    fps              | 30       |
|    time_elapsed     | 1649     |
|    total_timesteps  | 50878    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.5e-05  |
|    n_updates        | 2719     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 2832     |
|    fps              | 30       |
|    time_elapsed     | 1649     |
|    total_timesteps  | 50960    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.99e-06 |
|    n_updates        | 2739     |
----------------------------------
Eval num_timesteps=51000, episode_reward=-0.29 +/- 0.03
Episode length: 72.62 +/- 7.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.6     |
|    mean_reward      | -0.29    |
| rollout/            |          |
|    exploration_rate | 0.982    |
| time/               |          |
|    total_timesteps  | 51000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.16e-05 |
|    n_updates        | 2749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 2836     |
|    fps              | 30       |
|    time_elapsed     | 1661     |
|    total_timesteps  | 51042    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.8e-05  |
|    n_updates        | 2760     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 2840     |
|    fps              | 30       |
|    time_elapsed     | 1662     |
|    total_timesteps  | 51113    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.83e-05 |
|    n_updates        | 2778     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 2844     |
|    fps              | 30       |
|    time_elapsed     | 1662     |
|    total_timesteps  | 51187    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.35e-05 |
|    n_updates        | 2796     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 2848     |
|    fps              | 30       |
|    time_elapsed     | 1662     |
|    total_timesteps  | 51255    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4e-05    |
|    n_updates        | 2813     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00265 |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 2852     |
|    fps              | 30       |
|    time_elapsed     | 1663     |
|    total_timesteps  | 51314    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.16e-05 |
|    n_updates        | 2828     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00397 |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 2856     |
|    fps              | 30       |
|    time_elapsed     | 1663     |
|    total_timesteps  | 51416    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.56e-05 |
|    n_updates        | 2853     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 2860     |
|    fps              | 30       |
|    time_elapsed     | 1663     |
|    total_timesteps  | 51487    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.32e-05 |
|    n_updates        | 2871     |
----------------------------------
Eval num_timesteps=51500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.981    |
| time/               |          |
|    total_timesteps  | 51500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.35e-05 |
|    n_updates        | 2874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0241  |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 2864     |
|    fps              | 30       |
|    time_elapsed     | 1675     |
|    total_timesteps  | 51559    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.21e-05 |
|    n_updates        | 2889     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 2868     |
|    fps              | 30       |
|    time_elapsed     | 1676     |
|    total_timesteps  | 51625    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.78e-05 |
|    n_updates        | 2906     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0037  |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 2872     |
|    fps              | 30       |
|    time_elapsed     | 1676     |
|    total_timesteps  | 51698    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.72e-05 |
|    n_updates        | 2924     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0037  |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 2876     |
|    fps              | 30       |
|    time_elapsed     | 1676     |
|    total_timesteps  | 51770    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.84e-06 |
|    n_updates        | 2942     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0038  |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 2880     |
|    fps              | 30       |
|    time_elapsed     | 1677     |
|    total_timesteps  | 51845    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.26e-05 |
|    n_updates        | 2961     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00408 |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 2884     |
|    fps              | 30       |
|    time_elapsed     | 1677     |
|    total_timesteps  | 51918    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.09e-05 |
|    n_updates        | 2979     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00636  |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 2888     |
|    fps              | 30       |
|    time_elapsed     | 1677     |
|    total_timesteps  | 51991    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.18e-05 |
|    n_updates        | 2997     |
----------------------------------
Eval num_timesteps=52000, episode_reward=-0.14 +/- 0.09
Episode length: 35.78 +/- 23.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 35.8     |
|    mean_reward      | -0.142   |
| rollout/            |          |
|    exploration_rate | 0.979    |
| time/               |          |
|    total_timesteps  | 52000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.24e-05 |
|    n_updates        | 2999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.006    |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 2892     |
|    fps              | 30       |
|    time_elapsed     | 1685     |
|    total_timesteps  | 52070    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.24e-05 |
|    n_updates        | 3017     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 2896     |
|    fps              | 30       |
|    time_elapsed     | 1685     |
|    total_timesteps  | 52156    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.69e-05 |
|    n_updates        | 3038     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0159   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 2900     |
|    fps              | 30       |
|    time_elapsed     | 1686     |
|    total_timesteps  | 52232    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.93e-05 |
|    n_updates        | 3057     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 2904     |
|    fps              | 31       |
|    time_elapsed     | 1686     |
|    total_timesteps  | 52301    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 3075     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 2908     |
|    fps              | 31       |
|    time_elapsed     | 1686     |
|    total_timesteps  | 52365    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 3091     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.026    |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 2912     |
|    fps              | 31       |
|    time_elapsed     | 1687     |
|    total_timesteps  | 52456    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.66e-05 |
|    n_updates        | 3113     |
----------------------------------
Eval num_timesteps=52500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.978    |
| time/               |          |
|    total_timesteps  | 52500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.1e-05  |
|    n_updates        | 3124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0257   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 2916     |
|    fps              | 30       |
|    time_elapsed     | 1699     |
|    total_timesteps  | 52529    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.17e-05 |
|    n_updates        | 3132     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 2920     |
|    fps              | 30       |
|    time_elapsed     | 1699     |
|    total_timesteps  | 52598    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.33e-05 |
|    n_updates        | 3149     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0266   |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 2924     |
|    fps              | 30       |
|    time_elapsed     | 1700     |
|    total_timesteps  | 52663    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.62e-05 |
|    n_updates        | 3165     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.037    |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 2928     |
|    fps              | 31       |
|    time_elapsed     | 1700     |
|    total_timesteps  | 52729    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.8e-05  |
|    n_updates        | 3182     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0472   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 2932     |
|    fps              | 31       |
|    time_elapsed     | 1700     |
|    total_timesteps  | 52806    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 3201     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.058    |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 2936     |
|    fps              | 31       |
|    time_elapsed     | 1701     |
|    total_timesteps  | 52867    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0074   |
|    n_updates        | 3216     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0682   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 2940     |
|    fps              | 31       |
|    time_elapsed     | 1701     |
|    total_timesteps  | 52933    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.6e-05  |
|    n_updates        | 3233     |
----------------------------------
Eval num_timesteps=53000, episode_reward=-0.24 +/- 0.09
Episode length: 60.44 +/- 21.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60.4     |
|    mean_reward      | -0.241   |
| rollout/            |          |
|    exploration_rate | 0.977    |
| time/               |          |
|    total_timesteps  | 53000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.73e-05 |
|    n_updates        | 3249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0685   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 2944     |
|    fps              | 30       |
|    time_elapsed     | 1713     |
|    total_timesteps  | 53001    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 3250     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0584   |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 2948     |
|    fps              | 30       |
|    time_elapsed     | 1714     |
|    total_timesteps  | 53071    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.55e-05 |
|    n_updates        | 3267     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0579   |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 2952     |
|    fps              | 30       |
|    time_elapsed     | 1714     |
|    total_timesteps  | 53142    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00733  |
|    n_updates        | 3285     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0592   |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 2956     |
|    fps              | 31       |
|    time_elapsed     | 1714     |
|    total_timesteps  | 53211    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.21e-05 |
|    n_updates        | 3302     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0592   |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 2960     |
|    fps              | 31       |
|    time_elapsed     | 1715     |
|    total_timesteps  | 53282    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.25e-05 |
|    n_updates        | 3320     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0594   |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 2964     |
|    fps              | 31       |
|    time_elapsed     | 1715     |
|    total_timesteps  | 53349    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.05e-05 |
|    n_updates        | 3337     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0592   |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 2968     |
|    fps              | 31       |
|    time_elapsed     | 1715     |
|    total_timesteps  | 53420    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.65e-05 |
|    n_updates        | 3354     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0495   |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 2972     |
|    fps              | 31       |
|    time_elapsed     | 1716     |
|    total_timesteps  | 53487    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.52e-05 |
|    n_updates        | 3371     |
----------------------------------
Eval num_timesteps=53500, episode_reward=-0.09 +/- 0.00
Episode length: 22.06 +/- 0.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22.1     |
|    mean_reward      | -0.0872  |
| rollout/            |          |
|    exploration_rate | 0.976    |
| time/               |          |
|    total_timesteps  | 53500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.94e-05 |
|    n_updates        | 3374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0498   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 2976     |
|    fps              | 31       |
|    time_elapsed     | 1721     |
|    total_timesteps  | 53551    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00771  |
|    n_updates        | 3387     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 2980     |
|    fps              | 31       |
|    time_elapsed     | 1721     |
|    total_timesteps  | 53634    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.84e-05 |
|    n_updates        | 3408     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 2984     |
|    fps              | 31       |
|    time_elapsed     | 1721     |
|    total_timesteps  | 53701    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 3425     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 2988     |
|    fps              | 31       |
|    time_elapsed     | 1722     |
|    total_timesteps  | 53778    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.43e-05 |
|    n_updates        | 3444     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0399   |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 2992     |
|    fps              | 31       |
|    time_elapsed     | 1722     |
|    total_timesteps  | 53850    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.98e-05 |
|    n_updates        | 3462     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0305   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 2996     |
|    fps              | 31       |
|    time_elapsed     | 1722     |
|    total_timesteps  | 53920    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.5e-05  |
|    n_updates        | 3479     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0505   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3000     |
|    fps              | 31       |
|    time_elapsed     | 1723     |
|    total_timesteps  | 53997    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.52e-05 |
|    n_updates        | 3499     |
----------------------------------
Eval num_timesteps=54000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.974    |
| time/               |          |
|    total_timesteps  | 54000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0597   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3004     |
|    fps              | 31       |
|    time_elapsed     | 1739     |
|    total_timesteps  | 54086    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.6e-05  |
|    n_updates        | 3521     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0591   |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 3008     |
|    fps              | 31       |
|    time_elapsed     | 1739     |
|    total_timesteps  | 54165    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.4e-05  |
|    n_updates        | 3541     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0499   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3012     |
|    fps              | 31       |
|    time_elapsed     | 1739     |
|    total_timesteps  | 54235    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 3558     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0498   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3016     |
|    fps              | 31       |
|    time_elapsed     | 1740     |
|    total_timesteps  | 54312    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00737  |
|    n_updates        | 3577     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0497   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3020     |
|    fps              | 31       |
|    time_elapsed     | 1740     |
|    total_timesteps  | 54382    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.1e-05  |
|    n_updates        | 3595     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0492   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3024     |
|    fps              | 31       |
|    time_elapsed     | 1740     |
|    total_timesteps  | 54460    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00743  |
|    n_updates        | 3614     |
----------------------------------
Eval num_timesteps=54500, episode_reward=-0.09 +/- 0.27
Episode length: 38.30 +/- 25.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.3     |
|    mean_reward      | -0.0925  |
| rollout/            |          |
|    exploration_rate | 0.973    |
| time/               |          |
|    total_timesteps  | 54500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00776  |
|    n_updates        | 3624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 3028     |
|    fps              | 31       |
|    time_elapsed     | 1749     |
|    total_timesteps  | 54541    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.67e-05 |
|    n_updates        | 3635     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0388   |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3032     |
|    fps              | 31       |
|    time_elapsed     | 1749     |
|    total_timesteps  | 54614    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0146   |
|    n_updates        | 3653     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0283   |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3036     |
|    fps              | 31       |
|    time_elapsed     | 1750     |
|    total_timesteps  | 54685    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.13e-05 |
|    n_updates        | 3671     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3040     |
|    fps              | 31       |
|    time_elapsed     | 1750     |
|    total_timesteps  | 54756    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.23e-05 |
|    n_updates        | 3688     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00818  |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3044     |
|    fps              | 31       |
|    time_elapsed     | 1750     |
|    total_timesteps  | 54823    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0143   |
|    n_updates        | 3705     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0077   |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 3048     |
|    fps              | 31       |
|    time_elapsed     | 1751     |
|    total_timesteps  | 54905    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.23e-05 |
|    n_updates        | 3726     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00785  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3052     |
|    fps              | 31       |
|    time_elapsed     | 1751     |
|    total_timesteps  | 54972    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.6e-05  |
|    n_updates        | 3742     |
----------------------------------
Eval num_timesteps=55000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.971    |
| time/               |          |
|    total_timesteps  | 55000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.39e-05 |
|    n_updates        | 3749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00789  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3056     |
|    fps              | 31       |
|    time_elapsed     | 1766     |
|    total_timesteps  | 55040    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.38e-05 |
|    n_updates        | 3759     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00765  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3060     |
|    fps              | 31       |
|    time_elapsed     | 1767     |
|    total_timesteps  | 55117    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.65e-05 |
|    n_updates        | 3779     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00769  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3064     |
|    fps              | 31       |
|    time_elapsed     | 1767     |
|    total_timesteps  | 55183    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.03e-05 |
|    n_updates        | 3795     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0024  |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 3068     |
|    fps              | 31       |
|    time_elapsed     | 1767     |
|    total_timesteps  | 55256    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.09e-05 |
|    n_updates        | 3813     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3072     |
|    fps              | 31       |
|    time_elapsed     | 1767     |
|    total_timesteps  | 55313    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00722  |
|    n_updates        | 3828     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3076     |
|    fps              | 31       |
|    time_elapsed     | 1768     |
|    total_timesteps  | 55389    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.51e-06 |
|    n_updates        | 3847     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3080     |
|    fps              | 31       |
|    time_elapsed     | 1768     |
|    total_timesteps  | 55464    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.86e-05 |
|    n_updates        | 3865     |
----------------------------------
Eval num_timesteps=55500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.97     |
| time/               |          |
|    total_timesteps  | 55500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 3874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3084     |
|    fps              | 31       |
|    time_elapsed     | 1781     |
|    total_timesteps  | 55538    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.26e-05 |
|    n_updates        | 3884     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 3088     |
|    fps              | 31       |
|    time_elapsed     | 1781     |
|    total_timesteps  | 55619    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.07e-05 |
|    n_updates        | 3904     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00253 |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3092     |
|    fps              | 31       |
|    time_elapsed     | 1781     |
|    total_timesteps  | 55689    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00779  |
|    n_updates        | 3922     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00269 |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3096     |
|    fps              | 31       |
|    time_elapsed     | 1782     |
|    total_timesteps  | 55763    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.17e-05 |
|    n_updates        | 3940     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3100     |
|    fps              | 31       |
|    time_elapsed     | 1782     |
|    total_timesteps  | 55843    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.89e-05 |
|    n_updates        | 3960     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0323  |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 3104     |
|    fps              | 31       |
|    time_elapsed     | 1783     |
|    total_timesteps  | 55919    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.96e-05 |
|    n_updates        | 3979     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0218  |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3108     |
|    fps              | 31       |
|    time_elapsed     | 1783     |
|    total_timesteps  | 55985    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.38e-05 |
|    n_updates        | 3996     |
----------------------------------
Eval num_timesteps=56000, episode_reward=-0.13 +/- 0.08
Episode length: 31.54 +/- 20.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 31.5     |
|    mean_reward      | -0.125   |
| rollout/            |          |
|    exploration_rate | 0.968    |
| time/               |          |
|    total_timesteps  | 56000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 3999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3112     |
|    fps              | 31       |
|    time_elapsed     | 1790     |
|    total_timesteps  | 56054    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.26e-05 |
|    n_updates        | 4013     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3116     |
|    fps              | 31       |
|    time_elapsed     | 1790     |
|    total_timesteps  | 56121    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.77e-05 |
|    n_updates        | 4030     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3120     |
|    fps              | 31       |
|    time_elapsed     | 1790     |
|    total_timesteps  | 56211    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.29e-05 |
|    n_updates        | 4052     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 3124     |
|    fps              | 31       |
|    time_elapsed     | 1791     |
|    total_timesteps  | 56282    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.07e-05 |
|    n_updates        | 4070     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3128     |
|    fps              | 31       |
|    time_elapsed     | 1791     |
|    total_timesteps  | 56360    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.79e-06 |
|    n_updates        | 4089     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3132     |
|    fps              | 31       |
|    time_elapsed     | 1792     |
|    total_timesteps  | 56443    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.06e-05 |
|    n_updates        | 4110     |
----------------------------------
Eval num_timesteps=56500, episode_reward=-0.15 +/- 0.23
Episode length: 47.30 +/- 26.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | -0.149   |
| rollout/            |          |
|    exploration_rate | 0.967    |
| time/               |          |
|    total_timesteps  | 56500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.85e-05 |
|    n_updates        | 4124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0218  |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3136     |
|    fps              | 31       |
|    time_elapsed     | 1802     |
|    total_timesteps  | 56507    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.66e-05 |
|    n_updates        | 4126     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3140     |
|    fps              | 31       |
|    time_elapsed     | 1803     |
|    total_timesteps  | 56575    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00776  |
|    n_updates        | 4143     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00158 |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 3144     |
|    fps              | 31       |
|    time_elapsed     | 1803     |
|    total_timesteps  | 56638    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.24e-05 |
|    n_updates        | 4159     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00906  |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 3148     |
|    fps              | 31       |
|    time_elapsed     | 1803     |
|    total_timesteps  | 56704    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.83e-05 |
|    n_updates        | 4175     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0009  |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 3152     |
|    fps              | 31       |
|    time_elapsed     | 1804     |
|    total_timesteps  | 56770    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.51e-05 |
|    n_updates        | 4192     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00118 |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 3156     |
|    fps              | 31       |
|    time_elapsed     | 1804     |
|    total_timesteps  | 56845    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00734  |
|    n_updates        | 4211     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0189   |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 3160     |
|    fps              | 31       |
|    time_elapsed     | 1804     |
|    total_timesteps  | 56921    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.61e-05 |
|    n_updates        | 4230     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0189   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 3164     |
|    fps              | 31       |
|    time_elapsed     | 1805     |
|    total_timesteps  | 56987    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.3e-05  |
|    n_updates        | 4246     |
----------------------------------
Eval num_timesteps=57000, episode_reward=-0.14 +/- 0.10
Episode length: 34.54 +/- 25.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.5     |
|    mean_reward      | -0.137   |
| rollout/            |          |
|    exploration_rate | 0.965    |
| time/               |          |
|    total_timesteps  | 57000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.36e-05 |
|    n_updates        | 4249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0291   |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 3168     |
|    fps              | 31       |
|    time_elapsed     | 1813     |
|    total_timesteps  | 57054    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.91e-05 |
|    n_updates        | 4263     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00848  |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 3172     |
|    fps              | 31       |
|    time_elapsed     | 1813     |
|    total_timesteps  | 57127    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00741  |
|    n_updates        | 4281     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00872  |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 3176     |
|    fps              | 31       |
|    time_elapsed     | 1813     |
|    total_timesteps  | 57197    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.6e-05  |
|    n_updates        | 4299     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00912  |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 3180     |
|    fps              | 31       |
|    time_elapsed     | 1814     |
|    total_timesteps  | 57262    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.21e-05 |
|    n_updates        | 4315     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 3184     |
|    fps              | 31       |
|    time_elapsed     | 1814     |
|    total_timesteps  | 57340    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.7e-05  |
|    n_updates        | 4334     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 3188     |
|    fps              | 31       |
|    time_elapsed     | 1814     |
|    total_timesteps  | 57410    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 4352     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 3192     |
|    fps              | 31       |
|    time_elapsed     | 1815     |
|    total_timesteps  | 57486    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.35e-05 |
|    n_updates        | 4371     |
----------------------------------
Eval num_timesteps=57500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.964    |
| time/               |          |
|    total_timesteps  | 57500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.29e-05 |
|    n_updates        | 4374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 3196     |
|    fps              | 31       |
|    time_elapsed     | 1831     |
|    total_timesteps  | 57562    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.43e-05 |
|    n_updates        | 4390     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 3200     |
|    fps              | 31       |
|    time_elapsed     | 1831     |
|    total_timesteps  | 57633    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.47e-05 |
|    n_updates        | 4408     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 3204     |
|    fps              | 31       |
|    time_elapsed     | 1831     |
|    total_timesteps  | 57700    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.57e-05 |
|    n_updates        | 4424     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 3208     |
|    fps              | 31       |
|    time_elapsed     | 1832     |
|    total_timesteps  | 57772    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.65e-05 |
|    n_updates        | 4442     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 3212     |
|    fps              | 31       |
|    time_elapsed     | 1832     |
|    total_timesteps  | 57841    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.76e-05 |
|    n_updates        | 4460     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 3216     |
|    fps              | 31       |
|    time_elapsed     | 1832     |
|    total_timesteps  | 57907    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.14e-05 |
|    n_updates        | 4476     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0404   |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 3220     |
|    fps              | 31       |
|    time_elapsed     | 1833     |
|    total_timesteps  | 57978    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.7e-05  |
|    n_updates        | 4494     |
----------------------------------
Eval num_timesteps=58000, episode_reward=-0.05 +/- 0.14
Episode length: 17.96 +/- 0.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18       |
|    mean_reward      | -0.0508  |
| rollout/            |          |
|    exploration_rate | 0.962    |
| time/               |          |
|    total_timesteps  | 58000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.87e-05 |
|    n_updates        | 4499     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0403   |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 3224     |
|    fps              | 31       |
|    time_elapsed     | 1837     |
|    total_timesteps  | 58051    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00762  |
|    n_updates        | 4512     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0403   |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 3228     |
|    fps              | 31       |
|    time_elapsed     | 1838     |
|    total_timesteps  | 58130    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.64e-05 |
|    n_updates        | 4532     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0407   |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 3232     |
|    fps              | 31       |
|    time_elapsed     | 1838     |
|    total_timesteps  | 58203    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.64e-05 |
|    n_updates        | 4550     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0403   |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 3236     |
|    fps              | 31       |
|    time_elapsed     | 1838     |
|    total_timesteps  | 58276    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.13e-05 |
|    n_updates        | 4568     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0303   |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 3240     |
|    fps              | 31       |
|    time_elapsed     | 1839     |
|    total_timesteps  | 58345    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.21e-05 |
|    n_updates        | 4586     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0299   |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 3244     |
|    fps              | 31       |
|    time_elapsed     | 1839     |
|    total_timesteps  | 58418    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.63e-05 |
|    n_updates        | 4604     |
----------------------------------
Eval num_timesteps=58500, episode_reward=-0.08 +/- 0.00
Episode length: 19.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19       |
|    mean_reward      | -0.075   |
| rollout/            |          |
|    exploration_rate | 0.961    |
| time/               |          |
|    total_timesteps  | 58500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.89e-05 |
|    n_updates        | 4624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 3248     |
|    fps              | 31       |
|    time_elapsed     | 1844     |
|    total_timesteps  | 58506    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0148   |
|    n_updates        | 4626     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.029    |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 3252     |
|    fps              | 31       |
|    time_elapsed     | 1844     |
|    total_timesteps  | 58571    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.05e-05 |
|    n_updates        | 4642     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 3256     |
|    fps              | 31       |
|    time_elapsed     | 1844     |
|    total_timesteps  | 58654    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.98e-05 |
|    n_updates        | 4663     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00862  |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 3260     |
|    fps              | 31       |
|    time_elapsed     | 1845     |
|    total_timesteps  | 58732    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0147   |
|    n_updates        | 4682     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00846  |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 3264     |
|    fps              | 31       |
|    time_elapsed     | 1845     |
|    total_timesteps  | 58802    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.84e-05 |
|    n_updates        | 4700     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00172 |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 3268     |
|    fps              | 31       |
|    time_elapsed     | 1846     |
|    total_timesteps  | 58873    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.58e-05 |
|    n_updates        | 4718     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00815  |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 3272     |
|    fps              | 31       |
|    time_elapsed     | 1846     |
|    total_timesteps  | 58949    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.38e-05 |
|    n_updates        | 4737     |
----------------------------------
Eval num_timesteps=59000, episode_reward=-0.02 +/- 0.20
Episode length: 15.86 +/- 0.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.0224  |
| rollout/            |          |
|    exploration_rate | 0.959    |
| time/               |          |
|    total_timesteps  | 59000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.56e-05 |
|    n_updates        | 4749     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00799  |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 3276     |
|    fps              | 31       |
|    time_elapsed     | 1850     |
|    total_timesteps  | 59023    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.32e-05 |
|    n_updates        | 4755     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00783  |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 3280     |
|    fps              | 31       |
|    time_elapsed     | 1850     |
|    total_timesteps  | 59092    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.18e-05 |
|    n_updates        | 4772     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00204 |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 3284     |
|    fps              | 31       |
|    time_elapsed     | 1851     |
|    total_timesteps  | 59167    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.71e-05 |
|    n_updates        | 4791     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00758  |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 3288     |
|    fps              | 31       |
|    time_elapsed     | 1851     |
|    total_timesteps  | 59247    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00772  |
|    n_updates        | 4811     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00746  |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 3292     |
|    fps              | 32       |
|    time_elapsed     | 1851     |
|    total_timesteps  | 59326    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.14e-05 |
|    n_updates        | 4831     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 3296     |
|    fps              | 32       |
|    time_elapsed     | 1852     |
|    total_timesteps  | 59396    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.16e-05 |
|    n_updates        | 4848     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0376   |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 3300     |
|    fps              | 32       |
|    time_elapsed     | 1852     |
|    total_timesteps  | 59469    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.78e-05 |
|    n_updates        | 4867     |
----------------------------------
Eval num_timesteps=59500, episode_reward=-0.04 +/- 0.34
Episode length: 36.22 +/- 26.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36.2     |
|    mean_reward      | -0.0441  |
| rollout/            |          |
|    exploration_rate | 0.957    |
| time/               |          |
|    total_timesteps  | 59500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.82e-05 |
|    n_updates        | 4874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 3304     |
|    fps              | 32       |
|    time_elapsed     | 1860     |
|    total_timesteps  | 59536    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.34e-05 |
|    n_updates        | 4883     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00749  |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 3308     |
|    fps              | 32       |
|    time_elapsed     | 1860     |
|    total_timesteps  | 59610    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.44e-05 |
|    n_updates        | 4902     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00729  |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 3312     |
|    fps              | 32       |
|    time_elapsed     | 1861     |
|    total_timesteps  | 59684    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.01e-05 |
|    n_updates        | 4920     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00287 |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 3316     |
|    fps              | 32       |
|    time_elapsed     | 1861     |
|    total_timesteps  | 59754    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.36e-05 |
|    n_updates        | 4938     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00732  |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 3320     |
|    fps              | 32       |
|    time_elapsed     | 1861     |
|    total_timesteps  | 59820    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.37e-05 |
|    n_updates        | 4954     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 3324     |
|    fps              | 32       |
|    time_elapsed     | 1862     |
|    total_timesteps  | 59882    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.94e-05 |
|    n_updates        | 4970     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 3328     |
|    fps              | 32       |
|    time_elapsed     | 1862     |
|    total_timesteps  | 59951    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.94e-05 |
|    n_updates        | 4987     |
----------------------------------
Eval num_timesteps=60000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.956    |
| time/               |          |
|    total_timesteps  | 60000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.95e-05 |
|    n_updates        | 4999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 3332     |
|    fps              | 31       |
|    time_elapsed     | 1877     |
|    total_timesteps  | 60016    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00737  |
|    n_updates        | 5003     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 3336     |
|    fps              | 32       |
|    time_elapsed     | 1877     |
|    total_timesteps  | 60093    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00741  |
|    n_updates        | 5023     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 3340     |
|    fps              | 32       |
|    time_elapsed     | 1878     |
|    total_timesteps  | 60188    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.32e-05 |
|    n_updates        | 5046     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0374   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 3344     |
|    fps              | 32       |
|    time_elapsed     | 1878     |
|    total_timesteps  | 60257    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.12e-05 |
|    n_updates        | 5064     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 3348     |
|    fps              | 32       |
|    time_elapsed     | 1878     |
|    total_timesteps  | 60322    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.87e-05 |
|    n_updates        | 5080     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 3352     |
|    fps              | 32       |
|    time_elapsed     | 1879     |
|    total_timesteps  | 60393    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.34e-05 |
|    n_updates        | 5098     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 3356     |
|    fps              | 32       |
|    time_elapsed     | 1879     |
|    total_timesteps  | 60475    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.26e-05 |
|    n_updates        | 5118     |
----------------------------------
Eval num_timesteps=60500, episode_reward=-0.19 +/- 0.19
Episode length: 52.14 +/- 26.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.1     |
|    mean_reward      | -0.188   |
| rollout/            |          |
|    exploration_rate | 0.954    |
| time/               |          |
|    total_timesteps  | 60500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.36e-05 |
|    n_updates        | 5124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 3360     |
|    fps              | 32       |
|    time_elapsed     | 1888     |
|    total_timesteps  | 60551    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.29e-05 |
|    n_updates        | 5137     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 3364     |
|    fps              | 32       |
|    time_elapsed     | 1888     |
|    total_timesteps  | 60625    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.29e-05 |
|    n_updates        | 5156     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 3368     |
|    fps              | 32       |
|    time_elapsed     | 1889     |
|    total_timesteps  | 60694    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4e-05    |
|    n_updates        | 5173     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 3372     |
|    fps              | 32       |
|    time_elapsed     | 1889     |
|    total_timesteps  | 60757    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.91e-05 |
|    n_updates        | 5189     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0291   |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 3376     |
|    fps              | 32       |
|    time_elapsed     | 1889     |
|    total_timesteps  | 60820    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 5204     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.029    |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 3380     |
|    fps              | 32       |
|    time_elapsed     | 1890     |
|    total_timesteps  | 60893    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.84e-05 |
|    n_updates        | 5223     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0291   |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 3384     |
|    fps              | 32       |
|    time_elapsed     | 1890     |
|    total_timesteps  | 60965    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 5241     |
----------------------------------
Eval num_timesteps=61000, episode_reward=-0.19 +/- 0.22
Episode length: 58.22 +/- 20.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.2     |
|    mean_reward      | -0.192   |
| rollout/            |          |
|    exploration_rate | 0.953    |
| time/               |          |
|    total_timesteps  | 61000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00742  |
|    n_updates        | 5249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 3388     |
|    fps              | 32       |
|    time_elapsed     | 1903     |
|    total_timesteps  | 61043    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.26e-05 |
|    n_updates        | 5260     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 3392     |
|    fps              | 32       |
|    time_elapsed     | 1903     |
|    total_timesteps  | 61127    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.32e-05 |
|    n_updates        | 5281     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00875  |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 3396     |
|    fps              | 32       |
|    time_elapsed     | 1904     |
|    total_timesteps  | 61202    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 5300     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0014  |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 3400     |
|    fps              | 32       |
|    time_elapsed     | 1904     |
|    total_timesteps  | 61279    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00718  |
|    n_updates        | 5319     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00148 |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 3404     |
|    fps              | 32       |
|    time_elapsed     | 1904     |
|    total_timesteps  | 61348    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.24e-05 |
|    n_updates        | 5336     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00152 |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 3408     |
|    fps              | 32       |
|    time_elapsed     | 1905     |
|    total_timesteps  | 61423    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.9e-05  |
|    n_updates        | 5355     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0016  |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 3412     |
|    fps              | 32       |
|    time_elapsed     | 1905     |
|    total_timesteps  | 61499    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00741  |
|    n_updates        | 5374     |
----------------------------------
Eval num_timesteps=61500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 61500    |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00824  |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 3416     |
|    fps              | 32       |
|    time_elapsed     | 1921     |
|    total_timesteps  | 61573    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.85e-05 |
|    n_updates        | 5393     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00215 |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 3420     |
|    fps              | 32       |
|    time_elapsed     | 1921     |
|    total_timesteps  | 61649    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.23e-05 |
|    n_updates        | 5412     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00228 |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 3424     |
|    fps              | 32       |
|    time_elapsed     | 1921     |
|    total_timesteps  | 61714    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.83e-05 |
|    n_updates        | 5428     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 3428     |
|    fps              | 32       |
|    time_elapsed     | 1922     |
|    total_timesteps  | 61797    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.78e-05 |
|    n_updates        | 5449     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 3432     |
|    fps              | 32       |
|    time_elapsed     | 1922     |
|    total_timesteps  | 61873    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.17e-05 |
|    n_updates        | 5468     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00682  |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 3436     |
|    fps              | 32       |
|    time_elapsed     | 1922     |
|    total_timesteps  | 61948    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0219   |
|    n_updates        | 5486     |
----------------------------------
Eval num_timesteps=62000, episode_reward=0.06 +/- 0.33
Episode length: 14.54 +/- 1.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.5     |
|    mean_reward      | 0.0629   |
| rollout/            |          |
|    exploration_rate | 0.949    |
| time/               |          |
|    total_timesteps  | 62000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.46e-05 |
|    n_updates        | 5499     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 3440     |
|    fps              | 32       |
|    time_elapsed     | 1926     |
|    total_timesteps  | 62014    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.04e-05 |
|    n_updates        | 5503     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 3444     |
|    fps              | 32       |
|    time_elapsed     | 1926     |
|    total_timesteps  | 62085    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.12e-05 |
|    n_updates        | 5521     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0273   |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 3448     |
|    fps              | 32       |
|    time_elapsed     | 1927     |
|    total_timesteps  | 62166    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.44e-05 |
|    n_updates        | 5541     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0267   |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 3452     |
|    fps              | 32       |
|    time_elapsed     | 1927     |
|    total_timesteps  | 62252    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.98e-05 |
|    n_updates        | 5562     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 3456     |
|    fps              | 32       |
|    time_elapsed     | 1928     |
|    total_timesteps  | 62321    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.38e-05 |
|    n_updates        | 5580     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0275   |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 3460     |
|    fps              | 32       |
|    time_elapsed     | 1928     |
|    total_timesteps  | 62389    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.88e-05 |
|    n_updates        | 5597     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0275   |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 3464     |
|    fps              | 32       |
|    time_elapsed     | 1928     |
|    total_timesteps  | 62463    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.76e-05 |
|    n_updates        | 5615     |
----------------------------------
Eval num_timesteps=62500, episode_reward=-0.02 +/- 0.20
Episode length: 14.90 +/- 0.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | -0.0185  |
| rollout/            |          |
|    exploration_rate | 0.947    |
| time/               |          |
|    total_timesteps  | 62500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.46e-05 |
|    n_updates        | 5624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 3468     |
|    fps              | 32       |
|    time_elapsed     | 1932     |
|    total_timesteps  | 62541    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.97e-05 |
|    n_updates        | 5635     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 3472     |
|    fps              | 32       |
|    time_elapsed     | 1932     |
|    total_timesteps  | 62607    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4e-05    |
|    n_updates        | 5651     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 3476     |
|    fps              | 32       |
|    time_elapsed     | 1933     |
|    total_timesteps  | 62673    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.19e-05 |
|    n_updates        | 5668     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0167   |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 3480     |
|    fps              | 32       |
|    time_elapsed     | 1933     |
|    total_timesteps  | 62750    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.92e-05 |
|    n_updates        | 5687     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 3484     |
|    fps              | 32       |
|    time_elapsed     | 1933     |
|    total_timesteps  | 62815    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00723  |
|    n_updates        | 5703     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0165   |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 3488     |
|    fps              | 32       |
|    time_elapsed     | 1934     |
|    total_timesteps  | 62906    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00771  |
|    n_updates        | 5726     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 3492     |
|    fps              | 32       |
|    time_elapsed     | 1934     |
|    total_timesteps  | 62977    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.82e-05 |
|    n_updates        | 5744     |
----------------------------------
Eval num_timesteps=63000, episode_reward=0.05 +/- 0.33
Episode length: 17.32 +/- 1.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.3     |
|    mean_reward      | 0.0517   |
| rollout/            |          |
|    exploration_rate | 0.946    |
| time/               |          |
|    total_timesteps  | 63000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.43e-05 |
|    n_updates        | 5749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 3496     |
|    fps              | 32       |
|    time_elapsed     | 1939     |
|    total_timesteps  | 63052    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 5762     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 3500     |
|    fps              | 32       |
|    time_elapsed     | 1939     |
|    total_timesteps  | 63113    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 5778     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 3504     |
|    fps              | 32       |
|    time_elapsed     | 1939     |
|    total_timesteps  | 63177    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.38e-05 |
|    n_updates        | 5794     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 3508     |
|    fps              | 32       |
|    time_elapsed     | 1940     |
|    total_timesteps  | 63241    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00778  |
|    n_updates        | 5810     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0189   |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 3512     |
|    fps              | 32       |
|    time_elapsed     | 1940     |
|    total_timesteps  | 63304    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.92e-05 |
|    n_updates        | 5825     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00941  |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 3516     |
|    fps              | 32       |
|    time_elapsed     | 1940     |
|    total_timesteps  | 63364    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0146   |
|    n_updates        | 5840     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00925  |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 3520     |
|    fps              | 32       |
|    time_elapsed     | 1941     |
|    total_timesteps  | 63444    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.74e-05 |
|    n_updates        | 5860     |
----------------------------------
Eval num_timesteps=63500, episode_reward=0.08 +/- 0.35
Episode length: 15.38 +/- 2.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.4     |
|    mean_reward      | 0.0796   |
| rollout/            |          |
|    exploration_rate | 0.944    |
| time/               |          |
|    total_timesteps  | 63500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.28e-05 |
|    n_updates        | 5874     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00118 |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 3524     |
|    fps              | 32       |
|    time_elapsed     | 1945     |
|    total_timesteps  | 63520    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.84e-05 |
|    n_updates        | 5879     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 3528     |
|    fps              | 32       |
|    time_elapsed     | 1945     |
|    total_timesteps  | 63589    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0149   |
|    n_updates        | 5897     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0304  |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 3532     |
|    fps              | 32       |
|    time_elapsed     | 1945     |
|    total_timesteps  | 63658    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.7e-05  |
|    n_updates        | 5914     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 3536     |
|    fps              | 32       |
|    time_elapsed     | 1946     |
|    total_timesteps  | 63727    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0073   |
|    n_updates        | 5931     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0309  |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 3540     |
|    fps              | 32       |
|    time_elapsed     | 1946     |
|    total_timesteps  | 63813    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.81e-05 |
|    n_updates        | 5953     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0407  |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 3544     |
|    fps              | 32       |
|    time_elapsed     | 1946     |
|    total_timesteps  | 63878    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.94e-05 |
|    n_updates        | 5969     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.0508  |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 3548     |
|    fps              | 32       |
|    time_elapsed     | 1947     |
|    total_timesteps  | 63963    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.17e-05 |
|    n_updates        | 5990     |
----------------------------------
Eval num_timesteps=64000, episode_reward=0.02 +/- 0.28
Episode length: 14.86 +/- 1.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.9     |
|    mean_reward      | 0.0215   |
| rollout/            |          |
|    exploration_rate | 0.942    |
| time/               |          |
|    total_timesteps  | 64000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.6e-05  |
|    n_updates        | 5999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0502  |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 3552     |
|    fps              | 32       |
|    time_elapsed     | 1951     |
|    total_timesteps  | 64032    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.26e-05 |
|    n_updates        | 6007     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0402  |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 3556     |
|    fps              | 32       |
|    time_elapsed     | 1951     |
|    total_timesteps  | 64102    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.65e-05 |
|    n_updates        | 6025     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.04    |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 3560     |
|    fps              | 32       |
|    time_elapsed     | 1951     |
|    total_timesteps  | 64166    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.09e-05 |
|    n_updates        | 6041     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0399  |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 3564     |
|    fps              | 32       |
|    time_elapsed     | 1952     |
|    total_timesteps  | 64236    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.81e-05 |
|    n_updates        | 6058     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 3568     |
|    fps              | 32       |
|    time_elapsed     | 1952     |
|    total_timesteps  | 64311    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.56e-05 |
|    n_updates        | 6077     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 3572     |
|    fps              | 32       |
|    time_elapsed     | 1952     |
|    total_timesteps  | 64382    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.88e-05 |
|    n_updates        | 6095     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0199  |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 3576     |
|    fps              | 32       |
|    time_elapsed     | 1953     |
|    total_timesteps  | 64448    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00773  |
|    n_updates        | 6111     |
----------------------------------
Eval num_timesteps=64500, episode_reward=0.06 +/- 0.33
Episode length: 14.56 +/- 1.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0629   |
| rollout/            |          |
|    exploration_rate | 0.94     |
| time/               |          |
|    total_timesteps  | 64500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.23e-05 |
|    n_updates        | 6124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00989 |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 3580     |
|    fps              | 32       |
|    time_elapsed     | 1957     |
|    total_timesteps  | 64524    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.54e-05 |
|    n_updates        | 6130     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 3584     |
|    fps              | 33       |
|    time_elapsed     | 1957     |
|    total_timesteps  | 64596    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00724  |
|    n_updates        | 6148     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00055  |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 3588     |
|    fps              | 33       |
|    time_elapsed     | 1957     |
|    total_timesteps  | 64669    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.29e-05 |
|    n_updates        | 6167     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00039  |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 3592     |
|    fps              | 33       |
|    time_elapsed     | 1958     |
|    total_timesteps  | 64744    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.22e-05 |
|    n_updates        | 6185     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0107   |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 3596     |
|    fps              | 33       |
|    time_elapsed     | 1958     |
|    total_timesteps  | 64812    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.31e-05 |
|    n_updates        | 6202     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00051  |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 3600     |
|    fps              | 33       |
|    time_elapsed     | 1958     |
|    total_timesteps  | 64877    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.06e-05 |
|    n_updates        | 6219     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0195   |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 3604     |
|    fps              | 33       |
|    time_elapsed     | 1959     |
|    total_timesteps  | 64966    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.02e-05 |
|    n_updates        | 6241     |
----------------------------------
Eval num_timesteps=65000, episode_reward=-0.04 +/- 0.14
Episode length: 15.30 +/- 0.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.3     |
|    mean_reward      | -0.0402  |
| rollout/            |          |
|    exploration_rate | 0.938    |
| time/               |          |
|    total_timesteps  | 65000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.04e-05 |
|    n_updates        | 6249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 3608     |
|    fps              | 33       |
|    time_elapsed     | 1963     |
|    total_timesteps  | 65038    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.34e-05 |
|    n_updates        | 6259     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 3612     |
|    fps              | 33       |
|    time_elapsed     | 1963     |
|    total_timesteps  | 65116    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.95e-05 |
|    n_updates        | 6278     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.938    |
| time/               |          |
|    episodes         | 3616     |
|    fps              | 33       |
|    time_elapsed     | 1964     |
|    total_timesteps  | 65201    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00776  |
|    n_updates        | 6300     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0178   |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 3620     |
|    fps              | 33       |
|    time_elapsed     | 1964     |
|    total_timesteps  | 65277    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00696  |
|    n_updates        | 6319     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.018    |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 3624     |
|    fps              | 33       |
|    time_elapsed     | 1964     |
|    total_timesteps  | 65347    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.42e-05 |
|    n_updates        | 6336     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 3628     |
|    fps              | 33       |
|    time_elapsed     | 1965     |
|    total_timesteps  | 65412    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00733  |
|    n_updates        | 6352     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 3632     |
|    fps              | 33       |
|    time_elapsed     | 1965     |
|    total_timesteps  | 65479    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00771  |
|    n_updates        | 6369     |
----------------------------------
Eval num_timesteps=65500, episode_reward=0.02 +/- 0.27
Episode length: 14.78 +/- 0.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.8     |
|    mean_reward      | 0.022    |
| rollout/            |          |
|    exploration_rate | 0.936    |
| time/               |          |
|    total_timesteps  | 65500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0146   |
|    n_updates        | 6374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0285   |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 3636     |
|    fps              | 33       |
|    time_elapsed     | 1969     |
|    total_timesteps  | 65540    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.27e-05 |
|    n_updates        | 6384     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0288   |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 3640     |
|    fps              | 33       |
|    time_elapsed     | 1969     |
|    total_timesteps  | 65618    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00722  |
|    n_updates        | 6404     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0286   |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 3644     |
|    fps              | 33       |
|    time_elapsed     | 1969     |
|    total_timesteps  | 65689    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.28e-05 |
|    n_updates        | 6422     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 3648     |
|    fps              | 33       |
|    time_elapsed     | 1970     |
|    total_timesteps  | 65771    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.4e-05  |
|    n_updates        | 6442     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 3652     |
|    fps              | 33       |
|    time_elapsed     | 1970     |
|    total_timesteps  | 65834    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.21e-05 |
|    n_updates        | 6458     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0286   |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 3656     |
|    fps              | 33       |
|    time_elapsed     | 1971     |
|    total_timesteps  | 65914    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00731  |
|    n_updates        | 6478     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 3660     |
|    fps              | 33       |
|    time_elapsed     | 1971     |
|    total_timesteps  | 65992    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.55e-05 |
|    n_updates        | 6497     |
----------------------------------
Eval num_timesteps=66000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.935    |
| time/               |          |
|    total_timesteps  | 66000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.09e-05 |
|    n_updates        | 6499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 3664     |
|    fps              | 33       |
|    time_elapsed     | 1986     |
|    total_timesteps  | 66062    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5e-05    |
|    n_updates        | 6515     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 3668     |
|    fps              | 33       |
|    time_elapsed     | 1986     |
|    total_timesteps  | 66128    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00727  |
|    n_updates        | 6531     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00825  |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 3672     |
|    fps              | 33       |
|    time_elapsed     | 1987     |
|    total_timesteps  | 66202    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00733  |
|    n_updates        | 6550     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00805  |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 3676     |
|    fps              | 33       |
|    time_elapsed     | 1987     |
|    total_timesteps  | 66273    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.5e-05  |
|    n_updates        | 6568     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00233 |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 3680     |
|    fps              | 33       |
|    time_elapsed     | 1988     |
|    total_timesteps  | 66358    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00744  |
|    n_updates        | 6589     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00229 |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 3684     |
|    fps              | 33       |
|    time_elapsed     | 1988     |
|    total_timesteps  | 66429    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.64e-05 |
|    n_updates        | 6607     |
----------------------------------
Eval num_timesteps=66500, episode_reward=0.05 +/- 0.33
Episode length: 17.58 +/- 1.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.6     |
|    mean_reward      | 0.0508   |
| rollout/            |          |
|    exploration_rate | 0.933    |
| time/               |          |
|    total_timesteps  | 66500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.33e-05 |
|    n_updates        | 6624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 3688     |
|    fps              | 33       |
|    time_elapsed     | 1992     |
|    total_timesteps  | 66505    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.94e-05 |
|    n_updates        | 6626     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 3692     |
|    fps              | 33       |
|    time_elapsed     | 1993     |
|    total_timesteps  | 66578    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.86e-05 |
|    n_updates        | 6644     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 3696     |
|    fps              | 33       |
|    time_elapsed     | 1993     |
|    total_timesteps  | 66655    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 6663     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 3700     |
|    fps              | 33       |
|    time_elapsed     | 1993     |
|    total_timesteps  | 66720    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.47e-05 |
|    n_updates        | 6679     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0316  |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 3704     |
|    fps              | 33       |
|    time_elapsed     | 1994     |
|    total_timesteps  | 66782    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.83e-05 |
|    n_updates        | 6695     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 3708     |
|    fps              | 33       |
|    time_elapsed     | 1994     |
|    total_timesteps  | 66863    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.06e-05 |
|    n_updates        | 6715     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0321  |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 3712     |
|    fps              | 33       |
|    time_elapsed     | 1994     |
|    total_timesteps  | 66943    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.82e-05 |
|    n_updates        | 6735     |
----------------------------------
Eval num_timesteps=67000, episode_reward=0.04 +/- 0.30
Episode length: 14.62 +/- 1.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 14.6     |
|    mean_reward      | 0.0425   |
| rollout/            |          |
|    exploration_rate | 0.931    |
| time/               |          |
|    total_timesteps  | 67000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.16e-05 |
|    n_updates        | 6749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0215  |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 3716     |
|    fps              | 33       |
|    time_elapsed     | 1998     |
|    total_timesteps  | 67014    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.03e-05 |
|    n_updates        | 6753     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 3720     |
|    fps              | 33       |
|    time_elapsed     | 1999     |
|    total_timesteps  | 67096    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.77e-05 |
|    n_updates        | 6773     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0216  |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 3724     |
|    fps              | 33       |
|    time_elapsed     | 1999     |
|    total_timesteps  | 67163    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.75e-05 |
|    n_updates        | 6790     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 3728     |
|    fps              | 33       |
|    time_elapsed     | 1999     |
|    total_timesteps  | 67236    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.97e-05 |
|    n_updates        | 6808     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.022   |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 3732     |
|    fps              | 33       |
|    time_elapsed     | 2000     |
|    total_timesteps  | 67305    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.67e-05 |
|    n_updates        | 6826     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 3736     |
|    fps              | 33       |
|    time_elapsed     | 2000     |
|    total_timesteps  | 67393    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.82e-05 |
|    n_updates        | 6848     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0327  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 3740     |
|    fps              | 33       |
|    time_elapsed     | 2000     |
|    total_timesteps  | 67462    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.37e-05 |
|    n_updates        | 6865     |
----------------------------------
Eval num_timesteps=67500, episode_reward=-0.00 +/- 0.24
Episode length: 15.82 +/- 0.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | -0.00222 |
| rollout/            |          |
|    exploration_rate | 0.929    |
| time/               |          |
|    total_timesteps  | 67500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.07e-05 |
|    n_updates        | 6874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 3744     |
|    fps              | 33       |
|    time_elapsed     | 2005     |
|    total_timesteps  | 67538    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.07e-05 |
|    n_updates        | 6884     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 3748     |
|    fps              | 33       |
|    time_elapsed     | 2005     |
|    total_timesteps  | 67617    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00779  |
|    n_updates        | 6904     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 3752     |
|    fps              | 33       |
|    time_elapsed     | 2005     |
|    total_timesteps  | 67680    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.07e-05 |
|    n_updates        | 6919     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 3756     |
|    fps              | 33       |
|    time_elapsed     | 2006     |
|    total_timesteps  | 67751    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.21e-05 |
|    n_updates        | 6937     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 3760     |
|    fps              | 33       |
|    time_elapsed     | 2006     |
|    total_timesteps  | 67818    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.86e-05 |
|    n_updates        | 6954     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 3764     |
|    fps              | 33       |
|    time_elapsed     | 2006     |
|    total_timesteps  | 67889    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.25e-05 |
|    n_updates        | 6972     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0021  |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 3768     |
|    fps              | 33       |
|    time_elapsed     | 2007     |
|    total_timesteps  | 67957    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.86e-05 |
|    n_updates        | 6989     |
----------------------------------
Eval num_timesteps=68000, episode_reward=0.02 +/- 0.28
Episode length: 16.14 +/- 1.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | 0.0165   |
| rollout/            |          |
|    exploration_rate | 0.927    |
| time/               |          |
|    total_timesteps  | 68000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.98e-05 |
|    n_updates        | 6999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0075   |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 3772     |
|    fps              | 33       |
|    time_elapsed     | 2011     |
|    total_timesteps  | 68041    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.72e-05 |
|    n_updates        | 7010     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00738  |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 3776     |
|    fps              | 33       |
|    time_elapsed     | 2011     |
|    total_timesteps  | 68115    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.62e-05 |
|    n_updates        | 7028     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0079   |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 3780     |
|    fps              | 33       |
|    time_elapsed     | 2012     |
|    total_timesteps  | 68187    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00734  |
|    n_updates        | 7046     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00766  |
|    exploration_rate | 0.926    |
| time/               |          |
|    episodes         | 3784     |
|    fps              | 33       |
|    time_elapsed     | 2012     |
|    total_timesteps  | 68264    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.84e-05 |
|    n_updates        | 7065     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00702  |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 3788     |
|    fps              | 33       |
|    time_elapsed     | 2013     |
|    total_timesteps  | 68356    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.83e-05 |
|    n_updates        | 7088     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0071   |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 3792     |
|    fps              | 33       |
|    time_elapsed     | 2013     |
|    total_timesteps  | 68427    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 7106     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00754  |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 3796     |
|    fps              | 34       |
|    time_elapsed     | 2013     |
|    total_timesteps  | 68493    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.94e-05 |
|    n_updates        | 7123     |
----------------------------------
Eval num_timesteps=68500, episode_reward=-0.09 +/- 0.00
Episode length: 22.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22       |
|    mean_reward      | -0.087   |
| rollout/            |          |
|    exploration_rate | 0.925    |
| time/               |          |
|    total_timesteps  | 68500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.01e-05 |
|    n_updates        | 7124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00698  |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 3800     |
|    fps              | 33       |
|    time_elapsed     | 2019     |
|    total_timesteps  | 68572    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.34e-05 |
|    n_updates        | 7142     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00356 |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 3804     |
|    fps              | 33       |
|    time_elapsed     | 2019     |
|    total_timesteps  | 68647    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00726  |
|    n_updates        | 7161     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00316 |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 3808     |
|    fps              | 34       |
|    time_elapsed     | 2020     |
|    total_timesteps  | 68718    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0072   |
|    n_updates        | 7179     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00268 |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 3812     |
|    fps              | 34       |
|    time_elapsed     | 2020     |
|    total_timesteps  | 68786    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.18e-05 |
|    n_updates        | 7196     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 3816     |
|    fps              | 34       |
|    time_elapsed     | 2021     |
|    total_timesteps  | 68859    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.57e-05 |
|    n_updates        | 7214     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 3820     |
|    fps              | 34       |
|    time_elapsed     | 2021     |
|    total_timesteps  | 68929    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.04e-05 |
|    n_updates        | 7232     |
----------------------------------
Eval num_timesteps=69000, episode_reward=-0.30 +/- 0.01
Episode length: 74.56 +/- 3.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.923    |
| time/               |          |
|    total_timesteps  | 69000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.3e-05  |
|    n_updates        | 7249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 3824     |
|    fps              | 33       |
|    time_elapsed     | 2036     |
|    total_timesteps  | 69006    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.36e-05 |
|    n_updates        | 7251     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0225  |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 3828     |
|    fps              | 33       |
|    time_elapsed     | 2037     |
|    total_timesteps  | 69074    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.69e-05 |
|    n_updates        | 7268     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 3832     |
|    fps              | 33       |
|    time_elapsed     | 2037     |
|    total_timesteps  | 69156    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.67e-05 |
|    n_updates        | 7288     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0122  |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 3836     |
|    fps              | 33       |
|    time_elapsed     | 2037     |
|    total_timesteps  | 69223    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.45e-05 |
|    n_updates        | 7305     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 3840     |
|    fps              | 33       |
|    time_elapsed     | 2038     |
|    total_timesteps  | 69295    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00785  |
|    n_updates        | 7323     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 3844     |
|    fps              | 34       |
|    time_elapsed     | 2038     |
|    total_timesteps  | 69361    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.43e-05 |
|    n_updates        | 7340     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 3848     |
|    fps              | 34       |
|    time_elapsed     | 2038     |
|    total_timesteps  | 69432    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.47e-05 |
|    n_updates        | 7357     |
----------------------------------
Eval num_timesteps=69500, episode_reward=-0.29 +/- 0.05
Episode length: 72.64 +/- 11.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.6     |
|    mean_reward      | -0.291   |
| rollout/            |          |
|    exploration_rate | 0.921    |
| time/               |          |
|    total_timesteps  | 69500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.07e-05 |
|    n_updates        | 7374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 3852     |
|    fps              | 33       |
|    time_elapsed     | 2053     |
|    total_timesteps  | 69501    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.09e-05 |
|    n_updates        | 7375     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.921    |
| time/               |          |
|    episodes         | 3856     |
|    fps              | 33       |
|    time_elapsed     | 2054     |
|    total_timesteps  | 69587    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.95e-05 |
|    n_updates        | 7396     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 3860     |
|    fps              | 33       |
|    time_elapsed     | 2054     |
|    total_timesteps  | 69660    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.21e-05 |
|    n_updates        | 7414     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 3864     |
|    fps              | 33       |
|    time_elapsed     | 2054     |
|    total_timesteps  | 69733    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.4e-05  |
|    n_updates        | 7433     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0326  |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 3868     |
|    fps              | 33       |
|    time_elapsed     | 2055     |
|    total_timesteps  | 69798    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.19e-05 |
|    n_updates        | 7449     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0425  |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 3872     |
|    fps              | 33       |
|    time_elapsed     | 2055     |
|    total_timesteps  | 69879    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.44e-05 |
|    n_updates        | 7469     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0329  |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 3876     |
|    fps              | 34       |
|    time_elapsed     | 2055     |
|    total_timesteps  | 69964    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.99e-05 |
|    n_updates        | 7490     |
----------------------------------
Eval num_timesteps=70000, episode_reward=-0.08 +/- 0.00
Episode length: 19.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19       |
|    mean_reward      | -0.075   |
| rollout/            |          |
|    exploration_rate | 0.919    |
| time/               |          |
|    total_timesteps  | 70000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.07e-05 |
|    n_updates        | 7499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 3880     |
|    fps              | 33       |
|    time_elapsed     | 2060     |
|    total_timesteps  | 70040    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00783  |
|    n_updates        | 7509     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0333  |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 3884     |
|    fps              | 34       |
|    time_elapsed     | 2061     |
|    total_timesteps  | 70122    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.27e-05 |
|    n_updates        | 7530     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 3888     |
|    fps              | 34       |
|    time_elapsed     | 2061     |
|    total_timesteps  | 70191    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.13e-05 |
|    n_updates        | 7547     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00268 |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 3892     |
|    fps              | 34       |
|    time_elapsed     | 2061     |
|    total_timesteps  | 70270    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.24e-05 |
|    n_updates        | 7567     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00705  |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 3896     |
|    fps              | 34       |
|    time_elapsed     | 2062     |
|    total_timesteps  | 70343    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.41e-05 |
|    n_updates        | 7585     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00745  |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 3900     |
|    fps              | 34       |
|    time_elapsed     | 2062     |
|    total_timesteps  | 70412    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.41e-05 |
|    n_updates        | 7602     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00781  |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 3904     |
|    fps              | 34       |
|    time_elapsed     | 2063     |
|    total_timesteps  | 70478    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.56e-05 |
|    n_updates        | 7619     |
----------------------------------
Eval num_timesteps=70500, episode_reward=-0.05 +/- 0.14
Episode length: 18.94 +/- 0.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.9     |
|    mean_reward      | -0.0547  |
| rollout/            |          |
|    exploration_rate | 0.917    |
| time/               |          |
|    total_timesteps  | 70500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00734  |
|    n_updates        | 7624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00769  |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 3908     |
|    fps              | 34       |
|    time_elapsed     | 2068     |
|    total_timesteps  | 70552    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.14e-05 |
|    n_updates        | 7637     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00717  |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 3912     |
|    fps              | 34       |
|    time_elapsed     | 2068     |
|    total_timesteps  | 70633    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00736  |
|    n_updates        | 7658     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00693  |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 3916     |
|    fps              | 34       |
|    time_elapsed     | 2068     |
|    total_timesteps  | 70712    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.86e-05 |
|    n_updates        | 7677     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00653  |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 3920     |
|    fps              | 34       |
|    time_elapsed     | 2069     |
|    total_timesteps  | 70792    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.9e-05  |
|    n_updates        | 7697     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00677  |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 3924     |
|    fps              | 34       |
|    time_elapsed     | 2069     |
|    total_timesteps  | 70863    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.75e-05 |
|    n_updates        | 7715     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00633  |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 3928     |
|    fps              | 34       |
|    time_elapsed     | 2069     |
|    total_timesteps  | 70942    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.9e-05  |
|    n_updates        | 7735     |
----------------------------------
Eval num_timesteps=71000, episode_reward=-0.30 +/- 0.03
Episode length: 73.82 +/- 8.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.915    |
| time/               |          |
|    total_timesteps  | 71000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.46e-05 |
|    n_updates        | 7749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00641  |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 3932     |
|    fps              | 34       |
|    time_elapsed     | 2082     |
|    total_timesteps  | 71022    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.35e-05 |
|    n_updates        | 7755     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00436 |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 3936     |
|    fps              | 34       |
|    time_elapsed     | 2082     |
|    total_timesteps  | 71108    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00739  |
|    n_updates        | 7776     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00583  |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 3940     |
|    fps              | 34       |
|    time_elapsed     | 2083     |
|    total_timesteps  | 71175    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0072   |
|    n_updates        | 7793     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00417 |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 3944     |
|    fps              | 34       |
|    time_elapsed     | 2083     |
|    total_timesteps  | 71241    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.26e-05 |
|    n_updates        | 7810     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00405 |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 3948     |
|    fps              | 34       |
|    time_elapsed     | 2083     |
|    total_timesteps  | 71309    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.1e-05  |
|    n_updates        | 7827     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 3952     |
|    fps              | 34       |
|    time_elapsed     | 2084     |
|    total_timesteps  | 71382    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.5e-05  |
|    n_updates        | 7845     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 3956     |
|    fps              | 34       |
|    time_elapsed     | 2084     |
|    total_timesteps  | 71451    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.73e-05 |
|    n_updates        | 7862     |
----------------------------------
Eval num_timesteps=71500, episode_reward=-0.25 +/- 0.24
Episode length: 71.70 +/- 13.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.7     |
|    mean_reward      | -0.247   |
| rollout/            |          |
|    exploration_rate | 0.913    |
| time/               |          |
|    total_timesteps  | 71500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.1e-05  |
|    n_updates        | 7874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 3960     |
|    fps              | 34       |
|    time_elapsed     | 2100     |
|    total_timesteps  | 71524    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.07e-05 |
|    n_updates        | 7880     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 3964     |
|    fps              | 34       |
|    time_elapsed     | 2100     |
|    total_timesteps  | 71593    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00764  |
|    n_updates        | 7898     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 3968     |
|    fps              | 34       |
|    time_elapsed     | 2100     |
|    total_timesteps  | 71685    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.87e-05 |
|    n_updates        | 7921     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 3972     |
|    fps              | 34       |
|    time_elapsed     | 2101     |
|    total_timesteps  | 71753    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.38e-05 |
|    n_updates        | 7938     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 3976     |
|    fps              | 34       |
|    time_elapsed     | 2101     |
|    total_timesteps  | 71827    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.73e-05 |
|    n_updates        | 7956     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 3980     |
|    fps              | 34       |
|    time_elapsed     | 2101     |
|    total_timesteps  | 71900    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 7974     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 3984     |
|    fps              | 34       |
|    time_elapsed     | 2102     |
|    total_timesteps  | 71971    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0074   |
|    n_updates        | 7992     |
----------------------------------
Eval num_timesteps=72000, episode_reward=0.07 +/- 0.35
Episode length: 18.70 +/- 5.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.7     |
|    mean_reward      | 0.0663   |
| rollout/            |          |
|    exploration_rate | 0.911    |
| time/               |          |
|    total_timesteps  | 72000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.79e-05 |
|    n_updates        | 7999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0434  |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 3988     |
|    fps              | 34       |
|    time_elapsed     | 2106     |
|    total_timesteps  | 72050    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00744  |
|    n_updates        | 8012     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0433  |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 3992     |
|    fps              | 34       |
|    time_elapsed     | 2107     |
|    total_timesteps  | 72127    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.24e-05 |
|    n_updates        | 8031     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0531  |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 3996     |
|    fps              | 34       |
|    time_elapsed     | 2107     |
|    total_timesteps  | 72196    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00729  |
|    n_updates        | 8048     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0535  |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 4000     |
|    fps              | 34       |
|    time_elapsed     | 2108     |
|    total_timesteps  | 72274    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.67e-05 |
|    n_updates        | 8068     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0541  |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 4004     |
|    fps              | 34       |
|    time_elapsed     | 2108     |
|    total_timesteps  | 72356    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.52e-05 |
|    n_updates        | 8088     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0543  |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 4008     |
|    fps              | 34       |
|    time_elapsed     | 2108     |
|    total_timesteps  | 72433    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.74e-05 |
|    n_updates        | 8108     |
----------------------------------
Eval num_timesteps=72500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.909    |
| time/               |          |
|    total_timesteps  | 72500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.84e-05 |
|    n_updates        | 8124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.054   |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 4012     |
|    fps              | 34       |
|    time_elapsed     | 2124     |
|    total_timesteps  | 72507    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00732  |
|    n_updates        | 8126     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0439  |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 4016     |
|    fps              | 34       |
|    time_elapsed     | 2124     |
|    total_timesteps  | 72584    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 8145     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0334  |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 4020     |
|    fps              | 34       |
|    time_elapsed     | 2124     |
|    total_timesteps  | 72652    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.67e-05 |
|    n_updates        | 8162     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 4024     |
|    fps              | 34       |
|    time_elapsed     | 2125     |
|    total_timesteps  | 72720    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0219   |
|    n_updates        | 8179     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00273 |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 4028     |
|    fps              | 34       |
|    time_elapsed     | 2125     |
|    total_timesteps  | 72785    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.35e-05 |
|    n_updates        | 8196     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00237 |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 4032     |
|    fps              | 34       |
|    time_elapsed     | 2126     |
|    total_timesteps  | 72856    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00715  |
|    n_updates        | 8213     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00791  |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 4036     |
|    fps              | 34       |
|    time_elapsed     | 2126     |
|    total_timesteps  | 72935    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.15e-05 |
|    n_updates        | 8233     |
----------------------------------
Eval num_timesteps=73000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.906    |
| time/               |          |
|    total_timesteps  | 73000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.74e-05 |
|    n_updates        | 8249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00759  |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 4040     |
|    fps              | 34       |
|    time_elapsed     | 2141     |
|    total_timesteps  | 73010    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.01e-05 |
|    n_updates        | 8252     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 4044     |
|    fps              | 34       |
|    time_elapsed     | 2142     |
|    total_timesteps  | 73074    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.33e-05 |
|    n_updates        | 8268     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 4048     |
|    fps              | 34       |
|    time_elapsed     | 2142     |
|    total_timesteps  | 73153    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.22e-05 |
|    n_updates        | 8288     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 4052     |
|    fps              | 34       |
|    time_elapsed     | 2142     |
|    total_timesteps  | 73223    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 8305     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 4056     |
|    fps              | 34       |
|    time_elapsed     | 2143     |
|    total_timesteps  | 73289    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.77e-05 |
|    n_updates        | 8322     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 4060     |
|    fps              | 34       |
|    time_elapsed     | 2143     |
|    total_timesteps  | 73368    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.26e-05 |
|    n_updates        | 8341     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 4064     |
|    fps              | 34       |
|    time_elapsed     | 2143     |
|    total_timesteps  | 73439    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.41e-05 |
|    n_updates        | 8359     |
----------------------------------
Eval num_timesteps=73500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.904    |
| time/               |          |
|    total_timesteps  | 73500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 8374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.904    |
| time/               |          |
|    episodes         | 4068     |
|    fps              | 34       |
|    time_elapsed     | 2156     |
|    total_timesteps  | 73511    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.61e-05 |
|    n_updates        | 8377     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 0.904    |
| time/               |          |
|    episodes         | 4072     |
|    fps              | 34       |
|    time_elapsed     | 2156     |
|    total_timesteps  | 73583    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.28e-05 |
|    n_updates        | 8395     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.904    |
| time/               |          |
|    episodes         | 4076     |
|    fps              | 34       |
|    time_elapsed     | 2156     |
|    total_timesteps  | 73653    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0144   |
|    n_updates        | 8413     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 4080     |
|    fps              | 34       |
|    time_elapsed     | 2157     |
|    total_timesteps  | 73731    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.79e-05 |
|    n_updates        | 8432     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 4084     |
|    fps              | 34       |
|    time_elapsed     | 2157     |
|    total_timesteps  | 73805    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.82e-05 |
|    n_updates        | 8451     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 4088     |
|    fps              | 34       |
|    time_elapsed     | 2157     |
|    total_timesteps  | 73877    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.14e-05 |
|    n_updates        | 8469     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 4092     |
|    fps              | 34       |
|    time_elapsed     | 2158     |
|    total_timesteps  | 73967    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.48e-05 |
|    n_updates        | 8491     |
----------------------------------
Eval num_timesteps=74000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.902    |
| time/               |          |
|    total_timesteps  | 74000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.47e-05 |
|    n_updates        | 8499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 4096     |
|    fps              | 34       |
|    time_elapsed     | 2170     |
|    total_timesteps  | 74046    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.12e-05 |
|    n_updates        | 8511     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 4100     |
|    fps              | 34       |
|    time_elapsed     | 2171     |
|    total_timesteps  | 74123    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0073   |
|    n_updates        | 8530     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.901    |
| time/               |          |
|    episodes         | 4104     |
|    fps              | 34       |
|    time_elapsed     | 2171     |
|    total_timesteps  | 74191    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.85e-05 |
|    n_updates        | 8547     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.901    |
| time/               |          |
|    episodes         | 4108     |
|    fps              | 34       |
|    time_elapsed     | 2171     |
|    total_timesteps  | 74269    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.82e-05 |
|    n_updates        | 8567     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0275   |
|    exploration_rate | 0.901    |
| time/               |          |
|    episodes         | 4112     |
|    fps              | 34       |
|    time_elapsed     | 2172     |
|    total_timesteps  | 74345    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.15e-05 |
|    n_updates        | 8586     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 4116     |
|    fps              | 34       |
|    time_elapsed     | 2172     |
|    total_timesteps  | 74434    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.91e-05 |
|    n_updates        | 8608     |
----------------------------------
Eval num_timesteps=74500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.9      |
| time/               |          |
|    total_timesteps  | 74500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.74e-05 |
|    n_updates        | 8624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0067   |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 4120     |
|    fps              | 34       |
|    time_elapsed     | 2185     |
|    total_timesteps  | 74510    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.4e-05  |
|    n_updates        | 8627     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00343 |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 4124     |
|    fps              | 34       |
|    time_elapsed     | 2185     |
|    total_timesteps  | 74581    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.59e-05 |
|    n_updates        | 8645     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00363 |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 4128     |
|    fps              | 34       |
|    time_elapsed     | 2185     |
|    total_timesteps  | 74650    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.27e-05 |
|    n_updates        | 8662     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00387 |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 4132     |
|    fps              | 34       |
|    time_elapsed     | 2186     |
|    total_timesteps  | 74727    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.47e-05 |
|    n_updates        | 8681     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00372 |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 4136     |
|    fps              | 34       |
|    time_elapsed     | 2186     |
|    total_timesteps  | 74802    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.38e-05 |
|    n_updates        | 8700     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 4140     |
|    fps              | 34       |
|    time_elapsed     | 2186     |
|    total_timesteps  | 74890    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.8e-05  |
|    n_updates        | 8722     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0245  |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 4144     |
|    fps              | 34       |
|    time_elapsed     | 2187     |
|    total_timesteps  | 74962    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.19e-05 |
|    n_updates        | 8740     |
----------------------------------
Eval num_timesteps=75000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.898    |
| time/               |          |
|    total_timesteps  | 75000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00727  |
|    n_updates        | 8749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00451 |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 4148     |
|    fps              | 34       |
|    time_elapsed     | 2199     |
|    total_timesteps  | 75041    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.22e-05 |
|    n_updates        | 8760     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00562  |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 4152     |
|    fps              | 34       |
|    time_elapsed     | 2199     |
|    total_timesteps  | 75108    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00771  |
|    n_updates        | 8776     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 4156     |
|    fps              | 34       |
|    time_elapsed     | 2200     |
|    total_timesteps  | 75182    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.22e-05 |
|    n_updates        | 8795     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 4160     |
|    fps              | 34       |
|    time_elapsed     | 2200     |
|    total_timesteps  | 75255    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.1e-05  |
|    n_updates        | 8813     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00559  |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 4164     |
|    fps              | 34       |
|    time_elapsed     | 2200     |
|    total_timesteps  | 75325    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.45e-05 |
|    n_updates        | 8831     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00531  |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 4168     |
|    fps              | 34       |
|    time_elapsed     | 2201     |
|    total_timesteps  | 75404    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00726  |
|    n_updates        | 8850     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00531  |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 4172     |
|    fps              | 34       |
|    time_elapsed     | 2201     |
|    total_timesteps  | 75476    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.2e-05  |
|    n_updates        | 8868     |
----------------------------------
Eval num_timesteps=75500, episode_reward=-0.23 +/- 0.10
Episode length: 58.20 +/- 25.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.2     |
|    mean_reward      | -0.233   |
| rollout/            |          |
|    exploration_rate | 0.896    |
| time/               |          |
|    total_timesteps  | 75500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.9e-05  |
|    n_updates        | 8874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00487  |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 4176     |
|    fps              | 34       |
|    time_elapsed     | 2213     |
|    total_timesteps  | 75557    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.78e-05 |
|    n_updates        | 8889     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00515  |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 4180     |
|    fps              | 34       |
|    time_elapsed     | 2214     |
|    total_timesteps  | 75628    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.78e-05 |
|    n_updates        | 8906     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0149   |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 4184     |
|    fps              | 34       |
|    time_elapsed     | 2214     |
|    total_timesteps  | 75709    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.38e-05 |
|    n_updates        | 8927     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.0148   |
|    exploration_rate | 0.894    |
| time/               |          |
|    episodes         | 4188     |
|    fps              | 34       |
|    time_elapsed     | 2214     |
|    total_timesteps  | 75782    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.34e-05 |
|    n_updates        | 8945     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.894    |
| time/               |          |
|    episodes         | 4192     |
|    fps              | 34       |
|    time_elapsed     | 2215     |
|    total_timesteps  | 75854    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.96e-05 |
|    n_updates        | 8963     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.894    |
| time/               |          |
|    episodes         | 4196     |
|    fps              | 34       |
|    time_elapsed     | 2215     |
|    total_timesteps  | 75932    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00746  |
|    n_updates        | 8982     |
----------------------------------
Eval num_timesteps=76000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.893    |
| time/               |          |
|    total_timesteps  | 76000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.17e-05 |
|    n_updates        | 8999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0257   |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 4200     |
|    fps              | 34       |
|    time_elapsed     | 2230     |
|    total_timesteps  | 76008    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.39e-05 |
|    n_updates        | 9001     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0355   |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 4204     |
|    fps              | 34       |
|    time_elapsed     | 2231     |
|    total_timesteps  | 76080    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.69e-05 |
|    n_updates        | 9019     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.036    |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 4208     |
|    fps              | 34       |
|    time_elapsed     | 2231     |
|    total_timesteps  | 76146    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00729  |
|    n_updates        | 9036     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0565   |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 4212     |
|    fps              | 34       |
|    time_elapsed     | 2232     |
|    total_timesteps  | 76210    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.69e-05 |
|    n_updates        | 9052     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0574   |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 4216     |
|    fps              | 34       |
|    time_elapsed     | 2232     |
|    total_timesteps  | 76277    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00727  |
|    n_updates        | 9069     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0678   |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 4220     |
|    fps              | 34       |
|    time_elapsed     | 2232     |
|    total_timesteps  | 76343    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.38e-05 |
|    n_updates        | 9085     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0681   |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 4224     |
|    fps              | 34       |
|    time_elapsed     | 2232     |
|    total_timesteps  | 76407    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.03e-05 |
|    n_updates        | 9101     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0481   |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 4228     |
|    fps              | 34       |
|    time_elapsed     | 2233     |
|    total_timesteps  | 76476    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.34e-05 |
|    n_updates        | 9118     |
----------------------------------
Eval num_timesteps=76500, episode_reward=-0.26 +/- 0.17
Episode length: 69.80 +/- 14.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.8     |
|    mean_reward      | -0.259   |
| rollout/            |          |
|    exploration_rate | 0.891    |
| time/               |          |
|    total_timesteps  | 76500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00739  |
|    n_updates        | 9124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0476   |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 4232     |
|    fps              | 34       |
|    time_elapsed     | 2244     |
|    total_timesteps  | 76565    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.83e-05 |
|    n_updates        | 9141     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 4236     |
|    fps              | 34       |
|    time_elapsed     | 2244     |
|    total_timesteps  | 76638    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.68e-05 |
|    n_updates        | 9159     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 4240     |
|    fps              | 34       |
|    time_elapsed     | 2245     |
|    total_timesteps  | 76727    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00734  |
|    n_updates        | 9181     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 4244     |
|    fps              | 34       |
|    time_elapsed     | 2245     |
|    total_timesteps  | 76794    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.52e-05 |
|    n_updates        | 9198     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.889    |
| time/               |          |
|    episodes         | 4248     |
|    fps              | 34       |
|    time_elapsed     | 2245     |
|    total_timesteps  | 76891    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.15e-05 |
|    n_updates        | 9222     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0167   |
|    exploration_rate | 0.889    |
| time/               |          |
|    episodes         | 4252     |
|    fps              | 34       |
|    time_elapsed     | 2246     |
|    total_timesteps  | 76970    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.06e-05 |
|    n_updates        | 9242     |
----------------------------------
Eval num_timesteps=77000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.889    |
| time/               |          |
|    total_timesteps  | 77000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0079   |
|    n_updates        | 9249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.889    |
| time/               |          |
|    episodes         | 4256     |
|    fps              | 34       |
|    time_elapsed     | 2258     |
|    total_timesteps  | 77031    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.96e-05 |
|    n_updates        | 9257     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 4260     |
|    fps              | 34       |
|    time_elapsed     | 2258     |
|    total_timesteps  | 77097    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.93e-05 |
|    n_updates        | 9274     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 4264     |
|    fps              | 34       |
|    time_elapsed     | 2259     |
|    total_timesteps  | 77160    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00776  |
|    n_updates        | 9289     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 4268     |
|    fps              | 34       |
|    time_elapsed     | 2259     |
|    total_timesteps  | 77228    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.73e-05 |
|    n_updates        | 9306     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 4272     |
|    fps              | 34       |
|    time_elapsed     | 2260     |
|    total_timesteps  | 77306    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.58e-05 |
|    n_updates        | 9326     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 0.887    |
| time/               |          |
|    episodes         | 4276     |
|    fps              | 34       |
|    time_elapsed     | 2260     |
|    total_timesteps  | 77375    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.61e-05 |
|    n_updates        | 9343     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.887    |
| time/               |          |
|    episodes         | 4280     |
|    fps              | 34       |
|    time_elapsed     | 2260     |
|    total_timesteps  | 77458    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0144   |
|    n_updates        | 9364     |
----------------------------------
Eval num_timesteps=77500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.887    |
| time/               |          |
|    total_timesteps  | 77500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.54e-05 |
|    n_updates        | 9374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 4284     |
|    fps              | 34       |
|    time_elapsed     | 2273     |
|    total_timesteps  | 77536    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00705  |
|    n_updates        | 9383     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0387   |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 4288     |
|    fps              | 34       |
|    time_elapsed     | 2273     |
|    total_timesteps  | 77593    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 9398     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0385   |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 4292     |
|    fps              | 34       |
|    time_elapsed     | 2273     |
|    total_timesteps  | 77669    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.64e-05 |
|    n_updates        | 9417     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 4296     |
|    fps              | 34       |
|    time_elapsed     | 2274     |
|    total_timesteps  | 77759    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00792  |
|    n_updates        | 9439     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 4300     |
|    fps              | 34       |
|    time_elapsed     | 2274     |
|    total_timesteps  | 77828    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.79e-05 |
|    n_updates        | 9456     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 4304     |
|    fps              | 34       |
|    time_elapsed     | 2274     |
|    total_timesteps  | 77901    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.87e-05 |
|    n_updates        | 9475     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 4308     |
|    fps              | 34       |
|    time_elapsed     | 2275     |
|    total_timesteps  | 77967    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.38e-05 |
|    n_updates        | 9491     |
----------------------------------
Eval num_timesteps=78000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.884    |
| time/               |          |
|    total_timesteps  | 78000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.68e-05 |
|    n_updates        | 9499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00738  |
|    exploration_rate | 0.884    |
| time/               |          |
|    episodes         | 4312     |
|    fps              | 34       |
|    time_elapsed     | 2290     |
|    total_timesteps  | 78052    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.015    |
|    n_updates        | 9512     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0172   |
|    exploration_rate | 0.884    |
| time/               |          |
|    episodes         | 4316     |
|    fps              | 34       |
|    time_elapsed     | 2290     |
|    total_timesteps  | 78123    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.54e-05 |
|    n_updates        | 9530     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.884    |
| time/               |          |
|    episodes         | 4320     |
|    fps              | 34       |
|    time_elapsed     | 2291     |
|    total_timesteps  | 78185    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.63e-05 |
|    n_updates        | 9546     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 4324     |
|    fps              | 34       |
|    time_elapsed     | 2291     |
|    total_timesteps  | 78261    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.18e-05 |
|    n_updates        | 9565     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 4328     |
|    fps              | 34       |
|    time_elapsed     | 2291     |
|    total_timesteps  | 78319    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.94e-05 |
|    n_updates        | 9579     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 4332     |
|    fps              | 34       |
|    time_elapsed     | 2292     |
|    total_timesteps  | 78386    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.73e-05 |
|    n_updates        | 9596     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0483   |
|    exploration_rate | 0.882    |
| time/               |          |
|    episodes         | 4336     |
|    fps              | 34       |
|    time_elapsed     | 2292     |
|    total_timesteps  | 78458    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.83e-05 |
|    n_updates        | 9614     |
----------------------------------
Eval num_timesteps=78500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.882    |
| time/               |          |
|    total_timesteps  | 78500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 9624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0488   |
|    exploration_rate | 0.882    |
| time/               |          |
|    episodes         | 4340     |
|    fps              | 34       |
|    time_elapsed     | 2308     |
|    total_timesteps  | 78535    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.71e-05 |
|    n_updates        | 9633     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0484   |
|    exploration_rate | 0.882    |
| time/               |          |
|    episodes         | 4344     |
|    fps              | 34       |
|    time_elapsed     | 2308     |
|    total_timesteps  | 78610    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.68e-05 |
|    n_updates        | 9652     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 4348     |
|    fps              | 34       |
|    time_elapsed     | 2309     |
|    total_timesteps  | 78684    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.67e-05 |
|    n_updates        | 9670     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 4352     |
|    fps              | 34       |
|    time_elapsed     | 2309     |
|    total_timesteps  | 78753    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.08e-05 |
|    n_updates        | 9688     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 4356     |
|    fps              | 34       |
|    time_elapsed     | 2309     |
|    total_timesteps  | 78830    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.14e-05 |
|    n_updates        | 9707     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 4360     |
|    fps              | 34       |
|    time_elapsed     | 2310     |
|    total_timesteps  | 78916    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00705  |
|    n_updates        | 9728     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00788  |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 4364     |
|    fps              | 34       |
|    time_elapsed     | 2310     |
|    total_timesteps  | 78989    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 9747     |
----------------------------------
Eval num_timesteps=79000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.88     |
| time/               |          |
|    total_timesteps  | 79000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.67e-05 |
|    n_updates        | 9749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00792  |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 4368     |
|    fps              | 34       |
|    time_elapsed     | 2322     |
|    total_timesteps  | 79056    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.1e-05  |
|    n_updates        | 9763     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 4372     |
|    fps              | 34       |
|    time_elapsed     | 2322     |
|    total_timesteps  | 79128    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.04e-05 |
|    n_updates        | 9781     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0284   |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 4376     |
|    fps              | 34       |
|    time_elapsed     | 2323     |
|    total_timesteps  | 79191    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00729  |
|    n_updates        | 9797     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0393   |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 4380     |
|    fps              | 34       |
|    time_elapsed     | 2323     |
|    total_timesteps  | 79252    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.74e-05 |
|    n_updates        | 9812     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0394   |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 4384     |
|    fps              | 34       |
|    time_elapsed     | 2323     |
|    total_timesteps  | 79327    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.64e-05 |
|    n_updates        | 9831     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0191   |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 4388     |
|    fps              | 34       |
|    time_elapsed     | 2324     |
|    total_timesteps  | 79390    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.13e-05 |
|    n_updates        | 9847     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0297   |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 4392     |
|    fps              | 34       |
|    time_elapsed     | 2324     |
|    total_timesteps  | 79452    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.46e-05 |
|    n_updates        | 9862     |
----------------------------------
Eval num_timesteps=79500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.877    |
| time/               |          |
|    total_timesteps  | 79500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.27e-05 |
|    n_updates        | 9874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0407   |
|    exploration_rate | 0.877    |
| time/               |          |
|    episodes         | 4396     |
|    fps              | 33       |
|    time_elapsed     | 2339     |
|    total_timesteps  | 79518    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0151   |
|    n_updates        | 9879     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0298   |
|    exploration_rate | 0.877    |
| time/               |          |
|    episodes         | 4400     |
|    fps              | 34       |
|    time_elapsed     | 2340     |
|    total_timesteps  | 79610    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.21e-05 |
|    n_updates        | 9902     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0297   |
|    exploration_rate | 0.877    |
| time/               |          |
|    episodes         | 4404     |
|    fps              | 34       |
|    time_elapsed     | 2340     |
|    total_timesteps  | 79685    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000107 |
|    n_updates        | 9921     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 4408     |
|    fps              | 34       |
|    time_elapsed     | 2340     |
|    total_timesteps  | 79754    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.24e-05 |
|    n_updates        | 9938     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0404   |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 4412     |
|    fps              | 34       |
|    time_elapsed     | 2341     |
|    total_timesteps  | 79819    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.32e-05 |
|    n_updates        | 9954     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0306   |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 4416     |
|    fps              | 34       |
|    time_elapsed     | 2341     |
|    total_timesteps  | 79883    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.89e-05 |
|    n_updates        | 9970     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0204   |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 4420     |
|    fps              | 34       |
|    time_elapsed     | 2342     |
|    total_timesteps  | 79950    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00717  |
|    n_updates        | 9987     |
----------------------------------
Eval num_timesteps=80000, episode_reward=-0.25 +/- 0.08
Episode length: 63.78 +/- 20.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.8     |
|    mean_reward      | -0.255   |
| rollout/            |          |
|    exploration_rate | 0.875    |
| time/               |          |
|    total_timesteps  | 80000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000121 |
|    n_updates        | 9999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 4424     |
|    fps              | 33       |
|    time_elapsed     | 2355     |
|    total_timesteps  | 80024    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.17e-05 |
|    n_updates        | 10005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 9e-05    |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 4428     |
|    fps              | 33       |
|    time_elapsed     | 2355     |
|    total_timesteps  | 80092    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.37e-05 |
|    n_updates        | 10022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0102   |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 4432     |
|    fps              | 34       |
|    time_elapsed     | 2356     |
|    total_timesteps  | 80156    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.69e-05 |
|    n_updates        | 10038    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.00018 |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 4436     |
|    fps              | 34       |
|    time_elapsed     | 2356     |
|    total_timesteps  | 80238    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.11e-05 |
|    n_updates        | 10059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.00018  |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 4440     |
|    fps              | 34       |
|    time_elapsed     | 2356     |
|    total_timesteps  | 80306    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.4e-05  |
|    n_updates        | 10076    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0007   |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 4444     |
|    fps              | 34       |
|    time_elapsed     | 2357     |
|    total_timesteps  | 80368    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.44e-05 |
|    n_updates        | 10091    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0107   |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 4448     |
|    fps              | 34       |
|    time_elapsed     | 2357     |
|    total_timesteps  | 80443    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.3e-05  |
|    n_updates        | 10110    |
----------------------------------
Eval num_timesteps=80500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.873    |
| time/               |          |
|    total_timesteps  | 80500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.91e-05 |
|    n_updates        | 10124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0095   |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 4452     |
|    fps              | 33       |
|    time_elapsed     | 2369     |
|    total_timesteps  | 80541    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.86e-05 |
|    n_updates        | 10135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 4456     |
|    fps              | 34       |
|    time_elapsed     | 2370     |
|    total_timesteps  | 80612    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00695  |
|    n_updates        | 10152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 4460     |
|    fps              | 34       |
|    time_elapsed     | 2370     |
|    total_timesteps  | 80681    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0145   |
|    n_updates        | 10170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0298   |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 4464     |
|    fps              | 34       |
|    time_elapsed     | 2371     |
|    total_timesteps  | 80770    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.99e-05 |
|    n_updates        | 10192    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0295   |
|    exploration_rate | 0.871    |
| time/               |          |
|    episodes         | 4468     |
|    fps              | 34       |
|    time_elapsed     | 2371     |
|    total_timesteps  | 80845    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.25e-05 |
|    n_updates        | 10211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00848  |
|    exploration_rate | 0.871    |
| time/               |          |
|    episodes         | 4472     |
|    fps              | 34       |
|    time_elapsed     | 2371     |
|    total_timesteps  | 80942    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.05e-05 |
|    n_updates        | 10235    |
----------------------------------
Eval num_timesteps=81000, episode_reward=-0.00 +/- 0.24
Episode length: 15.44 +/- 1.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.4     |
|    mean_reward      | -0.00076 |
| rollout/            |          |
|    exploration_rate | 0.87     |
| time/               |          |
|    total_timesteps  | 81000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0073   |
|    n_updates        | 10249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00812  |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 4476     |
|    fps              | 34       |
|    time_elapsed     | 2375     |
|    total_timesteps  | 81014    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 10253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00709  |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 4480     |
|    fps              | 34       |
|    time_elapsed     | 2376     |
|    total_timesteps  | 81101    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0072   |
|    n_updates        | 10275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00677  |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 4484     |
|    fps              | 34       |
|    time_elapsed     | 2376     |
|    total_timesteps  | 81184    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.3e-05  |
|    n_updates        | 10295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.869    |
| time/               |          |
|    episodes         | 4488     |
|    fps              | 34       |
|    time_elapsed     | 2377     |
|    total_timesteps  | 81259    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.51e-05 |
|    n_updates        | 10314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0058   |
|    exploration_rate | 0.869    |
| time/               |          |
|    episodes         | 4492     |
|    fps              | 34       |
|    time_elapsed     | 2377     |
|    total_timesteps  | 81333    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.77e-05 |
|    n_updates        | 10333    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00473 |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 4496     |
|    fps              | 34       |
|    time_elapsed     | 2377     |
|    total_timesteps  | 81412    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.89e-05 |
|    n_updates        | 10352    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00365 |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 4500     |
|    fps              | 34       |
|    time_elapsed     | 2378     |
|    total_timesteps  | 81477    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 10369    |
----------------------------------
Eval num_timesteps=81500, episode_reward=-0.30 +/- 0.03
Episode length: 73.92 +/- 7.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.868    |
| time/               |          |
|    total_timesteps  | 81500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.61e-05 |
|    n_updates        | 10374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00361 |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 4504     |
|    fps              | 34       |
|    time_elapsed     | 2393     |
|    total_timesteps  | 81551    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.95e-05 |
|    n_updates        | 10387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.867    |
| time/               |          |
|    episodes         | 4508     |
|    fps              | 34       |
|    time_elapsed     | 2393     |
|    total_timesteps  | 81634    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.93e-05 |
|    n_updates        | 10408    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.867    |
| time/               |          |
|    episodes         | 4512     |
|    fps              | 34       |
|    time_elapsed     | 2394     |
|    total_timesteps  | 81717    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.8e-05  |
|    n_updates        | 10429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00456 |
|    exploration_rate | 0.867    |
| time/               |          |
|    episodes         | 4516     |
|    fps              | 34       |
|    time_elapsed     | 2394     |
|    total_timesteps  | 81773    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.93e-05 |
|    n_updates        | 10443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00448 |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 4520     |
|    fps              | 34       |
|    time_elapsed     | 2394     |
|    total_timesteps  | 81838    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.19e-05 |
|    n_updates        | 10459    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00464 |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 4524     |
|    fps              | 34       |
|    time_elapsed     | 2395     |
|    total_timesteps  | 81916    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.07e-05 |
|    n_updates        | 10478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00522  |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 4528     |
|    fps              | 34       |
|    time_elapsed     | 2395     |
|    total_timesteps  | 81988    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.99e-05 |
|    n_updates        | 10496    |
----------------------------------
Eval num_timesteps=82000, episode_reward=-0.07 +/- 0.31
Episode length: 38.30 +/- 24.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.3     |
|    mean_reward      | -0.0724  |
| rollout/            |          |
|    exploration_rate | 0.866    |
| time/               |          |
|    total_timesteps  | 82000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.63e-05 |
|    n_updates        | 10499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.00528 |
|    exploration_rate | 0.865    |
| time/               |          |
|    episodes         | 4532     |
|    fps              | 34       |
|    time_elapsed     | 2402     |
|    total_timesteps  | 82064    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00701  |
|    n_updates        | 10515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00488 |
|    exploration_rate | 0.865    |
| time/               |          |
|    episodes         | 4536     |
|    fps              | 34       |
|    time_elapsed     | 2402     |
|    total_timesteps  | 82136    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00727  |
|    n_updates        | 10533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00508 |
|    exploration_rate | 0.865    |
| time/               |          |
|    episodes         | 4540     |
|    fps              | 34       |
|    time_elapsed     | 2403     |
|    total_timesteps  | 82209    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00723  |
|    n_updates        | 10552    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0064  |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 4544     |
|    fps              | 34       |
|    time_elapsed     | 2403     |
|    total_timesteps  | 82304    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 10575    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0161  |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 4548     |
|    fps              | 34       |
|    time_elapsed     | 2404     |
|    total_timesteps  | 82371    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 10592    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00552  |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 4552     |
|    fps              | 34       |
|    time_elapsed     | 2404     |
|    total_timesteps  | 82429    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.05e-05 |
|    n_updates        | 10607    |
----------------------------------
Eval num_timesteps=82500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.863    |
| time/               |          |
|    total_timesteps  | 82500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.46e-05 |
|    n_updates        | 10624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00524  |
|    exploration_rate | 0.863    |
| time/               |          |
|    episodes         | 4556     |
|    fps              | 34       |
|    time_elapsed     | 2416     |
|    total_timesteps  | 82507    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.47e-05 |
|    n_updates        | 10626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00492 |
|    exploration_rate | 0.863    |
| time/               |          |
|    episodes         | 4560     |
|    fps              | 34       |
|    time_elapsed     | 2416     |
|    total_timesteps  | 82580    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.5e-05  |
|    n_updates        | 10644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00508 |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 4564     |
|    fps              | 34       |
|    time_elapsed     | 2417     |
|    total_timesteps  | 82673    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.19e-05 |
|    n_updates        | 10668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00488 |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 4568     |
|    fps              | 34       |
|    time_elapsed     | 2417     |
|    total_timesteps  | 82743    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.61e-05 |
|    n_updates        | 10685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0036  |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 4572     |
|    fps              | 34       |
|    time_elapsed     | 2417     |
|    total_timesteps  | 82808    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00708  |
|    n_updates        | 10701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00626  |
|    exploration_rate | 0.861    |
| time/               |          |
|    episodes         | 4576     |
|    fps              | 34       |
|    time_elapsed     | 2418     |
|    total_timesteps  | 82884    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.4e-05  |
|    n_updates        | 10720    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.861    |
| time/               |          |
|    episodes         | 4580     |
|    fps              | 34       |
|    time_elapsed     | 2418     |
|    total_timesteps  | 82943    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 10735    |
----------------------------------
Eval num_timesteps=83000, episode_reward=-0.05 +/- 0.14
Episode length: 18.90 +/- 0.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.9     |
|    mean_reward      | -0.0546  |
| rollout/            |          |
|    exploration_rate | 0.861    |
| time/               |          |
|    total_timesteps  | 83000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.58e-05 |
|    n_updates        | 10749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.861    |
| time/               |          |
|    episodes         | 4584     |
|    fps              | 34       |
|    time_elapsed     | 2423     |
|    total_timesteps  | 83022    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.51e-05 |
|    n_updates        | 10755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00769  |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 4588     |
|    fps              | 34       |
|    time_elapsed     | 2423     |
|    total_timesteps  | 83093    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.45e-05 |
|    n_updates        | 10773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.00805  |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 4592     |
|    fps              | 34       |
|    time_elapsed     | 2424     |
|    total_timesteps  | 83158    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.91e-05 |
|    n_updates        | 10789    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0183   |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 4596     |
|    fps              | 34       |
|    time_elapsed     | 2424     |
|    total_timesteps  | 83230    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0149   |
|    n_updates        | 10807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.859    |
| time/               |          |
|    episodes         | 4600     |
|    fps              | 34       |
|    time_elapsed     | 2425     |
|    total_timesteps  | 83316    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.72e-05 |
|    n_updates        | 10828    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.859    |
| time/               |          |
|    episodes         | 4604     |
|    fps              | 34       |
|    time_elapsed     | 2425     |
|    total_timesteps  | 83408    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.42e-05 |
|    n_updates        | 10851    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.858    |
| time/               |          |
|    episodes         | 4608     |
|    fps              | 34       |
|    time_elapsed     | 2425     |
|    total_timesteps  | 83478    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.41e-05 |
|    n_updates        | 10869    |
----------------------------------
Eval num_timesteps=83500, episode_reward=-0.01 +/- 0.28
Episode length: 22.56 +/- 7.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22.6     |
|    mean_reward      | -0.00912 |
| rollout/            |          |
|    exploration_rate | 0.858    |
| time/               |          |
|    total_timesteps  | 83500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.52e-05 |
|    n_updates        | 10874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0372   |
|    exploration_rate | 0.858    |
| time/               |          |
|    episodes         | 4612     |
|    fps              | 34       |
|    time_elapsed     | 2431     |
|    total_timesteps  | 83563    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.1e-05  |
|    n_updates        | 10890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0263   |
|    exploration_rate | 0.858    |
| time/               |          |
|    episodes         | 4616     |
|    fps              | 34       |
|    time_elapsed     | 2431     |
|    total_timesteps  | 83641    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 10910    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0261   |
|    exploration_rate | 0.857    |
| time/               |          |
|    episodes         | 4620     |
|    fps              | 34       |
|    time_elapsed     | 2431     |
|    total_timesteps  | 83711    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00703  |
|    n_updates        | 10927    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0264   |
|    exploration_rate | 0.857    |
| time/               |          |
|    episodes         | 4624     |
|    fps              | 34       |
|    time_elapsed     | 2432     |
|    total_timesteps  | 83783    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.04e-05 |
|    n_updates        | 10945    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0167   |
|    exploration_rate | 0.857    |
| time/               |          |
|    episodes         | 4628     |
|    fps              | 34       |
|    time_elapsed     | 2432     |
|    total_timesteps  | 83846    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00712  |
|    n_updates        | 10961    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0269   |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 4632     |
|    fps              | 34       |
|    time_elapsed     | 2433     |
|    total_timesteps  | 83917    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.21e-05 |
|    n_updates        | 10979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0374   |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 4636     |
|    fps              | 34       |
|    time_elapsed     | 2433     |
|    total_timesteps  | 83977    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.85e-05 |
|    n_updates        | 10994    |
----------------------------------
Eval num_timesteps=84000, episode_reward=-0.02 +/- 0.24
Episode length: 20.52 +/- 2.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20.5     |
|    mean_reward      | -0.0211  |
| rollout/            |          |
|    exploration_rate | 0.856    |
| time/               |          |
|    total_timesteps  | 84000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00749  |
|    n_updates        | 10999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 4640     |
|    fps              | 34       |
|    time_elapsed     | 2438     |
|    total_timesteps  | 84053    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.61e-05 |
|    n_updates        | 11013    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.855    |
| time/               |          |
|    episodes         | 4644     |
|    fps              | 34       |
|    time_elapsed     | 2439     |
|    total_timesteps  | 84121    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.92e-05 |
|    n_updates        | 11030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0381   |
|    exploration_rate | 0.855    |
| time/               |          |
|    episodes         | 4648     |
|    fps              | 34       |
|    time_elapsed     | 2439     |
|    total_timesteps  | 84195    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.6e-05  |
|    n_updates        | 11048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 0.855    |
| time/               |          |
|    episodes         | 4652     |
|    fps              | 34       |
|    time_elapsed     | 2439     |
|    total_timesteps  | 84256    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.87e-05 |
|    n_updates        | 11063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0284   |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 4656     |
|    fps              | 34       |
|    time_elapsed     | 2440     |
|    total_timesteps  | 84323    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.69e-05 |
|    n_updates        | 11080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0387   |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 4660     |
|    fps              | 34       |
|    time_elapsed     | 2440     |
|    total_timesteps  | 84388    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 11096    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 4664     |
|    fps              | 34       |
|    time_elapsed     | 2440     |
|    total_timesteps  | 84460    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.53e-05 |
|    n_updates        | 11114    |
----------------------------------
Eval num_timesteps=84500, episode_reward=0.03 +/- 0.43
Episode length: 37.50 +/- 20.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.5     |
|    mean_reward      | 0.031    |
| rollout/            |          |
|    exploration_rate | 0.853    |
| time/               |          |
|    total_timesteps  | 84500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.89e-05 |
|    n_updates        | 11124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 0.853    |
| time/               |          |
|    episodes         | 4668     |
|    fps              | 34       |
|    time_elapsed     | 2449     |
|    total_timesteps  | 84541    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00685  |
|    n_updates        | 11135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0385   |
|    exploration_rate | 0.853    |
| time/               |          |
|    episodes         | 4672     |
|    fps              | 34       |
|    time_elapsed     | 2449     |
|    total_timesteps  | 84621    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0221   |
|    n_updates        | 11155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0486   |
|    exploration_rate | 0.853    |
| time/               |          |
|    episodes         | 4676     |
|    fps              | 34       |
|    time_elapsed     | 2450     |
|    total_timesteps  | 84694    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000109 |
|    n_updates        | 11173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 4680     |
|    fps              | 34       |
|    time_elapsed     | 2450     |
|    total_timesteps  | 84764    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.23e-05 |
|    n_updates        | 11190    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0387   |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 4684     |
|    fps              | 34       |
|    time_elapsed     | 2451     |
|    total_timesteps  | 84830    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00695  |
|    n_updates        | 11207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0388   |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 4688     |
|    fps              | 34       |
|    time_elapsed     | 2451     |
|    total_timesteps  | 84898    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.84e-05 |
|    n_updates        | 11224    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0385   |
|    exploration_rate | 0.851    |
| time/               |          |
|    episodes         | 4692     |
|    fps              | 34       |
|    time_elapsed     | 2451     |
|    total_timesteps  | 84971    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00779  |
|    n_updates        | 11242    |
----------------------------------
Eval num_timesteps=85000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.851    |
| time/               |          |
|    total_timesteps  | 85000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0068   |
|    n_updates        | 11249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.851    |
| time/               |          |
|    episodes         | 4696     |
|    fps              | 34       |
|    time_elapsed     | 2463     |
|    total_timesteps  | 85075    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.16e-05 |
|    n_updates        | 11268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.85     |
| time/               |          |
|    episodes         | 4700     |
|    fps              | 34       |
|    time_elapsed     | 2464     |
|    total_timesteps  | 85156    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.18e-05 |
|    n_updates        | 11288    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0273   |
|    exploration_rate | 0.85     |
| time/               |          |
|    episodes         | 4704     |
|    fps              | 34       |
|    time_elapsed     | 2464     |
|    total_timesteps  | 85250    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0072   |
|    n_updates        | 11312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0264   |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 4708     |
|    fps              | 34       |
|    time_elapsed     | 2464     |
|    total_timesteps  | 85342    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0072   |
|    n_updates        | 11335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0067   |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 4712     |
|    fps              | 34       |
|    time_elapsed     | 2465     |
|    total_timesteps  | 85421    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 11355    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 4716     |
|    fps              | 34       |
|    time_elapsed     | 2465     |
|    total_timesteps  | 85489    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.6e-05  |
|    n_updates        | 11372    |
----------------------------------
Eval num_timesteps=85500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.849    |
| time/               |          |
|    total_timesteps  | 85500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.74e-05 |
|    n_updates        | 11374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.848    |
| time/               |          |
|    episodes         | 4720     |
|    fps              | 34       |
|    time_elapsed     | 2477     |
|    total_timesteps  | 85560    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.19e-05 |
|    n_updates        | 11389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.848    |
| time/               |          |
|    episodes         | 4724     |
|    fps              | 34       |
|    time_elapsed     | 2477     |
|    total_timesteps  | 85631    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.91e-05 |
|    n_updates        | 11407    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.847    |
| time/               |          |
|    episodes         | 4728     |
|    fps              | 34       |
|    time_elapsed     | 2478     |
|    total_timesteps  | 85702    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0217   |
|    n_updates        | 11425    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.847    |
| time/               |          |
|    episodes         | 4732     |
|    fps              | 34       |
|    time_elapsed     | 2478     |
|    total_timesteps  | 85772    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.39e-05 |
|    n_updates        | 11442    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00606  |
|    exploration_rate | 0.847    |
| time/               |          |
|    episodes         | 4736     |
|    fps              | 34       |
|    time_elapsed     | 2478     |
|    total_timesteps  | 85851    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.03e-05 |
|    n_updates        | 11462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.846    |
| time/               |          |
|    episodes         | 4740     |
|    fps              | 34       |
|    time_elapsed     | 2479     |
|    total_timesteps  | 85913    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.32e-05 |
|    n_updates        | 11478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.846    |
| time/               |          |
|    episodes         | 4744     |
|    fps              | 34       |
|    time_elapsed     | 2479     |
|    total_timesteps  | 85991    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.13e-05 |
|    n_updates        | 11497    |
----------------------------------
Eval num_timesteps=86000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.846    |
| time/               |          |
|    total_timesteps  | 86000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.78e-05 |
|    n_updates        | 11499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0167   |
|    exploration_rate | 0.846    |
| time/               |          |
|    episodes         | 4748     |
|    fps              | 34       |
|    time_elapsed     | 2491     |
|    total_timesteps  | 86053    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.2e-05  |
|    n_updates        | 11513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00382 |
|    exploration_rate | 0.845    |
| time/               |          |
|    episodes         | 4752     |
|    fps              | 34       |
|    time_elapsed     | 2492     |
|    total_timesteps  | 86127    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.43e-05 |
|    n_updates        | 11531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00422 |
|    exploration_rate | 0.845    |
| time/               |          |
|    episodes         | 4756     |
|    fps              | 34       |
|    time_elapsed     | 2492     |
|    total_timesteps  | 86204    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.16e-05 |
|    n_updates        | 11550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.845    |
| time/               |          |
|    episodes         | 4760     |
|    fps              | 34       |
|    time_elapsed     | 2492     |
|    total_timesteps  | 86275    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.28e-05 |
|    n_updates        | 11568    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00481 |
|    exploration_rate | 0.844    |
| time/               |          |
|    episodes         | 4764     |
|    fps              | 34       |
|    time_elapsed     | 2493     |
|    total_timesteps  | 86356    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000107 |
|    n_updates        | 11588    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00445 |
|    exploration_rate | 0.844    |
| time/               |          |
|    episodes         | 4768     |
|    fps              | 34       |
|    time_elapsed     | 2493     |
|    total_timesteps  | 86428    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000132 |
|    n_updates        | 11606    |
----------------------------------
Eval num_timesteps=86500, episode_reward=0.09 +/- 0.37
Episode length: 17.04 +/- 1.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17       |
|    mean_reward      | 0.0928   |
| rollout/            |          |
|    exploration_rate | 0.843    |
| time/               |          |
|    total_timesteps  | 86500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.94e-05 |
|    n_updates        | 11624    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00473 |
|    exploration_rate | 0.843    |
| time/               |          |
|    episodes         | 4772     |
|    fps              | 34       |
|    time_elapsed     | 2498     |
|    total_timesteps  | 86515    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.32e-05 |
|    n_updates        | 11628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0252  |
|    exploration_rate | 0.843    |
| time/               |          |
|    episodes         | 4776     |
|    fps              | 34       |
|    time_elapsed     | 2498     |
|    total_timesteps  | 86600    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.38e-05 |
|    n_updates        | 11649    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0353  |
|    exploration_rate | 0.843    |
| time/               |          |
|    episodes         | 4780     |
|    fps              | 34       |
|    time_elapsed     | 2498     |
|    total_timesteps  | 86672    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.05e-05 |
|    n_updates        | 11667    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 4784     |
|    fps              | 34       |
|    time_elapsed     | 2499     |
|    total_timesteps  | 86756    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.24e-05 |
|    n_updates        | 11688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0259  |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 4788     |
|    fps              | 34       |
|    time_elapsed     | 2499     |
|    total_timesteps  | 86820    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.02e-05 |
|    n_updates        | 11704    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 4792     |
|    fps              | 34       |
|    time_elapsed     | 2499     |
|    total_timesteps  | 86889    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.45e-05 |
|    n_updates        | 11722    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0153  |
|    exploration_rate | 0.841    |
| time/               |          |
|    episodes         | 4796     |
|    fps              | 34       |
|    time_elapsed     | 2500     |
|    total_timesteps  | 86982    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00763  |
|    n_updates        | 11745    |
----------------------------------
Eval num_timesteps=87000, episode_reward=-0.11 +/- 0.30
Episode length: 48.82 +/- 20.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.8     |
|    mean_reward      | -0.114   |
| rollout/            |          |
|    exploration_rate | 0.841    |
| time/               |          |
|    total_timesteps  | 87000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.78e-05 |
|    n_updates        | 11749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0147  |
|    exploration_rate | 0.841    |
| time/               |          |
|    episodes         | 4800     |
|    fps              | 34       |
|    time_elapsed     | 2510     |
|    total_timesteps  | 87050    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00718  |
|    n_updates        | 11762    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0147  |
|    exploration_rate | 0.84     |
| time/               |          |
|    episodes         | 4804     |
|    fps              | 34       |
|    time_elapsed     | 2511     |
|    total_timesteps  | 87143    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.44e-05 |
|    n_updates        | 11785    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.84     |
| time/               |          |
|    episodes         | 4808     |
|    fps              | 34       |
|    time_elapsed     | 2511     |
|    total_timesteps  | 87213    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00766  |
|    n_updates        | 11803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00303 |
|    exploration_rate | 0.84     |
| time/               |          |
|    episodes         | 4812     |
|    fps              | 34       |
|    time_elapsed     | 2512     |
|    total_timesteps  | 87272    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.31e-05 |
|    n_updates        | 11817    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.839    |
| time/               |          |
|    episodes         | 4816     |
|    fps              | 34       |
|    time_elapsed     | 2512     |
|    total_timesteps  | 87353    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.52e-05 |
|    n_updates        | 11838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.839    |
| time/               |          |
|    episodes         | 4820     |
|    fps              | 34       |
|    time_elapsed     | 2512     |
|    total_timesteps  | 87427    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.82e-05 |
|    n_updates        | 11856    |
----------------------------------
Eval num_timesteps=87500, episode_reward=0.04 +/- 0.41
Episode length: 35.02 +/- 20.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 35       |
|    mean_reward      | 0.041    |
| rollout/            |          |
|    exploration_rate | 0.838    |
| time/               |          |
|    total_timesteps  | 87500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.66e-05 |
|    n_updates        | 11874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.014   |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 4824     |
|    fps              | 34       |
|    time_elapsed     | 2521     |
|    total_timesteps  | 87506    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.63e-05 |
|    n_updates        | 11876    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00378 |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 4828     |
|    fps              | 34       |
|    time_elapsed     | 2521     |
|    total_timesteps  | 87572    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.73e-05 |
|    n_updates        | 11892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 4832     |
|    fps              | 34       |
|    time_elapsed     | 2521     |
|    total_timesteps  | 87654    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.52e-05 |
|    n_updates        | 11913    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.837    |
| time/               |          |
|    episodes         | 4836     |
|    fps              | 34       |
|    time_elapsed     | 2522     |
|    total_timesteps  | 87732    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0077   |
|    n_updates        | 11932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0151  |
|    exploration_rate | 0.837    |
| time/               |          |
|    episodes         | 4840     |
|    fps              | 34       |
|    time_elapsed     | 2522     |
|    total_timesteps  | 87816    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.03e-05 |
|    n_updates        | 11953    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0151  |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 4844     |
|    fps              | 34       |
|    time_elapsed     | 2523     |
|    total_timesteps  | 87893    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00731  |
|    n_updates        | 11973    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0155  |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 4848     |
|    fps              | 34       |
|    time_elapsed     | 2523     |
|    total_timesteps  | 87966    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.53e-05 |
|    n_updates        | 11991    |
----------------------------------
Eval num_timesteps=88000, episode_reward=-0.06 +/- 0.30
Episode length: 35.18 +/- 19.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 35.2     |
|    mean_reward      | -0.0598  |
| rollout/            |          |
|    exploration_rate | 0.836    |
| time/               |          |
|    total_timesteps  | 88000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.62e-05 |
|    n_updates        | 11999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00513 |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 4852     |
|    fps              | 34       |
|    time_elapsed     | 2531     |
|    total_timesteps  | 88030    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.14e-05 |
|    n_updates        | 12007    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 4856     |
|    fps              | 34       |
|    time_elapsed     | 2531     |
|    total_timesteps  | 88095    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.95e-05 |
|    n_updates        | 12023    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0349   |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 4860     |
|    fps              | 34       |
|    time_elapsed     | 2532     |
|    total_timesteps  | 88177    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.43e-05 |
|    n_updates        | 12044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0254   |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 4864     |
|    fps              | 34       |
|    time_elapsed     | 2532     |
|    total_timesteps  | 88245    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0072   |
|    n_updates        | 12061    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.0245   |
|    exploration_rate | 0.834    |
| time/               |          |
|    episodes         | 4868     |
|    fps              | 34       |
|    time_elapsed     | 2533     |
|    total_timesteps  | 88339    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.5e-05  |
|    n_updates        | 12084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0251   |
|    exploration_rate | 0.834    |
| time/               |          |
|    episodes         | 4872     |
|    fps              | 34       |
|    time_elapsed     | 2533     |
|    total_timesteps  | 88411    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00736  |
|    n_updates        | 12102    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0356   |
|    exploration_rate | 0.833    |
| time/               |          |
|    episodes         | 4876     |
|    fps              | 34       |
|    time_elapsed     | 2533     |
|    total_timesteps  | 88486    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.015    |
|    n_updates        | 12121    |
----------------------------------
Eval num_timesteps=88500, episode_reward=0.09 +/- 0.37
Episode length: 17.34 +/- 1.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.3     |
|    mean_reward      | 0.0917   |
| rollout/            |          |
|    exploration_rate | 0.833    |
| time/               |          |
|    total_timesteps  | 88500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 12124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.035    |
|    exploration_rate | 0.833    |
| time/               |          |
|    episodes         | 4880     |
|    fps              | 34       |
|    time_elapsed     | 2538     |
|    total_timesteps  | 88571    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00723  |
|    n_updates        | 12142    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0356   |
|    exploration_rate | 0.833    |
| time/               |          |
|    episodes         | 4884     |
|    fps              | 34       |
|    time_elapsed     | 2538     |
|    total_timesteps  | 88641    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.73e-05 |
|    n_updates        | 12160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.832    |
| time/               |          |
|    episodes         | 4888     |
|    fps              | 34       |
|    time_elapsed     | 2539     |
|    total_timesteps  | 88713    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.18e-05 |
|    n_updates        | 12178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0453   |
|    exploration_rate | 0.832    |
| time/               |          |
|    episodes         | 4892     |
|    fps              | 34       |
|    time_elapsed     | 2539     |
|    total_timesteps  | 88782    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.18e-05 |
|    n_updates        | 12195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0455   |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 4896     |
|    fps              | 34       |
|    time_elapsed     | 2539     |
|    total_timesteps  | 88870    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.87e-05 |
|    n_updates        | 12217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.0445   |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 4900     |
|    fps              | 35       |
|    time_elapsed     | 2540     |
|    total_timesteps  | 88963    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00757  |
|    n_updates        | 12240    |
----------------------------------
Eval num_timesteps=89000, episode_reward=-0.28 +/- 0.06
Episode length: 69.62 +/- 16.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.6     |
|    mean_reward      | -0.278   |
| rollout/            |          |
|    exploration_rate | 0.831    |
| time/               |          |
|    total_timesteps  | 89000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.44e-05 |
|    n_updates        | 12249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0455   |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 4904     |
|    fps              | 34       |
|    time_elapsed     | 2555     |
|    total_timesteps  | 89033    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.13e-05 |
|    n_updates        | 12258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0552   |
|    exploration_rate | 0.83     |
| time/               |          |
|    episodes         | 4908     |
|    fps              | 34       |
|    time_elapsed     | 2555     |
|    total_timesteps  | 89111    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.68e-05 |
|    n_updates        | 12277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.0447   |
|    exploration_rate | 0.83     |
| time/               |          |
|    episodes         | 4912     |
|    fps              | 34       |
|    time_elapsed     | 2555     |
|    total_timesteps  | 89181    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.39e-05 |
|    n_updates        | 12295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0442   |
|    exploration_rate | 0.829    |
| time/               |          |
|    episodes         | 4916     |
|    fps              | 34       |
|    time_elapsed     | 2556     |
|    total_timesteps  | 89274    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00746  |
|    n_updates        | 12318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0442   |
|    exploration_rate | 0.829    |
| time/               |          |
|    episodes         | 4920     |
|    fps              | 34       |
|    time_elapsed     | 2556     |
|    total_timesteps  | 89349    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00726  |
|    n_updates        | 12337    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0442   |
|    exploration_rate | 0.828    |
| time/               |          |
|    episodes         | 4924     |
|    fps              | 34       |
|    time_elapsed     | 2557     |
|    total_timesteps  | 89429    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00678  |
|    n_updates        | 12357    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0343   |
|    exploration_rate | 0.828    |
| time/               |          |
|    episodes         | 4928     |
|    fps              | 34       |
|    time_elapsed     | 2557     |
|    total_timesteps  | 89491    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000124 |
|    n_updates        | 12372    |
----------------------------------
Eval num_timesteps=89500, episode_reward=-0.30 +/- 0.01
Episode length: 74.04 +/- 2.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.828    |
| time/               |          |
|    total_timesteps  | 89500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.42e-05 |
|    n_updates        | 12374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0453   |
|    exploration_rate | 0.828    |
| time/               |          |
|    episodes         | 4932     |
|    fps              | 34       |
|    time_elapsed     | 2569     |
|    total_timesteps  | 89547    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000133 |
|    n_updates        | 12386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0456   |
|    exploration_rate | 0.827    |
| time/               |          |
|    episodes         | 4936     |
|    fps              | 34       |
|    time_elapsed     | 2569     |
|    total_timesteps  | 89619    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.78e-05 |
|    n_updates        | 12404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0362   |
|    exploration_rate | 0.827    |
| time/               |          |
|    episodes         | 4940     |
|    fps              | 34       |
|    time_elapsed     | 2569     |
|    total_timesteps  | 89688    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 12421    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.827    |
| time/               |          |
|    episodes         | 4944     |
|    fps              | 34       |
|    time_elapsed     | 2570     |
|    total_timesteps  | 89777    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.97e-05 |
|    n_updates        | 12444    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 4948     |
|    fps              | 34       |
|    time_elapsed     | 2570     |
|    total_timesteps  | 89851    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.82e-05 |
|    n_updates        | 12462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 4952     |
|    fps              | 34       |
|    time_elapsed     | 2571     |
|    total_timesteps  | 89914    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.25e-05 |
|    n_updates        | 12478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0151   |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 4956     |
|    fps              | 34       |
|    time_elapsed     | 2571     |
|    total_timesteps  | 89995    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.37e-05 |
|    n_updates        | 12498    |
----------------------------------
Eval num_timesteps=90000, episode_reward=-0.30 +/- 0.01
Episode length: 74.60 +/- 2.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.825    |
| time/               |          |
|    total_timesteps  | 90000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.02e-05 |
|    n_updates        | 12499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00546  |
|    exploration_rate | 0.825    |
| time/               |          |
|    episodes         | 4960     |
|    fps              | 34       |
|    time_elapsed     | 2583     |
|    total_timesteps  | 90068    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.46e-05 |
|    n_updates        | 12516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00554  |
|    exploration_rate | 0.825    |
| time/               |          |
|    episodes         | 4964     |
|    fps              | 34       |
|    time_elapsed     | 2584     |
|    total_timesteps  | 90134    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 12533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0165   |
|    exploration_rate | 0.824    |
| time/               |          |
|    episodes         | 4968     |
|    fps              | 34       |
|    time_elapsed     | 2584     |
|    total_timesteps  | 90205    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00712  |
|    n_updates        | 12551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0267   |
|    exploration_rate | 0.824    |
| time/               |          |
|    episodes         | 4972     |
|    fps              | 34       |
|    time_elapsed     | 2584     |
|    total_timesteps  | 90271    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.23e-05 |
|    n_updates        | 12567    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0273   |
|    exploration_rate | 0.824    |
| time/               |          |
|    episodes         | 4976     |
|    fps              | 34       |
|    time_elapsed     | 2585     |
|    total_timesteps  | 90332    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.52e-05 |
|    n_updates        | 12582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 0.823    |
| time/               |          |
|    episodes         | 4980     |
|    fps              | 34       |
|    time_elapsed     | 2585     |
|    total_timesteps  | 90397    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00714  |
|    n_updates        | 12599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.823    |
| time/               |          |
|    episodes         | 4984     |
|    fps              | 34       |
|    time_elapsed     | 2585     |
|    total_timesteps  | 90486    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00687  |
|    n_updates        | 12621    |
----------------------------------
Eval num_timesteps=90500, episode_reward=0.01 +/- 0.27
Episode length: 16.86 +/- 0.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.9     |
|    mean_reward      | 0.0136   |
| rollout/            |          |
|    exploration_rate | 0.823    |
| time/               |          |
|    total_timesteps  | 90500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.77e-05 |
|    n_updates        | 12624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.823    |
| time/               |          |
|    episodes         | 4988     |
|    fps              | 34       |
|    time_elapsed     | 2590     |
|    total_timesteps  | 90557    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.69e-05 |
|    n_updates        | 12639    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.822    |
| time/               |          |
|    episodes         | 4992     |
|    fps              | 34       |
|    time_elapsed     | 2590     |
|    total_timesteps  | 90630    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.45e-05 |
|    n_updates        | 12657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00799  |
|    exploration_rate | 0.822    |
| time/               |          |
|    episodes         | 4996     |
|    fps              | 35       |
|    time_elapsed     | 2590     |
|    total_timesteps  | 90696    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00718  |
|    n_updates        | 12673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0193   |
|    exploration_rate | 0.822    |
| time/               |          |
|    episodes         | 5000     |
|    fps              | 35       |
|    time_elapsed     | 2591     |
|    total_timesteps  | 90757    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.63e-05 |
|    n_updates        | 12689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.821    |
| time/               |          |
|    episodes         | 5004     |
|    fps              | 35       |
|    time_elapsed     | 2591     |
|    total_timesteps  | 90828    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000129 |
|    n_updates        | 12706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00896  |
|    exploration_rate | 0.821    |
| time/               |          |
|    episodes         | 5008     |
|    fps              | 35       |
|    time_elapsed     | 2592     |
|    total_timesteps  | 90912    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.6e-05  |
|    n_updates        | 12727    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00848  |
|    exploration_rate | 0.82     |
| time/               |          |
|    episodes         | 5012     |
|    fps              | 35       |
|    time_elapsed     | 2592     |
|    total_timesteps  | 90994    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.68e-05 |
|    n_updates        | 12748    |
----------------------------------
Eval num_timesteps=91000, episode_reward=-0.15 +/- 0.25
Episode length: 52.56 +/- 22.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.6     |
|    mean_reward      | -0.15    |
| rollout/            |          |
|    exploration_rate | 0.82     |
| time/               |          |
|    total_timesteps  | 91000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.61e-05 |
|    n_updates        | 12749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0291   |
|    exploration_rate | 0.82     |
| time/               |          |
|    episodes         | 5016     |
|    fps              | 34       |
|    time_elapsed     | 2603     |
|    total_timesteps  | 91073    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.61e-05 |
|    n_updates        | 12768    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0288   |
|    exploration_rate | 0.819    |
| time/               |          |
|    episodes         | 5020     |
|    fps              | 35       |
|    time_elapsed     | 2603     |
|    total_timesteps  | 91154    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.16e-05 |
|    n_updates        | 12788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 0.819    |
| time/               |          |
|    episodes         | 5024     |
|    fps              | 35       |
|    time_elapsed     | 2604     |
|    total_timesteps  | 91227    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.1e-05  |
|    n_updates        | 12806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0388   |
|    exploration_rate | 0.819    |
| time/               |          |
|    episodes         | 5028     |
|    fps              | 35       |
|    time_elapsed     | 2604     |
|    total_timesteps  | 91297    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 12824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.818    |
| time/               |          |
|    episodes         | 5032     |
|    fps              | 35       |
|    time_elapsed     | 2605     |
|    total_timesteps  | 91374    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.17e-05 |
|    n_updates        | 12843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.818    |
| time/               |          |
|    episodes         | 5036     |
|    fps              | 35       |
|    time_elapsed     | 2605     |
|    total_timesteps  | 91453    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000116 |
|    n_updates        | 12863    |
----------------------------------
Eval num_timesteps=91500, episode_reward=-0.27 +/- 0.06
Episode length: 68.20 +/- 13.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.2     |
|    mean_reward      | -0.273   |
| rollout/            |          |
|    exploration_rate | 0.818    |
| time/               |          |
|    total_timesteps  | 91500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.13e-05 |
|    n_updates        | 12874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0374   |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 5040     |
|    fps              | 34       |
|    time_elapsed     | 2616     |
|    total_timesteps  | 91528    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.11e-05 |
|    n_updates        | 12881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 5044     |
|    fps              | 35       |
|    time_elapsed     | 2617     |
|    total_timesteps  | 91619    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000137 |
|    n_updates        | 12904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0375   |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 5048     |
|    fps              | 35       |
|    time_elapsed     | 2617     |
|    total_timesteps  | 91690    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.14e-05 |
|    n_updates        | 12922    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 0.816    |
| time/               |          |
|    episodes         | 5052     |
|    fps              | 35       |
|    time_elapsed     | 2618     |
|    total_timesteps  | 91765    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000185 |
|    n_updates        | 12941    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0374   |
|    exploration_rate | 0.816    |
| time/               |          |
|    episodes         | 5056     |
|    fps              | 35       |
|    time_elapsed     | 2618     |
|    total_timesteps  | 91834    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.92e-05 |
|    n_updates        | 12958    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 5060     |
|    fps              | 35       |
|    time_elapsed     | 2618     |
|    total_timesteps  | 91915    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.28e-05 |
|    n_updates        | 12978    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0368   |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 5064     |
|    fps              | 35       |
|    time_elapsed     | 2619     |
|    total_timesteps  | 91988    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.3e-05  |
|    n_updates        | 12996    |
----------------------------------
Eval num_timesteps=92000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.815    |
| time/               |          |
|    total_timesteps  | 92000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.05e-05 |
|    n_updates        | 12999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0268   |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 5068     |
|    fps              | 34       |
|    time_elapsed     | 2635     |
|    total_timesteps  | 92060    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00723  |
|    n_updates        | 13014    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.814    |
| time/               |          |
|    episodes         | 5072     |
|    fps              | 34       |
|    time_elapsed     | 2636     |
|    total_timesteps  | 92130    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.83e-05 |
|    n_updates        | 13032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00626  |
|    exploration_rate | 0.814    |
| time/               |          |
|    episodes         | 5076     |
|    fps              | 34       |
|    time_elapsed     | 2636     |
|    total_timesteps  | 92200    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.89e-05 |
|    n_updates        | 13049    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.00557 |
|    exploration_rate | 0.813    |
| time/               |          |
|    episodes         | 5080     |
|    fps              | 35       |
|    time_elapsed     | 2637     |
|    total_timesteps  | 92311    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00704  |
|    n_updates        | 13077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00561  |
|    exploration_rate | 0.813    |
| time/               |          |
|    episodes         | 5084     |
|    fps              | 35       |
|    time_elapsed     | 2637     |
|    total_timesteps  | 92371    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.3e-05  |
|    n_updates        | 13092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0156   |
|    exploration_rate | 0.813    |
| time/               |          |
|    episodes         | 5088     |
|    fps              | 35       |
|    time_elapsed     | 2638     |
|    total_timesteps  | 92443    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.39e-05 |
|    n_updates        | 13110    |
----------------------------------
Eval num_timesteps=92500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.812    |
| time/               |          |
|    total_timesteps  | 92500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.41e-05 |
|    n_updates        | 13124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0255   |
|    exploration_rate | 0.812    |
| time/               |          |
|    episodes         | 5092     |
|    fps              | 34       |
|    time_elapsed     | 2654     |
|    total_timesteps  | 92519    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0142   |
|    n_updates        | 13129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.812    |
| time/               |          |
|    episodes         | 5096     |
|    fps              | 34       |
|    time_elapsed     | 2655     |
|    total_timesteps  | 92582    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00727  |
|    n_updates        | 13145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0152   |
|    exploration_rate | 0.811    |
| time/               |          |
|    episodes         | 5100     |
|    fps              | 34       |
|    time_elapsed     | 2655     |
|    total_timesteps  | 92652    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.35e-05 |
|    n_updates        | 13162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0149   |
|    exploration_rate | 0.811    |
| time/               |          |
|    episodes         | 5104     |
|    fps              | 34       |
|    time_elapsed     | 2656     |
|    total_timesteps  | 92731    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.31e-05 |
|    n_updates        | 13182    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.811    |
| time/               |          |
|    episodes         | 5108     |
|    fps              | 34       |
|    time_elapsed     | 2656     |
|    total_timesteps  | 92802    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.47e-05 |
|    n_updates        | 13200    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.81     |
| time/               |          |
|    episodes         | 5112     |
|    fps              | 34       |
|    time_elapsed     | 2656     |
|    total_timesteps  | 92879    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000154 |
|    n_updates        | 13219    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00546  |
|    exploration_rate | 0.81     |
| time/               |          |
|    episodes         | 5116     |
|    fps              | 34       |
|    time_elapsed     | 2657     |
|    total_timesteps  | 92962    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.46e-05 |
|    n_updates        | 13240    |
----------------------------------
Eval num_timesteps=93000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.81     |
| time/               |          |
|    total_timesteps  | 93000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 13249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00586  |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 5120     |
|    fps              | 34       |
|    time_elapsed     | 2669     |
|    total_timesteps  | 93033    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00718  |
|    n_updates        | 13258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00438 |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 5124     |
|    fps              | 34       |
|    time_elapsed     | 2669     |
|    total_timesteps  | 93112    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00012  |
|    n_updates        | 13277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00584  |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 5128     |
|    fps              | 34       |
|    time_elapsed     | 2670     |
|    total_timesteps  | 93177    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.26e-05 |
|    n_updates        | 13294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00604  |
|    exploration_rate | 0.808    |
| time/               |          |
|    episodes         | 5132     |
|    fps              | 34       |
|    time_elapsed     | 2670     |
|    total_timesteps  | 93249    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.7e-05  |
|    n_updates        | 13312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00401 |
|    exploration_rate | 0.808    |
| time/               |          |
|    episodes         | 5136     |
|    fps              | 34       |
|    time_elapsed     | 2670     |
|    total_timesteps  | 93329    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.38e-05 |
|    n_updates        | 13332    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00397 |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 5140     |
|    fps              | 34       |
|    time_elapsed     | 2671     |
|    total_timesteps  | 93403    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00723  |
|    n_updates        | 13350    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00341 |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 5144     |
|    fps              | 34       |
|    time_elapsed     | 2671     |
|    total_timesteps  | 93480    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.48e-05 |
|    n_updates        | 13369    |
----------------------------------
Eval num_timesteps=93500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.807    |
| time/               |          |
|    total_timesteps  | 93500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.12e-05 |
|    n_updates        | 13374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00341 |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 5148     |
|    fps              | 34       |
|    time_elapsed     | 2688     |
|    total_timesteps  | 93551    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.08e-05 |
|    n_updates        | 13387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00667  |
|    exploration_rate | 0.806    |
| time/               |          |
|    episodes         | 5152     |
|    fps              | 34       |
|    time_elapsed     | 2688     |
|    total_timesteps  | 93624    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00716  |
|    n_updates        | 13405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00336 |
|    exploration_rate | 0.806    |
| time/               |          |
|    episodes         | 5156     |
|    fps              | 34       |
|    time_elapsed     | 2689     |
|    total_timesteps  | 93694    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.01e-05 |
|    n_updates        | 13423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.00308 |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 5160     |
|    fps              | 34       |
|    time_elapsed     | 2689     |
|    total_timesteps  | 93768    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.81e-05 |
|    n_updates        | 13441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 5164     |
|    fps              | 34       |
|    time_elapsed     | 2689     |
|    total_timesteps  | 93834    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.88e-05 |
|    n_updates        | 13458    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00225 |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 5168     |
|    fps              | 34       |
|    time_elapsed     | 2690     |
|    total_timesteps  | 93893    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00788  |
|    n_updates        | 13473    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00229 |
|    exploration_rate | 0.804    |
| time/               |          |
|    episodes         | 5172     |
|    fps              | 34       |
|    time_elapsed     | 2690     |
|    total_timesteps  | 93964    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00708  |
|    n_updates        | 13490    |
----------------------------------
Eval num_timesteps=94000, episode_reward=-0.09 +/- 0.31
Episode length: 41.72 +/- 20.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.7     |
|    mean_reward      | -0.0861  |
| rollout/            |          |
|    exploration_rate | 0.804    |
| time/               |          |
|    total_timesteps  | 94000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.2e-05  |
|    n_updates        | 13499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00249 |
|    exploration_rate | 0.804    |
| time/               |          |
|    episodes         | 5176     |
|    fps              | 34       |
|    time_elapsed     | 2700     |
|    total_timesteps  | 94039    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.19e-05 |
|    n_updates        | 13509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.00959  |
|    exploration_rate | 0.804    |
| time/               |          |
|    episodes         | 5180     |
|    fps              | 34       |
|    time_elapsed     | 2701     |
|    total_timesteps  | 94098    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.11e-05 |
|    n_updates        | 13524    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.00881  |
|    exploration_rate | 0.803    |
| time/               |          |
|    episodes         | 5184     |
|    fps              | 34       |
|    time_elapsed     | 2701     |
|    total_timesteps  | 94177    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.32e-05 |
|    n_updates        | 13544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00892  |
|    exploration_rate | 0.803    |
| time/               |          |
|    episodes         | 5188     |
|    fps              | 34       |
|    time_elapsed     | 2701     |
|    total_timesteps  | 94246    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.49e-05 |
|    n_updates        | 13561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00146 |
|    exploration_rate | 0.802    |
| time/               |          |
|    episodes         | 5192     |
|    fps              | 34       |
|    time_elapsed     | 2702     |
|    total_timesteps  | 94331    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000165 |
|    n_updates        | 13582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00186 |
|    exploration_rate | 0.802    |
| time/               |          |
|    episodes         | 5196     |
|    fps              | 34       |
|    time_elapsed     | 2702     |
|    total_timesteps  | 94404    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.27e-05 |
|    n_updates        | 13600    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00234 |
|    exploration_rate | 0.801    |
| time/               |          |
|    episodes         | 5200     |
|    fps              | 34       |
|    time_elapsed     | 2703     |
|    total_timesteps  | 94486    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.55e-05 |
|    n_updates        | 13621    |
----------------------------------
Eval num_timesteps=94500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.801    |
| time/               |          |
|    total_timesteps  | 94500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.55e-05 |
|    n_updates        | 13624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00202 |
|    exploration_rate | 0.801    |
| time/               |          |
|    episodes         | 5204     |
|    fps              | 34       |
|    time_elapsed     | 2719     |
|    total_timesteps  | 94557    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.46e-05 |
|    n_updates        | 13639    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0017  |
|    exploration_rate | 0.801    |
| time/               |          |
|    episodes         | 5208     |
|    fps              | 34       |
|    time_elapsed     | 2720     |
|    total_timesteps  | 94620    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.93e-05 |
|    n_updates        | 13654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.8      |
| time/               |          |
|    episodes         | 5212     |
|    fps              | 34       |
|    time_elapsed     | 2720     |
|    total_timesteps  | 94693    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.69e-05 |
|    n_updates        | 13673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0108  |
|    exploration_rate | 0.8      |
| time/               |          |
|    episodes         | 5216     |
|    fps              | 34       |
|    time_elapsed     | 2720     |
|    total_timesteps  | 94757    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000129 |
|    n_updates        | 13689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00075 |
|    exploration_rate | 0.8      |
| time/               |          |
|    episodes         | 5220     |
|    fps              | 34       |
|    time_elapsed     | 2721     |
|    total_timesteps  | 94828    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 13706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00075 |
|    exploration_rate | 0.799    |
| time/               |          |
|    episodes         | 5224     |
|    fps              | 34       |
|    time_elapsed     | 2721     |
|    total_timesteps  | 94907    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 13726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00068 |
|    exploration_rate | 0.799    |
| time/               |          |
|    episodes         | 5228     |
|    fps              | 34       |
|    time_elapsed     | 2722     |
|    total_timesteps  | 94970    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.67e-05 |
|    n_updates        | 13742    |
----------------------------------
Eval num_timesteps=95000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.799    |
| time/               |          |
|    total_timesteps  | 95000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00714  |
|    n_updates        | 13749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00096 |
|    exploration_rate | 0.798    |
| time/               |          |
|    episodes         | 5232     |
|    fps              | 34       |
|    time_elapsed     | 2734     |
|    total_timesteps  | 95049    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.72e-05 |
|    n_updates        | 13762    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00909  |
|    exploration_rate | 0.798    |
| time/               |          |
|    episodes         | 5236     |
|    fps              | 34       |
|    time_elapsed     | 2734     |
|    total_timesteps  | 95128    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.29e-05 |
|    n_updates        | 13781    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00893  |
|    exploration_rate | 0.798    |
| time/               |          |
|    episodes         | 5240     |
|    fps              | 34       |
|    time_elapsed     | 2735     |
|    total_timesteps  | 95206    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00717  |
|    n_updates        | 13801    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00893  |
|    exploration_rate | 0.797    |
| time/               |          |
|    episodes         | 5244     |
|    fps              | 34       |
|    time_elapsed     | 2735     |
|    total_timesteps  | 95283    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000107 |
|    n_updates        | 13820    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00897  |
|    exploration_rate | 0.797    |
| time/               |          |
|    episodes         | 5248     |
|    fps              | 34       |
|    time_elapsed     | 2735     |
|    total_timesteps  | 95353    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.38e-05 |
|    n_updates        | 13838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00091 |
|    exploration_rate | 0.796    |
| time/               |          |
|    episodes         | 5252     |
|    fps              | 34       |
|    time_elapsed     | 2736     |
|    total_timesteps  | 95423    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.51e-05 |
|    n_updates        | 13855    |
----------------------------------
Eval num_timesteps=95500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.796    |
| time/               |          |
|    total_timesteps  | 95500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.44e-05 |
|    n_updates        | 13874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00135 |
|    exploration_rate | 0.796    |
| time/               |          |
|    episodes         | 5256     |
|    fps              | 34       |
|    time_elapsed     | 2748     |
|    total_timesteps  | 95504    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00712  |
|    n_updates        | 13875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.795    |
| time/               |          |
|    episodes         | 5260     |
|    fps              | 34       |
|    time_elapsed     | 2748     |
|    total_timesteps  | 95577    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.52e-05 |
|    n_updates        | 13894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.795    |
| time/               |          |
|    episodes         | 5264     |
|    fps              | 34       |
|    time_elapsed     | 2749     |
|    total_timesteps  | 95678    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.27e-05 |
|    n_updates        | 13919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00699  |
|    exploration_rate | 0.795    |
| time/               |          |
|    episodes         | 5268     |
|    fps              | 34       |
|    time_elapsed     | 2749     |
|    total_timesteps  | 95744    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.96e-05 |
|    n_updates        | 13935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.794    |
| time/               |          |
|    episodes         | 5272     |
|    fps              | 34       |
|    time_elapsed     | 2750     |
|    total_timesteps  | 95814    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0143   |
|    n_updates        | 13953    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0263   |
|    exploration_rate | 0.794    |
| time/               |          |
|    episodes         | 5276     |
|    fps              | 34       |
|    time_elapsed     | 2750     |
|    total_timesteps  | 95909    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 13977    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0151   |
|    exploration_rate | 0.793    |
| time/               |          |
|    episodes         | 5280     |
|    fps              | 34       |
|    time_elapsed     | 2750     |
|    total_timesteps  | 95998    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000179 |
|    n_updates        | 13999    |
----------------------------------
Eval num_timesteps=96000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.793    |
| time/               |          |
|    total_timesteps  | 96000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.015    |
|    exploration_rate | 0.793    |
| time/               |          |
|    episodes         | 5284     |
|    fps              | 34       |
|    time_elapsed     | 2763     |
|    total_timesteps  | 96079    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.15e-05 |
|    n_updates        | 14019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.00487  |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 5288     |
|    fps              | 34       |
|    time_elapsed     | 2763     |
|    total_timesteps  | 96151    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00716  |
|    n_updates        | 14037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00543  |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 5292     |
|    fps              | 34       |
|    time_elapsed     | 2764     |
|    total_timesteps  | 96222    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.31e-05 |
|    n_updates        | 14055    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00551  |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 5296     |
|    fps              | 34       |
|    time_elapsed     | 2764     |
|    total_timesteps  | 96293    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00712  |
|    n_updates        | 14073    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0159   |
|    exploration_rate | 0.791    |
| time/               |          |
|    episodes         | 5300     |
|    fps              | 34       |
|    time_elapsed     | 2764     |
|    total_timesteps  | 96364    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.22e-05 |
|    n_updates        | 14090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0159   |
|    exploration_rate | 0.791    |
| time/               |          |
|    episodes         | 5304     |
|    fps              | 34       |
|    time_elapsed     | 2765     |
|    total_timesteps  | 96435    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 14108    |
----------------------------------
Eval num_timesteps=96500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.79     |
| time/               |          |
|    total_timesteps  | 96500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 14124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0155   |
|    exploration_rate | 0.79     |
| time/               |          |
|    episodes         | 5308     |
|    fps              | 34       |
|    time_elapsed     | 2780     |
|    total_timesteps  | 96509    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.42e-05 |
|    n_updates        | 14127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.015    |
|    exploration_rate | 0.79     |
| time/               |          |
|    episodes         | 5312     |
|    fps              | 34       |
|    time_elapsed     | 2780     |
|    total_timesteps  | 96595    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00712  |
|    n_updates        | 14148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.0145   |
|    exploration_rate | 0.789    |
| time/               |          |
|    episodes         | 5316     |
|    fps              | 34       |
|    time_elapsed     | 2781     |
|    total_timesteps  | 96672    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.18e-05 |
|    n_updates        | 14167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.0145   |
|    exploration_rate | 0.789    |
| time/               |          |
|    episodes         | 5320     |
|    fps              | 34       |
|    time_elapsed     | 2781     |
|    total_timesteps  | 96741    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000126 |
|    n_updates        | 14185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.789    |
| time/               |          |
|    episodes         | 5324     |
|    fps              | 34       |
|    time_elapsed     | 2781     |
|    total_timesteps  | 96818    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 14204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.00411  |
|    exploration_rate | 0.788    |
| time/               |          |
|    episodes         | 5328     |
|    fps              | 34       |
|    time_elapsed     | 2782     |
|    total_timesteps  | 96893    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.98e-05 |
|    n_updates        | 14223    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.00459  |
|    exploration_rate | 0.788    |
| time/               |          |
|    episodes         | 5332     |
|    fps              | 34       |
|    time_elapsed     | 2782     |
|    total_timesteps  | 96960    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00707  |
|    n_updates        | 14239    |
----------------------------------
Eval num_timesteps=97000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.788    |
| time/               |          |
|    total_timesteps  | 97000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0071   |
|    n_updates        | 14249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.00546 |
|    exploration_rate | 0.787    |
| time/               |          |
|    episodes         | 5336     |
|    fps              | 34       |
|    time_elapsed     | 2794     |
|    total_timesteps  | 97040    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.92e-05 |
|    n_updates        | 14259    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.00469  |
|    exploration_rate | 0.787    |
| time/               |          |
|    episodes         | 5340     |
|    fps              | 34       |
|    time_elapsed     | 2795     |
|    total_timesteps  | 97114    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.9e-05  |
|    n_updates        | 14278    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00517  |
|    exploration_rate | 0.787    |
| time/               |          |
|    episodes         | 5344     |
|    fps              | 34       |
|    time_elapsed     | 2795     |
|    total_timesteps  | 97179    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000123 |
|    n_updates        | 14294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0149   |
|    exploration_rate | 0.786    |
| time/               |          |
|    episodes         | 5348     |
|    fps              | 34       |
|    time_elapsed     | 2796     |
|    total_timesteps  | 97257    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.93e-05 |
|    n_updates        | 14314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.0147   |
|    exploration_rate | 0.786    |
| time/               |          |
|    episodes         | 5352     |
|    fps              | 34       |
|    time_elapsed     | 2796     |
|    total_timesteps  | 97331    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.27e-05 |
|    n_updates        | 14332    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0356   |
|    exploration_rate | 0.785    |
| time/               |          |
|    episodes         | 5356     |
|    fps              | 34       |
|    time_elapsed     | 2796     |
|    total_timesteps  | 97391    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00696  |
|    n_updates        | 14347    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.785    |
| time/               |          |
|    episodes         | 5360     |
|    fps              | 34       |
|    time_elapsed     | 2797     |
|    total_timesteps  | 97470    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.39e-05 |
|    n_updates        | 14367    |
----------------------------------
Eval num_timesteps=97500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.785    |
| time/               |          |
|    total_timesteps  | 97500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0139   |
|    n_updates        | 14374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0367   |
|    exploration_rate | 0.785    |
| time/               |          |
|    episodes         | 5364     |
|    fps              | 34       |
|    time_elapsed     | 2809     |
|    total_timesteps  | 97536    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00717  |
|    n_updates        | 14383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0461   |
|    exploration_rate | 0.784    |
| time/               |          |
|    episodes         | 5368     |
|    fps              | 34       |
|    time_elapsed     | 2809     |
|    total_timesteps  | 97617    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000104 |
|    n_updates        | 14404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.784    |
| time/               |          |
|    episodes         | 5372     |
|    fps              | 34       |
|    time_elapsed     | 2810     |
|    total_timesteps  | 97693    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.32e-05 |
|    n_updates        | 14423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0268   |
|    exploration_rate | 0.783    |
| time/               |          |
|    episodes         | 5376     |
|    fps              | 34       |
|    time_elapsed     | 2810     |
|    total_timesteps  | 97766    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00706  |
|    n_updates        | 14441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.783    |
| time/               |          |
|    episodes         | 5380     |
|    fps              | 34       |
|    time_elapsed     | 2810     |
|    total_timesteps  | 97844    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000143 |
|    n_updates        | 14460    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.782    |
| time/               |          |
|    episodes         | 5384     |
|    fps              | 34       |
|    time_elapsed     | 2811     |
|    total_timesteps  | 97914    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.36e-05 |
|    n_updates        | 14478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0275   |
|    exploration_rate | 0.782    |
| time/               |          |
|    episodes         | 5388     |
|    fps              | 34       |
|    time_elapsed     | 2811     |
|    total_timesteps  | 97989    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.71e-05 |
|    n_updates        | 14497    |
----------------------------------
Eval num_timesteps=98000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.782    |
| time/               |          |
|    total_timesteps  | 98000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.2e-05  |
|    n_updates        | 14499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0273   |
|    exploration_rate | 0.782    |
| time/               |          |
|    episodes         | 5392     |
|    fps              | 34       |
|    time_elapsed     | 2823     |
|    total_timesteps  | 98065    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.73e-05 |
|    n_updates        | 14516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0475   |
|    exploration_rate | 0.781    |
| time/               |          |
|    episodes         | 5396     |
|    fps              | 34       |
|    time_elapsed     | 2824     |
|    total_timesteps  | 98132    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00711  |
|    n_updates        | 14532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.781    |
| time/               |          |
|    episodes         | 5400     |
|    fps              | 34       |
|    time_elapsed     | 2824     |
|    total_timesteps  | 98194    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.51e-05 |
|    n_updates        | 14548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.048    |
|    exploration_rate | 0.78     |
| time/               |          |
|    episodes         | 5404     |
|    fps              | 34       |
|    time_elapsed     | 2824     |
|    total_timesteps  | 98261    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.52e-05 |
|    n_updates        | 14565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0578   |
|    exploration_rate | 0.78     |
| time/               |          |
|    episodes         | 5408     |
|    fps              | 34       |
|    time_elapsed     | 2825     |
|    total_timesteps  | 98341    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.87e-05 |
|    n_updates        | 14585    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0583   |
|    exploration_rate | 0.78     |
| time/               |          |
|    episodes         | 5412     |
|    fps              | 34       |
|    time_elapsed     | 2825     |
|    total_timesteps  | 98415    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00706  |
|    n_updates        | 14603    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0786   |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 5416     |
|    fps              | 34       |
|    time_elapsed     | 2825     |
|    total_timesteps  | 98482    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.4e-05  |
|    n_updates        | 14620    |
----------------------------------
Eval num_timesteps=98500, episode_reward=-0.30 +/- 0.03
Episode length: 73.82 +/- 8.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.779    |
| time/               |          |
|    total_timesteps  | 98500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.94e-05 |
|    n_updates        | 14624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0685   |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 5420     |
|    fps              | 34       |
|    time_elapsed     | 2838     |
|    total_timesteps  | 98555    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.06e-05 |
|    n_updates        | 14638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0689   |
|    exploration_rate | 0.778    |
| time/               |          |
|    episodes         | 5424     |
|    fps              | 34       |
|    time_elapsed     | 2838     |
|    total_timesteps  | 98621    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.35e-05 |
|    n_updates        | 14655    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0692   |
|    exploration_rate | 0.778    |
| time/               |          |
|    episodes         | 5428     |
|    fps              | 34       |
|    time_elapsed     | 2838     |
|    total_timesteps  | 98690    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.42e-05 |
|    n_updates        | 14672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0681   |
|    exploration_rate | 0.778    |
| time/               |          |
|    episodes         | 5432     |
|    fps              | 34       |
|    time_elapsed     | 2839     |
|    total_timesteps  | 98783    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00712  |
|    n_updates        | 14695    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0682   |
|    exploration_rate | 0.777    |
| time/               |          |
|    episodes         | 5436     |
|    fps              | 34       |
|    time_elapsed     | 2839     |
|    total_timesteps  | 98861    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00723  |
|    n_updates        | 14715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0583   |
|    exploration_rate | 0.777    |
| time/               |          |
|    episodes         | 5440     |
|    fps              | 34       |
|    time_elapsed     | 2840     |
|    total_timesteps  | 98933    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.48e-05 |
|    n_updates        | 14733    |
----------------------------------
Eval num_timesteps=99000, episode_reward=-0.18 +/- 0.28
Episode length: 58.88 +/- 21.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.9     |
|    mean_reward      | -0.175   |
| rollout/            |          |
|    exploration_rate | 0.776    |
| time/               |          |
|    total_timesteps  | 99000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.44e-05 |
|    n_updates        | 14749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.058    |
|    exploration_rate | 0.776    |
| time/               |          |
|    episodes         | 5444     |
|    fps              | 34       |
|    time_elapsed     | 2852     |
|    total_timesteps  | 99006    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000108 |
|    n_updates        | 14751    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0482   |
|    exploration_rate | 0.776    |
| time/               |          |
|    episodes         | 5448     |
|    fps              | 34       |
|    time_elapsed     | 2852     |
|    total_timesteps  | 99078    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 14769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0483   |
|    exploration_rate | 0.775    |
| time/               |          |
|    episodes         | 5452     |
|    fps              | 34       |
|    time_elapsed     | 2853     |
|    total_timesteps  | 99150    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.19e-05 |
|    n_updates        | 14787    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.775    |
| time/               |          |
|    episodes         | 5456     |
|    fps              | 34       |
|    time_elapsed     | 2853     |
|    total_timesteps  | 99238    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 14809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0161   |
|    exploration_rate | 0.774    |
| time/               |          |
|    episodes         | 5460     |
|    fps              | 34       |
|    time_elapsed     | 2854     |
|    total_timesteps  | 99343    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00801  |
|    n_updates        | 14835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00621  |
|    exploration_rate | 0.774    |
| time/               |          |
|    episodes         | 5464     |
|    fps              | 34       |
|    time_elapsed     | 2854     |
|    total_timesteps  | 99406    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.92e-05 |
|    n_updates        | 14851    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00625  |
|    exploration_rate | 0.774    |
| time/               |          |
|    episodes         | 5468     |
|    fps              | 34       |
|    time_elapsed     | 2854     |
|    total_timesteps  | 99486    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 14871    |
----------------------------------
Eval num_timesteps=99500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.773    |
| time/               |          |
|    total_timesteps  | 99500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.14e-05 |
|    n_updates        | 14874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0164   |
|    exploration_rate | 0.773    |
| time/               |          |
|    episodes         | 5472     |
|    fps              | 34       |
|    time_elapsed     | 2870     |
|    total_timesteps  | 99560    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000109 |
|    n_updates        | 14889    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.016    |
|    exploration_rate | 0.773    |
| time/               |          |
|    episodes         | 5476     |
|    fps              | 34       |
|    time_elapsed     | 2870     |
|    total_timesteps  | 99642    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.97e-05 |
|    n_updates        | 14910    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.772    |
| time/               |          |
|    episodes         | 5480     |
|    fps              | 34       |
|    time_elapsed     | 2870     |
|    total_timesteps  | 99716    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.02e-05 |
|    n_updates        | 14928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00593  |
|    exploration_rate | 0.772    |
| time/               |          |
|    episodes         | 5484     |
|    fps              | 34       |
|    time_elapsed     | 2871     |
|    total_timesteps  | 99791    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.01e-05 |
|    n_updates        | 14947    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00593  |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 5488     |
|    fps              | 34       |
|    time_elapsed     | 2871     |
|    total_timesteps  | 99866    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.63e-05 |
|    n_updates        | 14966    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00621  |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 5492     |
|    fps              | 34       |
|    time_elapsed     | 2872     |
|    total_timesteps  | 99935    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.22e-05 |
|    n_updates        | 14983    |
----------------------------------
Eval num_timesteps=100000, episode_reward=-0.29 +/- 0.03
Episode length: 73.52 +/- 7.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.5     |
|    mean_reward      | -0.294   |
| rollout/            |          |
|    exploration_rate | 0.771    |
| time/               |          |
|    total_timesteps  | 100000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00788  |
|    n_updates        | 14999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 5496     |
|    fps              | 34       |
|    time_elapsed     | 2887     |
|    total_timesteps  | 100012   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00804  |
|    n_updates        | 15002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00421 |
|    exploration_rate | 0.77     |
| time/               |          |
|    episodes         | 5500     |
|    fps              | 34       |
|    time_elapsed     | 2887     |
|    total_timesteps  | 100075   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000116 |
|    n_updates        | 15018    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00437 |
|    exploration_rate | 0.77     |
| time/               |          |
|    episodes         | 5504     |
|    fps              | 34       |
|    time_elapsed     | 2887     |
|    total_timesteps  | 100146   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.92e-05 |
|    n_updates        | 15036    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00361 |
|    exploration_rate | 0.769    |
| time/               |          |
|    episodes         | 5508     |
|    fps              | 34       |
|    time_elapsed     | 2888     |
|    total_timesteps  | 100207   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.31e-05 |
|    n_updates        | 15051    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.769    |
| time/               |          |
|    episodes         | 5512     |
|    fps              | 34       |
|    time_elapsed     | 2888     |
|    total_timesteps  | 100270   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.52e-05 |
|    n_updates        | 15067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00393 |
|    exploration_rate | 0.769    |
| time/               |          |
|    episodes         | 5516     |
|    fps              | 34       |
|    time_elapsed     | 2888     |
|    total_timesteps  | 100356   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000139 |
|    n_updates        | 15088    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00469 |
|    exploration_rate | 0.768    |
| time/               |          |
|    episodes         | 5520     |
|    fps              | 34       |
|    time_elapsed     | 2889     |
|    total_timesteps  | 100448   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00686  |
|    n_updates        | 15111    |
----------------------------------
Eval num_timesteps=100500, episode_reward=-0.29 +/- 0.03
Episode length: 73.00 +/- 7.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73       |
|    mean_reward      | -0.292   |
| rollout/            |          |
|    exploration_rate | 0.768    |
| time/               |          |
|    total_timesteps  | 100500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.92e-05 |
|    n_updates        | 15124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00528  |
|    exploration_rate | 0.768    |
| time/               |          |
|    episodes         | 5524     |
|    fps              | 34       |
|    time_elapsed     | 2904     |
|    total_timesteps  | 100515   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.79e-05 |
|    n_updates        | 15128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0054   |
|    exploration_rate | 0.767    |
| time/               |          |
|    episodes         | 5528     |
|    fps              | 34       |
|    time_elapsed     | 2904     |
|    total_timesteps  | 100581   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000119 |
|    n_updates        | 15145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0064   |
|    exploration_rate | 0.767    |
| time/               |          |
|    episodes         | 5532     |
|    fps              | 34       |
|    time_elapsed     | 2905     |
|    total_timesteps  | 100649   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.93e-05 |
|    n_updates        | 15162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00632  |
|    exploration_rate | 0.766    |
| time/               |          |
|    episodes         | 5536     |
|    fps              | 34       |
|    time_elapsed     | 2905     |
|    total_timesteps  | 100729   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000108 |
|    n_updates        | 15182    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00648  |
|    exploration_rate | 0.766    |
| time/               |          |
|    episodes         | 5540     |
|    fps              | 34       |
|    time_elapsed     | 2905     |
|    total_timesteps  | 100797   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 15199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00648  |
|    exploration_rate | 0.766    |
| time/               |          |
|    episodes         | 5544     |
|    fps              | 34       |
|    time_elapsed     | 2906     |
|    total_timesteps  | 100870   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.58e-05 |
|    n_updates        | 15217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00624  |
|    exploration_rate | 0.765    |
| time/               |          |
|    episodes         | 5548     |
|    fps              | 34       |
|    time_elapsed     | 2906     |
|    total_timesteps  | 100948   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.82e-05 |
|    n_updates        | 15236    |
----------------------------------
Eval num_timesteps=101000, episode_reward=-0.29 +/- 0.05
Episode length: 72.68 +/- 11.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.7     |
|    mean_reward      | -0.291   |
| rollout/            |          |
|    exploration_rate | 0.765    |
| time/               |          |
|    total_timesteps  | 101000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.93e-05 |
|    n_updates        | 15249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.006    |
|    exploration_rate | 0.765    |
| time/               |          |
|    episodes         | 5552     |
|    fps              | 34       |
|    time_elapsed     | 2922     |
|    total_timesteps  | 101026   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000112 |
|    n_updates        | 15256    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00636  |
|    exploration_rate | 0.764    |
| time/               |          |
|    episodes         | 5556     |
|    fps              | 34       |
|    time_elapsed     | 2922     |
|    total_timesteps  | 101105   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.08e-05 |
|    n_updates        | 15276    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00724  |
|    exploration_rate | 0.764    |
| time/               |          |
|    episodes         | 5560     |
|    fps              | 34       |
|    time_elapsed     | 2923     |
|    total_timesteps  | 101188   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.014    |
|    n_updates        | 15296    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00648  |
|    exploration_rate | 0.763    |
| time/               |          |
|    episodes         | 5564     |
|    fps              | 34       |
|    time_elapsed     | 2923     |
|    total_timesteps  | 101270   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.73e-05 |
|    n_updates        | 15317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00343 |
|    exploration_rate | 0.763    |
| time/               |          |
|    episodes         | 5568     |
|    fps              | 34       |
|    time_elapsed     | 2924     |
|    total_timesteps  | 101348   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.79e-05 |
|    n_updates        | 15336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.762    |
| time/               |          |
|    episodes         | 5572     |
|    fps              | 34       |
|    time_elapsed     | 2924     |
|    total_timesteps  | 101430   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 15357    |
----------------------------------
Eval num_timesteps=101500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.762    |
| time/               |          |
|    total_timesteps  | 101500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.75e-05 |
|    n_updates        | 15374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.762    |
| time/               |          |
|    episodes         | 5576     |
|    fps              | 34       |
|    time_elapsed     | 2936     |
|    total_timesteps  | 101511   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.014    |
|    n_updates        | 15377    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.00337 |
|    exploration_rate | 0.761    |
| time/               |          |
|    episodes         | 5580     |
|    fps              | 34       |
|    time_elapsed     | 2937     |
|    total_timesteps  | 101576   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.49e-05 |
|    n_updates        | 15393    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00373 |
|    exploration_rate | 0.761    |
| time/               |          |
|    episodes         | 5584     |
|    fps              | 34       |
|    time_elapsed     | 2937     |
|    total_timesteps  | 101660   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.33e-05 |
|    n_updates        | 15414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00409 |
|    exploration_rate | 0.761    |
| time/               |          |
|    episodes         | 5588     |
|    fps              | 34       |
|    time_elapsed     | 2938     |
|    total_timesteps  | 101744   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000162 |
|    n_updates        | 15435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00409 |
|    exploration_rate | 0.76     |
| time/               |          |
|    episodes         | 5592     |
|    fps              | 34       |
|    time_elapsed     | 2938     |
|    total_timesteps  | 101813   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000102 |
|    n_updates        | 15453    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00405 |
|    exploration_rate | 0.76     |
| time/               |          |
|    episodes         | 5596     |
|    fps              | 34       |
|    time_elapsed     | 2938     |
|    total_timesteps  | 101889   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.23e-05 |
|    n_updates        | 15472    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.015   |
|    exploration_rate | 0.759    |
| time/               |          |
|    episodes         | 5600     |
|    fps              | 34       |
|    time_elapsed     | 2939     |
|    total_timesteps  | 101976   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.01e-05 |
|    n_updates        | 15493    |
----------------------------------
Eval num_timesteps=102000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.759    |
| time/               |          |
|    total_timesteps  | 102000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.64e-05 |
|    n_updates        | 15499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.759    |
| time/               |          |
|    episodes         | 5604     |
|    fps              | 34       |
|    time_elapsed     | 2955     |
|    total_timesteps  | 102053   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00692  |
|    n_updates        | 15513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0355  |
|    exploration_rate | 0.758    |
| time/               |          |
|    episodes         | 5608     |
|    fps              | 34       |
|    time_elapsed     | 2956     |
|    total_timesteps  | 102121   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.02e-05 |
|    n_updates        | 15530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0558  |
|    exploration_rate | 0.758    |
| time/               |          |
|    episodes         | 5612     |
|    fps              | 34       |
|    time_elapsed     | 2956     |
|    total_timesteps  | 102190   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000136 |
|    n_updates        | 15547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0454  |
|    exploration_rate | 0.757    |
| time/               |          |
|    episodes         | 5616     |
|    fps              | 34       |
|    time_elapsed     | 2956     |
|    total_timesteps  | 102266   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.37e-05 |
|    n_updates        | 15566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0443  |
|    exploration_rate | 0.757    |
| time/               |          |
|    episodes         | 5620     |
|    fps              | 34       |
|    time_elapsed     | 2957     |
|    total_timesteps  | 102331   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00012  |
|    n_updates        | 15582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0443  |
|    exploration_rate | 0.757    |
| time/               |          |
|    episodes         | 5624     |
|    fps              | 34       |
|    time_elapsed     | 2957     |
|    total_timesteps  | 102396   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.94e-05 |
|    n_updates        | 15598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0444  |
|    exploration_rate | 0.756    |
| time/               |          |
|    episodes         | 5628     |
|    fps              | 34       |
|    time_elapsed     | 2958     |
|    total_timesteps  | 102466   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00788  |
|    n_updates        | 15616    |
----------------------------------
Eval num_timesteps=102500, episode_reward=-0.30 +/- 0.03
Episode length: 73.84 +/- 8.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.756    |
| time/               |          |
|    total_timesteps  | 102500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.02e-05 |
|    n_updates        | 15624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0443  |
|    exploration_rate | 0.756    |
| time/               |          |
|    episodes         | 5632     |
|    fps              | 34       |
|    time_elapsed     | 2972     |
|    total_timesteps  | 102532   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.26e-05 |
|    n_updates        | 15632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0441  |
|    exploration_rate | 0.755    |
| time/               |          |
|    episodes         | 5636     |
|    fps              | 34       |
|    time_elapsed     | 2972     |
|    total_timesteps  | 102605   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00697  |
|    n_updates        | 15651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0447  |
|    exploration_rate | 0.755    |
| time/               |          |
|    episodes         | 5640     |
|    fps              | 34       |
|    time_elapsed     | 2973     |
|    total_timesteps  | 102688   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000125 |
|    n_updates        | 15671    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0247  |
|    exploration_rate | 0.755    |
| time/               |          |
|    episodes         | 5644     |
|    fps              | 34       |
|    time_elapsed     | 2973     |
|    total_timesteps  | 102762   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0142   |
|    n_updates        | 15690    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0241  |
|    exploration_rate | 0.754    |
| time/               |          |
|    episodes         | 5648     |
|    fps              | 34       |
|    time_elapsed     | 2974     |
|    total_timesteps  | 102826   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000107 |
|    n_updates        | 15706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0238  |
|    exploration_rate | 0.754    |
| time/               |          |
|    episodes         | 5652     |
|    fps              | 34       |
|    time_elapsed     | 2974     |
|    total_timesteps  | 102897   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.92e-05 |
|    n_updates        | 15724    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.753    |
| time/               |          |
|    episodes         | 5656     |
|    fps              | 34       |
|    time_elapsed     | 2974     |
|    total_timesteps  | 102967   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.9e-05  |
|    n_updates        | 15741    |
----------------------------------
Eval num_timesteps=103000, episode_reward=-0.01 +/- 0.35
Episode length: 33.56 +/- 17.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 33.6     |
|    mean_reward      | -0.0132  |
| rollout/            |          |
|    exploration_rate | 0.753    |
| time/               |          |
|    total_timesteps  | 103000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.81e-05 |
|    n_updates        | 15749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.753    |
| time/               |          |
|    episodes         | 5660     |
|    fps              | 34       |
|    time_elapsed     | 2982     |
|    total_timesteps  | 103031   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.37e-05 |
|    n_updates        | 15757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 0.753    |
| time/               |          |
|    episodes         | 5664     |
|    fps              | 34       |
|    time_elapsed     | 2983     |
|    total_timesteps  | 103105   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.64e-05 |
|    n_updates        | 15776    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.752    |
| time/               |          |
|    episodes         | 5668     |
|    fps              | 34       |
|    time_elapsed     | 2983     |
|    total_timesteps  | 103174   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.15e-05 |
|    n_updates        | 15793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.00151 |
|    exploration_rate | 0.752    |
| time/               |          |
|    episodes         | 5672     |
|    fps              | 34       |
|    time_elapsed     | 2984     |
|    total_timesteps  | 103243   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.55e-05 |
|    n_updates        | 15810    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.751    |
| time/               |          |
|    episodes         | 5676     |
|    fps              | 34       |
|    time_elapsed     | 2984     |
|    total_timesteps  | 103306   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 15826    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00894  |
|    exploration_rate | 0.751    |
| time/               |          |
|    episodes         | 5680     |
|    fps              | 34       |
|    time_elapsed     | 2984     |
|    total_timesteps  | 103378   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 15844    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.75     |
| time/               |          |
|    episodes         | 5684     |
|    fps              | 34       |
|    time_elapsed     | 2985     |
|    total_timesteps  | 103467   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.95e-05 |
|    n_updates        | 15866    |
----------------------------------
Eval num_timesteps=103500, episode_reward=-0.10 +/- 0.38
Episode length: 59.90 +/- 19.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.9     |
|    mean_reward      | -0.099   |
| rollout/            |          |
|    exploration_rate | 0.75     |
| time/               |          |
|    total_timesteps  | 103500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00689  |
|    n_updates        | 15874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.75     |
| time/               |          |
|    episodes         | 5688     |
|    fps              | 34       |
|    time_elapsed     | 2999     |
|    total_timesteps  | 103538   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 15884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.75     |
| time/               |          |
|    episodes         | 5692     |
|    fps              | 34       |
|    time_elapsed     | 2999     |
|    total_timesteps  | 103614   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.89e-05 |
|    n_updates        | 15903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.749    |
| time/               |          |
|    episodes         | 5696     |
|    fps              | 34       |
|    time_elapsed     | 3000     |
|    total_timesteps  | 103690   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000131 |
|    n_updates        | 15922    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 0.749    |
| time/               |          |
|    episodes         | 5700     |
|    fps              | 34       |
|    time_elapsed     | 3000     |
|    total_timesteps  | 103764   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.11e-05 |
|    n_updates        | 15940    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0497   |
|    exploration_rate | 0.748    |
| time/               |          |
|    episodes         | 5704     |
|    fps              | 34       |
|    time_elapsed     | 3000     |
|    total_timesteps  | 103836   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000144 |
|    n_updates        | 15958    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.748    |
| time/               |          |
|    episodes         | 5708     |
|    fps              | 34       |
|    time_elapsed     | 3001     |
|    total_timesteps  | 103896   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.24e-05 |
|    n_updates        | 15973    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0801   |
|    exploration_rate | 0.747    |
| time/               |          |
|    episodes         | 5712     |
|    fps              | 34       |
|    time_elapsed     | 3001     |
|    total_timesteps  | 103963   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.06e-05 |
|    n_updates        | 15990    |
----------------------------------
Eval num_timesteps=104000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.747    |
| time/               |          |
|    total_timesteps  | 104000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.014    |
|    n_updates        | 15999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.747    |
| time/               |          |
|    episodes         | 5716     |
|    fps              | 34       |
|    time_elapsed     | 3013     |
|    total_timesteps  | 104043   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.31e-05 |
|    n_updates        | 16010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0898   |
|    exploration_rate | 0.747    |
| time/               |          |
|    episodes         | 5720     |
|    fps              | 34       |
|    time_elapsed     | 3014     |
|    total_timesteps  | 104114   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.59e-05 |
|    n_updates        | 16028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0798   |
|    exploration_rate | 0.746    |
| time/               |          |
|    episodes         | 5724     |
|    fps              | 34       |
|    time_elapsed     | 3014     |
|    total_timesteps  | 104178   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.61e-05 |
|    n_updates        | 16044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0895   |
|    exploration_rate | 0.746    |
| time/               |          |
|    episodes         | 5728     |
|    fps              | 34       |
|    time_elapsed     | 3014     |
|    total_timesteps  | 104256   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 16063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0892   |
|    exploration_rate | 0.745    |
| time/               |          |
|    episodes         | 5732     |
|    fps              | 34       |
|    time_elapsed     | 3015     |
|    total_timesteps  | 104330   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.93e-05 |
|    n_updates        | 16082    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0888   |
|    exploration_rate | 0.745    |
| time/               |          |
|    episodes         | 5736     |
|    fps              | 34       |
|    time_elapsed     | 3015     |
|    total_timesteps  | 104412   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000114 |
|    n_updates        | 16102    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0995   |
|    exploration_rate | 0.744    |
| time/               |          |
|    episodes         | 5740     |
|    fps              | 34       |
|    time_elapsed     | 3016     |
|    total_timesteps  | 104479   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.43e-05 |
|    n_updates        | 16119    |
----------------------------------
Eval num_timesteps=104500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.744    |
| time/               |          |
|    total_timesteps  | 104500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00685  |
|    n_updates        | 16124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | 0.0886   |
|    exploration_rate | 0.744    |
| time/               |          |
|    episodes         | 5744     |
|    fps              | 34       |
|    time_elapsed     | 3031     |
|    total_timesteps  | 104574   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00715  |
|    n_updates        | 16143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0874   |
|    exploration_rate | 0.743    |
| time/               |          |
|    episodes         | 5748     |
|    fps              | 34       |
|    time_elapsed     | 3031     |
|    total_timesteps  | 104668   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.05e-05 |
|    n_updates        | 16166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0874   |
|    exploration_rate | 0.743    |
| time/               |          |
|    episodes         | 5752     |
|    fps              | 34       |
|    time_elapsed     | 3032     |
|    total_timesteps  | 104739   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000169 |
|    n_updates        | 16184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0772   |
|    exploration_rate | 0.742    |
| time/               |          |
|    episodes         | 5756     |
|    fps              | 34       |
|    time_elapsed     | 3032     |
|    total_timesteps  | 104815   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00714  |
|    n_updates        | 16203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0768   |
|    exploration_rate | 0.742    |
| time/               |          |
|    episodes         | 5760     |
|    fps              | 34       |
|    time_elapsed     | 3032     |
|    total_timesteps  | 104889   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.65e-05 |
|    n_updates        | 16222    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0771   |
|    exploration_rate | 0.742    |
| time/               |          |
|    episodes         | 5764     |
|    fps              | 34       |
|    time_elapsed     | 3033     |
|    total_timesteps  | 104955   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00817  |
|    n_updates        | 16238    |
----------------------------------
Eval num_timesteps=105000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.741    |
| time/               |          |
|    total_timesteps  | 105000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.45e-05 |
|    n_updates        | 16249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0767   |
|    exploration_rate | 0.741    |
| time/               |          |
|    episodes         | 5768     |
|    fps              | 34       |
|    time_elapsed     | 3045     |
|    total_timesteps  | 105033   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.88e-05 |
|    n_updates        | 16258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.066    |
|    exploration_rate | 0.741    |
| time/               |          |
|    episodes         | 5772     |
|    fps              | 34       |
|    time_elapsed     | 3045     |
|    total_timesteps  | 105121   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.87e-05 |
|    n_updates        | 16280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0452   |
|    exploration_rate | 0.74     |
| time/               |          |
|    episodes         | 5776     |
|    fps              | 34       |
|    time_elapsed     | 3046     |
|    total_timesteps  | 105202   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.6e-05  |
|    n_updates        | 16300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0552   |
|    exploration_rate | 0.74     |
| time/               |          |
|    episodes         | 5780     |
|    fps              | 34       |
|    time_elapsed     | 3046     |
|    total_timesteps  | 105275   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.67e-05 |
|    n_updates        | 16318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0458   |
|    exploration_rate | 0.739    |
| time/               |          |
|    episodes         | 5784     |
|    fps              | 34       |
|    time_elapsed     | 3047     |
|    total_timesteps  | 105349   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 16337    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0355   |
|    exploration_rate | 0.739    |
| time/               |          |
|    episodes         | 5788     |
|    fps              | 34       |
|    time_elapsed     | 3047     |
|    total_timesteps  | 105426   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.27e-05 |
|    n_updates        | 16356    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.738    |
| time/               |          |
|    episodes         | 5792     |
|    fps              | 34       |
|    time_elapsed     | 3047     |
|    total_timesteps  | 105489   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.47e-05 |
|    n_updates        | 16372    |
----------------------------------
Eval num_timesteps=105500, episode_reward=0.09 +/- 0.45
Episode length: 46.70 +/- 22.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.7     |
|    mean_reward      | 0.0943   |
| rollout/            |          |
|    exploration_rate | 0.738    |
| time/               |          |
|    total_timesteps  | 105500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.02e-05 |
|    n_updates        | 16374    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0362   |
|    exploration_rate | 0.738    |
| time/               |          |
|    episodes         | 5796     |
|    fps              | 34       |
|    time_elapsed     | 3056     |
|    total_timesteps  | 105561   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.16e-05 |
|    n_updates        | 16390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0365   |
|    exploration_rate | 0.738    |
| time/               |          |
|    episodes         | 5800     |
|    fps              | 34       |
|    time_elapsed     | 3056     |
|    total_timesteps  | 105629   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00712  |
|    n_updates        | 16407    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0365   |
|    exploration_rate | 0.737    |
| time/               |          |
|    episodes         | 5804     |
|    fps              | 34       |
|    time_elapsed     | 3056     |
|    total_timesteps  | 105701   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00731  |
|    n_updates        | 16425    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0254   |
|    exploration_rate | 0.737    |
| time/               |          |
|    episodes         | 5808     |
|    fps              | 34       |
|    time_elapsed     | 3057     |
|    total_timesteps  | 105789   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 16447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.00487  |
|    exploration_rate | 0.736    |
| time/               |          |
|    episodes         | 5812     |
|    fps              | 34       |
|    time_elapsed     | 3057     |
|    total_timesteps  | 105868   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00708  |
|    n_updates        | 16466    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00503 |
|    exploration_rate | 0.736    |
| time/               |          |
|    episodes         | 5816     |
|    fps              | 34       |
|    time_elapsed     | 3058     |
|    total_timesteps  | 105945   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.09e-05 |
|    n_updates        | 16486    |
----------------------------------
Eval num_timesteps=106000, episode_reward=-0.19 +/- 0.20
Episode length: 53.00 +/- 28.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53       |
|    mean_reward      | -0.192   |
| rollout/            |          |
|    exploration_rate | 0.735    |
| time/               |          |
|    total_timesteps  | 106000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00783  |
|    n_updates        | 16499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00497 |
|    exploration_rate | 0.735    |
| time/               |          |
|    episodes         | 5820     |
|    fps              | 34       |
|    time_elapsed     | 3068     |
|    total_timesteps  | 106014   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00682  |
|    n_updates        | 16503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.00521 |
|    exploration_rate | 0.735    |
| time/               |          |
|    episodes         | 5824     |
|    fps              | 34       |
|    time_elapsed     | 3069     |
|    total_timesteps  | 106084   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000162 |
|    n_updates        | 16520    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.734    |
| time/               |          |
|    episodes         | 5828     |
|    fps              | 34       |
|    time_elapsed     | 3069     |
|    total_timesteps  | 106153   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00694  |
|    n_updates        | 16538    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0151  |
|    exploration_rate | 0.734    |
| time/               |          |
|    episodes         | 5832     |
|    fps              | 34       |
|    time_elapsed     | 3070     |
|    total_timesteps  | 106234   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.77e-05 |
|    n_updates        | 16558    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0147  |
|    exploration_rate | 0.733    |
| time/               |          |
|    episodes         | 5836     |
|    fps              | 34       |
|    time_elapsed     | 3070     |
|    total_timesteps  | 106305   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000151 |
|    n_updates        | 16576    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0252  |
|    exploration_rate | 0.733    |
| time/               |          |
|    episodes         | 5840     |
|    fps              | 34       |
|    time_elapsed     | 3071     |
|    total_timesteps  | 106385   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 16596    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.733    |
| time/               |          |
|    episodes         | 5844     |
|    fps              | 34       |
|    time_elapsed     | 3071     |
|    total_timesteps  | 106465   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000158 |
|    n_updates        | 16616    |
----------------------------------
Eval num_timesteps=106500, episode_reward=-0.25 +/- 0.08
Episode length: 63.16 +/- 19.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.2     |
|    mean_reward      | -0.252   |
| rollout/            |          |
|    exploration_rate | 0.732    |
| time/               |          |
|    total_timesteps  | 106500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.21e-05 |
|    n_updates        | 16624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.732    |
| time/               |          |
|    episodes         | 5848     |
|    fps              | 34       |
|    time_elapsed     | 3081     |
|    total_timesteps  | 106534   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.07e-05 |
|    n_updates        | 16633    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.732    |
| time/               |          |
|    episodes         | 5852     |
|    fps              | 34       |
|    time_elapsed     | 3082     |
|    total_timesteps  | 106607   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000129 |
|    n_updates        | 16651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.731    |
| time/               |          |
|    episodes         | 5856     |
|    fps              | 34       |
|    time_elapsed     | 3082     |
|    total_timesteps  | 106684   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.19e-05 |
|    n_updates        | 16670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00457 |
|    exploration_rate | 0.731    |
| time/               |          |
|    episodes         | 5860     |
|    fps              | 34       |
|    time_elapsed     | 3083     |
|    total_timesteps  | 106778   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00691  |
|    n_updates        | 16694    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00493 |
|    exploration_rate | 0.73     |
| time/               |          |
|    episodes         | 5864     |
|    fps              | 34       |
|    time_elapsed     | 3083     |
|    total_timesteps  | 106853   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.09e-05 |
|    n_updates        | 16713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00511  |
|    exploration_rate | 0.73     |
| time/               |          |
|    episodes         | 5868     |
|    fps              | 34       |
|    time_elapsed     | 3083     |
|    total_timesteps  | 106930   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000158 |
|    n_updates        | 16732    |
----------------------------------
Eval num_timesteps=107000, episode_reward=-0.22 +/- 0.22
Episode length: 64.32 +/- 19.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.3     |
|    mean_reward      | -0.217   |
| rollout/            |          |
|    exploration_rate | 0.729    |
| time/               |          |
|    total_timesteps  | 107000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000143 |
|    n_updates        | 16749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00535  |
|    exploration_rate | 0.729    |
| time/               |          |
|    episodes         | 5872     |
|    fps              | 34       |
|    time_elapsed     | 3097     |
|    total_timesteps  | 107012   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00707  |
|    n_updates        | 16752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.00591  |
|    exploration_rate | 0.729    |
| time/               |          |
|    episodes         | 5876     |
|    fps              | 34       |
|    time_elapsed     | 3097     |
|    total_timesteps  | 107079   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 16769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.00619  |
|    exploration_rate | 0.728    |
| time/               |          |
|    episodes         | 5880     |
|    fps              | 34       |
|    time_elapsed     | 3098     |
|    total_timesteps  | 107145   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.67e-05 |
|    n_updates        | 16786    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0263   |
|    exploration_rate | 0.728    |
| time/               |          |
|    episodes         | 5884     |
|    fps              | 34       |
|    time_elapsed     | 3098     |
|    total_timesteps  | 107217   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.11e-05 |
|    n_updates        | 16804    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0264   |
|    exploration_rate | 0.728    |
| time/               |          |
|    episodes         | 5888     |
|    fps              | 34       |
|    time_elapsed     | 3098     |
|    total_timesteps  | 107292   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.13e-05 |
|    n_updates        | 16822    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.026    |
|    exploration_rate | 0.727    |
| time/               |          |
|    episodes         | 5892     |
|    fps              | 34       |
|    time_elapsed     | 3099     |
|    total_timesteps  | 107364   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000134 |
|    n_updates        | 16840    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.727    |
| time/               |          |
|    episodes         | 5896     |
|    fps              | 34       |
|    time_elapsed     | 3099     |
|    total_timesteps  | 107453   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.32e-05 |
|    n_updates        | 16863    |
----------------------------------
Eval num_timesteps=107500, episode_reward=-0.25 +/- 0.18
Episode length: 66.64 +/- 17.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.6     |
|    mean_reward      | -0.246   |
| rollout/            |          |
|    exploration_rate | 0.726    |
| time/               |          |
|    total_timesteps  | 107500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.64e-05 |
|    n_updates        | 16874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0351   |
|    exploration_rate | 0.726    |
| time/               |          |
|    episodes         | 5900     |
|    fps              | 34       |
|    time_elapsed     | 3113     |
|    total_timesteps  | 107528   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000159 |
|    n_updates        | 16881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0353   |
|    exploration_rate | 0.726    |
| time/               |          |
|    episodes         | 5904     |
|    fps              | 34       |
|    time_elapsed     | 3114     |
|    total_timesteps  | 107595   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0144   |
|    n_updates        | 16898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0363   |
|    exploration_rate | 0.725    |
| time/               |          |
|    episodes         | 5908     |
|    fps              | 34       |
|    time_elapsed     | 3114     |
|    total_timesteps  | 107658   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00691  |
|    n_updates        | 16914    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0358   |
|    exploration_rate | 0.725    |
| time/               |          |
|    episodes         | 5912     |
|    fps              | 34       |
|    time_elapsed     | 3114     |
|    total_timesteps  | 107750   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.03e-05 |
|    n_updates        | 16937    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.724    |
| time/               |          |
|    episodes         | 5916     |
|    fps              | 34       |
|    time_elapsed     | 3115     |
|    total_timesteps  | 107824   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.68e-05 |
|    n_updates        | 16955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0249   |
|    exploration_rate | 0.724    |
| time/               |          |
|    episodes         | 5920     |
|    fps              | 34       |
|    time_elapsed     | 3115     |
|    total_timesteps  | 107917   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 16979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.723    |
| time/               |          |
|    episodes         | 5924     |
|    fps              | 34       |
|    time_elapsed     | 3116     |
|    total_timesteps  | 107984   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0071   |
|    n_updates        | 16995    |
----------------------------------
Eval num_timesteps=108000, episode_reward=-0.10 +/- 0.24
Episode length: 34.24 +/- 26.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.2     |
|    mean_reward      | -0.0963  |
| rollout/            |          |
|    exploration_rate | 0.723    |
| time/               |          |
|    total_timesteps  | 108000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.83e-05 |
|    n_updates        | 16999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0252   |
|    exploration_rate | 0.723    |
| time/               |          |
|    episodes         | 5928     |
|    fps              | 34       |
|    time_elapsed     | 3124     |
|    total_timesteps  | 108049   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0071   |
|    n_updates        | 17012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0256   |
|    exploration_rate | 0.722    |
| time/               |          |
|    episodes         | 5932     |
|    fps              | 34       |
|    time_elapsed     | 3124     |
|    total_timesteps  | 108119   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.07e-05 |
|    n_updates        | 17029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.722    |
| time/               |          |
|    episodes         | 5936     |
|    fps              | 34       |
|    time_elapsed     | 3124     |
|    total_timesteps  | 108198   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000138 |
|    n_updates        | 17049    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | 0.0258   |
|    exploration_rate | 0.722    |
| time/               |          |
|    episodes         | 5940     |
|    fps              | 34       |
|    time_elapsed     | 3125     |
|    total_timesteps  | 108267   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.64e-05 |
|    n_updates        | 17066    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.721    |
| time/               |          |
|    episodes         | 5944     |
|    fps              | 34       |
|    time_elapsed     | 3125     |
|    total_timesteps  | 108335   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.91e-05 |
|    n_updates        | 17083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.721    |
| time/               |          |
|    episodes         | 5948     |
|    fps              | 34       |
|    time_elapsed     | 3126     |
|    total_timesteps  | 108404   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.82e-05 |
|    n_updates        | 17100    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0165   |
|    exploration_rate | 0.72     |
| time/               |          |
|    episodes         | 5952     |
|    fps              | 34       |
|    time_elapsed     | 3126     |
|    total_timesteps  | 108472   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 17117    |
----------------------------------
Eval num_timesteps=108500, episode_reward=-0.08 +/- 0.28
Episode length: 35.40 +/- 27.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 35.4     |
|    mean_reward      | -0.0808  |
| rollout/            |          |
|    exploration_rate | 0.72     |
| time/               |          |
|    total_timesteps  | 108500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.32e-05 |
|    n_updates        | 17124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.0167   |
|    exploration_rate | 0.72     |
| time/               |          |
|    episodes         | 5956     |
|    fps              | 34       |
|    time_elapsed     | 3134     |
|    total_timesteps  | 108544   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.47e-05 |
|    n_updates        | 17135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00763  |
|    exploration_rate | 0.719    |
| time/               |          |
|    episodes         | 5960     |
|    fps              | 34       |
|    time_elapsed     | 3134     |
|    total_timesteps  | 108614   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.1e-05  |
|    n_updates        | 17153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.719    |
| time/               |          |
|    episodes         | 5964     |
|    fps              | 34       |
|    time_elapsed     | 3134     |
|    total_timesteps  | 108696   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.23e-05 |
|    n_updates        | 17173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00714  |
|    exploration_rate | 0.718    |
| time/               |          |
|    episodes         | 5968     |
|    fps              | 34       |
|    time_elapsed     | 3135     |
|    total_timesteps  | 108778   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.55e-05 |
|    n_updates        | 17194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.718    |
| time/               |          |
|    episodes         | 5972     |
|    fps              | 34       |
|    time_elapsed     | 3135     |
|    total_timesteps  | 108851   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 17212    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 0.717    |
| time/               |          |
|    episodes         | 5976     |
|    fps              | 34       |
|    time_elapsed     | 3136     |
|    total_timesteps  | 108933   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.09e-05 |
|    n_updates        | 17233    |
----------------------------------
Eval num_timesteps=109000, episode_reward=-0.30 +/- 0.01
Episode length: 74.74 +/- 1.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.717    |
| time/               |          |
|    total_timesteps  | 109000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0147   |
|    n_updates        | 17249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | 0.00674  |
|    exploration_rate | 0.717    |
| time/               |          |
|    episodes         | 5980     |
|    fps              | 34       |
|    time_elapsed     | 3148     |
|    total_timesteps  | 109003   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.65e-05 |
|    n_updates        | 17250    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.717    |
| time/               |          |
|    episodes         | 5984     |
|    fps              | 34       |
|    time_elapsed     | 3148     |
|    total_timesteps  | 109075   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.49e-05 |
|    n_updates        | 17268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.716    |
| time/               |          |
|    episodes         | 5988     |
|    fps              | 34       |
|    time_elapsed     | 3149     |
|    total_timesteps  | 109152   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00017  |
|    n_updates        | 17287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.716    |
| time/               |          |
|    episodes         | 5992     |
|    fps              | 34       |
|    time_elapsed     | 3149     |
|    total_timesteps  | 109231   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00727  |
|    n_updates        | 17307    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.715    |
| time/               |          |
|    episodes         | 5996     |
|    fps              | 34       |
|    time_elapsed     | 3150     |
|    total_timesteps  | 109316   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.92e-05 |
|    n_updates        | 17328    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.715    |
| time/               |          |
|    episodes         | 6000     |
|    fps              | 34       |
|    time_elapsed     | 3150     |
|    total_timesteps  | 109384   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00705  |
|    n_updates        | 17345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0432  |
|    exploration_rate | 0.714    |
| time/               |          |
|    episodes         | 6004     |
|    fps              | 34       |
|    time_elapsed     | 3150     |
|    total_timesteps  | 109450   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.76e-05 |
|    n_updates        | 17362    |
----------------------------------
Eval num_timesteps=109500, episode_reward=-0.00 +/- 0.36
Episode length: 30.68 +/- 24.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 30.7     |
|    mean_reward      | -0.00186 |
| rollout/            |          |
|    exploration_rate | 0.714    |
| time/               |          |
|    total_timesteps  | 109500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000135 |
|    n_updates        | 17374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.714    |
| time/               |          |
|    episodes         | 6008     |
|    fps              | 34       |
|    time_elapsed     | 3157     |
|    total_timesteps  | 109533   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00757  |
|    n_updates        | 17383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.713    |
| time/               |          |
|    episodes         | 6012     |
|    fps              | 34       |
|    time_elapsed     | 3158     |
|    total_timesteps  | 109606   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.44e-05 |
|    n_updates        | 17401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.713    |
| time/               |          |
|    episodes         | 6016     |
|    fps              | 34       |
|    time_elapsed     | 3158     |
|    total_timesteps  | 109674   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00739  |
|    n_updates        | 17418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.712    |
| time/               |          |
|    episodes         | 6020     |
|    fps              | 34       |
|    time_elapsed     | 3159     |
|    total_timesteps  | 109751   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00717  |
|    n_updates        | 17437    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.712    |
| time/               |          |
|    episodes         | 6024     |
|    fps              | 34       |
|    time_elapsed     | 3159     |
|    total_timesteps  | 109835   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.47e-05 |
|    n_updates        | 17458    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.712    |
| time/               |          |
|    episodes         | 6028     |
|    fps              | 34       |
|    time_elapsed     | 3159     |
|    total_timesteps  | 109904   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.16e-05 |
|    n_updates        | 17475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.711    |
| time/               |          |
|    episodes         | 6032     |
|    fps              | 34       |
|    time_elapsed     | 3160     |
|    total_timesteps  | 109974   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 17493    |
----------------------------------
Eval num_timesteps=110000, episode_reward=-0.29 +/- 0.04
Episode length: 72.72 +/- 9.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.7     |
|    mean_reward      | -0.291   |
| rollout/            |          |
|    exploration_rate | 0.711    |
| time/               |          |
|    total_timesteps  | 110000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000136 |
|    n_updates        | 17499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.711    |
| time/               |          |
|    episodes         | 6036     |
|    fps              | 34       |
|    time_elapsed     | 3175     |
|    total_timesteps  | 110046   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.11e-05 |
|    n_updates        | 17511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.71     |
| time/               |          |
|    episodes         | 6040     |
|    fps              | 34       |
|    time_elapsed     | 3175     |
|    total_timesteps  | 110130   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.69e-05 |
|    n_updates        | 17532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.71     |
| time/               |          |
|    episodes         | 6044     |
|    fps              | 34       |
|    time_elapsed     | 3175     |
|    total_timesteps  | 110200   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00699  |
|    n_updates        | 17549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.709    |
| time/               |          |
|    episodes         | 6048     |
|    fps              | 34       |
|    time_elapsed     | 3176     |
|    total_timesteps  | 110267   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000162 |
|    n_updates        | 17566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.709    |
| time/               |          |
|    episodes         | 6052     |
|    fps              | 34       |
|    time_elapsed     | 3176     |
|    total_timesteps  | 110335   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.06e-05 |
|    n_updates        | 17583    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.708    |
| time/               |          |
|    episodes         | 6056     |
|    fps              | 34       |
|    time_elapsed     | 3176     |
|    total_timesteps  | 110408   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00701  |
|    n_updates        | 17601    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.708    |
| time/               |          |
|    episodes         | 6060     |
|    fps              | 34       |
|    time_elapsed     | 3177     |
|    total_timesteps  | 110482   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000149 |
|    n_updates        | 17620    |
----------------------------------
Eval num_timesteps=110500, episode_reward=-0.01 +/- 0.24
Episode length: 16.88 +/- 0.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.9     |
|    mean_reward      | -0.00652 |
| rollout/            |          |
|    exploration_rate | 0.708    |
| time/               |          |
|    total_timesteps  | 110500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000218 |
|    n_updates        | 17624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.708    |
| time/               |          |
|    episodes         | 6064     |
|    fps              | 34       |
|    time_elapsed     | 3181     |
|    total_timesteps  | 110547   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.87e-05 |
|    n_updates        | 17636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00256 |
|    exploration_rate | 0.707    |
| time/               |          |
|    episodes         | 6068     |
|    fps              | 34       |
|    time_elapsed     | 3182     |
|    total_timesteps  | 110617   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00705  |
|    n_updates        | 17654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00259 |
|    exploration_rate | 0.707    |
| time/               |          |
|    episodes         | 6072     |
|    fps              | 34       |
|    time_elapsed     | 3182     |
|    total_timesteps  | 110691   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000171 |
|    n_updates        | 17672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00223 |
|    exploration_rate | 0.706    |
| time/               |          |
|    episodes         | 6076     |
|    fps              | 34       |
|    time_elapsed     | 3183     |
|    total_timesteps  | 110764   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.16e-05 |
|    n_updates        | 17690    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00727  |
|    exploration_rate | 0.706    |
| time/               |          |
|    episodes         | 6080     |
|    fps              | 34       |
|    time_elapsed     | 3183     |
|    total_timesteps  | 110847   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.57e-05 |
|    n_updates        | 17711    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00711  |
|    exploration_rate | 0.705    |
| time/               |          |
|    episodes         | 6084     |
|    fps              | 34       |
|    time_elapsed     | 3184     |
|    total_timesteps  | 110923   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00787  |
|    n_updates        | 17730    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00731  |
|    exploration_rate | 0.705    |
| time/               |          |
|    episodes         | 6088     |
|    fps              | 34       |
|    time_elapsed     | 3184     |
|    total_timesteps  | 110995   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.17e-05 |
|    n_updates        | 17748    |
----------------------------------
Eval num_timesteps=111000, episode_reward=-0.01 +/- 0.24
Episode length: 16.88 +/- 0.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.9     |
|    mean_reward      | -0.00656 |
| rollout/            |          |
|    exploration_rate | 0.705    |
| time/               |          |
|    total_timesteps  | 111000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.007    |
|    n_updates        | 17749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00783  |
|    exploration_rate | 0.704    |
| time/               |          |
|    episodes         | 6092     |
|    fps              | 34       |
|    time_elapsed     | 3188     |
|    total_timesteps  | 111061   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0139   |
|    n_updates        | 17765    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0181   |
|    exploration_rate | 0.704    |
| time/               |          |
|    episodes         | 6096     |
|    fps              | 34       |
|    time_elapsed     | 3189     |
|    total_timesteps  | 111139   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000112 |
|    n_updates        | 17784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.703    |
| time/               |          |
|    episodes         | 6100     |
|    fps              | 34       |
|    time_elapsed     | 3189     |
|    total_timesteps  | 111206   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 17801    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.703    |
| time/               |          |
|    episodes         | 6104     |
|    fps              | 34       |
|    time_elapsed     | 3190     |
|    total_timesteps  | 111285   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000138 |
|    n_updates        | 17821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.702    |
| time/               |          |
|    episodes         | 6108     |
|    fps              | 34       |
|    time_elapsed     | 3190     |
|    total_timesteps  | 111367   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.12e-05 |
|    n_updates        | 17841    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00739  |
|    exploration_rate | 0.702    |
| time/               |          |
|    episodes         | 6112     |
|    fps              | 34       |
|    time_elapsed     | 3190     |
|    total_timesteps  | 111447   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000127 |
|    n_updates        | 17861    |
----------------------------------
Eval num_timesteps=111500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.702    |
| time/               |          |
|    total_timesteps  | 111500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000139 |
|    n_updates        | 17874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | 0.00715  |
|    exploration_rate | 0.701    |
| time/               |          |
|    episodes         | 6116     |
|    fps              | 34       |
|    time_elapsed     | 3202     |
|    total_timesteps  | 111521   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000127 |
|    n_updates        | 17880    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0026  |
|    exploration_rate | 0.701    |
| time/               |          |
|    episodes         | 6120     |
|    fps              | 34       |
|    time_elapsed     | 3203     |
|    total_timesteps  | 111592   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00716  |
|    n_updates        | 17897    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00228 |
|    exploration_rate | 0.701    |
| time/               |          |
|    episodes         | 6124     |
|    fps              | 34       |
|    time_elapsed     | 3203     |
|    total_timesteps  | 111668   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 17916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00224 |
|    exploration_rate | 0.7      |
| time/               |          |
|    episodes         | 6128     |
|    fps              | 34       |
|    time_elapsed     | 3204     |
|    total_timesteps  | 111736   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.73e-05 |
|    n_updates        | 17933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.7      |
| time/               |          |
|    episodes         | 6132     |
|    fps              | 34       |
|    time_elapsed     | 3204     |
|    total_timesteps  | 111807   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.81e-05 |
|    n_updates        | 17951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.699    |
| time/               |          |
|    episodes         | 6136     |
|    fps              | 34       |
|    time_elapsed     | 3204     |
|    total_timesteps  | 111880   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000132 |
|    n_updates        | 17969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 0.699    |
| time/               |          |
|    episodes         | 6140     |
|    fps              | 34       |
|    time_elapsed     | 3205     |
|    total_timesteps  | 111965   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 17991    |
----------------------------------
Eval num_timesteps=112000, episode_reward=-0.02 +/- 0.29
Episode length: 24.36 +/- 18.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 24.4     |
|    mean_reward      | -0.0165  |
| rollout/            |          |
|    exploration_rate | 0.698    |
| time/               |          |
|    total_timesteps  | 112000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.68e-05 |
|    n_updates        | 17999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00206 |
|    exploration_rate | 0.698    |
| time/               |          |
|    episodes         | 6144     |
|    fps              | 34       |
|    time_elapsed     | 3211     |
|    total_timesteps  | 112027   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.65e-05 |
|    n_updates        | 18006    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00234 |
|    exploration_rate | 0.698    |
| time/               |          |
|    episodes         | 6148     |
|    fps              | 34       |
|    time_elapsed     | 3211     |
|    total_timesteps  | 112101   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.22e-05 |
|    n_updates        | 18025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00234 |
|    exploration_rate | 0.697    |
| time/               |          |
|    episodes         | 6152     |
|    fps              | 34       |
|    time_elapsed     | 3211     |
|    total_timesteps  | 112169   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.75e-05 |
|    n_updates        | 18042    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00242 |
|    exploration_rate | 0.697    |
| time/               |          |
|    episodes         | 6156     |
|    fps              | 34       |
|    time_elapsed     | 3212     |
|    total_timesteps  | 112244   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.61e-05 |
|    n_updates        | 18060    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.00761  |
|    exploration_rate | 0.696    |
| time/               |          |
|    episodes         | 6160     |
|    fps              | 34       |
|    time_elapsed     | 3212     |
|    total_timesteps  | 112317   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00789  |
|    n_updates        | 18079    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.00773  |
|    exploration_rate | 0.696    |
| time/               |          |
|    episodes         | 6164     |
|    fps              | 34       |
|    time_elapsed     | 3213     |
|    total_timesteps  | 112379   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000131 |
|    n_updates        | 18094    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.00267 |
|    exploration_rate | 0.696    |
| time/               |          |
|    episodes         | 6168     |
|    fps              | 34       |
|    time_elapsed     | 3213     |
|    total_timesteps  | 112459   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.53e-05 |
|    n_updates        | 18114    |
----------------------------------
Eval num_timesteps=112500, episode_reward=-0.03 +/- 0.20
Episode length: 17.84 +/- 2.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.8     |
|    mean_reward      | -0.0304  |
| rollout/            |          |
|    exploration_rate | 0.695    |
| time/               |          |
|    total_timesteps  | 112500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.49e-05 |
|    n_updates        | 18124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.695    |
| time/               |          |
|    episodes         | 6172     |
|    fps              | 34       |
|    time_elapsed     | 3218     |
|    total_timesteps  | 112539   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00014  |
|    n_updates        | 18134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.695    |
| time/               |          |
|    episodes         | 6176     |
|    fps              | 34       |
|    time_elapsed     | 3218     |
|    total_timesteps  | 112620   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00697  |
|    n_updates        | 18154    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.694    |
| time/               |          |
|    episodes         | 6180     |
|    fps              | 35       |
|    time_elapsed     | 3219     |
|    total_timesteps  | 112701   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.19e-05 |
|    n_updates        | 18175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.694    |
| time/               |          |
|    episodes         | 6184     |
|    fps              | 35       |
|    time_elapsed     | 3219     |
|    total_timesteps  | 112782   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0069   |
|    n_updates        | 18195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.693    |
| time/               |          |
|    episodes         | 6188     |
|    fps              | 35       |
|    time_elapsed     | 3220     |
|    total_timesteps  | 112884   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000109 |
|    n_updates        | 18220    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0251  |
|    exploration_rate | 0.692    |
| time/               |          |
|    episodes         | 6192     |
|    fps              | 35       |
|    time_elapsed     | 3220     |
|    total_timesteps  | 112964   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000136 |
|    n_updates        | 18240    |
----------------------------------
Eval num_timesteps=113000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.692    |
| time/               |          |
|    total_timesteps  | 113000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.57e-05 |
|    n_updates        | 18249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0348  |
|    exploration_rate | 0.692    |
| time/               |          |
|    episodes         | 6196     |
|    fps              | 34       |
|    time_elapsed     | 3232     |
|    total_timesteps  | 113034   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00688  |
|    n_updates        | 18258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0353  |
|    exploration_rate | 0.691    |
| time/               |          |
|    episodes         | 6200     |
|    fps              | 34       |
|    time_elapsed     | 3233     |
|    total_timesteps  | 113112   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.95e-05 |
|    n_updates        | 18277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0357  |
|    exploration_rate | 0.691    |
| time/               |          |
|    episodes         | 6204     |
|    fps              | 35       |
|    time_elapsed     | 3233     |
|    total_timesteps  | 113201   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.38e-05 |
|    n_updates        | 18300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0361  |
|    exploration_rate | 0.69     |
| time/               |          |
|    episodes         | 6208     |
|    fps              | 35       |
|    time_elapsed     | 3234     |
|    total_timesteps  | 113295   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.08e-05 |
|    n_updates        | 18323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0361  |
|    exploration_rate | 0.69     |
| time/               |          |
|    episodes         | 6212     |
|    fps              | 35       |
|    time_elapsed     | 3234     |
|    total_timesteps  | 113374   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.77e-05 |
|    n_updates        | 18343    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0361  |
|    exploration_rate | 0.689    |
| time/               |          |
|    episodes         | 6216     |
|    fps              | 35       |
|    time_elapsed     | 3235     |
|    total_timesteps  | 113447   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.41e-05 |
|    n_updates        | 18361    |
----------------------------------
Eval num_timesteps=113500, episode_reward=-0.08 +/- 0.28
Episode length: 34.80 +/- 26.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.8     |
|    mean_reward      | -0.0785  |
| rollout/            |          |
|    exploration_rate | 0.689    |
| time/               |          |
|    total_timesteps  | 113500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000107 |
|    n_updates        | 18374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0361  |
|    exploration_rate | 0.689    |
| time/               |          |
|    episodes         | 6220     |
|    fps              | 34       |
|    time_elapsed     | 3243     |
|    total_timesteps  | 113520   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00699  |
|    n_updates        | 18379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0255  |
|    exploration_rate | 0.688    |
| time/               |          |
|    episodes         | 6224     |
|    fps              | 35       |
|    time_elapsed     | 3244     |
|    total_timesteps  | 113581   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00692  |
|    n_updates        | 18395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0255  |
|    exploration_rate | 0.688    |
| time/               |          |
|    episodes         | 6228     |
|    fps              | 35       |
|    time_elapsed     | 3244     |
|    total_timesteps  | 113648   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.91e-05 |
|    n_updates        | 18411    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.688    |
| time/               |          |
|    episodes         | 6232     |
|    fps              | 35       |
|    time_elapsed     | 3244     |
|    total_timesteps  | 113723   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000114 |
|    n_updates        | 18430    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0159  |
|    exploration_rate | 0.687    |
| time/               |          |
|    episodes         | 6236     |
|    fps              | 35       |
|    time_elapsed     | 3245     |
|    total_timesteps  | 113802   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000137 |
|    n_updates        | 18450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0153  |
|    exploration_rate | 0.687    |
| time/               |          |
|    episodes         | 6240     |
|    fps              | 35       |
|    time_elapsed     | 3245     |
|    total_timesteps  | 113872   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.62e-05 |
|    n_updates        | 18467    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0259  |
|    exploration_rate | 0.686    |
| time/               |          |
|    episodes         | 6244     |
|    fps              | 35       |
|    time_elapsed     | 3246     |
|    total_timesteps  | 113949   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.55e-05 |
|    n_updates        | 18487    |
----------------------------------
Eval num_timesteps=114000, episode_reward=-0.29 +/- 0.05
Episode length: 71.98 +/- 11.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72       |
|    mean_reward      | -0.288   |
| rollout/            |          |
|    exploration_rate | 0.686    |
| time/               |          |
|    total_timesteps  | 114000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000151 |
|    n_updates        | 18499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0156  |
|    exploration_rate | 0.686    |
| time/               |          |
|    episodes         | 6248     |
|    fps              | 34       |
|    time_elapsed     | 3258     |
|    total_timesteps  | 114017   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.59e-05 |
|    n_updates        | 18504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0165  |
|    exploration_rate | 0.685    |
| time/               |          |
|    episodes         | 6252     |
|    fps              | 35       |
|    time_elapsed     | 3258     |
|    total_timesteps  | 114106   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00673  |
|    n_updates        | 18526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0264  |
|    exploration_rate | 0.685    |
| time/               |          |
|    episodes         | 6256     |
|    fps              | 35       |
|    time_elapsed     | 3259     |
|    total_timesteps  | 114180   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0136   |
|    n_updates        | 18544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0264  |
|    exploration_rate | 0.684    |
| time/               |          |
|    episodes         | 6260     |
|    fps              | 35       |
|    time_elapsed     | 3259     |
|    total_timesteps  | 114253   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.87e-05 |
|    n_updates        | 18563    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0367  |
|    exploration_rate | 0.684    |
| time/               |          |
|    episodes         | 6264     |
|    fps              | 35       |
|    time_elapsed     | 3259     |
|    total_timesteps  | 114321   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.62e-05 |
|    n_updates        | 18580    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0365  |
|    exploration_rate | 0.683    |
| time/               |          |
|    episodes         | 6268     |
|    fps              | 35       |
|    time_elapsed     | 3260     |
|    total_timesteps  | 114397   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00773  |
|    n_updates        | 18599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0362  |
|    exploration_rate | 0.683    |
| time/               |          |
|    episodes         | 6272     |
|    fps              | 35       |
|    time_elapsed     | 3260     |
|    total_timesteps  | 114470   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0071   |
|    n_updates        | 18617    |
----------------------------------
Eval num_timesteps=114500, episode_reward=-0.03 +/- 0.38
Episode length: 41.98 +/- 22.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42       |
|    mean_reward      | -0.027   |
| rollout/            |          |
|    exploration_rate | 0.683    |
| time/               |          |
|    total_timesteps  | 114500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000121 |
|    n_updates        | 18624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.682    |
| time/               |          |
|    episodes         | 6276     |
|    fps              | 35       |
|    time_elapsed     | 3270     |
|    total_timesteps  | 114539   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.97e-05 |
|    n_updates        | 18634    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.682    |
| time/               |          |
|    episodes         | 6280     |
|    fps              | 35       |
|    time_elapsed     | 3271     |
|    total_timesteps  | 114619   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.93e-05 |
|    n_updates        | 18654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.681    |
| time/               |          |
|    episodes         | 6284     |
|    fps              | 35       |
|    time_elapsed     | 3271     |
|    total_timesteps  | 114700   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.97e-05 |
|    n_updates        | 18674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.681    |
| time/               |          |
|    episodes         | 6288     |
|    fps              | 35       |
|    time_elapsed     | 3272     |
|    total_timesteps  | 114770   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.52e-05 |
|    n_updates        | 18692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.68     |
| time/               |          |
|    episodes         | 6292     |
|    fps              | 35       |
|    time_elapsed     | 3272     |
|    total_timesteps  | 114854   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.4e-05  |
|    n_updates        | 18713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0247  |
|    exploration_rate | 0.68     |
| time/               |          |
|    episodes         | 6296     |
|    fps              | 35       |
|    time_elapsed     | 3272     |
|    total_timesteps  | 114928   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.94e-05 |
|    n_updates        | 18731    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.679    |
| time/               |          |
|    episodes         | 6300     |
|    fps              | 35       |
|    time_elapsed     | 3273     |
|    total_timesteps  | 114994   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.36e-05 |
|    n_updates        | 18748    |
----------------------------------
Eval num_timesteps=115000, episode_reward=0.05 +/- 0.33
Episode length: 17.86 +/- 8.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.9     |
|    mean_reward      | 0.0496   |
| rollout/            |          |
|    exploration_rate | 0.679    |
| time/               |          |
|    total_timesteps  | 115000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000108 |
|    n_updates        | 18749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.679    |
| time/               |          |
|    episodes         | 6304     |
|    fps              | 35       |
|    time_elapsed     | 3277     |
|    total_timesteps  | 115062   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.49e-05 |
|    n_updates        | 18765    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.679    |
| time/               |          |
|    episodes         | 6308     |
|    fps              | 35       |
|    time_elapsed     | 3278     |
|    total_timesteps  | 115138   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 18784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.678    |
| time/               |          |
|    episodes         | 6312     |
|    fps              | 35       |
|    time_elapsed     | 3278     |
|    total_timesteps  | 115210   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00723  |
|    n_updates        | 18802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.678    |
| time/               |          |
|    episodes         | 6316     |
|    fps              | 35       |
|    time_elapsed     | 3279     |
|    total_timesteps  | 115288   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000153 |
|    n_updates        | 18821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0225  |
|    exploration_rate | 0.677    |
| time/               |          |
|    episodes         | 6320     |
|    fps              | 35       |
|    time_elapsed     | 3279     |
|    total_timesteps  | 115358   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.93e-05 |
|    n_updates        | 18839    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.677    |
| time/               |          |
|    episodes         | 6324     |
|    fps              | 35       |
|    time_elapsed     | 3279     |
|    total_timesteps  | 115436   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.84e-05 |
|    n_updates        | 18858    |
----------------------------------
Eval num_timesteps=115500, episode_reward=-0.23 +/- 0.18
Episode length: 62.78 +/- 18.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.8     |
|    mean_reward      | -0.231   |
| rollout/            |          |
|    exploration_rate | 0.676    |
| time/               |          |
|    total_timesteps  | 115500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.93e-05 |
|    n_updates        | 18874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0336  |
|    exploration_rate | 0.676    |
| time/               |          |
|    episodes         | 6328     |
|    fps              | 35       |
|    time_elapsed     | 3292     |
|    total_timesteps  | 115515   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00695  |
|    n_updates        | 18878    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0342  |
|    exploration_rate | 0.676    |
| time/               |          |
|    episodes         | 6332     |
|    fps              | 35       |
|    time_elapsed     | 3293     |
|    total_timesteps  | 115603   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00693  |
|    n_updates        | 18900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0443  |
|    exploration_rate | 0.675    |
| time/               |          |
|    episodes         | 6336     |
|    fps              | 35       |
|    time_elapsed     | 3293     |
|    total_timesteps  | 115686   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.05e-05 |
|    n_updates        | 18921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0448  |
|    exploration_rate | 0.674    |
| time/               |          |
|    episodes         | 6340     |
|    fps              | 35       |
|    time_elapsed     | 3294     |
|    total_timesteps  | 115767   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.45e-05 |
|    n_updates        | 18941    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0451  |
|    exploration_rate | 0.674    |
| time/               |          |
|    episodes         | 6344     |
|    fps              | 35       |
|    time_elapsed     | 3294     |
|    total_timesteps  | 115852   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00695  |
|    n_updates        | 18962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0466  |
|    exploration_rate | 0.673    |
| time/               |          |
|    episodes         | 6348     |
|    fps              | 35       |
|    time_elapsed     | 3295     |
|    total_timesteps  | 115959   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 18989    |
----------------------------------
Eval num_timesteps=116000, episode_reward=-0.29 +/- 0.04
Episode length: 72.18 +/- 9.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.2     |
|    mean_reward      | -0.289   |
| rollout/            |          |
|    exploration_rate | 0.673    |
| time/               |          |
|    total_timesteps  | 116000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 18999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0462  |
|    exploration_rate | 0.673    |
| time/               |          |
|    episodes         | 6352     |
|    fps              | 35       |
|    time_elapsed     | 3307     |
|    total_timesteps  | 116038   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.84e-05 |
|    n_updates        | 19009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0464  |
|    exploration_rate | 0.672    |
| time/               |          |
|    episodes         | 6356     |
|    fps              | 35       |
|    time_elapsed     | 3307     |
|    total_timesteps  | 116115   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000129 |
|    n_updates        | 19028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0461  |
|    exploration_rate | 0.672    |
| time/               |          |
|    episodes         | 6360     |
|    fps              | 35       |
|    time_elapsed     | 3308     |
|    total_timesteps  | 116181   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.15e-05 |
|    n_updates        | 19045    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0469  |
|    exploration_rate | 0.671    |
| time/               |          |
|    episodes         | 6364     |
|    fps              | 35       |
|    time_elapsed     | 3308     |
|    total_timesteps  | 116269   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 19067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0465  |
|    exploration_rate | 0.671    |
| time/               |          |
|    episodes         | 6368     |
|    fps              | 35       |
|    time_elapsed     | 3309     |
|    total_timesteps  | 116336   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.46e-05 |
|    n_updates        | 19083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.0476  |
|    exploration_rate | 0.67     |
| time/               |          |
|    episodes         | 6372     |
|    fps              | 35       |
|    time_elapsed     | 3309     |
|    total_timesteps  | 116437   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000107 |
|    n_updates        | 19109    |
----------------------------------
Eval num_timesteps=116500, episode_reward=-0.01 +/- 0.24
Episode length: 16.98 +/- 0.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17       |
|    mean_reward      | -0.00686 |
| rollout/            |          |
|    exploration_rate | 0.67     |
| time/               |          |
|    total_timesteps  | 116500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.73e-05 |
|    n_updates        | 19124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0476  |
|    exploration_rate | 0.67     |
| time/               |          |
|    episodes         | 6376     |
|    fps              | 35       |
|    time_elapsed     | 3313     |
|    total_timesteps  | 116504   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.21e-05 |
|    n_updates        | 19125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0472  |
|    exploration_rate | 0.669    |
| time/               |          |
|    episodes         | 6380     |
|    fps              | 35       |
|    time_elapsed     | 3314     |
|    total_timesteps  | 116575   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.47e-05 |
|    n_updates        | 19143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0466  |
|    exploration_rate | 0.669    |
| time/               |          |
|    episodes         | 6384     |
|    fps              | 35       |
|    time_elapsed     | 3314     |
|    total_timesteps  | 116640   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.15e-05 |
|    n_updates        | 19159    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0472  |
|    exploration_rate | 0.668    |
| time/               |          |
|    episodes         | 6388     |
|    fps              | 35       |
|    time_elapsed     | 3315     |
|    total_timesteps  | 116727   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.92e-05 |
|    n_updates        | 19181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0476  |
|    exploration_rate | 0.668    |
| time/               |          |
|    episodes         | 6392     |
|    fps              | 35       |
|    time_elapsed     | 3315     |
|    total_timesteps  | 116819   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00786  |
|    n_updates        | 19204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.0479  |
|    exploration_rate | 0.667    |
| time/               |          |
|    episodes         | 6396     |
|    fps              | 35       |
|    time_elapsed     | 3316     |
|    total_timesteps  | 116902   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00697  |
|    n_updates        | 19225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0486  |
|    exploration_rate | 0.667    |
| time/               |          |
|    episodes         | 6400     |
|    fps              | 35       |
|    time_elapsed     | 3316     |
|    total_timesteps  | 116985   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.98e-05 |
|    n_updates        | 19246    |
----------------------------------
Eval num_timesteps=117000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.666    |
| time/               |          |
|    total_timesteps  | 117000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.68e-05 |
|    n_updates        | 19249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0386  |
|    exploration_rate | 0.666    |
| time/               |          |
|    episodes         | 6404     |
|    fps              | 35       |
|    time_elapsed     | 3328     |
|    total_timesteps  | 117053   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000158 |
|    n_updates        | 19263    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.0389  |
|    exploration_rate | 0.666    |
| time/               |          |
|    episodes         | 6408     |
|    fps              | 35       |
|    time_elapsed     | 3329     |
|    total_timesteps  | 117137   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000127 |
|    n_updates        | 19284    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0398  |
|    exploration_rate | 0.665    |
| time/               |          |
|    episodes         | 6412     |
|    fps              | 35       |
|    time_elapsed     | 3329     |
|    total_timesteps  | 117231   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.18e-05 |
|    n_updates        | 19307    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0398  |
|    exploration_rate | 0.664    |
| time/               |          |
|    episodes         | 6416     |
|    fps              | 35       |
|    time_elapsed     | 3330     |
|    total_timesteps  | 117309   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00693  |
|    n_updates        | 19327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0409  |
|    exploration_rate | 0.664    |
| time/               |          |
|    episodes         | 6420     |
|    fps              | 35       |
|    time_elapsed     | 3330     |
|    total_timesteps  | 117407   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00015  |
|    n_updates        | 19351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0408  |
|    exploration_rate | 0.663    |
| time/               |          |
|    episodes         | 6424     |
|    fps              | 35       |
|    time_elapsed     | 3331     |
|    total_timesteps  | 117481   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.7e-05  |
|    n_updates        | 19370    |
----------------------------------
Eval num_timesteps=117500, episode_reward=-0.02 +/- 0.39
Episode length: 49.04 +/- 21.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49       |
|    mean_reward      | -0.0154  |
| rollout/            |          |
|    exploration_rate | 0.663    |
| time/               |          |
|    total_timesteps  | 117500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000167 |
|    n_updates        | 19374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0408  |
|    exploration_rate | 0.663    |
| time/               |          |
|    episodes         | 6428     |
|    fps              | 35       |
|    time_elapsed     | 3339     |
|    total_timesteps  | 117560   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.24e-05 |
|    n_updates        | 19389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0404  |
|    exploration_rate | 0.662    |
| time/               |          |
|    episodes         | 6432     |
|    fps              | 35       |
|    time_elapsed     | 3340     |
|    total_timesteps  | 117639   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0078   |
|    n_updates        | 19409    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0401  |
|    exploration_rate | 0.662    |
| time/               |          |
|    episodes         | 6436     |
|    fps              | 35       |
|    time_elapsed     | 3340     |
|    total_timesteps  | 117714   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00715  |
|    n_updates        | 19428    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0399  |
|    exploration_rate | 0.661    |
| time/               |          |
|    episodes         | 6440     |
|    fps              | 35       |
|    time_elapsed     | 3341     |
|    total_timesteps  | 117789   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.45e-05 |
|    n_updates        | 19447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0401  |
|    exploration_rate | 0.661    |
| time/               |          |
|    episodes         | 6444     |
|    fps              | 35       |
|    time_elapsed     | 3341     |
|    total_timesteps  | 117881   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000182 |
|    n_updates        | 19470    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0284  |
|    exploration_rate | 0.66     |
| time/               |          |
|    episodes         | 6448     |
|    fps              | 35       |
|    time_elapsed     | 3342     |
|    total_timesteps  | 117945   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00013  |
|    n_updates        | 19486    |
----------------------------------
Eval num_timesteps=118000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.66     |
| time/               |          |
|    total_timesteps  | 118000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.54e-05 |
|    n_updates        | 19499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0281  |
|    exploration_rate | 0.66     |
| time/               |          |
|    episodes         | 6452     |
|    fps              | 35       |
|    time_elapsed     | 3357     |
|    total_timesteps  | 118017   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 19504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0281  |
|    exploration_rate | 0.659    |
| time/               |          |
|    episodes         | 6456     |
|    fps              | 35       |
|    time_elapsed     | 3357     |
|    total_timesteps  | 118092   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.36e-05 |
|    n_updates        | 19522    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0285  |
|    exploration_rate | 0.659    |
| time/               |          |
|    episodes         | 6460     |
|    fps              | 35       |
|    time_elapsed     | 3358     |
|    total_timesteps  | 118168   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.15e-05 |
|    n_updates        | 19541    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0283  |
|    exploration_rate | 0.658    |
| time/               |          |
|    episodes         | 6464     |
|    fps              | 35       |
|    time_elapsed     | 3358     |
|    total_timesteps  | 118252   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000139 |
|    n_updates        | 19562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0187  |
|    exploration_rate | 0.658    |
| time/               |          |
|    episodes         | 6468     |
|    fps              | 35       |
|    time_elapsed     | 3359     |
|    total_timesteps  | 118331   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000104 |
|    n_updates        | 19582    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00214  |
|    exploration_rate | 0.657    |
| time/               |          |
|    episodes         | 6472     |
|    fps              | 35       |
|    time_elapsed     | 3359     |
|    total_timesteps  | 118410   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.09e-05 |
|    n_updates        | 19602    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.00205  |
|    exploration_rate | 0.657    |
| time/               |          |
|    episodes         | 6476     |
|    fps              | 35       |
|    time_elapsed     | 3359     |
|    total_timesteps  | 118479   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.88e-05 |
|    n_updates        | 19619    |
----------------------------------
Eval num_timesteps=118500, episode_reward=-0.25 +/- 0.21
Episode length: 71.58 +/- 11.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.6     |
|    mean_reward      | -0.246   |
| rollout/            |          |
|    exploration_rate | 0.657    |
| time/               |          |
|    total_timesteps  | 118500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000107 |
|    n_updates        | 19624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.0121   |
|    exploration_rate | 0.656    |
| time/               |          |
|    episodes         | 6480     |
|    fps              | 35       |
|    time_elapsed     | 3371     |
|    total_timesteps  | 118548   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000121 |
|    n_updates        | 19636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 0.656    |
| time/               |          |
|    episodes         | 6484     |
|    fps              | 35       |
|    time_elapsed     | 3372     |
|    total_timesteps  | 118624   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00769  |
|    n_updates        | 19655    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.0119   |
|    exploration_rate | 0.655    |
| time/               |          |
|    episodes         | 6488     |
|    fps              | 35       |
|    time_elapsed     | 3372     |
|    total_timesteps  | 118706   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00788  |
|    n_updates        | 19676    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.0122   |
|    exploration_rate | 0.655    |
| time/               |          |
|    episodes         | 6492     |
|    fps              | 35       |
|    time_elapsed     | 3373     |
|    total_timesteps  | 118790   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.95e-05 |
|    n_updates        | 19697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.0231   |
|    exploration_rate | 0.654    |
| time/               |          |
|    episodes         | 6496     |
|    fps              | 35       |
|    time_elapsed     | 3373     |
|    total_timesteps  | 118850   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.97e-05 |
|    n_updates        | 19712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.0229   |
|    exploration_rate | 0.654    |
| time/               |          |
|    episodes         | 6500     |
|    fps              | 35       |
|    time_elapsed     | 3373     |
|    total_timesteps  | 118939   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00787  |
|    n_updates        | 19734    |
----------------------------------
Eval num_timesteps=119000, episode_reward=-0.08 +/- 0.21
Episode length: 29.26 +/- 21.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 29.3     |
|    mean_reward      | -0.0761  |
| rollout/            |          |
|    exploration_rate | 0.653    |
| time/               |          |
|    total_timesteps  | 119000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 19749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.0223   |
|    exploration_rate | 0.653    |
| time/               |          |
|    episodes         | 6504     |
|    fps              | 35       |
|    time_elapsed     | 3380     |
|    total_timesteps  | 119023   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.16e-05 |
|    n_updates        | 19755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.0227   |
|    exploration_rate | 0.653    |
| time/               |          |
|    episodes         | 6508     |
|    fps              | 35       |
|    time_elapsed     | 3381     |
|    total_timesteps  | 119097   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00682  |
|    n_updates        | 19774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0234   |
|    exploration_rate | 0.652    |
| time/               |          |
|    episodes         | 6512     |
|    fps              | 35       |
|    time_elapsed     | 3381     |
|    total_timesteps  | 119174   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00681  |
|    n_updates        | 19793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0436   |
|    exploration_rate | 0.652    |
| time/               |          |
|    episodes         | 6516     |
|    fps              | 35       |
|    time_elapsed     | 3382     |
|    total_timesteps  | 119246   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.45e-05 |
|    n_updates        | 19811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0544   |
|    exploration_rate | 0.651    |
| time/               |          |
|    episodes         | 6520     |
|    fps              | 35       |
|    time_elapsed     | 3382     |
|    total_timesteps  | 119324   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000181 |
|    n_updates        | 19830    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0544   |
|    exploration_rate | 0.651    |
| time/               |          |
|    episodes         | 6524     |
|    fps              | 35       |
|    time_elapsed     | 3382     |
|    total_timesteps  | 119397   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.2e-05  |
|    n_updates        | 19849    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0539   |
|    exploration_rate | 0.65     |
| time/               |          |
|    episodes         | 6528     |
|    fps              | 35       |
|    time_elapsed     | 3383     |
|    total_timesteps  | 119489   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00015  |
|    n_updates        | 19872    |
----------------------------------
Eval num_timesteps=119500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.65     |
| time/               |          |
|    total_timesteps  | 119500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000161 |
|    n_updates        | 19874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0538   |
|    exploration_rate | 0.65     |
| time/               |          |
|    episodes         | 6532     |
|    fps              | 35       |
|    time_elapsed     | 3396     |
|    total_timesteps  | 119570   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000109 |
|    n_updates        | 19892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0643   |
|    exploration_rate | 0.649    |
| time/               |          |
|    episodes         | 6536     |
|    fps              | 35       |
|    time_elapsed     | 3396     |
|    total_timesteps  | 119633   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0153   |
|    n_updates        | 19908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.064    |
|    exploration_rate | 0.649    |
| time/               |          |
|    episodes         | 6540     |
|    fps              | 35       |
|    time_elapsed     | 3396     |
|    total_timesteps  | 119717   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 19929    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0642   |
|    exploration_rate | 0.648    |
| time/               |          |
|    episodes         | 6544     |
|    fps              | 35       |
|    time_elapsed     | 3397     |
|    total_timesteps  | 119804   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0149   |
|    n_updates        | 19950    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0539   |
|    exploration_rate | 0.648    |
| time/               |          |
|    episodes         | 6548     |
|    fps              | 35       |
|    time_elapsed     | 3397     |
|    total_timesteps  | 119875   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.16e-05 |
|    n_updates        | 19968    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0538   |
|    exploration_rate | 0.647    |
| time/               |          |
|    episodes         | 6552     |
|    fps              | 35       |
|    time_elapsed     | 3398     |
|    total_timesteps  | 119950   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.22e-05 |
|    n_updates        | 19987    |
----------------------------------
Eval num_timesteps=120000, episode_reward=-0.10 +/- 0.36
Episode length: 48.98 +/- 26.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49       |
|    mean_reward      | -0.0954  |
| rollout/            |          |
|    exploration_rate | 0.647    |
| time/               |          |
|    total_timesteps  | 120000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000157 |
|    n_updates        | 19999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0535   |
|    exploration_rate | 0.647    |
| time/               |          |
|    episodes         | 6556     |
|    fps              | 35       |
|    time_elapsed     | 3407     |
|    total_timesteps  | 120033   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.05e-05 |
|    n_updates        | 20008    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0439   |
|    exploration_rate | 0.646    |
| time/               |          |
|    episodes         | 6560     |
|    fps              | 35       |
|    time_elapsed     | 3407     |
|    total_timesteps  | 120097   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.23e-05 |
|    n_updates        | 20024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0444   |
|    exploration_rate | 0.646    |
| time/               |          |
|    episodes         | 6564     |
|    fps              | 35       |
|    time_elapsed     | 3408     |
|    total_timesteps  | 120169   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.56e-05 |
|    n_updates        | 20042    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.0345   |
|    exploration_rate | 0.645    |
| time/               |          |
|    episodes         | 6568     |
|    fps              | 35       |
|    time_elapsed     | 3408     |
|    total_timesteps  | 120245   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000127 |
|    n_updates        | 20061    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0144   |
|    exploration_rate | 0.645    |
| time/               |          |
|    episodes         | 6572     |
|    fps              | 35       |
|    time_elapsed     | 3409     |
|    total_timesteps  | 120326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.15e-05 |
|    n_updates        | 20081    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.004    |
|    exploration_rate | 0.644    |
| time/               |          |
|    episodes         | 6576     |
|    fps              | 35       |
|    time_elapsed     | 3409     |
|    total_timesteps  | 120405   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.1e-05  |
|    n_updates        | 20101    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00656 |
|    exploration_rate | 0.644    |
| time/               |          |
|    episodes         | 6580     |
|    fps              | 35       |
|    time_elapsed     | 3409     |
|    total_timesteps  | 120488   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 20121    |
----------------------------------
Eval num_timesteps=120500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.643    |
| time/               |          |
|    total_timesteps  | 120500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.007    |
|    n_updates        | 20124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.00376  |
|    exploration_rate | 0.643    |
| time/               |          |
|    episodes         | 6584     |
|    fps              | 35       |
|    time_elapsed     | 3426     |
|    total_timesteps  | 120556   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0136   |
|    n_updates        | 20138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.643    |
| time/               |          |
|    episodes         | 6588     |
|    fps              | 35       |
|    time_elapsed     | 3427     |
|    total_timesteps  | 120624   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.77e-05 |
|    n_updates        | 20155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0244   |
|    exploration_rate | 0.642    |
| time/               |          |
|    episodes         | 6592     |
|    fps              | 35       |
|    time_elapsed     | 3427     |
|    total_timesteps  | 120707   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.44e-05 |
|    n_updates        | 20176    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0233   |
|    exploration_rate | 0.642    |
| time/               |          |
|    episodes         | 6596     |
|    fps              | 35       |
|    time_elapsed     | 3428     |
|    total_timesteps  | 120794   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.18e-05 |
|    n_updates        | 20198    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0232   |
|    exploration_rate | 0.641    |
| time/               |          |
|    episodes         | 6600     |
|    fps              | 35       |
|    time_elapsed     | 3428     |
|    total_timesteps  | 120884   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00688  |
|    n_updates        | 20220    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0236   |
|    exploration_rate | 0.64     |
| time/               |          |
|    episodes         | 6604     |
|    fps              | 35       |
|    time_elapsed     | 3429     |
|    total_timesteps  | 120958   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000141 |
|    n_updates        | 20239    |
----------------------------------
Eval num_timesteps=121000, episode_reward=-0.07 +/- 0.28
Episode length: 37.72 +/- 20.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.7     |
|    mean_reward      | -0.0698  |
| rollout/            |          |
|    exploration_rate | 0.64     |
| time/               |          |
|    total_timesteps  | 121000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00697  |
|    n_updates        | 20249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0443   |
|    exploration_rate | 0.64     |
| time/               |          |
|    episodes         | 6608     |
|    fps              | 35       |
|    time_elapsed     | 3437     |
|    total_timesteps  | 121016   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000142 |
|    n_updates        | 20253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.0444   |
|    exploration_rate | 0.64     |
| time/               |          |
|    episodes         | 6612     |
|    fps              | 35       |
|    time_elapsed     | 3438     |
|    total_timesteps  | 121090   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.05e-05 |
|    n_updates        | 20272    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0234   |
|    exploration_rate | 0.639    |
| time/               |          |
|    episodes         | 6616     |
|    fps              | 35       |
|    time_elapsed     | 3438     |
|    total_timesteps  | 121185   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000121 |
|    n_updates        | 20296    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.638    |
| time/               |          |
|    episodes         | 6620     |
|    fps              | 35       |
|    time_elapsed     | 3438     |
|    total_timesteps  | 121250   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000147 |
|    n_updates        | 20312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0137   |
|    exploration_rate | 0.638    |
| time/               |          |
|    episodes         | 6624     |
|    fps              | 35       |
|    time_elapsed     | 3439     |
|    total_timesteps  | 121331   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.65e-05 |
|    n_updates        | 20332    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.024    |
|    exploration_rate | 0.637    |
| time/               |          |
|    episodes         | 6628     |
|    fps              | 35       |
|    time_elapsed     | 3439     |
|    total_timesteps  | 121414   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000125 |
|    n_updates        | 20353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0239   |
|    exploration_rate | 0.637    |
| time/               |          |
|    episodes         | 6632     |
|    fps              | 35       |
|    time_elapsed     | 3440     |
|    total_timesteps  | 121497   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000193 |
|    n_updates        | 20374    |
----------------------------------
Eval num_timesteps=121500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.637    |
| time/               |          |
|    total_timesteps  | 121500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0138   |
|    exploration_rate | 0.636    |
| time/               |          |
|    episodes         | 6636     |
|    fps              | 35       |
|    time_elapsed     | 3457     |
|    total_timesteps  | 121564   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.65e-05 |
|    n_updates        | 20390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.636    |
| time/               |          |
|    episodes         | 6640     |
|    fps              | 35       |
|    time_elapsed     | 3457     |
|    total_timesteps  | 121645   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.015    |
|    n_updates        | 20411    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0133   |
|    exploration_rate | 0.635    |
| time/               |          |
|    episodes         | 6644     |
|    fps              | 35       |
|    time_elapsed     | 3458     |
|    total_timesteps  | 121746   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.61e-05 |
|    n_updates        | 20436    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.00301  |
|    exploration_rate | 0.635    |
| time/               |          |
|    episodes         | 6648     |
|    fps              | 35       |
|    time_elapsed     | 3458     |
|    total_timesteps  | 121825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.98e-05 |
|    n_updates        | 20456    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.00329  |
|    exploration_rate | 0.634    |
| time/               |          |
|    episodes         | 6652     |
|    fps              | 35       |
|    time_elapsed     | 3458     |
|    total_timesteps  | 121893   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00712  |
|    n_updates        | 20473    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.00285  |
|    exploration_rate | 0.634    |
| time/               |          |
|    episodes         | 6656     |
|    fps              | 35       |
|    time_elapsed     | 3459     |
|    total_timesteps  | 121987   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000109 |
|    n_updates        | 20496    |
----------------------------------
Eval num_timesteps=122000, episode_reward=-0.30 +/- 0.03
Episode length: 73.82 +/- 8.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.633    |
| time/               |          |
|    total_timesteps  | 122000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.49e-05 |
|    n_updates        | 20499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00237  |
|    exploration_rate | 0.633    |
| time/               |          |
|    episodes         | 6660     |
|    fps              | 35       |
|    time_elapsed     | 3471     |
|    total_timesteps  | 122063   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.007    |
|    n_updates        | 20515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.0124   |
|    exploration_rate | 0.633    |
| time/               |          |
|    episodes         | 6664     |
|    fps              | 35       |
|    time_elapsed     | 3471     |
|    total_timesteps  | 122133   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.68e-05 |
|    n_updates        | 20533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | 0.0116   |
|    exploration_rate | 0.632    |
| time/               |          |
|    episodes         | 6668     |
|    fps              | 35       |
|    time_elapsed     | 3472     |
|    total_timesteps  | 122231   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.68e-05 |
|    n_updates        | 20557    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | 0.0113   |
|    exploration_rate | 0.631    |
| time/               |          |
|    episodes         | 6672     |
|    fps              | 35       |
|    time_elapsed     | 3472     |
|    total_timesteps  | 122319   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.07e-05 |
|    n_updates        | 20579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | 0.0215   |
|    exploration_rate | 0.631    |
| time/               |          |
|    episodes         | 6676     |
|    fps              | 35       |
|    time_elapsed     | 3473     |
|    total_timesteps  | 122392   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.38e-05 |
|    n_updates        | 20597    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.0217   |
|    exploration_rate | 0.63     |
| time/               |          |
|    episodes         | 6680     |
|    fps              | 35       |
|    time_elapsed     | 3473     |
|    total_timesteps  | 122471   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.51e-05 |
|    n_updates        | 20617    |
----------------------------------
Eval num_timesteps=122500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.63     |
| time/               |          |
|    total_timesteps  | 122500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.76e-05 |
|    n_updates        | 20624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | 0.0211   |
|    exploration_rate | 0.63     |
| time/               |          |
|    episodes         | 6684     |
|    fps              | 35       |
|    time_elapsed     | 3485     |
|    total_timesteps  | 122552   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0001   |
|    n_updates        | 20637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0104   |
|    exploration_rate | 0.629    |
| time/               |          |
|    episodes         | 6688     |
|    fps              | 35       |
|    time_elapsed     | 3486     |
|    total_timesteps  | 122638   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.25e-05 |
|    n_updates        | 20659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | 0.0009   |
|    exploration_rate | 0.629    |
| time/               |          |
|    episodes         | 6692     |
|    fps              | 35       |
|    time_elapsed     | 3486     |
|    total_timesteps  | 122709   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00663  |
|    n_updates        | 20677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.00875 |
|    exploration_rate | 0.628    |
| time/               |          |
|    episodes         | 6696     |
|    fps              | 35       |
|    time_elapsed     | 3487     |
|    total_timesteps  | 122787   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00765  |
|    n_updates        | 20696    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.00799 |
|    exploration_rate | 0.628    |
| time/               |          |
|    episodes         | 6700     |
|    fps              | 35       |
|    time_elapsed     | 3487     |
|    total_timesteps  | 122858   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.58e-05 |
|    n_updates        | 20714    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.00805 |
|    exploration_rate | 0.627    |
| time/               |          |
|    episodes         | 6704     |
|    fps              | 35       |
|    time_elapsed     | 3487     |
|    total_timesteps  | 122934   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.38e-05 |
|    n_updates        | 20733    |
----------------------------------
Eval num_timesteps=123000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.627    |
| time/               |          |
|    total_timesteps  | 123000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.85e-05 |
|    n_updates        | 20749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0288  |
|    exploration_rate | 0.627    |
| time/               |          |
|    episodes         | 6708     |
|    fps              | 35       |
|    time_elapsed     | 3499     |
|    total_timesteps  | 123010   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000139 |
|    n_updates        | 20752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0284  |
|    exploration_rate | 0.626    |
| time/               |          |
|    episodes         | 6712     |
|    fps              | 35       |
|    time_elapsed     | 3500     |
|    total_timesteps  | 123074   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00718  |
|    n_updates        | 20768    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0174  |
|    exploration_rate | 0.626    |
| time/               |          |
|    episodes         | 6716     |
|    fps              | 35       |
|    time_elapsed     | 3500     |
|    total_timesteps  | 123146   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000194 |
|    n_updates        | 20786    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0183  |
|    exploration_rate | 0.625    |
| time/               |          |
|    episodes         | 6720     |
|    fps              | 35       |
|    time_elapsed     | 3501     |
|    total_timesteps  | 123233   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.59e-05 |
|    n_updates        | 20808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.0191  |
|    exploration_rate | 0.624    |
| time/               |          |
|    episodes         | 6724     |
|    fps              | 35       |
|    time_elapsed     | 3501     |
|    total_timesteps  | 123335   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0148   |
|    n_updates        | 20833    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 0.624    |
| time/               |          |
|    episodes         | 6728     |
|    fps              | 35       |
|    time_elapsed     | 3502     |
|    total_timesteps  | 123420   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.96e-05 |
|    n_updates        | 20854    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0185  |
|    exploration_rate | 0.623    |
| time/               |          |
|    episodes         | 6732     |
|    fps              | 35       |
|    time_elapsed     | 3502     |
|    total_timesteps  | 123485   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00711  |
|    n_updates        | 20871    |
----------------------------------
Eval num_timesteps=123500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.623    |
| time/               |          |
|    total_timesteps  | 123500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.68e-05 |
|    n_updates        | 20874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.00912 |
|    exploration_rate | 0.623    |
| time/               |          |
|    episodes         | 6736     |
|    fps              | 35       |
|    time_elapsed     | 3517     |
|    total_timesteps  | 123567   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.63e-05 |
|    n_updates        | 20891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.00904 |
|    exploration_rate | 0.622    |
| time/               |          |
|    episodes         | 6740     |
|    fps              | 35       |
|    time_elapsed     | 3518     |
|    total_timesteps  | 123646   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.3e-05  |
|    n_updates        | 20911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.00772 |
|    exploration_rate | 0.622    |
| time/               |          |
|    episodes         | 6744     |
|    fps              | 35       |
|    time_elapsed     | 3518     |
|    total_timesteps  | 123714   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.74e-05 |
|    n_updates        | 20928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.00772 |
|    exploration_rate | 0.621    |
| time/               |          |
|    episodes         | 6748     |
|    fps              | 35       |
|    time_elapsed     | 3519     |
|    total_timesteps  | 123793   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000181 |
|    n_updates        | 20948    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.0078  |
|    exploration_rate | 0.621    |
| time/               |          |
|    episodes         | 6752     |
|    fps              | 35       |
|    time_elapsed     | 3519     |
|    total_timesteps  | 123863   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.2e-05  |
|    n_updates        | 20965    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00668 |
|    exploration_rate | 0.62     |
| time/               |          |
|    episodes         | 6756     |
|    fps              | 35       |
|    time_elapsed     | 3519     |
|    total_timesteps  | 123929   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00691  |
|    n_updates        | 20982    |
----------------------------------
Eval num_timesteps=124000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.62     |
| time/               |          |
|    total_timesteps  | 124000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000104 |
|    n_updates        | 20999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00744 |
|    exploration_rate | 0.62     |
| time/               |          |
|    episodes         | 6760     |
|    fps              | 35       |
|    time_elapsed     | 3532     |
|    total_timesteps  | 124024   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.97e-05 |
|    n_updates        | 21005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.00762 |
|    exploration_rate | 0.619    |
| time/               |          |
|    episodes         | 6764     |
|    fps              | 35       |
|    time_elapsed     | 3532     |
|    total_timesteps  | 124099   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.74e-05 |
|    n_updates        | 21024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00674 |
|    exploration_rate | 0.619    |
| time/               |          |
|    episodes         | 6768     |
|    fps              | 35       |
|    time_elapsed     | 3532     |
|    total_timesteps  | 124175   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000129 |
|    n_updates        | 21043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.00622 |
|    exploration_rate | 0.618    |
| time/               |          |
|    episodes         | 6772     |
|    fps              | 35       |
|    time_elapsed     | 3533     |
|    total_timesteps  | 124250   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00012  |
|    n_updates        | 21062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00669 |
|    exploration_rate | 0.618    |
| time/               |          |
|    episodes         | 6776     |
|    fps              | 35       |
|    time_elapsed     | 3533     |
|    total_timesteps  | 124335   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000217 |
|    n_updates        | 21083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00725 |
|    exploration_rate | 0.617    |
| time/               |          |
|    episodes         | 6780     |
|    fps              | 35       |
|    time_elapsed     | 3534     |
|    total_timesteps  | 124428   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00687  |
|    n_updates        | 21106    |
----------------------------------
Eval num_timesteps=124500, episode_reward=-0.30 +/- 0.01
Episode length: 74.70 +/- 2.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | -0.299   |
| rollout/            |          |
|    exploration_rate | 0.617    |
| time/               |          |
|    total_timesteps  | 124500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.79e-05 |
|    n_updates        | 21124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0172  |
|    exploration_rate | 0.617    |
| time/               |          |
|    episodes         | 6784     |
|    fps              | 35       |
|    time_elapsed     | 3546     |
|    total_timesteps  | 124508   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.12e-05 |
|    n_updates        | 21126    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00646 |
|    exploration_rate | 0.616    |
| time/               |          |
|    episodes         | 6788     |
|    fps              | 35       |
|    time_elapsed     | 3546     |
|    total_timesteps  | 124576   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 21143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.00296  |
|    exploration_rate | 0.615    |
| time/               |          |
|    episodes         | 6792     |
|    fps              | 35       |
|    time_elapsed     | 3547     |
|    total_timesteps  | 124662   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.07e-05 |
|    n_updates        | 21165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.00324  |
|    exploration_rate | 0.615    |
| time/               |          |
|    episodes         | 6796     |
|    fps              | 35       |
|    time_elapsed     | 3547     |
|    total_timesteps  | 124733   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.52e-05 |
|    n_updates        | 21183    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.0028   |
|    exploration_rate | 0.614    |
| time/               |          |
|    episodes         | 6800     |
|    fps              | 35       |
|    time_elapsed     | 3548     |
|    total_timesteps  | 124815   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.72e-05 |
|    n_updates        | 21203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00718 |
|    exploration_rate | 0.614    |
| time/               |          |
|    episodes         | 6804     |
|    fps              | 35       |
|    time_elapsed     | 3548     |
|    total_timesteps  | 124890   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.67e-05 |
|    n_updates        | 21222    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00714 |
|    exploration_rate | 0.613    |
| time/               |          |
|    episodes         | 6808     |
|    fps              | 35       |
|    time_elapsed     | 3548     |
|    total_timesteps  | 124965   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.35e-05 |
|    n_updates        | 21241    |
----------------------------------
Eval num_timesteps=125000, episode_reward=0.07 +/- 0.39
Episode length: 28.64 +/- 21.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28.6     |
|    mean_reward      | 0.0664   |
| rollout/            |          |
|    exploration_rate | 0.613    |
| time/               |          |
|    total_timesteps  | 125000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00732  |
|    n_updates        | 21249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.00762 |
|    exploration_rate | 0.613    |
| time/               |          |
|    episodes         | 6812     |
|    fps              | 35       |
|    time_elapsed     | 3555     |
|    total_timesteps  | 125041   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.96e-05 |
|    n_updates        | 21260    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0179  |
|    exploration_rate | 0.612    |
| time/               |          |
|    episodes         | 6816     |
|    fps              | 35       |
|    time_elapsed     | 3556     |
|    total_timesteps  | 125121   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.13e-05 |
|    n_updates        | 21280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.017   |
|    exploration_rate | 0.612    |
| time/               |          |
|    episodes         | 6820     |
|    fps              | 35       |
|    time_elapsed     | 3556     |
|    total_timesteps  | 125184   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.92e-05 |
|    n_updates        | 21295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.611    |
| time/               |          |
|    episodes         | 6824     |
|    fps              | 35       |
|    time_elapsed     | 3556     |
|    total_timesteps  | 125271   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000137 |
|    n_updates        | 21317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0265  |
|    exploration_rate | 0.611    |
| time/               |          |
|    episodes         | 6828     |
|    fps              | 35       |
|    time_elapsed     | 3557     |
|    total_timesteps  | 125359   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000147 |
|    n_updates        | 21339    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.0277  |
|    exploration_rate | 0.61     |
| time/               |          |
|    episodes         | 6832     |
|    fps              | 35       |
|    time_elapsed     | 3557     |
|    total_timesteps  | 125453   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.11e-05 |
|    n_updates        | 21363    |
----------------------------------
Eval num_timesteps=125500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.61     |
| time/               |          |
|    total_timesteps  | 125500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0134   |
|    n_updates        | 21374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.0276  |
|    exploration_rate | 0.61     |
| time/               |          |
|    episodes         | 6836     |
|    fps              | 35       |
|    time_elapsed     | 3571     |
|    total_timesteps  | 125533   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.43e-05 |
|    n_updates        | 21383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0274  |
|    exploration_rate | 0.609    |
| time/               |          |
|    episodes         | 6840     |
|    fps              | 35       |
|    time_elapsed     | 3571     |
|    total_timesteps  | 125608   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.26e-05 |
|    n_updates        | 21401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.0279  |
|    exploration_rate | 0.608    |
| time/               |          |
|    episodes         | 6844     |
|    fps              | 35       |
|    time_elapsed     | 3572     |
|    total_timesteps  | 125687   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00711  |
|    n_updates        | 21421    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0274  |
|    exploration_rate | 0.608    |
| time/               |          |
|    episodes         | 6848     |
|    fps              | 35       |
|    time_elapsed     | 3572     |
|    total_timesteps  | 125755   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.34e-05 |
|    n_updates        | 21438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0274  |
|    exploration_rate | 0.608    |
| time/               |          |
|    episodes         | 6852     |
|    fps              | 35       |
|    time_elapsed     | 3573     |
|    total_timesteps  | 125824   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.86e-05 |
|    n_updates        | 21455    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0275  |
|    exploration_rate | 0.607    |
| time/               |          |
|    episodes         | 6856     |
|    fps              | 35       |
|    time_elapsed     | 3573     |
|    total_timesteps  | 125893   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000145 |
|    n_updates        | 21473    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0271  |
|    exploration_rate | 0.606    |
| time/               |          |
|    episodes         | 6860     |
|    fps              | 35       |
|    time_elapsed     | 3573     |
|    total_timesteps  | 125979   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.77e-05 |
|    n_updates        | 21494    |
----------------------------------
Eval num_timesteps=126000, episode_reward=-0.30 +/- 0.03
Episode length: 73.98 +/- 7.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.606    |
| time/               |          |
|    total_timesteps  | 126000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.43e-05 |
|    n_updates        | 21499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0369  |
|    exploration_rate | 0.606    |
| time/               |          |
|    episodes         | 6864     |
|    fps              | 35       |
|    time_elapsed     | 3585     |
|    total_timesteps  | 126048   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.99e-05 |
|    n_updates        | 21511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0368  |
|    exploration_rate | 0.605    |
| time/               |          |
|    episodes         | 6868     |
|    fps              | 35       |
|    time_elapsed     | 3586     |
|    total_timesteps  | 126121   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 21530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0384  |
|    exploration_rate | 0.605    |
| time/               |          |
|    episodes         | 6872     |
|    fps              | 35       |
|    time_elapsed     | 3586     |
|    total_timesteps  | 126237   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0078   |
|    n_updates        | 21559    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0482  |
|    exploration_rate | 0.604    |
| time/               |          |
|    episodes         | 6876     |
|    fps              | 35       |
|    time_elapsed     | 3587     |
|    total_timesteps  | 126316   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.06e-05 |
|    n_updates        | 21578    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0371  |
|    exploration_rate | 0.604    |
| time/               |          |
|    episodes         | 6880     |
|    fps              | 35       |
|    time_elapsed     | 3587     |
|    total_timesteps  | 126382   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00667  |
|    n_updates        | 21595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.603    |
| time/               |          |
|    episodes         | 6884     |
|    fps              | 35       |
|    time_elapsed     | 3588     |
|    total_timesteps  | 126460   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000164 |
|    n_updates        | 21614    |
----------------------------------
Eval num_timesteps=126500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.603    |
| time/               |          |
|    total_timesteps  | 126500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000102 |
|    n_updates        | 21624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0268  |
|    exploration_rate | 0.603    |
| time/               |          |
|    episodes         | 6888     |
|    fps              | 35       |
|    time_elapsed     | 3604     |
|    total_timesteps  | 126523   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.12e-05 |
|    n_updates        | 21630    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0364  |
|    exploration_rate | 0.602    |
| time/               |          |
|    episodes         | 6892     |
|    fps              | 35       |
|    time_elapsed     | 3604     |
|    total_timesteps  | 126598   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.57e-05 |
|    n_updates        | 21649    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0363  |
|    exploration_rate | 0.602    |
| time/               |          |
|    episodes         | 6896     |
|    fps              | 35       |
|    time_elapsed     | 3605     |
|    total_timesteps  | 126665   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 21666    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0361  |
|    exploration_rate | 0.601    |
| time/               |          |
|    episodes         | 6900     |
|    fps              | 35       |
|    time_elapsed     | 3605     |
|    total_timesteps  | 126742   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00788  |
|    n_updates        | 21685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0256  |
|    exploration_rate | 0.601    |
| time/               |          |
|    episodes         | 6904     |
|    fps              | 35       |
|    time_elapsed     | 3605     |
|    total_timesteps  | 126806   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.37e-05 |
|    n_updates        | 21701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0159  |
|    exploration_rate | 0.6      |
| time/               |          |
|    episodes         | 6908     |
|    fps              | 35       |
|    time_elapsed     | 3606     |
|    total_timesteps  | 126888   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.6e-05  |
|    n_updates        | 21721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0168  |
|    exploration_rate | 0.6      |
| time/               |          |
|    episodes         | 6912     |
|    fps              | 35       |
|    time_elapsed     | 3606     |
|    total_timesteps  | 126987   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.57e-05 |
|    n_updates        | 21746    |
----------------------------------
Eval num_timesteps=127000, episode_reward=-0.30 +/- 0.02
Episode length: 74.04 +/- 4.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.599    |
| time/               |          |
|    total_timesteps  | 127000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000163 |
|    n_updates        | 21749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.599    |
| time/               |          |
|    episodes         | 6916     |
|    fps              | 35       |
|    time_elapsed     | 3618     |
|    total_timesteps  | 127058   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.99e-05 |
|    n_updates        | 21764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.00681 |
|    exploration_rate | 0.599    |
| time/               |          |
|    episodes         | 6920     |
|    fps              | 35       |
|    time_elapsed     | 3619     |
|    total_timesteps  | 127131   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.28e-05 |
|    n_updates        | 21782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.00621 |
|    exploration_rate | 0.598    |
| time/               |          |
|    episodes         | 6924     |
|    fps              | 35       |
|    time_elapsed     | 3619     |
|    total_timesteps  | 127203   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.51e-05 |
|    n_updates        | 21800    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | 0.00468  |
|    exploration_rate | 0.598    |
| time/               |          |
|    episodes         | 6928     |
|    fps              | 35       |
|    time_elapsed     | 3619     |
|    total_timesteps  | 127269   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00712  |
|    n_updates        | 21817    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | 0.00436  |
|    exploration_rate | 0.597    |
| time/               |          |
|    episodes         | 6932     |
|    fps              | 35       |
|    time_elapsed     | 3620     |
|    total_timesteps  | 127371   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0071   |
|    n_updates        | 21842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00491  |
|    exploration_rate | 0.596    |
| time/               |          |
|    episodes         | 6936     |
|    fps              | 35       |
|    time_elapsed     | 3620     |
|    total_timesteps  | 127437   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000154 |
|    n_updates        | 21859    |
----------------------------------
Eval num_timesteps=127500, episode_reward=-0.21 +/- 0.19
Episode length: 56.42 +/- 27.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.4     |
|    mean_reward      | -0.205   |
| rollout/            |          |
|    exploration_rate | 0.596    |
| time/               |          |
|    total_timesteps  | 127500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 21874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.00535  |
|    exploration_rate | 0.596    |
| time/               |          |
|    episodes         | 6940     |
|    fps              | 35       |
|    time_elapsed     | 3630     |
|    total_timesteps  | 127501   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.94e-05 |
|    n_updates        | 21875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00523  |
|    exploration_rate | 0.595    |
| time/               |          |
|    episodes         | 6944     |
|    fps              | 35       |
|    time_elapsed     | 3630     |
|    total_timesteps  | 127583   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000121 |
|    n_updates        | 21895    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.00403  |
|    exploration_rate | 0.595    |
| time/               |          |
|    episodes         | 6948     |
|    fps              | 35       |
|    time_elapsed     | 3631     |
|    total_timesteps  | 127681   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.6e-05  |
|    n_updates        | 21920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.594    |
| time/               |          |
|    episodes         | 6952     |
|    fps              | 35       |
|    time_elapsed     | 3631     |
|    total_timesteps  | 127778   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.62e-05 |
|    n_updates        | 21944    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.0128   |
|    exploration_rate | 0.594    |
| time/               |          |
|    episodes         | 6956     |
|    fps              | 35       |
|    time_elapsed     | 3632     |
|    total_timesteps  | 127851   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.26e-05 |
|    n_updates        | 21962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.0232   |
|    exploration_rate | 0.593    |
| time/               |          |
|    episodes         | 6960     |
|    fps              | 35       |
|    time_elapsed     | 3632     |
|    total_timesteps  | 127927   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000146 |
|    n_updates        | 21981    |
----------------------------------
Eval num_timesteps=128000, episode_reward=0.01 +/- 0.27
Episode length: 17.04 +/- 1.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17       |
|    mean_reward      | 0.0129   |
| rollout/            |          |
|    exploration_rate | 0.593    |
| time/               |          |
|    total_timesteps  | 128000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.86e-05 |
|    n_updates        | 21999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.0228   |
|    exploration_rate | 0.592    |
| time/               |          |
|    episodes         | 6964     |
|    fps              | 35       |
|    time_elapsed     | 3637     |
|    total_timesteps  | 128005   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.95e-05 |
|    n_updates        | 22001    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.0223   |
|    exploration_rate | 0.592    |
| time/               |          |
|    episodes         | 6968     |
|    fps              | 35       |
|    time_elapsed     | 3637     |
|    total_timesteps  | 128090   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.45e-05 |
|    n_updates        | 22022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0238   |
|    exploration_rate | 0.591    |
| time/               |          |
|    episodes         | 6972     |
|    fps              | 35       |
|    time_elapsed     | 3638     |
|    total_timesteps  | 128169   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.31e-05 |
|    n_updates        | 22042    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.024    |
|    exploration_rate | 0.591    |
| time/               |          |
|    episodes         | 6976     |
|    fps              | 35       |
|    time_elapsed     | 3638     |
|    total_timesteps  | 128243   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.55e-05 |
|    n_updates        | 22060    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0238   |
|    exploration_rate | 0.59     |
| time/               |          |
|    episodes         | 6980     |
|    fps              | 35       |
|    time_elapsed     | 3638     |
|    total_timesteps  | 128314   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0072   |
|    n_updates        | 22078    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.59     |
| time/               |          |
|    episodes         | 6984     |
|    fps              | 35       |
|    time_elapsed     | 3639     |
|    total_timesteps  | 128390   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.62e-05 |
|    n_updates        | 22097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0136   |
|    exploration_rate | 0.589    |
| time/               |          |
|    episodes         | 6988     |
|    fps              | 35       |
|    time_elapsed     | 3639     |
|    total_timesteps  | 128460   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000132 |
|    n_updates        | 22114    |
----------------------------------
Eval num_timesteps=128500, episode_reward=-0.24 +/- 0.20
Episode length: 70.42 +/- 11.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.4     |
|    mean_reward      | -0.242   |
| rollout/            |          |
|    exploration_rate | 0.589    |
| time/               |          |
|    total_timesteps  | 128500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00014  |
|    n_updates        | 22124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0235   |
|    exploration_rate | 0.589    |
| time/               |          |
|    episodes         | 6992     |
|    fps              | 35       |
|    time_elapsed     | 3655     |
|    total_timesteps  | 128538   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000145 |
|    n_updates        | 22134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.0226   |
|    exploration_rate | 0.588    |
| time/               |          |
|    episodes         | 6996     |
|    fps              | 35       |
|    time_elapsed     | 3656     |
|    total_timesteps  | 128628   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.35e-05 |
|    n_updates        | 22156    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.0223   |
|    exploration_rate | 0.588    |
| time/               |          |
|    episodes         | 7000     |
|    fps              | 35       |
|    time_elapsed     | 3656     |
|    total_timesteps  | 128711   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.34e-05 |
|    n_updates        | 22177    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 0.587    |
| time/               |          |
|    episodes         | 7004     |
|    fps              | 35       |
|    time_elapsed     | 3657     |
|    total_timesteps  | 128789   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000119 |
|    n_updates        | 22197    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.586    |
| time/               |          |
|    episodes         | 7008     |
|    fps              | 35       |
|    time_elapsed     | 3657     |
|    total_timesteps  | 128877   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000162 |
|    n_updates        | 22219    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.022    |
|    exploration_rate | 0.586    |
| time/               |          |
|    episodes         | 7012     |
|    fps              | 35       |
|    time_elapsed     | 3658     |
|    total_timesteps  | 128963   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.56e-05 |
|    n_updates        | 22240    |
----------------------------------
Eval num_timesteps=129000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.586    |
| time/               |          |
|    total_timesteps  | 129000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.24e-05 |
|    n_updates        | 22249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | 0.0215   |
|    exploration_rate | 0.585    |
| time/               |          |
|    episodes         | 7016     |
|    fps              | 35       |
|    time_elapsed     | 3673     |
|    total_timesteps  | 129047   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000141 |
|    n_updates        | 22261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | 0.021    |
|    exploration_rate | 0.585    |
| time/               |          |
|    episodes         | 7020     |
|    fps              | 35       |
|    time_elapsed     | 3673     |
|    total_timesteps  | 129133   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.42e-05 |
|    n_updates        | 22283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 0.584    |
| time/               |          |
|    episodes         | 7024     |
|    fps              | 35       |
|    time_elapsed     | 3674     |
|    total_timesteps  | 129227   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.9e-05  |
|    n_updates        | 22306    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.583    |
| time/               |          |
|    episodes         | 7028     |
|    fps              | 35       |
|    time_elapsed     | 3674     |
|    total_timesteps  | 129319   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.21e-05 |
|    n_updates        | 22329    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0199   |
|    exploration_rate | 0.583    |
| time/               |          |
|    episodes         | 7032     |
|    fps              | 35       |
|    time_elapsed     | 3675     |
|    total_timesteps  | 129399   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000109 |
|    n_updates        | 22349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.00952  |
|    exploration_rate | 0.582    |
| time/               |          |
|    episodes         | 7036     |
|    fps              | 35       |
|    time_elapsed     | 3675     |
|    total_timesteps  | 129475   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00703  |
|    n_updates        | 22368    |
----------------------------------
Eval num_timesteps=129500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.582    |
| time/               |          |
|    total_timesteps  | 129500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00784  |
|    n_updates        | 22374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0086   |
|    exploration_rate | 0.582    |
| time/               |          |
|    episodes         | 7040     |
|    fps              | 35       |
|    time_elapsed     | 3691     |
|    total_timesteps  | 129562   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00704  |
|    n_updates        | 22390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.00868  |
|    exploration_rate | 0.581    |
| time/               |          |
|    episodes         | 7044     |
|    fps              | 35       |
|    time_elapsed     | 3691     |
|    total_timesteps  | 129642   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.03e-05 |
|    n_updates        | 22410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.00956  |
|    exploration_rate | 0.581    |
| time/               |          |
|    episodes         | 7048     |
|    fps              | 35       |
|    time_elapsed     | 3691     |
|    total_timesteps  | 129718   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.89e-05 |
|    n_updates        | 22429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 0.58     |
| time/               |          |
|    episodes         | 7052     |
|    fps              | 35       |
|    time_elapsed     | 3692     |
|    total_timesteps  | 129792   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000124 |
|    n_updates        | 22447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 0.58     |
| time/               |          |
|    episodes         | 7056     |
|    fps              | 35       |
|    time_elapsed     | 3692     |
|    total_timesteps  | 129863   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4e-05    |
|    n_updates        | 22465    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0096   |
|    exploration_rate | 0.579    |
| time/               |          |
|    episodes         | 7060     |
|    fps              | 35       |
|    time_elapsed     | 3693     |
|    total_timesteps  | 129962   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.16e-05 |
|    n_updates        | 22490    |
----------------------------------
Eval num_timesteps=130000, episode_reward=-0.13 +/- 0.22
Episode length: 41.66 +/- 20.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.7     |
|    mean_reward      | -0.126   |
| rollout/            |          |
|    exploration_rate | 0.579    |
| time/               |          |
|    total_timesteps  | 130000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.63e-05 |
|    n_updates        | 22499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 0.578    |
| time/               |          |
|    episodes         | 7064     |
|    fps              | 35       |
|    time_elapsed     | 3702     |
|    total_timesteps  | 130038   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.03e-05 |
|    n_updates        | 22509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0195   |
|    exploration_rate | 0.578    |
| time/               |          |
|    episodes         | 7068     |
|    fps              | 35       |
|    time_elapsed     | 3702     |
|    total_timesteps  | 130128   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.09e-05 |
|    n_updates        | 22531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0198   |
|    exploration_rate | 0.577    |
| time/               |          |
|    episodes         | 7072     |
|    fps              | 35       |
|    time_elapsed     | 3703     |
|    total_timesteps  | 130198   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.04e-05 |
|    n_updates        | 22549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.0201   |
|    exploration_rate | 0.577    |
| time/               |          |
|    episodes         | 7076     |
|    fps              | 35       |
|    time_elapsed     | 3703     |
|    total_timesteps  | 130266   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0141   |
|    n_updates        | 22566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.00972  |
|    exploration_rate | 0.576    |
| time/               |          |
|    episodes         | 7080     |
|    fps              | 35       |
|    time_elapsed     | 3704     |
|    total_timesteps  | 130346   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.05e-05 |
|    n_updates        | 22586    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0195   |
|    exploration_rate | 0.576    |
| time/               |          |
|    episodes         | 7084     |
|    fps              | 35       |
|    time_elapsed     | 3704     |
|    total_timesteps  | 130427   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.1e-05  |
|    n_updates        | 22606    |
----------------------------------
Eval num_timesteps=130500, episode_reward=-0.29 +/- 0.04
Episode length: 72.62 +/- 9.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.6     |
|    mean_reward      | -0.29    |
| rollout/            |          |
|    exploration_rate | 0.575    |
| time/               |          |
|    total_timesteps  | 130500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.34e-05 |
|    n_updates        | 22624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.00875  |
|    exploration_rate | 0.575    |
| time/               |          |
|    episodes         | 7088     |
|    fps              | 35       |
|    time_elapsed     | 3720     |
|    total_timesteps  | 130516   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000126 |
|    n_updates        | 22628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.00116 |
|    exploration_rate | 0.574    |
| time/               |          |
|    episodes         | 7092     |
|    fps              | 35       |
|    time_elapsed     | 3721     |
|    total_timesteps  | 130592   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.46e-05 |
|    n_updates        | 22647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.00052 |
|    exploration_rate | 0.574    |
| time/               |          |
|    episodes         | 7096     |
|    fps              | 35       |
|    time_elapsed     | 3721     |
|    total_timesteps  | 130666   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000159 |
|    n_updates        | 22666    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.00048 |
|    exploration_rate | 0.573    |
| time/               |          |
|    episodes         | 7100     |
|    fps              | 35       |
|    time_elapsed     | 3722     |
|    total_timesteps  | 130748   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.28e-05 |
|    n_updates        | 22686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.00112 |
|    exploration_rate | 0.573    |
| time/               |          |
|    episodes         | 7104     |
|    fps              | 35       |
|    time_elapsed     | 3722     |
|    total_timesteps  | 130842   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.31e-05 |
|    n_updates        | 22710    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.572    |
| time/               |          |
|    episodes         | 7108     |
|    fps              | 35       |
|    time_elapsed     | 3723     |
|    total_timesteps  | 130945   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.51e-05 |
|    n_updates        | 22736    |
----------------------------------
Eval num_timesteps=131000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.572    |
| time/               |          |
|    total_timesteps  | 131000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.95e-05 |
|    n_updates        | 22749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 0.571    |
| time/               |          |
|    episodes         | 7112     |
|    fps              | 35       |
|    time_elapsed     | 3735     |
|    total_timesteps  | 131024   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.84e-05 |
|    n_updates        | 22755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 0.571    |
| time/               |          |
|    episodes         | 7116     |
|    fps              | 35       |
|    time_elapsed     | 3735     |
|    total_timesteps  | 131101   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 22775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0309  |
|    exploration_rate | 0.57     |
| time/               |          |
|    episodes         | 7120     |
|    fps              | 35       |
|    time_elapsed     | 3736     |
|    total_timesteps  | 131180   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.38e-05 |
|    n_updates        | 22794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0303  |
|    exploration_rate | 0.57     |
| time/               |          |
|    episodes         | 7124     |
|    fps              | 35       |
|    time_elapsed     | 3736     |
|    total_timesteps  | 131259   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.75e-05 |
|    n_updates        | 22814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0293  |
|    exploration_rate | 0.569    |
| time/               |          |
|    episodes         | 7128     |
|    fps              | 35       |
|    time_elapsed     | 3737     |
|    total_timesteps  | 131326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00701  |
|    n_updates        | 22831    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0294  |
|    exploration_rate | 0.569    |
| time/               |          |
|    episodes         | 7132     |
|    fps              | 35       |
|    time_elapsed     | 3737     |
|    total_timesteps  | 131409   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.74e-05 |
|    n_updates        | 22852    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.029   |
|    exploration_rate | 0.568    |
| time/               |          |
|    episodes         | 7136     |
|    fps              | 35       |
|    time_elapsed     | 3738     |
|    total_timesteps  | 131475   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.58e-05 |
|    n_updates        | 22868    |
----------------------------------
Eval num_timesteps=131500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.568    |
| time/               |          |
|    total_timesteps  | 131500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.82e-05 |
|    n_updates        | 22874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0287  |
|    exploration_rate | 0.568    |
| time/               |          |
|    episodes         | 7140     |
|    fps              | 35       |
|    time_elapsed     | 3753     |
|    total_timesteps  | 131553   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.13e-05 |
|    n_updates        | 22888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0288  |
|    exploration_rate | 0.567    |
| time/               |          |
|    episodes         | 7144     |
|    fps              | 35       |
|    time_elapsed     | 3753     |
|    total_timesteps  | 131635   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.43e-05 |
|    n_updates        | 22908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.0289  |
|    exploration_rate | 0.566    |
| time/               |          |
|    episodes         | 7148     |
|    fps              | 35       |
|    time_elapsed     | 3754     |
|    total_timesteps  | 131714   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00706  |
|    n_updates        | 22928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0287  |
|    exploration_rate | 0.566    |
| time/               |          |
|    episodes         | 7152     |
|    fps              | 35       |
|    time_elapsed     | 3754     |
|    total_timesteps  | 131785   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00789  |
|    n_updates        | 22946    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0395  |
|    exploration_rate | 0.565    |
| time/               |          |
|    episodes         | 7156     |
|    fps              | 35       |
|    time_elapsed     | 3755     |
|    total_timesteps  | 131876   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.78e-05 |
|    n_updates        | 22968    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0393  |
|    exploration_rate | 0.565    |
| time/               |          |
|    episodes         | 7160     |
|    fps              | 35       |
|    time_elapsed     | 3755     |
|    total_timesteps  | 131969   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00676  |
|    n_updates        | 22992    |
----------------------------------
Eval num_timesteps=132000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.564    |
| time/               |          |
|    total_timesteps  | 132000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.96e-05 |
|    n_updates        | 22999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0512  |
|    exploration_rate | 0.564    |
| time/               |          |
|    episodes         | 7164     |
|    fps              | 35       |
|    time_elapsed     | 3771     |
|    total_timesteps  | 132094   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.11e-05 |
|    n_updates        | 23023    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0506  |
|    exploration_rate | 0.563    |
| time/               |          |
|    episodes         | 7168     |
|    fps              | 35       |
|    time_elapsed     | 3771     |
|    total_timesteps  | 132167   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.19e-05 |
|    n_updates        | 23041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.041   |
|    exploration_rate | 0.563    |
| time/               |          |
|    episodes         | 7172     |
|    fps              | 35       |
|    time_elapsed     | 3772     |
|    total_timesteps  | 132247   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000102 |
|    n_updates        | 23061    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0432  |
|    exploration_rate | 0.562    |
| time/               |          |
|    episodes         | 7176     |
|    fps              | 35       |
|    time_elapsed     | 3772     |
|    total_timesteps  | 132371   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.64e-05 |
|    n_updates        | 23092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0432  |
|    exploration_rate | 0.561    |
| time/               |          |
|    episodes         | 7180     |
|    fps              | 35       |
|    time_elapsed     | 3773     |
|    total_timesteps  | 132450   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.19e-05 |
|    n_updates        | 23112    |
----------------------------------
Eval num_timesteps=132500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.561    |
| time/               |          |
|    total_timesteps  | 132500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 23124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0435  |
|    exploration_rate | 0.561    |
| time/               |          |
|    episodes         | 7184     |
|    fps              | 34       |
|    time_elapsed     | 3789     |
|    total_timesteps  | 132540   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.04e-05 |
|    n_updates        | 23134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.043   |
|    exploration_rate | 0.56     |
| time/               |          |
|    episodes         | 7188     |
|    fps              | 34       |
|    time_elapsed     | 3790     |
|    total_timesteps  | 132616   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.54e-05 |
|    n_updates        | 23153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0431  |
|    exploration_rate | 0.559    |
| time/               |          |
|    episodes         | 7192     |
|    fps              | 35       |
|    time_elapsed     | 3790     |
|    total_timesteps  | 132696   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000137 |
|    n_updates        | 23173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0437  |
|    exploration_rate | 0.559    |
| time/               |          |
|    episodes         | 7196     |
|    fps              | 35       |
|    time_elapsed     | 3791     |
|    total_timesteps  | 132783   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.33e-05 |
|    n_updates        | 23195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0435  |
|    exploration_rate | 0.558    |
| time/               |          |
|    episodes         | 7200     |
|    fps              | 35       |
|    time_elapsed     | 3791     |
|    total_timesteps  | 132860   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.82e-05 |
|    n_updates        | 23214    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0429  |
|    exploration_rate | 0.558    |
| time/               |          |
|    episodes         | 7204     |
|    fps              | 35       |
|    time_elapsed     | 3792     |
|    total_timesteps  | 132940   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.18e-05 |
|    n_updates        | 23234    |
----------------------------------
Eval num_timesteps=133000, episode_reward=-0.23 +/- 0.10
Episode length: 56.92 +/- 24.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.9     |
|    mean_reward      | -0.227   |
| rollout/            |          |
|    exploration_rate | 0.557    |
| time/               |          |
|    total_timesteps  | 133000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 23249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0417  |
|    exploration_rate | 0.557    |
| time/               |          |
|    episodes         | 7208     |
|    fps              | 34       |
|    time_elapsed     | 3804     |
|    total_timesteps  | 133014   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.02e-05 |
|    n_updates        | 23253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0414  |
|    exploration_rate | 0.557    |
| time/               |          |
|    episodes         | 7212     |
|    fps              | 34       |
|    time_elapsed     | 3804     |
|    total_timesteps  | 133085   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.3e-05  |
|    n_updates        | 23271    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0411  |
|    exploration_rate | 0.556    |
| time/               |          |
|    episodes         | 7216     |
|    fps              | 34       |
|    time_elapsed     | 3805     |
|    total_timesteps  | 133154   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.3e-05  |
|    n_updates        | 23288    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0417  |
|    exploration_rate | 0.556    |
| time/               |          |
|    episodes         | 7220     |
|    fps              | 35       |
|    time_elapsed     | 3805     |
|    total_timesteps  | 133248   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000157 |
|    n_updates        | 23311    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0416  |
|    exploration_rate | 0.555    |
| time/               |          |
|    episodes         | 7224     |
|    fps              | 35       |
|    time_elapsed     | 3806     |
|    total_timesteps  | 133324   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.87e-05 |
|    n_updates        | 23330    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0421  |
|    exploration_rate | 0.554    |
| time/               |          |
|    episodes         | 7228     |
|    fps              | 35       |
|    time_elapsed     | 3806     |
|    total_timesteps  | 133403   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.98e-05 |
|    n_updates        | 23350    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0421  |
|    exploration_rate | 0.554    |
| time/               |          |
|    episodes         | 7232     |
|    fps              | 35       |
|    time_elapsed     | 3806     |
|    total_timesteps  | 133486   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000114 |
|    n_updates        | 23371    |
----------------------------------
Eval num_timesteps=133500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.554    |
| time/               |          |
|    total_timesteps  | 133500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00703  |
|    n_updates        | 23374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0326  |
|    exploration_rate | 0.553    |
| time/               |          |
|    episodes         | 7236     |
|    fps              | 34       |
|    time_elapsed     | 3822     |
|    total_timesteps  | 133566   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.32e-05 |
|    n_updates        | 23391    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.553    |
| time/               |          |
|    episodes         | 7240     |
|    fps              | 34       |
|    time_elapsed     | 3822     |
|    total_timesteps  | 133645   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.85e-05 |
|    n_updates        | 23411    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.552    |
| time/               |          |
|    episodes         | 7244     |
|    fps              | 34       |
|    time_elapsed     | 3823     |
|    total_timesteps  | 133720   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 23429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 0.552    |
| time/               |          |
|    episodes         | 7248     |
|    fps              | 34       |
|    time_elapsed     | 3823     |
|    total_timesteps  | 133793   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000151 |
|    n_updates        | 23448    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.551    |
| time/               |          |
|    episodes         | 7252     |
|    fps              | 35       |
|    time_elapsed     | 3823     |
|    total_timesteps  | 133865   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.67e-05 |
|    n_updates        | 23466    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.551    |
| time/               |          |
|    episodes         | 7256     |
|    fps              | 35       |
|    time_elapsed     | 3824     |
|    total_timesteps  | 133942   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.13e-05 |
|    n_updates        | 23485    |
----------------------------------
Eval num_timesteps=134000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.55     |
| time/               |          |
|    total_timesteps  | 134000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000114 |
|    n_updates        | 23499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 0.55     |
| time/               |          |
|    episodes         | 7260     |
|    fps              | 34       |
|    time_elapsed     | 3839     |
|    total_timesteps  | 134031   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00705  |
|    n_updates        | 23507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.00979 |
|    exploration_rate | 0.549    |
| time/               |          |
|    episodes         | 7264     |
|    fps              | 34       |
|    time_elapsed     | 3840     |
|    total_timesteps  | 134115   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 23528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.00051 |
|    exploration_rate | 0.549    |
| time/               |          |
|    episodes         | 7268     |
|    fps              | 34       |
|    time_elapsed     | 3840     |
|    total_timesteps  | 134206   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00787  |
|    n_updates        | 23551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0105  |
|    exploration_rate | 0.548    |
| time/               |          |
|    episodes         | 7272     |
|    fps              | 34       |
|    time_elapsed     | 3840     |
|    total_timesteps  | 134286   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00708  |
|    n_updates        | 23571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.00202  |
|    exploration_rate | 0.548    |
| time/               |          |
|    episodes         | 7276     |
|    fps              | 34       |
|    time_elapsed     | 3841     |
|    total_timesteps  | 134347   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 23586    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.00186  |
|    exploration_rate | 0.547    |
| time/               |          |
|    episodes         | 7280     |
|    fps              | 34       |
|    time_elapsed     | 3841     |
|    total_timesteps  | 134430   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00692  |
|    n_updates        | 23607    |
----------------------------------
Eval num_timesteps=134500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.547    |
| time/               |          |
|    total_timesteps  | 134500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00784  |
|    n_updates        | 23624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00748 |
|    exploration_rate | 0.547    |
| time/               |          |
|    episodes         | 7284     |
|    fps              | 34       |
|    time_elapsed     | 3856     |
|    total_timesteps  | 134503   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.16e-05 |
|    n_updates        | 23625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.00804 |
|    exploration_rate | 0.546    |
| time/               |          |
|    episodes         | 7288     |
|    fps              | 34       |
|    time_elapsed     | 3857     |
|    total_timesteps  | 134593   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.1e-05  |
|    n_updates        | 23648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.00249  |
|    exploration_rate | 0.545    |
| time/               |          |
|    episodes         | 7292     |
|    fps              | 34       |
|    time_elapsed     | 3857     |
|    total_timesteps  | 134660   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.12e-05 |
|    n_updates        | 23664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00237  |
|    exploration_rate | 0.545    |
| time/               |          |
|    episodes         | 7296     |
|    fps              | 34       |
|    time_elapsed     | 3858     |
|    total_timesteps  | 134750   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.44e-05 |
|    n_updates        | 23687    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00225  |
|    exploration_rate | 0.544    |
| time/               |          |
|    episodes         | 7300     |
|    fps              | 34       |
|    time_elapsed     | 3858     |
|    total_timesteps  | 134830   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 23707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00225  |
|    exploration_rate | 0.544    |
| time/               |          |
|    episodes         | 7304     |
|    fps              | 34       |
|    time_elapsed     | 3859     |
|    total_timesteps  | 134910   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 23727    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00213  |
|    exploration_rate | 0.543    |
| time/               |          |
|    episodes         | 7308     |
|    fps              | 34       |
|    time_elapsed     | 3859     |
|    total_timesteps  | 134987   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00715  |
|    n_updates        | 23746    |
----------------------------------
Eval num_timesteps=135000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.543    |
| time/               |          |
|    total_timesteps  | 135000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.63e-05 |
|    n_updates        | 23749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00213  |
|    exploration_rate | 0.543    |
| time/               |          |
|    episodes         | 7312     |
|    fps              | 34       |
|    time_elapsed     | 3871     |
|    total_timesteps  | 135058   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.6e-05  |
|    n_updates        | 23764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.0121   |
|    exploration_rate | 0.542    |
| time/               |          |
|    episodes         | 7316     |
|    fps              | 34       |
|    time_elapsed     | 3872     |
|    total_timesteps  | 135129   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00777  |
|    n_updates        | 23782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.541    |
| time/               |          |
|    episodes         | 7320     |
|    fps              | 34       |
|    time_elapsed     | 3872     |
|    total_timesteps  | 135203   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00785  |
|    n_updates        | 23800    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.013    |
|    exploration_rate | 0.541    |
| time/               |          |
|    episodes         | 7324     |
|    fps              | 34       |
|    time_elapsed     | 3873     |
|    total_timesteps  | 135275   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.89e-05 |
|    n_updates        | 23818    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.00347  |
|    exploration_rate | 0.54     |
| time/               |          |
|    episodes         | 7328     |
|    fps              | 34       |
|    time_elapsed     | 3873     |
|    total_timesteps  | 135343   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0138   |
|    n_updates        | 23835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.00347  |
|    exploration_rate | 0.54     |
| time/               |          |
|    episodes         | 7332     |
|    fps              | 34       |
|    time_elapsed     | 3873     |
|    total_timesteps  | 135426   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.16e-05 |
|    n_updates        | 23856    |
----------------------------------
Eval num_timesteps=135500, episode_reward=-0.30 +/- 0.02
Episode length: 74.32 +/- 4.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.3     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.539    |
| time/               |          |
|    total_timesteps  | 135500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.43e-05 |
|    n_updates        | 23874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00651 |
|    exploration_rate | 0.539    |
| time/               |          |
|    episodes         | 7336     |
|    fps              | 34       |
|    time_elapsed     | 3889     |
|    total_timesteps  | 135505   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.49e-05 |
|    n_updates        | 23876    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00668 |
|    exploration_rate | 0.539    |
| time/               |          |
|    episodes         | 7340     |
|    fps              | 34       |
|    time_elapsed     | 3889     |
|    total_timesteps  | 135588   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0139   |
|    n_updates        | 23896    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.00342  |
|    exploration_rate | 0.538    |
| time/               |          |
|    episodes         | 7344     |
|    fps              | 34       |
|    time_elapsed     | 3890     |
|    total_timesteps  | 135661   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.99e-05 |
|    n_updates        | 23915    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.00771 |
|    exploration_rate | 0.537    |
| time/               |          |
|    episodes         | 7348     |
|    fps              | 34       |
|    time_elapsed     | 3890     |
|    total_timesteps  | 135762   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.62e-05 |
|    n_updates        | 23940    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.00819 |
|    exploration_rate | 0.537    |
| time/               |          |
|    episodes         | 7352     |
|    fps              | 34       |
|    time_elapsed     | 3891     |
|    total_timesteps  | 135846   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0001   |
|    n_updates        | 23961    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.0187  |
|    exploration_rate | 0.536    |
| time/               |          |
|    episodes         | 7356     |
|    fps              | 34       |
|    time_elapsed     | 3891     |
|    total_timesteps  | 135936   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.34e-05 |
|    n_updates        | 23983    |
----------------------------------
Eval num_timesteps=136000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.536    |
| time/               |          |
|    total_timesteps  | 136000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.72e-05 |
|    n_updates        | 23999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 0.535    |
| time/               |          |
|    episodes         | 7360     |
|    fps              | 34       |
|    time_elapsed     | 3903     |
|    total_timesteps  | 136050   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00694  |
|    n_updates        | 24012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 0.535    |
| time/               |          |
|    episodes         | 7364     |
|    fps              | 34       |
|    time_elapsed     | 3904     |
|    total_timesteps  | 136141   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000104 |
|    n_updates        | 24035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0297  |
|    exploration_rate | 0.534    |
| time/               |          |
|    episodes         | 7368     |
|    fps              | 34       |
|    time_elapsed     | 3904     |
|    total_timesteps  | 136225   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.25e-05 |
|    n_updates        | 24056    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.019   |
|    exploration_rate | 0.534    |
| time/               |          |
|    episodes         | 7372     |
|    fps              | 34       |
|    time_elapsed     | 3905     |
|    total_timesteps  | 136287   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.88e-05 |
|    n_updates        | 24071    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.533    |
| time/               |          |
|    episodes         | 7376     |
|    fps              | 34       |
|    time_elapsed     | 3905     |
|    total_timesteps  | 136369   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000125 |
|    n_updates        | 24092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.532    |
| time/               |          |
|    episodes         | 7380     |
|    fps              | 34       |
|    time_elapsed     | 3906     |
|    total_timesteps  | 136451   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000153 |
|    n_updates        | 24112    |
----------------------------------
Eval num_timesteps=136500, episode_reward=-0.04 +/- 0.33
Episode length: 34.12 +/- 20.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.1     |
|    mean_reward      | -0.0356  |
| rollout/            |          |
|    exploration_rate | 0.532    |
| time/               |          |
|    total_timesteps  | 136500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000108 |
|    n_updates        | 24124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0304  |
|    exploration_rate | 0.532    |
| time/               |          |
|    episodes         | 7384     |
|    fps              | 34       |
|    time_elapsed     | 3914     |
|    total_timesteps  | 136539   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.25e-05 |
|    n_updates        | 24134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0197  |
|    exploration_rate | 0.531    |
| time/               |          |
|    episodes         | 7388     |
|    fps              | 34       |
|    time_elapsed     | 3914     |
|    total_timesteps  | 136612   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 24152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.531    |
| time/               |          |
|    episodes         | 7392     |
|    fps              | 34       |
|    time_elapsed     | 3915     |
|    total_timesteps  | 136690   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.37e-05 |
|    n_updates        | 24172    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 0.53     |
| time/               |          |
|    episodes         | 7396     |
|    fps              | 34       |
|    time_elapsed     | 3915     |
|    total_timesteps  | 136776   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.47e-05 |
|    n_updates        | 24193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.529    |
| time/               |          |
|    episodes         | 7400     |
|    fps              | 34       |
|    time_elapsed     | 3916     |
|    total_timesteps  | 136860   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.69e-05 |
|    n_updates        | 24214    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0201  |
|    exploration_rate | 0.529    |
| time/               |          |
|    episodes         | 7404     |
|    fps              | 34       |
|    time_elapsed     | 3916     |
|    total_timesteps  | 136940   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.1e-05  |
|    n_updates        | 24234    |
----------------------------------
Eval num_timesteps=137000, episode_reward=-0.04 +/- 0.29
Episode length: 30.22 +/- 14.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 30.2     |
|    mean_reward      | -0.0399  |
| rollout/            |          |
|    exploration_rate | 0.528    |
| time/               |          |
|    total_timesteps  | 137000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.77e-05 |
|    n_updates        | 24249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 0.528    |
| time/               |          |
|    episodes         | 7408     |
|    fps              | 34       |
|    time_elapsed     | 3923     |
|    total_timesteps  | 137019   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00012  |
|    n_updates        | 24254    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0107  |
|    exploration_rate | 0.528    |
| time/               |          |
|    episodes         | 7412     |
|    fps              | 34       |
|    time_elapsed     | 3924     |
|    total_timesteps  | 137102   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000141 |
|    n_updates        | 24275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 0.527    |
| time/               |          |
|    episodes         | 7416     |
|    fps              | 34       |
|    time_elapsed     | 3924     |
|    total_timesteps  | 137183   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00793  |
|    n_updates        | 24295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0114  |
|    exploration_rate | 0.527    |
| time/               |          |
|    episodes         | 7420     |
|    fps              | 34       |
|    time_elapsed     | 3925     |
|    total_timesteps  | 137264   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.85e-05 |
|    n_updates        | 24315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.526    |
| time/               |          |
|    episodes         | 7424     |
|    fps              | 34       |
|    time_elapsed     | 3925     |
|    total_timesteps  | 137384   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000105 |
|    n_updates        | 24345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.00327 |
|    exploration_rate | 0.525    |
| time/               |          |
|    episodes         | 7428     |
|    fps              | 35       |
|    time_elapsed     | 3926     |
|    total_timesteps  | 137452   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.94e-05 |
|    n_updates        | 24362    |
----------------------------------
Eval num_timesteps=137500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.525    |
| time/               |          |
|    total_timesteps  | 137500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000116 |
|    n_updates        | 24374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.00323 |
|    exploration_rate | 0.525    |
| time/               |          |
|    episodes         | 7432     |
|    fps              | 34       |
|    time_elapsed     | 3940     |
|    total_timesteps  | 137534   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.38e-05 |
|    n_updates        | 24383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.00291 |
|    exploration_rate | 0.524    |
| time/               |          |
|    episodes         | 7436     |
|    fps              | 34       |
|    time_elapsed     | 3941     |
|    total_timesteps  | 137605   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.56e-05 |
|    n_updates        | 24401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.00296 |
|    exploration_rate | 0.523    |
| time/               |          |
|    episodes         | 7440     |
|    fps              | 34       |
|    time_elapsed     | 3942     |
|    total_timesteps  | 137690   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.35e-05 |
|    n_updates        | 24422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.00701  |
|    exploration_rate | 0.523    |
| time/               |          |
|    episodes         | 7444     |
|    fps              | 34       |
|    time_elapsed     | 3942     |
|    total_timesteps  | 137764   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.06e-05 |
|    n_updates        | 24440    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.00761  |
|    exploration_rate | 0.522    |
| time/               |          |
|    episodes         | 7448     |
|    fps              | 34       |
|    time_elapsed     | 3942     |
|    total_timesteps  | 137850   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.65e-05 |
|    n_updates        | 24462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.522    |
| time/               |          |
|    episodes         | 7452     |
|    fps              | 34       |
|    time_elapsed     | 3943     |
|    total_timesteps  | 137932   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000166 |
|    n_updates        | 24482    |
----------------------------------
Eval num_timesteps=138000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.521    |
| time/               |          |
|    total_timesteps  | 138000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.28e-05 |
|    n_updates        | 24499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.521    |
| time/               |          |
|    episodes         | 7456     |
|    fps              | 34       |
|    time_elapsed     | 3955     |
|    total_timesteps  | 138009   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.11e-05 |
|    n_updates        | 24502    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 0.52     |
| time/               |          |
|    episodes         | 7460     |
|    fps              | 34       |
|    time_elapsed     | 3955     |
|    total_timesteps  | 138090   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000105 |
|    n_updates        | 24522    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0387   |
|    exploration_rate | 0.52     |
| time/               |          |
|    episodes         | 7464     |
|    fps              | 34       |
|    time_elapsed     | 3956     |
|    total_timesteps  | 138202   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.74e-05 |
|    n_updates        | 24550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.519    |
| time/               |          |
|    episodes         | 7468     |
|    fps              | 34       |
|    time_elapsed     | 3957     |
|    total_timesteps  | 138305   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.18e-05 |
|    n_updates        | 24576    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.518    |
| time/               |          |
|    episodes         | 7472     |
|    fps              | 34       |
|    time_elapsed     | 3957     |
|    total_timesteps  | 138385   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00782  |
|    n_updates        | 24596    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0375   |
|    exploration_rate | 0.518    |
| time/               |          |
|    episodes         | 7476     |
|    fps              | 34       |
|    time_elapsed     | 3958     |
|    total_timesteps  | 138461   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.45e-05 |
|    n_updates        | 24615    |
----------------------------------
Eval num_timesteps=138500, episode_reward=-0.26 +/- 0.17
Episode length: 69.22 +/- 16.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.2     |
|    mean_reward      | -0.257   |
| rollout/            |          |
|    exploration_rate | 0.517    |
| time/               |          |
|    total_timesteps  | 138500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.18e-05 |
|    n_updates        | 24624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.517    |
| time/               |          |
|    episodes         | 7480     |
|    fps              | 34       |
|    time_elapsed     | 3973     |
|    total_timesteps  | 138531   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00763  |
|    n_updates        | 24632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.517    |
| time/               |          |
|    episodes         | 7484     |
|    fps              | 34       |
|    time_elapsed     | 3974     |
|    total_timesteps  | 138609   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000116 |
|    n_updates        | 24652    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.516    |
| time/               |          |
|    episodes         | 7488     |
|    fps              | 34       |
|    time_elapsed     | 3974     |
|    total_timesteps  | 138674   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00699  |
|    n_updates        | 24668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.515    |
| time/               |          |
|    episodes         | 7492     |
|    fps              | 34       |
|    time_elapsed     | 3975     |
|    total_timesteps  | 138771   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00782  |
|    n_updates        | 24692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.515    |
| time/               |          |
|    episodes         | 7496     |
|    fps              | 34       |
|    time_elapsed     | 3975     |
|    total_timesteps  | 138861   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.97e-05 |
|    n_updates        | 24715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.514    |
| time/               |          |
|    episodes         | 7500     |
|    fps              | 34       |
|    time_elapsed     | 3976     |
|    total_timesteps  | 138940   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.89e-05 |
|    n_updates        | 24734    |
----------------------------------
Eval num_timesteps=139000, episode_reward=-0.16 +/- 0.31
Episode length: 60.96 +/- 17.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61       |
|    mean_reward      | -0.163   |
| rollout/            |          |
|    exploration_rate | 0.514    |
| time/               |          |
|    total_timesteps  | 139000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00784  |
|    n_updates        | 24749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0282   |
|    exploration_rate | 0.514    |
| time/               |          |
|    episodes         | 7504     |
|    fps              | 34       |
|    time_elapsed     | 3989     |
|    total_timesteps  | 139014   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.17e-05 |
|    n_updates        | 24753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.513    |
| time/               |          |
|    episodes         | 7508     |
|    fps              | 34       |
|    time_elapsed     | 3990     |
|    total_timesteps  | 139099   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.48e-05 |
|    n_updates        | 24774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.512    |
| time/               |          |
|    episodes         | 7512     |
|    fps              | 34       |
|    time_elapsed     | 3990     |
|    total_timesteps  | 139183   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00012  |
|    n_updates        | 24795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | 0.0267   |
|    exploration_rate | 0.512    |
| time/               |          |
|    episodes         | 7516     |
|    fps              | 34       |
|    time_elapsed     | 3991     |
|    total_timesteps  | 139294   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 24823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | 0.0164   |
|    exploration_rate | 0.511    |
| time/               |          |
|    episodes         | 7520     |
|    fps              | 34       |
|    time_elapsed     | 3992     |
|    total_timesteps  | 139382   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.32e-05 |
|    n_updates        | 24845    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.51     |
| time/               |          |
|    episodes         | 7524     |
|    fps              | 34       |
|    time_elapsed     | 3992     |
|    total_timesteps  | 139463   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000116 |
|    n_updates        | 24865    |
----------------------------------
Eval num_timesteps=139500, episode_reward=-0.11 +/- 0.32
Episode length: 53.38 +/- 20.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.4     |
|    mean_reward      | -0.113   |
| rollout/            |          |
|    exploration_rate | 0.51     |
| time/               |          |
|    total_timesteps  | 139500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.46e-05 |
|    n_updates        | 24874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.51     |
| time/               |          |
|    episodes         | 7528     |
|    fps              | 34       |
|    time_elapsed     | 4003     |
|    total_timesteps  | 139547   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000188 |
|    n_updates        | 24886    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.509    |
| time/               |          |
|    episodes         | 7532     |
|    fps              | 34       |
|    time_elapsed     | 4004     |
|    total_timesteps  | 139629   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000112 |
|    n_updates        | 24907    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.508    |
| time/               |          |
|    episodes         | 7536     |
|    fps              | 34       |
|    time_elapsed     | 4004     |
|    total_timesteps  | 139730   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.67e-05 |
|    n_updates        | 24932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | 0.0258   |
|    exploration_rate | 0.508    |
| time/               |          |
|    episodes         | 7540     |
|    fps              | 34       |
|    time_elapsed     | 4005     |
|    total_timesteps  | 139823   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.42e-05 |
|    n_updates        | 24955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.00482  |
|    exploration_rate | 0.507    |
| time/               |          |
|    episodes         | 7544     |
|    fps              | 34       |
|    time_elapsed     | 4005     |
|    total_timesteps  | 139921   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00685  |
|    n_updates        | 24980    |
----------------------------------
Eval num_timesteps=140000, episode_reward=-0.08 +/- 0.22
Episode length: 30.34 +/- 19.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 30.3     |
|    mean_reward      | -0.0805  |
| rollout/            |          |
|    exploration_rate | 0.506    |
| time/               |          |
|    total_timesteps  | 140000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.63e-05 |
|    n_updates        | 24999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.00458  |
|    exploration_rate | 0.506    |
| time/               |          |
|    episodes         | 7548     |
|    fps              | 34       |
|    time_elapsed     | 4012     |
|    total_timesteps  | 140013   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.34e-05 |
|    n_updates        | 25003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.5     |
|    ep_rew_mean      | 0.0051   |
|    exploration_rate | 0.506    |
| time/               |          |
|    episodes         | 7552     |
|    fps              | 34       |
|    time_elapsed     | 4013     |
|    total_timesteps  | 140082   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00756  |
|    n_updates        | 25020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | 0.00546  |
|    exploration_rate | 0.505    |
| time/               |          |
|    episodes         | 7556     |
|    fps              | 34       |
|    time_elapsed     | 4013     |
|    total_timesteps  | 140150   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0147   |
|    n_updates        | 25037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.5     |
|    ep_rew_mean      | -0.00488 |
|    exploration_rate | 0.505    |
| time/               |          |
|    episodes         | 7560     |
|    fps              | 34       |
|    time_elapsed     | 4014     |
|    total_timesteps  | 140239   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.61e-05 |
|    n_updates        | 25059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0042  |
|    exploration_rate | 0.504    |
| time/               |          |
|    episodes         | 7564     |
|    fps              | 34       |
|    time_elapsed     | 4014     |
|    total_timesteps  | 140334   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.92e-05 |
|    n_updates        | 25083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.00352 |
|    exploration_rate | 0.503    |
| time/               |          |
|    episodes         | 7568     |
|    fps              | 34       |
|    time_elapsed     | 4015     |
|    total_timesteps  | 140420   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000112 |
|    n_updates        | 25104    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | 0.00665  |
|    exploration_rate | 0.503    |
| time/               |          |
|    episodes         | 7572     |
|    fps              | 34       |
|    time_elapsed     | 4015     |
|    total_timesteps  | 140496   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000102 |
|    n_updates        | 25123    |
----------------------------------
Eval num_timesteps=140500, episode_reward=-0.30 +/- 0.00
Episode length: 74.88 +/- 0.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.9     |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.503    |
| time/               |          |
|    total_timesteps  | 140500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.63e-05 |
|    n_updates        | 25124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.00344 |
|    exploration_rate | 0.502    |
| time/               |          |
|    episodes         | 7576     |
|    fps              | 34       |
|    time_elapsed     | 4027     |
|    total_timesteps  | 140574   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 25143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.00388 |
|    exploration_rate | 0.502    |
| time/               |          |
|    episodes         | 7580     |
|    fps              | 34       |
|    time_elapsed     | 4028     |
|    total_timesteps  | 140655   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 25163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | 0.00653  |
|    exploration_rate | 0.501    |
| time/               |          |
|    episodes         | 7584     |
|    fps              | 34       |
|    time_elapsed     | 4028     |
|    total_timesteps  | 140723   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.18e-05 |
|    n_updates        | 25180    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 7588     |
|    fps              | 34       |
|    time_elapsed     | 4029     |
|    total_timesteps  | 140795   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.16e-05 |
|    n_updates        | 25198    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 7592     |
|    fps              | 34       |
|    time_elapsed     | 4029     |
|    total_timesteps  | 140872   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000156 |
|    n_updates        | 25217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0275   |
|    exploration_rate | 0.499    |
| time/               |          |
|    episodes         | 7596     |
|    fps              | 34       |
|    time_elapsed     | 4030     |
|    total_timesteps  | 140951   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000172 |
|    n_updates        | 25237    |
----------------------------------
Eval num_timesteps=141000, episode_reward=-0.28 +/- 0.07
Episode length: 69.36 +/- 16.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.4     |
|    mean_reward      | -0.277   |
| rollout/            |          |
|    exploration_rate | 0.499    |
| time/               |          |
|    total_timesteps  | 141000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00677  |
|    n_updates        | 25249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.499    |
| time/               |          |
|    episodes         | 7600     |
|    fps              | 34       |
|    time_elapsed     | 4044     |
|    total_timesteps  | 141033   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.77e-05 |
|    n_updates        | 25258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.498    |
| time/               |          |
|    episodes         | 7604     |
|    fps              | 34       |
|    time_elapsed     | 4044     |
|    total_timesteps  | 141111   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.38e-05 |
|    n_updates        | 25277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.498    |
| time/               |          |
|    episodes         | 7608     |
|    fps              | 34       |
|    time_elapsed     | 4045     |
|    total_timesteps  | 141183   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.85e-05 |
|    n_updates        | 25295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.497    |
| time/               |          |
|    episodes         | 7612     |
|    fps              | 34       |
|    time_elapsed     | 4045     |
|    total_timesteps  | 141253   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.49e-05 |
|    n_updates        | 25313    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 0.497    |
| time/               |          |
|    episodes         | 7616     |
|    fps              | 34       |
|    time_elapsed     | 4046     |
|    total_timesteps  | 141326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.2e-05  |
|    n_updates        | 25331    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.496    |
| time/               |          |
|    episodes         | 7620     |
|    fps              | 34       |
|    time_elapsed     | 4046     |
|    total_timesteps  | 141433   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00703  |
|    n_updates        | 25358    |
----------------------------------
Eval num_timesteps=141500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.495    |
| time/               |          |
|    total_timesteps  | 141500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.39e-05 |
|    n_updates        | 25374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0284   |
|    exploration_rate | 0.495    |
| time/               |          |
|    episodes         | 7624     |
|    fps              | 34       |
|    time_elapsed     | 4062     |
|    total_timesteps  | 141528   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.52e-05 |
|    n_updates        | 25381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0386   |
|    exploration_rate | 0.494    |
| time/               |          |
|    episodes         | 7628     |
|    fps              | 34       |
|    time_elapsed     | 4063     |
|    total_timesteps  | 141607   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.26e-05 |
|    n_updates        | 25401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.494    |
| time/               |          |
|    episodes         | 7632     |
|    fps              | 34       |
|    time_elapsed     | 4063     |
|    total_timesteps  | 141675   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.31e-05 |
|    n_updates        | 25418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.493    |
| time/               |          |
|    episodes         | 7636     |
|    fps              | 34       |
|    time_elapsed     | 4064     |
|    total_timesteps  | 141775   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000107 |
|    n_updates        | 25443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.0202   |
|    exploration_rate | 0.493    |
| time/               |          |
|    episodes         | 7640     |
|    fps              | 34       |
|    time_elapsed     | 4064     |
|    total_timesteps  | 141842   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000124 |
|    n_updates        | 25460    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.492    |
| time/               |          |
|    episodes         | 7644     |
|    fps              | 34       |
|    time_elapsed     | 4065     |
|    total_timesteps  | 141972   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.18e-05 |
|    n_updates        | 25492    |
----------------------------------
Eval num_timesteps=142000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.492    |
| time/               |          |
|    total_timesteps  | 142000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.71e-05 |
|    n_updates        | 25499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.491    |
| time/               |          |
|    episodes         | 7648     |
|    fps              | 34       |
|    time_elapsed     | 4077     |
|    total_timesteps  | 142055   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.04e-05 |
|    n_updates        | 25513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0188   |
|    exploration_rate | 0.49     |
| time/               |          |
|    episodes         | 7652     |
|    fps              | 34       |
|    time_elapsed     | 4078     |
|    total_timesteps  | 142137   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.07e-05 |
|    n_updates        | 25534    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.49     |
| time/               |          |
|    episodes         | 7656     |
|    fps              | 34       |
|    time_elapsed     | 4078     |
|    total_timesteps  | 142227   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 25556    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.489    |
| time/               |          |
|    episodes         | 7660     |
|    fps              | 34       |
|    time_elapsed     | 4078     |
|    total_timesteps  | 142297   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00707  |
|    n_updates        | 25574    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 0.489    |
| time/               |          |
|    episodes         | 7664     |
|    fps              | 34       |
|    time_elapsed     | 4079     |
|    total_timesteps  | 142367   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00693  |
|    n_updates        | 25591    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0304   |
|    exploration_rate | 0.488    |
| time/               |          |
|    episodes         | 7668     |
|    fps              | 34       |
|    time_elapsed     | 4079     |
|    total_timesteps  | 142435   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 25608    |
----------------------------------
Eval num_timesteps=142500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.488    |
| time/               |          |
|    total_timesteps  | 142500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000102 |
|    n_updates        | 25624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0206   |
|    exploration_rate | 0.488    |
| time/               |          |
|    episodes         | 7672     |
|    fps              | 34       |
|    time_elapsed     | 4092     |
|    total_timesteps  | 142507   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.74e-05 |
|    n_updates        | 25626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.019    |
|    exploration_rate | 0.487    |
| time/               |          |
|    episodes         | 7676     |
|    fps              | 34       |
|    time_elapsed     | 4093     |
|    total_timesteps  | 142623   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.33e-05 |
|    n_updates        | 25655    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0197   |
|    exploration_rate | 0.486    |
| time/               |          |
|    episodes         | 7680     |
|    fps              | 34       |
|    time_elapsed     | 4093     |
|    total_timesteps  | 142687   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000175 |
|    n_updates        | 25671    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.00874  |
|    exploration_rate | 0.486    |
| time/               |          |
|    episodes         | 7684     |
|    fps              | 34       |
|    time_elapsed     | 4093     |
|    total_timesteps  | 142779   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.68e-05 |
|    n_updates        | 25694    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.00141 |
|    exploration_rate | 0.485    |
| time/               |          |
|    episodes         | 7688     |
|    fps              | 34       |
|    time_elapsed     | 4094     |
|    total_timesteps  | 142855   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00691  |
|    n_updates        | 25713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0125  |
|    exploration_rate | 0.484    |
| time/               |          |
|    episodes         | 7692     |
|    fps              | 34       |
|    time_elapsed     | 4094     |
|    total_timesteps  | 142959   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 25739    |
----------------------------------
Eval num_timesteps=143000, episode_reward=-0.30 +/- 0.03
Episode length: 73.84 +/- 8.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.484    |
| time/               |          |
|    total_timesteps  | 143000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000139 |
|    n_updates        | 25749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.00241 |
|    exploration_rate | 0.484    |
| time/               |          |
|    episodes         | 7696     |
|    fps              | 34       |
|    time_elapsed     | 4110     |
|    total_timesteps  | 143036   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0141   |
|    n_updates        | 25758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.00224 |
|    exploration_rate | 0.483    |
| time/               |          |
|    episodes         | 7700     |
|    fps              | 34       |
|    time_elapsed     | 4110     |
|    total_timesteps  | 143114   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.64e-05 |
|    n_updates        | 25778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.00224 |
|    exploration_rate | 0.483    |
| time/               |          |
|    episodes         | 7704     |
|    fps              | 34       |
|    time_elapsed     | 4111     |
|    total_timesteps  | 143192   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00017  |
|    n_updates        | 25797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.00308 |
|    exploration_rate | 0.482    |
| time/               |          |
|    episodes         | 7708     |
|    fps              | 34       |
|    time_elapsed     | 4111     |
|    total_timesteps  | 143285   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.71e-05 |
|    n_updates        | 25821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.481    |
| time/               |          |
|    episodes         | 7712     |
|    fps              | 34       |
|    time_elapsed     | 4112     |
|    total_timesteps  | 143354   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.96e-05 |
|    n_updates        | 25838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.5     |
|    ep_rew_mean      | -0.0248  |
|    exploration_rate | 0.48     |
| time/               |          |
|    episodes         | 7716     |
|    fps              | 34       |
|    time_elapsed     | 4112     |
|    total_timesteps  | 143472   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000133 |
|    n_updates        | 25867    |
----------------------------------
Eval num_timesteps=143500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.48     |
| time/               |          |
|    total_timesteps  | 143500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000152 |
|    n_updates        | 25874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0035  |
|    exploration_rate | 0.48     |
| time/               |          |
|    episodes         | 7720     |
|    fps              | 34       |
|    time_elapsed     | 4127     |
|    total_timesteps  | 143545   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.73e-05 |
|    n_updates        | 25886    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.00298 |
|    exploration_rate | 0.479    |
| time/               |          |
|    episodes         | 7724     |
|    fps              | 34       |
|    time_elapsed     | 4128     |
|    total_timesteps  | 143627   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00784  |
|    n_updates        | 25906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.479    |
| time/               |          |
|    episodes         | 7728     |
|    fps              | 34       |
|    time_elapsed     | 4128     |
|    total_timesteps  | 143713   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.06e-05 |
|    n_updates        | 25928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.478    |
| time/               |          |
|    episodes         | 7732     |
|    fps              | 34       |
|    time_elapsed     | 4129     |
|    total_timesteps  | 143795   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0073   |
|    n_updates        | 25948    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.477    |
| time/               |          |
|    episodes         | 7736     |
|    fps              | 34       |
|    time_elapsed     | 4129     |
|    total_timesteps  | 143878   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00012  |
|    n_updates        | 25969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.00289 |
|    exploration_rate | 0.477    |
| time/               |          |
|    episodes         | 7740     |
|    fps              | 34       |
|    time_elapsed     | 4130     |
|    total_timesteps  | 143939   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.22e-05 |
|    n_updates        | 25984    |
----------------------------------
Eval num_timesteps=144000, episode_reward=-0.29 +/- 0.05
Episode length: 72.08 +/- 12.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.1     |
|    mean_reward      | -0.288   |
| rollout/            |          |
|    exploration_rate | 0.476    |
| time/               |          |
|    total_timesteps  | 144000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00793  |
|    n_updates        | 25999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0199   |
|    exploration_rate | 0.476    |
| time/               |          |
|    episodes         | 7744     |
|    fps              | 34       |
|    time_elapsed     | 4141     |
|    total_timesteps  | 144000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.00995  |
|    exploration_rate | 0.476    |
| time/               |          |
|    episodes         | 7748     |
|    fps              | 34       |
|    time_elapsed     | 4142     |
|    total_timesteps  | 144081   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00699  |
|    n_updates        | 26020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.0203   |
|    exploration_rate | 0.475    |
| time/               |          |
|    episodes         | 7752     |
|    fps              | 34       |
|    time_elapsed     | 4142     |
|    total_timesteps  | 144154   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.5e-05  |
|    n_updates        | 26038    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 0.475    |
| time/               |          |
|    episodes         | 7756     |
|    fps              | 34       |
|    time_elapsed     | 4143     |
|    total_timesteps  | 144261   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00701  |
|    n_updates        | 26065    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.00914  |
|    exploration_rate | 0.474    |
| time/               |          |
|    episodes         | 7760     |
|    fps              | 34       |
|    time_elapsed     | 4144     |
|    total_timesteps  | 144343   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.93e-05 |
|    n_updates        | 26085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.473    |
| time/               |          |
|    episodes         | 7764     |
|    fps              | 34       |
|    time_elapsed     | 4144     |
|    total_timesteps  | 144438   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.29e-05 |
|    n_updates        | 26109    |
----------------------------------
Eval num_timesteps=144500, episode_reward=-0.29 +/- 0.04
Episode length: 72.84 +/- 9.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.8     |
|    mean_reward      | -0.291   |
| rollout/            |          |
|    exploration_rate | 0.473    |
| time/               |          |
|    total_timesteps  | 144500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 26124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.00732  |
|    exploration_rate | 0.472    |
| time/               |          |
|    episodes         | 7768     |
|    fps              | 34       |
|    time_elapsed     | 4156     |
|    total_timesteps  | 144527   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.21e-05 |
|    n_updates        | 26131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.00708  |
|    exploration_rate | 0.472    |
| time/               |          |
|    episodes         | 7772     |
|    fps              | 34       |
|    time_elapsed     | 4157     |
|    total_timesteps  | 144605   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.1e-05  |
|    n_updates        | 26151    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.471    |
| time/               |          |
|    episodes         | 7776     |
|    fps              | 34       |
|    time_elapsed     | 4157     |
|    total_timesteps  | 144668   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.41e-05 |
|    n_updates        | 26166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0287   |
|    exploration_rate | 0.471    |
| time/               |          |
|    episodes         | 7780     |
|    fps              | 34       |
|    time_elapsed     | 4158     |
|    total_timesteps  | 144744   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00711  |
|    n_updates        | 26185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 0.47     |
| time/               |          |
|    episodes         | 7784     |
|    fps              | 34       |
|    time_elapsed     | 4158     |
|    total_timesteps  | 144816   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000138 |
|    n_updates        | 26203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.0491   |
|    exploration_rate | 0.47     |
| time/               |          |
|    episodes         | 7788     |
|    fps              | 34       |
|    time_elapsed     | 4159     |
|    total_timesteps  | 144903   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 26225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0497   |
|    exploration_rate | 0.469    |
| time/               |          |
|    episodes         | 7792     |
|    fps              | 34       |
|    time_elapsed     | 4159     |
|    total_timesteps  | 144993   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00794  |
|    n_updates        | 26248    |
----------------------------------
Eval num_timesteps=145000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.469    |
| time/               |          |
|    total_timesteps  | 145000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.45e-05 |
|    n_updates        | 26249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 0.468    |
| time/               |          |
|    episodes         | 7796     |
|    fps              | 34       |
|    time_elapsed     | 4175     |
|    total_timesteps  | 145072   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.91e-05 |
|    n_updates        | 26267    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 0.468    |
| time/               |          |
|    episodes         | 7800     |
|    fps              | 34       |
|    time_elapsed     | 4175     |
|    total_timesteps  | 145159   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.35e-05 |
|    n_updates        | 26289    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.0289   |
|    exploration_rate | 0.467    |
| time/               |          |
|    episodes         | 7804     |
|    fps              | 34       |
|    time_elapsed     | 4176     |
|    total_timesteps  | 145245   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000111 |
|    n_updates        | 26311    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.0292   |
|    exploration_rate | 0.466    |
| time/               |          |
|    episodes         | 7808     |
|    fps              | 34       |
|    time_elapsed     | 4176     |
|    total_timesteps  | 145331   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0145   |
|    n_updates        | 26332    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.466    |
| time/               |          |
|    episodes         | 7812     |
|    fps              | 34       |
|    time_elapsed     | 4177     |
|    total_timesteps  | 145399   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 26349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0308   |
|    exploration_rate | 0.465    |
| time/               |          |
|    episodes         | 7816     |
|    fps              | 34       |
|    time_elapsed     | 4177     |
|    total_timesteps  | 145479   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000137 |
|    n_updates        | 26369    |
----------------------------------
Eval num_timesteps=145500, episode_reward=-0.05 +/- 0.39
Episode length: 47.22 +/- 25.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.2     |
|    mean_reward      | -0.0483  |
| rollout/            |          |
|    exploration_rate | 0.465    |
| time/               |          |
|    total_timesteps  | 145500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.4e-05  |
|    n_updates        | 26374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | 0.0212   |
|    exploration_rate | 0.465    |
| time/               |          |
|    episodes         | 7820     |
|    fps              | 34       |
|    time_elapsed     | 4187     |
|    total_timesteps  | 145543   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000234 |
|    n_updates        | 26385    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 0.464    |
| time/               |          |
|    episodes         | 7824     |
|    fps              | 34       |
|    time_elapsed     | 4188     |
|    total_timesteps  | 145642   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00723  |
|    n_updates        | 26410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | 0.0414   |
|    exploration_rate | 0.464    |
| time/               |          |
|    episodes         | 7828     |
|    fps              | 34       |
|    time_elapsed     | 4188     |
|    total_timesteps  | 145704   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000198 |
|    n_updates        | 26425    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.0421   |
|    exploration_rate | 0.463    |
| time/               |          |
|    episodes         | 7832     |
|    fps              | 34       |
|    time_elapsed     | 4189     |
|    total_timesteps  | 145770   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.69e-05 |
|    n_updates        | 26442    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.0421   |
|    exploration_rate | 0.462    |
| time/               |          |
|    episodes         | 7836     |
|    fps              | 34       |
|    time_elapsed     | 4189     |
|    total_timesteps  | 145853   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.1e-05  |
|    n_updates        | 26463    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | 0.0317   |
|    exploration_rate | 0.462    |
| time/               |          |
|    episodes         | 7840     |
|    fps              | 34       |
|    time_elapsed     | 4190     |
|    total_timesteps  | 145924   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000159 |
|    n_updates        | 26480    |
----------------------------------
Eval num_timesteps=146000, episode_reward=-0.03 +/- 0.25
Episode length: 21.52 +/- 13.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 21.5     |
|    mean_reward      | -0.0251  |
| rollout/            |          |
|    exploration_rate | 0.461    |
| time/               |          |
|    total_timesteps  | 146000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000134 |
|    n_updates        | 26499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0107   |
|    exploration_rate | 0.461    |
| time/               |          |
|    episodes         | 7844     |
|    fps              | 34       |
|    time_elapsed     | 4195     |
|    total_timesteps  | 146008   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.62e-05 |
|    n_updates        | 26501    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | 0.0112   |
|    exploration_rate | 0.461    |
| time/               |          |
|    episodes         | 7848     |
|    fps              | 34       |
|    time_elapsed     | 4195     |
|    total_timesteps  | 146077   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000114 |
|    n_updates        | 26519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | 0.00119  |
|    exploration_rate | 0.46     |
| time/               |          |
|    episodes         | 7852     |
|    fps              | 34       |
|    time_elapsed     | 4196     |
|    total_timesteps  | 146151   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.29e-05 |
|    n_updates        | 26537    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.00255  |
|    exploration_rate | 0.46     |
| time/               |          |
|    episodes         | 7856     |
|    fps              | 34       |
|    time_elapsed     | 4196     |
|    total_timesteps  | 146224   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.94e-05 |
|    n_updates        | 26555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.00191  |
|    exploration_rate | 0.459    |
| time/               |          |
|    episodes         | 7860     |
|    fps              | 34       |
|    time_elapsed     | 4197     |
|    total_timesteps  | 146322   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000116 |
|    n_updates        | 26580    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.00855 |
|    exploration_rate | 0.458    |
| time/               |          |
|    episodes         | 7864     |
|    fps              | 34       |
|    time_elapsed     | 4197     |
|    total_timesteps  | 146428   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00693  |
|    n_updates        | 26606    |
----------------------------------
Eval num_timesteps=146500, episode_reward=-0.29 +/- 0.04
Episode length: 72.80 +/- 10.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.8     |
|    mean_reward      | -0.291   |
| rollout/            |          |
|    exploration_rate | 0.457    |
| time/               |          |
|    total_timesteps  | 146500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00707  |
|    n_updates        | 26624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | 0.0015   |
|    exploration_rate | 0.457    |
| time/               |          |
|    episodes         | 7868     |
|    fps              | 34       |
|    time_elapsed     | 4213     |
|    total_timesteps  | 146516   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000119 |
|    n_updates        | 26628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.00066  |
|    exploration_rate | 0.457    |
| time/               |          |
|    episodes         | 7872     |
|    fps              | 34       |
|    time_elapsed     | 4214     |
|    total_timesteps  | 146615   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.06e-05 |
|    n_updates        | 26653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.455    |
| time/               |          |
|    episodes         | 7876     |
|    fps              | 34       |
|    time_elapsed     | 4215     |
|    total_timesteps  | 146760   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000137 |
|    n_updates        | 26689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.455    |
| time/               |          |
|    episodes         | 7880     |
|    fps              | 34       |
|    time_elapsed     | 4215     |
|    total_timesteps  | 146846   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.86e-05 |
|    n_updates        | 26711    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.454    |
| time/               |          |
|    episodes         | 7884     |
|    fps              | 34       |
|    time_elapsed     | 4216     |
|    total_timesteps  | 146919   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.57e-05 |
|    n_updates        | 26729    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.454    |
| time/               |          |
|    episodes         | 7888     |
|    fps              | 34       |
|    time_elapsed     | 4216     |
|    total_timesteps  | 146986   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000138 |
|    n_updates        | 26746    |
----------------------------------
Eval num_timesteps=147000, episode_reward=-0.03 +/- 0.20
Episode length: 17.82 +/- 6.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.8     |
|    mean_reward      | -0.0302  |
| rollout/            |          |
|    exploration_rate | 0.454    |
| time/               |          |
|    total_timesteps  | 147000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00765  |
|    n_updates        | 26749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.453    |
| time/               |          |
|    episodes         | 7892     |
|    fps              | 34       |
|    time_elapsed     | 4221     |
|    total_timesteps  | 147056   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00711  |
|    n_updates        | 26763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.453    |
| time/               |          |
|    episodes         | 7896     |
|    fps              | 34       |
|    time_elapsed     | 4222     |
|    total_timesteps  | 147135   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.11e-05 |
|    n_updates        | 26783    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.452    |
| time/               |          |
|    episodes         | 7900     |
|    fps              | 34       |
|    time_elapsed     | 4222     |
|    total_timesteps  | 147227   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.22e-05 |
|    n_updates        | 26806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.451    |
| time/               |          |
|    episodes         | 7904     |
|    fps              | 34       |
|    time_elapsed     | 4223     |
|    total_timesteps  | 147311   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.6e-05  |
|    n_updates        | 26827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.00153 |
|    exploration_rate | 0.451    |
| time/               |          |
|    episodes         | 7908     |
|    fps              | 34       |
|    time_elapsed     | 4223     |
|    total_timesteps  | 147396   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 26848    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.00787  |
|    exploration_rate | 0.45     |
| time/               |          |
|    episodes         | 7912     |
|    fps              | 34       |
|    time_elapsed     | 4224     |
|    total_timesteps  | 147479   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00699  |
|    n_updates        | 26869    |
----------------------------------
Eval num_timesteps=147500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.45     |
| time/               |          |
|    total_timesteps  | 147500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.68e-05 |
|    n_updates        | 26874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.449    |
| time/               |          |
|    episodes         | 7916     |
|    fps              | 34       |
|    time_elapsed     | 4240     |
|    total_timesteps  | 147568   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.66e-05 |
|    n_updates        | 26891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | 0.00625  |
|    exploration_rate | 0.449    |
| time/               |          |
|    episodes         | 7920     |
|    fps              | 34       |
|    time_elapsed     | 4240     |
|    total_timesteps  | 147664   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.61e-05 |
|    n_updates        | 26915    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.448    |
| time/               |          |
|    episodes         | 7924     |
|    fps              | 34       |
|    time_elapsed     | 4241     |
|    total_timesteps  | 147737   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.03e-05 |
|    n_updates        | 26934    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.00321 |
|    exploration_rate | 0.447    |
| time/               |          |
|    episodes         | 7928     |
|    fps              | 34       |
|    time_elapsed     | 4241     |
|    total_timesteps  | 147811   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0141   |
|    n_updates        | 26952    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.00449 |
|    exploration_rate | 0.447    |
| time/               |          |
|    episodes         | 7932     |
|    fps              | 34       |
|    time_elapsed     | 4242     |
|    total_timesteps  | 147909   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.49e-05 |
|    n_updates        | 26977    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.00469 |
|    exploration_rate | 0.446    |
| time/               |          |
|    episodes         | 7936     |
|    fps              | 34       |
|    time_elapsed     | 4242     |
|    total_timesteps  | 147997   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0145   |
|    n_updates        | 26999    |
----------------------------------
Eval num_timesteps=148000, episode_reward=-0.20 +/- 0.09
Episode length: 49.96 +/- 23.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50       |
|    mean_reward      | -0.199   |
| rollout/            |          |
|    exploration_rate | 0.446    |
| time/               |          |
|    total_timesteps  | 148000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.00589 |
|    exploration_rate | 0.445    |
| time/               |          |
|    episodes         | 7940     |
|    fps              | 34       |
|    time_elapsed     | 4254     |
|    total_timesteps  | 148098   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000112 |
|    n_updates        | 27024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.00487  |
|    exploration_rate | 0.445    |
| time/               |          |
|    episodes         | 7944     |
|    fps              | 34       |
|    time_elapsed     | 4255     |
|    total_timesteps  | 148163   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.33e-05 |
|    n_updates        | 27040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.00471  |
|    exploration_rate | 0.444    |
| time/               |          |
|    episodes         | 7948     |
|    fps              | 34       |
|    time_elapsed     | 4255     |
|    total_timesteps  | 148236   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 27058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.00447  |
|    exploration_rate | 0.444    |
| time/               |          |
|    episodes         | 7952     |
|    fps              | 34       |
|    time_elapsed     | 4256     |
|    total_timesteps  | 148316   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000114 |
|    n_updates        | 27078    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.443    |
| time/               |          |
|    episodes         | 7956     |
|    fps              | 34       |
|    time_elapsed     | 4256     |
|    total_timesteps  | 148400   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 27099    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.0148   |
|    exploration_rate | 0.442    |
| time/               |          |
|    episodes         | 7960     |
|    fps              | 34       |
|    time_elapsed     | 4257     |
|    total_timesteps  | 148478   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000147 |
|    n_updates        | 27119    |
----------------------------------
Eval num_timesteps=148500, episode_reward=-0.10 +/- 0.33
Episode length: 50.80 +/- 20.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.8     |
|    mean_reward      | -0.102   |
| rollout/            |          |
|    exploration_rate | 0.442    |
| time/               |          |
|    total_timesteps  | 148500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 27124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | 0.0157   |
|    exploration_rate | 0.442    |
| time/               |          |
|    episodes         | 7964     |
|    fps              | 34       |
|    time_elapsed     | 4267     |
|    total_timesteps  | 148561   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.66e-05 |
|    n_updates        | 27140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | 0.00581  |
|    exploration_rate | 0.441    |
| time/               |          |
|    episodes         | 7968     |
|    fps              | 34       |
|    time_elapsed     | 4268     |
|    total_timesteps  | 148647   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 27161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | 0.00573  |
|    exploration_rate | 0.44     |
| time/               |          |
|    episodes         | 7972     |
|    fps              | 34       |
|    time_elapsed     | 4268     |
|    total_timesteps  | 148748   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00778  |
|    n_updates        | 27186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.439    |
| time/               |          |
|    episodes         | 7976     |
|    fps              | 34       |
|    time_elapsed     | 4269     |
|    total_timesteps  | 148849   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 27212    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.439    |
| time/               |          |
|    episodes         | 7980     |
|    fps              | 34       |
|    time_elapsed     | 4270     |
|    total_timesteps  | 148935   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 27233    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.028    |
|    exploration_rate | 0.438    |
| time/               |          |
|    episodes         | 7984     |
|    fps              | 34       |
|    time_elapsed     | 4270     |
|    total_timesteps  | 148997   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.37e-05 |
|    n_updates        | 27249    |
----------------------------------
Eval num_timesteps=149000, episode_reward=-0.04 +/- 0.20
Episode length: 19.42 +/- 3.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.4     |
|    mean_reward      | -0.0367  |
| rollout/            |          |
|    exploration_rate | 0.438    |
| time/               |          |
|    total_timesteps  | 149000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0021  |
|    exploration_rate | 0.438    |
| time/               |          |
|    episodes         | 7988     |
|    fps              | 34       |
|    time_elapsed     | 4275     |
|    total_timesteps  | 149065   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.29e-05 |
|    n_updates        | 27266    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.00258 |
|    exploration_rate | 0.437    |
| time/               |          |
|    episodes         | 7992     |
|    fps              | 34       |
|    time_elapsed     | 4275     |
|    total_timesteps  | 149147   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.5e-05  |
|    n_updates        | 27286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0021  |
|    exploration_rate | 0.437    |
| time/               |          |
|    episodes         | 7996     |
|    fps              | 34       |
|    time_elapsed     | 4276     |
|    total_timesteps  | 149214   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00777  |
|    n_updates        | 27303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.00314 |
|    exploration_rate | 0.436    |
| time/               |          |
|    episodes         | 8000     |
|    fps              | 34       |
|    time_elapsed     | 4276     |
|    total_timesteps  | 149332   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000102 |
|    n_updates        | 27332    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.00721  |
|    exploration_rate | 0.435    |
| time/               |          |
|    episodes         | 8004     |
|    fps              | 34       |
|    time_elapsed     | 4277     |
|    total_timesteps  | 149407   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.45e-05 |
|    n_updates        | 27351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.00309 |
|    exploration_rate | 0.434    |
| time/               |          |
|    episodes         | 8008     |
|    fps              | 34       |
|    time_elapsed     | 4277     |
|    total_timesteps  | 149499   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000174 |
|    n_updates        | 27374    |
----------------------------------
Eval num_timesteps=149500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75       |
|    mean_reward     | -0.3     |
| time/              |          |
|    total_timesteps | 149500   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.434    |
| time/               |          |
|    episodes         | 8012     |
|    fps              | 34       |
|    time_elapsed     | 4290     |
|    total_timesteps  | 149587   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.54e-05 |
|    n_updates        | 27396    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.433    |
| time/               |          |
|    episodes         | 8016     |
|    fps              | 34       |
|    time_elapsed     | 4290     |
|    total_timesteps  | 149672   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00778  |
|    n_updates        | 27417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.432    |
| time/               |          |
|    episodes         | 8020     |
|    fps              | 34       |
|    time_elapsed     | 4290     |
|    total_timesteps  | 149758   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000129 |
|    n_updates        | 27439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.432    |
| time/               |          |
|    episodes         | 8024     |
|    fps              | 34       |
|    time_elapsed     | 4291     |
|    total_timesteps  | 149837   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.85e-05 |
|    n_updates        | 27459    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0233  |
|    exploration_rate | 0.431    |
| time/               |          |
|    episodes         | 8028     |
|    fps              | 34       |
|    time_elapsed     | 4291     |
|    total_timesteps  | 149919   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.87e-05 |
|    n_updates        | 27479    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.431    |
| time/               |          |
|    episodes         | 8032     |
|    fps              | 34       |
|    time_elapsed     | 4292     |
|    total_timesteps  | 149995   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.53e-05 |
|    n_updates        | 27498    |
----------------------------------
Eval num_timesteps=150000, episode_reward=-0.30 +/- 0.03
Episode length: 73.76 +/- 6.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.431    |
| time/               |          |
|    total_timesteps  | 150000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.85e-05 |
|    n_updates        | 27499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.43     |
| time/               |          |
|    episodes         | 8036     |
|    fps              | 34       |
|    time_elapsed     | 4307     |
|    total_timesteps  | 150084   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00708  |
|    n_updates        | 27520    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.429    |
| time/               |          |
|    episodes         | 8040     |
|    fps              | 34       |
|    time_elapsed     | 4308     |
|    total_timesteps  | 150179   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.17e-05 |
|    n_updates        | 27544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0341  |
|    exploration_rate | 0.428    |
| time/               |          |
|    episodes         | 8044     |
|    fps              | 34       |
|    time_elapsed     | 4309     |
|    total_timesteps  | 150292   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.8e-05  |
|    n_updates        | 27572    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0346  |
|    exploration_rate | 0.428    |
| time/               |          |
|    episodes         | 8048     |
|    fps              | 34       |
|    time_elapsed     | 4309     |
|    total_timesteps  | 150376   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.85e-05 |
|    n_updates        | 27593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0345  |
|    exploration_rate | 0.427    |
| time/               |          |
|    episodes         | 8052     |
|    fps              | 34       |
|    time_elapsed     | 4309     |
|    total_timesteps  | 150453   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.5e-05  |
|    n_updates        | 27613    |
----------------------------------
Eval num_timesteps=150500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.427    |
| time/               |          |
|    total_timesteps  | 150500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.69e-05 |
|    n_updates        | 27624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | -0.0456  |
|    exploration_rate | 0.426    |
| time/               |          |
|    episodes         | 8056     |
|    fps              | 34       |
|    time_elapsed     | 4322     |
|    total_timesteps  | 150565   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000183 |
|    n_updates        | 27641    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.0356  |
|    exploration_rate | 0.426    |
| time/               |          |
|    episodes         | 8060     |
|    fps              | 34       |
|    time_elapsed     | 4322     |
|    total_timesteps  | 150644   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.68e-05 |
|    n_updates        | 27660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | -0.0355  |
|    exploration_rate | 0.425    |
| time/               |          |
|    episodes         | 8064     |
|    fps              | 34       |
|    time_elapsed     | 4323     |
|    total_timesteps  | 150725   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00706  |
|    n_updates        | 27681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | -0.0354  |
|    exploration_rate | 0.424    |
| time/               |          |
|    episodes         | 8068     |
|    fps              | 34       |
|    time_elapsed     | 4323     |
|    total_timesteps  | 150808   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0147   |
|    n_updates        | 27701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.424    |
| time/               |          |
|    episodes         | 8072     |
|    fps              | 34       |
|    time_elapsed     | 4324     |
|    total_timesteps  | 150891   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000111 |
|    n_updates        | 27722    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.423    |
| time/               |          |
|    episodes         | 8076     |
|    fps              | 34       |
|    time_elapsed     | 4324     |
|    total_timesteps  | 150975   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 27743    |
----------------------------------
Eval num_timesteps=151000, episode_reward=-0.10 +/- 0.38
Episode length: 55.44 +/- 21.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.4     |
|    mean_reward      | -0.101   |
| rollout/            |          |
|    exploration_rate | 0.423    |
| time/               |          |
|    total_timesteps  | 151000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00701  |
|    n_updates        | 27749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0436  |
|    exploration_rate | 0.422    |
| time/               |          |
|    episodes         | 8080     |
|    fps              | 34       |
|    time_elapsed     | 4336     |
|    total_timesteps  | 151050   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.29e-05 |
|    n_updates        | 27762    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | -0.0554  |
|    exploration_rate | 0.422    |
| time/               |          |
|    episodes         | 8084     |
|    fps              | 34       |
|    time_elapsed     | 4337     |
|    total_timesteps  | 151157   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000127 |
|    n_updates        | 27789    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | -0.0554  |
|    exploration_rate | 0.421    |
| time/               |          |
|    episodes         | 8088     |
|    fps              | 34       |
|    time_elapsed     | 4337     |
|    total_timesteps  | 151226   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.86e-05 |
|    n_updates        | 27806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.5     |
|    ep_rew_mean      | -0.045   |
|    exploration_rate | 0.42     |
| time/               |          |
|    episodes         | 8092     |
|    fps              | 34       |
|    time_elapsed     | 4337     |
|    total_timesteps  | 151298   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.31e-05 |
|    n_updates        | 27824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.5     |
|    ep_rew_mean      | -0.0251  |
|    exploration_rate | 0.42     |
| time/               |          |
|    episodes         | 8096     |
|    fps              | 34       |
|    time_elapsed     | 4338     |
|    total_timesteps  | 151367   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00776  |
|    n_updates        | 27841    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0235  |
|    exploration_rate | 0.419    |
| time/               |          |
|    episodes         | 8100     |
|    fps              | 34       |
|    time_elapsed     | 4338     |
|    total_timesteps  | 151444   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000104 |
|    n_updates        | 27860    |
----------------------------------
Eval num_timesteps=151500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.419    |
| time/               |          |
|    total_timesteps  | 151500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000164 |
|    n_updates        | 27874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0234  |
|    exploration_rate | 0.419    |
| time/               |          |
|    episodes         | 8104     |
|    fps              | 34       |
|    time_elapsed     | 4354     |
|    total_timesteps  | 151518   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.014    |
|    n_updates        | 27879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.418    |
| time/               |          |
|    episodes         | 8108     |
|    fps              | 34       |
|    time_elapsed     | 4354     |
|    total_timesteps  | 151610   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000135 |
|    n_updates        | 27902    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.00278 |
|    exploration_rate | 0.417    |
| time/               |          |
|    episodes         | 8112     |
|    fps              | 34       |
|    time_elapsed     | 4355     |
|    total_timesteps  | 151683   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.78e-05 |
|    n_updates        | 27920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0023  |
|    exploration_rate | 0.417    |
| time/               |          |
|    episodes         | 8116     |
|    fps              | 34       |
|    time_elapsed     | 4355     |
|    total_timesteps  | 151756   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.62e-05 |
|    n_updates        | 27938    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 0.416    |
| time/               |          |
|    episodes         | 8120     |
|    fps              | 34       |
|    time_elapsed     | 4356     |
|    total_timesteps  | 151837   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.58e-05 |
|    n_updates        | 27959    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.416    |
| time/               |          |
|    episodes         | 8124     |
|    fps              | 34       |
|    time_elapsed     | 4356     |
|    total_timesteps  | 151920   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6e-05    |
|    n_updates        | 27979    |
----------------------------------
Eval num_timesteps=152000, episode_reward=-0.16 +/- 0.31
Episode length: 59.38 +/- 19.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.4     |
|    mean_reward      | -0.157   |
| rollout/            |          |
|    exploration_rate | 0.415    |
| time/               |          |
|    total_timesteps  | 152000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.82e-05 |
|    n_updates        | 27999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.00285 |
|    exploration_rate | 0.415    |
| time/               |          |
|    episodes         | 8128     |
|    fps              | 34       |
|    time_elapsed     | 4369     |
|    total_timesteps  | 152017   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.87e-05 |
|    n_updates        | 28004    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.00329 |
|    exploration_rate | 0.414    |
| time/               |          |
|    episodes         | 8132     |
|    fps              | 34       |
|    time_elapsed     | 4369     |
|    total_timesteps  | 152104   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 28025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.00703  |
|    exploration_rate | 0.413    |
| time/               |          |
|    episodes         | 8136     |
|    fps              | 34       |
|    time_elapsed     | 4370     |
|    total_timesteps  | 152185   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.53e-05 |
|    n_updates        | 28046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0184   |
|    exploration_rate | 0.413    |
| time/               |          |
|    episodes         | 8140     |
|    fps              | 34       |
|    time_elapsed     | 4370     |
|    total_timesteps  | 152246   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 28061    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | 0.0298   |
|    exploration_rate | 0.412    |
| time/               |          |
|    episodes         | 8144     |
|    fps              | 34       |
|    time_elapsed     | 4371     |
|    total_timesteps  | 152323   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000174 |
|    n_updates        | 28080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0295   |
|    exploration_rate | 0.412    |
| time/               |          |
|    episodes         | 8148     |
|    fps              | 34       |
|    time_elapsed     | 4371     |
|    total_timesteps  | 152416   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.3e-05  |
|    n_updates        | 28103    |
----------------------------------
Eval num_timesteps=152500, episode_reward=-0.30 +/- 0.03
Episode length: 73.96 +/- 7.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.411    |
| time/               |          |
|    total_timesteps  | 152500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.31e-05 |
|    n_updates        | 28124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0388   |
|    exploration_rate | 0.411    |
| time/               |          |
|    episodes         | 8152     |
|    fps              | 34       |
|    time_elapsed     | 4384     |
|    total_timesteps  | 152510   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.18e-05 |
|    n_updates        | 28127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.0692   |
|    exploration_rate | 0.41     |
| time/               |          |
|    episodes         | 8156     |
|    fps              | 34       |
|    time_elapsed     | 4384     |
|    total_timesteps  | 152613   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.58e-05 |
|    n_updates        | 28153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0682   |
|    exploration_rate | 0.409    |
| time/               |          |
|    episodes         | 8160     |
|    fps              | 34       |
|    time_elapsed     | 4385     |
|    total_timesteps  | 152718   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.5e-05  |
|    n_updates        | 28179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0676   |
|    exploration_rate | 0.409    |
| time/               |          |
|    episodes         | 8164     |
|    fps              | 34       |
|    time_elapsed     | 4385     |
|    total_timesteps  | 152813   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.06e-05 |
|    n_updates        | 28203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0776   |
|    exploration_rate | 0.408    |
| time/               |          |
|    episodes         | 8168     |
|    fps              | 34       |
|    time_elapsed     | 4386     |
|    total_timesteps  | 152897   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.41e-05 |
|    n_updates        | 28224    |
----------------------------------
Eval num_timesteps=153000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.407    |
| time/               |          |
|    total_timesteps  | 153000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.64e-05 |
|    n_updates        | 28249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | 0.0764   |
|    exploration_rate | 0.407    |
| time/               |          |
|    episodes         | 8172     |
|    fps              | 34       |
|    time_elapsed     | 4398     |
|    total_timesteps  | 153009   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000124 |
|    n_updates        | 28252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | 0.0857   |
|    exploration_rate | 0.406    |
| time/               |          |
|    episodes         | 8176     |
|    fps              | 34       |
|    time_elapsed     | 4399     |
|    total_timesteps  | 153112   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00788  |
|    n_updates        | 28277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | 0.0855   |
|    exploration_rate | 0.406    |
| time/               |          |
|    episodes         | 8180     |
|    fps              | 34       |
|    time_elapsed     | 4399     |
|    total_timesteps  | 153191   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.32e-05 |
|    n_updates        | 28297    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0874   |
|    exploration_rate | 0.405    |
| time/               |          |
|    episodes         | 8184     |
|    fps              | 34       |
|    time_elapsed     | 4400     |
|    total_timesteps  | 153251   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.22e-05 |
|    n_updates        | 28312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | 0.0856   |
|    exploration_rate | 0.404    |
| time/               |          |
|    episodes         | 8188     |
|    fps              | 34       |
|    time_elapsed     | 4400     |
|    total_timesteps  | 153364   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.06e-05 |
|    n_updates        | 28340    |
----------------------------------
Eval num_timesteps=153500, episode_reward=-0.28 +/- 0.17
Episode length: 73.82 +/- 8.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.275   |
| rollout/            |          |
|    exploration_rate | 0.403    |
| time/               |          |
|    total_timesteps  | 153500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.29e-05 |
|    n_updates        | 28374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.2     |
|    ep_rew_mean      | 0.0824   |
|    exploration_rate | 0.403    |
| time/               |          |
|    episodes         | 8192     |
|    fps              | 34       |
|    time_elapsed     | 4414     |
|    total_timesteps  | 153516   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 28378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.8     |
|    ep_rew_mean      | 0.0701   |
|    exploration_rate | 0.402    |
| time/               |          |
|    episodes         | 8196     |
|    fps              | 34       |
|    time_elapsed     | 4415     |
|    total_timesteps  | 153643   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000201 |
|    n_updates        | 28410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.8     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.401    |
| time/               |          |
|    episodes         | 8200     |
|    fps              | 34       |
|    time_elapsed     | 4416     |
|    total_timesteps  | 153722   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.84e-05 |
|    n_updates        | 28430    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | 0.0597   |
|    exploration_rate | 0.401    |
| time/               |          |
|    episodes         | 8204     |
|    fps              | 34       |
|    time_elapsed     | 4416     |
|    total_timesteps  | 153804   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00773  |
|    n_updates        | 28450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.8     |
|    ep_rew_mean      | 0.0601   |
|    exploration_rate | 0.4      |
| time/               |          |
|    episodes         | 8208     |
|    fps              | 34       |
|    time_elapsed     | 4417     |
|    total_timesteps  | 153886   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.68e-05 |
|    n_updates        | 28471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23       |
|    ep_rew_mean      | 0.049    |
|    exploration_rate | 0.399    |
| time/               |          |
|    episodes         | 8212     |
|    fps              | 34       |
|    time_elapsed     | 4417     |
|    total_timesteps  | 153985   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00693  |
|    n_updates        | 28496    |
----------------------------------
Eval num_timesteps=154000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.399    |
| time/               |          |
|    total_timesteps  | 154000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.8e-05  |
|    n_updates        | 28499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.3     |
|    ep_rew_mean      | 0.048    |
|    exploration_rate | 0.399    |
| time/               |          |
|    episodes         | 8216     |
|    fps              | 34       |
|    time_elapsed     | 4433     |
|    total_timesteps  | 154084   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.55e-05 |
|    n_updates        | 28520    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | 0.0473   |
|    exploration_rate | 0.398    |
| time/               |          |
|    episodes         | 8220     |
|    fps              | 34       |
|    time_elapsed     | 4433     |
|    total_timesteps  | 154182   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.54e-05 |
|    n_updates        | 28545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.2     |
|    ep_rew_mean      | 0.0581   |
|    exploration_rate | 0.397    |
| time/               |          |
|    episodes         | 8224     |
|    fps              | 34       |
|    time_elapsed     | 4434     |
|    total_timesteps  | 154244   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.2e-05  |
|    n_updates        | 28560    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | 0.0594   |
|    exploration_rate | 0.397    |
| time/               |          |
|    episodes         | 8228     |
|    fps              | 34       |
|    time_elapsed     | 4434     |
|    total_timesteps  | 154309   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 28577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23       |
|    ep_rew_mean      | 0.0592   |
|    exploration_rate | 0.396    |
| time/               |          |
|    episodes         | 8232     |
|    fps              | 34       |
|    time_elapsed     | 4434     |
|    total_timesteps  | 154402   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0145   |
|    n_updates        | 28600    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 0.395    |
| time/               |          |
|    episodes         | 8236     |
|    fps              | 34       |
|    time_elapsed     | 4435     |
|    total_timesteps  | 154480   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 28619    |
----------------------------------
Eval num_timesteps=154500, episode_reward=-0.09 +/- 0.26
Episode length: 38.96 +/- 20.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39       |
|    mean_reward      | -0.0949  |
| rollout/            |          |
|    exploration_rate | 0.395    |
| time/               |          |
|    total_timesteps  | 154500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000105 |
|    n_updates        | 28624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | 0.0487   |
|    exploration_rate | 0.395    |
| time/               |          |
|    episodes         | 8240     |
|    fps              | 34       |
|    time_elapsed     | 4444     |
|    total_timesteps  | 154556   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.65e-05 |
|    n_updates        | 28638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | 0.0487   |
|    exploration_rate | 0.394    |
| time/               |          |
|    episodes         | 8244     |
|    fps              | 34       |
|    time_elapsed     | 4445     |
|    total_timesteps  | 154634   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0155   |
|    n_updates        | 28658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 0.394    |
| time/               |          |
|    episodes         | 8248     |
|    fps              | 34       |
|    time_elapsed     | 4445     |
|    total_timesteps  | 154710   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.26e-05 |
|    n_updates        | 28677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.8     |
|    ep_rew_mean      | 0.0499   |
|    exploration_rate | 0.393    |
| time/               |          |
|    episodes         | 8252     |
|    fps              | 34       |
|    time_elapsed     | 4446     |
|    total_timesteps  | 154789   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 28697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.6     |
|    ep_rew_mean      | 0.0207   |
|    exploration_rate | 0.392    |
| time/               |          |
|    episodes         | 8256     |
|    fps              | 34       |
|    time_elapsed     | 4446     |
|    total_timesteps  | 154871   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.27e-05 |
|    n_updates        | 28717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.3     |
|    ep_rew_mean      | 0.012    |
|    exploration_rate | 0.392    |
| time/               |          |
|    episodes         | 8260     |
|    fps              | 34       |
|    time_elapsed     | 4447     |
|    total_timesteps  | 154944   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.91e-05 |
|    n_updates        | 28735    |
----------------------------------
Eval num_timesteps=155000, episode_reward=-0.11 +/- 0.23
Episode length: 37.60 +/- 25.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 37.6     |
|    mean_reward      | -0.11    |
| rollout/            |          |
|    exploration_rate | 0.391    |
| time/               |          |
|    total_timesteps  | 155000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.61e-05 |
|    n_updates        | 28749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22       |
|    ep_rew_mean      | 0.0131   |
|    exploration_rate | 0.391    |
| time/               |          |
|    episodes         | 8264     |
|    fps              | 34       |
|    time_elapsed     | 4455     |
|    total_timesteps  | 155010   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.44e-05 |
|    n_updates        | 28752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | 0.0132   |
|    exploration_rate | 0.391    |
| time/               |          |
|    episodes         | 8268     |
|    fps              | 34       |
|    time_elapsed     | 4455     |
|    total_timesteps  | 155092   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000145 |
|    n_updates        | 28772    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.39     |
| time/               |          |
|    episodes         | 8272     |
|    fps              | 34       |
|    time_elapsed     | 4456     |
|    total_timesteps  | 155170   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.72e-05 |
|    n_updates        | 28792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | 0.0155   |
|    exploration_rate | 0.389    |
| time/               |          |
|    episodes         | 8276     |
|    fps              | 34       |
|    time_elapsed     | 4456     |
|    total_timesteps  | 155251   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 28812    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.389    |
| time/               |          |
|    episodes         | 8280     |
|    fps              | 34       |
|    time_elapsed     | 4457     |
|    total_timesteps  | 155319   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 28829    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.0345   |
|    exploration_rate | 0.388    |
| time/               |          |
|    episodes         | 8284     |
|    fps              | 34       |
|    time_elapsed     | 4457     |
|    total_timesteps  | 155414   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00696  |
|    n_updates        | 28853    |
----------------------------------
Eval num_timesteps=155500, episode_reward=-0.27 +/- 0.05
Episode length: 67.80 +/- 12.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.8     |
|    mean_reward      | -0.271   |
| rollout/            |          |
|    exploration_rate | 0.387    |
| time/               |          |
|    total_timesteps  | 155500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000108 |
|    n_updates        | 28874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | 0.0354   |
|    exploration_rate | 0.387    |
| time/               |          |
|    episodes         | 8288     |
|    fps              | 34       |
|    time_elapsed     | 4469     |
|    total_timesteps  | 155506   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.62e-05 |
|    n_updates        | 28876    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.387    |
| time/               |          |
|    episodes         | 8292     |
|    fps              | 34       |
|    time_elapsed     | 4469     |
|    total_timesteps  | 155595   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.44e-05 |
|    n_updates        | 28898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.386    |
| time/               |          |
|    episodes         | 8296     |
|    fps              | 34       |
|    time_elapsed     | 4470     |
|    total_timesteps  | 155668   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00014  |
|    n_updates        | 28916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0283   |
|    exploration_rate | 0.385    |
| time/               |          |
|    episodes         | 8300     |
|    fps              | 34       |
|    time_elapsed     | 4471     |
|    total_timesteps  | 155789   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 28947    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.384    |
| time/               |          |
|    episodes         | 8304     |
|    fps              | 34       |
|    time_elapsed     | 4471     |
|    total_timesteps  | 155878   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00687  |
|    n_updates        | 28969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.384    |
| time/               |          |
|    episodes         | 8308     |
|    fps              | 34       |
|    time_elapsed     | 4471     |
|    total_timesteps  | 155964   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.44e-05 |
|    n_updates        | 28990    |
----------------------------------
Eval num_timesteps=156000, episode_reward=-0.05 +/- 0.14
Episode length: 18.10 +/- 0.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.1     |
|    mean_reward      | -0.0514  |
| rollout/            |          |
|    exploration_rate | 0.383    |
| time/               |          |
|    total_timesteps  | 156000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.92e-05 |
|    n_updates        | 28999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.5     |
|    ep_rew_mean      | 0.049    |
|    exploration_rate | 0.383    |
| time/               |          |
|    episodes         | 8312     |
|    fps              | 34       |
|    time_elapsed     | 4476     |
|    total_timesteps  | 156036   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.74e-05 |
|    n_updates        | 29008    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | 0.0494   |
|    exploration_rate | 0.382    |
| time/               |          |
|    episodes         | 8316     |
|    fps              | 34       |
|    time_elapsed     | 4477     |
|    total_timesteps  | 156125   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00744  |
|    n_updates        | 29031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0506   |
|    exploration_rate | 0.382    |
| time/               |          |
|    episodes         | 8320     |
|    fps              | 34       |
|    time_elapsed     | 4477     |
|    total_timesteps  | 156192   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.31e-05 |
|    n_updates        | 29047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.381    |
| time/               |          |
|    episodes         | 8324     |
|    fps              | 34       |
|    time_elapsed     | 4478     |
|    total_timesteps  | 156324   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.26e-05 |
|    n_updates        | 29080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 0.38     |
| time/               |          |
|    episodes         | 8328     |
|    fps              | 34       |
|    time_elapsed     | 4478     |
|    total_timesteps  | 156410   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.95e-05 |
|    n_updates        | 29102    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.0483   |
|    exploration_rate | 0.38     |
| time/               |          |
|    episodes         | 8332     |
|    fps              | 34       |
|    time_elapsed     | 4479     |
|    total_timesteps  | 156471   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.05e-05 |
|    n_updates        | 29117    |
----------------------------------
Eval num_timesteps=156500, episode_reward=-0.03 +/- 0.25
Episode length: 22.94 +/- 15.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22.9     |
|    mean_reward      | -0.0309  |
| rollout/            |          |
|    exploration_rate | 0.379    |
| time/               |          |
|    total_timesteps  | 156500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00707  |
|    n_updates        | 29124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | 0.0587   |
|    exploration_rate | 0.379    |
| time/               |          |
|    episodes         | 8336     |
|    fps              | 34       |
|    time_elapsed     | 4484     |
|    total_timesteps  | 156539   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.62e-05 |
|    n_updates        | 29134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.0478   |
|    exploration_rate | 0.378    |
| time/               |          |
|    episodes         | 8340     |
|    fps              | 34       |
|    time_elapsed     | 4485     |
|    total_timesteps  | 156636   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.99e-05 |
|    n_updates        | 29158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | 0.0375   |
|    exploration_rate | 0.378    |
| time/               |          |
|    episodes         | 8344     |
|    fps              | 34       |
|    time_elapsed     | 4485     |
|    total_timesteps  | 156723   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00701  |
|    n_updates        | 29180    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.0371   |
|    exploration_rate | 0.377    |
| time/               |          |
|    episodes         | 8348     |
|    fps              | 34       |
|    time_elapsed     | 4486     |
|    total_timesteps  | 156808   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.01e-05 |
|    n_updates        | 29201    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.027    |
|    exploration_rate | 0.376    |
| time/               |          |
|    episodes         | 8352     |
|    fps              | 34       |
|    time_elapsed     | 4486     |
|    total_timesteps  | 156889   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00764  |
|    n_updates        | 29222    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | 0.037    |
|    exploration_rate | 0.376    |
| time/               |          |
|    episodes         | 8356     |
|    fps              | 34       |
|    time_elapsed     | 4487     |
|    total_timesteps  | 156972   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00704  |
|    n_updates        | 29242    |
----------------------------------
Eval num_timesteps=157000, episode_reward=-0.00 +/- 0.40
Episode length: 40.88 +/- 22.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.9     |
|    mean_reward      | -0.00266 |
| rollout/            |          |
|    exploration_rate | 0.375    |
| time/               |          |
|    total_timesteps  | 157000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00701  |
|    n_updates        | 29249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | 0.0354   |
|    exploration_rate | 0.375    |
| time/               |          |
|    episodes         | 8360     |
|    fps              | 34       |
|    time_elapsed     | 4496     |
|    total_timesteps  | 157085   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.02e-05 |
|    n_updates        | 29271    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | 0.0342   |
|    exploration_rate | 0.374    |
| time/               |          |
|    episodes         | 8364     |
|    fps              | 34       |
|    time_elapsed     | 4497     |
|    total_timesteps  | 157181   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.04e-05 |
|    n_updates        | 29295    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | 0.0244   |
|    exploration_rate | 0.373    |
| time/               |          |
|    episodes         | 8368     |
|    fps              | 34       |
|    time_elapsed     | 4497     |
|    total_timesteps  | 157258   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.47e-05 |
|    n_updates        | 29314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | 0.0233   |
|    exploration_rate | 0.372    |
| time/               |          |
|    episodes         | 8372     |
|    fps              | 34       |
|    time_elapsed     | 4498     |
|    total_timesteps  | 157364   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.99e-05 |
|    n_updates        | 29340    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | 0.0133   |
|    exploration_rate | 0.372    |
| time/               |          |
|    episodes         | 8376     |
|    fps              | 34       |
|    time_elapsed     | 4498     |
|    total_timesteps  | 157443   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000128 |
|    n_updates        | 29360    |
----------------------------------
Eval num_timesteps=157500, episode_reward=-0.28 +/- 0.04
Episode length: 69.88 +/- 9.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.9     |
|    mean_reward      | -0.279   |
| rollout/            |          |
|    exploration_rate | 0.371    |
| time/               |          |
|    total_timesteps  | 157500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.54e-05 |
|    n_updates        | 29374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.2     |
|    ep_rew_mean      | 0.00226  |
|    exploration_rate | 0.371    |
| time/               |          |
|    episodes         | 8380     |
|    fps              | 34       |
|    time_elapsed     | 4513     |
|    total_timesteps  | 157538   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.84e-05 |
|    n_updates        | 29384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | 0.0133   |
|    exploration_rate | 0.37     |
| time/               |          |
|    episodes         | 8384     |
|    fps              | 34       |
|    time_elapsed     | 4514     |
|    total_timesteps  | 157606   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.04e-05 |
|    n_updates        | 29401    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.37     |
| time/               |          |
|    episodes         | 8388     |
|    fps              | 34       |
|    time_elapsed     | 4514     |
|    total_timesteps  | 157683   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.48e-05 |
|    n_updates        | 29420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.0145   |
|    exploration_rate | 0.369    |
| time/               |          |
|    episodes         | 8392     |
|    fps              | 34       |
|    time_elapsed     | 4514     |
|    total_timesteps  | 157758   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.32e-05 |
|    n_updates        | 29439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | 0.0247   |
|    exploration_rate | 0.369    |
| time/               |          |
|    episodes         | 8396     |
|    fps              | 34       |
|    time_elapsed     | 4515     |
|    total_timesteps  | 157825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00777  |
|    n_updates        | 29456    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | 0.0158   |
|    exploration_rate | 0.368    |
| time/               |          |
|    episodes         | 8400     |
|    fps              | 34       |
|    time_elapsed     | 4515     |
|    total_timesteps  | 157918   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.74e-05 |
|    n_updates        | 29479    |
----------------------------------
Eval num_timesteps=158000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.367    |
| time/               |          |
|    total_timesteps  | 158000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.48e-05 |
|    n_updates        | 29499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | 0.0154   |
|    exploration_rate | 0.367    |
| time/               |          |
|    episodes         | 8404     |
|    fps              | 34       |
|    time_elapsed     | 4532     |
|    total_timesteps  | 158017   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000136 |
|    n_updates        | 29504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.00448 |
|    exploration_rate | 0.366    |
| time/               |          |
|    episodes         | 8408     |
|    fps              | 34       |
|    time_elapsed     | 4532     |
|    total_timesteps  | 158101   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.21e-05 |
|    n_updates        | 29525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.366    |
| time/               |          |
|    episodes         | 8412     |
|    fps              | 34       |
|    time_elapsed     | 4533     |
|    total_timesteps  | 158173   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.57e-05 |
|    n_updates        | 29543    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.014   |
|    exploration_rate | 0.365    |
| time/               |          |
|    episodes         | 8416     |
|    fps              | 34       |
|    time_elapsed     | 4533     |
|    total_timesteps  | 158250   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00778  |
|    n_updates        | 29562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 0.365    |
| time/               |          |
|    episodes         | 8420     |
|    fps              | 34       |
|    time_elapsed     | 4533     |
|    total_timesteps  | 158324   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.58e-05 |
|    n_updates        | 29580    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.364    |
| time/               |          |
|    episodes         | 8424     |
|    fps              | 34       |
|    time_elapsed     | 4534     |
|    total_timesteps  | 158405   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000119 |
|    n_updates        | 29601    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.363    |
| time/               |          |
|    episodes         | 8428     |
|    fps              | 34       |
|    time_elapsed     | 4534     |
|    total_timesteps  | 158499   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000119 |
|    n_updates        | 29624    |
----------------------------------
Eval num_timesteps=158500, episode_reward=0.03 +/- 0.30
Episode length: 17.30 +/- 0.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 17.3     |
|    mean_reward     | 0.0318   |
| time/              |          |
|    total_timesteps | 158500   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.363    |
| time/               |          |
|    episodes         | 8432     |
|    fps              | 34       |
|    time_elapsed     | 4539     |
|    total_timesteps  | 158583   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.59e-05 |
|    n_updates        | 29645    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0443  |
|    exploration_rate | 0.362    |
| time/               |          |
|    episodes         | 8436     |
|    fps              | 34       |
|    time_elapsed     | 4540     |
|    total_timesteps  | 158670   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.84e-05 |
|    n_updates        | 29667    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0348  |
|    exploration_rate | 0.361    |
| time/               |          |
|    episodes         | 8440     |
|    fps              | 34       |
|    time_elapsed     | 4541     |
|    total_timesteps  | 158781   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.55e-05 |
|    n_updates        | 29695    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0342  |
|    exploration_rate | 0.36     |
| time/               |          |
|    episodes         | 8444     |
|    fps              | 34       |
|    time_elapsed     | 4541     |
|    total_timesteps  | 158852   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.84e-05 |
|    n_updates        | 29712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.36     |
| time/               |          |
|    episodes         | 8448     |
|    fps              | 34       |
|    time_elapsed     | 4542     |
|    total_timesteps  | 158950   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.32e-05 |
|    n_updates        | 29737    |
----------------------------------
Eval num_timesteps=159000, episode_reward=-0.22 +/- 0.28
Episode length: 70.42 +/- 13.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.4     |
|    mean_reward      | -0.221   |
| rollout/            |          |
|    exploration_rate | 0.359    |
| time/               |          |
|    total_timesteps  | 159000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.94e-05 |
|    n_updates        | 29749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.5     |
|    ep_rew_mean      | -0.0349  |
|    exploration_rate | 0.359    |
| time/               |          |
|    episodes         | 8452     |
|    fps              | 34       |
|    time_elapsed     | 4557     |
|    total_timesteps  | 159036   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00692  |
|    n_updates        | 29758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.5     |
|    ep_rew_mean      | -0.0449  |
|    exploration_rate | 0.358    |
| time/               |          |
|    episodes         | 8456     |
|    fps              | 34       |
|    time_elapsed     | 4558     |
|    total_timesteps  | 159120   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00706  |
|    n_updates        | 29779    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 0.357    |
| time/               |          |
|    episodes         | 8460     |
|    fps              | 34       |
|    time_elapsed     | 4558     |
|    total_timesteps  | 159221   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.37e-05 |
|    n_updates        | 29805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0336  |
|    exploration_rate | 0.357    |
| time/               |          |
|    episodes         | 8464     |
|    fps              | 34       |
|    time_elapsed     | 4559     |
|    total_timesteps  | 159297   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00697  |
|    n_updates        | 29824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.356    |
| time/               |          |
|    episodes         | 8468     |
|    fps              | 34       |
|    time_elapsed     | 4559     |
|    total_timesteps  | 159371   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.78e-05 |
|    n_updates        | 29842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0322  |
|    exploration_rate | 0.356    |
| time/               |          |
|    episodes         | 8472     |
|    fps              | 34       |
|    time_elapsed     | 4560     |
|    total_timesteps  | 159445   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.29e-05 |
|    n_updates        | 29861    |
----------------------------------
Eval num_timesteps=159500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.355    |
| time/               |          |
|    total_timesteps  | 159500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0147   |
|    n_updates        | 29874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.355    |
| time/               |          |
|    episodes         | 8476     |
|    fps              | 34       |
|    time_elapsed     | 4572     |
|    total_timesteps  | 159539   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0068   |
|    n_updates        | 29884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0239  |
|    exploration_rate | 0.354    |
| time/               |          |
|    episodes         | 8480     |
|    fps              | 34       |
|    time_elapsed     | 4573     |
|    total_timesteps  | 159660   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.99e-05 |
|    n_updates        | 29914    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0443  |
|    exploration_rate | 0.353    |
| time/               |          |
|    episodes         | 8484     |
|    fps              | 34       |
|    time_elapsed     | 4573     |
|    total_timesteps  | 159740   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.8e-05  |
|    n_updates        | 29934    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0445  |
|    exploration_rate | 0.353    |
| time/               |          |
|    episodes         | 8488     |
|    fps              | 34       |
|    time_elapsed     | 4574     |
|    total_timesteps  | 159822   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 29955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0447  |
|    exploration_rate | 0.352    |
| time/               |          |
|    episodes         | 8492     |
|    fps              | 34       |
|    time_elapsed     | 4574     |
|    total_timesteps  | 159900   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.68e-05 |
|    n_updates        | 29974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.5     |
|    ep_rew_mean      | -0.0449  |
|    exploration_rate | 0.351    |
| time/               |          |
|    episodes         | 8496     |
|    fps              | 34       |
|    time_elapsed     | 4575     |
|    total_timesteps  | 159972   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00765  |
|    n_updates        | 29992    |
----------------------------------
Eval num_timesteps=160000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.351    |
| time/               |          |
|    total_timesteps  | 160000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.02e-05 |
|    n_updates        | 29999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | -0.0456  |
|    exploration_rate | 0.35     |
| time/               |          |
|    episodes         | 8500     |
|    fps              | 34       |
|    time_elapsed     | 4590     |
|    total_timesteps  | 160083   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.97e-05 |
|    n_updates        | 30020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.35     |
| time/               |          |
|    episodes         | 8504     |
|    fps              | 34       |
|    time_elapsed     | 4591     |
|    total_timesteps  | 160191   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2e-05    |
|    n_updates        | 30047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.0357  |
|    exploration_rate | 0.349    |
| time/               |          |
|    episodes         | 8508     |
|    fps              | 34       |
|    time_elapsed     | 4591     |
|    total_timesteps  | 160269   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.25e-05 |
|    n_updates        | 30067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.0258  |
|    exploration_rate | 0.348    |
| time/               |          |
|    episodes         | 8512     |
|    fps              | 34       |
|    time_elapsed     | 4592     |
|    total_timesteps  | 160344   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000123 |
|    n_updates        | 30085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | -0.0268  |
|    exploration_rate | 0.348    |
| time/               |          |
|    episodes         | 8516     |
|    fps              | 34       |
|    time_elapsed     | 4592     |
|    total_timesteps  | 160444   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.92e-05 |
|    n_updates        | 30110    |
----------------------------------
Eval num_timesteps=160500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.347    |
| time/               |          |
|    total_timesteps  | 160500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.42e-05 |
|    n_updates        | 30124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.4     |
|    ep_rew_mean      | -0.0185  |
|    exploration_rate | 0.347    |
| time/               |          |
|    episodes         | 8520     |
|    fps              | 34       |
|    time_elapsed     | 4605     |
|    total_timesteps  | 160561   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.83e-05 |
|    n_updates        | 30140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.6     |
|    ep_rew_mean      | -0.0194  |
|    exploration_rate | 0.346    |
| time/               |          |
|    episodes         | 8524     |
|    fps              | 34       |
|    time_elapsed     | 4605     |
|    total_timesteps  | 160664   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00774  |
|    n_updates        | 30165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 0.345    |
| time/               |          |
|    episodes         | 8528     |
|    fps              | 34       |
|    time_elapsed     | 4606     |
|    total_timesteps  | 160753   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.88e-05 |
|    n_updates        | 30188    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | -0.019   |
|    exploration_rate | 0.344    |
| time/               |          |
|    episodes         | 8532     |
|    fps              | 34       |
|    time_elapsed     | 4606     |
|    total_timesteps  | 160834   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00711  |
|    n_updates        | 30208    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.3     |
|    ep_rew_mean      | -0.0184  |
|    exploration_rate | 0.344    |
| time/               |          |
|    episodes         | 8536     |
|    fps              | 34       |
|    time_elapsed     | 4607     |
|    total_timesteps  | 160904   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.36e-05 |
|    n_updates        | 30225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | -0.00648 |
|    exploration_rate | 0.343    |
| time/               |          |
|    episodes         | 8540     |
|    fps              | 34       |
|    time_elapsed     | 4607     |
|    total_timesteps  | 160967   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000104 |
|    n_updates        | 30241    |
----------------------------------
Eval num_timesteps=161000, episode_reward=0.07 +/- 0.35
Episode length: 16.80 +/- 0.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.8     |
|    mean_reward      | 0.0739   |
| rollout/            |          |
|    exploration_rate | 0.343    |
| time/               |          |
|    total_timesteps  | 161000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000119 |
|    n_updates        | 30249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | 0.00383  |
|    exploration_rate | 0.343    |
| time/               |          |
|    episodes         | 8544     |
|    fps              | 34       |
|    time_elapsed     | 4612     |
|    total_timesteps  | 161030   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.2e-05  |
|    n_updates        | 30257    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | 0.00363  |
|    exploration_rate | 0.342    |
| time/               |          |
|    episodes         | 8548     |
|    fps              | 34       |
|    time_elapsed     | 4612     |
|    total_timesteps  | 161133   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.7e-05  |
|    n_updates        | 30283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.1     |
|    ep_rew_mean      | 0.00239  |
|    exploration_rate | 0.341    |
| time/               |          |
|    episodes         | 8552     |
|    fps              | 34       |
|    time_elapsed     | 4613     |
|    total_timesteps  | 161250   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000137 |
|    n_updates        | 30312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | 0.00095  |
|    exploration_rate | 0.34     |
| time/               |          |
|    episodes         | 8556     |
|    fps              | 34       |
|    time_elapsed     | 4613     |
|    total_timesteps  | 161370   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000209 |
|    n_updates        | 30342    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.3     |
|    ep_rew_mean      | -0.00842 |
|    exploration_rate | 0.339    |
| time/               |          |
|    episodes         | 8560     |
|    fps              | 34       |
|    time_elapsed     | 4614     |
|    total_timesteps  | 161455   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00786  |
|    n_updates        | 30363    |
----------------------------------
Eval num_timesteps=161500, episode_reward=-0.28 +/- 0.05
Episode length: 70.86 +/- 13.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.9     |
|    mean_reward      | -0.283   |
| rollout/            |          |
|    exploration_rate | 0.339    |
| time/               |          |
|    total_timesteps  | 161500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0148   |
|    n_updates        | 30374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.3     |
|    ep_rew_mean      | 0.00169  |
|    exploration_rate | 0.339    |
| time/               |          |
|    episodes         | 8564     |
|    fps              | 34       |
|    time_elapsed     | 4626     |
|    total_timesteps  | 161528   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.8e-05  |
|    n_updates        | 30381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 0.338    |
| time/               |          |
|    episodes         | 8568     |
|    fps              | 34       |
|    time_elapsed     | 4626     |
|    total_timesteps  | 161622   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.41e-05 |
|    n_updates        | 30405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | 0.0108   |
|    exploration_rate | 0.337    |
| time/               |          |
|    episodes         | 8572     |
|    fps              | 34       |
|    time_elapsed     | 4627     |
|    total_timesteps  | 161698   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000102 |
|    n_updates        | 30424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.4     |
|    ep_rew_mean      | 0.0313   |
|    exploration_rate | 0.337    |
| time/               |          |
|    episodes         | 8576     |
|    fps              | 34       |
|    time_elapsed     | 4627     |
|    total_timesteps  | 161781   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.44e-05 |
|    n_updates        | 30445    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.4     |
|    ep_rew_mean      | 0.0413   |
|    exploration_rate | 0.336    |
| time/               |          |
|    episodes         | 8580     |
|    fps              | 34       |
|    time_elapsed     | 4628     |
|    total_timesteps  | 161902   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 30475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | 0.0408   |
|    exploration_rate | 0.335    |
| time/               |          |
|    episodes         | 8584     |
|    fps              | 34       |
|    time_elapsed     | 4629     |
|    total_timesteps  | 161994   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00689  |
|    n_updates        | 30498    |
----------------------------------
Eval num_timesteps=162000, episode_reward=-0.15 +/- 0.08
Episode length: 38.42 +/- 20.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.4     |
|    mean_reward      | -0.153   |
| rollout/            |          |
|    exploration_rate | 0.335    |
| time/               |          |
|    total_timesteps  | 162000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00707  |
|    n_updates        | 30499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23       |
|    ep_rew_mean      | 0.0391   |
|    exploration_rate | 0.334    |
| time/               |          |
|    episodes         | 8588     |
|    fps              | 34       |
|    time_elapsed     | 4638     |
|    total_timesteps  | 162120   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.7e-05  |
|    n_updates        | 30529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | 0.0384   |
|    exploration_rate | 0.333    |
| time/               |          |
|    episodes         | 8592     |
|    fps              | 34       |
|    time_elapsed     | 4638     |
|    total_timesteps  | 162215   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.68e-05 |
|    n_updates        | 30553    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | 0.0275   |
|    exploration_rate | 0.332    |
| time/               |          |
|    episodes         | 8596     |
|    fps              | 34       |
|    time_elapsed     | 4639     |
|    total_timesteps  | 162310   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.74e-05 |
|    n_updates        | 30577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.2     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.332    |
| time/               |          |
|    episodes         | 8600     |
|    fps              | 35       |
|    time_elapsed     | 4639     |
|    total_timesteps  | 162401   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00695  |
|    n_updates        | 30600    |
----------------------------------
Eval num_timesteps=162500, episode_reward=-0.10 +/- 0.40
Episode length: 58.96 +/- 22.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59       |
|    mean_reward      | -0.0953  |
| rollout/            |          |
|    exploration_rate | 0.331    |
| time/               |          |
|    total_timesteps  | 162500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.93e-05 |
|    n_updates        | 30624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | 0.0284   |
|    exploration_rate | 0.331    |
| time/               |          |
|    episodes         | 8604     |
|    fps              | 34       |
|    time_elapsed     | 4652     |
|    total_timesteps  | 162506   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.39e-05 |
|    n_updates        | 30626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.2     |
|    ep_rew_mean      | 0.0281   |
|    exploration_rate | 0.33     |
| time/               |          |
|    episodes         | 8608     |
|    fps              | 34       |
|    time_elapsed     | 4652     |
|    total_timesteps  | 162592   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0071   |
|    n_updates        | 30647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.329    |
| time/               |          |
|    episodes         | 8612     |
|    fps              | 34       |
|    time_elapsed     | 4653     |
|    total_timesteps  | 162684   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.93e-05 |
|    n_updates        | 30670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.6     |
|    ep_rew_mean      | 0.0168   |
|    exploration_rate | 0.328    |
| time/               |          |
|    episodes         | 8616     |
|    fps              | 34       |
|    time_elapsed     | 4654     |
|    total_timesteps  | 162799   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00716  |
|    n_updates        | 30699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | 0.0187   |
|    exploration_rate | 0.328    |
| time/               |          |
|    episodes         | 8620     |
|    fps              | 34       |
|    time_elapsed     | 4654     |
|    total_timesteps  | 162869   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.92e-05 |
|    n_updates        | 30717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 0.327    |
| time/               |          |
|    episodes         | 8624     |
|    fps              | 35       |
|    time_elapsed     | 4655     |
|    total_timesteps  | 162953   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.83e-05 |
|    n_updates        | 30738    |
----------------------------------
Eval num_timesteps=163000, episode_reward=-0.01 +/- 0.24
Episode length: 18.32 +/- 8.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.3     |
|    mean_reward      | -0.0123  |
| rollout/            |          |
|    exploration_rate | 0.327    |
| time/               |          |
|    total_timesteps  | 163000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.93e-05 |
|    n_updates        | 30749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | 0.0196   |
|    exploration_rate | 0.326    |
| time/               |          |
|    episodes         | 8628     |
|    fps              | 34       |
|    time_elapsed     | 4660     |
|    total_timesteps  | 163038   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.75e-05 |
|    n_updates        | 30759    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.8     |
|    ep_rew_mean      | 0.0198   |
|    exploration_rate | 0.326    |
| time/               |          |
|    episodes         | 8632     |
|    fps              | 34       |
|    time_elapsed     | 4660     |
|    total_timesteps  | 163113   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000142 |
|    n_updates        | 30778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | 0.0194   |
|    exploration_rate | 0.325    |
| time/               |          |
|    episodes         | 8636     |
|    fps              | 35       |
|    time_elapsed     | 4661     |
|    total_timesteps  | 163194   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 30798    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | 0.0186   |
|    exploration_rate | 0.324    |
| time/               |          |
|    episodes         | 8640     |
|    fps              | 35       |
|    time_elapsed     | 4661     |
|    total_timesteps  | 163278   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.82e-05 |
|    n_updates        | 30819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.8     |
|    ep_rew_mean      | 0.00572  |
|    exploration_rate | 0.323    |
| time/               |          |
|    episodes         | 8644     |
|    fps              | 35       |
|    time_elapsed     | 4662     |
|    total_timesteps  | 163413   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000128 |
|    n_updates        | 30853    |
----------------------------------
Eval num_timesteps=163500, episode_reward=-0.09 +/- 0.27
Episode length: 36.80 +/- 21.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36.8     |
|    mean_reward      | -0.0862  |
| rollout/            |          |
|    exploration_rate | 0.323    |
| time/               |          |
|    total_timesteps  | 163500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.66e-05 |
|    n_updates        | 30874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.323    |
| time/               |          |
|    episodes         | 8648     |
|    fps              | 35       |
|    time_elapsed     | 4670     |
|    total_timesteps  | 163502   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.97e-05 |
|    n_updates        | 30875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.322    |
| time/               |          |
|    episodes         | 8652     |
|    fps              | 35       |
|    time_elapsed     | 4671     |
|    total_timesteps  | 163602   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 30900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.3     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.321    |
| time/               |          |
|    episodes         | 8656     |
|    fps              | 35       |
|    time_elapsed     | 4671     |
|    total_timesteps  | 163703   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000121 |
|    n_updates        | 30925    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | 0.0272   |
|    exploration_rate | 0.32     |
| time/               |          |
|    episodes         | 8660     |
|    fps              | 35       |
|    time_elapsed     | 4672     |
|    total_timesteps  | 163801   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.09e-05 |
|    n_updates        | 30950    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.319    |
| time/               |          |
|    episodes         | 8664     |
|    fps              | 35       |
|    time_elapsed     | 4672     |
|    total_timesteps  | 163872   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.59e-05 |
|    n_updates        | 30967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | 0.00734  |
|    exploration_rate | 0.319    |
| time/               |          |
|    episodes         | 8668     |
|    fps              | 35       |
|    time_elapsed     | 4673     |
|    total_timesteps  | 163965   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.19e-05 |
|    n_updates        | 30991    |
----------------------------------
Eval num_timesteps=164000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.318    |
| time/               |          |
|    total_timesteps  | 164000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 30999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | 0.0045   |
|    exploration_rate | 0.317    |
| time/               |          |
|    episodes         | 8672     |
|    fps              | 34       |
|    time_elapsed     | 4691     |
|    total_timesteps  | 164112   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0067   |
|    n_updates        | 31027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.2     |
|    ep_rew_mean      | -0.0159  |
|    exploration_rate | 0.317    |
| time/               |          |
|    episodes         | 8676     |
|    fps              | 34       |
|    time_elapsed     | 4691     |
|    total_timesteps  | 164206   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.2e-05  |
|    n_updates        | 31051    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.00394 |
|    exploration_rate | 0.316    |
| time/               |          |
|    episodes         | 8680     |
|    fps              | 35       |
|    time_elapsed     | 4692     |
|    total_timesteps  | 164276   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00776  |
|    n_updates        | 31068    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.0039  |
|    exploration_rate | 0.315    |
| time/               |          |
|    episodes         | 8684     |
|    fps              | 35       |
|    time_elapsed     | 4692     |
|    total_timesteps  | 164367   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.75e-05 |
|    n_updates        | 31091    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.2     |
|    ep_rew_mean      | -0.00198 |
|    exploration_rate | 0.315    |
| time/               |          |
|    episodes         | 8688     |
|    fps              | 35       |
|    time_elapsed     | 4693     |
|    total_timesteps  | 164445   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.68e-05 |
|    n_updates        | 31111    |
----------------------------------
Eval num_timesteps=164500, episode_reward=0.05 +/- 0.33
Episode length: 18.46 +/- 1.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.5     |
|    mean_reward      | 0.0471   |
| rollout/            |          |
|    exploration_rate | 0.314    |
| time/               |          |
|    total_timesteps  | 164500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000105 |
|    n_updates        | 31124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | 0.00879  |
|    exploration_rate | 0.314    |
| time/               |          |
|    episodes         | 8692     |
|    fps              | 35       |
|    time_elapsed     | 4697     |
|    total_timesteps  | 164521   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 31130    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | 0.00527  |
|    exploration_rate | 0.313    |
| time/               |          |
|    episodes         | 8696     |
|    fps              | 35       |
|    time_elapsed     | 4699     |
|    total_timesteps  | 164704   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.99e-05 |
|    n_updates        | 31175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.00452 |
|    exploration_rate | 0.312    |
| time/               |          |
|    episodes         | 8700     |
|    fps              | 35       |
|    time_elapsed     | 4699     |
|    total_timesteps  | 164790   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 31197    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | -0.003   |
|    exploration_rate | 0.311    |
| time/               |          |
|    episodes         | 8704     |
|    fps              | 35       |
|    time_elapsed     | 4699     |
|    total_timesteps  | 164857   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.93e-05 |
|    n_updates        | 31214    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.00392 |
|    exploration_rate | 0.31     |
| time/               |          |
|    episodes         | 8708     |
|    fps              | 35       |
|    time_elapsed     | 4700     |
|    total_timesteps  | 164966   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.27e-05 |
|    n_updates        | 31241    |
----------------------------------
Eval num_timesteps=165000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.31     |
| time/               |          |
|    total_timesteps  | 165000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.37e-05 |
|    n_updates        | 31249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.00452 |
|    exploration_rate | 0.31     |
| time/               |          |
|    episodes         | 8712     |
|    fps              | 35       |
|    time_elapsed     | 4713     |
|    total_timesteps  | 165073   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00703  |
|    n_updates        | 31268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.6     |
|    ep_rew_mean      | -0.00328 |
|    exploration_rate | 0.309    |
| time/               |          |
|    episodes         | 8716     |
|    fps              | 35       |
|    time_elapsed     | 4713     |
|    total_timesteps  | 165157   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000112 |
|    n_updates        | 31289    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.00449 |
|    exploration_rate | 0.308    |
| time/               |          |
|    episodes         | 8720     |
|    fps              | 35       |
|    time_elapsed     | 4714     |
|    total_timesteps  | 165257   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 31314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.00525 |
|    exploration_rate | 0.307    |
| time/               |          |
|    episodes         | 8724     |
|    fps              | 35       |
|    time_elapsed     | 4714     |
|    total_timesteps  | 165360   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.44e-05 |
|    n_updates        | 31339    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.00541 |
|    exploration_rate | 0.306    |
| time/               |          |
|    episodes         | 8728     |
|    fps              | 35       |
|    time_elapsed     | 4715     |
|    total_timesteps  | 165449   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000123 |
|    n_updates        | 31362    |
----------------------------------
Eval num_timesteps=165500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.306    |
| time/               |          |
|    total_timesteps  | 165500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00692  |
|    n_updates        | 31374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.6     |
|    ep_rew_mean      | -0.00725 |
|    exploration_rate | 0.305    |
| time/               |          |
|    episodes         | 8732     |
|    fps              | 35       |
|    time_elapsed     | 4727     |
|    total_timesteps  | 165570   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0143   |
|    n_updates        | 31392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.5     |
|    ep_rew_mean      | -0.00713 |
|    exploration_rate | 0.305    |
| time/               |          |
|    episodes         | 8736     |
|    fps              | 35       |
|    time_elapsed     | 4728     |
|    total_timesteps  | 165648   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.39e-05 |
|    n_updates        | 31411    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | -0.0299  |
|    exploration_rate | 0.304    |
| time/               |          |
|    episodes         | 8740     |
|    fps              | 35       |
|    time_elapsed     | 4729     |
|    total_timesteps  | 165800   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.37e-05 |
|    n_updates        | 31449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.302    |
| time/               |          |
|    episodes         | 8744     |
|    fps              | 35       |
|    time_elapsed     | 4729     |
|    total_timesteps  | 165934   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.95e-05 |
|    n_updates        | 31483    |
----------------------------------
Eval num_timesteps=166000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.302    |
| time/               |          |
|    total_timesteps  | 166000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 31499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0403  |
|    exploration_rate | 0.302    |
| time/               |          |
|    episodes         | 8748     |
|    fps              | 34       |
|    time_elapsed     | 4746     |
|    total_timesteps  | 166035   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00012  |
|    n_updates        | 31508    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0318  |
|    exploration_rate | 0.3      |
| time/               |          |
|    episodes         | 8752     |
|    fps              | 35       |
|    time_elapsed     | 4747     |
|    total_timesteps  | 166173   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.015    |
|    n_updates        | 31543    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0318  |
|    exploration_rate | 0.3      |
| time/               |          |
|    episodes         | 8756     |
|    fps              | 35       |
|    time_elapsed     | 4747     |
|    total_timesteps  | 166273   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000133 |
|    n_updates        | 31568    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0423  |
|    exploration_rate | 0.299    |
| time/               |          |
|    episodes         | 8760     |
|    fps              | 35       |
|    time_elapsed     | 4748     |
|    total_timesteps  | 166384   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.64e-05 |
|    n_updates        | 31595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.298    |
| time/               |          |
|    episodes         | 8764     |
|    fps              | 35       |
|    time_elapsed     | 4749     |
|    total_timesteps  | 166485   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.82e-05 |
|    n_updates        | 31621    |
----------------------------------
Eval num_timesteps=166500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.298    |
| time/               |          |
|    total_timesteps  | 166500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.97e-05 |
|    n_updates        | 31624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.297    |
| time/               |          |
|    episodes         | 8768     |
|    fps              | 34       |
|    time_elapsed     | 4765     |
|    total_timesteps  | 166608   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 31651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.296    |
| time/               |          |
|    episodes         | 8772     |
|    fps              | 34       |
|    time_elapsed     | 4765     |
|    total_timesteps  | 166717   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00681  |
|    n_updates        | 31679    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0324  |
|    exploration_rate | 0.295    |
| time/               |          |
|    episodes         | 8776     |
|    fps              | 34       |
|    time_elapsed     | 4766     |
|    total_timesteps  | 166792   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000131 |
|    n_updates        | 31697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0534  |
|    exploration_rate | 0.294    |
| time/               |          |
|    episodes         | 8780     |
|    fps              | 35       |
|    time_elapsed     | 4766     |
|    total_timesteps  | 166887   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.05e-05 |
|    n_updates        | 31721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0536  |
|    exploration_rate | 0.294    |
| time/               |          |
|    episodes         | 8784     |
|    fps              | 35       |
|    time_elapsed     | 4767     |
|    total_timesteps  | 166982   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.44e-05 |
|    n_updates        | 31745    |
----------------------------------
Eval num_timesteps=167000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.294    |
| time/               |          |
|    total_timesteps  | 167000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.72e-05 |
|    n_updates        | 31749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0552  |
|    exploration_rate | 0.293    |
| time/               |          |
|    episodes         | 8788     |
|    fps              | 34       |
|    time_elapsed     | 4784     |
|    total_timesteps  | 167100   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.89e-05 |
|    n_updates        | 31774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0564  |
|    exploration_rate | 0.292    |
| time/               |          |
|    episodes         | 8792     |
|    fps              | 34       |
|    time_elapsed     | 4785     |
|    total_timesteps  | 167207   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00777  |
|    n_updates        | 31801    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0531  |
|    exploration_rate | 0.291    |
| time/               |          |
|    episodes         | 8796     |
|    fps              | 34       |
|    time_elapsed     | 4785     |
|    total_timesteps  | 167307   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00684  |
|    n_updates        | 31826    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0529  |
|    exploration_rate | 0.29     |
| time/               |          |
|    episodes         | 8800     |
|    fps              | 34       |
|    time_elapsed     | 4786     |
|    total_timesteps  | 167388   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.24e-05 |
|    n_updates        | 31846    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0335  |
|    exploration_rate | 0.29     |
| time/               |          |
|    episodes         | 8804     |
|    fps              | 34       |
|    time_elapsed     | 4787     |
|    total_timesteps  | 167470   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 31867    |
----------------------------------
Eval num_timesteps=167500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.289    |
| time/               |          |
|    total_timesteps  | 167500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00706  |
|    n_updates        | 31874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0328  |
|    exploration_rate | 0.289    |
| time/               |          |
|    episodes         | 8808     |
|    fps              | 34       |
|    time_elapsed     | 4803     |
|    total_timesteps  | 167562   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.77e-05 |
|    n_updates        | 31890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0327  |
|    exploration_rate | 0.288    |
| time/               |          |
|    episodes         | 8812     |
|    fps              | 34       |
|    time_elapsed     | 4804     |
|    total_timesteps  | 167668   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.28e-05 |
|    n_updates        | 31916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.3     |
|    ep_rew_mean      | -0.034   |
|    exploration_rate | 0.287    |
| time/               |          |
|    episodes         | 8816     |
|    fps              | 34       |
|    time_elapsed     | 4805     |
|    total_timesteps  | 167784   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.3e-05  |
|    n_updates        | 31945    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.3     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.286    |
| time/               |          |
|    episodes         | 8820     |
|    fps              | 34       |
|    time_elapsed     | 4805     |
|    total_timesteps  | 167883   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00771  |
|    n_updates        | 31970    |
----------------------------------
Eval num_timesteps=168000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.285    |
| time/               |          |
|    total_timesteps  | 168000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.48e-05 |
|    n_updates        | 31999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.0251  |
|    exploration_rate | 0.285    |
| time/               |          |
|    episodes         | 8824     |
|    fps              | 34       |
|    time_elapsed     | 4821     |
|    total_timesteps  | 168014   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.27e-05 |
|    n_updates        | 32003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.4     |
|    ep_rew_mean      | -0.0146  |
|    exploration_rate | 0.284    |
| time/               |          |
|    episodes         | 8828     |
|    fps              | 34       |
|    time_elapsed     | 4822     |
|    total_timesteps  | 168091   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.67e-05 |
|    n_updates        | 32022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0035  |
|    exploration_rate | 0.284    |
| time/               |          |
|    episodes         | 8832     |
|    fps              | 34       |
|    time_elapsed     | 4822     |
|    total_timesteps  | 168184   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.49e-05 |
|    n_updates        | 32045    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.0051  |
|    exploration_rate | 0.283    |
| time/               |          |
|    episodes         | 8836     |
|    fps              | 34       |
|    time_elapsed     | 4823     |
|    total_timesteps  | 168302   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.06e-05 |
|    n_updates        | 32075    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.00202 |
|    exploration_rate | 0.282    |
| time/               |          |
|    episodes         | 8840     |
|    fps              | 34       |
|    time_elapsed     | 4823     |
|    total_timesteps  | 168377   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.1e-05  |
|    n_updates        | 32094    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | 0.00022  |
|    exploration_rate | 0.281    |
| time/               |          |
|    episodes         | 8844     |
|    fps              | 34       |
|    time_elapsed     | 4824     |
|    total_timesteps  | 168455   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.81e-05 |
|    n_updates        | 32113    |
----------------------------------
Eval num_timesteps=168500, episode_reward=-0.29 +/- 0.03
Episode length: 73.16 +/- 7.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.2     |
|    mean_reward      | -0.293   |
| rollout/            |          |
|    exploration_rate | 0.281    |
| time/               |          |
|    total_timesteps  | 168500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.1e-05  |
|    n_updates        | 32124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.00018 |
|    exploration_rate | 0.28     |
| time/               |          |
|    episodes         | 8848     |
|    fps              | 34       |
|    time_elapsed     | 4839     |
|    total_timesteps  | 168566   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.31e-05 |
|    n_updates        | 32141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.7     |
|    ep_rew_mean      | -0.00764 |
|    exploration_rate | 0.28     |
| time/               |          |
|    episodes         | 8852     |
|    fps              | 34       |
|    time_elapsed     | 4840     |
|    total_timesteps  | 168640   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.91e-05 |
|    n_updates        | 32159    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.5     |
|    ep_rew_mean      | -0.00696 |
|    exploration_rate | 0.279    |
| time/               |          |
|    episodes         | 8856     |
|    fps              | 34       |
|    time_elapsed     | 4841     |
|    total_timesteps  | 168723   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.51e-05 |
|    n_updates        | 32180    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.00536 |
|    exploration_rate | 0.279    |
| time/               |          |
|    episodes         | 8860     |
|    fps              | 34       |
|    time_elapsed     | 4841     |
|    total_timesteps  | 168794   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.34e-05 |
|    n_updates        | 32198    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.00455 |
|    exploration_rate | 0.278    |
| time/               |          |
|    episodes         | 8864     |
|    fps              | 34       |
|    time_elapsed     | 4841     |
|    total_timesteps  | 168875   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.59e-05 |
|    n_updates        | 32218    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | -0.00295 |
|    exploration_rate | 0.277    |
| time/               |          |
|    episodes         | 8868     |
|    fps              | 34       |
|    time_elapsed     | 4842     |
|    total_timesteps  | 168958   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.38e-05 |
|    n_updates        | 32239    |
----------------------------------
Eval num_timesteps=169000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.277    |
| time/               |          |
|    total_timesteps  | 169000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.94e-05 |
|    n_updates        | 32249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | 0.00553  |
|    exploration_rate | 0.276    |
| time/               |          |
|    episodes         | 8872     |
|    fps              | 34       |
|    time_elapsed     | 4858     |
|    total_timesteps  | 169105   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.69e-05 |
|    n_updates        | 32276    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.00507 |
|    exploration_rate | 0.275    |
| time/               |          |
|    episodes         | 8876     |
|    fps              | 34       |
|    time_elapsed     | 4858     |
|    total_timesteps  | 169195   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 32298    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.00435 |
|    exploration_rate | 0.274    |
| time/               |          |
|    episodes         | 8880     |
|    fps              | 34       |
|    time_elapsed     | 4859     |
|    total_timesteps  | 169272   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.56e-05 |
|    n_updates        | 32317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.6     |
|    ep_rew_mean      | -0.00339 |
|    exploration_rate | 0.274    |
| time/               |          |
|    episodes         | 8884     |
|    fps              | 34       |
|    time_elapsed     | 4859     |
|    total_timesteps  | 169343   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000129 |
|    n_updates        | 32335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | -0.00243 |
|    exploration_rate | 0.273    |
| time/               |          |
|    episodes         | 8888     |
|    fps              | 34       |
|    time_elapsed     | 4860     |
|    total_timesteps  | 169437   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.24e-05 |
|    n_updates        | 32359    |
----------------------------------
Eval num_timesteps=169500, episode_reward=-0.30 +/- 0.02
Episode length: 74.24 +/- 4.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.2     |
|    mean_reward      | -0.297   |
| rollout/            |          |
|    exploration_rate | 0.273    |
| time/               |          |
|    total_timesteps  | 169500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.84e-05 |
|    n_updates        | 32374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | -0.00256 |
|    exploration_rate | 0.272    |
| time/               |          |
|    episodes         | 8892     |
|    fps              | 34       |
|    time_elapsed     | 4876     |
|    total_timesteps  | 169547   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0139   |
|    n_updates        | 32386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | 0.00764  |
|    exploration_rate | 0.271    |
| time/               |          |
|    episodes         | 8896     |
|    fps              | 34       |
|    time_elapsed     | 4877     |
|    total_timesteps  | 169642   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 32410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.3     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.271    |
| time/               |          |
|    episodes         | 8900     |
|    fps              | 34       |
|    time_elapsed     | 4877     |
|    total_timesteps  | 169722   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.97e-05 |
|    n_updates        | 32430    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.5     |
|    ep_rew_mean      | 0.00701  |
|    exploration_rate | 0.27     |
| time/               |          |
|    episodes         | 8904     |
|    fps              | 34       |
|    time_elapsed     | 4878     |
|    total_timesteps  | 169821   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 32455    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.8     |
|    ep_rew_mean      | 0.00605  |
|    exploration_rate | 0.269    |
| time/               |          |
|    episodes         | 8908     |
|    fps              | 34       |
|    time_elapsed     | 4878     |
|    total_timesteps  | 169937   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.29e-05 |
|    n_updates        | 32484    |
----------------------------------
Eval num_timesteps=170000, episode_reward=-0.30 +/- 0.01
Episode length: 74.60 +/- 2.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.6     |
|    mean_reward      | -0.298   |
| rollout/            |          |
|    exploration_rate | 0.268    |
| time/               |          |
|    total_timesteps  | 170000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0217   |
|    n_updates        | 32499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | 0.00725  |
|    exploration_rate | 0.268    |
| time/               |          |
|    episodes         | 8912     |
|    fps              | 34       |
|    time_elapsed     | 4891     |
|    total_timesteps  | 170013   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.61e-05 |
|    n_updates        | 32503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.2     |
|    ep_rew_mean      | 0.00813  |
|    exploration_rate | 0.267    |
| time/               |          |
|    episodes         | 8916     |
|    fps              | 34       |
|    time_elapsed     | 4892     |
|    total_timesteps  | 170107   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.36e-05 |
|    n_updates        | 32526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.2     |
|    ep_rew_mean      | 0.0182   |
|    exploration_rate | 0.267    |
| time/               |          |
|    episodes         | 8920     |
|    fps              | 34       |
|    time_elapsed     | 4892     |
|    total_timesteps  | 170204   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.73e-05 |
|    n_updates        | 32550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.6     |
|    ep_rew_mean      | 0.00044  |
|    exploration_rate | 0.266    |
| time/               |          |
|    episodes         | 8924     |
|    fps              | 34       |
|    time_elapsed     | 4893     |
|    total_timesteps  | 170279   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.84e-05 |
|    n_updates        | 32569    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.7     |
|    ep_rew_mean      | 0.00013  |
|    exploration_rate | 0.265    |
| time/               |          |
|    episodes         | 8928     |
|    fps              | 34       |
|    time_elapsed     | 4893     |
|    total_timesteps  | 170363   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.67e-05 |
|    n_updates        | 32590    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | -0.0113  |
|    exploration_rate | 0.264    |
| time/               |          |
|    episodes         | 8932     |
|    fps              | 34       |
|    time_elapsed     | 4894     |
|    total_timesteps  | 170492   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.99e-05 |
|    n_updates        | 32622    |
----------------------------------
Eval num_timesteps=170500, episode_reward=-0.24 +/- 0.16
Episode length: 63.96 +/- 17.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64       |
|    mean_reward      | -0.235   |
| rollout/            |          |
|    exploration_rate | 0.264    |
| time/               |          |
|    total_timesteps  | 170500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.83e-05 |
|    n_updates        | 32624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | -0.0105  |
|    exploration_rate | 0.263    |
| time/               |          |
|    episodes         | 8936     |
|    fps              | 34       |
|    time_elapsed     | 4907     |
|    total_timesteps  | 170591   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00696  |
|    n_updates        | 32647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.3     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.262    |
| time/               |          |
|    episodes         | 8940     |
|    fps              | 34       |
|    time_elapsed     | 4908     |
|    total_timesteps  | 170703   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.32e-05 |
|    n_updates        | 32675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.262    |
| time/               |          |
|    episodes         | 8944     |
|    fps              | 34       |
|    time_elapsed     | 4909     |
|    total_timesteps  | 170787   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000142 |
|    n_updates        | 32696    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.4     |
|    ep_rew_mean      | -0.0125  |
|    exploration_rate | 0.261    |
| time/               |          |
|    episodes         | 8948     |
|    fps              | 34       |
|    time_elapsed     | 4909     |
|    total_timesteps  | 170905   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.04e-05 |
|    n_updates        | 32726    |
----------------------------------
Eval num_timesteps=171000, episode_reward=-0.24 +/- 0.16
Episode length: 65.70 +/- 18.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.7     |
|    mean_reward      | -0.243   |
| rollout/            |          |
|    exploration_rate | 0.26     |
| time/               |          |
|    total_timesteps  | 171000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.56e-05 |
|    n_updates        | 32749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.26     |
| time/               |          |
|    episodes         | 8952     |
|    fps              | 34       |
|    time_elapsed     | 4921     |
|    total_timesteps  | 171039   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.86e-05 |
|    n_updates        | 32759    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.0151  |
|    exploration_rate | 0.259    |
| time/               |          |
|    episodes         | 8956     |
|    fps              | 34       |
|    time_elapsed     | 4922     |
|    total_timesteps  | 171126   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.08e-05 |
|    n_updates        | 32781    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.0156  |
|    exploration_rate | 0.258    |
| time/               |          |
|    episodes         | 8960     |
|    fps              | 34       |
|    time_elapsed     | 4922     |
|    total_timesteps  | 171209   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00781  |
|    n_updates        | 32802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0301  |
|    exploration_rate | 0.256    |
| time/               |          |
|    episodes         | 8964     |
|    fps              | 34       |
|    time_elapsed     | 4923     |
|    total_timesteps  | 171404   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00672  |
|    n_updates        | 32850    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0203  |
|    exploration_rate | 0.256    |
| time/               |          |
|    episodes         | 8968     |
|    fps              | 34       |
|    time_elapsed     | 4924     |
|    total_timesteps  | 171490   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.38e-05 |
|    n_updates        | 32872    |
----------------------------------
Eval num_timesteps=171500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.256    |
| time/               |          |
|    total_timesteps  | 171500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 32874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.7     |
|    ep_rew_mean      | -0.0277  |
|    exploration_rate | 0.255    |
| time/               |          |
|    episodes         | 8972     |
|    fps              | 34       |
|    time_elapsed     | 4936     |
|    total_timesteps  | 171572   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.84e-05 |
|    n_updates        | 32892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.1     |
|    ep_rew_mean      | -0.0293  |
|    exploration_rate | 0.254    |
| time/               |          |
|    episodes         | 8976     |
|    fps              | 34       |
|    time_elapsed     | 4937     |
|    total_timesteps  | 171704   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.86e-05 |
|    n_updates        | 32925    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.1     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 0.253    |
| time/               |          |
|    episodes         | 8980     |
|    fps              | 34       |
|    time_elapsed     | 4938     |
|    total_timesteps  | 171777   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.15e-05 |
|    n_updates        | 32944    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0202  |
|    exploration_rate | 0.252    |
| time/               |          |
|    episodes         | 8984     |
|    fps              | 34       |
|    time_elapsed     | 4938     |
|    total_timesteps  | 171875   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.79e-05 |
|    n_updates        | 32968    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.252    |
| time/               |          |
|    episodes         | 8988     |
|    fps              | 34       |
|    time_elapsed     | 4939     |
|    total_timesteps  | 171972   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.4e-05  |
|    n_updates        | 32992    |
----------------------------------
Eval num_timesteps=172000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.251    |
| time/               |          |
|    total_timesteps  | 172000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 32999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.25     |
| time/               |          |
|    episodes         | 8992     |
|    fps              | 34       |
|    time_elapsed     | 4955     |
|    total_timesteps  | 172141   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.97e-05 |
|    n_updates        | 33035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.25     |
| time/               |          |
|    episodes         | 8996     |
|    fps              | 34       |
|    time_elapsed     | 4956     |
|    total_timesteps  | 172219   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 33054    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0533  |
|    exploration_rate | 0.249    |
| time/               |          |
|    episodes         | 9000     |
|    fps              | 34       |
|    time_elapsed     | 4956     |
|    total_timesteps  | 172331   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00686  |
|    n_updates        | 33082    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0527  |
|    exploration_rate | 0.248    |
| time/               |          |
|    episodes         | 9004     |
|    fps              | 34       |
|    time_elapsed     | 4957     |
|    total_timesteps  | 172413   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.53e-05 |
|    n_updates        | 33103    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.0409  |
|    exploration_rate | 0.247    |
| time/               |          |
|    episodes         | 9008     |
|    fps              | 34       |
|    time_elapsed     | 4958     |
|    total_timesteps  | 172486   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.42e-05 |
|    n_updates        | 33121    |
----------------------------------
Eval num_timesteps=172500, episode_reward=-0.29 +/- 0.05
Episode length: 72.66 +/- 11.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.7     |
|    mean_reward      | -0.291   |
| rollout/            |          |
|    exploration_rate | 0.247    |
| time/               |          |
|    total_timesteps  | 172500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.98e-05 |
|    n_updates        | 33124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0317  |
|    exploration_rate | 0.246    |
| time/               |          |
|    episodes         | 9012     |
|    fps              | 34       |
|    time_elapsed     | 4973     |
|    total_timesteps  | 172582   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00708  |
|    n_updates        | 33145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 0.246    |
| time/               |          |
|    episodes         | 9016     |
|    fps              | 34       |
|    time_elapsed     | 4974     |
|    total_timesteps  | 172648   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0145   |
|    n_updates        | 33161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0401  |
|    exploration_rate | 0.245    |
| time/               |          |
|    episodes         | 9020     |
|    fps              | 34       |
|    time_elapsed     | 4974     |
|    total_timesteps  | 172732   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.44e-05 |
|    n_updates        | 33182    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.0408  |
|    exploration_rate | 0.244    |
| time/               |          |
|    episodes         | 9024     |
|    fps              | 34       |
|    time_elapsed     | 4975     |
|    total_timesteps  | 172825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.05e-05 |
|    n_updates        | 33206    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0527  |
|    exploration_rate | 0.243    |
| time/               |          |
|    episodes         | 9028     |
|    fps              | 34       |
|    time_elapsed     | 4976     |
|    total_timesteps  | 172957   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.66e-05 |
|    n_updates        | 33239    |
----------------------------------
Eval num_timesteps=173000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.243    |
| time/               |          |
|    total_timesteps  | 173000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0077   |
|    n_updates        | 33249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0301  |
|    exploration_rate | 0.243    |
| time/               |          |
|    episodes         | 9032     |
|    fps              | 34       |
|    time_elapsed     | 4988     |
|    total_timesteps  | 173022   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.99e-05 |
|    n_updates        | 33255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 0.242    |
| time/               |          |
|    episodes         | 9036     |
|    fps              | 34       |
|    time_elapsed     | 4989     |
|    total_timesteps  | 173147   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.1e-05  |
|    n_updates        | 33286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0211  |
|    exploration_rate | 0.241    |
| time/               |          |
|    episodes         | 9040     |
|    fps              | 34       |
|    time_elapsed     | 4990     |
|    total_timesteps  | 173258   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 33314    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0224  |
|    exploration_rate | 0.24     |
| time/               |          |
|    episodes         | 9044     |
|    fps              | 34       |
|    time_elapsed     | 4991     |
|    total_timesteps  | 173374   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.48e-05 |
|    n_updates        | 33343    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.239    |
| time/               |          |
|    episodes         | 9048     |
|    fps              | 34       |
|    time_elapsed     | 4991     |
|    total_timesteps  | 173474   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 33368    |
----------------------------------
Eval num_timesteps=173500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.239    |
| time/               |          |
|    total_timesteps  | 173500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000108 |
|    n_updates        | 33374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.238    |
| time/               |          |
|    episodes         | 9052     |
|    fps              | 34       |
|    time_elapsed     | 5004     |
|    total_timesteps  | 173574   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00772  |
|    n_updates        | 33393    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.00062 |
|    exploration_rate | 0.237    |
| time/               |          |
|    episodes         | 9056     |
|    fps              | 34       |
|    time_elapsed     | 5004     |
|    total_timesteps  | 173669   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.94e-05 |
|    n_updates        | 33417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.00306 |
|    exploration_rate | 0.236    |
| time/               |          |
|    episodes         | 9060     |
|    fps              | 34       |
|    time_elapsed     | 5005     |
|    total_timesteps  | 173813   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000195 |
|    n_updates        | 33453    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.00018 |
|    exploration_rate | 0.235    |
| time/               |          |
|    episodes         | 9064     |
|    fps              | 34       |
|    time_elapsed     | 5006     |
|    total_timesteps  | 173936   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00705  |
|    n_updates        | 33483    |
----------------------------------
Eval num_timesteps=174000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.234    |
| time/               |          |
|    total_timesteps  | 174000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.9e-05  |
|    n_updates        | 33499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0115  |
|    exploration_rate | 0.234    |
| time/               |          |
|    episodes         | 9068     |
|    fps              | 34       |
|    time_elapsed     | 5018     |
|    total_timesteps  | 174055   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.22e-05 |
|    n_updates        | 33513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 0.233    |
| time/               |          |
|    episodes         | 9072     |
|    fps              | 34       |
|    time_elapsed     | 5019     |
|    total_timesteps  | 174153   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0068   |
|    n_updates        | 33538    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0124  |
|    exploration_rate | 0.232    |
| time/               |          |
|    episodes         | 9076     |
|    fps              | 34       |
|    time_elapsed     | 5020     |
|    total_timesteps  | 174291   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.98e-05 |
|    n_updates        | 33572    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.3     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.231    |
| time/               |          |
|    episodes         | 9080     |
|    fps              | 34       |
|    time_elapsed     | 5021     |
|    total_timesteps  | 174408   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.39e-05 |
|    n_updates        | 33601    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.2     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.23     |
| time/               |          |
|    episodes         | 9084     |
|    fps              | 34       |
|    time_elapsed     | 5021     |
|    total_timesteps  | 174492   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.7e-05  |
|    n_updates        | 33622    |
----------------------------------
Eval num_timesteps=174500, episode_reward=-0.30 +/- 0.03
Episode length: 73.88 +/- 7.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.23     |
| time/               |          |
|    total_timesteps  | 174500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.1e-05  |
|    n_updates        | 33624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.229    |
| time/               |          |
|    episodes         | 9088     |
|    fps              | 34       |
|    time_elapsed     | 5033     |
|    total_timesteps  | 174565   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00704  |
|    n_updates        | 33641    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.0208  |
|    exploration_rate | 0.228    |
| time/               |          |
|    episodes         | 9092     |
|    fps              | 34       |
|    time_elapsed     | 5034     |
|    total_timesteps  | 174688   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.37e-05 |
|    n_updates        | 33671    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | -0.0213  |
|    exploration_rate | 0.228    |
| time/               |          |
|    episodes         | 9096     |
|    fps              | 34       |
|    time_elapsed     | 5035     |
|    total_timesteps  | 174777   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.67e-05 |
|    n_updates        | 33694    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | -0.00974 |
|    exploration_rate | 0.227    |
| time/               |          |
|    episodes         | 9100     |
|    fps              | 34       |
|    time_elapsed     | 5035     |
|    total_timesteps  | 174851   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 33712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.0108  |
|    exploration_rate | 0.226    |
| time/               |          |
|    episodes         | 9104     |
|    fps              | 34       |
|    time_elapsed     | 5036     |
|    total_timesteps  | 174959   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.85e-05 |
|    n_updates        | 33739    |
----------------------------------
Eval num_timesteps=175000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.226    |
| time/               |          |
|    total_timesteps  | 175000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.44e-05 |
|    n_updates        | 33749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.0251  |
|    exploration_rate | 0.225    |
| time/               |          |
|    episodes         | 9108     |
|    fps              | 34       |
|    time_elapsed     | 5049     |
|    total_timesteps  | 175140   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.44e-05 |
|    n_updates        | 33784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.8     |
|    ep_rew_mean      | -0.026   |
|    exploration_rate | 0.224    |
| time/               |          |
|    episodes         | 9112     |
|    fps              | 34       |
|    time_elapsed     | 5050     |
|    total_timesteps  | 175257   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00785  |
|    n_updates        | 33814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.3     |
|    ep_rew_mean      | -0.0182  |
|    exploration_rate | 0.222    |
| time/               |          |
|    episodes         | 9116     |
|    fps              | 34       |
|    time_elapsed     | 5050     |
|    total_timesteps  | 175379   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0072   |
|    n_updates        | 33844    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.4     |
|    ep_rew_mean      | -0.00879 |
|    exploration_rate | 0.222    |
| time/               |          |
|    episodes         | 9120     |
|    fps              | 34       |
|    time_elapsed     | 5051     |
|    total_timesteps  | 175477   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.26e-05 |
|    n_updates        | 33869    |
----------------------------------
Eval num_timesteps=175500, episode_reward=-0.30 +/- 0.03
Episode length: 73.82 +/- 8.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.221    |
| time/               |          |
|    total_timesteps  | 175500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 33874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.22     |
| time/               |          |
|    episodes         | 9124     |
|    fps              | 34       |
|    time_elapsed     | 5064     |
|    total_timesteps  | 175659   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000175 |
|    n_updates        | 33914    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28       |
|    ep_rew_mean      | -0.00106 |
|    exploration_rate | 0.219    |
| time/               |          |
|    episodes         | 9128     |
|    fps              | 34       |
|    time_elapsed     | 5064     |
|    total_timesteps  | 175759   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.007    |
|    n_updates        | 33939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 0.219    |
| time/               |          |
|    episodes         | 9132     |
|    fps              | 34       |
|    time_elapsed     | 5065     |
|    total_timesteps  | 175833   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.14e-05 |
|    n_updates        | 33958    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 0.218    |
| time/               |          |
|    episodes         | 9136     |
|    fps              | 34       |
|    time_elapsed     | 5065     |
|    total_timesteps  | 175938   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.45e-05 |
|    n_updates        | 33984    |
----------------------------------
Eval num_timesteps=176000, episode_reward=0.02 +/- 0.31
Episode length: 19.20 +/- 14.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.2     |
|    mean_reward      | 0.0242   |
| rollout/            |          |
|    exploration_rate | 0.217    |
| time/               |          |
|    total_timesteps  | 176000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.24e-05 |
|    n_updates        | 33999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.6     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 0.217    |
| time/               |          |
|    episodes         | 9140     |
|    fps              | 34       |
|    time_elapsed     | 5071     |
|    total_timesteps  | 176015   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.95e-05 |
|    n_updates        | 34003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.2     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.216    |
| time/               |          |
|    episodes         | 9144     |
|    fps              | 34       |
|    time_elapsed     | 5071     |
|    total_timesteps  | 176092   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.1e-05  |
|    n_updates        | 34022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.216    |
| time/               |          |
|    episodes         | 9148     |
|    fps              | 34       |
|    time_elapsed     | 5072     |
|    total_timesteps  | 176160   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0141   |
|    n_updates        | 34039    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0254  |
|    exploration_rate | 0.215    |
| time/               |          |
|    episodes         | 9152     |
|    fps              | 34       |
|    time_elapsed     | 5072     |
|    total_timesteps  | 176236   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.03e-05 |
|    n_updates        | 34058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.8     |
|    ep_rew_mean      | -0.0361  |
|    exploration_rate | 0.214    |
| time/               |          |
|    episodes         | 9156     |
|    fps              | 34       |
|    time_elapsed     | 5073     |
|    total_timesteps  | 176348   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.15e-05 |
|    n_updates        | 34086    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0357  |
|    exploration_rate | 0.213    |
| time/               |          |
|    episodes         | 9160     |
|    fps              | 34       |
|    time_elapsed     | 5074     |
|    total_timesteps  | 176481   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.51e-05 |
|    n_updates        | 34120    |
----------------------------------
Eval num_timesteps=176500, episode_reward=-0.22 +/- 0.22
Episode length: 64.94 +/- 18.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.9     |
|    mean_reward      | -0.22    |
| rollout/            |          |
|    exploration_rate | 0.213    |
| time/               |          |
|    total_timesteps  | 176500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.91e-05 |
|    n_updates        | 34124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.0249  |
|    exploration_rate | 0.212    |
| time/               |          |
|    episodes         | 9164     |
|    fps              | 34       |
|    time_elapsed     | 5085     |
|    total_timesteps  | 176585   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.71e-05 |
|    n_updates        | 34146    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.4     |
|    ep_rew_mean      | -0.0187  |
|    exploration_rate | 0.21     |
| time/               |          |
|    episodes         | 9168     |
|    fps              | 34       |
|    time_elapsed     | 5086     |
|    total_timesteps  | 176797   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00717  |
|    n_updates        | 34199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.8     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.209    |
| time/               |          |
|    episodes         | 9172     |
|    fps              | 34       |
|    time_elapsed     | 5087     |
|    total_timesteps  | 176937   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.63e-05 |
|    n_updates        | 34234    |
----------------------------------
Eval num_timesteps=177000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.208    |
| time/               |          |
|    total_timesteps  | 177000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.09e-05 |
|    n_updates        | 34249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.8     |
|    ep_rew_mean      | -0.00023 |
|    exploration_rate | 0.208    |
| time/               |          |
|    episodes         | 9176     |
|    fps              | 34       |
|    time_elapsed     | 5103     |
|    total_timesteps  | 177073   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.57e-05 |
|    n_updates        | 34268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.8     |
|    ep_rew_mean      | -0.0001  |
|    exploration_rate | 0.207    |
| time/               |          |
|    episodes         | 9180     |
|    fps              | 34       |
|    time_elapsed     | 5103     |
|    total_timesteps  | 177187   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.2e-05  |
|    n_updates        | 34296    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.3     |
|    ep_rew_mean      | 0.00782  |
|    exploration_rate | 0.206    |
| time/               |          |
|    episodes         | 9184     |
|    fps              | 34       |
|    time_elapsed     | 5104     |
|    total_timesteps  | 177323   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00683  |
|    n_updates        | 34330    |
----------------------------------
Eval num_timesteps=177500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.204    |
| time/               |          |
|    total_timesteps  | 177500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.39e-05 |
|    n_updates        | 34374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.4     |
|    ep_rew_mean      | 0.0134   |
|    exploration_rate | 0.204    |
| time/               |          |
|    episodes         | 9188     |
|    fps              | 34       |
|    time_elapsed     | 5117     |
|    total_timesteps  | 177508   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.15e-05 |
|    n_updates        | 34376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30       |
|    ep_rew_mean      | 0.0109   |
|    exploration_rate | 0.202    |
| time/               |          |
|    episodes         | 9192     |
|    fps              | 34       |
|    time_elapsed     | 5118     |
|    total_timesteps  | 177691   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.08e-05 |
|    n_updates        | 34422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.3     |
|    ep_rew_mean      | 0.00978  |
|    exploration_rate | 0.201    |
| time/               |          |
|    episodes         | 9196     |
|    fps              | 34       |
|    time_elapsed     | 5119     |
|    total_timesteps  | 177809   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.01e-05 |
|    n_updates        | 34452    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.4     |
|    ep_rew_mean      | -0.00475 |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 9200     |
|    fps              | 34       |
|    time_elapsed     | 5120     |
|    total_timesteps  | 177996   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.72e-05 |
|    n_updates        | 34498    |
----------------------------------
Eval num_timesteps=178000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.2      |
| time/               |          |
|    total_timesteps  | 178000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00692  |
|    n_updates        | 34499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.5     |
|    ep_rew_mean      | -0.00499 |
|    exploration_rate | 0.199    |
| time/               |          |
|    episodes         | 9204     |
|    fps              | 34       |
|    time_elapsed     | 5132     |
|    total_timesteps  | 178110   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0218   |
|    n_updates        | 34527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.7     |
|    ep_rew_mean      | -0.00166 |
|    exploration_rate | 0.198    |
| time/               |          |
|    episodes         | 9208     |
|    fps              | 34       |
|    time_elapsed     | 5133     |
|    total_timesteps  | 178208   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0077   |
|    n_updates        | 34551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.9     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.197    |
| time/               |          |
|    episodes         | 9212     |
|    fps              | 34       |
|    time_elapsed     | 5134     |
|    total_timesteps  | 178352   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.84e-05 |
|    n_updates        | 34587    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.5     |
|    ep_rew_mean      | -0.021   |
|    exploration_rate | 0.196    |
| time/               |          |
|    episodes         | 9216     |
|    fps              | 34       |
|    time_elapsed     | 5134     |
|    total_timesteps  | 178432   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.25e-05 |
|    n_updates        | 34607    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.2     |
|    ep_rew_mean      | -0.0297  |
|    exploration_rate | 0.195    |
| time/               |          |
|    episodes         | 9220     |
|    fps              | 34       |
|    time_elapsed     | 5135     |
|    total_timesteps  | 178497   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.51e-05 |
|    n_updates        | 34624    |
----------------------------------
Eval num_timesteps=178500, episode_reward=0.08 +/- 0.35
Episode length: 15.48 +/- 1.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.5     |
|    mean_reward      | 0.0791   |
| rollout/            |          |
|    exploration_rate | 0.195    |
| time/               |          |
|    total_timesteps  | 178500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.2     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.195    |
| time/               |          |
|    episodes         | 9224     |
|    fps              | 34       |
|    time_elapsed     | 5139     |
|    total_timesteps  | 178579   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.65e-05 |
|    n_updates        | 34644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.9     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.194    |
| time/               |          |
|    episodes         | 9228     |
|    fps              | 34       |
|    time_elapsed     | 5139     |
|    total_timesteps  | 178650   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.58e-05 |
|    n_updates        | 34662    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.8     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.194    |
| time/               |          |
|    episodes         | 9232     |
|    fps              | 34       |
|    time_elapsed     | 5140     |
|    total_timesteps  | 178715   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.74e-05 |
|    n_updates        | 34678    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29       |
|    ep_rew_mean      | -0.0349  |
|    exploration_rate | 0.193    |
| time/               |          |
|    episodes         | 9236     |
|    fps              | 34       |
|    time_elapsed     | 5141     |
|    total_timesteps  | 178836   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.08e-05 |
|    n_updates        | 34708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.8     |
|    ep_rew_mean      | -0.0282  |
|    exploration_rate | 0.191    |
| time/               |          |
|    episodes         | 9240     |
|    fps              | 34       |
|    time_elapsed     | 5142     |
|    total_timesteps  | 178996   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.97e-05 |
|    n_updates        | 34748    |
----------------------------------
Eval num_timesteps=179000, episode_reward=-0.28 +/- 0.05
Episode length: 70.66 +/- 12.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.7     |
|    mean_reward      | -0.283   |
| rollout/            |          |
|    exploration_rate | 0.191    |
| time/               |          |
|    total_timesteps  | 179000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.88e-05 |
|    n_updates        | 34749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.2     |
|    ep_rew_mean      | -0.0298  |
|    exploration_rate | 0.19     |
| time/               |          |
|    episodes         | 9244     |
|    fps              | 34       |
|    time_elapsed     | 5154     |
|    total_timesteps  | 179113   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.09e-05 |
|    n_updates        | 34778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.2     |
|    ep_rew_mean      | -0.0296  |
|    exploration_rate | 0.19     |
| time/               |          |
|    episodes         | 9248     |
|    fps              | 34       |
|    time_elapsed     | 5154     |
|    total_timesteps  | 179177   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.74e-05 |
|    n_updates        | 34794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.8     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.188    |
| time/               |          |
|    episodes         | 9252     |
|    fps              | 34       |
|    time_elapsed     | 5155     |
|    total_timesteps  | 179313   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8e-05    |
|    n_updates        | 34828    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.3     |
|    ep_rew_mean      | -0.0341  |
|    exploration_rate | 0.187    |
| time/               |          |
|    episodes         | 9256     |
|    fps              | 34       |
|    time_elapsed     | 5156     |
|    total_timesteps  | 179476   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.17e-05 |
|    n_updates        | 34868    |
----------------------------------
Eval num_timesteps=179500, episode_reward=-0.26 +/- 0.09
Episode length: 63.86 +/- 22.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.9     |
|    mean_reward      | -0.255   |
| rollout/            |          |
|    exploration_rate | 0.187    |
| time/               |          |
|    total_timesteps  | 179500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00696  |
|    n_updates        | 34874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.4     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.186    |
| time/               |          |
|    episodes         | 9260     |
|    fps              | 34       |
|    time_elapsed     | 5167     |
|    total_timesteps  | 179623   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000135 |
|    n_updates        | 34905    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.6     |
|    ep_rew_mean      | -0.0352  |
|    exploration_rate | 0.185    |
| time/               |          |
|    episodes         | 9264     |
|    fps              | 34       |
|    time_elapsed     | 5168     |
|    total_timesteps  | 179741   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00776  |
|    n_updates        | 34935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.9     |
|    ep_rew_mean      | -0.0425  |
|    exploration_rate | 0.183    |
| time/               |          |
|    episodes         | 9268     |
|    fps              | 34       |
|    time_elapsed     | 5168     |
|    total_timesteps  | 179886   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.8e-05  |
|    n_updates        | 34971    |
----------------------------------
Eval num_timesteps=180000, episode_reward=-0.27 +/- 0.08
Episode length: 67.18 +/- 18.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.2     |
|    mean_reward      | -0.269   |
| rollout/            |          |
|    exploration_rate | 0.182    |
| time/               |          |
|    total_timesteps  | 180000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.1e-05  |
|    n_updates        | 34999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.7     |
|    ep_rew_mean      | -0.0416  |
|    exploration_rate | 0.182    |
| time/               |          |
|    episodes         | 9272     |
|    fps              | 34       |
|    time_elapsed     | 5180     |
|    total_timesteps  | 180003   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000128 |
|    n_updates        | 35000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31       |
|    ep_rew_mean      | -0.0429  |
|    exploration_rate | 0.181    |
| time/               |          |
|    episodes         | 9276     |
|    fps              | 34       |
|    time_elapsed     | 5181     |
|    total_timesteps  | 180172   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.85e-05 |
|    n_updates        | 35042    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31       |
|    ep_rew_mean      | -0.0429  |
|    exploration_rate | 0.18     |
| time/               |          |
|    episodes         | 9280     |
|    fps              | 34       |
|    time_elapsed     | 5181     |
|    total_timesteps  | 180285   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.12e-05 |
|    n_updates        | 35071    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.5     |
|    ep_rew_mean      | -0.0508  |
|    exploration_rate | 0.179    |
| time/               |          |
|    episodes         | 9284     |
|    fps              | 34       |
|    time_elapsed     | 5182     |
|    total_timesteps  | 180369   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000111 |
|    n_updates        | 35092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.2     |
|    ep_rew_mean      | -0.0458  |
|    exploration_rate | 0.179    |
| time/               |          |
|    episodes         | 9288     |
|    fps              | 34       |
|    time_elapsed     | 5182     |
|    total_timesteps  | 180430   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00787  |
|    n_updates        | 35107    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28       |
|    ep_rew_mean      | -0.0208  |
|    exploration_rate | 0.178    |
| time/               |          |
|    episodes         | 9292     |
|    fps              | 34       |
|    time_elapsed     | 5183     |
|    total_timesteps  | 180488   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.43e-05 |
|    n_updates        | 35121    |
----------------------------------
Eval num_timesteps=180500, episode_reward=-0.21 +/- 0.18
Episode length: 58.54 +/- 22.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.5     |
|    mean_reward      | -0.214   |
| rollout/            |          |
|    exploration_rate | 0.178    |
| time/               |          |
|    total_timesteps  | 180500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.04e-05 |
|    n_updates        | 35124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.9     |
|    ep_rew_mean      | -0.0207  |
|    exploration_rate | 0.177    |
| time/               |          |
|    episodes         | 9296     |
|    fps              | 34       |
|    time_elapsed     | 5195     |
|    total_timesteps  | 180602   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.88e-05 |
|    n_updates        | 35150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.3     |
|    ep_rew_mean      | -0.00798 |
|    exploration_rate | 0.176    |
| time/               |          |
|    episodes         | 9300     |
|    fps              | 34       |
|    time_elapsed     | 5196     |
|    total_timesteps  | 180722   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 35180    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.2     |
|    ep_rew_mean      | 0.00215  |
|    exploration_rate | 0.175    |
| time/               |          |
|    episodes         | 9304     |
|    fps              | 34       |
|    time_elapsed     | 5197     |
|    total_timesteps  | 180833   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.8e-05  |
|    n_updates        | 35208    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.2     |
|    ep_rew_mean      | 0.00243  |
|    exploration_rate | 0.174    |
| time/               |          |
|    episodes         | 9308     |
|    fps              | 34       |
|    time_elapsed     | 5197     |
|    total_timesteps  | 180924   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.69e-05 |
|    n_updates        | 35230    |
----------------------------------
Eval num_timesteps=181000, episode_reward=-0.30 +/- 0.03
Episode length: 74.10 +/- 6.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.1     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.174    |
| time/               |          |
|    total_timesteps  | 181000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.65e-05 |
|    n_updates        | 35249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.2     |
|    ep_rew_mean      | 0.00235  |
|    exploration_rate | 0.173    |
| time/               |          |
|    episodes         | 9312     |
|    fps              | 34       |
|    time_elapsed     | 5210     |
|    total_timesteps  | 181070   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000128 |
|    n_updates        | 35267    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.6     |
|    ep_rew_mean      | 0.0207   |
|    exploration_rate | 0.172    |
| time/               |          |
|    episodes         | 9316     |
|    fps              | 34       |
|    time_elapsed     | 5210     |
|    total_timesteps  | 181192   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.07e-05 |
|    n_updates        | 35297    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.6     |
|    ep_rew_mean      | 0.0166   |
|    exploration_rate | 0.17     |
| time/               |          |
|    episodes         | 9320     |
|    fps              | 34       |
|    time_elapsed     | 5211     |
|    total_timesteps  | 181360   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.36e-05 |
|    n_updates        | 35339    |
----------------------------------
Eval num_timesteps=181500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.169    |
| time/               |          |
|    total_timesteps  | 181500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.49e-05 |
|    n_updates        | 35374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.5     |
|    ep_rew_mean      | 0.013    |
|    exploration_rate | 0.169    |
| time/               |          |
|    episodes         | 9324     |
|    fps              | 34       |
|    time_elapsed     | 5224     |
|    total_timesteps  | 181531   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00669  |
|    n_updates        | 35382    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.5     |
|    ep_rew_mean      | 0.0131   |
|    exploration_rate | 0.168    |
| time/               |          |
|    episodes         | 9328     |
|    fps              | 34       |
|    time_elapsed     | 5225     |
|    total_timesteps  | 181600   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000127 |
|    n_updates        | 35399    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.8     |
|    ep_rew_mean      | 0.0117   |
|    exploration_rate | 0.167    |
| time/               |          |
|    episodes         | 9332     |
|    fps              | 34       |
|    time_elapsed     | 5225     |
|    total_timesteps  | 181699   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000104 |
|    n_updates        | 35424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.2     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.166    |
| time/               |          |
|    episodes         | 9336     |
|    fps              | 34       |
|    time_elapsed     | 5226     |
|    total_timesteps  | 181856   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 35463    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.8     |
|    ep_rew_mean      | 0.00186  |
|    exploration_rate | 0.165    |
| time/               |          |
|    episodes         | 9340     |
|    fps              | 34       |
|    time_elapsed     | 5227     |
|    total_timesteps  | 181976   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.7e-05  |
|    n_updates        | 35493    |
----------------------------------
Eval num_timesteps=182000, episode_reward=-0.08 +/- 0.28
Episode length: 36.04 +/- 27.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 36       |
|    mean_reward      | -0.0835  |
| rollout/            |          |
|    exploration_rate | 0.165    |
| time/               |          |
|    total_timesteps  | 182000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.46e-05 |
|    n_updates        | 35499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.2     |
|    ep_rew_mean      | 0.0141   |
|    exploration_rate | 0.164    |
| time/               |          |
|    episodes         | 9344     |
|    fps              | 34       |
|    time_elapsed     | 5235     |
|    total_timesteps  | 182037   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.54e-05 |
|    n_updates        | 35509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.4     |
|    ep_rew_mean      | 0.0136   |
|    exploration_rate | 0.164    |
| time/               |          |
|    episodes         | 9348     |
|    fps              | 34       |
|    time_elapsed     | 5236     |
|    total_timesteps  | 182115   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.67e-05 |
|    n_updates        | 35528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29       |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.163    |
| time/               |          |
|    episodes         | 9352     |
|    fps              | 34       |
|    time_elapsed     | 5236     |
|    total_timesteps  | 182214   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.32e-05 |
|    n_updates        | 35553    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.9     |
|    ep_rew_mean      | 0.0493   |
|    exploration_rate | 0.162    |
| time/               |          |
|    episodes         | 9356     |
|    fps              | 34       |
|    time_elapsed     | 5237     |
|    total_timesteps  | 182271   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.79e-05 |
|    n_updates        | 35567    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.7     |
|    ep_rew_mean      | 0.0402   |
|    exploration_rate | 0.161    |
| time/               |          |
|    episodes         | 9360     |
|    fps              | 34       |
|    time_elapsed     | 5237     |
|    total_timesteps  | 182394   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000127 |
|    n_updates        | 35598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.2     |
|    ep_rew_mean      | 0.0424   |
|    exploration_rate | 0.161    |
| time/               |          |
|    episodes         | 9364     |
|    fps              | 34       |
|    time_elapsed     | 5238     |
|    total_timesteps  | 182458   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.87e-05 |
|    n_updates        | 35614    |
----------------------------------
Eval num_timesteps=182500, episode_reward=-0.10 +/- 0.24
Episode length: 34.72 +/- 27.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 34.7     |
|    mean_reward      | -0.0982  |
| rollout/            |          |
|    exploration_rate | 0.16     |
| time/               |          |
|    total_timesteps  | 182500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.15e-05 |
|    n_updates        | 35624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | 0.0445   |
|    exploration_rate | 0.16     |
| time/               |          |
|    episodes         | 9368     |
|    fps              | 34       |
|    time_elapsed     | 5246     |
|    total_timesteps  | 182551   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.4e-05  |
|    n_updates        | 35637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.3     |
|    ep_rew_mean      | 0.0459   |
|    exploration_rate | 0.159    |
| time/               |          |
|    episodes         | 9372     |
|    fps              | 34       |
|    time_elapsed     | 5246     |
|    total_timesteps  | 182632   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 35657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.6     |
|    ep_rew_mean      | 0.0588   |
|    exploration_rate | 0.158    |
| time/               |          |
|    episodes         | 9376     |
|    fps              | 34       |
|    time_elapsed     | 5247     |
|    total_timesteps  | 182728   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00707  |
|    n_updates        | 35681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | 0.047    |
|    exploration_rate | 0.157    |
| time/               |          |
|    episodes         | 9380     |
|    fps              | 34       |
|    time_elapsed     | 5248     |
|    total_timesteps  | 182886   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.12e-05 |
|    n_updates        | 35721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | 0.0466   |
|    exploration_rate | 0.156    |
| time/               |          |
|    episodes         | 9384     |
|    fps              | 34       |
|    time_elapsed     | 5249     |
|    total_timesteps  | 182981   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.6e-05  |
|    n_updates        | 35745    |
----------------------------------
Eval num_timesteps=183000, episode_reward=-0.30 +/- 0.03
Episode length: 74.04 +/- 6.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74       |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.156    |
| time/               |          |
|    total_timesteps  | 183000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.77e-05 |
|    n_updates        | 35749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.4     |
|    ep_rew_mean      | 0.0455   |
|    exploration_rate | 0.155    |
| time/               |          |
|    episodes         | 9388     |
|    fps              | 34       |
|    time_elapsed     | 5261     |
|    total_timesteps  | 183069   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000108 |
|    n_updates        | 35767    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.1     |
|    ep_rew_mean      | 0.0425   |
|    exploration_rate | 0.154    |
| time/               |          |
|    episodes         | 9392     |
|    fps              | 34       |
|    time_elapsed     | 5262     |
|    total_timesteps  | 183202   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.19e-05 |
|    n_updates        | 35800    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28       |
|    ep_rew_mean      | 0.039    |
|    exploration_rate | 0.152    |
| time/               |          |
|    episodes         | 9396     |
|    fps              | 34       |
|    time_elapsed     | 5263     |
|    total_timesteps  | 183404   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00774  |
|    n_updates        | 35850    |
----------------------------------
Eval num_timesteps=183500, episode_reward=-0.30 +/- 0.03
Episode length: 73.82 +/- 8.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.8     |
|    mean_reward      | -0.295   |
| rollout/            |          |
|    exploration_rate | 0.151    |
| time/               |          |
|    total_timesteps  | 183500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.31e-05 |
|    n_updates        | 35874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.7     |
|    ep_rew_mean      | 0.0264   |
|    exploration_rate | 0.151    |
| time/               |          |
|    episodes         | 9400     |
|    fps              | 34       |
|    time_elapsed     | 5276     |
|    total_timesteps  | 183589   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.23e-05 |
|    n_updates        | 35897    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.3     |
|    ep_rew_mean      | 0.0179   |
|    exploration_rate | 0.15     |
| time/               |          |
|    episodes         | 9404     |
|    fps              | 34       |
|    time_elapsed     | 5276     |
|    total_timesteps  | 183661   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.74e-05 |
|    n_updates        | 35915    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.5     |
|    ep_rew_mean      | 0.0169   |
|    exploration_rate | 0.149    |
| time/               |          |
|    episodes         | 9408     |
|    fps              | 34       |
|    time_elapsed     | 5277     |
|    total_timesteps  | 183776   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2e-05    |
|    n_updates        | 35943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28       |
|    ep_rew_mean      | 0.0189   |
|    exploration_rate | 0.148    |
| time/               |          |
|    episodes         | 9412     |
|    fps              | 34       |
|    time_elapsed     | 5278     |
|    total_timesteps  | 183874   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.11e-05 |
|    n_updates        | 35968    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28       |
|    ep_rew_mean      | -0.00108 |
|    exploration_rate | 0.147    |
| time/               |          |
|    episodes         | 9416     |
|    fps              | 34       |
|    time_elapsed     | 5278     |
|    total_timesteps  | 183994   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.34e-05 |
|    n_updates        | 35998    |
----------------------------------
Eval num_timesteps=184000, episode_reward=-0.07 +/- 0.16
Episode length: 21.86 +/- 17.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 21.9     |
|    mean_reward      | -0.0665  |
| rollout/            |          |
|    exploration_rate | 0.147    |
| time/               |          |
|    total_timesteps  | 184000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.68e-05 |
|    n_updates        | 35999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.2     |
|    ep_rew_mean      | 0.00228  |
|    exploration_rate | 0.146    |
| time/               |          |
|    episodes         | 9420     |
|    fps              | 34       |
|    time_elapsed     | 5284     |
|    total_timesteps  | 184078   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.82e-05 |
|    n_updates        | 36019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | 0.0167   |
|    exploration_rate | 0.146    |
| time/               |          |
|    episodes         | 9424     |
|    fps              | 34       |
|    time_elapsed     | 5285     |
|    total_timesteps  | 184138   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000104 |
|    n_updates        | 36034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | 0.00444  |
|    exploration_rate | 0.145    |
| time/               |          |
|    episodes         | 9428     |
|    fps              | 34       |
|    time_elapsed     | 5285     |
|    total_timesteps  | 184264   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.29e-05 |
|    n_updates        | 36065    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.3     |
|    ep_rew_mean      | 0.00584  |
|    exploration_rate | 0.144    |
| time/               |          |
|    episodes         | 9432     |
|    fps              | 34       |
|    time_elapsed     | 5286     |
|    total_timesteps  | 184328   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.82e-05 |
|    n_updates        | 36081    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | 0.00913  |
|    exploration_rate | 0.143    |
| time/               |          |
|    episodes         | 9436     |
|    fps              | 34       |
|    time_elapsed     | 5286     |
|    total_timesteps  | 184403   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00687  |
|    n_updates        | 36100    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.9     |
|    ep_rew_mean      | 0.0114   |
|    exploration_rate | 0.143    |
| time/               |          |
|    episodes         | 9440     |
|    fps              | 34       |
|    time_elapsed     | 5287     |
|    total_timesteps  | 184467   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.5e-05  |
|    n_updates        | 36116    |
----------------------------------
Eval num_timesteps=184500, episode_reward=0.10 +/- 0.37
Episode length: 15.46 +/- 1.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.5     |
|    mean_reward      | 0.0993   |
| rollout/            |          |
|    exploration_rate | 0.143    |
| time/               |          |
|    total_timesteps  | 184500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00765  |
|    n_updates        | 36124    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | 0.011    |
|    exploration_rate | 0.142    |
| time/               |          |
|    episodes         | 9444     |
|    fps              | 34       |
|    time_elapsed     | 5291     |
|    total_timesteps  | 184537   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.86e-05 |
|    n_updates        | 36134    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | 0.0112   |
|    exploration_rate | 0.142    |
| time/               |          |
|    episodes         | 9448     |
|    fps              | 34       |
|    time_elapsed     | 5292     |
|    total_timesteps  | 184611   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.67e-05 |
|    n_updates        | 36152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.7     |
|    ep_rew_mean      | 0.0123   |
|    exploration_rate | 0.141    |
| time/               |          |
|    episodes         | 9452     |
|    fps              | 34       |
|    time_elapsed     | 5292     |
|    total_timesteps  | 184683   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.65e-05 |
|    n_updates        | 36170    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.1     |
|    ep_rew_mean      | -0.00944 |
|    exploration_rate | 0.14     |
| time/               |          |
|    episodes         | 9456     |
|    fps              | 34       |
|    time_elapsed     | 5293     |
|    total_timesteps  | 184782   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00704  |
|    n_updates        | 36195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.5     |
|    ep_rew_mean      | -0.00708 |
|    exploration_rate | 0.14     |
| time/               |          |
|    episodes         | 9460     |
|    fps              | 34       |
|    time_elapsed     | 5293     |
|    total_timesteps  | 184846   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.41e-05 |
|    n_updates        | 36211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.8     |
|    ep_rew_mean      | -0.00824 |
|    exploration_rate | 0.139    |
| time/               |          |
|    episodes         | 9464     |
|    fps              | 34       |
|    time_elapsed     | 5294     |
|    total_timesteps  | 184939   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 36234    |
----------------------------------
Eval num_timesteps=185000, episode_reward=-0.17 +/- 0.25
Episode length: 52.48 +/- 28.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.5     |
|    mean_reward      | -0.17    |
| rollout/            |          |
|    exploration_rate | 0.138    |
| time/               |          |
|    total_timesteps  | 185000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00692  |
|    n_updates        | 36249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.9     |
|    ep_rew_mean      | -0.00844 |
|    exploration_rate | 0.138    |
| time/               |          |
|    episodes         | 9468     |
|    fps              | 34       |
|    time_elapsed     | 5303     |
|    total_timesteps  | 185037   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.014    |
|    n_updates        | 36259    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.8     |
|    ep_rew_mean      | -0.018   |
|    exploration_rate | 0.137    |
| time/               |          |
|    episodes         | 9472     |
|    fps              | 34       |
|    time_elapsed     | 5304     |
|    total_timesteps  | 185107   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.53e-05 |
|    n_updates        | 36276    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.1     |
|    ep_rew_mean      | -0.0393  |
|    exploration_rate | 0.136    |
| time/               |          |
|    episodes         | 9476     |
|    fps              | 34       |
|    time_elapsed     | 5305     |
|    total_timesteps  | 185235   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.78e-05 |
|    n_updates        | 36308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0418  |
|    exploration_rate | 0.134    |
| time/               |          |
|    episodes         | 9480     |
|    fps              | 34       |
|    time_elapsed     | 5306     |
|    total_timesteps  | 185456   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.88e-05 |
|    n_updates        | 36363    |
----------------------------------
Eval num_timesteps=185500, episode_reward=-0.07 +/- 0.32
Episode length: 38.18 +/- 28.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 38.2     |
|    mean_reward      | -0.0721  |
| rollout/            |          |
|    exploration_rate | 0.134    |
| time/               |          |
|    total_timesteps  | 185500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.66e-05 |
|    n_updates        | 36374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.0411  |
|    exploration_rate | 0.133    |
| time/               |          |
|    episodes         | 9484     |
|    fps              | 34       |
|    time_elapsed     | 5314     |
|    total_timesteps  | 185534   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.87e-05 |
|    n_updates        | 36383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0503  |
|    exploration_rate | 0.133    |
| time/               |          |
|    episodes         | 9488     |
|    fps              | 34       |
|    time_elapsed     | 5314     |
|    total_timesteps  | 185602   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0071   |
|    n_updates        | 36400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.7     |
|    ep_rew_mean      | -0.068   |
|    exploration_rate | 0.132    |
| time/               |          |
|    episodes         | 9492     |
|    fps              | 34       |
|    time_elapsed     | 5315     |
|    total_timesteps  | 185676   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.16e-05 |
|    n_updates        | 36418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.0547  |
|    exploration_rate | 0.131    |
| time/               |          |
|    episodes         | 9496     |
|    fps              | 34       |
|    time_elapsed     | 5316     |
|    total_timesteps  | 185797   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.85e-05 |
|    n_updates        | 36449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.7     |
|    ep_rew_mean      | -0.0499  |
|    exploration_rate | 0.13     |
| time/               |          |
|    episodes         | 9500     |
|    fps              | 34       |
|    time_elapsed     | 5316     |
|    total_timesteps  | 185861   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.25e-05 |
|    n_updates        | 36465    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | -0.0506  |
|    exploration_rate | 0.13     |
| time/               |          |
|    episodes         | 9504     |
|    fps              | 34       |
|    time_elapsed     | 5317     |
|    total_timesteps  | 185951   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.28e-05 |
|    n_updates        | 36487    |
----------------------------------
Eval num_timesteps=186000, episode_reward=-0.03 +/- 0.21
Episode length: 18.26 +/- 11.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.3     |
|    mean_reward      | -0.032   |
| rollout/            |          |
|    exploration_rate | 0.129    |
| time/               |          |
|    total_timesteps  | 186000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.08e-05 |
|    n_updates        | 36499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.4     |
|    ep_rew_mean      | -0.0386  |
|    exploration_rate | 0.129    |
| time/               |          |
|    episodes         | 9508     |
|    fps              | 34       |
|    time_elapsed     | 5321     |
|    total_timesteps  | 186015   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.42e-05 |
|    n_updates        | 36503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.1     |
|    ep_rew_mean      | -0.0274  |
|    exploration_rate | 0.128    |
| time/               |          |
|    episodes         | 9512     |
|    fps              | 34       |
|    time_elapsed     | 5322     |
|    total_timesteps  | 186085   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.24e-05 |
|    n_updates        | 36521    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.128    |
| time/               |          |
|    episodes         | 9516     |
|    fps              | 34       |
|    time_elapsed     | 5322     |
|    total_timesteps  | 186162   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.94e-05 |
|    n_updates        | 36540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | -0.019   |
|    exploration_rate | 0.126    |
| time/               |          |
|    episodes         | 9520     |
|    fps              | 34       |
|    time_elapsed     | 5323     |
|    total_timesteps  | 186328   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.73e-05 |
|    n_updates        | 36581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | -0.0214  |
|    exploration_rate | 0.125    |
| time/               |          |
|    episodes         | 9524     |
|    fps              | 35       |
|    time_elapsed     | 5324     |
|    total_timesteps  | 186448   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.92e-05 |
|    n_updates        | 36611    |
----------------------------------
Eval num_timesteps=186500, episode_reward=-0.29 +/- 0.06
Episode length: 71.46 +/- 14.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.5     |
|    mean_reward      | -0.286   |
| rollout/            |          |
|    exploration_rate | 0.125    |
| time/               |          |
|    total_timesteps  | 186500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.01e-05 |
|    n_updates        | 36624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.6     |
|    ep_rew_mean      | -0.0274  |
|    exploration_rate | 0.123    |
| time/               |          |
|    episodes         | 9528     |
|    fps              | 34       |
|    time_elapsed     | 5337     |
|    total_timesteps  | 186723   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.54e-05 |
|    n_updates        | 36680    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0329  |
|    exploration_rate | 0.121    |
| time/               |          |
|    episodes         | 9532     |
|    fps              | 35       |
|    time_elapsed     | 5339     |
|    total_timesteps  | 186924   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.5e-05  |
|    n_updates        | 36730    |
----------------------------------
Eval num_timesteps=187000, episode_reward=-0.02 +/- 0.28
Episode length: 25.60 +/- 16.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 25.6     |
|    mean_reward      | -0.0214  |
| rollout/            |          |
|    exploration_rate | 0.12     |
| time/               |          |
|    total_timesteps  | 187000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00718  |
|    n_updates        | 36749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0365  |
|    exploration_rate | 0.119    |
| time/               |          |
|    episodes         | 9536     |
|    fps              | 34       |
|    time_elapsed     | 5346     |
|    total_timesteps  | 187090   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.09e-05 |
|    n_updates        | 36772    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.7     |
|    ep_rew_mean      | -0.0299  |
|    exploration_rate | 0.118    |
| time/               |          |
|    episodes         | 9540     |
|    fps              | 35       |
|    time_elapsed     | 5346     |
|    total_timesteps  | 187238   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.007    |
|    n_updates        | 36809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.8     |
|    ep_rew_mean      | -0.0302  |
|    exploration_rate | 0.117    |
| time/               |          |
|    episodes         | 9544     |
|    fps              | 35       |
|    time_elapsed     | 5347     |
|    total_timesteps  | 187317   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00771  |
|    n_updates        | 36829    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.4     |
|    ep_rew_mean      | -0.0225  |
|    exploration_rate | 0.116    |
| time/               |          |
|    episodes         | 9548     |
|    fps              | 35       |
|    time_elapsed     | 5348     |
|    total_timesteps  | 187449   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.74e-05 |
|    n_updates        | 36862    |
----------------------------------
Eval num_timesteps=187500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.116    |
| time/               |          |
|    total_timesteps  | 187500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00766  |
|    n_updates        | 36874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.1     |
|    ep_rew_mean      | -0.0354  |
|    exploration_rate | 0.115    |
| time/               |          |
|    episodes         | 9552     |
|    fps              | 34       |
|    time_elapsed     | 5360     |
|    total_timesteps  | 187593   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00711  |
|    n_updates        | 36898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.9     |
|    ep_rew_mean      | -0.0388  |
|    exploration_rate | 0.113    |
| time/               |          |
|    episodes         | 9556     |
|    fps              | 35       |
|    time_elapsed     | 5361     |
|    total_timesteps  | 187776   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 36943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.8     |
|    ep_rew_mean      | -0.0323  |
|    exploration_rate | 0.112    |
| time/               |          |
|    episodes         | 9560     |
|    fps              | 35       |
|    time_elapsed     | 5362     |
|    total_timesteps  | 187927   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.38e-05 |
|    n_updates        | 36981    |
----------------------------------
Eval num_timesteps=188000, episode_reward=-0.21 +/- 0.22
Episode length: 62.34 +/- 18.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.3     |
|    mean_reward      | -0.209   |
| rollout/            |          |
|    exploration_rate | 0.111    |
| time/               |          |
|    total_timesteps  | 188000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4e-05    |
|    n_updates        | 36999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.5     |
|    ep_rew_mean      | -0.0349  |
|    exploration_rate | 0.11     |
| time/               |          |
|    episodes         | 9564     |
|    fps              | 34       |
|    time_elapsed     | 5376     |
|    total_timesteps  | 188085   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000133 |
|    n_updates        | 37021    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.9     |
|    ep_rew_mean      | -0.0367  |
|    exploration_rate | 0.109    |
| time/               |          |
|    episodes         | 9568     |
|    fps              | 35       |
|    time_elapsed     | 5376     |
|    total_timesteps  | 188229   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.33e-05 |
|    n_updates        | 37057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | -0.0391  |
|    exploration_rate | 0.108    |
| time/               |          |
|    episodes         | 9572     |
|    fps              | 35       |
|    time_elapsed     | 5377     |
|    total_timesteps  | 188357   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.49e-05 |
|    n_updates        | 37089    |
----------------------------------
Eval num_timesteps=188500, episode_reward=-0.30 +/- 0.03
Episode length: 73.92 +/- 7.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.9     |
|    mean_reward      | -0.296   |
| rollout/            |          |
|    exploration_rate | 0.107    |
| time/               |          |
|    total_timesteps  | 188500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.51e-05 |
|    n_updates        | 37124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.7     |
|    ep_rew_mean      | -0.0437  |
|    exploration_rate | 0.106    |
| time/               |          |
|    episodes         | 9576     |
|    fps              | 34       |
|    time_elapsed     | 5394     |
|    total_timesteps  | 188601   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.5e-05  |
|    n_updates        | 37150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.2     |
|    ep_rew_mean      | -0.0319  |
|    exploration_rate | 0.104    |
| time/               |          |
|    episodes         | 9580     |
|    fps              | 34       |
|    time_elapsed     | 5395     |
|    total_timesteps  | 188775   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0067   |
|    n_updates        | 37193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.3     |
|    ep_rew_mean      | -0.0364  |
|    exploration_rate | 0.103    |
| time/               |          |
|    episodes         | 9584     |
|    fps              | 35       |
|    time_elapsed     | 5396     |
|    total_timesteps  | 188967   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.26e-05 |
|    n_updates        | 37241    |
----------------------------------
Eval num_timesteps=189000, episode_reward=0.00 +/- 0.28
Episode length: 19.24 +/- 12.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.2     |
|    mean_reward      | 0.00404  |
| rollout/            |          |
|    exploration_rate | 0.102    |
| time/               |          |
|    total_timesteps  | 189000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.02e-05 |
|    n_updates        | 37249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.3     |
|    ep_rew_mean      | -0.0264  |
|    exploration_rate | 0.102    |
| time/               |          |
|    episodes         | 9588     |
|    fps              | 34       |
|    time_elapsed     | 5401     |
|    total_timesteps  | 189034   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.28e-05 |
|    n_updates        | 37258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.7     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.101    |
| time/               |          |
|    episodes         | 9592     |
|    fps              | 35       |
|    time_elapsed     | 5401     |
|    total_timesteps  | 189142   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.58e-05 |
|    n_updates        | 37285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.1     |
|    ep_rew_mean      | -0.0295  |
|    exploration_rate | 0.0995   |
| time/               |          |
|    episodes         | 9596     |
|    fps              | 35       |
|    time_elapsed     | 5402     |
|    total_timesteps  | 189307   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.79e-05 |
|    n_updates        | 37326    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.7     |
|    ep_rew_mean      | -0.0319  |
|    exploration_rate | 0.0983   |
| time/               |          |
|    episodes         | 9600     |
|    fps              | 35       |
|    time_elapsed     | 5403     |
|    total_timesteps  | 189431   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.79e-05 |
|    n_updates        | 37357    |
----------------------------------
Eval num_timesteps=189500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.0977   |
| time/               |          |
|    total_timesteps  | 189500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.33e-05 |
|    n_updates        | 37374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36       |
|    ep_rew_mean      | -0.0232  |
|    exploration_rate | 0.0972   |
| time/               |          |
|    episodes         | 9604     |
|    fps              | 34       |
|    time_elapsed     | 5419     |
|    total_timesteps  | 189554   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.37e-05 |
|    n_updates        | 37388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.8     |
|    ep_rew_mean      | -0.0263  |
|    exploration_rate | 0.0959   |
| time/               |          |
|    episodes         | 9608     |
|    fps              | 34       |
|    time_elapsed     | 5420     |
|    total_timesteps  | 189695   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000121 |
|    n_updates        | 37423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | -0.0278  |
|    exploration_rate | 0.095    |
| time/               |          |
|    episodes         | 9612     |
|    fps              | 35       |
|    time_elapsed     | 5420     |
|    total_timesteps  | 189802   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.38e-05 |
|    n_updates        | 37450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37       |
|    ep_rew_mean      | -0.0273  |
|    exploration_rate | 0.0944   |
| time/               |          |
|    episodes         | 9616     |
|    fps              | 35       |
|    time_elapsed     | 5421     |
|    total_timesteps  | 189866   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.28e-05 |
|    n_updates        | 37466    |
----------------------------------
Eval num_timesteps=190000, episode_reward=-0.26 +/- 0.18
Episode length: 70.18 +/- 16.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.2     |
|    mean_reward      | -0.261   |
| rollout/            |          |
|    exploration_rate | 0.0932   |
| time/               |          |
|    total_timesteps  | 190000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.32e-05 |
|    n_updates        | 37499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | -0.0381  |
|    exploration_rate | 0.0927   |
| time/               |          |
|    episodes         | 9620     |
|    fps              | 34       |
|    time_elapsed     | 5437     |
|    total_timesteps  | 190053   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.62e-05 |
|    n_updates        | 37513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | -0.0478  |
|    exploration_rate | 0.0917   |
| time/               |          |
|    episodes         | 9624     |
|    fps              | 34       |
|    time_elapsed     | 5438     |
|    total_timesteps  | 190167   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.58e-05 |
|    n_updates        | 37541    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.7     |
|    ep_rew_mean      | -0.0319  |
|    exploration_rate | 0.0905   |
| time/               |          |
|    episodes         | 9628     |
|    fps              | 34       |
|    time_elapsed     | 5439     |
|    total_timesteps  | 190295   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0068   |
|    n_updates        | 37573    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.9     |
|    ep_rew_mean      | -0.0287  |
|    exploration_rate | 0.0894   |
| time/               |          |
|    episodes         | 9632     |
|    fps              | 35       |
|    time_elapsed     | 5440     |
|    total_timesteps  | 190417   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.82e-05 |
|    n_updates        | 37604    |
----------------------------------
Eval num_timesteps=190500, episode_reward=-0.09 +/- 0.28
Episode length: 42.80 +/- 3.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | -0.0901  |
| rollout/            |          |
|    exploration_rate | 0.0886   |
| time/               |          |
|    total_timesteps  | 190500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000129 |
|    n_updates        | 37624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.9     |
|    ep_rew_mean      | -0.0286  |
|    exploration_rate | 0.0879   |
| time/               |          |
|    episodes         | 9636     |
|    fps              | 34       |
|    time_elapsed     | 5450     |
|    total_timesteps  | 190580   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.1e-05  |
|    n_updates        | 37644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35       |
|    ep_rew_mean      | -0.039   |
|    exploration_rate | 0.0865   |
| time/               |          |
|    episodes         | 9640     |
|    fps              | 34       |
|    time_elapsed     | 5451     |
|    total_timesteps  | 190737   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.45e-05 |
|    n_updates        | 37684    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.3     |
|    ep_rew_mean      | -0.0543  |
|    exploration_rate | 0.0846   |
| time/               |          |
|    episodes         | 9644     |
|    fps              | 35       |
|    time_elapsed     | 5452     |
|    total_timesteps  | 190948   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00701  |
|    n_updates        | 37736    |
----------------------------------
Eval num_timesteps=191000, episode_reward=-0.29 +/- 0.04
Episode length: 72.92 +/- 10.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.9     |
|    mean_reward      | -0.292   |
| rollout/            |          |
|    exploration_rate | 0.0841   |
| time/               |          |
|    total_timesteps  | 191000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.58e-05 |
|    n_updates        | 37749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.5     |
|    ep_rew_mean      | -0.065   |
|    exploration_rate | 0.0832   |
| time/               |          |
|    episodes         | 9648     |
|    fps              | 34       |
|    time_elapsed     | 5465     |
|    total_timesteps  | 191098   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.01e-05 |
|    n_updates        | 37774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.9     |
|    ep_rew_mean      | -0.0665  |
|    exploration_rate | 0.0816   |
| time/               |          |
|    episodes         | 9652     |
|    fps              | 34       |
|    time_elapsed     | 5466     |
|    total_timesteps  | 191279   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00696  |
|    n_updates        | 37819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.5     |
|    ep_rew_mean      | -0.0651  |
|    exploration_rate | 0.0802   |
| time/               |          |
|    episodes         | 9656     |
|    fps              | 35       |
|    time_elapsed     | 5467     |
|    total_timesteps  | 191428   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.34e-05 |
|    n_updates        | 37856    |
----------------------------------
Eval num_timesteps=191500, episode_reward=-0.08 +/- 0.00
Episode length: 20.94 +/- 0.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20.9     |
|    mean_reward      | -0.0828  |
| rollout/            |          |
|    exploration_rate | 0.0796   |
| time/               |          |
|    total_timesteps  | 191500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.66e-05 |
|    n_updates        | 37874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.5     |
|    ep_rew_mean      | -0.0749  |
|    exploration_rate | 0.0789   |
| time/               |          |
|    episodes         | 9660     |
|    fps              | 35       |
|    time_elapsed     | 5472     |
|    total_timesteps  | 191572   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0139   |
|    n_updates        | 37892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36       |
|    ep_rew_mean      | -0.0731  |
|    exploration_rate | 0.0778   |
| time/               |          |
|    episodes         | 9664     |
|    fps              | 35       |
|    time_elapsed     | 5473     |
|    total_timesteps  | 191686   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.42e-05 |
|    n_updates        | 37921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36       |
|    ep_rew_mean      | -0.0729  |
|    exploration_rate | 0.0766   |
| time/               |          |
|    episodes         | 9668     |
|    fps              | 35       |
|    time_elapsed     | 5474     |
|    total_timesteps  | 191825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.89e-05 |
|    n_updates        | 37956    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.8     |
|    ep_rew_mean      | -0.0621  |
|    exploration_rate | 0.0756   |
| time/               |          |
|    episodes         | 9672     |
|    fps              | 35       |
|    time_elapsed     | 5474     |
|    total_timesteps  | 191933   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.56e-05 |
|    n_updates        | 37983    |
----------------------------------
Eval num_timesteps=192000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.075    |
| time/               |          |
|    total_timesteps  | 192000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.64e-05 |
|    n_updates        | 37999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.2     |
|    ep_rew_mean      | -0.0598  |
|    exploration_rate | 0.0739   |
| time/               |          |
|    episodes         | 9676     |
|    fps              | 34       |
|    time_elapsed     | 5492     |
|    total_timesteps  | 192119   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.58e-06 |
|    n_updates        | 38029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.3     |
|    ep_rew_mean      | -0.0702  |
|    exploration_rate | 0.0722   |
| time/               |          |
|    episodes         | 9680     |
|    fps              | 35       |
|    time_elapsed     | 5493     |
|    total_timesteps  | 192305   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.33e-05 |
|    n_updates        | 38076    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.2     |
|    ep_rew_mean      | -0.0697  |
|    exploration_rate | 0.0705   |
| time/               |          |
|    episodes         | 9684     |
|    fps              | 35       |
|    time_elapsed     | 5494     |
|    total_timesteps  | 192485   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.79e-05 |
|    n_updates        | 38121    |
----------------------------------
Eval num_timesteps=192500, episode_reward=-0.26 +/- 0.18
Episode length: 70.58 +/- 15.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.6     |
|    mean_reward      | -0.262   |
| rollout/            |          |
|    exploration_rate | 0.0704   |
| time/               |          |
|    total_timesteps  | 192500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.54e-05 |
|    n_updates        | 38124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.8     |
|    ep_rew_mean      | -0.0724  |
|    exploration_rate | 0.0693   |
| time/               |          |
|    episodes         | 9688     |
|    fps              | 34       |
|    time_elapsed     | 5506     |
|    total_timesteps  | 192618   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.61e-05 |
|    n_updates        | 38154    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37       |
|    ep_rew_mean      | -0.0873  |
|    exploration_rate | 0.0672   |
| time/               |          |
|    episodes         | 9692     |
|    fps              | 35       |
|    time_elapsed     | 5507     |
|    total_timesteps  | 192847   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.83e-05 |
|    n_updates        | 38211    |
----------------------------------
Eval num_timesteps=193000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.0658   |
| time/               |          |
|    total_timesteps  | 193000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00762  |
|    n_updates        | 38249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.7     |
|    ep_rew_mean      | -0.09    |
|    exploration_rate | 0.0651   |
| time/               |          |
|    episodes         | 9696     |
|    fps              | 34       |
|    time_elapsed     | 5520     |
|    total_timesteps  | 193081   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.21e-05 |
|    n_updates        | 38270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.5     |
|    ep_rew_mean      | -0.0833  |
|    exploration_rate | 0.0632   |
| time/               |          |
|    episodes         | 9700     |
|    fps              | 35       |
|    time_elapsed     | 5521     |
|    total_timesteps  | 193286   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.24e-05 |
|    n_updates        | 38321    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39       |
|    ep_rew_mean      | -0.0952  |
|    exploration_rate | 0.0616   |
| time/               |          |
|    episodes         | 9704     |
|    fps              | 35       |
|    time_elapsed     | 5522     |
|    total_timesteps  | 193457   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.47e-05 |
|    n_updates        | 38364    |
----------------------------------
Eval num_timesteps=193500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.0613   |
| time/               |          |
|    total_timesteps  | 193500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.45e-05 |
|    n_updates        | 38374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.6     |
|    ep_rew_mean      | -0.108   |
|    exploration_rate | 0.0598   |
| time/               |          |
|    episodes         | 9708     |
|    fps              | 34       |
|    time_elapsed     | 5536     |
|    total_timesteps  | 193660   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00675  |
|    n_updates        | 38414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40       |
|    ep_rew_mean      | -0.109   |
|    exploration_rate | 0.0585   |
| time/               |          |
|    episodes         | 9712     |
|    fps              | 34       |
|    time_elapsed     | 5537     |
|    total_timesteps  | 193805   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.85e-05 |
|    n_updates        | 38451    |
----------------------------------
Eval num_timesteps=194000, episode_reward=-0.26 +/- 0.15
Episode length: 70.46 +/- 11.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.5     |
|    mean_reward      | -0.262   |
| rollout/            |          |
|    exploration_rate | 0.0567   |
| time/               |          |
|    total_timesteps  | 194000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.77e-05 |
|    n_updates        | 38499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.6     |
|    ep_rew_mean      | -0.116   |
|    exploration_rate | 0.0564   |
| time/               |          |
|    episodes         | 9716     |
|    fps              | 34       |
|    time_elapsed     | 5550     |
|    total_timesteps  | 194026   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000109 |
|    n_updates        | 38506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.5     |
|    ep_rew_mean      | -0.105   |
|    exploration_rate | 0.0548   |
| time/               |          |
|    episodes         | 9720     |
|    fps              | 34       |
|    time_elapsed     | 5551     |
|    total_timesteps  | 194206   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00704  |
|    n_updates        | 38551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.6     |
|    ep_rew_mean      | -0.0956  |
|    exploration_rate | 0.0537   |
| time/               |          |
|    episodes         | 9724     |
|    fps              | 34       |
|    time_elapsed     | 5552     |
|    total_timesteps  | 194327   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00675  |
|    n_updates        | 38581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.4     |
|    ep_rew_mean      | -0.105   |
|    exploration_rate | 0.0526   |
| time/               |          |
|    episodes         | 9728     |
|    fps              | 35       |
|    time_elapsed     | 5553     |
|    total_timesteps  | 194438   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.44e-05 |
|    n_updates        | 38609    |
----------------------------------
Eval num_timesteps=194500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.0521   |
| time/               |          |
|    total_timesteps  | 194500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00686  |
|    n_updates        | 38624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.8     |
|    ep_rew_mean      | -0.11    |
|    exploration_rate | 0.0502   |
| time/               |          |
|    episodes         | 9732     |
|    fps              | 34       |
|    time_elapsed     | 5569     |
|    total_timesteps  | 194698   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 38674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.7     |
|    ep_rew_mean      | -0.114   |
|    exploration_rate | 0.048    |
| time/               |          |
|    episodes         | 9736     |
|    fps              | 34       |
|    time_elapsed     | 5571     |
|    total_timesteps  | 194946   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.72e-05 |
|    n_updates        | 38736    |
----------------------------------
Eval num_timesteps=195000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.0475   |
| time/               |          |
|    total_timesteps  | 195000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000142 |
|    n_updates        | 38749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.3     |
|    ep_rew_mean      | -0.117   |
|    exploration_rate | 0.0459   |
| time/               |          |
|    episodes         | 9740     |
|    fps              | 34       |
|    time_elapsed     | 5584     |
|    total_timesteps  | 195170   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.12e-05 |
|    n_updates        | 38792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.3     |
|    ep_rew_mean      | -0.116   |
|    exploration_rate | 0.044    |
| time/               |          |
|    episodes         | 9744     |
|    fps              | 34       |
|    time_elapsed     | 5585     |
|    total_timesteps  | 195374   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0068   |
|    n_updates        | 38843    |
----------------------------------
Eval num_timesteps=195500, episode_reward=-0.23 +/- 0.18
Episode length: 62.84 +/- 19.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.8     |
|    mean_reward      | -0.231   |
| rollout/            |          |
|    exploration_rate | 0.0429   |
| time/               |          |
|    total_timesteps  | 195500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 38874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.7     |
|    ep_rew_mean      | -0.108   |
|    exploration_rate | 0.0422   |
| time/               |          |
|    episodes         | 9748     |
|    fps              | 34       |
|    time_elapsed     | 5599     |
|    total_timesteps  | 195568   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.21e-05 |
|    n_updates        | 38891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.6     |
|    ep_rew_mean      | -0.108   |
|    exploration_rate | 0.0406   |
| time/               |          |
|    episodes         | 9752     |
|    fps              | 34       |
|    time_elapsed     | 5600     |
|    total_timesteps  | 195738   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.02e-05 |
|    n_updates        | 38934    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45       |
|    ep_rew_mean      | -0.109   |
|    exploration_rate | 0.0389   |
| time/               |          |
|    episodes         | 9756     |
|    fps              | 34       |
|    time_elapsed     | 5601     |
|    total_timesteps  | 195930   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.85e-05 |
|    n_updates        | 38982    |
----------------------------------
Eval num_timesteps=196000, episode_reward=-0.28 +/- 0.05
Episode length: 68.96 +/- 11.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69       |
|    mean_reward      | -0.276   |
| rollout/            |          |
|    exploration_rate | 0.0382   |
| time/               |          |
|    total_timesteps  | 196000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.85e-05 |
|    n_updates        | 38999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.4     |
|    ep_rew_mean      | -0.115   |
|    exploration_rate | 0.0362   |
| time/               |          |
|    episodes         | 9760     |
|    fps              | 34       |
|    time_elapsed     | 5616     |
|    total_timesteps  | 196214   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.37e-06 |
|    n_updates        | 39053    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.9     |
|    ep_rew_mean      | -0.121   |
|    exploration_rate | 0.0338   |
| time/               |          |
|    episodes         | 9764     |
|    fps              | 34       |
|    time_elapsed     | 5618     |
|    total_timesteps  | 196477   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0069   |
|    n_updates        | 39119    |
----------------------------------
Eval num_timesteps=196500, episode_reward=-0.29 +/- 0.04
Episode length: 71.50 +/- 10.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.5     |
|    mean_reward      | -0.286   |
| rollout/            |          |
|    exploration_rate | 0.0336   |
| time/               |          |
|    total_timesteps  | 196500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00696  |
|    n_updates        | 39124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.8     |
|    ep_rew_mean      | -0.12    |
|    exploration_rate | 0.0326   |
| time/               |          |
|    episodes         | 9768     |
|    fps              | 34       |
|    time_elapsed     | 5631     |
|    total_timesteps  | 196604   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.55e-05 |
|    n_updates        | 39150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.3     |
|    ep_rew_mean      | -0.119   |
|    exploration_rate | 0.0321   |
| time/               |          |
|    episodes         | 9772     |
|    fps              | 34       |
|    time_elapsed     | 5632     |
|    total_timesteps  | 196665   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000129 |
|    n_updates        | 39166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.1     |
|    ep_rew_mean      | -0.114   |
|    exploration_rate | 0.0315   |
| time/               |          |
|    episodes         | 9776     |
|    fps              | 34       |
|    time_elapsed     | 5632     |
|    total_timesteps  | 196731   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.03e-05 |
|    n_updates        | 39182    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45.4     |
|    ep_rew_mean      | -0.111   |
|    exploration_rate | 0.0304   |
| time/               |          |
|    episodes         | 9780     |
|    fps              | 34       |
|    time_elapsed     | 5633     |
|    total_timesteps  | 196840   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2e-05    |
|    n_updates        | 39209    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.6     |
|    ep_rew_mean      | -0.107   |
|    exploration_rate | 0.0295   |
| time/               |          |
|    episodes         | 9784     |
|    fps              | 34       |
|    time_elapsed     | 5634     |
|    total_timesteps  | 196941   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.34e-05 |
|    n_updates        | 39235    |
----------------------------------
Eval num_timesteps=197000, episode_reward=0.05 +/- 0.38
Episode length: 26.88 +/- 17.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 26.9     |
|    mean_reward      | 0.0535   |
| rollout/            |          |
|    exploration_rate | 0.029    |
| time/               |          |
|    total_timesteps  | 197000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.59e-05 |
|    n_updates        | 39249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.9     |
|    ep_rew_mean      | -0.115   |
|    exploration_rate | 0.0289   |
| time/               |          |
|    episodes         | 9788     |
|    fps              | 34       |
|    time_elapsed     | 5640     |
|    total_timesteps  | 197011   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.7e-05  |
|    n_updates        | 39252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.9     |
|    ep_rew_mean      | -0.111   |
|    exploration_rate | 0.0277   |
| time/               |          |
|    episodes         | 9792     |
|    fps              | 34       |
|    time_elapsed     | 5641     |
|    total_timesteps  | 197133   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00706  |
|    n_updates        | 39283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.9     |
|    ep_rew_mean      | -0.107   |
|    exploration_rate | 0.0264   |
| time/               |          |
|    episodes         | 9796     |
|    fps              | 34       |
|    time_elapsed     | 5642     |
|    total_timesteps  | 197271   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.44e-05 |
|    n_updates        | 39317    |
----------------------------------
Eval num_timesteps=197500, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.0243   |
| time/               |          |
|    total_timesteps  | 197500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.02e-05 |
|    n_updates        | 39374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.2     |
|    ep_rew_mean      | -0.118   |
|    exploration_rate | 0.0242   |
| time/               |          |
|    episodes         | 9800     |
|    fps              | 34       |
|    time_elapsed     | 5655     |
|    total_timesteps  | 197510   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.56e-05 |
|    n_updates        | 39377    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.3     |
|    ep_rew_mean      | -0.123   |
|    exploration_rate | 0.0216   |
| time/               |          |
|    episodes         | 9804     |
|    fps              | 34       |
|    time_elapsed     | 5657     |
|    total_timesteps  | 197791   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000134 |
|    n_updates        | 39447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.5     |
|    ep_rew_mean      | -0.119   |
|    exploration_rate | 0.0205   |
| time/               |          |
|    episodes         | 9808     |
|    fps              | 34       |
|    time_elapsed     | 5658     |
|    total_timesteps  | 197907   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.89e-06 |
|    n_updates        | 39476    |
----------------------------------
Eval num_timesteps=198000, episode_reward=0.02 +/- 0.28
Episode length: 15.78 +/- 1.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.0179   |
| rollout/            |          |
|    exploration_rate | 0.0197   |
| time/               |          |
|    total_timesteps  | 198000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.9e-05  |
|    n_updates        | 39499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42       |
|    ep_rew_mean      | -0.127   |
|    exploration_rate | 0.0196   |
| time/               |          |
|    episodes         | 9812     |
|    fps              | 34       |
|    time_elapsed     | 5662     |
|    total_timesteps  | 198009   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.22e-05 |
|    n_updates        | 39502    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.5     |
|    ep_rew_mean      | -0.121   |
|    exploration_rate | 0.019    |
| time/               |          |
|    episodes         | 9816     |
|    fps              | 34       |
|    time_elapsed     | 5662     |
|    total_timesteps  | 198073   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000126 |
|    n_updates        | 39518    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.9     |
|    ep_rew_mean      | -0.129   |
|    exploration_rate | 0.0178   |
| time/               |          |
|    episodes         | 9820     |
|    fps              | 34       |
|    time_elapsed     | 5663     |
|    total_timesteps  | 198196   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.05e-05 |
|    n_updates        | 39548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.9     |
|    ep_rew_mean      | -0.143   |
|    exploration_rate | 0.0158   |
| time/               |          |
|    episodes         | 9824     |
|    fps              | 35       |
|    time_elapsed     | 5665     |
|    total_timesteps  | 198414   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.77e-05 |
|    n_updates        | 39603    |
----------------------------------
Eval num_timesteps=198500, episode_reward=-0.20 +/- 0.17
Episode length: 55.70 +/- 21.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.7     |
|    mean_reward      | -0.202   |
| rollout/            |          |
|    exploration_rate | 0.015    |
| time/               |          |
|    total_timesteps  | 198500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.32e-05 |
|    n_updates        | 39624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.9     |
|    ep_rew_mean      | -0.137   |
|    exploration_rate | 0.0138   |
| time/               |          |
|    episodes         | 9828     |
|    fps              | 34       |
|    time_elapsed     | 5678     |
|    total_timesteps  | 198630   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.59e-05 |
|    n_updates        | 39657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.4     |
|    ep_rew_mean      | -0.131   |
|    exploration_rate | 0.0128   |
| time/               |          |
|    episodes         | 9832     |
|    fps              | 34       |
|    time_elapsed     | 5678     |
|    total_timesteps  | 198736   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.96e-05 |
|    n_updates        | 39683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.5     |
|    ep_rew_mean      | -0.113   |
|    exploration_rate | 0.0122   |
| time/               |          |
|    episodes         | 9836     |
|    fps              | 35       |
|    time_elapsed     | 5679     |
|    total_timesteps  | 198800   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.52e-05 |
|    n_updates        | 39699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.6     |
|    ep_rew_mean      | -0.11    |
|    exploration_rate | 0.011    |
| time/               |          |
|    episodes         | 9840     |
|    fps              | 35       |
|    time_elapsed     | 5679     |
|    total_timesteps  | 198934   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000104 |
|    n_updates        | 39733    |
----------------------------------
Eval num_timesteps=199000, episode_reward=-0.23 +/- 0.16
Episode length: 63.08 +/- 20.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.1     |
|    mean_reward      | -0.232   |
| rollout/            |          |
|    exploration_rate | 0.0104   |
| time/               |          |
|    total_timesteps  | 199000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.45e-05 |
|    n_updates        | 39749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.1     |
|    ep_rew_mean      | -0.0975  |
|    exploration_rate | 0.00959  |
| time/               |          |
|    episodes         | 9844     |
|    fps              | 34       |
|    time_elapsed     | 5694     |
|    total_timesteps  | 199082   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.26e-05 |
|    n_updates        | 39770    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.9     |
|    ep_rew_mean      | -0.111   |
|    exploration_rate | 0.00702  |
| time/               |          |
|    episodes         | 9848     |
|    fps              | 35       |
|    time_elapsed     | 5695     |
|    total_timesteps  | 199357   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.66e-05 |
|    n_updates        | 39839    |
----------------------------------
Eval num_timesteps=199500, episode_reward=-0.25 +/- 0.08
Episode length: 61.62 +/- 19.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.6     |
|    mean_reward      | -0.246   |
| rollout/            |          |
|    exploration_rate | 0.00569  |
| time/               |          |
|    total_timesteps  | 199500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.69e-06 |
|    n_updates        | 39874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.3     |
|    ep_rew_mean      | -0.112   |
|    exploration_rate | 0.00503  |
| time/               |          |
|    episodes         | 9852     |
|    fps              | 34       |
|    time_elapsed     | 5707     |
|    total_timesteps  | 199569   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.23e-05 |
|    n_updates        | 39892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38       |
|    ep_rew_mean      | -0.111   |
|    exploration_rate | 0.00348  |
| time/               |          |
|    episodes         | 9856     |
|    fps              | 34       |
|    time_elapsed     | 5708     |
|    total_timesteps  | 199735   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.79e-05 |
|    n_updates        | 39933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.6     |
|    ep_rew_mean      | -0.11    |
|    exploration_rate | 0.00122  |
| time/               |          |
|    episodes         | 9860     |
|    fps              | 35       |
|    time_elapsed     | 5709     |
|    total_timesteps  | 199977   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 39994    |
----------------------------------
Eval num_timesteps=200000, episode_reward=-0.27 +/- 0.06
Episode length: 68.52 +/- 13.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.5     |
|    mean_reward      | -0.274   |
| rollout/            |          |
|    exploration_rate | 0.00101  |
| time/               |          |
|    total_timesteps  | 200000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.05e-05 |
|    n_updates        | 39999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.8     |
|    ep_rew_mean      | -0.111   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9864     |
|    fps              | 34       |
|    time_elapsed     | 5722     |
|    total_timesteps  | 200261   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.41e-05 |
|    n_updates        | 40065    |
----------------------------------
Eval num_timesteps=200500, episode_reward=-0.04 +/- 0.14
Episode length: 15.90 +/- 0.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.0426  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 200500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.73e-05 |
|    n_updates        | 40124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39       |
|    ep_rew_mean      | -0.115   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9868     |
|    fps              | 35       |
|    time_elapsed     | 5727     |
|    total_timesteps  | 200502   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.007    |
|    n_updates        | 40125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39       |
|    ep_rew_mean      | -0.125   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9872     |
|    fps              | 35       |
|    time_elapsed     | 5728     |
|    total_timesteps  | 200566   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.11e-05 |
|    n_updates        | 40141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.6     |
|    ep_rew_mean      | -0.128   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9876     |
|    fps              | 35       |
|    time_elapsed     | 5729     |
|    total_timesteps  | 200689   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.29e-05 |
|    n_updates        | 40172    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.5     |
|    ep_rew_mean      | -0.131   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9880     |
|    fps              | 35       |
|    time_elapsed     | 5730     |
|    total_timesteps  | 200886   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.48e-05 |
|    n_updates        | 40221    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.1     |
|    ep_rew_mean      | -0.12    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9884     |
|    fps              | 35       |
|    time_elapsed     | 5730     |
|    total_timesteps  | 200953   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.42e-05 |
|    n_updates        | 40238    |
----------------------------------
Eval num_timesteps=201000, episode_reward=-0.06 +/- 0.22
Episode length: 25.08 +/- 17.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 25.1     |
|    mean_reward      | -0.0593  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 201000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.44e-05 |
|    n_updates        | 40249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.1     |
|    ep_rew_mean      | -0.12    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9888     |
|    fps              | 35       |
|    time_elapsed     | 5736     |
|    total_timesteps  | 201017   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.2e-05  |
|    n_updates        | 40254    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.8     |
|    ep_rew_mean      | -0.122   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9892     |
|    fps              | 35       |
|    time_elapsed     | 5737     |
|    total_timesteps  | 201211   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.65e-05 |
|    n_updates        | 40302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.3     |
|    ep_rew_mean      | -0.121   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9896     |
|    fps              | 35       |
|    time_elapsed     | 5738     |
|    total_timesteps  | 201304   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.65e-05 |
|    n_updates        | 40325    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.5     |
|    ep_rew_mean      | -0.103   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9900     |
|    fps              | 35       |
|    time_elapsed     | 5738     |
|    total_timesteps  | 201364   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.81e-05 |
|    n_updates        | 40340    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.4     |
|    ep_rew_mean      | -0.0947  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9904     |
|    fps              | 35       |
|    time_elapsed     | 5739     |
|    total_timesteps  | 201428   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.23e-05 |
|    n_updates        | 40356    |
----------------------------------
Eval num_timesteps=201500, episode_reward=-0.04 +/- 0.26
Episode length: 24.76 +/- 20.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 24.8     |
|    mean_reward      | -0.0381  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 201500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.48e-05 |
|    n_updates        | 40374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.4     |
|    ep_rew_mean      | -0.095   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9908     |
|    fps              | 35       |
|    time_elapsed     | 5745     |
|    total_timesteps  | 201551   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.37e-05 |
|    n_updates        | 40387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36       |
|    ep_rew_mean      | -0.0833  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9912     |
|    fps              | 35       |
|    time_elapsed     | 5746     |
|    total_timesteps  | 201612   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.36e-05 |
|    n_updates        | 40402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.6     |
|    ep_rew_mean      | -0.0755  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9916     |
|    fps              | 35       |
|    time_elapsed     | 5746     |
|    total_timesteps  | 201731   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.12e-05 |
|    n_updates        | 40432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.8     |
|    ep_rew_mean      | -0.0803  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9920     |
|    fps              | 35       |
|    time_elapsed     | 5748     |
|    total_timesteps  | 201972   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00678  |
|    n_updates        | 40492    |
----------------------------------
Eval num_timesteps=202000, episode_reward=-0.29 +/- 0.04
Episode length: 73.08 +/- 9.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.1     |
|    mean_reward      | -0.292   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 202000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.95e-05 |
|    n_updates        | 40499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.6     |
|    ep_rew_mean      | -0.0836  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9924     |
|    fps              | 35       |
|    time_elapsed     | 5761     |
|    total_timesteps  | 202272   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.3e-05  |
|    n_updates        | 40567    |
----------------------------------
Eval num_timesteps=202500, episode_reward=-0.29 +/- 0.03
Episode length: 72.84 +/- 7.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.8     |
|    mean_reward      | -0.291   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 202500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.94e-05 |
|    n_updates        | 40624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.2     |
|    ep_rew_mean      | -0.096   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9928     |
|    fps              | 35       |
|    time_elapsed     | 5774     |
|    total_timesteps  | 202549   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.67e-05 |
|    n_updates        | 40637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.8     |
|    ep_rew_mean      | -0.0944  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9932     |
|    fps              | 35       |
|    time_elapsed     | 5775     |
|    total_timesteps  | 202613   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.56e-05 |
|    n_updates        | 40653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.8     |
|    ep_rew_mean      | -0.104   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9936     |
|    fps              | 35       |
|    time_elapsed     | 5775     |
|    total_timesteps  | 202677   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.42e-05 |
|    n_updates        | 40669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38       |
|    ep_rew_mean      | -0.0914  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9940     |
|    fps              | 35       |
|    time_elapsed     | 5776     |
|    total_timesteps  | 202738   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.82e-05 |
|    n_updates        | 40684    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | -0.0981  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9944     |
|    fps              | 35       |
|    time_elapsed     | 5776     |
|    total_timesteps  | 202802   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.82e-05 |
|    n_updates        | 40700    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.1     |
|    ep_rew_mean      | -0.0896  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9948     |
|    fps              | 35       |
|    time_elapsed     | 5776     |
|    total_timesteps  | 202866   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.74e-05 |
|    n_updates        | 40716    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.6     |
|    ep_rew_mean      | -0.0836  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9952     |
|    fps              | 35       |
|    time_elapsed     | 5777     |
|    total_timesteps  | 202929   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.72e-05 |
|    n_updates        | 40732    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.6     |
|    ep_rew_mean      | -0.0795  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9956     |
|    fps              | 35       |
|    time_elapsed     | 5777     |
|    total_timesteps  | 202993   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.32e-05 |
|    n_updates        | 40748    |
----------------------------------
Eval num_timesteps=203000, episode_reward=0.06 +/- 0.33
Episode length: 15.52 +/- 1.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.5     |
|    mean_reward      | 0.0589   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 203000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000125 |
|    n_updates        | 40749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.8     |
|    ep_rew_mean      | -0.0724  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9960     |
|    fps              | 35       |
|    time_elapsed     | 5782     |
|    total_timesteps  | 203058   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.56e-05 |
|    n_updates        | 40764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.4     |
|    ep_rew_mean      | -0.0707  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9964     |
|    fps              | 35       |
|    time_elapsed     | 5783     |
|    total_timesteps  | 203300   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.88e-05 |
|    n_updates        | 40824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.8     |
|    ep_rew_mean      | -0.0582  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9968     |
|    fps              | 35       |
|    time_elapsed     | 5784     |
|    total_timesteps  | 203478   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.94e-05 |
|    n_updates        | 40869    |
----------------------------------
Eval num_timesteps=203500, episode_reward=-0.00 +/- 0.24
Episode length: 15.84 +/- 0.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | -0.0023  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 203500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.86e-05 |
|    n_updates        | 40874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.7     |
|    ep_rew_mean      | -0.048   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9972     |
|    fps              | 35       |
|    time_elapsed     | 5788     |
|    total_timesteps  | 203538   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.7e-05  |
|    n_updates        | 40884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.1     |
|    ep_rew_mean      | -0.0456  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9976     |
|    fps              | 35       |
|    time_elapsed     | 5789     |
|    total_timesteps  | 203602   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.21e-05 |
|    n_updates        | 40900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.8     |
|    ep_rew_mean      | -0.0403  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9980     |
|    fps              | 35       |
|    time_elapsed     | 5789     |
|    total_timesteps  | 203666   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.09e-05 |
|    n_updates        | 40916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.8     |
|    ep_rew_mean      | -0.0502  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9984     |
|    fps              | 35       |
|    time_elapsed     | 5790     |
|    total_timesteps  | 203730   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.18e-05 |
|    n_updates        | 40932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.8     |
|    ep_rew_mean      | -0.0502  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9988     |
|    fps              | 35       |
|    time_elapsed     | 5790     |
|    total_timesteps  | 203794   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.42e-05 |
|    n_updates        | 40948    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.045   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9992     |
|    fps              | 35       |
|    time_elapsed     | 5791     |
|    total_timesteps  | 203859   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.36e-05 |
|    n_updates        | 40964    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.2     |
|    ep_rew_mean      | -0.0439  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 9996     |
|    fps              | 35       |
|    time_elapsed     | 5791     |
|    total_timesteps  | 203923   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.65e-05 |
|    n_updates        | 40980    |
----------------------------------
Eval num_timesteps=204000, episode_reward=-0.30 +/- 0.00
Episode length: 75.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 75       |
|    mean_reward      | -0.3     |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 204000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.9e-05  |
|    n_updates        | 40999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28       |
|    ep_rew_mean      | -0.0612  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10000    |
|    fps              | 35       |
|    time_elapsed     | 5804     |
|    total_timesteps  | 204166   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.1e-05  |
|    n_updates        | 41041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30       |
|    ep_rew_mean      | -0.0593  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10004    |
|    fps              | 35       |
|    time_elapsed     | 5806     |
|    total_timesteps  | 204431   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.09e-05 |
|    n_updates        | 41107    |
----------------------------------
Eval num_timesteps=204500, episode_reward=-0.16 +/- 0.26
Episode length: 54.16 +/- 22.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.2     |
|    mean_reward      | -0.156   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 204500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.51e-05 |
|    n_updates        | 41124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30       |
|    ep_rew_mean      | -0.0593  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10008    |
|    fps              | 35       |
|    time_elapsed     | 5817     |
|    total_timesteps  | 204553   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.45e-05 |
|    n_updates        | 41138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.1     |
|    ep_rew_mean      | -0.0695  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10012    |
|    fps              | 35       |
|    time_elapsed     | 5818     |
|    total_timesteps  | 204621   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000117 |
|    n_updates        | 41155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.6     |
|    ep_rew_mean      | -0.0774  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10016    |
|    fps              | 35       |
|    time_elapsed     | 5818     |
|    total_timesteps  | 204686   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.14e-05 |
|    n_updates        | 41171    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.8     |
|    ep_rew_mean      | -0.0704  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10020    |
|    fps              | 35       |
|    time_elapsed     | 5819     |
|    total_timesteps  | 204754   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.49e-05 |
|    n_updates        | 41188    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.6     |
|    ep_rew_mean      | -0.0657  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10024    |
|    fps              | 35       |
|    time_elapsed     | 5820     |
|    total_timesteps  | 204936   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.3e-05  |
|    n_updates        | 41233    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.5     |
|    ep_rew_mean      | -0.047   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10028    |
|    fps              | 35       |
|    time_elapsed     | 5820     |
|    total_timesteps  | 204996   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.13e-05 |
|    n_updates        | 41248    |
----------------------------------
Eval num_timesteps=205000, episode_reward=0.04 +/- 0.30
Episode length: 15.62 +/- 1.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.6     |
|    mean_reward      | 0.0385   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 205000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00704  |
|    n_updates        | 41249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.1     |
|    ep_rew_mean      | -0.0493  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10032    |
|    fps              | 35       |
|    time_elapsed     | 5825     |
|    total_timesteps  | 205119   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.33e-05 |
|    n_updates        | 41279    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0521  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10036    |
|    fps              | 35       |
|    time_elapsed     | 5826     |
|    total_timesteps  | 205252   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.56e-06 |
|    n_updates        | 41312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0624  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10040    |
|    fps              | 35       |
|    time_elapsed     | 5826     |
|    total_timesteps  | 205320   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.72e-05 |
|    n_updates        | 41329    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0624  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10044    |
|    fps              | 35       |
|    time_elapsed     | 5827     |
|    total_timesteps  | 205384   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.76e-05 |
|    n_updates        | 41345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.8     |
|    ep_rew_mean      | -0.0523  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10048    |
|    fps              | 35       |
|    time_elapsed     | 5827     |
|    total_timesteps  | 205445   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.23e-06 |
|    n_updates        | 41361    |
----------------------------------
Eval num_timesteps=205500, episode_reward=-0.26 +/- 0.08
Episode length: 63.92 +/- 20.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.9     |
|    mean_reward      | -0.255   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 205500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.6e-05  |
|    n_updates        | 41374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0568  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10052    |
|    fps              | 35       |
|    time_elapsed     | 5841     |
|    total_timesteps  | 205622   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.33e-05 |
|    n_updates        | 41405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0467  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10056    |
|    fps              | 35       |
|    time_elapsed     | 5842     |
|    total_timesteps  | 205683   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.68e-05 |
|    n_updates        | 41420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0365  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10060    |
|    fps              | 35       |
|    time_elapsed     | 5842     |
|    total_timesteps  | 205744   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.74e-05 |
|    n_updates        | 41435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.1     |
|    ep_rew_mean      | -0.0294  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10064    |
|    fps              | 35       |
|    time_elapsed     | 5842     |
|    total_timesteps  | 205808   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.13e-05 |
|    n_updates        | 41451    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.0348  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10068    |
|    fps              | 35       |
|    time_elapsed     | 5843     |
|    total_timesteps  | 205872   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.15e-05 |
|    n_updates        | 41467    |
----------------------------------
Eval num_timesteps=206000, episode_reward=-0.07 +/- 0.35
Episode length: 48.06 +/- 23.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.1     |
|    mean_reward      | -0.0715  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 206000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.18e-05 |
|    n_updates        | 41499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.2     |
|    ep_rew_mean      | -0.0498  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10072    |
|    fps              | 35       |
|    time_elapsed     | 5852     |
|    total_timesteps  | 206056   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.55e-05 |
|    n_updates        | 41513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0503  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10076    |
|    fps              | 35       |
|    time_elapsed     | 5852     |
|    total_timesteps  | 206134   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.33e-05 |
|    n_updates        | 41533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0503  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10080    |
|    fps              | 35       |
|    time_elapsed     | 5853     |
|    total_timesteps  | 206198   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.26e-05 |
|    n_updates        | 41549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0503  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10084    |
|    fps              | 35       |
|    time_elapsed     | 5853     |
|    total_timesteps  | 206262   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.63e-05 |
|    n_updates        | 41565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0402  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10088    |
|    fps              | 35       |
|    time_elapsed     | 5854     |
|    total_timesteps  | 206323   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.37e-05 |
|    n_updates        | 41580    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0402  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10092    |
|    fps              | 35       |
|    time_elapsed     | 5854     |
|    total_timesteps  | 206387   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.58e-05 |
|    n_updates        | 41596    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.3     |
|    ep_rew_mean      | -0.0404  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10096    |
|    fps              | 35       |
|    time_elapsed     | 5855     |
|    total_timesteps  | 206457   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.51e-05 |
|    n_updates        | 41614    |
----------------------------------
Eval num_timesteps=206500, episode_reward=-0.09 +/- 0.28
Episode length: 43.42 +/- 22.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.4     |
|    mean_reward      | -0.0929  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 206500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.86e-06 |
|    n_updates        | 41624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.0351  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10100    |
|    fps              | 35       |
|    time_elapsed     | 5865     |
|    total_timesteps  | 206567   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00775  |
|    n_updates        | 41641    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22       |
|    ep_rew_mean      | -0.037   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10104    |
|    fps              | 35       |
|    time_elapsed     | 5865     |
|    total_timesteps  | 206631   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.56e-05 |
|    n_updates        | 41657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0245  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10108    |
|    fps              | 35       |
|    time_elapsed     | 5866     |
|    total_timesteps  | 206690   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.63e-05 |
|    n_updates        | 41672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0243  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10112    |
|    fps              | 35       |
|    time_elapsed     | 5866     |
|    total_timesteps  | 206754   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.63e-05 |
|    n_updates        | 41688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.5     |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10116    |
|    fps              | 35       |
|    time_elapsed     | 5867     |
|    total_timesteps  | 206832   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.42e-05 |
|    n_updates        | 41707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22       |
|    ep_rew_mean      | -0.0168  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10120    |
|    fps              | 35       |
|    time_elapsed     | 5867     |
|    total_timesteps  | 206950   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.94e-06 |
|    n_updates        | 41737    |
----------------------------------
Eval num_timesteps=207000, episode_reward=0.02 +/- 0.27
Episode length: 16.42 +/- 1.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | 0.0153   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 207000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.78e-05 |
|    n_updates        | 41749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10124    |
|    fps              | 35       |
|    time_elapsed     | 5872     |
|    total_timesteps  | 207015   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.49e-06 |
|    n_updates        | 41753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10128    |
|    fps              | 35       |
|    time_elapsed     | 5872     |
|    total_timesteps  | 207075   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.75e-05 |
|    n_updates        | 41768    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.00976 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10132    |
|    fps              | 35       |
|    time_elapsed     | 5873     |
|    total_timesteps  | 207139   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.37e-05 |
|    n_updates        | 41784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.00699 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10136    |
|    fps              | 35       |
|    time_elapsed     | 5873     |
|    total_timesteps  | 207203   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.2e-05  |
|    n_updates        | 41800    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0092  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10140    |
|    fps              | 35       |
|    time_elapsed     | 5874     |
|    total_timesteps  | 207326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.92e-05 |
|    n_updates        | 41831    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0116  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10144    |
|    fps              | 35       |
|    time_elapsed     | 5875     |
|    total_timesteps  | 207449   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.4e-05  |
|    n_updates        | 41862    |
----------------------------------
Eval num_timesteps=207500, episode_reward=-0.02 +/- 0.20
Episode length: 15.86 +/- 0.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.0224  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 207500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.49e-05 |
|    n_updates        | 41874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0217  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10148    |
|    fps              | 35       |
|    time_elapsed     | 5879     |
|    total_timesteps  | 207513   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.34e-05 |
|    n_updates        | 41878    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.00703 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10152    |
|    fps              | 35       |
|    time_elapsed     | 5879     |
|    total_timesteps  | 207573   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.83e-05 |
|    n_updates        | 41893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0172  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10156    |
|    fps              | 35       |
|    time_elapsed     | 5880     |
|    total_timesteps  | 207637   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.12e-05 |
|    n_updates        | 41909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0172  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10160    |
|    fps              | 35       |
|    time_elapsed     | 5880     |
|    total_timesteps  | 207697   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.82e-05 |
|    n_updates        | 41924    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0172  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10164    |
|    fps              | 35       |
|    time_elapsed     | 5881     |
|    total_timesteps  | 207761   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.17e-05 |
|    n_updates        | 41940    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.00706 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10168    |
|    fps              | 35       |
|    time_elapsed     | 5881     |
|    total_timesteps  | 207823   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.95e-05 |
|    n_updates        | 41955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.00224 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10172    |
|    fps              | 35       |
|    time_elapsed     | 5882     |
|    total_timesteps  | 207887   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.98e-05 |
|    n_updates        | 41971    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00168 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10176    |
|    fps              | 35       |
|    time_elapsed     | 5882     |
|    total_timesteps  | 207951   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.21e-05 |
|    n_updates        | 41987    |
----------------------------------
Eval num_timesteps=208000, episode_reward=-0.02 +/- 0.20
Episode length: 15.90 +/- 0.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.0226  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 208000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.21e-05 |
|    n_updates        | 41999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00168 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10180    |
|    fps              | 35       |
|    time_elapsed     | 5886     |
|    total_timesteps  | 208015   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.53e-05 |
|    n_updates        | 42003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.00168 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10184    |
|    fps              | 35       |
|    time_elapsed     | 5887     |
|    total_timesteps  | 208079   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00689  |
|    n_updates        | 42019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0118  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10188    |
|    fps              | 35       |
|    time_elapsed     | 5888     |
|    total_timesteps  | 208143   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.98e-05 |
|    n_updates        | 42035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00477 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10192    |
|    fps              | 35       |
|    time_elapsed     | 5888     |
|    total_timesteps  | 208281   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.2e-05  |
|    n_updates        | 42070    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.00774 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10196    |
|    fps              | 35       |
|    time_elapsed     | 5889     |
|    total_timesteps  | 208425   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.47e-05 |
|    n_updates        | 42106    |
----------------------------------
Eval num_timesteps=208500, episode_reward=-0.03 +/- 0.20
Episode length: 16.98 +/- 2.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17       |
|    mean_reward      | -0.0269  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 208500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.16e-05 |
|    n_updates        | 42124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.00341  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10200    |
|    fps              | 35       |
|    time_elapsed     | 5894     |
|    total_timesteps  | 208506   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.92e-05 |
|    n_updates        | 42126    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.00293  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10204    |
|    fps              | 35       |
|    time_elapsed     | 5894     |
|    total_timesteps  | 208582   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.63e-05 |
|    n_updates        | 42145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.0123   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10208    |
|    fps              | 35       |
|    time_elapsed     | 5895     |
|    total_timesteps  | 208656   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.84e-05 |
|    n_updates        | 42163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.0123   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10212    |
|    fps              | 35       |
|    time_elapsed     | 5895     |
|    total_timesteps  | 208720   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00759  |
|    n_updates        | 42179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.00289  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10216    |
|    fps              | 35       |
|    time_elapsed     | 5896     |
|    total_timesteps  | 208784   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.47e-05 |
|    n_updates        | 42195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00505  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10220    |
|    fps              | 35       |
|    time_elapsed     | 5896     |
|    total_timesteps  | 208848   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.75e-05 |
|    n_updates        | 42211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0134   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10224    |
|    fps              | 35       |
|    time_elapsed     | 5897     |
|    total_timesteps  | 208955   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.16e-05 |
|    n_updates        | 42238    |
----------------------------------
Eval num_timesteps=209000, episode_reward=-0.24 +/- 0.09
Episode length: 58.88 +/- 22.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.9     |
|    mean_reward      | -0.235   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 209000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.6e-05  |
|    n_updates        | 42249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.00024  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10228    |
|    fps              | 35       |
|    time_elapsed     | 5908     |
|    total_timesteps  | 209093   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.02e-05 |
|    n_updates        | 42273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.00237 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10232    |
|    fps              | 35       |
|    time_elapsed     | 5908     |
|    total_timesteps  | 209222   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.82e-05 |
|    n_updates        | 42305    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.00237 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10236    |
|    fps              | 35       |
|    time_elapsed     | 5909     |
|    total_timesteps  | 209286   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.15e-05 |
|    n_updates        | 42321    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.0101   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10240    |
|    fps              | 35       |
|    time_elapsed     | 5909     |
|    total_timesteps  | 209348   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.88e-05 |
|    n_updates        | 42336    |
----------------------------------
Eval num_timesteps=209500, episode_reward=-0.17 +/- 0.26
Episode length: 57.40 +/- 23.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.4     |
|    mean_reward      | -0.169   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 209500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.2e-05  |
|    n_updates        | 42374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | 0.00773  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10244    |
|    fps              | 35       |
|    time_elapsed     | 5922     |
|    total_timesteps  | 209530   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.37e-05 |
|    n_updates        | 42382    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | 0.00083  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10248    |
|    fps              | 35       |
|    time_elapsed     | 5924     |
|    total_timesteps  | 209766   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.3e-05  |
|    n_updates        | 42441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10252    |
|    fps              | 35       |
|    time_elapsed     | 5925     |
|    total_timesteps  | 209952   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.47e-06 |
|    n_updates        | 42487    |
----------------------------------
Eval num_timesteps=210000, episode_reward=-0.25 +/- 0.09
Episode length: 62.48 +/- 21.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.5     |
|    mean_reward      | -0.25    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 210000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.13e-05 |
|    n_updates        | 42499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | -0.019   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10256    |
|    fps              | 35       |
|    time_elapsed     | 5939     |
|    total_timesteps  | 210134   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.62e-05 |
|    n_updates        | 42533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | -0.0291  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10260    |
|    fps              | 35       |
|    time_elapsed     | 5940     |
|    total_timesteps  | 210198   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.41e-05 |
|    n_updates        | 42549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | -0.0291  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10264    |
|    fps              | 35       |
|    time_elapsed     | 5940     |
|    total_timesteps  | 210262   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.65e-05 |
|    n_updates        | 42565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | -0.0392  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10268    |
|    fps              | 35       |
|    time_elapsed     | 5941     |
|    total_timesteps  | 210326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.9e-05  |
|    n_updates        | 42581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25       |
|    ep_rew_mean      | -0.0392  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10272    |
|    fps              | 35       |
|    time_elapsed     | 5941     |
|    total_timesteps  | 210390   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.98e-05 |
|    n_updates        | 42597    |
----------------------------------
Eval num_timesteps=210500, episode_reward=-0.11 +/- 0.17
Episode length: 31.50 +/- 17.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 31.5     |
|    mean_reward      | -0.105   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 210500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.3e-05  |
|    n_updates        | 42624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0418  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10276    |
|    fps              | 35       |
|    time_elapsed     | 5949     |
|    total_timesteps  | 210519   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.33e-05 |
|    n_updates        | 42629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0418  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10280    |
|    fps              | 35       |
|    time_elapsed     | 5949     |
|    total_timesteps  | 210583   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.67e-05 |
|    n_updates        | 42645    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0418  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10284    |
|    fps              | 35       |
|    time_elapsed     | 5950     |
|    total_timesteps  | 210647   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.73e-05 |
|    n_updates        | 42661    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0418  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10288    |
|    fps              | 35       |
|    time_elapsed     | 5950     |
|    total_timesteps  | 210711   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.29e-05 |
|    n_updates        | 42677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.9     |
|    ep_rew_mean      | -0.0489  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10292    |
|    fps              | 35       |
|    time_elapsed     | 5951     |
|    total_timesteps  | 210775   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00699  |
|    n_updates        | 42693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.0457  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10296    |
|    fps              | 35       |
|    time_elapsed     | 5951     |
|    total_timesteps  | 210840   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.3e-06  |
|    n_updates        | 42709    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.055   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10300    |
|    fps              | 35       |
|    time_elapsed     | 5951     |
|    total_timesteps  | 210904   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.05e-05 |
|    n_updates        | 42725    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.0545  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10304    |
|    fps              | 35       |
|    time_elapsed     | 5952     |
|    total_timesteps  | 210968   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.32e-05 |
|    n_updates        | 42741    |
----------------------------------
Eval num_timesteps=211000, episode_reward=-0.00 +/- 0.24
Episode length: 16.46 +/- 1.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.5     |
|    mean_reward      | -0.00482 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 211000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00756  |
|    n_updates        | 42749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.064   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10308    |
|    fps              | 35       |
|    time_elapsed     | 5956     |
|    total_timesteps  | 211028   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.35e-06 |
|    n_updates        | 42756    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.064   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10312    |
|    fps              | 35       |
|    time_elapsed     | 5957     |
|    total_timesteps  | 211092   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.84e-05 |
|    n_updates        | 42772    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.0653  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10316    |
|    fps              | 35       |
|    time_elapsed     | 5957     |
|    total_timesteps  | 211190   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.79e-05 |
|    n_updates        | 42797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.1     |
|    ep_rew_mean      | -0.0653  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10320    |
|    fps              | 35       |
|    time_elapsed     | 5958     |
|    total_timesteps  | 211254   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.78e-05 |
|    n_updates        | 42813    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.6     |
|    ep_rew_mean      | -0.0737  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10324    |
|    fps              | 35       |
|    time_elapsed     | 5958     |
|    total_timesteps  | 211320   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00767  |
|    n_updates        | 42829    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.9     |
|    ep_rew_mean      | -0.0707  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10328    |
|    fps              | 35       |
|    time_elapsed     | 5959     |
|    total_timesteps  | 211384   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.18e-05 |
|    n_updates        | 42845    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.3     |
|    ep_rew_mean      | -0.0681  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10332    |
|    fps              | 35       |
|    time_elapsed     | 5959     |
|    total_timesteps  | 211448   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.29e-05 |
|    n_updates        | 42861    |
----------------------------------
Eval num_timesteps=211500, episode_reward=-0.05 +/- 0.24
Episode length: 27.52 +/- 14.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 27.5     |
|    mean_reward      | -0.0491  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 211500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.9e-06  |
|    n_updates        | 42874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | -0.059   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10336    |
|    fps              | 35       |
|    time_elapsed     | 5966     |
|    total_timesteps  | 211534   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.52e-05 |
|    n_updates        | 42883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.5     |
|    ep_rew_mean      | -0.0691  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10340    |
|    fps              | 35       |
|    time_elapsed     | 5966     |
|    total_timesteps  | 211598   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.11e-05 |
|    n_updates        | 42899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.6     |
|    ep_rew_mean      | -0.0654  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10344    |
|    fps              | 35       |
|    time_elapsed     | 5967     |
|    total_timesteps  | 211688   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.47e-05 |
|    n_updates        | 42921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0483  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10348    |
|    fps              | 35       |
|    time_elapsed     | 5967     |
|    total_timesteps  | 211748   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.57e-05 |
|    n_updates        | 42936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0434  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10352    |
|    fps              | 35       |
|    time_elapsed     | 5968     |
|    total_timesteps  | 211812   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.09e-05 |
|    n_updates        | 42952    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0387  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10356    |
|    fps              | 35       |
|    time_elapsed     | 5968     |
|    total_timesteps  | 211876   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.32e-05 |
|    n_updates        | 42968    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0391  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10360    |
|    fps              | 35       |
|    time_elapsed     | 5969     |
|    total_timesteps  | 211950   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.62e-06 |
|    n_updates        | 42987    |
----------------------------------
Eval num_timesteps=212000, episode_reward=0.02 +/- 0.27
Episode length: 15.76 +/- 0.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.018    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 212000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.92e-05 |
|    n_updates        | 42999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0391  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10364    |
|    fps              | 35       |
|    time_elapsed     | 5973     |
|    total_timesteps  | 212014   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.89e-05 |
|    n_updates        | 43003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.029   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10368    |
|    fps              | 35       |
|    time_elapsed     | 5973     |
|    total_timesteps  | 212075   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.9e-05  |
|    n_updates        | 43018    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.029   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10372    |
|    fps              | 35       |
|    time_elapsed     | 5974     |
|    total_timesteps  | 212139   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.13e-06 |
|    n_updates        | 43034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10376    |
|    fps              | 35       |
|    time_elapsed     | 5974     |
|    total_timesteps  | 212219   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.76e-05 |
|    n_updates        | 43054    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0271  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10380    |
|    fps              | 35       |
|    time_elapsed     | 5975     |
|    total_timesteps  | 212285   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.85e-05 |
|    n_updates        | 43071    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0271  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10384    |
|    fps              | 35       |
|    time_elapsed     | 5975     |
|    total_timesteps  | 212349   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000126 |
|    n_updates        | 43087    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0289  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10388    |
|    fps              | 35       |
|    time_elapsed     | 5976     |
|    total_timesteps  | 212458   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.4e-05  |
|    n_updates        | 43114    |
----------------------------------
Eval num_timesteps=212500, episode_reward=0.02 +/- 0.27
Episode length: 15.76 +/- 0.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.018    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 212500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.6e-05  |
|    n_updates        | 43124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0289  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10392    |
|    fps              | 35       |
|    time_elapsed     | 5980     |
|    total_timesteps  | 212522   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.27e-05 |
|    n_updates        | 43130    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0288  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10396    |
|    fps              | 35       |
|    time_elapsed     | 5981     |
|    total_timesteps  | 212586   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.08e-05 |
|    n_updates        | 43146    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.029   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10400    |
|    fps              | 35       |
|    time_elapsed     | 5981     |
|    total_timesteps  | 212654   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.71e-05 |
|    n_updates        | 43163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.029   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10404    |
|    fps              | 35       |
|    time_elapsed     | 5982     |
|    total_timesteps  | 212718   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.79e-05 |
|    n_updates        | 43179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.029   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10408    |
|    fps              | 35       |
|    time_elapsed     | 5982     |
|    total_timesteps  | 212779   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.43e-05 |
|    n_updates        | 43194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.029   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10412    |
|    fps              | 35       |
|    time_elapsed     | 5982     |
|    total_timesteps  | 212843   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.89e-05 |
|    n_updates        | 43210    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0176  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10416    |
|    fps              | 35       |
|    time_elapsed     | 5983     |
|    total_timesteps  | 212907   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.88e-05 |
|    n_updates        | 43226    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10420    |
|    fps              | 35       |
|    time_elapsed     | 5983     |
|    total_timesteps  | 212973   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.5e-05  |
|    n_updates        | 43243    |
----------------------------------
Eval num_timesteps=213000, episode_reward=-0.02 +/- 0.20
Episode length: 15.88 +/- 0.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.0225  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 213000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.02e-05 |
|    n_updates        | 43249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00756 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10424    |
|    fps              | 35       |
|    time_elapsed     | 5987     |
|    total_timesteps  | 213035   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.74e-05 |
|    n_updates        | 43258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00756 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10428    |
|    fps              | 35       |
|    time_elapsed     | 5988     |
|    total_timesteps  | 213099   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.17e-05 |
|    n_updates        | 43274    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00756 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10432    |
|    fps              | 35       |
|    time_elapsed     | 5989     |
|    total_timesteps  | 213163   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.84e-05 |
|    n_updates        | 43290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0168  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10436    |
|    fps              | 35       |
|    time_elapsed     | 5989     |
|    total_timesteps  | 213231   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00709  |
|    n_updates        | 43307    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0091  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10440    |
|    fps              | 35       |
|    time_elapsed     | 5990     |
|    total_timesteps  | 213352   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.96e-05 |
|    n_updates        | 43337    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00806 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10444    |
|    fps              | 35       |
|    time_elapsed     | 5990     |
|    total_timesteps  | 213416   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00695  |
|    n_updates        | 43353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.00828 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10448    |
|    fps              | 35       |
|    time_elapsed     | 5991     |
|    total_timesteps  | 213482   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.12e-05 |
|    n_updates        | 43370    |
----------------------------------
Eval num_timesteps=213500, episode_reward=-0.23 +/- 0.10
Episode length: 57.70 +/- 25.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.7     |
|    mean_reward      | -0.23    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 213500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.47e-05 |
|    n_updates        | 43374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.011   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10452    |
|    fps              | 35       |
|    time_elapsed     | 6003     |
|    total_timesteps  | 213613   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.64e-05 |
|    n_updates        | 43403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.011   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10456    |
|    fps              | 35       |
|    time_elapsed     | 6004     |
|    total_timesteps  | 213677   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.79e-05 |
|    n_updates        | 43419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0106  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10460    |
|    fps              | 35       |
|    time_elapsed     | 6004     |
|    total_timesteps  | 213741   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00744  |
|    n_updates        | 43435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0106  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10464    |
|    fps              | 35       |
|    time_elapsed     | 6005     |
|    total_timesteps  | 213805   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.46e-05 |
|    n_updates        | 43451    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0207  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10468    |
|    fps              | 35       |
|    time_elapsed     | 6005     |
|    total_timesteps  | 213869   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.53e-05 |
|    n_updates        | 43467    |
----------------------------------
Eval num_timesteps=214000, episode_reward=-0.04 +/- 0.36
Episode length: 44.32 +/- 22.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.3     |
|    mean_reward      | -0.0364  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 214000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.77e-05 |
|    n_updates        | 43499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0245  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10472    |
|    fps              | 35       |
|    time_elapsed     | 6014     |
|    total_timesteps  | 214028   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.84e-05 |
|    n_updates        | 43506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10476    |
|    fps              | 35       |
|    time_elapsed     | 6016     |
|    total_timesteps  | 214261   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.15e-05 |
|    n_updates        | 43565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0306  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10480    |
|    fps              | 35       |
|    time_elapsed     | 6016     |
|    total_timesteps  | 214325   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 43581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10484    |
|    fps              | 35       |
|    time_elapsed     | 6016     |
|    total_timesteps  | 214382   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.75e-06 |
|    n_updates        | 43595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.9     |
|    ep_rew_mean      | -0.00844 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10488    |
|    fps              | 35       |
|    time_elapsed     | 6017     |
|    total_timesteps  | 214446   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.95e-05 |
|    n_updates        | 43611    |
----------------------------------
Eval num_timesteps=214500, episode_reward=-0.14 +/- 0.17
Episode length: 40.98 +/- 23.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41       |
|    mean_reward      | -0.143   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 214500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.3e-05  |
|    n_updates        | 43624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10492    |
|    fps              | 35       |
|    time_elapsed     | 6027     |
|    total_timesteps  | 214660   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0069   |
|    n_updates        | 43664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.1     |
|    ep_rew_mean      | -0.0174  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10496    |
|    fps              | 35       |
|    time_elapsed     | 6028     |
|    total_timesteps  | 214799   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.11e-05 |
|    n_updates        | 43699    |
----------------------------------
Eval num_timesteps=215000, episode_reward=-0.24 +/- 0.10
Episode length: 59.52 +/- 23.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.5     |
|    mean_reward      | -0.238   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 215000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.37e-05 |
|    n_updates        | 43749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.6     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10500    |
|    fps              | 35       |
|    time_elapsed     | 6038     |
|    total_timesteps  | 215014   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.99e-05 |
|    n_updates        | 43753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10504    |
|    fps              | 35       |
|    time_elapsed     | 6039     |
|    total_timesteps  | 215115   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.8e-05  |
|    n_updates        | 43778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10508    |
|    fps              | 35       |
|    time_elapsed     | 6040     |
|    total_timesteps  | 215175   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.01e-05 |
|    n_updates        | 43793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.7     |
|    ep_rew_mean      | -0.0216  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10512    |
|    fps              | 35       |
|    time_elapsed     | 6041     |
|    total_timesteps  | 215409   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00763  |
|    n_updates        | 43852    |
----------------------------------
Eval num_timesteps=215500, episode_reward=-0.00 +/- 0.24
Episode length: 15.82 +/- 0.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | -0.00228 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 215500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.42e-05 |
|    n_updates        | 43874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0328  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10516    |
|    fps              | 35       |
|    time_elapsed     | 6046     |
|    total_timesteps  | 215501   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.31e-05 |
|    n_updates        | 43875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0327  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10520    |
|    fps              | 35       |
|    time_elapsed     | 6046     |
|    total_timesteps  | 215565   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.87e-05 |
|    n_updates        | 43891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0327  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10524    |
|    fps              | 35       |
|    time_elapsed     | 6047     |
|    total_timesteps  | 215627   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.94e-05 |
|    n_updates        | 43906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0328  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10528    |
|    fps              | 35       |
|    time_elapsed     | 6047     |
|    total_timesteps  | 215695   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.47e-05 |
|    n_updates        | 43923    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0328  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10532    |
|    fps              | 35       |
|    time_elapsed     | 6048     |
|    total_timesteps  | 215759   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.22e-05 |
|    n_updates        | 43939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10536    |
|    fps              | 35       |
|    time_elapsed     | 6048     |
|    total_timesteps  | 215821   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.87e-05 |
|    n_updates        | 43955    |
----------------------------------
Eval num_timesteps=216000, episode_reward=0.02 +/- 0.27
Episode length: 16.22 +/- 1.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.2     |
|    mean_reward      | 0.0161   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 216000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00694  |
|    n_updates        | 43999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.5     |
|    ep_rew_mean      | -0.0351  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10540    |
|    fps              | 35       |
|    time_elapsed     | 6053     |
|    total_timesteps  | 216003   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.77e-05 |
|    n_updates        | 44000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.8     |
|    ep_rew_mean      | -0.0361  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10544    |
|    fps              | 35       |
|    time_elapsed     | 6054     |
|    total_timesteps  | 216091   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.36e-05 |
|    n_updates        | 44022    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.046   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10548    |
|    fps              | 35       |
|    time_elapsed     | 6054     |
|    total_timesteps  | 216155   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.14e-05 |
|    n_updates        | 44038    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0435  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10552    |
|    fps              | 35       |
|    time_elapsed     | 6055     |
|    total_timesteps  | 216225   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.07e-05 |
|    n_updates        | 44056    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0458  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10556    |
|    fps              | 35       |
|    time_elapsed     | 6055     |
|    total_timesteps  | 216347   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.02e-05 |
|    n_updates        | 44086    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0458  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10560    |
|    fps              | 35       |
|    time_elapsed     | 6056     |
|    total_timesteps  | 216411   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.64e-05 |
|    n_updates        | 44102    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.7     |
|    ep_rew_mean      | -0.0458  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10564    |
|    fps              | 35       |
|    time_elapsed     | 6056     |
|    total_timesteps  | 216475   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.12e-05 |
|    n_updates        | 44118    |
----------------------------------
Eval num_timesteps=216500, episode_reward=-0.14 +/- 0.18
Episode length: 40.64 +/- 24.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.6     |
|    mean_reward      | -0.142   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 216500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.47e-05 |
|    n_updates        | 44124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.9     |
|    ep_rew_mean      | -0.0366  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10568    |
|    fps              | 35       |
|    time_elapsed     | 6065     |
|    total_timesteps  | 216559   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00707  |
|    n_updates        | 44139    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0329  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10572    |
|    fps              | 35       |
|    time_elapsed     | 6066     |
|    total_timesteps  | 216625   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.16e-05 |
|    n_updates        | 44156    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.3     |
|    ep_rew_mean      | -0.0262  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10576    |
|    fps              | 35       |
|    time_elapsed     | 6066     |
|    total_timesteps  | 216689   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0071   |
|    n_updates        | 44172    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.3     |
|    ep_rew_mean      | -0.0262  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10580    |
|    fps              | 35       |
|    time_elapsed     | 6067     |
|    total_timesteps  | 216753   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.58e-05 |
|    n_updates        | 44188    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.6     |
|    ep_rew_mean      | -0.0475  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10584    |
|    fps              | 35       |
|    time_elapsed     | 6067     |
|    total_timesteps  | 216843   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.91e-05 |
|    n_updates        | 44210    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.6     |
|    ep_rew_mean      | -0.0475  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10588    |
|    fps              | 35       |
|    time_elapsed     | 6068     |
|    total_timesteps  | 216907   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00771  |
|    n_updates        | 44226    |
----------------------------------
Eval num_timesteps=217000, episode_reward=-0.21 +/- 0.16
Episode length: 57.36 +/- 21.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.4     |
|    mean_reward      | -0.209   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 217000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.89e-05 |
|    n_updates        | 44249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.051   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10592    |
|    fps              | 35       |
|    time_elapsed     | 6079     |
|    total_timesteps  | 217207   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.11e-05 |
|    n_updates        | 44301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.9     |
|    ep_rew_mean      | -0.0487  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10596    |
|    fps              | 35       |
|    time_elapsed     | 6079     |
|    total_timesteps  | 217290   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00704  |
|    n_updates        | 44322    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.054   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10600    |
|    fps              | 35       |
|    time_elapsed     | 6080     |
|    total_timesteps  | 217386   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.09e-05 |
|    n_updates        | 44346    |
----------------------------------
Eval num_timesteps=217500, episode_reward=0.05 +/- 0.34
Episode length: 18.20 +/- 11.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.2     |
|    mean_reward      | 0.0483   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 217500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.22e-05 |
|    n_updates        | 44374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.0547  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10604    |
|    fps              | 35       |
|    time_elapsed     | 6085     |
|    total_timesteps  | 217506   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.63e-05 |
|    n_updates        | 44376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.0649  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10608    |
|    fps              | 35       |
|    time_elapsed     | 6086     |
|    total_timesteps  | 217570   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.26e-05 |
|    n_updates        | 44392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.2     |
|    ep_rew_mean      | -0.0479  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10612    |
|    fps              | 35       |
|    time_elapsed     | 6086     |
|    total_timesteps  | 217631   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.25e-05 |
|    n_updates        | 44407    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | -0.0468  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10616    |
|    fps              | 35       |
|    time_elapsed     | 6087     |
|    total_timesteps  | 217695   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.95e-05 |
|    n_updates        | 44423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.4     |
|    ep_rew_mean      | -0.0487  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10620    |
|    fps              | 35       |
|    time_elapsed     | 6087     |
|    total_timesteps  | 217807   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.33e-05 |
|    n_updates        | 44451    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.1     |
|    ep_rew_mean      | -0.0614  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10624    |
|    fps              | 35       |
|    time_elapsed     | 6088     |
|    total_timesteps  | 217935   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.23e-05 |
|    n_updates        | 44483    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23       |
|    ep_rew_mean      | -0.0612  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10628    |
|    fps              | 35       |
|    time_elapsed     | 6089     |
|    total_timesteps  | 217999   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.54e-05 |
|    n_updates        | 44499    |
----------------------------------
Eval num_timesteps=218000, episode_reward=-0.02 +/- 0.20
Episode length: 16.48 +/- 1.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 16.5     |
|    mean_reward     | -0.0249  |
| time/              |          |
|    total_timesteps | 218000   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23       |
|    ep_rew_mean      | -0.0412  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10632    |
|    fps              | 35       |
|    time_elapsed     | 6093     |
|    total_timesteps  | 218062   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00671  |
|    n_updates        | 44515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.7     |
|    ep_rew_mean      | -0.0537  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10636    |
|    fps              | 35       |
|    time_elapsed     | 6094     |
|    total_timesteps  | 218187   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.37e-05 |
|    n_updates        | 44546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.3     |
|    ep_rew_mean      | -0.0523  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10640    |
|    fps              | 35       |
|    time_elapsed     | 6095     |
|    total_timesteps  | 218336   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.59e-05 |
|    n_updates        | 44583    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.8     |
|    ep_rew_mean      | -0.0543  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10644    |
|    fps              | 35       |
|    time_elapsed     | 6096     |
|    total_timesteps  | 218474   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.98e-05 |
|    n_updates        | 44618    |
----------------------------------
Eval num_timesteps=218500, episode_reward=-0.02 +/- 0.20
Episode length: 16.06 +/- 0.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0232  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 218500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.98e-05 |
|    n_updates        | 44624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.9     |
|    ep_rew_mean      | -0.0544  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10648    |
|    fps              | 35       |
|    time_elapsed     | 6100     |
|    total_timesteps  | 218540   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.78e-05 |
|    n_updates        | 44634    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.4     |
|    ep_rew_mean      | -0.0566  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10652    |
|    fps              | 35       |
|    time_elapsed     | 6101     |
|    total_timesteps  | 218663   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.6e-05  |
|    n_updates        | 44665    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.055   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10656    |
|    fps              | 35       |
|    time_elapsed     | 6101     |
|    total_timesteps  | 218747   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.39e-05 |
|    n_updates        | 44686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.0551  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10660    |
|    fps              | 35       |
|    time_elapsed     | 6102     |
|    total_timesteps  | 218812   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.52e-05 |
|    n_updates        | 44702    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24       |
|    ep_rew_mean      | -0.0551  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10664    |
|    fps              | 35       |
|    time_elapsed     | 6102     |
|    total_timesteps  | 218876   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00723  |
|    n_updates        | 44718    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.8     |
|    ep_rew_mean      | -0.0643  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10668    |
|    fps              | 35       |
|    time_elapsed     | 6103     |
|    total_timesteps  | 218940   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.56e-05 |
|    n_updates        | 44734    |
----------------------------------
Eval num_timesteps=219000, episode_reward=0.01 +/- 0.28
Episode length: 16.88 +/- 8.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.9     |
|    mean_reward      | 0.0135   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 219000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.95e-05 |
|    n_updates        | 44749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23.8     |
|    ep_rew_mean      | -0.054   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10672    |
|    fps              | 35       |
|    time_elapsed     | 6107     |
|    total_timesteps  | 219000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.3     |
|    ep_rew_mean      | -0.0564  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10676    |
|    fps              | 35       |
|    time_elapsed     | 6108     |
|    total_timesteps  | 219123   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.92e-05 |
|    n_updates        | 44780    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.8     |
|    ep_rew_mean      | -0.0483  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10680    |
|    fps              | 35       |
|    time_elapsed     | 6109     |
|    total_timesteps  | 219234   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.24e-06 |
|    n_updates        | 44808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.4     |
|    ep_rew_mean      | -0.0504  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10684    |
|    fps              | 35       |
|    time_elapsed     | 6110     |
|    total_timesteps  | 219378   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.62e-05 |
|    n_updates        | 44844    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.5     |
|    ep_rew_mean      | -0.0409  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10688    |
|    fps              | 35       |
|    time_elapsed     | 6110     |
|    total_timesteps  | 219453   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.17e-05 |
|    n_updates        | 44863    |
----------------------------------
Eval num_timesteps=219500, episode_reward=-0.20 +/- 0.10
Episode length: 50.42 +/- 25.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.4     |
|    mean_reward      | -0.201   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 219500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.94e-05 |
|    n_updates        | 44874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.2     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10692    |
|    fps              | 35       |
|    time_elapsed     | 6122     |
|    total_timesteps  | 219632   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.33e-05 |
|    n_updates        | 44907    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.2     |
|    ep_rew_mean      | -0.0356  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10696    |
|    fps              | 35       |
|    time_elapsed     | 6122     |
|    total_timesteps  | 219706   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 44926    |
----------------------------------
Eval num_timesteps=220000, episode_reward=-0.19 +/- 0.24
Episode length: 56.80 +/- 24.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.8     |
|    mean_reward      | -0.187   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 220000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 44999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.1     |
|    ep_rew_mean      | -0.0436  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10700    |
|    fps              | 35       |
|    time_elapsed     | 6137     |
|    total_timesteps  | 220000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0425  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10704    |
|    fps              | 35       |
|    time_elapsed     | 6138     |
|    total_timesteps  | 220093   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.42e-05 |
|    n_updates        | 45023    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0327  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10708    |
|    fps              | 35       |
|    time_elapsed     | 6138     |
|    total_timesteps  | 220161   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.06e-05 |
|    n_updates        | 45040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26       |
|    ep_rew_mean      | -0.0328  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10712    |
|    fps              | 35       |
|    time_elapsed     | 6139     |
|    total_timesteps  | 220227   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.45e-05 |
|    n_updates        | 45056    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 26.8     |
|    ep_rew_mean      | -0.026   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10716    |
|    fps              | 35       |
|    time_elapsed     | 6140     |
|    total_timesteps  | 220371   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.31e-05 |
|    n_updates        | 45092    |
----------------------------------
Eval num_timesteps=220500, episode_reward=-0.21 +/- 0.10
Episode length: 53.28 +/- 25.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.3     |
|    mean_reward      | -0.213   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 220500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.63e-05 |
|    n_updates        | 45124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.9     |
|    ep_rew_mean      | -0.0204  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10720    |
|    fps              | 35       |
|    time_elapsed     | 6152     |
|    total_timesteps  | 220593   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.77e-05 |
|    n_updates        | 45148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.5     |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10724    |
|    fps              | 35       |
|    time_elapsed     | 6153     |
|    total_timesteps  | 220782   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.9e-05  |
|    n_updates        | 45195    |
----------------------------------
Eval num_timesteps=221000, episode_reward=-0.21 +/- 0.10
Episode length: 53.62 +/- 24.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.6     |
|    mean_reward      | -0.214   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 221000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.12e-05 |
|    n_updates        | 45249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.2     |
|    ep_rew_mean      | -0.0198  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10728    |
|    fps              | 35       |
|    time_elapsed     | 6166     |
|    total_timesteps  | 221018   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.78e-05 |
|    n_updates        | 45254    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.9     |
|    ep_rew_mean      | -0.0468  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10732    |
|    fps              | 35       |
|    time_elapsed     | 6168     |
|    total_timesteps  | 221254   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.95e-05 |
|    n_updates        | 45313    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.4     |
|    ep_rew_mean      | -0.0445  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10736    |
|    fps              | 35       |
|    time_elapsed     | 6168     |
|    total_timesteps  | 221322   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.09e-05 |
|    n_updates        | 45330    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.6     |
|    ep_rew_mean      | -0.0454  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10740    |
|    fps              | 35       |
|    time_elapsed     | 6169     |
|    total_timesteps  | 221495   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6e-05    |
|    n_updates        | 45373    |
----------------------------------
Eval num_timesteps=221500, episode_reward=-0.26 +/- 0.08
Episode length: 65.26 +/- 20.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.3     |
|    mean_reward      | -0.261   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 221500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.34e-05 |
|    n_updates        | 45374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.6     |
|    ep_rew_mean      | -0.0494  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10744    |
|    fps              | 35       |
|    time_elapsed     | 6181     |
|    total_timesteps  | 221732   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.98e-05 |
|    n_updates        | 45432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.8     |
|    ep_rew_mean      | -0.0544  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10748    |
|    fps              | 35       |
|    time_elapsed     | 6182     |
|    total_timesteps  | 221923   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.29e-05 |
|    n_updates        | 45480    |
----------------------------------
Eval num_timesteps=222000, episode_reward=-0.20 +/- 0.17
Episode length: 55.34 +/- 23.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.3     |
|    mean_reward      | -0.201   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 222000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.46e-05 |
|    n_updates        | 45499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.6     |
|    ep_rew_mean      | -0.0574  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10752    |
|    fps              | 35       |
|    time_elapsed     | 6192     |
|    total_timesteps  | 222121   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.5e-05  |
|    n_updates        | 45530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.8     |
|    ep_rew_mean      | -0.0623  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10756    |
|    fps              | 35       |
|    time_elapsed     | 6194     |
|    total_timesteps  | 222326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.04e-05 |
|    n_updates        | 45581    |
----------------------------------
Eval num_timesteps=222500, episode_reward=-0.23 +/- 0.18
Episode length: 61.96 +/- 21.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62       |
|    mean_reward      | -0.228   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 222500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.05e-05 |
|    n_updates        | 45624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38       |
|    ep_rew_mean      | -0.071   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10760    |
|    fps              | 35       |
|    time_elapsed     | 6206     |
|    total_timesteps  | 222607   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.83e-05 |
|    n_updates        | 45651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.7     |
|    ep_rew_mean      | -0.0738  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10764    |
|    fps              | 35       |
|    time_elapsed     | 6206     |
|    total_timesteps  | 222742   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.36e-05 |
|    n_updates        | 45685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.4     |
|    ep_rew_mean      | -0.0808  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10768    |
|    fps              | 35       |
|    time_elapsed     | 6208     |
|    total_timesteps  | 222980   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.71e-05 |
|    n_updates        | 45744    |
----------------------------------
Eval num_timesteps=223000, episode_reward=-0.21 +/- 0.16
Episode length: 57.68 +/- 23.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.7     |
|    mean_reward      | -0.21    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 223000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.37e-05 |
|    n_updates        | 45749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.3     |
|    ep_rew_mean      | -0.0884  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10772    |
|    fps              | 35       |
|    time_elapsed     | 6221     |
|    total_timesteps  | 223229   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.5e-05  |
|    n_updates        | 45807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.3     |
|    ep_rew_mean      | -0.0884  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10776    |
|    fps              | 35       |
|    time_elapsed     | 6222     |
|    total_timesteps  | 223353   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.77e-05 |
|    n_updates        | 45838    |
----------------------------------
Eval num_timesteps=223500, episode_reward=0.05 +/- 0.37
Episode length: 28.44 +/- 16.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 28.4     |
|    mean_reward      | 0.0473   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 223500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.15e-05 |
|    n_updates        | 45874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43       |
|    ep_rew_mean      | -0.0812  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10780    |
|    fps              | 35       |
|    time_elapsed     | 6229     |
|    total_timesteps  | 223533   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.62e-05 |
|    n_updates        | 45883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.2     |
|    ep_rew_mean      | -0.0781  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10784    |
|    fps              | 35       |
|    time_elapsed     | 6230     |
|    total_timesteps  | 223599   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.89e-05 |
|    n_updates        | 45899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.6     |
|    ep_rew_mean      | -0.0896  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10788    |
|    fps              | 35       |
|    time_elapsed     | 6231     |
|    total_timesteps  | 223713   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.95e-05 |
|    n_updates        | 45928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.2     |
|    ep_rew_mean      | -0.0922  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10792    |
|    fps              | 35       |
|    time_elapsed     | 6232     |
|    total_timesteps  | 223955   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.22e-05 |
|    n_updates        | 45988    |
----------------------------------
Eval num_timesteps=224000, episode_reward=-0.22 +/- 0.09
Episode length: 55.02 +/- 22.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55       |
|    mean_reward      | -0.22    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 224000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.75e-05 |
|    n_updates        | 45999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45       |
|    ep_rew_mean      | -0.0993  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10796    |
|    fps              | 35       |
|    time_elapsed     | 6246     |
|    total_timesteps  | 224207   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00696  |
|    n_updates        | 46051    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.7     |
|    ep_rew_mean      | -0.098   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10800    |
|    fps              | 35       |
|    time_elapsed     | 6247     |
|    total_timesteps  | 224468   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.56e-05 |
|    n_updates        | 46116    |
----------------------------------
Eval num_timesteps=224500, episode_reward=-0.21 +/- 0.10
Episode length: 52.30 +/- 25.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.3     |
|    mean_reward      | -0.209   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 224500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.8e-05  |
|    n_updates        | 46124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.4     |
|    ep_rew_mean      | -0.105   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10804    |
|    fps              | 35       |
|    time_elapsed     | 6257     |
|    total_timesteps  | 224729   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.97e-05 |
|    n_updates        | 46182    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.1     |
|    ep_rew_mean      | -0.118   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10808    |
|    fps              | 35       |
|    time_elapsed     | 6258     |
|    total_timesteps  | 224870   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.13e-05 |
|    n_updates        | 46217    |
----------------------------------
Eval num_timesteps=225000, episode_reward=-0.20 +/- 0.09
Episode length: 49.80 +/- 21.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.8     |
|    mean_reward      | -0.198   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 225000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.77e-05 |
|    n_updates        | 46249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.8     |
|    ep_rew_mean      | -0.135   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10812    |
|    fps              | 35       |
|    time_elapsed     | 6268     |
|    total_timesteps  | 225111   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.28e-05 |
|    n_updates        | 46277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.9     |
|    ep_rew_mean      | -0.145   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10816    |
|    fps              | 35       |
|    time_elapsed     | 6269     |
|    total_timesteps  | 225261   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2e-05    |
|    n_updates        | 46315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.8     |
|    ep_rew_mean      | -0.154   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10820    |
|    fps              | 35       |
|    time_elapsed     | 6270     |
|    total_timesteps  | 225470   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.12e-05 |
|    n_updates        | 46367    |
----------------------------------
Eval num_timesteps=225500, episode_reward=-0.23 +/- 0.16
Episode length: 63.12 +/- 21.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.1     |
|    mean_reward      | -0.232   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 225500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.56e-05 |
|    n_updates        | 46374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49       |
|    ep_rew_mean      | -0.155   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10824    |
|    fps              | 35       |
|    time_elapsed     | 6282     |
|    total_timesteps  | 225678   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.19e-05 |
|    n_updates        | 46419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.7     |
|    ep_rew_mean      | -0.164   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10828    |
|    fps              | 35       |
|    time_elapsed     | 6283     |
|    total_timesteps  | 225884   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.89e-05 |
|    n_updates        | 46470    |
----------------------------------
Eval num_timesteps=226000, episode_reward=-0.04 +/- 0.21
Episode length: 20.60 +/- 13.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20.6     |
|    mean_reward      | -0.0414  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 226000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.17e-05 |
|    n_updates        | 46499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.7     |
|    ep_rew_mean      | -0.15    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10832    |
|    fps              | 35       |
|    time_elapsed     | 6288     |
|    total_timesteps  | 226023   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.84e-05 |
|    n_updates        | 46505    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.2     |
|    ep_rew_mean      | -0.152   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10836    |
|    fps              | 35       |
|    time_elapsed     | 6289     |
|    total_timesteps  | 226146   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.47e-05 |
|    n_updates        | 46536    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.5     |
|    ep_rew_mean      | -0.153   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10840    |
|    fps              | 35       |
|    time_elapsed     | 6290     |
|    total_timesteps  | 226343   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.17e-05 |
|    n_updates        | 46585    |
----------------------------------
Eval num_timesteps=226500, episode_reward=-0.24 +/- 0.10
Episode length: 60.20 +/- 24.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60.2     |
|    mean_reward      | -0.241   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 226500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0139   |
|    n_updates        | 46624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.4     |
|    ep_rew_mean      | -0.153   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10844    |
|    fps              | 35       |
|    time_elapsed     | 6302     |
|    total_timesteps  | 226576   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.1e-05  |
|    n_updates        | 46643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.6     |
|    ep_rew_mean      | -0.154   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10848    |
|    fps              | 35       |
|    time_elapsed     | 6303     |
|    total_timesteps  | 226782   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.2e-05  |
|    n_updates        | 46695    |
----------------------------------
Eval num_timesteps=227000, episode_reward=-0.20 +/- 0.18
Episode length: 56.32 +/- 23.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.3     |
|    mean_reward      | -0.205   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 227000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.53e-05 |
|    n_updates        | 46749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49       |
|    ep_rew_mean      | -0.156   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10852    |
|    fps              | 35       |
|    time_elapsed     | 6313     |
|    total_timesteps  | 227024   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.75e-05 |
|    n_updates        | 46755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50       |
|    ep_rew_mean      | -0.159   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10856    |
|    fps              | 35       |
|    time_elapsed     | 6315     |
|    total_timesteps  | 227324   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.66e-05 |
|    n_updates        | 46830    |
----------------------------------
Eval num_timesteps=227500, episode_reward=-0.26 +/- 0.08
Episode length: 65.00 +/- 20.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65       |
|    mean_reward      | -0.26    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 227500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.57e-05 |
|    n_updates        | 46874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.8     |
|    ep_rew_mean      | -0.159   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10860    |
|    fps              | 35       |
|    time_elapsed     | 6327     |
|    total_timesteps  | 227586   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.4e-05  |
|    n_updates        | 46896    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50.5     |
|    ep_rew_mean      | -0.161   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10864    |
|    fps              | 35       |
|    time_elapsed     | 6329     |
|    total_timesteps  | 227787   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0077   |
|    n_updates        | 46946    |
----------------------------------
Eval num_timesteps=228000, episode_reward=-0.23 +/- 0.09
Episode length: 56.58 +/- 22.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.6     |
|    mean_reward      | -0.226   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 228000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.15e-05 |
|    n_updates        | 46999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50.2     |
|    ep_rew_mean      | -0.16    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10868    |
|    fps              | 35       |
|    time_elapsed     | 6339     |
|    total_timesteps  | 228004   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.82e-05 |
|    n_updates        | 47000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50.4     |
|    ep_rew_mean      | -0.171   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10872    |
|    fps              | 35       |
|    time_elapsed     | 6341     |
|    total_timesteps  | 228266   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00659  |
|    n_updates        | 47066    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50.6     |
|    ep_rew_mean      | -0.172   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10876    |
|    fps              | 36       |
|    time_elapsed     | 6341     |
|    total_timesteps  | 228411   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.82e-05 |
|    n_updates        | 47102    |
----------------------------------
Eval num_timesteps=228500, episode_reward=-0.27 +/- 0.07
Episode length: 67.02 +/- 18.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67       |
|    mean_reward      | -0.268   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 228500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.2e-05  |
|    n_updates        | 47124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.8     |
|    ep_rew_mean      | -0.189   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10880    |
|    fps              | 35       |
|    time_elapsed     | 6353     |
|    total_timesteps  | 228515   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.08e-05 |
|    n_updates        | 47128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 51.9     |
|    ep_rew_mean      | -0.197   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10884    |
|    fps              | 36       |
|    time_elapsed     | 6355     |
|    total_timesteps  | 228784   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.54e-05 |
|    n_updates        | 47195    |
----------------------------------
Eval num_timesteps=229000, episode_reward=-0.24 +/- 0.17
Episode length: 65.76 +/- 20.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.8     |
|    mean_reward      | -0.243   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 229000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.78e-05 |
|    n_updates        | 47249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.7     |
|    ep_rew_mean      | -0.204   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10888    |
|    fps              | 35       |
|    time_elapsed     | 6367     |
|    total_timesteps  | 229079   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.48e-05 |
|    n_updates        | 47269    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.4     |
|    ep_rew_mean      | -0.199   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10892    |
|    fps              | 35       |
|    time_elapsed     | 6368     |
|    total_timesteps  | 229191   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.06e-05 |
|    n_updates        | 47297    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.4     |
|    ep_rew_mean      | -0.199   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10896    |
|    fps              | 36       |
|    time_elapsed     | 6369     |
|    total_timesteps  | 229446   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.99e-05 |
|    n_updates        | 47361    |
----------------------------------
Eval num_timesteps=229500, episode_reward=-0.09 +/- 0.30
Episode length: 43.26 +/- 24.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.3     |
|    mean_reward      | -0.0924  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 229500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.75e-05 |
|    n_updates        | 47374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.2     |
|    ep_rew_mean      | -0.198   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10900    |
|    fps              | 35       |
|    time_elapsed     | 6380     |
|    total_timesteps  | 229687   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.04e-05 |
|    n_updates        | 47421    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.6     |
|    ep_rew_mean      | -0.2     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10904    |
|    fps              | 36       |
|    time_elapsed     | 6381     |
|    total_timesteps  | 229987   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.48e-05 |
|    n_updates        | 47496    |
----------------------------------
Eval num_timesteps=230000, episode_reward=-0.25 +/- 0.08
Episode length: 63.36 +/- 20.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.4     |
|    mean_reward      | -0.253   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 230000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.45e-05 |
|    n_updates        | 47499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53       |
|    ep_rew_mean      | -0.202   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10908    |
|    fps              | 36       |
|    time_elapsed     | 6393     |
|    total_timesteps  | 230171   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.54e-06 |
|    n_updates        | 47542    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.1     |
|    ep_rew_mean      | -0.198   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10912    |
|    fps              | 36       |
|    time_elapsed     | 6394     |
|    total_timesteps  | 230326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.67e-05 |
|    n_updates        | 47581    |
----------------------------------
Eval num_timesteps=230500, episode_reward=-0.15 +/- 0.16
Episode length: 43.64 +/- 23.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | -0.154   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 230500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.52e-05 |
|    n_updates        | 47624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.8     |
|    ep_rew_mean      | -0.191   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10916    |
|    fps              | 36       |
|    time_elapsed     | 6403     |
|    total_timesteps  | 230541   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.9e-05  |
|    n_updates        | 47635    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.5     |
|    ep_rew_mean      | -0.19    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10920    |
|    fps              | 36       |
|    time_elapsed     | 6404     |
|    total_timesteps  | 230725   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.06e-05 |
|    n_updates        | 47681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 51.8     |
|    ep_rew_mean      | -0.187   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10924    |
|    fps              | 36       |
|    time_elapsed     | 6404     |
|    total_timesteps  | 230861   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.47e-05 |
|    n_updates        | 47715    |
----------------------------------
Eval num_timesteps=231000, episode_reward=-0.17 +/- 0.11
Episode length: 41.78 +/- 26.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.8     |
|    mean_reward      | -0.167   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 231000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.73e-05 |
|    n_updates        | 47749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 51.8     |
|    ep_rew_mean      | -0.187   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10928    |
|    fps              | 36       |
|    time_elapsed     | 6415     |
|    total_timesteps  | 231066   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.22e-05 |
|    n_updates        | 47766    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.6     |
|    ep_rew_mean      | -0.19    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10932    |
|    fps              | 36       |
|    time_elapsed     | 6416     |
|    total_timesteps  | 231287   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00734  |
|    n_updates        | 47821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.3     |
|    ep_rew_mean      | -0.193   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10936    |
|    fps              | 36       |
|    time_elapsed     | 6417     |
|    total_timesteps  | 231473   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.73e-05 |
|    n_updates        | 47868    |
----------------------------------
Eval num_timesteps=231500, episode_reward=-0.18 +/- 0.11
Episode length: 46.18 +/- 27.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.2     |
|    mean_reward      | -0.184   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 231500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.26e-05 |
|    n_updates        | 47874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.2     |
|    ep_rew_mean      | -0.178   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10940    |
|    fps              | 36       |
|    time_elapsed     | 6427     |
|    total_timesteps  | 231564   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.82e-05 |
|    n_updates        | 47890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52       |
|    ep_rew_mean      | -0.177   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10944    |
|    fps              | 36       |
|    time_elapsed     | 6428     |
|    total_timesteps  | 231773   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.29e-05 |
|    n_updates        | 47943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 51.4     |
|    ep_rew_mean      | -0.175   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10948    |
|    fps              | 36       |
|    time_elapsed     | 6429     |
|    total_timesteps  | 231917   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.51e-05 |
|    n_updates        | 47979    |
----------------------------------
Eval num_timesteps=232000, episode_reward=-0.04 +/- 0.20
Episode length: 20.02 +/- 11.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20       |
|    mean_reward      | -0.0391  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 232000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00737  |
|    n_updates        | 47999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50.8     |
|    ep_rew_mean      | -0.172   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10952    |
|    fps              | 36       |
|    time_elapsed     | 6435     |
|    total_timesteps  | 232099   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.24e-05 |
|    n_updates        | 48024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.4     |
|    ep_rew_mean      | -0.163   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10956    |
|    fps              | 36       |
|    time_elapsed     | 6435     |
|    total_timesteps  | 232163   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.8e-05  |
|    n_updates        | 48040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.4     |
|    ep_rew_mean      | -0.155   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10960    |
|    fps              | 36       |
|    time_elapsed     | 6436     |
|    total_timesteps  | 232228   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.08e-05 |
|    n_updates        | 48056    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45.6     |
|    ep_rew_mean      | -0.152   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10964    |
|    fps              | 36       |
|    time_elapsed     | 6437     |
|    total_timesteps  | 232352   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.51e-05 |
|    n_updates        | 48087    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.2     |
|    ep_rew_mean      | -0.146   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10968    |
|    fps              | 36       |
|    time_elapsed     | 6437     |
|    total_timesteps  | 232420   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.52e-05 |
|    n_updates        | 48104    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.2     |
|    ep_rew_mean      | -0.138   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10972    |
|    fps              | 36       |
|    time_elapsed     | 6437     |
|    total_timesteps  | 232484   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.4e-05  |
|    n_updates        | 48120    |
----------------------------------
Eval num_timesteps=232500, episode_reward=-0.00 +/- 0.33
Episode length: 26.32 +/- 22.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 26.3     |
|    mean_reward      | -0.00446 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 232500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.96e-05 |
|    n_updates        | 48124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.5     |
|    ep_rew_mean      | -0.135   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10976    |
|    fps              | 36       |
|    time_elapsed     | 6444     |
|    total_timesteps  | 232561   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.2e-05  |
|    n_updates        | 48140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.1     |
|    ep_rew_mean      | -0.134   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10980    |
|    fps              | 36       |
|    time_elapsed     | 6444     |
|    total_timesteps  | 232626   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.77e-05 |
|    n_updates        | 48156    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.1     |
|    ep_rew_mean      | -0.126   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10984    |
|    fps              | 36       |
|    time_elapsed     | 6445     |
|    total_timesteps  | 232692   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.09e-05 |
|    n_updates        | 48172    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.8     |
|    ep_rew_mean      | -0.116   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10988    |
|    fps              | 36       |
|    time_elapsed     | 6445     |
|    total_timesteps  | 232757   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.09e-05 |
|    n_updates        | 48189    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.3     |
|    ep_rew_mean      | -0.115   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10992    |
|    fps              | 36       |
|    time_elapsed     | 6446     |
|    total_timesteps  | 232823   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.91e-05 |
|    n_updates        | 48205    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.1     |
|    ep_rew_mean      | -0.109   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 10996    |
|    fps              | 36       |
|    time_elapsed     | 6446     |
|    total_timesteps  | 232952   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.63e-05 |
|    n_updates        | 48237    |
----------------------------------
Eval num_timesteps=233000, episode_reward=-0.04 +/- 0.27
Episode length: 25.30 +/- 21.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 25.3     |
|    mean_reward      | -0.0403  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 233000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.3e-05  |
|    n_updates        | 48249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.3     |
|    ep_rew_mean      | -0.102   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11000    |
|    fps              | 36       |
|    time_elapsed     | 6452     |
|    total_timesteps  | 233017   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.88e-05 |
|    n_updates        | 48254    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.9     |
|    ep_rew_mean      | -0.093   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11004    |
|    fps              | 36       |
|    time_elapsed     | 6453     |
|    total_timesteps  | 233082   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.4e-05  |
|    n_updates        | 48270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.8     |
|    ep_rew_mean      | -0.0882  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11008    |
|    fps              | 36       |
|    time_elapsed     | 6453     |
|    total_timesteps  | 233146   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3e-05    |
|    n_updates        | 48286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.9     |
|    ep_rew_mean      | -0.0846  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11012    |
|    fps              | 36       |
|    time_elapsed     | 6454     |
|    total_timesteps  | 233212   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.54e-05 |
|    n_updates        | 48302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.4     |
|    ep_rew_mean      | -0.0886  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11016    |
|    fps              | 36       |
|    time_elapsed     | 6454     |
|    total_timesteps  | 233278   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.81e-05 |
|    n_updates        | 48319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.4     |
|    ep_rew_mean      | -0.0886  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11020    |
|    fps              | 36       |
|    time_elapsed     | 6455     |
|    total_timesteps  | 233462   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.37e-05 |
|    n_updates        | 48365    |
----------------------------------
Eval num_timesteps=233500, episode_reward=-0.02 +/- 0.20
Episode length: 16.18 +/- 1.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.2     |
|    mean_reward      | -0.0237  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 233500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.18e-05 |
|    n_updates        | 48374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.3     |
|    ep_rew_mean      | -0.0882  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11024    |
|    fps              | 36       |
|    time_elapsed     | 6460     |
|    total_timesteps  | 233589   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.54e-05 |
|    n_updates        | 48397    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 25.9     |
|    ep_rew_mean      | -0.0826  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11028    |
|    fps              | 36       |
|    time_elapsed     | 6461     |
|    total_timesteps  | 233653   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.05e-05 |
|    n_updates        | 48413    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.9     |
|    ep_rew_mean      | -0.0887  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11032    |
|    fps              | 36       |
|    time_elapsed     | 6461     |
|    total_timesteps  | 233776   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.58e-05 |
|    n_updates        | 48443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.3     |
|    ep_rew_mean      | -0.0862  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11036    |
|    fps              | 36       |
|    time_elapsed     | 6462     |
|    total_timesteps  | 233899   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00706  |
|    n_updates        | 48474    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 24.2     |
|    ep_rew_mean      | -0.0958  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11040    |
|    fps              | 36       |
|    time_elapsed     | 6463     |
|    total_timesteps  | 233981   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.45e-05 |
|    n_updates        | 48495    |
----------------------------------
Eval num_timesteps=234000, episode_reward=-0.05 +/- 0.15
Episode length: 18.32 +/- 8.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.3     |
|    mean_reward      | -0.0523  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 234000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.88e-05 |
|    n_updates        | 48499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22.8     |
|    ep_rew_mean      | -0.0904  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11044    |
|    fps              | 36       |
|    time_elapsed     | 6468     |
|    total_timesteps  | 234055   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.17e-05 |
|    n_updates        | 48513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 22       |
|    ep_rew_mean      | -0.0872  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11048    |
|    fps              | 36       |
|    time_elapsed     | 6469     |
|    total_timesteps  | 234121   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00677  |
|    n_updates        | 48530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0826  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11052    |
|    fps              | 36       |
|    time_elapsed     | 6469     |
|    total_timesteps  | 234186   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.16e-05 |
|    n_updates        | 48546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0826  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11056    |
|    fps              | 36       |
|    time_elapsed     | 6469     |
|    total_timesteps  | 234250   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.88e-05 |
|    n_updates        | 48562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0825  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11060    |
|    fps              | 36       |
|    time_elapsed     | 6470     |
|    total_timesteps  | 234314   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.04e-05 |
|    n_updates        | 48578    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0801  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11064    |
|    fps              | 36       |
|    time_elapsed     | 6470     |
|    total_timesteps  | 234378   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.92e-05 |
|    n_updates        | 48594    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.0799  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11068    |
|    fps              | 36       |
|    time_elapsed     | 6471     |
|    total_timesteps  | 234442   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.5e-05  |
|    n_updates        | 48610    |
----------------------------------
Eval num_timesteps=234500, episode_reward=0.03 +/- 0.31
Episode length: 16.92 +/- 8.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.9     |
|    mean_reward      | 0.0334   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 234500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.23e-05 |
|    n_updates        | 48624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.08    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11072    |
|    fps              | 36       |
|    time_elapsed     | 6475     |
|    total_timesteps  | 234507   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.34e-05 |
|    n_updates        | 48626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0795  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11076    |
|    fps              | 36       |
|    time_elapsed     | 6476     |
|    total_timesteps  | 234571   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.62e-05 |
|    n_updates        | 48642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0796  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11080    |
|    fps              | 36       |
|    time_elapsed     | 6476     |
|    total_timesteps  | 234639   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.11e-05 |
|    n_updates        | 48659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0803  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11084    |
|    fps              | 36       |
|    time_elapsed     | 6477     |
|    total_timesteps  | 234724   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.34e-05 |
|    n_updates        | 48680    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0805  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11088    |
|    fps              | 36       |
|    time_elapsed     | 6477     |
|    total_timesteps  | 234794   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.9e-05  |
|    n_updates        | 48698    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0806  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11092    |
|    fps              | 36       |
|    time_elapsed     | 6478     |
|    total_timesteps  | 234861   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.52e-05 |
|    n_updates        | 48715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.078   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11096    |
|    fps              | 36       |
|    time_elapsed     | 6478     |
|    total_timesteps  | 234925   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.5e-05  |
|    n_updates        | 48731    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0781  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11100    |
|    fps              | 36       |
|    time_elapsed     | 6479     |
|    total_timesteps  | 234993   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.98e-05 |
|    n_updates        | 48748    |
----------------------------------
Eval num_timesteps=235000, episode_reward=-0.03 +/- 0.26
Episode length: 21.82 +/- 16.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 21.8     |
|    mean_reward      | -0.0263  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 235000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 48749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0804  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11104    |
|    fps              | 36       |
|    time_elapsed     | 6484     |
|    total_timesteps  | 235116   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.96e-05 |
|    n_updates        | 48778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0805  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11108    |
|    fps              | 36       |
|    time_elapsed     | 6485     |
|    total_timesteps  | 235183   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.76e-05 |
|    n_updates        | 48795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.4     |
|    ep_rew_mean      | -0.0805  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11112    |
|    fps              | 36       |
|    time_elapsed     | 6485     |
|    total_timesteps  | 235248   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.92e-05 |
|    n_updates        | 48811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0804  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11116    |
|    fps              | 36       |
|    time_elapsed     | 6486     |
|    total_timesteps  | 235312   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.53e-05 |
|    n_updates        | 48827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0656  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11120    |
|    fps              | 36       |
|    time_elapsed     | 6486     |
|    total_timesteps  | 235376   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.71e-05 |
|    n_updates        | 48843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0631  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11124    |
|    fps              | 36       |
|    time_elapsed     | 6486     |
|    total_timesteps  | 235440   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.9e-05  |
|    n_updates        | 48859    |
----------------------------------
Eval num_timesteps=235500, episode_reward=-0.01 +/- 0.25
Episode length: 18.78 +/- 11.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.8     |
|    mean_reward      | -0.0141  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 235500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.03e-05 |
|    n_updates        | 48874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0631  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11128    |
|    fps              | 36       |
|    time_elapsed     | 6491     |
|    total_timesteps  | 235504   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.39e-05 |
|    n_updates        | 48875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0607  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11132    |
|    fps              | 36       |
|    time_elapsed     | 6492     |
|    total_timesteps  | 235568   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.02e-05 |
|    n_updates        | 48891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0583  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11136    |
|    fps              | 36       |
|    time_elapsed     | 6492     |
|    total_timesteps  | 235632   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.9e-05  |
|    n_updates        | 48907    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0577  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11140    |
|    fps              | 36       |
|    time_elapsed     | 6493     |
|    total_timesteps  | 235698   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.01e-05 |
|    n_updates        | 48924    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.0597  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11144    |
|    fps              | 36       |
|    time_elapsed     | 6494     |
|    total_timesteps  | 235821   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.54e-05 |
|    n_updates        | 48955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0619  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11148    |
|    fps              | 36       |
|    time_elapsed     | 6494     |
|    total_timesteps  | 235944   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.9e-05  |
|    n_updates        | 48985    |
----------------------------------
Eval num_timesteps=236000, episode_reward=0.01 +/- 0.28
Episode length: 17.72 +/- 9.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.7     |
|    mean_reward      | 0.0101   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 236000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.82e-05 |
|    n_updates        | 48999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0619  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11152    |
|    fps              | 36       |
|    time_elapsed     | 6499     |
|    total_timesteps  | 236008   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.18e-05 |
|    n_updates        | 49001    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0518  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11156    |
|    fps              | 36       |
|    time_elapsed     | 6499     |
|    total_timesteps  | 236069   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.21e-05 |
|    n_updates        | 49017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0518  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11160    |
|    fps              | 36       |
|    time_elapsed     | 6500     |
|    total_timesteps  | 236134   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.22e-05 |
|    n_updates        | 49033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11164    |
|    fps              | 36       |
|    time_elapsed     | 6501     |
|    total_timesteps  | 236253   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.03e-05 |
|    n_updates        | 49063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0442  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11168    |
|    fps              | 36       |
|    time_elapsed     | 6501     |
|    total_timesteps  | 236321   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.96e-05 |
|    n_updates        | 49080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0343  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11172    |
|    fps              | 36       |
|    time_elapsed     | 6502     |
|    total_timesteps  | 236389   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.8e-05  |
|    n_updates        | 49097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0243  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11176    |
|    fps              | 36       |
|    time_elapsed     | 6502     |
|    total_timesteps  | 236452   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.7e-05  |
|    n_updates        | 49112    |
----------------------------------
Eval num_timesteps=236500, episode_reward=-0.06 +/- 0.15
Episode length: 19.46 +/- 14.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.5     |
|    mean_reward      | -0.0569  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 236500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00738  |
|    n_updates        | 49124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0139  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11180    |
|    fps              | 36       |
|    time_elapsed     | 6507     |
|    total_timesteps  | 236512   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.08e-05 |
|    n_updates        | 49127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0155  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11184    |
|    fps              | 36       |
|    time_elapsed     | 6508     |
|    total_timesteps  | 236636   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.2e-05  |
|    n_updates        | 49158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.00523 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11188    |
|    fps              | 36       |
|    time_elapsed     | 6508     |
|    total_timesteps  | 236699   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.71e-05 |
|    n_updates        | 49174    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00515 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11192    |
|    fps              | 36       |
|    time_elapsed     | 6509     |
|    total_timesteps  | 236764   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.16e-05 |
|    n_updates        | 49190    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00515 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11196    |
|    fps              | 36       |
|    time_elapsed     | 6509     |
|    total_timesteps  | 236828   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.52e-05 |
|    n_updates        | 49206    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00736 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11200    |
|    fps              | 36       |
|    time_elapsed     | 6510     |
|    total_timesteps  | 236951   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.81e-05 |
|    n_updates        | 49237    |
----------------------------------
Eval num_timesteps=237000, episode_reward=-0.03 +/- 0.20
Episode length: 17.38 +/- 8.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.4     |
|    mean_reward      | -0.0285  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 237000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.65e-05 |
|    n_updates        | 49249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00499 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11204    |
|    fps              | 36       |
|    time_elapsed     | 6515     |
|    total_timesteps  | 237015   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.55e-05 |
|    n_updates        | 49253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00487 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11208    |
|    fps              | 36       |
|    time_elapsed     | 6515     |
|    total_timesteps  | 237079   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00737  |
|    n_updates        | 49269    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0072  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11212    |
|    fps              | 36       |
|    time_elapsed     | 6516     |
|    total_timesteps  | 237202   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.06e-05 |
|    n_updates        | 49300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00728 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11216    |
|    fps              | 36       |
|    time_elapsed     | 6517     |
|    total_timesteps  | 237268   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.44e-05 |
|    n_updates        | 49316    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.00716 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11220    |
|    fps              | 36       |
|    time_elapsed     | 6517     |
|    total_timesteps  | 237329   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.82e-05 |
|    n_updates        | 49332    |
----------------------------------
Eval num_timesteps=237500, episode_reward=-0.07 +/- 0.16
Episode length: 22.12 +/- 17.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 22.1     |
|    mean_reward      | -0.0675  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 237500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.02e-05 |
|    n_updates        | 49374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0119  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11224    |
|    fps              | 36       |
|    time_elapsed     | 6524     |
|    total_timesteps  | 237511   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00697  |
|    n_updates        | 49377    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0122  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11228    |
|    fps              | 36       |
|    time_elapsed     | 6524     |
|    total_timesteps  | 237582   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.92e-05 |
|    n_updates        | 49395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.00202 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11232    |
|    fps              | 36       |
|    time_elapsed     | 6525     |
|    total_timesteps  | 237642   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.66e-05 |
|    n_updates        | 49410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | -0.00676 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11236    |
|    fps              | 36       |
|    time_elapsed     | 6526     |
|    total_timesteps  | 237824   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.23e-05 |
|    n_updates        | 49455    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.9     |
|    ep_rew_mean      | 0.0034   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11240    |
|    fps              | 36       |
|    time_elapsed     | 6526     |
|    total_timesteps  | 237886   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.29e-05 |
|    n_updates        | 49471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | 0.00577  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11244    |
|    fps              | 36       |
|    time_elapsed     | 6527     |
|    total_timesteps  | 237950   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.1e-05  |
|    n_updates        | 49487    |
----------------------------------
Eval num_timesteps=238000, episode_reward=0.03 +/- 0.31
Episode length: 18.04 +/- 11.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18       |
|    mean_reward      | 0.029    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 238000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.07e-05 |
|    n_updates        | 49499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.00814  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11248    |
|    fps              | 36       |
|    time_elapsed     | 6532     |
|    total_timesteps  | 238014   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.07e-05 |
|    n_updates        | 49503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | 0.00814  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11252    |
|    fps              | 36       |
|    time_elapsed     | 6532     |
|    total_timesteps  | 238078   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.23e-05 |
|    n_updates        | 49519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.00213 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11256    |
|    fps              | 36       |
|    time_elapsed     | 6533     |
|    total_timesteps  | 238146   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.66e-05 |
|    n_updates        | 49536    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.00213 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11260    |
|    fps              | 36       |
|    time_elapsed     | 6533     |
|    total_timesteps  | 238211   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.39e-05 |
|    n_updates        | 49552    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.00992 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11264    |
|    fps              | 36       |
|    time_elapsed     | 6534     |
|    total_timesteps  | 238275   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.42e-05 |
|    n_updates        | 49568    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0145  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11268    |
|    fps              | 36       |
|    time_elapsed     | 6535     |
|    total_timesteps  | 238457   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.83e-05 |
|    n_updates        | 49614    |
----------------------------------
Eval num_timesteps=238500, episode_reward=0.06 +/- 0.37
Episode length: 21.40 +/- 17.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 21.4     |
|    mean_reward      | 0.0554   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 238500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.66e-05 |
|    n_updates        | 49624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.00403 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11272    |
|    fps              | 36       |
|    time_elapsed     | 6541     |
|    total_timesteps  | 238514   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.12e-05 |
|    n_updates        | 49628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11276    |
|    fps              | 36       |
|    time_elapsed     | 6542     |
|    total_timesteps  | 238578   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.25e-05 |
|    n_updates        | 49644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.3     |
|    ep_rew_mean      | -0.0242  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11280    |
|    fps              | 36       |
|    time_elapsed     | 6542     |
|    total_timesteps  | 238642   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.54e-05 |
|    n_updates        | 49660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.022   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11284    |
|    fps              | 36       |
|    time_elapsed     | 6543     |
|    total_timesteps  | 238709   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.86e-05 |
|    n_updates        | 49677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11288    |
|    fps              | 36       |
|    time_elapsed     | 6543     |
|    total_timesteps  | 238773   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.98e-05 |
|    n_updates        | 49693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11292    |
|    fps              | 36       |
|    time_elapsed     | 6544     |
|    total_timesteps  | 238837   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.59e-05 |
|    n_updates        | 49709    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.032   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11296    |
|    fps              | 36       |
|    time_elapsed     | 6544     |
|    total_timesteps  | 238901   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.7e-05  |
|    n_updates        | 49725    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0296  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11300    |
|    fps              | 36       |
|    time_elapsed     | 6545     |
|    total_timesteps  | 238965   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00703  |
|    n_updates        | 49741    |
----------------------------------
Eval num_timesteps=239000, episode_reward=-0.10 +/- 0.08
Episode length: 24.50 +/- 20.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 24.5     |
|    mean_reward      | -0.0971  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 239000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.8e-05  |
|    n_updates        | 49749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0195  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11304    |
|    fps              | 36       |
|    time_elapsed     | 6551     |
|    total_timesteps  | 239026   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.15e-05 |
|    n_updates        | 49756    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0195  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11308    |
|    fps              | 36       |
|    time_elapsed     | 6551     |
|    total_timesteps  | 239090   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.08e-05 |
|    n_updates        | 49772    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0171  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11312    |
|    fps              | 36       |
|    time_elapsed     | 6552     |
|    total_timesteps  | 239154   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.27e-05 |
|    n_updates        | 49788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.00689 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11316    |
|    fps              | 36       |
|    time_elapsed     | 6552     |
|    total_timesteps  | 239214   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.41e-05 |
|    n_updates        | 49803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.017   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11320    |
|    fps              | 36       |
|    time_elapsed     | 6552     |
|    total_timesteps  | 239279   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.86e-05 |
|    n_updates        | 49819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11324    |
|    fps              | 36       |
|    time_elapsed     | 6553     |
|    total_timesteps  | 239343   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.02e-05 |
|    n_updates        | 49835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11328    |
|    fps              | 36       |
|    time_elapsed     | 6553     |
|    total_timesteps  | 239407   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.35e-05 |
|    n_updates        | 49851    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0222  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11332    |
|    fps              | 36       |
|    time_elapsed     | 6554     |
|    total_timesteps  | 239471   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.5e-05  |
|    n_updates        | 49867    |
----------------------------------
Eval num_timesteps=239500, episode_reward=-0.02 +/- 0.20
Episode length: 16.08 +/- 1.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0233  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 239500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.82e-05 |
|    n_updates        | 49874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0174  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11336    |
|    fps              | 36       |
|    time_elapsed     | 6559     |
|    total_timesteps  | 239535   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.96e-05 |
|    n_updates        | 49883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0275  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11340    |
|    fps              | 36       |
|    time_elapsed     | 6559     |
|    total_timesteps  | 239599   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.63e-05 |
|    n_updates        | 49899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0174  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11344    |
|    fps              | 36       |
|    time_elapsed     | 6560     |
|    total_timesteps  | 239660   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.97e-05 |
|    n_updates        | 49914    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0174  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11348    |
|    fps              | 36       |
|    time_elapsed     | 6560     |
|    total_timesteps  | 239725   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.92e-05 |
|    n_updates        | 49931    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0175  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11352    |
|    fps              | 36       |
|    time_elapsed     | 6561     |
|    total_timesteps  | 239790   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.07e-05 |
|    n_updates        | 49947    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0174  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11356    |
|    fps              | 36       |
|    time_elapsed     | 6561     |
|    total_timesteps  | 239856   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.63e-05 |
|    n_updates        | 49963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00719 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11360    |
|    fps              | 36       |
|    time_elapsed     | 6562     |
|    total_timesteps  | 239916   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.76e-05 |
|    n_updates        | 49978    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00735 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11364    |
|    fps              | 36       |
|    time_elapsed     | 6562     |
|    total_timesteps  | 239984   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.48e-05 |
|    n_updates        | 49995    |
----------------------------------
Eval num_timesteps=240000, episode_reward=-0.02 +/- 0.20
Episode length: 16.36 +/- 1.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | -0.0244  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 240000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00703  |
|    n_updates        | 49999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00742  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11368    |
|    fps              | 36       |
|    time_elapsed     | 6567     |
|    total_timesteps  | 240047   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.44e-05 |
|    n_updates        | 50011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11372    |
|    fps              | 36       |
|    time_elapsed     | 6567     |
|    total_timesteps  | 240111   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.78e-05 |
|    n_updates        | 50027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0154  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11376    |
|    fps              | 36       |
|    time_elapsed     | 6568     |
|    total_timesteps  | 240238   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.81e-05 |
|    n_updates        | 50059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0178  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11380    |
|    fps              | 36       |
|    time_elapsed     | 6569     |
|    total_timesteps  | 240361   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.59e-05 |
|    n_updates        | 50090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.02    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11384    |
|    fps              | 36       |
|    time_elapsed     | 6570     |
|    total_timesteps  | 240484   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.07e-05 |
|    n_updates        | 50120    |
----------------------------------
Eval num_timesteps=240500, episode_reward=-0.09 +/- 0.24
Episode length: 31.82 +/- 25.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 31.8     |
|    mean_reward      | -0.0865  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 240500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.11e-05 |
|    n_updates        | 50124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | -0.00988 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11388    |
|    fps              | 36       |
|    time_elapsed     | 6577     |
|    total_timesteps  | 240544   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.24e-05 |
|    n_updates        | 50135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | -0.0123  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11392    |
|    fps              | 36       |
|    time_elapsed     | 6578     |
|    total_timesteps  | 240668   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.38e-05 |
|    n_updates        | 50166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00465 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11396    |
|    fps              | 36       |
|    time_elapsed     | 6579     |
|    total_timesteps  | 240791   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.69e-05 |
|    n_updates        | 50197    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00465 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11400    |
|    fps              | 36       |
|    time_elapsed     | 6579     |
|    total_timesteps  | 240855   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.94e-05 |
|    n_updates        | 50213    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00461 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11404    |
|    fps              | 36       |
|    time_elapsed     | 6580     |
|    total_timesteps  | 240915   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.4e-05  |
|    n_updates        | 50228    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00461 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11408    |
|    fps              | 36       |
|    time_elapsed     | 6580     |
|    total_timesteps  | 240979   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.17e-05 |
|    n_updates        | 50244    |
----------------------------------
Eval num_timesteps=241000, episode_reward=0.05 +/- 0.37
Episode length: 23.12 +/- 17.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 23.1     |
|    mean_reward      | 0.0485   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 241000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.36e-05 |
|    n_updates        | 50249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.00581 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11412    |
|    fps              | 36       |
|    time_elapsed     | 6587     |
|    total_timesteps  | 241073   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.22e-05 |
|    n_updates        | 50268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0168  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11416    |
|    fps              | 36       |
|    time_elapsed     | 6587     |
|    total_timesteps  | 241159   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.37e-05 |
|    n_updates        | 50289    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0169  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11420    |
|    fps              | 36       |
|    time_elapsed     | 6588     |
|    total_timesteps  | 241226   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.88e-05 |
|    n_updates        | 50306    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0169  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11424    |
|    fps              | 36       |
|    time_elapsed     | 6588     |
|    total_timesteps  | 241290   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.06e-05 |
|    n_updates        | 50322    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00745 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11428    |
|    fps              | 36       |
|    time_elapsed     | 6588     |
|    total_timesteps  | 241367   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0067   |
|    n_updates        | 50341    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.0024   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11432    |
|    fps              | 36       |
|    time_elapsed     | 6589     |
|    total_timesteps  | 241435   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.97e-05 |
|    n_updates        | 50358    |
----------------------------------
Eval num_timesteps=241500, episode_reward=-0.03 +/- 0.20
Episode length: 16.86 +/- 1.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.9     |
|    mean_reward      | -0.0264  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 241500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.05e-05 |
|    n_updates        | 50374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00216  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11436    |
|    fps              | 36       |
|    time_elapsed     | 6594     |
|    total_timesteps  | 241505   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.21e-05 |
|    n_updates        | 50376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.0121   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11440    |
|    fps              | 36       |
|    time_elapsed     | 6594     |
|    total_timesteps  | 241571   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00699  |
|    n_updates        | 50392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.00191  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11444    |
|    fps              | 36       |
|    time_elapsed     | 6595     |
|    total_timesteps  | 241636   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00749  |
|    n_updates        | 50408    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | 0.00195  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11448    |
|    fps              | 36       |
|    time_elapsed     | 6595     |
|    total_timesteps  | 241700   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.39e-05 |
|    n_updates        | 50424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00199  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11452    |
|    fps              | 36       |
|    time_elapsed     | 6596     |
|    total_timesteps  | 241764   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.79e-05 |
|    n_updates        | 50440    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | 0.00207  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11456    |
|    fps              | 36       |
|    time_elapsed     | 6596     |
|    total_timesteps  | 241828   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.83e-05 |
|    n_updates        | 50456    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.00829 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11460    |
|    fps              | 36       |
|    time_elapsed     | 6597     |
|    total_timesteps  | 241897   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.3e-05  |
|    n_updates        | 50474    |
----------------------------------
Eval num_timesteps=242000, episode_reward=-0.04 +/- 0.21
Episode length: 20.66 +/- 16.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20.7     |
|    mean_reward      | -0.0417  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 242000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.14e-05 |
|    n_updates        | 50499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0121  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11464    |
|    fps              | 36       |
|    time_elapsed     | 6603     |
|    total_timesteps  | 242059   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.55e-05 |
|    n_updates        | 50514    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11468    |
|    fps              | 36       |
|    time_elapsed     | 6604     |
|    total_timesteps  | 242123   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.71e-05 |
|    n_updates        | 50530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.012   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11472    |
|    fps              | 36       |
|    time_elapsed     | 6604     |
|    total_timesteps  | 242185   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.3e-05  |
|    n_updates        | 50546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.00948 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11476    |
|    fps              | 36       |
|    time_elapsed     | 6605     |
|    total_timesteps  | 242249   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.7e-05  |
|    n_updates        | 50562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.00711 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11480    |
|    fps              | 36       |
|    time_elapsed     | 6605     |
|    total_timesteps  | 242313   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6e-05    |
|    n_updates        | 50578    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.00474 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11484    |
|    fps              | 36       |
|    time_elapsed     | 6606     |
|    total_timesteps  | 242377   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.25e-05 |
|    n_updates        | 50594    |
----------------------------------
Eval num_timesteps=242500, episode_reward=0.06 +/- 0.36
Episode length: 19.34 +/- 14.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.3     |
|    mean_reward      | 0.0637   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 242500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 50624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0173  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11488    |
|    fps              | 36       |
|    time_elapsed     | 6611     |
|    total_timesteps  | 242500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.0149  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11492    |
|    fps              | 36       |
|    time_elapsed     | 6612     |
|    total_timesteps  | 242564   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.83e-05 |
|    n_updates        | 50640    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0225  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11496    |
|    fps              | 36       |
|    time_elapsed     | 6612     |
|    total_timesteps  | 242629   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00727  |
|    n_updates        | 50657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11500    |
|    fps              | 36       |
|    time_elapsed     | 6613     |
|    total_timesteps  | 242697   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.3e-05  |
|    n_updates        | 50674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0329  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11504    |
|    fps              | 36       |
|    time_elapsed     | 6613     |
|    total_timesteps  | 242763   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.78e-05 |
|    n_updates        | 50690    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11508    |
|    fps              | 36       |
|    time_elapsed     | 6613     |
|    total_timesteps  | 242823   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.08e-05 |
|    n_updates        | 50705    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0239  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11512    |
|    fps              | 36       |
|    time_elapsed     | 6614     |
|    total_timesteps  | 242946   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.16e-05 |
|    n_updates        | 50736    |
----------------------------------
Eval num_timesteps=243000, episode_reward=0.03 +/- 0.31
Episode length: 18.18 +/- 11.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.2     |
|    mean_reward      | 0.0283   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 243000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.59e-05 |
|    n_updates        | 50749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11516    |
|    fps              | 36       |
|    time_elapsed     | 6619     |
|    total_timesteps  | 243010   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.62e-05 |
|    n_updates        | 50752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11520    |
|    fps              | 36       |
|    time_elapsed     | 6620     |
|    total_timesteps  | 243074   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.7e-05  |
|    n_updates        | 50768    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0152  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11524    |
|    fps              | 36       |
|    time_elapsed     | 6621     |
|    total_timesteps  | 243195   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.63e-05 |
|    n_updates        | 50798    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0275  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11528    |
|    fps              | 36       |
|    time_elapsed     | 6622     |
|    total_timesteps  | 243330   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.58e-05 |
|    n_updates        | 50832    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0272  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11532    |
|    fps              | 36       |
|    time_elapsed     | 6622     |
|    total_timesteps  | 243390   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.09e-05 |
|    n_updates        | 50847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11536    |
|    fps              | 36       |
|    time_elapsed     | 6623     |
|    total_timesteps  | 243454   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.99e-05 |
|    n_updates        | 50863    |
----------------------------------
Eval num_timesteps=243500, episode_reward=-0.03 +/- 0.20
Episode length: 17.04 +/- 8.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17       |
|    mean_reward      | -0.0271  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 243500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.05e-05 |
|    n_updates        | 50874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0369  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11540    |
|    fps              | 36       |
|    time_elapsed     | 6627     |
|    total_timesteps  | 243518   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.46e-05 |
|    n_updates        | 50879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | -0.0269  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11544    |
|    fps              | 36       |
|    time_elapsed     | 6628     |
|    total_timesteps  | 243582   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.33e-05 |
|    n_updates        | 50895    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0292  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11548    |
|    fps              | 36       |
|    time_elapsed     | 6629     |
|    total_timesteps  | 243705   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.81e-05 |
|    n_updates        | 50926    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | -0.0292  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11552    |
|    fps              | 36       |
|    time_elapsed     | 6629     |
|    total_timesteps  | 243769   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.53e-05 |
|    n_updates        | 50942    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.0191  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11556    |
|    fps              | 36       |
|    time_elapsed     | 6629     |
|    total_timesteps  | 243831   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.98e-05 |
|    n_updates        | 50957    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20       |
|    ep_rew_mean      | -0.00893 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11560    |
|    fps              | 36       |
|    time_elapsed     | 6630     |
|    total_timesteps  | 243895   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.54e-05 |
|    n_updates        | 50973    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00517  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11564    |
|    fps              | 36       |
|    time_elapsed     | 6630     |
|    total_timesteps  | 243955   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.78e-05 |
|    n_updates        | 50988    |
----------------------------------
Eval num_timesteps=244000, episode_reward=0.03 +/- 0.31
Episode length: 17.08 +/- 8.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.1     |
|    mean_reward      | 0.0327   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 244000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.37e-05 |
|    n_updates        | 50999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0152   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11568    |
|    fps              | 36       |
|    time_elapsed     | 6635     |
|    total_timesteps  | 244017   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.66e-05 |
|    n_updates        | 51004    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00516  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11572    |
|    fps              | 36       |
|    time_elapsed     | 6635     |
|    total_timesteps  | 244081   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.7e-05  |
|    n_updates        | 51020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.00512  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11576    |
|    fps              | 36       |
|    time_elapsed     | 6636     |
|    total_timesteps  | 244146   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00663  |
|    n_updates        | 51036    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.00271  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11580    |
|    fps              | 36       |
|    time_elapsed     | 6636     |
|    total_timesteps  | 244270   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.84e-05 |
|    n_updates        | 51067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11584    |
|    fps              | 36       |
|    time_elapsed     | 6637     |
|    total_timesteps  | 244330   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00701  |
|    n_updates        | 51082    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0153   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11588    |
|    fps              | 36       |
|    time_elapsed     | 6637     |
|    total_timesteps  | 244394   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.65e-05 |
|    n_updates        | 51098    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11592    |
|    fps              | 36       |
|    time_elapsed     | 6638     |
|    total_timesteps  | 244457   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.03e-05 |
|    n_updates        | 51114    |
----------------------------------
Eval num_timesteps=244500, episode_reward=-0.03 +/- 0.21
Episode length: 18.44 +/- 11.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.4     |
|    mean_reward      | -0.0327  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 244500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.25e-05 |
|    n_updates        | 51124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11596    |
|    fps              | 36       |
|    time_elapsed     | 6642     |
|    total_timesteps  | 244522   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.44e-05 |
|    n_updates        | 51130    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | 0.0252   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11600    |
|    fps              | 36       |
|    time_elapsed     | 6643     |
|    total_timesteps  | 244593   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.42e-05 |
|    n_updates        | 51148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.0205   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11604    |
|    fps              | 36       |
|    time_elapsed     | 6644     |
|    total_timesteps  | 244777   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00734  |
|    n_updates        | 51194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11608    |
|    fps              | 36       |
|    time_elapsed     | 6645     |
|    total_timesteps  | 244841   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.42e-05 |
|    n_updates        | 51210    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.0127   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11612    |
|    fps              | 36       |
|    time_elapsed     | 6645     |
|    total_timesteps  | 244905   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.09e-05 |
|    n_updates        | 51226    |
----------------------------------
Eval num_timesteps=245000, episode_reward=-0.00 +/- 0.24
Episode length: 15.90 +/- 0.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.00256 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 245000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00736  |
|    n_updates        | 51249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.0103   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11616    |
|    fps              | 36       |
|    time_elapsed     | 6650     |
|    total_timesteps  | 245029   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.07e-05 |
|    n_updates        | 51257    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.0203   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11620    |
|    fps              | 36       |
|    time_elapsed     | 6650     |
|    total_timesteps  | 245091   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.74e-05 |
|    n_updates        | 51272    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | 0.0204   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11624    |
|    fps              | 36       |
|    time_elapsed     | 6651     |
|    total_timesteps  | 245211   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.27e-05 |
|    n_updates        | 51302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | 0.0232   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11628    |
|    fps              | 36       |
|    time_elapsed     | 6651     |
|    total_timesteps  | 245275   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.55e-05 |
|    n_updates        | 51318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.013    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11632    |
|    fps              | 36       |
|    time_elapsed     | 6652     |
|    total_timesteps  | 245339   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.43e-05 |
|    n_updates        | 51334    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11636    |
|    fps              | 36       |
|    time_elapsed     | 6652     |
|    total_timesteps  | 245405   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0077   |
|    n_updates        | 51351    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.0129   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11640    |
|    fps              | 36       |
|    time_elapsed     | 6653     |
|    total_timesteps  | 245469   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.03e-05 |
|    n_updates        | 51367    |
----------------------------------
Eval num_timesteps=245500, episode_reward=-0.02 +/- 0.25
Episode length: 19.14 +/- 11.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 19.1     |
|    mean_reward      | -0.0156  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 245500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.04e-05 |
|    n_updates        | 51374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.1     |
|    ep_rew_mean      | 0.00056  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11644    |
|    fps              | 36       |
|    time_elapsed     | 6658     |
|    total_timesteps  | 245592   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.4e-05  |
|    n_updates        | 51397    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.00281  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11648    |
|    fps              | 36       |
|    time_elapsed     | 6659     |
|    total_timesteps  | 245659   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.92e-05 |
|    n_updates        | 51414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.5     |
|    ep_rew_mean      | 0.00281  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11652    |
|    fps              | 36       |
|    time_elapsed     | 6659     |
|    total_timesteps  | 245723   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.32e-05 |
|    n_updates        | 51430    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | 0.00261  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11656    |
|    fps              | 36       |
|    time_elapsed     | 6660     |
|    total_timesteps  | 245790   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.29e-05 |
|    n_updates        | 51447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00741 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11660    |
|    fps              | 36       |
|    time_elapsed     | 6660     |
|    total_timesteps  | 245854   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.71e-05 |
|    n_updates        | 51463    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00752 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11664    |
|    fps              | 36       |
|    time_elapsed     | 6660     |
|    total_timesteps  | 245917   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00636  |
|    n_updates        | 51479    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0176  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11668    |
|    fps              | 36       |
|    time_elapsed     | 6661     |
|    total_timesteps  | 245981   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00685  |
|    n_updates        | 51495    |
----------------------------------
Eval num_timesteps=246000, episode_reward=-0.03 +/- 0.21
Episode length: 18.30 +/- 11.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.3     |
|    mean_reward      | -0.0322  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 246000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.17e-05 |
|    n_updates        | 51499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0176  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11672    |
|    fps              | 36       |
|    time_elapsed     | 6665     |
|    total_timesteps  | 246045   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.31e-05 |
|    n_updates        | 51511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.00746 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11676    |
|    fps              | 36       |
|    time_elapsed     | 6666     |
|    total_timesteps  | 246107   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.66e-05 |
|    n_updates        | 51526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19       |
|    ep_rew_mean      | -0.00513 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11680    |
|    fps              | 36       |
|    time_elapsed     | 6666     |
|    total_timesteps  | 246173   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.55e-05 |
|    n_updates        | 51543    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0154  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11684    |
|    fps              | 36       |
|    time_elapsed     | 6667     |
|    total_timesteps  | 246239   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.92e-05 |
|    n_updates        | 51559    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0154  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11688    |
|    fps              | 36       |
|    time_elapsed     | 6667     |
|    total_timesteps  | 246303   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.84e-05 |
|    n_updates        | 51575    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11692    |
|    fps              | 36       |
|    time_elapsed     | 6668     |
|    total_timesteps  | 246373   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.24e-05 |
|    n_updates        | 51593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.2     |
|    ep_rew_mean      | -0.0257  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11696    |
|    fps              | 36       |
|    time_elapsed     | 6668     |
|    total_timesteps  | 246438   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00718  |
|    n_updates        | 51609    |
----------------------------------
Eval num_timesteps=246500, episode_reward=-0.02 +/- 0.25
Episode length: 20.70 +/- 16.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 20.7     |
|    mean_reward      | -0.0219  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 246500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.8e-05  |
|    n_updates        | 51624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0254  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11700    |
|    fps              | 36       |
|    time_elapsed     | 6673     |
|    total_timesteps  | 246502   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.22e-05 |
|    n_updates        | 51625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11704    |
|    fps              | 36       |
|    time_elapsed     | 6674     |
|    total_timesteps  | 246625   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.21e-05 |
|    n_updates        | 51656    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.5     |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11708    |
|    fps              | 36       |
|    time_elapsed     | 6675     |
|    total_timesteps  | 246689   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.22e-05 |
|    n_updates        | 51672    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11712    |
|    fps              | 36       |
|    time_elapsed     | 6675     |
|    total_timesteps  | 246750   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.31e-05 |
|    n_updates        | 51687    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0104  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11716    |
|    fps              | 36       |
|    time_elapsed     | 6675     |
|    total_timesteps  | 246814   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.57e-05 |
|    n_updates        | 51703    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.0206  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11720    |
|    fps              | 36       |
|    time_elapsed     | 6676     |
|    total_timesteps  | 246880   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.87e-05 |
|    n_updates        | 51719    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0183  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11724    |
|    fps              | 36       |
|    time_elapsed     | 6676     |
|    total_timesteps  | 246944   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00769  |
|    n_updates        | 51735    |
----------------------------------
Eval num_timesteps=247000, episode_reward=-0.05 +/- 0.30
Episode length: 32.38 +/- 21.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 32.4     |
|    mean_reward      | -0.0486  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 247000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.65e-05 |
|    n_updates        | 51749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0184  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11728    |
|    fps              | 36       |
|    time_elapsed     | 6684     |
|    total_timesteps  | 247010   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.62e-05 |
|    n_updates        | 51752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00856 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11732    |
|    fps              | 36       |
|    time_elapsed     | 6685     |
|    total_timesteps  | 247078   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.43e-05 |
|    n_updates        | 51769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00884 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11736    |
|    fps              | 36       |
|    time_elapsed     | 6685     |
|    total_timesteps  | 247151   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.28e-05 |
|    n_updates        | 51787    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.1     |
|    ep_rew_mean      | -0.0112  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11740    |
|    fps              | 36       |
|    time_elapsed     | 6686     |
|    total_timesteps  | 247274   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.68e-05 |
|    n_updates        | 51818    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00896 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11744    |
|    fps              | 36       |
|    time_elapsed     | 6686     |
|    total_timesteps  | 247341   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.31e-05 |
|    n_updates        | 51835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00059  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11748    |
|    fps              | 36       |
|    time_elapsed     | 6687     |
|    total_timesteps  | 247419   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.82e-05 |
|    n_updates        | 51854    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.0105   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11752    |
|    fps              | 37       |
|    time_elapsed     | 6688     |
|    total_timesteps  | 247485   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0136   |
|    n_updates        | 51871    |
----------------------------------
Eval num_timesteps=247500, episode_reward=-0.03 +/- 0.25
Episode length: 23.84 +/- 15.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 23.8     |
|    mean_reward      | -0.0344  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 247500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.77e-05 |
|    n_updates        | 51874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00648 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11756    |
|    fps              | 37       |
|    time_elapsed     | 6695     |
|    total_timesteps  | 247726   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.93e-05 |
|    n_updates        | 51931    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11760    |
|    fps              | 37       |
|    time_elapsed     | 6696     |
|    total_timesteps  | 247920   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00687  |
|    n_updates        | 51979    |
----------------------------------
Eval num_timesteps=248000, episode_reward=0.03 +/- 0.34
Episode length: 23.90 +/- 16.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 23.9     |
|    mean_reward      | 0.0254   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 248000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.42e-05 |
|    n_updates        | 51999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0238  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11764    |
|    fps              | 37       |
|    time_elapsed     | 6702     |
|    total_timesteps  | 248035   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.89e-05 |
|    n_updates        | 52008    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | -0.0264  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11768    |
|    fps              | 37       |
|    time_elapsed     | 6703     |
|    total_timesteps  | 248163   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.71e-05 |
|    n_updates        | 52040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | -0.0163  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11772    |
|    fps              | 37       |
|    time_elapsed     | 6703     |
|    total_timesteps  | 248224   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.68e-05 |
|    n_updates        | 52055    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | -0.0263  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11776    |
|    fps              | 37       |
|    time_elapsed     | 6703     |
|    total_timesteps  | 248288   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.61e-05 |
|    n_updates        | 52071    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | -0.0263  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11780    |
|    fps              | 37       |
|    time_elapsed     | 6704     |
|    total_timesteps  | 248352   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.18e-05 |
|    n_updates        | 52087    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | -0.0262  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11784    |
|    fps              | 37       |
|    time_elapsed     | 6704     |
|    total_timesteps  | 248416   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2e-05    |
|    n_updates        | 52103    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.8     |
|    ep_rew_mean      | -0.0262  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11788    |
|    fps              | 37       |
|    time_elapsed     | 6705     |
|    total_timesteps  | 248480   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.44e-05 |
|    n_updates        | 52119    |
----------------------------------
Eval num_timesteps=248500, episode_reward=-0.03 +/- 0.26
Episode length: 21.92 +/- 17.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 21.9     |
|    mean_reward      | -0.0268  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 248500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.69e-05 |
|    n_updates        | 52124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.0259  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11792    |
|    fps              | 37       |
|    time_elapsed     | 6710     |
|    total_timesteps  | 248544   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.94e-05 |
|    n_updates        | 52135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.026   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11796    |
|    fps              | 37       |
|    time_elapsed     | 6711     |
|    total_timesteps  | 248611   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00732  |
|    n_updates        | 52152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.7     |
|    ep_rew_mean      | -0.026   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11800    |
|    fps              | 37       |
|    time_elapsed     | 6711     |
|    total_timesteps  | 248675   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00694  |
|    n_updates        | 52168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11804    |
|    fps              | 37       |
|    time_elapsed     | 6711     |
|    total_timesteps  | 248735   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.94e-05 |
|    n_updates        | 52183    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11808    |
|    fps              | 37       |
|    time_elapsed     | 6712     |
|    total_timesteps  | 248799   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.3e-05  |
|    n_updates        | 52199    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0236  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11812    |
|    fps              | 37       |
|    time_elapsed     | 6712     |
|    total_timesteps  | 248863   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.86e-05 |
|    n_updates        | 52215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11816    |
|    fps              | 37       |
|    time_elapsed     | 6713     |
|    total_timesteps  | 248923   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.23e-05 |
|    n_updates        | 52230    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.00326 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11820    |
|    fps              | 37       |
|    time_elapsed     | 6713     |
|    total_timesteps  | 248985   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 52246    |
----------------------------------
Eval num_timesteps=249000, episode_reward=0.07 +/- 0.35
Episode length: 16.84 +/- 8.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.8     |
|    mean_reward      | 0.0736   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 249000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.29e-05 |
|    n_updates        | 52249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11824    |
|    fps              | 37       |
|    time_elapsed     | 6718     |
|    total_timesteps  | 249051   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.6e-05  |
|    n_updates        | 52262    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.00315 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11828    |
|    fps              | 37       |
|    time_elapsed     | 6718     |
|    total_timesteps  | 249112   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00673  |
|    n_updates        | 52277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11832    |
|    fps              | 37       |
|    time_elapsed     | 6719     |
|    total_timesteps  | 249177   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.41e-05 |
|    n_updates        | 52294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0127  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11836    |
|    fps              | 37       |
|    time_elapsed     | 6719     |
|    total_timesteps  | 249241   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.56e-05 |
|    n_updates        | 52310    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11840    |
|    fps              | 37       |
|    time_elapsed     | 6719     |
|    total_timesteps  | 249305   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00724  |
|    n_updates        | 52326    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.3     |
|    ep_rew_mean      | -0.0103  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11844    |
|    fps              | 37       |
|    time_elapsed     | 6720     |
|    total_timesteps  | 249373   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.28e-05 |
|    n_updates        | 52343    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0221  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11848    |
|    fps              | 37       |
|    time_elapsed     | 6721     |
|    total_timesteps  | 249496   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.71e-05 |
|    n_updates        | 52373    |
----------------------------------
Eval num_timesteps=249500, episode_reward=0.03 +/- 0.31
Episode length: 18.10 +/- 11.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.1     |
|    mean_reward      | 0.0286   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 249500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00722  |
|    n_updates        | 52374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.0219  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11852    |
|    fps              | 37       |
|    time_elapsed     | 6725     |
|    total_timesteps  | 249556   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.46e-05 |
|    n_updates        | 52388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.9     |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11856    |
|    fps              | 37       |
|    time_elapsed     | 6726     |
|    total_timesteps  | 249620   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.01e-05 |
|    n_updates        | 52404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00956 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11860    |
|    fps              | 37       |
|    time_elapsed     | 6726     |
|    total_timesteps  | 249684   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3e-05    |
|    n_updates        | 52420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.00776 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11864    |
|    fps              | 37       |
|    time_elapsed     | 6727     |
|    total_timesteps  | 249754   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.14e-05 |
|    n_updates        | 52438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00756 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11868    |
|    fps              | 37       |
|    time_elapsed     | 6727     |
|    total_timesteps  | 249877   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.17e-05 |
|    n_updates        | 52469    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11872    |
|    fps              | 37       |
|    time_elapsed     | 6728     |
|    total_timesteps  | 249941   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.7e-05  |
|    n_updates        | 52485    |
----------------------------------
Eval num_timesteps=250000, episode_reward=-0.01 +/- 0.25
Episode length: 18.18 +/- 11.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.2     |
|    mean_reward      | -0.0118  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 250000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.82e-05 |
|    n_updates        | 52499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11876    |
|    fps              | 37       |
|    time_elapsed     | 6732     |
|    total_timesteps  | 250005   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.69e-05 |
|    n_updates        | 52501    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11880    |
|    fps              | 37       |
|    time_elapsed     | 6733     |
|    total_timesteps  | 250069   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.91e-05 |
|    n_updates        | 52517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0178  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11884    |
|    fps              | 37       |
|    time_elapsed     | 6733     |
|    total_timesteps  | 250136   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.52e-05 |
|    n_updates        | 52533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0178  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11888    |
|    fps              | 37       |
|    time_elapsed     | 6734     |
|    total_timesteps  | 250200   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 52549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0178  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11892    |
|    fps              | 37       |
|    time_elapsed     | 6734     |
|    total_timesteps  | 250265   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.86e-05 |
|    n_updates        | 52566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00753 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11896    |
|    fps              | 37       |
|    time_elapsed     | 6735     |
|    total_timesteps  | 250325   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.17e-05 |
|    n_updates        | 52581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00753 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11900    |
|    fps              | 37       |
|    time_elapsed     | 6735     |
|    total_timesteps  | 250389   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.8e-05  |
|    n_updates        | 52597    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11904    |
|    fps              | 37       |
|    time_elapsed     | 6736     |
|    total_timesteps  | 250453   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.31e-05 |
|    n_updates        | 52613    |
----------------------------------
Eval num_timesteps=250500, episode_reward=-0.01 +/- 0.24
Episode length: 17.18 +/- 8.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.2     |
|    mean_reward      | -0.00766 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 250500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00737  |
|    n_updates        | 52624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00756 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11908    |
|    fps              | 37       |
|    time_elapsed     | 6740     |
|    total_timesteps  | 250513   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.7e-05  |
|    n_updates        | 52628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.00756 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11912    |
|    fps              | 37       |
|    time_elapsed     | 6741     |
|    total_timesteps  | 250577   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 52644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0177  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11916    |
|    fps              | 37       |
|    time_elapsed     | 6741     |
|    total_timesteps  | 250641   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.62e-05 |
|    n_updates        | 52660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.03    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11920    |
|    fps              | 37       |
|    time_elapsed     | 6742     |
|    total_timesteps  | 250760   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.35e-05 |
|    n_updates        | 52689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.6     |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11924    |
|    fps              | 37       |
|    time_elapsed     | 6743     |
|    total_timesteps  | 250906   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.41e-05 |
|    n_updates        | 52726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11928    |
|    fps              | 37       |
|    time_elapsed     | 6743     |
|    total_timesteps  | 250988   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 52746    |
----------------------------------
Eval num_timesteps=251000, episode_reward=0.06 +/- 0.33
Episode length: 16.00 +/- 1.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.0571   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 251000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00735  |
|    n_updates        | 52749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0441  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11932    |
|    fps              | 37       |
|    time_elapsed     | 6748     |
|    total_timesteps  | 251054   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00754  |
|    n_updates        | 52763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.1     |
|    ep_rew_mean      | -0.0452  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11936    |
|    fps              | 37       |
|    time_elapsed     | 6749     |
|    total_timesteps  | 251146   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00702  |
|    n_updates        | 52786    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.7     |
|    ep_rew_mean      | -0.0478  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11940    |
|    fps              | 37       |
|    time_elapsed     | 6749     |
|    total_timesteps  | 251274   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.76e-05 |
|    n_updates        | 52818    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.7     |
|    ep_rew_mean      | -0.052   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11944    |
|    fps              | 37       |
|    time_elapsed     | 6751     |
|    total_timesteps  | 251447   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.75e-05 |
|    n_updates        | 52861    |
----------------------------------
Eval num_timesteps=251500, episode_reward=0.04 +/- 0.42
Episode length: 39.82 +/- 20.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.8     |
|    mean_reward      | 0.0418   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 251500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.31e-05 |
|    n_updates        | 52874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.052   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11948    |
|    fps              | 37       |
|    time_elapsed     | 6761     |
|    total_timesteps  | 251572   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.58e-05 |
|    n_updates        | 52892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0624  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11952    |
|    fps              | 37       |
|    time_elapsed     | 6762     |
|    total_timesteps  | 251641   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.1e-05  |
|    n_updates        | 52910    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0525  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11956    |
|    fps              | 37       |
|    time_elapsed     | 6762     |
|    total_timesteps  | 251706   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00703  |
|    n_updates        | 52926    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0547  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11960    |
|    fps              | 37       |
|    time_elapsed     | 6763     |
|    total_timesteps  | 251826   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.05e-05 |
|    n_updates        | 52956    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.4     |
|    ep_rew_mean      | -0.0545  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11964    |
|    fps              | 37       |
|    time_elapsed     | 6764     |
|    total_timesteps  | 251891   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.59e-05 |
|    n_updates        | 52972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0522  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11968    |
|    fps              | 37       |
|    time_elapsed     | 6764     |
|    total_timesteps  | 251958   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.75e-05 |
|    n_updates        | 52989    |
----------------------------------
Eval num_timesteps=252000, episode_reward=-0.00 +/- 0.24
Episode length: 15.94 +/- 0.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.0027  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 252000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.12e-05 |
|    n_updates        | 52999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0522  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11972    |
|    fps              | 37       |
|    time_elapsed     | 6768     |
|    total_timesteps  | 252022   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.64e-05 |
|    n_updates        | 53005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.8     |
|    ep_rew_mean      | -0.0522  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11976    |
|    fps              | 37       |
|    time_elapsed     | 6769     |
|    total_timesteps  | 252086   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.21e-05 |
|    n_updates        | 53021    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0525  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11980    |
|    fps              | 37       |
|    time_elapsed     | 6770     |
|    total_timesteps  | 252156   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00826  |
|    n_updates        | 53038    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0527  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11984    |
|    fps              | 37       |
|    time_elapsed     | 6770     |
|    total_timesteps  | 252229   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.43e-05 |
|    n_updates        | 53057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.9     |
|    ep_rew_mean      | -0.0528  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11988    |
|    fps              | 37       |
|    time_elapsed     | 6771     |
|    total_timesteps  | 252295   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00699  |
|    n_updates        | 53073    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0533  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11992    |
|    fps              | 37       |
|    time_elapsed     | 6771     |
|    total_timesteps  | 252373   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00739  |
|    n_updates        | 53093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0636  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 11996    |
|    fps              | 37       |
|    time_elapsed     | 6772     |
|    total_timesteps  | 252440   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.38e-05 |
|    n_updates        | 53109    |
----------------------------------
Eval num_timesteps=252500, episode_reward=-0.01 +/- 0.25
Episode length: 17.44 +/- 8.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.4     |
|    mean_reward      | -0.00876 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 252500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00751  |
|    n_updates        | 53124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0636  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12000    |
|    fps              | 37       |
|    time_elapsed     | 6777     |
|    total_timesteps  | 252504   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.72e-05 |
|    n_updates        | 53125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.1     |
|    ep_rew_mean      | -0.0636  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12004    |
|    fps              | 37       |
|    time_elapsed     | 6777     |
|    total_timesteps  | 252568   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3e-05    |
|    n_updates        | 53141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0738  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12008    |
|    fps              | 37       |
|    time_elapsed     | 6778     |
|    total_timesteps  | 252632   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.51e-05 |
|    n_updates        | 53157    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0738  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12012    |
|    fps              | 37       |
|    time_elapsed     | 6778     |
|    total_timesteps  | 252696   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.71e-05 |
|    n_updates        | 53173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 21.2     |
|    ep_rew_mean      | -0.0738  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12016    |
|    fps              | 37       |
|    time_elapsed     | 6779     |
|    total_timesteps  | 252760   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00707  |
|    n_updates        | 53189    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.6     |
|    ep_rew_mean      | -0.0614  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12020    |
|    fps              | 37       |
|    time_elapsed     | 6779     |
|    total_timesteps  | 252821   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00782  |
|    n_updates        | 53205    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.8     |
|    ep_rew_mean      | -0.0582  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12024    |
|    fps              | 37       |
|    time_elapsed     | 6779     |
|    total_timesteps  | 252885   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000163 |
|    n_updates        | 53221    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0473  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12028    |
|    fps              | 37       |
|    time_elapsed     | 6780     |
|    total_timesteps  | 252946   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.82e-05 |
|    n_updates        | 53236    |
----------------------------------
Eval num_timesteps=253000, episode_reward=-0.06 +/- 0.00
Episode length: 16.14 +/- 0.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0636  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 253000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.94e-05 |
|    n_updates        | 53249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.6     |
|    ep_rew_mean      | -0.0474  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12032    |
|    fps              | 37       |
|    time_elapsed     | 6785     |
|    total_timesteps  | 253013   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00677  |
|    n_updates        | 53253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.0462  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12036    |
|    fps              | 37       |
|    time_elapsed     | 6785     |
|    total_timesteps  | 253077   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.54e-05 |
|    n_updates        | 53269    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.044   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12040    |
|    fps              | 37       |
|    time_elapsed     | 6786     |
|    total_timesteps  | 253148   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.18e-05 |
|    n_updates        | 53286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0396  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12044    |
|    fps              | 37       |
|    time_elapsed     | 6786     |
|    total_timesteps  | 253212   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.18e-05 |
|    n_updates        | 53302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0371  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12048    |
|    fps              | 37       |
|    time_elapsed     | 6787     |
|    total_timesteps  | 253276   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.76e-05 |
|    n_updates        | 53318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0369  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12052    |
|    fps              | 37       |
|    time_elapsed     | 6787     |
|    total_timesteps  | 253340   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00698  |
|    n_updates        | 53334    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0368  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12056    |
|    fps              | 37       |
|    time_elapsed     | 6788     |
|    total_timesteps  | 253402   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.41e-05 |
|    n_updates        | 53350    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0346  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12060    |
|    fps              | 37       |
|    time_elapsed     | 6788     |
|    total_timesteps  | 253466   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.65e-05 |
|    n_updates        | 53366    |
----------------------------------
Eval num_timesteps=253500, episode_reward=-0.03 +/- 0.20
Episode length: 17.52 +/- 8.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.5     |
|    mean_reward      | -0.0291  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 253500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0131   |
|    n_updates        | 53374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0345  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12064    |
|    fps              | 37       |
|    time_elapsed     | 6793     |
|    total_timesteps  | 253530   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 53382    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12068    |
|    fps              | 37       |
|    time_elapsed     | 6793     |
|    total_timesteps  | 253601   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.71e-05 |
|    n_updates        | 53400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12072    |
|    fps              | 37       |
|    time_elapsed     | 6794     |
|    total_timesteps  | 253665   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.65e-05 |
|    n_updates        | 53416    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12076    |
|    fps              | 37       |
|    time_elapsed     | 6794     |
|    total_timesteps  | 253730   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.6e-05  |
|    n_updates        | 53432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0345  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12080    |
|    fps              | 37       |
|    time_elapsed     | 6794     |
|    total_timesteps  | 253794   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.69e-05 |
|    n_updates        | 53448    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0342  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12084    |
|    fps              | 37       |
|    time_elapsed     | 6795     |
|    total_timesteps  | 253859   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.56e-05 |
|    n_updates        | 53464    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12088    |
|    fps              | 37       |
|    time_elapsed     | 6795     |
|    total_timesteps  | 253921   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.64e-05 |
|    n_updates        | 53480    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12092    |
|    fps              | 37       |
|    time_elapsed     | 6796     |
|    total_timesteps  | 253992   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.22e-05 |
|    n_updates        | 53497    |
----------------------------------
Eval num_timesteps=254000, episode_reward=-0.00 +/- 0.24
Episode length: 16.26 +/- 1.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.3     |
|    mean_reward      | -0.00398 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 254000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.07e-05 |
|    n_updates        | 53499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0135  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12096    |
|    fps              | 37       |
|    time_elapsed     | 6800     |
|    total_timesteps  | 254054   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.32e-05 |
|    n_updates        | 53513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12100    |
|    fps              | 37       |
|    time_elapsed     | 6801     |
|    total_timesteps  | 254119   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.87e-05 |
|    n_updates        | 53529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12104    |
|    fps              | 37       |
|    time_elapsed     | 6801     |
|    total_timesteps  | 254184   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.59e-05 |
|    n_updates        | 53545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12108    |
|    fps              | 37       |
|    time_elapsed     | 6802     |
|    total_timesteps  | 254249   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00716  |
|    n_updates        | 53562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12112    |
|    fps              | 37       |
|    time_elapsed     | 6802     |
|    total_timesteps  | 254316   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.97e-05 |
|    n_updates        | 53578    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12116    |
|    fps              | 37       |
|    time_elapsed     | 6803     |
|    total_timesteps  | 254380   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.15e-05 |
|    n_updates        | 53594    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.024   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12120    |
|    fps              | 37       |
|    time_elapsed     | 6803     |
|    total_timesteps  | 254447   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.34e-05 |
|    n_updates        | 53611    |
----------------------------------
Eval num_timesteps=254500, episode_reward=-0.01 +/- 0.24
Episode length: 17.16 +/- 7.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.2     |
|    mean_reward      | -0.00754 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 254500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.76e-05 |
|    n_updates        | 53624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0241  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12124    |
|    fps              | 37       |
|    time_elapsed     | 6807     |
|    total_timesteps  | 254512   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.07e-05 |
|    n_updates        | 53627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0342  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12128    |
|    fps              | 37       |
|    time_elapsed     | 6808     |
|    total_timesteps  | 254576   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.15e-05 |
|    n_updates        | 53643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0341  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12132    |
|    fps              | 37       |
|    time_elapsed     | 6809     |
|    total_timesteps  | 254641   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.43e-05 |
|    n_updates        | 53660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0341  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12136    |
|    fps              | 37       |
|    time_elapsed     | 6809     |
|    total_timesteps  | 254706   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.87e-05 |
|    n_updates        | 53676    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0343  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12140    |
|    fps              | 37       |
|    time_elapsed     | 6809     |
|    total_timesteps  | 254780   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.16e-05 |
|    n_updates        | 53694    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12144    |
|    fps              | 37       |
|    time_elapsed     | 6810     |
|    total_timesteps  | 254847   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.5e-05  |
|    n_updates        | 53711    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0345  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12148    |
|    fps              | 37       |
|    time_elapsed     | 6810     |
|    total_timesteps  | 254913   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00713  |
|    n_updates        | 53728    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0345  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12152    |
|    fps              | 37       |
|    time_elapsed     | 6811     |
|    total_timesteps  | 254978   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.11e-05 |
|    n_updates        | 53744    |
----------------------------------
Eval num_timesteps=255000, episode_reward=0.04 +/- 0.31
Episode length: 16.44 +/- 2.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | 0.0352   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 255000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.03e-05 |
|    n_updates        | 53749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0448  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12156    |
|    fps              | 37       |
|    time_elapsed     | 6816     |
|    total_timesteps  | 255047   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 53761    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0448  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12160    |
|    fps              | 37       |
|    time_elapsed     | 6816     |
|    total_timesteps  | 255112   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.64e-05 |
|    n_updates        | 53777    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0448  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12164    |
|    fps              | 37       |
|    time_elapsed     | 6817     |
|    total_timesteps  | 255176   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00663  |
|    n_updates        | 53793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0445  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12168    |
|    fps              | 37       |
|    time_elapsed     | 6817     |
|    total_timesteps  | 255240   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.35e-05 |
|    n_updates        | 53809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0445  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12172    |
|    fps              | 37       |
|    time_elapsed     | 6818     |
|    total_timesteps  | 255304   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.03e-05 |
|    n_updates        | 53825    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0445  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12176    |
|    fps              | 37       |
|    time_elapsed     | 6818     |
|    total_timesteps  | 255369   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.26e-05 |
|    n_updates        | 53842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0344  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12180    |
|    fps              | 37       |
|    time_elapsed     | 6819     |
|    total_timesteps  | 255430   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.15e-05 |
|    n_updates        | 53857    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0345  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12184    |
|    fps              | 37       |
|    time_elapsed     | 6819     |
|    total_timesteps  | 255497   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.19e-05 |
|    n_updates        | 53874    |
----------------------------------
Eval num_timesteps=255500, episode_reward=-0.01 +/- 0.25
Episode length: 18.78 +/- 11.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.8     |
|    mean_reward      | -0.0141  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 255500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0446  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12188    |
|    fps              | 37       |
|    time_elapsed     | 6824     |
|    total_timesteps  | 255561   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0059   |
|    n_updates        | 53890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0467  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12192    |
|    fps              | 37       |
|    time_elapsed     | 6825     |
|    total_timesteps  | 255684   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.65e-05 |
|    n_updates        | 53920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0568  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12196    |
|    fps              | 37       |
|    time_elapsed     | 6825     |
|    total_timesteps  | 255748   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.54e-05 |
|    n_updates        | 53936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0567  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12200    |
|    fps              | 37       |
|    time_elapsed     | 6826     |
|    total_timesteps  | 255812   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.26e-05 |
|    n_updates        | 53952    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0569  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12204    |
|    fps              | 37       |
|    time_elapsed     | 6826     |
|    total_timesteps  | 255880   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00732  |
|    n_updates        | 53969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0569  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12208    |
|    fps              | 37       |
|    time_elapsed     | 6827     |
|    total_timesteps  | 255945   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.03e-05 |
|    n_updates        | 53986    |
----------------------------------
Eval num_timesteps=256000, episode_reward=0.04 +/- 0.31
Episode length: 16.48 +/- 2.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.5     |
|    mean_reward      | 0.0351   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 256000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.4e-05  |
|    n_updates        | 53999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0567  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12212    |
|    fps              | 37       |
|    time_elapsed     | 6831     |
|    total_timesteps  | 256009   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.3e-05  |
|    n_updates        | 54002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0467  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12216    |
|    fps              | 37       |
|    time_elapsed     | 6832     |
|    total_timesteps  | 256073   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.02e-05 |
|    n_updates        | 54018    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0467  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12220    |
|    fps              | 37       |
|    time_elapsed     | 6832     |
|    total_timesteps  | 256138   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.43e-05 |
|    n_updates        | 54034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0378  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12224    |
|    fps              | 37       |
|    time_elapsed     | 6833     |
|    total_timesteps  | 256231   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00725  |
|    n_updates        | 54057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0278  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12228    |
|    fps              | 37       |
|    time_elapsed     | 6833     |
|    total_timesteps  | 256295   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.18e-05 |
|    n_updates        | 54073    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0278  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12232    |
|    fps              | 37       |
|    time_elapsed     | 6834     |
|    total_timesteps  | 256361   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.37e-05 |
|    n_updates        | 54090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0278  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12236    |
|    fps              | 37       |
|    time_elapsed     | 6834     |
|    total_timesteps  | 256425   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00729  |
|    n_updates        | 54106    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0274  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12240    |
|    fps              | 37       |
|    time_elapsed     | 6835     |
|    total_timesteps  | 256490   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.31e-05 |
|    n_updates        | 54122    |
----------------------------------
Eval num_timesteps=256500, episode_reward=0.12 +/- 0.39
Episode length: 15.62 +/- 1.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.6     |
|    mean_reward      | 0.119    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 256500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.71e-05 |
|    n_updates        | 54124    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0273  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12244    |
|    fps              | 37       |
|    time_elapsed     | 6839     |
|    total_timesteps  | 256554   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.44e-05 |
|    n_updates        | 54138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0273  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12248    |
|    fps              | 37       |
|    time_elapsed     | 6839     |
|    total_timesteps  | 256619   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.77e-05 |
|    n_updates        | 54154    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0171  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12252    |
|    fps              | 37       |
|    time_elapsed     | 6840     |
|    total_timesteps  | 256679   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.15e-05 |
|    n_updates        | 54169    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12256    |
|    fps              | 37       |
|    time_elapsed     | 6841     |
|    total_timesteps  | 256802   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.79e-05 |
|    n_updates        | 54200    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0192  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12260    |
|    fps              | 37       |
|    time_elapsed     | 6841     |
|    total_timesteps  | 256867   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.5e-05  |
|    n_updates        | 54216    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00907 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12264    |
|    fps              | 37       |
|    time_elapsed     | 6841     |
|    total_timesteps  | 256927   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00731  |
|    n_updates        | 54231    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00911 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12268    |
|    fps              | 37       |
|    time_elapsed     | 6842     |
|    total_timesteps  | 256992   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.33e-05 |
|    n_updates        | 54247    |
----------------------------------
Eval num_timesteps=257000, episode_reward=-0.01 +/- 0.23
Episode length: 16.82 +/- 4.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.8     |
|    mean_reward      | -0.0062  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 257000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.36e-05 |
|    n_updates        | 54249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.00911 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12272    |
|    fps              | 37       |
|    time_elapsed     | 6846     |
|    total_timesteps  | 257056   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 54263    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00091  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12276    |
|    fps              | 37       |
|    time_elapsed     | 6847     |
|    total_timesteps  | 257121   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.52e-05 |
|    n_updates        | 54280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00956 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12280    |
|    fps              | 37       |
|    time_elapsed     | 6847     |
|    total_timesteps  | 257194   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.34e-05 |
|    n_updates        | 54298    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.00956 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12284    |
|    fps              | 37       |
|    time_elapsed     | 6848     |
|    total_timesteps  | 257261   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.52e-05 |
|    n_updates        | 54315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | 0.00055  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12288    |
|    fps              | 37       |
|    time_elapsed     | 6848     |
|    total_timesteps  | 257322   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00724  |
|    n_updates        | 54330    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00252  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12292    |
|    fps              | 37       |
|    time_elapsed     | 6849     |
|    total_timesteps  | 257396   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00686  |
|    n_updates        | 54348    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0127   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12296    |
|    fps              | 37       |
|    time_elapsed     | 6849     |
|    total_timesteps  | 257456   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.07e-05 |
|    n_updates        | 54363    |
----------------------------------
Eval num_timesteps=257500, episode_reward=-0.00 +/- 0.24
Episode length: 15.96 +/- 1.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.00282 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 257500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.95e-05 |
|    n_updates        | 54374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0228   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12300    |
|    fps              | 37       |
|    time_elapsed     | 6853     |
|    total_timesteps  | 257516   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.33e-05 |
|    n_updates        | 54378    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.023    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12304    |
|    fps              | 37       |
|    time_elapsed     | 6854     |
|    total_timesteps  | 257580   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.75e-05 |
|    n_updates        | 54394    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.023    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12308    |
|    fps              | 37       |
|    time_elapsed     | 6854     |
|    total_timesteps  | 257645   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.75e-05 |
|    n_updates        | 54411    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.023    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12312    |
|    fps              | 37       |
|    time_elapsed     | 6855     |
|    total_timesteps  | 257709   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.38e-05 |
|    n_updates        | 54427    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0333   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12316    |
|    fps              | 37       |
|    time_elapsed     | 6855     |
|    total_timesteps  | 257765   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.52e-05 |
|    n_updates        | 54441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0334   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12320    |
|    fps              | 37       |
|    time_elapsed     | 6856     |
|    total_timesteps  | 257829   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.97e-05 |
|    n_updates        | 54457    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0341   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12324    |
|    fps              | 37       |
|    time_elapsed     | 6856     |
|    total_timesteps  | 257905   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.23e-05 |
|    n_updates        | 54476    |
----------------------------------
Eval num_timesteps=258000, episode_reward=0.04 +/- 0.30
Episode length: 15.72 +/- 1.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.7     |
|    mean_reward      | 0.0382   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 258000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00691  |
|    n_updates        | 54499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0198   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12328    |
|    fps              | 37       |
|    time_elapsed     | 6861     |
|    total_timesteps  | 258075   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.27e-05 |
|    n_updates        | 54518    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0301   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12332    |
|    fps              | 37       |
|    time_elapsed     | 6861     |
|    total_timesteps  | 258135   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00718  |
|    n_updates        | 54533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0299   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12336    |
|    fps              | 37       |
|    time_elapsed     | 6862     |
|    total_timesteps  | 258203   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.02e-05 |
|    n_updates        | 54550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12340    |
|    fps              | 37       |
|    time_elapsed     | 6863     |
|    total_timesteps  | 258326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00673  |
|    n_updates        | 54581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | 0.0274   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12344    |
|    fps              | 37       |
|    time_elapsed     | 6863     |
|    total_timesteps  | 258395   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.9e-05  |
|    n_updates        | 54598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0477   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12348    |
|    fps              | 37       |
|    time_elapsed     | 6864     |
|    total_timesteps  | 258452   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.93e-05 |
|    n_updates        | 54612    |
----------------------------------
Eval num_timesteps=258500, episode_reward=0.06 +/- 0.33
Episode length: 15.68 +/- 1.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.7     |
|    mean_reward      | 0.0583   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 258500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00721  |
|    n_updates        | 54624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.3     |
|    ep_rew_mean      | 0.0477   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12352    |
|    fps              | 37       |
|    time_elapsed     | 6868     |
|    total_timesteps  | 258512   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.97e-05 |
|    n_updates        | 54627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.7     |
|    ep_rew_mean      | 0.0501   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12356    |
|    fps              | 37       |
|    time_elapsed     | 6868     |
|    total_timesteps  | 258576   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.88e-05 |
|    n_updates        | 54643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12360    |
|    fps              | 37       |
|    time_elapsed     | 6869     |
|    total_timesteps  | 258644   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.51e-05 |
|    n_updates        | 54660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12364    |
|    fps              | 37       |
|    time_elapsed     | 6869     |
|    total_timesteps  | 258710   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.83e-05 |
|    n_updates        | 54677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0397   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12368    |
|    fps              | 37       |
|    time_elapsed     | 6870     |
|    total_timesteps  | 258776   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0119   |
|    n_updates        | 54693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12372    |
|    fps              | 37       |
|    time_elapsed     | 6870     |
|    total_timesteps  | 258842   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.15e-05 |
|    n_updates        | 54710    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0396   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12376    |
|    fps              | 37       |
|    time_elapsed     | 6871     |
|    total_timesteps  | 258906   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.61e-05 |
|    n_updates        | 54726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12380    |
|    fps              | 37       |
|    time_elapsed     | 6871     |
|    total_timesteps  | 258974   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.53e-05 |
|    n_updates        | 54743    |
----------------------------------
Eval num_timesteps=259000, episode_reward=-0.04 +/- 0.14
Episode length: 16.12 +/- 0.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0435  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 259000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.71e-05 |
|    n_updates        | 54749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0499   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12384    |
|    fps              | 37       |
|    time_elapsed     | 6875     |
|    total_timesteps  | 259038   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.69e-05 |
|    n_updates        | 54759    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 0.0398   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12388    |
|    fps              | 37       |
|    time_elapsed     | 6876     |
|    total_timesteps  | 259102   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.58e-05 |
|    n_updates        | 54775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0395   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12392    |
|    fps              | 37       |
|    time_elapsed     | 6877     |
|    total_timesteps  | 259184   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.76e-05 |
|    n_updates        | 54795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12396    |
|    fps              | 37       |
|    time_elapsed     | 6877     |
|    total_timesteps  | 259248   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.45e-05 |
|    n_updates        | 54811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.0192   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12400    |
|    fps              | 37       |
|    time_elapsed     | 6877     |
|    total_timesteps  | 259312   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0142   |
|    n_updates        | 54827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0293   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12404    |
|    fps              | 37       |
|    time_elapsed     | 6878     |
|    total_timesteps  | 259372   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.94e-05 |
|    n_updates        | 54842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12408    |
|    fps              | 37       |
|    time_elapsed     | 6878     |
|    total_timesteps  | 259436   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.55e-05 |
|    n_updates        | 54858    |
----------------------------------
Eval num_timesteps=259500, episode_reward=-0.02 +/- 0.20
Episode length: 16.08 +/- 0.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0233  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 259500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3e-05    |
|    n_updates        | 54874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | 0.0294   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12412    |
|    fps              | 37       |
|    time_elapsed     | 6883     |
|    total_timesteps  | 259500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00891  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12416    |
|    fps              | 37       |
|    time_elapsed     | 6883     |
|    total_timesteps  | 259568   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.41e-05 |
|    n_updates        | 54891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | 0.00887  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12420    |
|    fps              | 37       |
|    time_elapsed     | 6884     |
|    total_timesteps  | 259633   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00757  |
|    n_updates        | 54908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.9     |
|    ep_rew_mean      | -0.00067 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12424    |
|    fps              | 37       |
|    time_elapsed     | 6884     |
|    total_timesteps  | 259697   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0067   |
|    n_updates        | 54924    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00358  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12428    |
|    fps              | 37       |
|    time_elapsed     | 6885     |
|    total_timesteps  | 259761   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.47e-05 |
|    n_updates        | 54940    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00659 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12432    |
|    fps              | 37       |
|    time_elapsed     | 6885     |
|    total_timesteps  | 259825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.8e-05  |
|    n_updates        | 54956    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00683 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12436    |
|    fps              | 37       |
|    time_elapsed     | 6886     |
|    total_timesteps  | 259899   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00728  |
|    n_updates        | 54974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0045  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12440    |
|    fps              | 37       |
|    time_elapsed     | 6886     |
|    total_timesteps  | 259964   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.91e-05 |
|    n_updates        | 54990    |
----------------------------------
Eval num_timesteps=260000, episode_reward=-0.04 +/- 0.14
Episode length: 16.48 +/- 1.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.5     |
|    mean_reward      | -0.0449  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 260000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.81e-05 |
|    n_updates        | 54999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0043  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12444    |
|    fps              | 37       |
|    time_elapsed     | 6890     |
|    total_timesteps  | 260028   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000135 |
|    n_updates        | 55006    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0247  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12448    |
|    fps              | 37       |
|    time_elapsed     | 6891     |
|    total_timesteps  | 260095   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.81e-05 |
|    n_updates        | 55023    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.035   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12452    |
|    fps              | 37       |
|    time_elapsed     | 6891     |
|    total_timesteps  | 260161   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.93e-05 |
|    n_updates        | 55040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.035   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12456    |
|    fps              | 37       |
|    time_elapsed     | 6892     |
|    total_timesteps  | 260225   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00012  |
|    n_updates        | 55056    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0349  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12460    |
|    fps              | 37       |
|    time_elapsed     | 6892     |
|    total_timesteps  | 260292   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.72e-05 |
|    n_updates        | 55072    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0348  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12464    |
|    fps              | 37       |
|    time_elapsed     | 6893     |
|    total_timesteps  | 260356   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.49e-05 |
|    n_updates        | 55088    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0348  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12468    |
|    fps              | 37       |
|    time_elapsed     | 6893     |
|    total_timesteps  | 260420   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.64e-05 |
|    n_updates        | 55104    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12472    |
|    fps              | 37       |
|    time_elapsed     | 6894     |
|    total_timesteps  | 260484   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.93e-05 |
|    n_updates        | 55120    |
----------------------------------
Eval num_timesteps=260500, episode_reward=-0.01 +/- 0.24
Episode length: 16.72 +/- 5.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.7     |
|    mean_reward      | -0.00586 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 260500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000114 |
|    n_updates        | 55124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0347  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12476    |
|    fps              | 37       |
|    time_elapsed     | 6898     |
|    total_timesteps  | 260548   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.33e-05 |
|    n_updates        | 55136    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12480    |
|    fps              | 37       |
|    time_elapsed     | 6899     |
|    total_timesteps  | 260609   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.51e-05 |
|    n_updates        | 55152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0244  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12484    |
|    fps              | 37       |
|    time_elapsed     | 6899     |
|    total_timesteps  | 260674   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00659  |
|    n_updates        | 55168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12488    |
|    fps              | 37       |
|    time_elapsed     | 6900     |
|    total_timesteps  | 260760   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.68e-05 |
|    n_updates        | 55189    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0246  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12492    |
|    fps              | 37       |
|    time_elapsed     | 6900     |
|    total_timesteps  | 260824   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.53e-05 |
|    n_updates        | 55205    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0144  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12496    |
|    fps              | 37       |
|    time_elapsed     | 6901     |
|    total_timesteps  | 260884   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.15e-05 |
|    n_updates        | 55220    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0059   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12500    |
|    fps              | 37       |
|    time_elapsed     | 6901     |
|    total_timesteps  | 260941   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.63e-05 |
|    n_updates        | 55235    |
----------------------------------
Eval num_timesteps=261000, episode_reward=0.01 +/- 0.28
Episode length: 17.40 +/- 8.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.4     |
|    mean_reward      | 0.0115   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 261000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.68e-05 |
|    n_updates        | 55249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00427 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12504    |
|    fps              | 37       |
|    time_elapsed     | 6905     |
|    total_timesteps  | 261005   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.64e-05 |
|    n_updates        | 55251    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00443 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12508    |
|    fps              | 37       |
|    time_elapsed     | 6906     |
|    total_timesteps  | 261073   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00544  |
|    n_updates        | 55268    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00451 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12512    |
|    fps              | 37       |
|    time_elapsed     | 6907     |
|    total_timesteps  | 261139   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00624  |
|    n_updates        | 55284    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00411  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12516    |
|    fps              | 37       |
|    time_elapsed     | 6907     |
|    total_timesteps  | 261242   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.34e-05 |
|    n_updates        | 55310    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00411  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12520    |
|    fps              | 37       |
|    time_elapsed     | 6908     |
|    total_timesteps  | 261307   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.6e-05  |
|    n_updates        | 55326    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00411  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12524    |
|    fps              | 37       |
|    time_elapsed     | 6908     |
|    total_timesteps  | 261371   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0141   |
|    n_updates        | 55342    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00407  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12528    |
|    fps              | 37       |
|    time_elapsed     | 6909     |
|    total_timesteps  | 261436   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00691  |
|    n_updates        | 55358    |
----------------------------------
Eval num_timesteps=261500, episode_reward=0.07 +/- 0.36
Episode length: 18.22 +/- 11.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.2     |
|    mean_reward      | 0.0682   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 261500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.51e-05 |
|    n_updates        | 55374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00391  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12532    |
|    fps              | 37       |
|    time_elapsed     | 6913     |
|    total_timesteps  | 261504   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.34e-05 |
|    n_updates        | 55375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00194  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12536    |
|    fps              | 37       |
|    time_elapsed     | 6914     |
|    total_timesteps  | 261627   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.8e-05  |
|    n_updates        | 55406    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00146  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12540    |
|    fps              | 37       |
|    time_elapsed     | 6915     |
|    total_timesteps  | 261704   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00656  |
|    n_updates        | 55425    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00126  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12544    |
|    fps              | 37       |
|    time_elapsed     | 6915     |
|    total_timesteps  | 261773   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000127 |
|    n_updates        | 55443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00138  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12548    |
|    fps              | 37       |
|    time_elapsed     | 6916     |
|    total_timesteps  | 261837   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00665  |
|    n_updates        | 55459    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12552    |
|    fps              | 37       |
|    time_elapsed     | 6916     |
|    total_timesteps  | 261899   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.31e-05 |
|    n_updates        | 55474    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12556    |
|    fps              | 37       |
|    time_elapsed     | 6917     |
|    total_timesteps  | 261964   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 55490    |
----------------------------------
Eval num_timesteps=262000, episode_reward=-0.03 +/- 0.20
Episode length: 17.18 +/- 8.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.2     |
|    mean_reward      | -0.0278  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 262000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.97e-05 |
|    n_updates        | 55499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12560    |
|    fps              | 37       |
|    time_elapsed     | 6922     |
|    total_timesteps  | 262032   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.38e-05 |
|    n_updates        | 55507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0215   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12564    |
|    fps              | 37       |
|    time_elapsed     | 6922     |
|    total_timesteps  | 262095   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00645  |
|    n_updates        | 55523    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0317   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12568    |
|    fps              | 37       |
|    time_elapsed     | 6923     |
|    total_timesteps  | 262155   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 55538    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0317   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12572    |
|    fps              | 37       |
|    time_elapsed     | 6924     |
|    total_timesteps  | 262219   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.04e-05 |
|    n_updates        | 55554    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0317   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12576    |
|    fps              | 37       |
|    time_elapsed     | 6924     |
|    total_timesteps  | 262282   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000123 |
|    n_updates        | 55570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.021    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12580    |
|    fps              | 37       |
|    time_elapsed     | 6925     |
|    total_timesteps  | 262361   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.77e-05 |
|    n_updates        | 55590    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.011    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12584    |
|    fps              | 37       |
|    time_elapsed     | 6925     |
|    total_timesteps  | 262425   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.79e-05 |
|    n_updates        | 55606    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0119   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12588    |
|    fps              | 37       |
|    time_elapsed     | 6926     |
|    total_timesteps  | 262489   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.95e-05 |
|    n_updates        | 55622    |
----------------------------------
Eval num_timesteps=262500, episode_reward=-0.01 +/- 0.24
Episode length: 16.68 +/- 2.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.7     |
|    mean_reward      | -0.00564 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 262500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.23e-05 |
|    n_updates        | 55624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0118   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12592    |
|    fps              | 37       |
|    time_elapsed     | 6930     |
|    total_timesteps  | 262555   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00637  |
|    n_updates        | 55638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.00162  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12596    |
|    fps              | 37       |
|    time_elapsed     | 6931     |
|    total_timesteps  | 262620   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00654  |
|    n_updates        | 55654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00856 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12600    |
|    fps              | 37       |
|    time_elapsed     | 6931     |
|    total_timesteps  | 262681   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00681  |
|    n_updates        | 55670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00856 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12604    |
|    fps              | 37       |
|    time_elapsed     | 6932     |
|    total_timesteps  | 262745   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.1e-05  |
|    n_updates        | 55686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0084  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12608    |
|    fps              | 37       |
|    time_elapsed     | 6932     |
|    total_timesteps  | 262809   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00024  |
|    n_updates        | 55702    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.00186  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12612    |
|    fps              | 37       |
|    time_elapsed     | 6933     |
|    total_timesteps  | 262869   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00644  |
|    n_updates        | 55717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0066  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12616    |
|    fps              | 37       |
|    time_elapsed     | 6934     |
|    total_timesteps  | 262933   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.44e-05 |
|    n_updates        | 55733    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00354  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12620    |
|    fps              | 37       |
|    time_elapsed     | 6934     |
|    total_timesteps  | 262995   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.21e-05 |
|    n_updates        | 55748    |
----------------------------------
Eval num_timesteps=263000, episode_reward=0.03 +/- 0.31
Episode length: 16.98 +/- 8.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17       |
|    mean_reward      | 0.0331   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 263000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.43e-05 |
|    n_updates        | 55749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.00338  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12624    |
|    fps              | 37       |
|    time_elapsed     | 6939     |
|    total_timesteps  | 263063   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.05e-05 |
|    n_updates        | 55765    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00298  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12628    |
|    fps              | 37       |
|    time_elapsed     | 6940     |
|    total_timesteps  | 263138   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00631  |
|    n_updates        | 55784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00314  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12632    |
|    fps              | 37       |
|    time_elapsed     | 6940     |
|    total_timesteps  | 263202   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.01e-05 |
|    n_updates        | 55800    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0157   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12636    |
|    fps              | 37       |
|    time_elapsed     | 6940     |
|    total_timesteps  | 263262   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.13e-05 |
|    n_updates        | 55815    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0162   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12640    |
|    fps              | 37       |
|    time_elapsed     | 6941     |
|    total_timesteps  | 263326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000206 |
|    n_updates        | 55831    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0164   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12644    |
|    fps              | 37       |
|    time_elapsed     | 6942     |
|    total_timesteps  | 263390   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000119 |
|    n_updates        | 55847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12648    |
|    fps              | 37       |
|    time_elapsed     | 6942     |
|    total_timesteps  | 263458   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.67e-05 |
|    n_updates        | 55864    |
----------------------------------
Eval num_timesteps=263500, episode_reward=-0.00 +/- 0.24
Episode length: 16.32 +/- 1.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.3     |
|    mean_reward      | -0.00424 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 263500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000167 |
|    n_updates        | 55874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0159   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12652    |
|    fps              | 37       |
|    time_elapsed     | 6946     |
|    total_timesteps  | 263529   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.92e-05 |
|    n_updates        | 55882    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0159   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12656    |
|    fps              | 37       |
|    time_elapsed     | 6947     |
|    total_timesteps  | 263594   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0149   |
|    n_updates        | 55898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.026    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12660    |
|    fps              | 37       |
|    time_elapsed     | 6947     |
|    total_timesteps  | 263659   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.83e-05 |
|    n_updates        | 55914    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.016    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12664    |
|    fps              | 37       |
|    time_elapsed     | 6948     |
|    total_timesteps  | 263723   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 55930    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.00579  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12668    |
|    fps              | 37       |
|    time_elapsed     | 6948     |
|    total_timesteps  | 263787   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 55946    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.00579  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12672    |
|    fps              | 37       |
|    time_elapsed     | 6949     |
|    total_timesteps  | 263851   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 55962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00442 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12676    |
|    fps              | 37       |
|    time_elapsed     | 6949     |
|    total_timesteps  | 263919   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000143 |
|    n_updates        | 55979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0161   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12680    |
|    fps              | 37       |
|    time_elapsed     | 6950     |
|    total_timesteps  | 263984   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.31e-05 |
|    n_updates        | 55995    |
----------------------------------
Eval num_timesteps=264000, episode_reward=-0.04 +/- 0.14
Episode length: 16.38 +/- 1.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | -0.0445  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 264000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.04e-05 |
|    n_updates        | 55999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.016    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12684    |
|    fps              | 37       |
|    time_elapsed     | 6954     |
|    total_timesteps  | 264052   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.45e-05 |
|    n_updates        | 56012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0157   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12688    |
|    fps              | 37       |
|    time_elapsed     | 6955     |
|    total_timesteps  | 264123   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.77e-05 |
|    n_updates        | 56030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0259   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12692    |
|    fps              | 37       |
|    time_elapsed     | 6955     |
|    total_timesteps  | 264185   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.74e-05 |
|    n_updates        | 56046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0361   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12696    |
|    fps              | 37       |
|    time_elapsed     | 6956     |
|    total_timesteps  | 264245   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 56061    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12700    |
|    fps              | 37       |
|    time_elapsed     | 6956     |
|    total_timesteps  | 264315   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.66e-05 |
|    n_updates        | 56078    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12704    |
|    fps              | 38       |
|    time_elapsed     | 6956     |
|    total_timesteps  | 264379   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.93e-05 |
|    n_updates        | 56094    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12708    |
|    fps              | 38       |
|    time_elapsed     | 6957     |
|    total_timesteps  | 264443   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.46e-05 |
|    n_updates        | 56110    |
----------------------------------
Eval num_timesteps=264500, episode_reward=0.02 +/- 0.28
Episode length: 16.02 +/- 1.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.017    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 264500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000143 |
|    n_updates        | 56124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0458   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12712    |
|    fps              | 37       |
|    time_elapsed     | 6961     |
|    total_timesteps  | 264500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0458   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12716    |
|    fps              | 37       |
|    time_elapsed     | 6962     |
|    total_timesteps  | 264564   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000202 |
|    n_updates        | 56140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12720    |
|    fps              | 38       |
|    time_elapsed     | 6962     |
|    total_timesteps  | 264628   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00725  |
|    n_updates        | 56156    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0461   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12724    |
|    fps              | 38       |
|    time_elapsed     | 6963     |
|    total_timesteps  | 264688   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.57e-05 |
|    n_updates        | 56171    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0463   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12728    |
|    fps              | 38       |
|    time_elapsed     | 6963     |
|    total_timesteps  | 264757   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0067   |
|    n_updates        | 56189    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0461   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12732    |
|    fps              | 38       |
|    time_elapsed     | 6964     |
|    total_timesteps  | 264826   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.71e-05 |
|    n_updates        | 56206    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0359   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12736    |
|    fps              | 38       |
|    time_elapsed     | 6964     |
|    total_timesteps  | 264890   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.49e-05 |
|    n_updates        | 56222    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0358   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12740    |
|    fps              | 38       |
|    time_elapsed     | 6965     |
|    total_timesteps  | 264957   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.23e-05 |
|    n_updates        | 56239    |
----------------------------------
Eval num_timesteps=265000, episode_reward=-0.07 +/- 0.01
Episode length: 16.50 +/- 1.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.5     |
|    mean_reward      | -0.065   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 265000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0135   |
|    n_updates        | 56249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0357   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12744    |
|    fps              | 38       |
|    time_elapsed     | 6969     |
|    total_timesteps  | 265024   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.21e-05 |
|    n_updates        | 56255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0335   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12748    |
|    fps              | 38       |
|    time_elapsed     | 6970     |
|    total_timesteps  | 265147   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00708  |
|    n_updates        | 56286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0237   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12752    |
|    fps              | 38       |
|    time_elapsed     | 6970     |
|    total_timesteps  | 265212   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00635  |
|    n_updates        | 56302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0339   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12756    |
|    fps              | 38       |
|    time_elapsed     | 6971     |
|    total_timesteps  | 265273   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.86e-05 |
|    n_updates        | 56318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0239   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12760    |
|    fps              | 38       |
|    time_elapsed     | 6971     |
|    total_timesteps  | 265338   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.05e-05 |
|    n_updates        | 56334    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0239   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12764    |
|    fps              | 38       |
|    time_elapsed     | 6972     |
|    total_timesteps  | 265402   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.26e-05 |
|    n_updates        | 56350    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.034    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12768    |
|    fps              | 38       |
|    time_elapsed     | 6972     |
|    total_timesteps  | 265462   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.84e-05 |
|    n_updates        | 56365    |
----------------------------------
Eval num_timesteps=265500, episode_reward=0.03 +/- 0.31
Episode length: 17.40 +/- 8.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.4     |
|    mean_reward      | 0.0314   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 265500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000126 |
|    n_updates        | 56374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0441   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12772    |
|    fps              | 38       |
|    time_elapsed     | 6976     |
|    total_timesteps  | 265524   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.54e-05 |
|    n_updates        | 56380    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0543   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12776    |
|    fps              | 38       |
|    time_elapsed     | 6977     |
|    total_timesteps  | 265588   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.29e-05 |
|    n_updates        | 56396    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0343   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12780    |
|    fps              | 38       |
|    time_elapsed     | 6978     |
|    total_timesteps  | 265653   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00656  |
|    n_updates        | 56413    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0343   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12784    |
|    fps              | 38       |
|    time_elapsed     | 6978     |
|    total_timesteps  | 265719   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.15e-05 |
|    n_updates        | 56429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0345   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12788    |
|    fps              | 38       |
|    time_elapsed     | 6978     |
|    total_timesteps  | 265786   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00576  |
|    n_updates        | 56446    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0244   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12792    |
|    fps              | 38       |
|    time_elapsed     | 6979     |
|    total_timesteps  | 265850   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00015  |
|    n_updates        | 56462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0142   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12796    |
|    fps              | 38       |
|    time_elapsed     | 6979     |
|    total_timesteps  | 265914   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.64e-05 |
|    n_updates        | 56478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0146   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12800    |
|    fps              | 38       |
|    time_elapsed     | 6980     |
|    total_timesteps  | 265974   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000109 |
|    n_updates        | 56493    |
----------------------------------
Eval num_timesteps=266000, episode_reward=-0.03 +/- 0.20
Episode length: 17.24 +/- 8.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.2     |
|    mean_reward      | -0.0279  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 266000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000114 |
|    n_updates        | 56499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0248   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12804    |
|    fps              | 38       |
|    time_elapsed     | 6984     |
|    total_timesteps  | 266034   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000116 |
|    n_updates        | 56508    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0349   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12808    |
|    fps              | 38       |
|    time_elapsed     | 6985     |
|    total_timesteps  | 266095   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.6e-05  |
|    n_updates        | 56523    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0147   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12812    |
|    fps              | 38       |
|    time_elapsed     | 6985     |
|    total_timesteps  | 266159   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00019  |
|    n_updates        | 56539    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0147   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12816    |
|    fps              | 38       |
|    time_elapsed     | 6986     |
|    total_timesteps  | 266223   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.47e-05 |
|    n_updates        | 56555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0147   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12820    |
|    fps              | 38       |
|    time_elapsed     | 6986     |
|    total_timesteps  | 266287   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000147 |
|    n_updates        | 56571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00449  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12824    |
|    fps              | 38       |
|    time_elapsed     | 6987     |
|    total_timesteps  | 266351   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.61e-05 |
|    n_updates        | 56587    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.0147   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12828    |
|    fps              | 38       |
|    time_elapsed     | 6987     |
|    total_timesteps  | 266416   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000237 |
|    n_updates        | 56603    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12832    |
|    fps              | 38       |
|    time_elapsed     | 6987     |
|    total_timesteps  | 266477   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.62e-05 |
|    n_updates        | 56619    |
----------------------------------
Eval num_timesteps=266500, episode_reward=-0.00 +/- 0.24
Episode length: 16.36 +/- 1.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | -0.00444 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 266500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000186 |
|    n_updates        | 56624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.025    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12836    |
|    fps              | 38       |
|    time_elapsed     | 6992     |
|    total_timesteps  | 266541   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.28e-05 |
|    n_updates        | 56635    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0251   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12840    |
|    fps              | 38       |
|    time_elapsed     | 6992     |
|    total_timesteps  | 266605   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00653  |
|    n_updates        | 56651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0354   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12844    |
|    fps              | 38       |
|    time_elapsed     | 6993     |
|    total_timesteps  | 266665   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00653  |
|    n_updates        | 56666    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12848    |
|    fps              | 38       |
|    time_elapsed     | 6993     |
|    total_timesteps  | 266729   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000111 |
|    n_updates        | 56682    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12852    |
|    fps              | 38       |
|    time_elapsed     | 6994     |
|    total_timesteps  | 266793   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.013    |
|    n_updates        | 56698    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12856    |
|    fps              | 38       |
|    time_elapsed     | 6994     |
|    total_timesteps  | 266857   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.37e-05 |
|    n_updates        | 56714    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12860    |
|    fps              | 38       |
|    time_elapsed     | 6995     |
|    total_timesteps  | 266921   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.63e-05 |
|    n_updates        | 56730    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12864    |
|    fps              | 38       |
|    time_elapsed     | 6995     |
|    total_timesteps  | 266982   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 56745    |
----------------------------------
Eval num_timesteps=267000, episode_reward=-0.00 +/- 0.24
Episode length: 16.34 +/- 1.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.3     |
|    mean_reward      | -0.00436 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 267000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0002   |
|    n_updates        | 56749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12868    |
|    fps              | 38       |
|    time_elapsed     | 6999     |
|    total_timesteps  | 267043   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.22e-05 |
|    n_updates        | 56760    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0278   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12872    |
|    fps              | 38       |
|    time_elapsed     | 7000     |
|    total_timesteps  | 267107   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.08e-05 |
|    n_updates        | 56776    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12876    |
|    fps              | 38       |
|    time_elapsed     | 7000     |
|    total_timesteps  | 267173   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000139 |
|    n_updates        | 56793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0177   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12880    |
|    fps              | 38       |
|    time_elapsed     | 7001     |
|    total_timesteps  | 267238   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00753  |
|    n_updates        | 56809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12884    |
|    fps              | 38       |
|    time_elapsed     | 7001     |
|    total_timesteps  | 267300   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.98e-05 |
|    n_updates        | 56824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0255   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12888    |
|    fps              | 38       |
|    time_elapsed     | 7002     |
|    total_timesteps  | 267426   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.61e-05 |
|    n_updates        | 56856    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0356   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12892    |
|    fps              | 38       |
|    time_elapsed     | 7003     |
|    total_timesteps  | 267487   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.88e-05 |
|    n_updates        | 56871    |
----------------------------------
Eval num_timesteps=267500, episode_reward=0.01 +/- 0.28
Episode length: 17.24 +/- 8.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.2     |
|    mean_reward      | 0.0121   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 267500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.18e-05 |
|    n_updates        | 56874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | 0.0457   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12896    |
|    fps              | 38       |
|    time_elapsed     | 7007     |
|    total_timesteps  | 267548   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000135 |
|    n_updates        | 56886    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0355   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12900    |
|    fps              | 38       |
|    time_elapsed     | 7008     |
|    total_timesteps  | 267614   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00671  |
|    n_updates        | 56903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0354   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12904    |
|    fps              | 38       |
|    time_elapsed     | 7008     |
|    total_timesteps  | 267675   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 56918    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.023    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12908    |
|    fps              | 38       |
|    time_elapsed     | 7009     |
|    total_timesteps  | 267798   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000234 |
|    n_updates        | 56949    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0331   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12912    |
|    fps              | 38       |
|    time_elapsed     | 7009     |
|    total_timesteps  | 267858   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00657  |
|    n_updates        | 56964    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.033    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12916    |
|    fps              | 38       |
|    time_elapsed     | 7010     |
|    total_timesteps  | 267925   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.54e-05 |
|    n_updates        | 56981    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0532   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12920    |
|    fps              | 38       |
|    time_elapsed     | 7010     |
|    total_timesteps  | 267984   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.77e-05 |
|    n_updates        | 56995    |
----------------------------------
Eval num_timesteps=268000, episode_reward=0.04 +/- 0.30
Episode length: 15.78 +/- 0.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.0379   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 268000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.78e-05 |
|    n_updates        | 56999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0532   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12924    |
|    fps              | 38       |
|    time_elapsed     | 7014     |
|    total_timesteps  | 268048   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00714  |
|    n_updates        | 57011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0432   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12928    |
|    fps              | 38       |
|    time_elapsed     | 7015     |
|    total_timesteps  | 268113   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000232 |
|    n_updates        | 57028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.0329   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12932    |
|    fps              | 38       |
|    time_elapsed     | 7015     |
|    total_timesteps  | 268180   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9e-05    |
|    n_updates        | 57044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0328   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12936    |
|    fps              | 38       |
|    time_elapsed     | 7016     |
|    total_timesteps  | 268246   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.45e-05 |
|    n_updates        | 57061    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0328   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12940    |
|    fps              | 38       |
|    time_elapsed     | 7016     |
|    total_timesteps  | 268310   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000139 |
|    n_updates        | 57077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0227   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12944    |
|    fps              | 38       |
|    time_elapsed     | 7017     |
|    total_timesteps  | 268374   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.32e-05 |
|    n_updates        | 57093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0226   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12948    |
|    fps              | 38       |
|    time_elapsed     | 7017     |
|    total_timesteps  | 268439   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000152 |
|    n_updates        | 57109    |
----------------------------------
Eval num_timesteps=268500, episode_reward=-0.02 +/- 0.20
Episode length: 16.04 +/- 1.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.0232  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 268500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.86e-05 |
|    n_updates        | 57124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0226   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12952    |
|    fps              | 38       |
|    time_elapsed     | 7021     |
|    total_timesteps  | 268503   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000136 |
|    n_updates        | 57125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0226   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12956    |
|    fps              | 38       |
|    time_elapsed     | 7022     |
|    total_timesteps  | 268567   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000108 |
|    n_updates        | 57141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0227   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12960    |
|    fps              | 38       |
|    time_elapsed     | 7022     |
|    total_timesteps  | 268630   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000162 |
|    n_updates        | 57157    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.0125   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12964    |
|    fps              | 38       |
|    time_elapsed     | 7023     |
|    total_timesteps  | 268696   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.54e-05 |
|    n_updates        | 57173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00233  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12968    |
|    fps              | 38       |
|    time_elapsed     | 7023     |
|    total_timesteps  | 268760   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.51e-05 |
|    n_updates        | 57189    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | 0.00233  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12972    |
|    fps              | 38       |
|    time_elapsed     | 7024     |
|    total_timesteps  | 268824   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.57e-05 |
|    n_updates        | 57205    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00241  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12976    |
|    fps              | 38       |
|    time_elapsed     | 7024     |
|    total_timesteps  | 268888   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000206 |
|    n_updates        | 57221    |
----------------------------------
Eval num_timesteps=269000, episode_reward=-0.05 +/- 0.15
Episode length: 17.44 +/- 8.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.4     |
|    mean_reward      | -0.0488  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 269000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000152 |
|    n_updates        | 57249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | 1.44e-17 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12980    |
|    fps              | 38       |
|    time_elapsed     | 7029     |
|    total_timesteps  | 269013   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00563  |
|    n_updates        | 57253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0102  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12984    |
|    fps              | 38       |
|    time_elapsed     | 7030     |
|    total_timesteps  | 269080   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00568  |
|    n_updates        | 57269    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.00777 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12988    |
|    fps              | 38       |
|    time_elapsed     | 7030     |
|    total_timesteps  | 269145   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000141 |
|    n_updates        | 57286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0179  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12992    |
|    fps              | 38       |
|    time_elapsed     | 7030     |
|    total_timesteps  | 269209   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00729  |
|    n_updates        | 57302    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.028   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 12996    |
|    fps              | 38       |
|    time_elapsed     | 7031     |
|    total_timesteps  | 269273   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.36e-05 |
|    n_updates        | 57318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0279  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13000    |
|    fps              | 38       |
|    time_elapsed     | 7031     |
|    total_timesteps  | 269337   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00648  |
|    n_updates        | 57334    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0381  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13004    |
|    fps              | 38       |
|    time_elapsed     | 7032     |
|    total_timesteps  | 269401   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000149 |
|    n_updates        | 57350    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0357  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13008    |
|    fps              | 38       |
|    time_elapsed     | 7032     |
|    total_timesteps  | 269465   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00657  |
|    n_updates        | 57366    |
----------------------------------
Eval num_timesteps=269500, episode_reward=-0.01 +/- 0.24
Episode length: 17.50 +/- 8.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.5     |
|    mean_reward      | -0.00894 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 269500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00727  |
|    n_updates        | 57374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0459  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13012    |
|    fps              | 38       |
|    time_elapsed     | 7037     |
|    total_timesteps  | 269530   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000246 |
|    n_updates        | 57382    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0462  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13016    |
|    fps              | 38       |
|    time_elapsed     | 7037     |
|    total_timesteps  | 269604   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000184 |
|    n_updates        | 57400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0665  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13020    |
|    fps              | 38       |
|    time_elapsed     | 7038     |
|    total_timesteps  | 269671   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00546  |
|    n_updates        | 57417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0564  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13024    |
|    fps              | 38       |
|    time_elapsed     | 7038     |
|    total_timesteps  | 269732   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000268 |
|    n_updates        | 57432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0564  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13028    |
|    fps              | 38       |
|    time_elapsed     | 7039     |
|    total_timesteps  | 269797   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00506  |
|    n_updates        | 57449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0564  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13032    |
|    fps              | 38       |
|    time_elapsed     | 7039     |
|    total_timesteps  | 269865   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.23e-05 |
|    n_updates        | 57466    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0563  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13036    |
|    fps              | 38       |
|    time_elapsed     | 7040     |
|    total_timesteps  | 269929   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.84e-05 |
|    n_updates        | 57482    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0563  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13040    |
|    fps              | 38       |
|    time_elapsed     | 7040     |
|    total_timesteps  | 269993   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000156 |
|    n_updates        | 57498    |
----------------------------------
Eval num_timesteps=270000, episode_reward=-0.05 +/- 0.15
Episode length: 17.42 +/- 8.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.4     |
|    mean_reward      | -0.0487  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 270000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000156 |
|    n_updates        | 57499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0565  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13044    |
|    fps              | 38       |
|    time_elapsed     | 7045     |
|    total_timesteps  | 270062   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000109 |
|    n_updates        | 57515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0567  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13048    |
|    fps              | 38       |
|    time_elapsed     | 7045     |
|    total_timesteps  | 270130   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0062   |
|    n_updates        | 57532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0568  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13052    |
|    fps              | 38       |
|    time_elapsed     | 7046     |
|    total_timesteps  | 270198   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000158 |
|    n_updates        | 57549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0571  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13056    |
|    fps              | 38       |
|    time_elapsed     | 7046     |
|    total_timesteps  | 270269   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0002   |
|    n_updates        | 57567    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0572  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13060    |
|    fps              | 38       |
|    time_elapsed     | 7047     |
|    total_timesteps  | 270334   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000143 |
|    n_updates        | 57583    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0571  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13064    |
|    fps              | 38       |
|    time_elapsed     | 7047     |
|    total_timesteps  | 270398   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.72e-05 |
|    n_updates        | 57599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0572  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13068    |
|    fps              | 38       |
|    time_elapsed     | 7048     |
|    total_timesteps  | 270464   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000151 |
|    n_updates        | 57615    |
----------------------------------
Eval num_timesteps=270500, episode_reward=0.12 +/- 0.39
Episode length: 15.88 +/- 2.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | 0.118    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 270500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00639  |
|    n_updates        | 57624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0573  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13072    |
|    fps              | 38       |
|    time_elapsed     | 7052     |
|    total_timesteps  | 270532   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000236 |
|    n_updates        | 57632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0573  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13076    |
|    fps              | 38       |
|    time_elapsed     | 7053     |
|    total_timesteps  | 270596   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.45e-05 |
|    n_updates        | 57648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0549  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13080    |
|    fps              | 38       |
|    time_elapsed     | 7053     |
|    total_timesteps  | 270660   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000107 |
|    n_updates        | 57664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0548  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13084    |
|    fps              | 38       |
|    time_elapsed     | 7054     |
|    total_timesteps  | 270726   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000147 |
|    n_updates        | 57681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0548  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13088    |
|    fps              | 38       |
|    time_elapsed     | 7054     |
|    total_timesteps  | 270790   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0077   |
|    n_updates        | 57697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0548  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13092    |
|    fps              | 38       |
|    time_elapsed     | 7055     |
|    total_timesteps  | 270854   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00632  |
|    n_updates        | 57713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0548  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13096    |
|    fps              | 38       |
|    time_elapsed     | 7055     |
|    total_timesteps  | 270918   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000442 |
|    n_updates        | 57729    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0548  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13100    |
|    fps              | 38       |
|    time_elapsed     | 7055     |
|    total_timesteps  | 270982   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000116 |
|    n_updates        | 57745    |
----------------------------------
Eval num_timesteps=271000, episode_reward=0.06 +/- 0.33
Episode length: 15.82 +/- 1.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.0578   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 271000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.61e-05 |
|    n_updates        | 57749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0548  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13104    |
|    fps              | 38       |
|    time_elapsed     | 7060     |
|    total_timesteps  | 271046   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000384 |
|    n_updates        | 57761    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0548  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13108    |
|    fps              | 38       |
|    time_elapsed     | 7060     |
|    total_timesteps  | 271110   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000146 |
|    n_updates        | 57777    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0548  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13112    |
|    fps              | 38       |
|    time_elapsed     | 7061     |
|    total_timesteps  | 271174   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0132   |
|    n_updates        | 57793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0544  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13116    |
|    fps              | 38       |
|    time_elapsed     | 7061     |
|    total_timesteps  | 271240   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000111 |
|    n_updates        | 57809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0543  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13120    |
|    fps              | 38       |
|    time_elapsed     | 7062     |
|    total_timesteps  | 271304   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0057   |
|    n_updates        | 57825    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0644  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13124    |
|    fps              | 38       |
|    time_elapsed     | 7062     |
|    total_timesteps  | 271368   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000214 |
|    n_updates        | 57841    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.0644  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13128    |
|    fps              | 38       |
|    time_elapsed     | 7063     |
|    total_timesteps  | 271432   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00725  |
|    n_updates        | 57857    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0642  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13132    |
|    fps              | 38       |
|    time_elapsed     | 7063     |
|    total_timesteps  | 271496   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000142 |
|    n_updates        | 57873    |
----------------------------------
Eval num_timesteps=271500, episode_reward=-0.00 +/- 0.24
Episode length: 16.04 +/- 1.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.00312 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 271500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00658  |
|    n_updates        | 57874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0642  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13136    |
|    fps              | 38       |
|    time_elapsed     | 7068     |
|    total_timesteps  | 271560   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000181 |
|    n_updates        | 57889    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.0541  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13140    |
|    fps              | 38       |
|    time_elapsed     | 7068     |
|    total_timesteps  | 271621   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000251 |
|    n_updates        | 57905    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0539  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13144    |
|    fps              | 38       |
|    time_elapsed     | 7069     |
|    total_timesteps  | 271685   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.55e-05 |
|    n_updates        | 57921    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0538  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13148    |
|    fps              | 38       |
|    time_elapsed     | 7069     |
|    total_timesteps  | 271749   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000204 |
|    n_updates        | 57937    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0537  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13152    |
|    fps              | 38       |
|    time_elapsed     | 7070     |
|    total_timesteps  | 271816   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000153 |
|    n_updates        | 57953    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0534  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13156    |
|    fps              | 38       |
|    time_elapsed     | 7070     |
|    total_timesteps  | 271880   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000156 |
|    n_updates        | 57969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0534  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13160    |
|    fps              | 38       |
|    time_elapsed     | 7071     |
|    total_timesteps  | 271945   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000102 |
|    n_updates        | 57986    |
----------------------------------
Eval num_timesteps=272000, episode_reward=0.02 +/- 0.28
Episode length: 15.90 +/- 1.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | 0.0174   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 272000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000355 |
|    n_updates        | 57999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0433  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13164    |
|    fps              | 38       |
|    time_elapsed     | 7075     |
|    total_timesteps  | 272006   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00661  |
|    n_updates        | 58001    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0332  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13168    |
|    fps              | 38       |
|    time_elapsed     | 7075     |
|    total_timesteps  | 272068   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000126 |
|    n_updates        | 58016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13172    |
|    fps              | 38       |
|    time_elapsed     | 7076     |
|    total_timesteps  | 272133   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 58033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13176    |
|    fps              | 38       |
|    time_elapsed     | 7076     |
|    total_timesteps  | 272194   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000193 |
|    n_updates        | 58048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0229  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13180    |
|    fps              | 38       |
|    time_elapsed     | 7077     |
|    total_timesteps  | 272258   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.19e-05 |
|    n_updates        | 58064    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13184    |
|    fps              | 38       |
|    time_elapsed     | 7077     |
|    total_timesteps  | 272327   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 58081    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13188    |
|    fps              | 38       |
|    time_elapsed     | 7077     |
|    total_timesteps  | 272392   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000182 |
|    n_updates        | 58097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13192    |
|    fps              | 38       |
|    time_elapsed     | 7078     |
|    total_timesteps  | 272456   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 58113    |
----------------------------------
Eval num_timesteps=272500, episode_reward=-0.00 +/- 0.24
Episode length: 16.36 +/- 2.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | -0.0044  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 272500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00573  |
|    n_updates        | 58124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13196    |
|    fps              | 38       |
|    time_elapsed     | 7082     |
|    total_timesteps  | 272520   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 58129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13200    |
|    fps              | 38       |
|    time_elapsed     | 7083     |
|    total_timesteps  | 272584   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000175 |
|    n_updates        | 58145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13204    |
|    fps              | 38       |
|    time_elapsed     | 7083     |
|    total_timesteps  | 272652   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00604  |
|    n_updates        | 58162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13208    |
|    fps              | 38       |
|    time_elapsed     | 7084     |
|    total_timesteps  | 272721   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000119 |
|    n_updates        | 58180    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00689  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13212    |
|    fps              | 38       |
|    time_elapsed     | 7084     |
|    total_timesteps  | 272777   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000327 |
|    n_updates        | 58194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00697  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13216    |
|    fps              | 38       |
|    time_elapsed     | 7085     |
|    total_timesteps  | 272841   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00606  |
|    n_updates        | 58210    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00693  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13220    |
|    fps              | 38       |
|    time_elapsed     | 7085     |
|    total_timesteps  | 272906   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000297 |
|    n_updates        | 58226    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00693  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13224    |
|    fps              | 38       |
|    time_elapsed     | 7085     |
|    total_timesteps  | 272970   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000158 |
|    n_updates        | 58242    |
----------------------------------
Eval num_timesteps=273000, episode_reward=-0.00 +/- 0.24
Episode length: 16.18 +/- 1.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.2     |
|    mean_reward      | -0.00374 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 273000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00626  |
|    n_updates        | 58249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00685  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13228    |
|    fps              | 38       |
|    time_elapsed     | 7090     |
|    total_timesteps  | 273036   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000225 |
|    n_updates        | 58258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00665  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13232    |
|    fps              | 38       |
|    time_elapsed     | 7090     |
|    total_timesteps  | 273105   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000283 |
|    n_updates        | 58276    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00653  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13236    |
|    fps              | 38       |
|    time_elapsed     | 7091     |
|    total_timesteps  | 273172   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00515  |
|    n_updates        | 58292    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00395 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13240    |
|    fps              | 38       |
|    time_elapsed     | 7091     |
|    total_timesteps  | 273245   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000143 |
|    n_updates        | 58311    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00399 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13244    |
|    fps              | 38       |
|    time_elapsed     | 7092     |
|    total_timesteps  | 273310   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000133 |
|    n_updates        | 58327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.00399 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13248    |
|    fps              | 38       |
|    time_elapsed     | 7092     |
|    total_timesteps  | 273374   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000242 |
|    n_updates        | 58343    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00624  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13252    |
|    fps              | 38       |
|    time_elapsed     | 7093     |
|    total_timesteps  | 273435   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000247 |
|    n_updates        | 58358    |
----------------------------------
Eval num_timesteps=273500, episode_reward=-0.03 +/- 0.20
Episode length: 17.58 +/- 8.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.6     |
|    mean_reward      | -0.0293  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 273500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000174 |
|    n_updates        | 58374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0062   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13256    |
|    fps              | 38       |
|    time_elapsed     | 7097     |
|    total_timesteps  | 273500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13260    |
|    fps              | 38       |
|    time_elapsed     | 7098     |
|    total_timesteps  | 273562   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0126   |
|    n_updates        | 58390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.0163   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13264    |
|    fps              | 38       |
|    time_elapsed     | 7098     |
|    total_timesteps  | 273624   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000345 |
|    n_updates        | 58405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00612  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13268    |
|    fps              | 38       |
|    time_elapsed     | 7099     |
|    total_timesteps  | 273691   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000133 |
|    n_updates        | 58422    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00616  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13272    |
|    fps              | 38       |
|    time_elapsed     | 7099     |
|    total_timesteps  | 273755   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0151   |
|    n_updates        | 58438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00399 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13276    |
|    fps              | 38       |
|    time_elapsed     | 7100     |
|    total_timesteps  | 273820   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000171 |
|    n_updates        | 58454    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.3     |
|    ep_rew_mean      | -0.00399 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13280    |
|    fps              | 38       |
|    time_elapsed     | 7100     |
|    total_timesteps  | 273884   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00601  |
|    n_updates        | 58470    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13284    |
|    fps              | 38       |
|    time_elapsed     | 7101     |
|    total_timesteps  | 273948   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000211 |
|    n_updates        | 58486    |
----------------------------------
Eval num_timesteps=274000, episode_reward=-0.02 +/- 0.20
Episode length: 16.08 +/- 1.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0233  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 274000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000287 |
|    n_updates        | 58499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0036  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13288    |
|    fps              | 38       |
|    time_elapsed     | 7105     |
|    total_timesteps  | 274008   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00595  |
|    n_updates        | 58501    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00649  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13292    |
|    fps              | 38       |
|    time_elapsed     | 7105     |
|    total_timesteps  | 274070   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000155 |
|    n_updates        | 58517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00649  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13296    |
|    fps              | 38       |
|    time_elapsed     | 7106     |
|    total_timesteps  | 274134   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000165 |
|    n_updates        | 58533    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00621  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13300    |
|    fps              | 38       |
|    time_elapsed     | 7106     |
|    total_timesteps  | 274205   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00553  |
|    n_updates        | 58551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | 0.00637  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13304    |
|    fps              | 38       |
|    time_elapsed     | 7107     |
|    total_timesteps  | 274269   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00443  |
|    n_updates        | 58567    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00657  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13308    |
|    fps              | 38       |
|    time_elapsed     | 7107     |
|    total_timesteps  | 274333   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.25e-05 |
|    n_updates        | 58583    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13312    |
|    fps              | 38       |
|    time_elapsed     | 7108     |
|    total_timesteps  | 274397   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000252 |
|    n_updates        | 58599    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0138  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13316    |
|    fps              | 38       |
|    time_elapsed     | 7108     |
|    total_timesteps  | 274461   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.39e-05 |
|    n_updates        | 58615    |
----------------------------------
Eval num_timesteps=274500, episode_reward=-0.00 +/- 0.24
Episode length: 16.34 +/- 1.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.3     |
|    mean_reward      | -0.00432 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 274500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000134 |
|    n_updates        | 58624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13320    |
|    fps              | 38       |
|    time_elapsed     | 7113     |
|    total_timesteps  | 274525   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00027  |
|    n_updates        | 58631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0137  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13324    |
|    fps              | 38       |
|    time_elapsed     | 7113     |
|    total_timesteps  | 274589   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.55e-05 |
|    n_updates        | 58647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0136  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13328    |
|    fps              | 38       |
|    time_elapsed     | 7114     |
|    total_timesteps  | 274653   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000164 |
|    n_updates        | 58663    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0134  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13332    |
|    fps              | 38       |
|    time_elapsed     | 7114     |
|    total_timesteps  | 274717   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000178 |
|    n_updates        | 58679    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13336    |
|    fps              | 38       |
|    time_elapsed     | 7114     |
|    total_timesteps  | 274781   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000303 |
|    n_updates        | 58695    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13340    |
|    fps              | 38       |
|    time_elapsed     | 7115     |
|    total_timesteps  | 274846   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000172 |
|    n_updates        | 58711    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13344    |
|    fps              | 38       |
|    time_elapsed     | 7115     |
|    total_timesteps  | 274910   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000377 |
|    n_updates        | 58727    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00286 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13348    |
|    fps              | 38       |
|    time_elapsed     | 7116     |
|    total_timesteps  | 274972   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0124   |
|    n_updates        | 58742    |
----------------------------------
Eval num_timesteps=275000, episode_reward=0.04 +/- 0.31
Episode length: 16.02 +/- 2.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.0369   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 275000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00716  |
|    n_updates        | 58749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13352    |
|    fps              | 38       |
|    time_elapsed     | 7120     |
|    total_timesteps  | 275036   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00535  |
|    n_updates        | 58758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13356    |
|    fps              | 38       |
|    time_elapsed     | 7121     |
|    total_timesteps  | 275100   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000232 |
|    n_updates        | 58774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13360    |
|    fps              | 38       |
|    time_elapsed     | 7121     |
|    total_timesteps  | 275164   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.61e-05 |
|    n_updates        | 58790    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13364    |
|    fps              | 38       |
|    time_elapsed     | 7121     |
|    total_timesteps  | 275228   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000135 |
|    n_updates        | 58806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0331  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13368    |
|    fps              | 38       |
|    time_elapsed     | 7122     |
|    total_timesteps  | 275294   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.96e-05 |
|    n_updates        | 58823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13372    |
|    fps              | 38       |
|    time_elapsed     | 7122     |
|    total_timesteps  | 275355   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000136 |
|    n_updates        | 58838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13376    |
|    fps              | 38       |
|    time_elapsed     | 7123     |
|    total_timesteps  | 275415   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000537 |
|    n_updates        | 58853    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13380    |
|    fps              | 38       |
|    time_elapsed     | 7123     |
|    total_timesteps  | 275479   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000224 |
|    n_updates        | 58869    |
----------------------------------
Eval num_timesteps=275500, episode_reward=-0.00 +/- 0.24
Episode length: 15.94 +/- 1.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.00276 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 275500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000144 |
|    n_updates        | 58874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13384    |
|    fps              | 38       |
|    time_elapsed     | 7127     |
|    total_timesteps  | 275545   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000148 |
|    n_updates        | 58886    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13388    |
|    fps              | 38       |
|    time_elapsed     | 7128     |
|    total_timesteps  | 275606   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000128 |
|    n_updates        | 58901    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13392    |
|    fps              | 38       |
|    time_elapsed     | 7128     |
|    total_timesteps  | 275670   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000262 |
|    n_updates        | 58917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.023   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13396    |
|    fps              | 38       |
|    time_elapsed     | 7129     |
|    total_timesteps  | 275734   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.94e-05 |
|    n_updates        | 58933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0227  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13400    |
|    fps              | 38       |
|    time_elapsed     | 7129     |
|    total_timesteps  | 275799   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000442 |
|    n_updates        | 58949    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13404    |
|    fps              | 38       |
|    time_elapsed     | 7130     |
|    total_timesteps  | 275860   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00647  |
|    n_updates        | 58964    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13408    |
|    fps              | 38       |
|    time_elapsed     | 7130     |
|    total_timesteps  | 275925   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.91e-05 |
|    n_updates        | 58981    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13412    |
|    fps              | 38       |
|    time_elapsed     | 7131     |
|    total_timesteps  | 275989   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000156 |
|    n_updates        | 58997    |
----------------------------------
Eval num_timesteps=276000, episode_reward=0.01 +/- 0.28
Episode length: 17.02 +/- 8.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17       |
|    mean_reward      | 0.013    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 276000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000216 |
|    n_updates        | 58999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13416    |
|    fps              | 38       |
|    time_elapsed     | 7135     |
|    total_timesteps  | 276053   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000128 |
|    n_updates        | 59013    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13420    |
|    fps              | 38       |
|    time_elapsed     | 7136     |
|    total_timesteps  | 276117   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000333 |
|    n_updates        | 59029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0128  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13424    |
|    fps              | 38       |
|    time_elapsed     | 7136     |
|    total_timesteps  | 276185   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.37e-05 |
|    n_updates        | 59046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0129  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13428    |
|    fps              | 38       |
|    time_elapsed     | 7137     |
|    total_timesteps  | 276251   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000341 |
|    n_updates        | 59062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.013   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13432    |
|    fps              | 38       |
|    time_elapsed     | 7137     |
|    total_timesteps  | 276317   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.44e-05 |
|    n_updates        | 59079    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13436    |
|    fps              | 38       |
|    time_elapsed     | 7138     |
|    total_timesteps  | 276387   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000279 |
|    n_updates        | 59096    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00303 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13440    |
|    fps              | 38       |
|    time_elapsed     | 7138     |
|    total_timesteps  | 276448   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000207 |
|    n_updates        | 59111    |
----------------------------------
Eval num_timesteps=276500, episode_reward=0.04 +/- 0.30
Episode length: 15.70 +/- 1.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.7     |
|    mean_reward      | 0.0382   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 276500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0051   |
|    n_updates        | 59124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00303 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13444    |
|    fps              | 38       |
|    time_elapsed     | 7142     |
|    total_timesteps  | 276512   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.84e-05 |
|    n_updates        | 59127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13448    |
|    fps              | 38       |
|    time_elapsed     | 7143     |
|    total_timesteps  | 276576   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.45e-05 |
|    n_updates        | 59143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13452    |
|    fps              | 38       |
|    time_elapsed     | 7143     |
|    total_timesteps  | 276640   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000275 |
|    n_updates        | 59159    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13456    |
|    fps              | 38       |
|    time_elapsed     | 7144     |
|    total_timesteps  | 276705   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00011  |
|    n_updates        | 59176    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0071   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13460    |
|    fps              | 38       |
|    time_elapsed     | 7144     |
|    total_timesteps  | 276763   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.22e-05 |
|    n_updates        | 59190    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0071   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13464    |
|    fps              | 38       |
|    time_elapsed     | 7144     |
|    total_timesteps  | 276827   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.013    |
|    n_updates        | 59206    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13468    |
|    fps              | 38       |
|    time_elapsed     | 7145     |
|    total_timesteps  | 276889   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000486 |
|    n_updates        | 59222    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00714  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13472    |
|    fps              | 38       |
|    time_elapsed     | 7145     |
|    total_timesteps  | 276953   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000262 |
|    n_updates        | 59238    |
----------------------------------
Eval num_timesteps=277000, episode_reward=0.05 +/- 0.33
Episode length: 17.08 +/- 8.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.1     |
|    mean_reward      | 0.0527   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 277000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000447 |
|    n_updates        | 59249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00301 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13476    |
|    fps              | 38       |
|    time_elapsed     | 7150     |
|    total_timesteps  | 277017   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.7e-05  |
|    n_updates        | 59254    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00301 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13480    |
|    fps              | 38       |
|    time_elapsed     | 7150     |
|    total_timesteps  | 277081   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000311 |
|    n_updates        | 59270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00721  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13484    |
|    fps              | 38       |
|    time_elapsed     | 7151     |
|    total_timesteps  | 277142   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0109   |
|    n_updates        | 59285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00292 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13488    |
|    fps              | 38       |
|    time_elapsed     | 7151     |
|    total_timesteps  | 277206   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000149 |
|    n_updates        | 59301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00292 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13492    |
|    fps              | 38       |
|    time_elapsed     | 7152     |
|    total_timesteps  | 277270   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000152 |
|    n_updates        | 59317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00292 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13496    |
|    fps              | 38       |
|    time_elapsed     | 7152     |
|    total_timesteps  | 277334   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00655  |
|    n_updates        | 59333    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13500    |
|    fps              | 38       |
|    time_elapsed     | 7153     |
|    total_timesteps  | 277391   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000147 |
|    n_updates        | 59347    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00728  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13504    |
|    fps              | 38       |
|    time_elapsed     | 7153     |
|    total_timesteps  | 277455   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00575  |
|    n_updates        | 59363    |
----------------------------------
Eval num_timesteps=277500, episode_reward=-0.04 +/- 0.14
Episode length: 16.12 +/- 0.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0434  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 277500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00692  |
|    n_updates        | 59374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00732  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13508    |
|    fps              | 38       |
|    time_elapsed     | 7157     |
|    total_timesteps  | 277519   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000153 |
|    n_updates        | 59379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00732  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13512    |
|    fps              | 38       |
|    time_elapsed     | 7158     |
|    total_timesteps  | 277583   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0105   |
|    n_updates        | 59395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0174   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13516    |
|    fps              | 38       |
|    time_elapsed     | 7158     |
|    total_timesteps  | 277644   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 59410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13520    |
|    fps              | 38       |
|    time_elapsed     | 7159     |
|    total_timesteps  | 277700   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000214 |
|    n_updates        | 59424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13524    |
|    fps              | 38       |
|    time_elapsed     | 7159     |
|    total_timesteps  | 277764   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000283 |
|    n_updates        | 59440    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13528    |
|    fps              | 38       |
|    time_elapsed     | 7159     |
|    total_timesteps  | 277828   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000304 |
|    n_updates        | 59456    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0381   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13532    |
|    fps              | 38       |
|    time_elapsed     | 7160     |
|    total_timesteps  | 277892   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000101 |
|    n_updates        | 59472    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13536    |
|    fps              | 38       |
|    time_elapsed     | 7160     |
|    total_timesteps  | 277958   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000378 |
|    n_updates        | 59489    |
----------------------------------
Eval num_timesteps=278000, episode_reward=0.02 +/- 0.28
Episode length: 15.84 +/- 1.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.0176   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 278000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000211 |
|    n_updates        | 59499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0382   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13540    |
|    fps              | 38       |
|    time_elapsed     | 7165     |
|    total_timesteps  | 278019   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.49e-05 |
|    n_updates        | 59504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0484   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13544    |
|    fps              | 38       |
|    time_elapsed     | 7165     |
|    total_timesteps  | 278079   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000334 |
|    n_updates        | 59519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0483   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13548    |
|    fps              | 38       |
|    time_elapsed     | 7166     |
|    total_timesteps  | 278146   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0102   |
|    n_updates        | 59536    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0686   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13552    |
|    fps              | 38       |
|    time_elapsed     | 7166     |
|    total_timesteps  | 278203   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00013  |
|    n_updates        | 59550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0788   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13556    |
|    fps              | 38       |
|    time_elapsed     | 7166     |
|    total_timesteps  | 278263   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000396 |
|    n_updates        | 59565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13560    |
|    fps              | 38       |
|    time_elapsed     | 7167     |
|    total_timesteps  | 278322   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000145 |
|    n_updates        | 59580    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13564    |
|    fps              | 38       |
|    time_elapsed     | 7167     |
|    total_timesteps  | 278386   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00553  |
|    n_updates        | 59596    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13568    |
|    fps              | 38       |
|    time_elapsed     | 7168     |
|    total_timesteps  | 278450   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000115 |
|    n_updates        | 59612    |
----------------------------------
Eval num_timesteps=278500, episode_reward=0.03 +/- 0.31
Episode length: 16.92 +/- 8.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.9     |
|    mean_reward      | 0.0334   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 278500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000261 |
|    n_updates        | 59624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0688   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13572    |
|    fps              | 38       |
|    time_elapsed     | 7172     |
|    total_timesteps  | 278511   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000103 |
|    n_updates        | 59627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0688   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13576    |
|    fps              | 38       |
|    time_elapsed     | 7173     |
|    total_timesteps  | 278575   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.62e-05 |
|    n_updates        | 59643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0789   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13580    |
|    fps              | 38       |
|    time_elapsed     | 7173     |
|    total_timesteps  | 278636   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0119   |
|    n_updates        | 59658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13584    |
|    fps              | 38       |
|    time_elapsed     | 7173     |
|    total_timesteps  | 278700   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 59674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13588    |
|    fps              | 38       |
|    time_elapsed     | 7174     |
|    total_timesteps  | 278764   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000151 |
|    n_updates        | 59690    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13592    |
|    fps              | 38       |
|    time_elapsed     | 7174     |
|    total_timesteps  | 278828   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000149 |
|    n_updates        | 59706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.5     |
|    ep_rew_mean      | 0.0789   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13596    |
|    fps              | 38       |
|    time_elapsed     | 7175     |
|    total_timesteps  | 278888   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000178 |
|    n_updates        | 59721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13600    |
|    fps              | 38       |
|    time_elapsed     | 7175     |
|    total_timesteps  | 278953   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000157 |
|    n_updates        | 59738    |
----------------------------------
Eval num_timesteps=279000, episode_reward=-0.02 +/- 0.20
Episode length: 16.02 +/- 0.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.0231  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 279000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000145 |
|    n_updates        | 59749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13604    |
|    fps              | 38       |
|    time_elapsed     | 7179     |
|    total_timesteps  | 279017   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000157 |
|    n_updates        | 59754    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13608    |
|    fps              | 38       |
|    time_elapsed     | 7180     |
|    total_timesteps  | 279079   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000285 |
|    n_updates        | 59769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13612    |
|    fps              | 38       |
|    time_elapsed     | 7181     |
|    total_timesteps  | 279143   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00786  |
|    n_updates        | 59785    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0585   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13616    |
|    fps              | 38       |
|    time_elapsed     | 7181     |
|    total_timesteps  | 279207   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00566  |
|    n_updates        | 59801    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0586   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13620    |
|    fps              | 38       |
|    time_elapsed     | 7181     |
|    total_timesteps  | 279263   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00741  |
|    n_updates        | 59815    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0585   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13624    |
|    fps              | 38       |
|    time_elapsed     | 7182     |
|    total_timesteps  | 279328   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.82e-05 |
|    n_updates        | 59831    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0686   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13628    |
|    fps              | 38       |
|    time_elapsed     | 7182     |
|    total_timesteps  | 279389   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000225 |
|    n_updates        | 59847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0686   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13632    |
|    fps              | 38       |
|    time_elapsed     | 7183     |
|    total_timesteps  | 279453   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000298 |
|    n_updates        | 59863    |
----------------------------------
Eval num_timesteps=279500, episode_reward=0.10 +/- 0.37
Episode length: 15.78 +/- 1.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.098    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 279500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00689  |
|    n_updates        | 59874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0789   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13636    |
|    fps              | 38       |
|    time_elapsed     | 7187     |
|    total_timesteps  | 279514   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00053  |
|    n_updates        | 59878    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13640    |
|    fps              | 38       |
|    time_elapsed     | 7187     |
|    total_timesteps  | 279578   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000178 |
|    n_updates        | 59894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0687   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13644    |
|    fps              | 38       |
|    time_elapsed     | 7188     |
|    total_timesteps  | 279639   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000201 |
|    n_updates        | 59909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0688   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13648    |
|    fps              | 38       |
|    time_elapsed     | 7188     |
|    total_timesteps  | 279703   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 59925    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | 0.0485   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13652    |
|    fps              | 38       |
|    time_elapsed     | 7189     |
|    total_timesteps  | 279767   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00444  |
|    n_updates        | 59941    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13656    |
|    fps              | 38       |
|    time_elapsed     | 7189     |
|    total_timesteps  | 279831   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000333 |
|    n_updates        | 59957    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0383   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13660    |
|    fps              | 38       |
|    time_elapsed     | 7190     |
|    total_timesteps  | 279892   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.98e-05 |
|    n_updates        | 59972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0484   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13664    |
|    fps              | 38       |
|    time_elapsed     | 7190     |
|    total_timesteps  | 279953   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00661  |
|    n_updates        | 59988    |
----------------------------------
Eval num_timesteps=280000, episode_reward=-0.04 +/- 0.14
Episode length: 16.18 +/- 1.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.2     |
|    mean_reward      | -0.0437  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 280000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000131 |
|    n_updates        | 59999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0483   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13668    |
|    fps              | 38       |
|    time_elapsed     | 7195     |
|    total_timesteps  | 280019   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000284 |
|    n_updates        | 60004    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.038    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13672    |
|    fps              | 38       |
|    time_elapsed     | 7195     |
|    total_timesteps  | 280088   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000264 |
|    n_updates        | 60021    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.7     |
|    ep_rew_mean      | 0.0482   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13676    |
|    fps              | 38       |
|    time_elapsed     | 7196     |
|    total_timesteps  | 280147   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000255 |
|    n_updates        | 60036    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0381   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13680    |
|    fps              | 38       |
|    time_elapsed     | 7196     |
|    total_timesteps  | 280211   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000441 |
|    n_updates        | 60052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13684    |
|    fps              | 38       |
|    time_elapsed     | 7197     |
|    total_timesteps  | 280279   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00062  |
|    n_updates        | 60069    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0379   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13688    |
|    fps              | 38       |
|    time_elapsed     | 7197     |
|    total_timesteps  | 280343   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000216 |
|    n_updates        | 60085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13692    |
|    fps              | 38       |
|    time_elapsed     | 7198     |
|    total_timesteps  | 280411   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00027  |
|    n_updates        | 60102    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13696    |
|    fps              | 38       |
|    time_elapsed     | 7198     |
|    total_timesteps  | 280475   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000242 |
|    n_updates        | 60118    |
----------------------------------
Eval num_timesteps=280500, episode_reward=0.04 +/- 0.30
Episode length: 15.88 +/- 1.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | 0.0375   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 280500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00511  |
|    n_updates        | 60124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13700    |
|    fps              | 38       |
|    time_elapsed     | 7202     |
|    total_timesteps  | 280536   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000259 |
|    n_updates        | 60133    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0479   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13704    |
|    fps              | 38       |
|    time_elapsed     | 7203     |
|    total_timesteps  | 280597   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00028  |
|    n_updates        | 60149    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13708    |
|    fps              | 38       |
|    time_elapsed     | 7203     |
|    total_timesteps  | 280662   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00568  |
|    n_updates        | 60165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13712    |
|    fps              | 38       |
|    time_elapsed     | 7204     |
|    total_timesteps  | 280726   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.79e-05 |
|    n_updates        | 60181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13716    |
|    fps              | 38       |
|    time_elapsed     | 7204     |
|    total_timesteps  | 280791   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000356 |
|    n_updates        | 60197    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13720    |
|    fps              | 38       |
|    time_elapsed     | 7205     |
|    total_timesteps  | 280856   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000353 |
|    n_updates        | 60213    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0275   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13724    |
|    fps              | 38       |
|    time_elapsed     | 7205     |
|    total_timesteps  | 280918   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.82e-05 |
|    n_updates        | 60229    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13728    |
|    fps              | 38       |
|    time_elapsed     | 7206     |
|    total_timesteps  | 280982   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000169 |
|    n_updates        | 60245    |
----------------------------------
Eval num_timesteps=281000, episode_reward=-0.00 +/- 0.24
Episode length: 16.10 +/- 1.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.00338 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 281000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00562  |
|    n_updates        | 60249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13732    |
|    fps              | 38       |
|    time_elapsed     | 7210     |
|    total_timesteps  | 281046   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000185 |
|    n_updates        | 60261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13736    |
|    fps              | 38       |
|    time_elapsed     | 7210     |
|    total_timesteps  | 281107   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00993  |
|    n_updates        | 60276    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0173   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13740    |
|    fps              | 38       |
|    time_elapsed     | 7211     |
|    total_timesteps  | 281171   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000178 |
|    n_updates        | 60292    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0072   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13744    |
|    fps              | 38       |
|    time_elapsed     | 7211     |
|    total_timesteps  | 281235   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.23e-05 |
|    n_updates        | 60308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0072   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13748    |
|    fps              | 39       |
|    time_elapsed     | 7212     |
|    total_timesteps  | 281299   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000191 |
|    n_updates        | 60324    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0072   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13752    |
|    fps              | 39       |
|    time_elapsed     | 7212     |
|    total_timesteps  | 281363   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00675  |
|    n_updates        | 60340    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00716  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13756    |
|    fps              | 39       |
|    time_elapsed     | 7213     |
|    total_timesteps  | 281428   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000595 |
|    n_updates        | 60356    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00302 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13760    |
|    fps              | 39       |
|    time_elapsed     | 7213     |
|    total_timesteps  | 281493   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00426  |
|    n_updates        | 60373    |
----------------------------------
Eval num_timesteps=281500, episode_reward=-0.04 +/- 0.14
Episode length: 16.26 +/- 1.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.3     |
|    mean_reward      | -0.044   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 281500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00019  |
|    n_updates        | 60374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0132  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13764    |
|    fps              | 39       |
|    time_elapsed     | 7217     |
|    total_timesteps  | 281557   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.47e-05 |
|    n_updates        | 60389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0131  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13768    |
|    fps              | 39       |
|    time_elapsed     | 7218     |
|    total_timesteps  | 281621   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000106 |
|    n_updates        | 60405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0028  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13772    |
|    fps              | 39       |
|    time_elapsed     | 7218     |
|    total_timesteps  | 281683   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000378 |
|    n_updates        | 60420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00725  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13776    |
|    fps              | 39       |
|    time_elapsed     | 7219     |
|    total_timesteps  | 281741   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000436 |
|    n_updates        | 60435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.00725  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13780    |
|    fps              | 39       |
|    time_elapsed     | 7219     |
|    total_timesteps  | 281805   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000263 |
|    n_updates        | 60451    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13784    |
|    fps              | 39       |
|    time_elapsed     | 7219     |
|    total_timesteps  | 281865   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000173 |
|    n_updates        | 60466    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13788    |
|    fps              | 39       |
|    time_elapsed     | 7220     |
|    total_timesteps  | 281925   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.03e-05 |
|    n_updates        | 60481    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13792    |
|    fps              | 39       |
|    time_elapsed     | 7220     |
|    total_timesteps  | 281989   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00498  |
|    n_updates        | 60497    |
----------------------------------
Eval num_timesteps=282000, episode_reward=0.02 +/- 0.28
Episode length: 15.88 +/- 1.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | 0.0176   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 282000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000268 |
|    n_updates        | 60499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0279   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13796    |
|    fps              | 39       |
|    time_elapsed     | 7225     |
|    total_timesteps  | 282054   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.81e-05 |
|    n_updates        | 60513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0176   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13800    |
|    fps              | 39       |
|    time_elapsed     | 7225     |
|    total_timesteps  | 282121   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000281 |
|    n_updates        | 60530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0277   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13804    |
|    fps              | 39       |
|    time_elapsed     | 7226     |
|    total_timesteps  | 282181   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000171 |
|    n_updates        | 60545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13808    |
|    fps              | 39       |
|    time_elapsed     | 7226     |
|    total_timesteps  | 282248   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000234 |
|    n_updates        | 60561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0377   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13812    |
|    fps              | 39       |
|    time_elapsed     | 7226     |
|    total_timesteps  | 282309   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00604  |
|    n_updates        | 60577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13816    |
|    fps              | 39       |
|    time_elapsed     | 7227     |
|    total_timesteps  | 282373   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00988  |
|    n_updates        | 60593    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0378   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13820    |
|    fps              | 39       |
|    time_elapsed     | 7227     |
|    total_timesteps  | 282437   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.19e-05 |
|    n_updates        | 60609    |
----------------------------------
Eval num_timesteps=282500, episode_reward=-0.02 +/- 0.20
Episode length: 16.12 +/- 1.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0234  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 282500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.11e-05 |
|    n_updates        | 60624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.8     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13824    |
|    fps              | 39       |
|    time_elapsed     | 7231     |
|    total_timesteps  | 282503   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00606  |
|    n_updates        | 60625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13828    |
|    fps              | 39       |
|    time_elapsed     | 7232     |
|    total_timesteps  | 282568   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000421 |
|    n_updates        | 60641    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0276   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13832    |
|    fps              | 39       |
|    time_elapsed     | 7233     |
|    total_timesteps  | 282632   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000307 |
|    n_updates        | 60657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0175   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13836    |
|    fps              | 39       |
|    time_elapsed     | 7233     |
|    total_timesteps  | 282696   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000122 |
|    n_updates        | 60673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13840    |
|    fps              | 39       |
|    time_elapsed     | 7233     |
|    total_timesteps  | 282769   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000102 |
|    n_updates        | 60692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13844    |
|    fps              | 39       |
|    time_elapsed     | 7234     |
|    total_timesteps  | 282833   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000181 |
|    n_updates        | 60708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13848    |
|    fps              | 39       |
|    time_elapsed     | 7234     |
|    total_timesteps  | 282899   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00414  |
|    n_updates        | 60724    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.017    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13852    |
|    fps              | 39       |
|    time_elapsed     | 7235     |
|    total_timesteps  | 282964   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000447 |
|    n_updates        | 60740    |
----------------------------------
Eval num_timesteps=283000, episode_reward=0.02 +/- 0.28
Episode length: 15.96 +/- 1.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.0172   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 283000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00682  |
|    n_updates        | 60749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0271   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13856    |
|    fps              | 39       |
|    time_elapsed     | 7239     |
|    total_timesteps  | 283027   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000371 |
|    n_updates        | 60756    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0474   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13860    |
|    fps              | 39       |
|    time_elapsed     | 7239     |
|    total_timesteps  | 283084   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000224 |
|    n_updates        | 60770    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0474   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13864    |
|    fps              | 39       |
|    time_elapsed     | 7240     |
|    total_timesteps  | 283148   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00417  |
|    n_updates        | 60786    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0474   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13868    |
|    fps              | 39       |
|    time_elapsed     | 7240     |
|    total_timesteps  | 283212   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.5e-05  |
|    n_updates        | 60802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | 0.0373   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13872    |
|    fps              | 39       |
|    time_elapsed     | 7241     |
|    total_timesteps  | 283276   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000208 |
|    n_updates        | 60818    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13876    |
|    fps              | 39       |
|    time_elapsed     | 7241     |
|    total_timesteps  | 283340   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000394 |
|    n_updates        | 60834    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.0171   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13880    |
|    fps              | 39       |
|    time_elapsed     | 7242     |
|    total_timesteps  | 283404   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00038  |
|    n_updates        | 60850    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00686  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13884    |
|    fps              | 39       |
|    time_elapsed     | 7242     |
|    total_timesteps  | 283469   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000212 |
|    n_updates        | 60867    |
----------------------------------
Eval num_timesteps=283500, episode_reward=0.02 +/- 0.27
Episode length: 15.84 +/- 0.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.0177   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 283500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.33e-05 |
|    n_updates        | 60874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00329 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13888    |
|    fps              | 39       |
|    time_elapsed     | 7246     |
|    total_timesteps  | 283533   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000711 |
|    n_updates        | 60883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00672  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13892    |
|    fps              | 39       |
|    time_elapsed     | 7247     |
|    total_timesteps  | 283597   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000308 |
|    n_updates        | 60899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00676  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13896    |
|    fps              | 39       |
|    time_elapsed     | 7247     |
|    total_timesteps  | 283661   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00403  |
|    n_updates        | 60915    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | 0.00688  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13900    |
|    fps              | 39       |
|    time_elapsed     | 7248     |
|    total_timesteps  | 283725   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00376  |
|    n_updates        | 60931    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0133  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13904    |
|    fps              | 39       |
|    time_elapsed     | 7248     |
|    total_timesteps  | 283789   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00039  |
|    n_updates        | 60947    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00305 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13908    |
|    fps              | 39       |
|    time_elapsed     | 7249     |
|    total_timesteps  | 283850   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00044  |
|    n_updates        | 60962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00301 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13912    |
|    fps              | 39       |
|    time_elapsed     | 7249     |
|    total_timesteps  | 283910   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000544 |
|    n_updates        | 60977    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00301 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13916    |
|    fps              | 39       |
|    time_elapsed     | 7249     |
|    total_timesteps  | 283974   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.74e-05 |
|    n_updates        | 60993    |
----------------------------------
Eval num_timesteps=284000, episode_reward=0.09 +/- 0.37
Episode length: 16.78 +/- 7.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.8     |
|    mean_reward      | 0.094    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 284000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00768  |
|    n_updates        | 60999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00301 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13920    |
|    fps              | 39       |
|    time_elapsed     | 7254     |
|    total_timesteps  | 284038   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000127 |
|    n_updates        | 61009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00297 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13924    |
|    fps              | 39       |
|    time_elapsed     | 7254     |
|    total_timesteps  | 284103   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0113   |
|    n_updates        | 61025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00293 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13928    |
|    fps              | 39       |
|    time_elapsed     | 7255     |
|    total_timesteps  | 284167   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000185 |
|    n_updates        | 61041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.00297 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13932    |
|    fps              | 39       |
|    time_elapsed     | 7255     |
|    total_timesteps  | 284232   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000308 |
|    n_updates        | 61057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00534 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13936    |
|    fps              | 39       |
|    time_elapsed     | 7256     |
|    total_timesteps  | 284355   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000436 |
|    n_updates        | 61088    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.00504  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13940    |
|    fps              | 39       |
|    time_elapsed     | 7256     |
|    total_timesteps  | 284419   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000133 |
|    n_updates        | 61104    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0152   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13944    |
|    fps              | 39       |
|    time_elapsed     | 7257     |
|    total_timesteps  | 284480   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00515  |
|    n_updates        | 61119    |
----------------------------------
Eval num_timesteps=284500, episode_reward=-0.02 +/- 0.20
Episode length: 16.06 +/- 0.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.0232  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 284500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000542 |
|    n_updates        | 61124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | 0.0253   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13948    |
|    fps              | 39       |
|    time_elapsed     | 7261     |
|    total_timesteps  | 284542   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000349 |
|    n_updates        | 61135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0252   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13952    |
|    fps              | 39       |
|    time_elapsed     | 7262     |
|    total_timesteps  | 284610   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000338 |
|    n_updates        | 61152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | 0.0151   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13956    |
|    fps              | 39       |
|    time_elapsed     | 7262     |
|    total_timesteps  | 284676   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00597  |
|    n_updates        | 61168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00533 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13960    |
|    fps              | 39       |
|    time_elapsed     | 7263     |
|    total_timesteps  | 284743   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000578 |
|    n_updates        | 61185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00533 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13964    |
|    fps              | 39       |
|    time_elapsed     | 7263     |
|    total_timesteps  | 284807   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000128 |
|    n_updates        | 61201    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | 0.00253  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13968    |
|    fps              | 39       |
|    time_elapsed     | 7264     |
|    total_timesteps  | 284925   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0149   |
|    n_updates        | 61231    |
----------------------------------
Eval num_timesteps=285000, episode_reward=-0.17 +/- 0.27
Episode length: 58.76 +/- 21.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.8     |
|    mean_reward      | -0.175   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 285000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00602  |
|    n_updates        | 61249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | 0.00093  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13972    |
|    fps              | 39       |
|    time_elapsed     | 7277     |
|    total_timesteps  | 285029   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00429  |
|    n_updates        | 61257    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18       |
|    ep_rew_mean      | -0.00107 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13976    |
|    fps              | 39       |
|    time_elapsed     | 7277     |
|    total_timesteps  | 285143   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000515 |
|    n_updates        | 61285    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.00384 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13980    |
|    fps              | 39       |
|    time_elapsed     | 7278     |
|    total_timesteps  | 285276   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000243 |
|    n_updates        | 61318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.00624 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13984    |
|    fps              | 39       |
|    time_elapsed     | 7279     |
|    total_timesteps  | 285401   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000222 |
|    n_updates        | 61350    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.00388  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13988    |
|    fps              | 39       |
|    time_elapsed     | 7279     |
|    total_timesteps  | 285462   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000151 |
|    n_updates        | 61365    |
----------------------------------
Eval num_timesteps=285500, episode_reward=0.02 +/- 0.28
Episode length: 15.90 +/- 1.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | 0.0174   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 285500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.43e-05 |
|    n_updates        | 61374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.00621 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13992    |
|    fps              | 39       |
|    time_elapsed     | 7284     |
|    total_timesteps  | 285528   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000227 |
|    n_updates        | 61381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.00621 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 13996    |
|    fps              | 39       |
|    time_elapsed     | 7284     |
|    total_timesteps  | 285592   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000425 |
|    n_updates        | 61397    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.00621 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14000    |
|    fps              | 39       |
|    time_elapsed     | 7285     |
|    total_timesteps  | 285656   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000297 |
|    n_updates        | 61413    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | 0.00393  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14004    |
|    fps              | 39       |
|    time_elapsed     | 7285     |
|    total_timesteps  | 285717   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000596 |
|    n_updates        | 61429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00634 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14008    |
|    fps              | 39       |
|    time_elapsed     | 7286     |
|    total_timesteps  | 285785   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0069   |
|    n_updates        | 61446    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.0165  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14012    |
|    fps              | 39       |
|    time_elapsed     | 7286     |
|    total_timesteps  | 285849   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000434 |
|    n_updates        | 61462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00637 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14016    |
|    fps              | 39       |
|    time_elapsed     | 7286     |
|    total_timesteps  | 285909   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00559  |
|    n_updates        | 61477    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00637 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14020    |
|    fps              | 39       |
|    time_elapsed     | 7287     |
|    total_timesteps  | 285973   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000449 |
|    n_updates        | 61493    |
----------------------------------
Eval num_timesteps=286000, episode_reward=0.08 +/- 0.35
Episode length: 15.60 +/- 1.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.6     |
|    mean_reward      | 0.0786   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 286000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000266 |
|    n_updates        | 61499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.3     |
|    ep_rew_mean      | -0.00633 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14024    |
|    fps              | 39       |
|    time_elapsed     | 7291     |
|    total_timesteps  | 286037   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000177 |
|    n_updates        | 61509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00649 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14028    |
|    fps              | 39       |
|    time_elapsed     | 7292     |
|    total_timesteps  | 286105   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0114   |
|    n_updates        | 61526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 19.4     |
|    ep_rew_mean      | -0.00649 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14032    |
|    fps              | 39       |
|    time_elapsed     | 7292     |
|    total_timesteps  | 286170   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0145   |
|    n_updates        | 61542    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00412 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14036    |
|    fps              | 39       |
|    time_elapsed     | 7293     |
|    total_timesteps  | 286234   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00507  |
|    n_updates        | 61558    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.00409 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14040    |
|    fps              | 39       |
|    time_elapsed     | 7293     |
|    total_timesteps  | 286297   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000189 |
|    n_updates        | 61574    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0143  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14044    |
|    fps              | 39       |
|    time_elapsed     | 7293     |
|    total_timesteps  | 286364   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000256 |
|    n_updates        | 61590    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14048    |
|    fps              | 39       |
|    time_elapsed     | 7294     |
|    total_timesteps  | 286424   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000437 |
|    n_updates        | 61605    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0142  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14052    |
|    fps              | 39       |
|    time_elapsed     | 7294     |
|    total_timesteps  | 286490   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000283 |
|    n_updates        | 61622    |
----------------------------------
Eval num_timesteps=286500, episode_reward=-0.02 +/- 0.20
Episode length: 15.86 +/- 0.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.0224  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 286500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00605  |
|    n_updates        | 61624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.8     |
|    ep_rew_mean      | -0.0141  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14056    |
|    fps              | 39       |
|    time_elapsed     | 7299     |
|    total_timesteps  | 286554   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000281 |
|    n_updates        | 61638    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0038  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14060    |
|    fps              | 39       |
|    time_elapsed     | 7299     |
|    total_timesteps  | 286614   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000391 |
|    n_updates        | 61653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.7     |
|    ep_rew_mean      | -0.0038  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14064    |
|    fps              | 39       |
|    time_elapsed     | 7300     |
|    total_timesteps  | 286678   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00022  |
|    n_updates        | 61669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.2     |
|    ep_rew_mean      | -0.0117  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14068    |
|    fps              | 39       |
|    time_elapsed     | 7300     |
|    total_timesteps  | 286744   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00016  |
|    n_updates        | 61685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.8     |
|    ep_rew_mean      | -0.0101  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14072    |
|    fps              | 39       |
|    time_elapsed     | 7300     |
|    total_timesteps  | 286808   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000217 |
|    n_updates        | 61701    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.00842 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14076    |
|    fps              | 39       |
|    time_elapsed     | 7301     |
|    total_timesteps  | 286879   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000152 |
|    n_updates        | 61719    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00565 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14080    |
|    fps              | 39       |
|    time_elapsed     | 7301     |
|    total_timesteps  | 286943   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000561 |
|    n_updates        | 61735    |
----------------------------------
Eval num_timesteps=287000, episode_reward=0.01 +/- 0.28
Episode length: 17.44 +/- 7.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.4     |
|    mean_reward      | 0.0113   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 287000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000304 |
|    n_updates        | 61749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.0068   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14084    |
|    fps              | 39       |
|    time_elapsed     | 7306     |
|    total_timesteps  | 287007   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0042   |
|    n_updates        | 61751    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.0034  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14088    |
|    fps              | 39       |
|    time_elapsed     | 7306     |
|    total_timesteps  | 287073   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000206 |
|    n_updates        | 61768    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00332 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14092    |
|    fps              | 39       |
|    time_elapsed     | 7307     |
|    total_timesteps  | 287137   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000512 |
|    n_updates        | 61784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | -0.00332 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14096    |
|    fps              | 39       |
|    time_elapsed     | 7307     |
|    total_timesteps  | 287201   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00992  |
|    n_updates        | 61800    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.1     |
|    ep_rew_mean      | 0.00654  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14100    |
|    fps              | 39       |
|    time_elapsed     | 7308     |
|    total_timesteps  | 287269   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000313 |
|    n_updates        | 61817    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0048  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14104    |
|    fps              | 39       |
|    time_elapsed     | 7308     |
|    total_timesteps  | 287363   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000325 |
|    n_updates        | 61840    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00464 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14108    |
|    fps              | 39       |
|    time_elapsed     | 7309     |
|    total_timesteps  | 287427   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000284 |
|    n_updates        | 61856    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00468 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14112    |
|    fps              | 39       |
|    time_elapsed     | 7309     |
|    total_timesteps  | 287492   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 61872    |
----------------------------------
Eval num_timesteps=287500, episode_reward=-0.00 +/- 0.24
Episode length: 15.94 +/- 0.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.00272 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 287500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00484  |
|    n_updates        | 61874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14116    |
|    fps              | 39       |
|    time_elapsed     | 7314     |
|    total_timesteps  | 287556   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000305 |
|    n_updates        | 61888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.0148  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14120    |
|    fps              | 39       |
|    time_elapsed     | 7314     |
|    total_timesteps  | 287620   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000225 |
|    n_updates        | 61904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00467 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14124    |
|    fps              | 39       |
|    time_elapsed     | 7315     |
|    total_timesteps  | 287680   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000449 |
|    n_updates        | 61919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00451 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14128    |
|    fps              | 39       |
|    time_elapsed     | 7315     |
|    total_timesteps  | 287744   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.44e-05 |
|    n_updates        | 61935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.4     |
|    ep_rew_mean      | -0.00447 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14132    |
|    fps              | 39       |
|    time_elapsed     | 7315     |
|    total_timesteps  | 287808   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000611 |
|    n_updates        | 61951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.00487 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14136    |
|    fps              | 39       |
|    time_elapsed     | 7316     |
|    total_timesteps  | 287882   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000322 |
|    n_updates        | 61970    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0152  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14140    |
|    fps              | 39       |
|    time_elapsed     | 7316     |
|    total_timesteps  | 287953   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00023  |
|    n_updates        | 61988    |
----------------------------------
Eval num_timesteps=288000, episode_reward=0.07 +/- 0.36
Episode length: 17.48 +/- 8.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.5     |
|    mean_reward      | 0.0712   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 288000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000118 |
|    n_updates        | 61999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0153  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14144    |
|    fps              | 39       |
|    time_elapsed     | 7321     |
|    total_timesteps  | 288023   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000223 |
|    n_updates        | 62005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0267  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14148    |
|    fps              | 39       |
|    time_elapsed     | 7322     |
|    total_timesteps  | 288118   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000329 |
|    n_updates        | 62029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0266  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14152    |
|    fps              | 39       |
|    time_elapsed     | 7322     |
|    total_timesteps  | 288182   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000165 |
|    n_updates        | 62045    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0268  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14156    |
|    fps              | 39       |
|    time_elapsed     | 7323     |
|    total_timesteps  | 288249   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000189 |
|    n_updates        | 62062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0374  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14160    |
|    fps              | 39       |
|    time_elapsed     | 7323     |
|    total_timesteps  | 288326   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00589  |
|    n_updates        | 62081    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0379  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14164    |
|    fps              | 39       |
|    time_elapsed     | 7324     |
|    total_timesteps  | 288402   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00458  |
|    n_updates        | 62100    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0378  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14168    |
|    fps              | 39       |
|    time_elapsed     | 7324     |
|    total_timesteps  | 288466   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00768  |
|    n_updates        | 62116    |
----------------------------------
Eval num_timesteps=288500, episode_reward=-0.06 +/- 0.00
Episode length: 16.00 +/- 0.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.063   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 288500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000264 |
|    n_updates        | 62124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0378  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14172    |
|    fps              | 39       |
|    time_elapsed     | 7328     |
|    total_timesteps  | 288530   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000179 |
|    n_updates        | 62132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0376  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14176    |
|    fps              | 39       |
|    time_elapsed     | 7329     |
|    total_timesteps  | 288594   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000511 |
|    n_updates        | 62148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0376  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14180    |
|    fps              | 39       |
|    time_elapsed     | 7329     |
|    total_timesteps  | 288658   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00504  |
|    n_updates        | 62164    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0375  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14184    |
|    fps              | 39       |
|    time_elapsed     | 7330     |
|    total_timesteps  | 288720   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00751  |
|    n_updates        | 62179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0374  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14188    |
|    fps              | 39       |
|    time_elapsed     | 7330     |
|    total_timesteps  | 288784   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00047  |
|    n_updates        | 62195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0374  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14192    |
|    fps              | 39       |
|    time_elapsed     | 7331     |
|    total_timesteps  | 288848   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000123 |
|    n_updates        | 62211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0273  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14196    |
|    fps              | 39       |
|    time_elapsed     | 7331     |
|    total_timesteps  | 288910   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00772  |
|    n_updates        | 62227    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14200    |
|    fps              | 39       |
|    time_elapsed     | 7331     |
|    total_timesteps  | 288970   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0108   |
|    n_updates        | 62242    |
----------------------------------
Eval num_timesteps=289000, episode_reward=0.02 +/- 0.27
Episode length: 15.90 +/- 1.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | 0.0175   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 289000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00996  |
|    n_updates        | 62249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0258  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14204    |
|    fps              | 39       |
|    time_elapsed     | 7336     |
|    total_timesteps  | 289034   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000231 |
|    n_updates        | 62258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0258  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14208    |
|    fps              | 39       |
|    time_elapsed     | 7336     |
|    total_timesteps  | 289098   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000448 |
|    n_updates        | 62274    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0258  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14212    |
|    fps              | 39       |
|    time_elapsed     | 7337     |
|    total_timesteps  | 289162   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00391  |
|    n_updates        | 62290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0258  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14216    |
|    fps              | 39       |
|    time_elapsed     | 7337     |
|    total_timesteps  | 289226   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000599 |
|    n_updates        | 62306    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0258  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14220    |
|    fps              | 39       |
|    time_elapsed     | 7338     |
|    total_timesteps  | 289291   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00381  |
|    n_updates        | 62322    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0259  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14224    |
|    fps              | 39       |
|    time_elapsed     | 7338     |
|    total_timesteps  | 289353   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000152 |
|    n_updates        | 62338    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0259  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14228    |
|    fps              | 39       |
|    time_elapsed     | 7339     |
|    total_timesteps  | 289417   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000331 |
|    n_updates        | 62354    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0259  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14232    |
|    fps              | 39       |
|    time_elapsed     | 7339     |
|    total_timesteps  | 289481   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000416 |
|    n_updates        | 62370    |
----------------------------------
Eval num_timesteps=289500, episode_reward=0.08 +/- 0.35
Episode length: 15.74 +/- 1.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.7     |
|    mean_reward      | 0.0782   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 289500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00574  |
|    n_updates        | 62374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0255  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14236    |
|    fps              | 39       |
|    time_elapsed     | 7344     |
|    total_timesteps  | 289545   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00548  |
|    n_updates        | 62386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0252  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14240    |
|    fps              | 39       |
|    time_elapsed     | 7344     |
|    total_timesteps  | 289609   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000202 |
|    n_updates        | 62402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.5     |
|    ep_rew_mean      | -0.025   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14244    |
|    fps              | 39       |
|    time_elapsed     | 7345     |
|    total_timesteps  | 289673   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000767 |
|    n_updates        | 62418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14248    |
|    fps              | 39       |
|    time_elapsed     | 7345     |
|    total_timesteps  | 289737   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0077   |
|    n_updates        | 62434    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0237  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14252    |
|    fps              | 39       |
|    time_elapsed     | 7346     |
|    total_timesteps  | 289801   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000466 |
|    n_updates        | 62450    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.2     |
|    ep_rew_mean      | -0.0236  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14256    |
|    fps              | 39       |
|    time_elapsed     | 7346     |
|    total_timesteps  | 289865   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00925  |
|    n_updates        | 62466    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.0231  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14260    |
|    fps              | 39       |
|    time_elapsed     | 7346     |
|    total_timesteps  | 289929   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00769  |
|    n_updates        | 62482    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14264    |
|    fps              | 39       |
|    time_elapsed     | 7347     |
|    total_timesteps  | 289993   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000703 |
|    n_updates        | 62498    |
----------------------------------
Eval num_timesteps=290000, episode_reward=0.04 +/- 0.30
Episode length: 15.72 +/- 1.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.7     |
|    mean_reward      | 0.0382   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 290000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000288 |
|    n_updates        | 62499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0226  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14268    |
|    fps              | 39       |
|    time_elapsed     | 7352     |
|    total_timesteps  | 290057   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0132   |
|    n_updates        | 62514    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0125  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14272    |
|    fps              | 39       |
|    time_elapsed     | 7352     |
|    total_timesteps  | 290118   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000206 |
|    n_updates        | 62529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14276    |
|    fps              | 39       |
|    time_elapsed     | 7353     |
|    total_timesteps  | 290184   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000198 |
|    n_updates        | 62545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14280    |
|    fps              | 39       |
|    time_elapsed     | 7353     |
|    total_timesteps  | 290248   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000108 |
|    n_updates        | 62561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0125  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14284    |
|    fps              | 39       |
|    time_elapsed     | 7353     |
|    total_timesteps  | 290308   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00685  |
|    n_updates        | 62576    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0125  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14288    |
|    fps              | 39       |
|    time_elapsed     | 7354     |
|    total_timesteps  | 290372   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000509 |
|    n_updates        | 62592    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0126  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14292    |
|    fps              | 39       |
|    time_elapsed     | 7354     |
|    total_timesteps  | 290439   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00719  |
|    n_updates        | 62609    |
----------------------------------
Eval num_timesteps=290500, episode_reward=0.04 +/- 0.30
Episode length: 16.26 +/- 1.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.3     |
|    mean_reward      | 0.036    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 290500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000492 |
|    n_updates        | 62624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.9     |
|    ep_rew_mean      | -0.0228  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14296    |
|    fps              | 39       |
|    time_elapsed     | 7359     |
|    total_timesteps  | 290505   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000332 |
|    n_updates        | 62626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16       |
|    ep_rew_mean      | -0.033   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14300    |
|    fps              | 39       |
|    time_elapsed     | 7359     |
|    total_timesteps  | 290569   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000385 |
|    n_updates        | 62642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0354  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14304    |
|    fps              | 39       |
|    time_elapsed     | 7360     |
|    total_timesteps  | 290693   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.94e-05 |
|    n_updates        | 62673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0355  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14308    |
|    fps              | 39       |
|    time_elapsed     | 7360     |
|    total_timesteps  | 290759   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.32e-05 |
|    n_updates        | 62689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0253  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14312    |
|    fps              | 39       |
|    time_elapsed     | 7361     |
|    total_timesteps  | 290820   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000303 |
|    n_updates        | 62704    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0256  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14316    |
|    fps              | 39       |
|    time_elapsed     | 7361     |
|    total_timesteps  | 290890   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000359 |
|    n_updates        | 62722    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.0156  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14320    |
|    fps              | 39       |
|    time_elapsed     | 7362     |
|    total_timesteps  | 290956   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000183 |
|    n_updates        | 62738    |
----------------------------------
Eval num_timesteps=291000, episode_reward=-0.07 +/- 0.23
Episode length: 27.06 +/- 22.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 27.1     |
|    mean_reward      | -0.0674  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 291000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00998  |
|    n_updates        | 62749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0258  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14324    |
|    fps              | 39       |
|    time_elapsed     | 7368     |
|    total_timesteps  | 291022   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00833  |
|    n_updates        | 62755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0281  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14328    |
|    fps              | 39       |
|    time_elapsed     | 7369     |
|    total_timesteps  | 291145   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.1e-05  |
|    n_updates        | 62786    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0283  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14332    |
|    fps              | 39       |
|    time_elapsed     | 7369     |
|    total_timesteps  | 291214   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000538 |
|    n_updates        | 62803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0283  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14336    |
|    fps              | 39       |
|    time_elapsed     | 7369     |
|    total_timesteps  | 291278   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000234 |
|    n_updates        | 62819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0283  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14340    |
|    fps              | 39       |
|    time_elapsed     | 7370     |
|    total_timesteps  | 291342   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00816  |
|    n_updates        | 62835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0283  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14344    |
|    fps              | 39       |
|    time_elapsed     | 7370     |
|    total_timesteps  | 291406   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000121 |
|    n_updates        | 62851    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0283  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14348    |
|    fps              | 39       |
|    time_elapsed     | 7371     |
|    total_timesteps  | 291470   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00064  |
|    n_updates        | 62867    |
----------------------------------
Eval num_timesteps=291500, episode_reward=-0.00 +/- 0.24
Episode length: 16.18 +/- 1.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.2     |
|    mean_reward      | -0.00366 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 291500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000452 |
|    n_updates        | 62874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0284  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14352    |
|    fps              | 39       |
|    time_elapsed     | 7375     |
|    total_timesteps  | 291537   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.11e-05 |
|    n_updates        | 62884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0287  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14356    |
|    fps              | 39       |
|    time_elapsed     | 7376     |
|    total_timesteps  | 291607   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.015    |
|    n_updates        | 62901    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0287  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14360    |
|    fps              | 39       |
|    time_elapsed     | 7376     |
|    total_timesteps  | 291672   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000494 |
|    n_updates        | 62917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | -0.0287  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14364    |
|    fps              | 39       |
|    time_elapsed     | 7377     |
|    total_timesteps  | 291736   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00781  |
|    n_updates        | 62933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0289  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14368    |
|    fps              | 39       |
|    time_elapsed     | 7377     |
|    total_timesteps  | 291805   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000948 |
|    n_updates        | 62951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.039   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14372    |
|    fps              | 39       |
|    time_elapsed     | 7377     |
|    total_timesteps  | 291869   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.011    |
|    n_updates        | 62967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.039   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14376    |
|    fps              | 39       |
|    time_elapsed     | 7378     |
|    total_timesteps  | 291935   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000355 |
|    n_updates        | 62983    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.039   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14380    |
|    fps              | 39       |
|    time_elapsed     | 7378     |
|    total_timesteps  | 291999   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00378  |
|    n_updates        | 62999    |
----------------------------------
Eval num_timesteps=292000, episode_reward=-0.01 +/- 0.24
Episode length: 17.04 +/- 8.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 17       |
|    mean_reward     | -0.0072  |
| time/              |          |
|    total_timesteps | 292000   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0492  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14384    |
|    fps              | 39       |
|    time_elapsed     | 7383     |
|    total_timesteps  | 292063   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00473  |
|    n_updates        | 63015    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0492  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14388    |
|    fps              | 39       |
|    time_elapsed     | 7383     |
|    total_timesteps  | 292127   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000742 |
|    n_updates        | 63031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0491  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14392    |
|    fps              | 39       |
|    time_elapsed     | 7384     |
|    total_timesteps  | 292191   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000238 |
|    n_updates        | 63047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.049   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14396    |
|    fps              | 39       |
|    time_elapsed     | 7384     |
|    total_timesteps  | 292255   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000636 |
|    n_updates        | 63063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.049   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14400    |
|    fps              | 39       |
|    time_elapsed     | 7385     |
|    total_timesteps  | 292319   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000424 |
|    n_updates        | 63079    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0472  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14404    |
|    fps              | 39       |
|    time_elapsed     | 7385     |
|    total_timesteps  | 292397   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000578 |
|    n_updates        | 63099    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.037   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14408    |
|    fps              | 39       |
|    time_elapsed     | 7386     |
|    total_timesteps  | 292459   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00889  |
|    n_updates        | 63114    |
----------------------------------
Eval num_timesteps=292500, episode_reward=-0.02 +/- 0.20
Episode length: 16.28 +/- 2.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.3     |
|    mean_reward      | -0.0241  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 292500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000424 |
|    n_updates        | 63124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.6     |
|    ep_rew_mean      | -0.0393  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14412    |
|    fps              | 39       |
|    time_elapsed     | 7390     |
|    total_timesteps  | 292578   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00337  |
|    n_updates        | 63144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0391  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14416    |
|    fps              | 39       |
|    time_elapsed     | 7391     |
|    total_timesteps  | 292643   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000341 |
|    n_updates        | 63160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0389  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14420    |
|    fps              | 39       |
|    time_elapsed     | 7391     |
|    total_timesteps  | 292704   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000374 |
|    n_updates        | 63175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.5     |
|    ep_rew_mean      | -0.0388  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14424    |
|    fps              | 39       |
|    time_elapsed     | 7392     |
|    total_timesteps  | 292768   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.32e-05 |
|    n_updates        | 63191    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0264  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14428    |
|    fps              | 39       |
|    time_elapsed     | 7392     |
|    total_timesteps  | 292830   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00573  |
|    n_updates        | 63207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.0262  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14432    |
|    fps              | 39       |
|    time_elapsed     | 7393     |
|    total_timesteps  | 292894   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00588  |
|    n_updates        | 63223    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0267  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14436    |
|    fps              | 39       |
|    time_elapsed     | 7393     |
|    total_timesteps  | 292972   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00382  |
|    n_updates        | 63242    |
----------------------------------
Eval num_timesteps=293000, episode_reward=-0.00 +/- 0.24
Episode length: 15.88 +/- 0.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | -0.00252 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 293000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000275 |
|    n_updates        | 63249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0268  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14440    |
|    fps              | 39       |
|    time_elapsed     | 7398     |
|    total_timesteps  | 293037   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00058  |
|    n_updates        | 63259    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0268  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14444    |
|    fps              | 39       |
|    time_elapsed     | 7398     |
|    total_timesteps  | 293102   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00817  |
|    n_updates        | 63275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0269  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14448    |
|    fps              | 39       |
|    time_elapsed     | 7399     |
|    total_timesteps  | 293168   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0011   |
|    n_updates        | 63291    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0268  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14452    |
|    fps              | 39       |
|    time_elapsed     | 7399     |
|    total_timesteps  | 293234   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000202 |
|    n_updates        | 63308    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0266  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14456    |
|    fps              | 39       |
|    time_elapsed     | 7400     |
|    total_timesteps  | 293298   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00462  |
|    n_updates        | 63324    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14460    |
|    fps              | 39       |
|    time_elapsed     | 7400     |
|    total_timesteps  | 293358   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00537  |
|    n_updates        | 63339    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0164  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14464    |
|    fps              | 39       |
|    time_elapsed     | 7401     |
|    total_timesteps  | 293422   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00376  |
|    n_updates        | 63355    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00612 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14468    |
|    fps              | 39       |
|    time_elapsed     | 7401     |
|    total_timesteps  | 293484   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000244 |
|    n_updates        | 63370    |
----------------------------------
Eval num_timesteps=293500, episode_reward=-0.03 +/- 0.20
Episode length: 18.14 +/- 8.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 18.1     |
|    mean_reward      | -0.0316  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 293500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000185 |
|    n_updates        | 63374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00372  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14472    |
|    fps              | 39       |
|    time_elapsed     | 7406     |
|    total_timesteps  | 293552   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000146 |
|    n_updates        | 63387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0038   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14476    |
|    fps              | 39       |
|    time_elapsed     | 7406     |
|    total_timesteps  | 293616   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000288 |
|    n_updates        | 63403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00372  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14480    |
|    fps              | 39       |
|    time_elapsed     | 7407     |
|    total_timesteps  | 293682   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000601 |
|    n_updates        | 63420    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0135   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14484    |
|    fps              | 39       |
|    time_elapsed     | 7407     |
|    total_timesteps  | 293752   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000146 |
|    n_updates        | 63437    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0236   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14488    |
|    fps              | 39       |
|    time_elapsed     | 7408     |
|    total_timesteps  | 293812   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000376 |
|    n_updates        | 63452    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0236   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14492    |
|    fps              | 39       |
|    time_elapsed     | 7408     |
|    total_timesteps  | 293876   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00535  |
|    n_updates        | 63468    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0236   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14496    |
|    fps              | 39       |
|    time_elapsed     | 7409     |
|    total_timesteps  | 293940   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00423  |
|    n_updates        | 63484    |
----------------------------------
Eval num_timesteps=294000, episode_reward=-0.06 +/- 0.00
Episode length: 16.36 +/- 0.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.4     |
|    mean_reward      | -0.0644  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 294000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000624 |
|    n_updates        | 63499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | 0.0236   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14500    |
|    fps              | 39       |
|    time_elapsed     | 7413     |
|    total_timesteps  | 294004   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000683 |
|    n_updates        | 63500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0218   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14504    |
|    fps              | 39       |
|    time_elapsed     | 7414     |
|    total_timesteps  | 294127   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.29e-05 |
|    n_updates        | 63531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0116   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14508    |
|    fps              | 39       |
|    time_elapsed     | 7414     |
|    total_timesteps  | 294194   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000421 |
|    n_updates        | 63548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00381  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14512    |
|    fps              | 39       |
|    time_elapsed     | 7415     |
|    total_timesteps  | 294258   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.69e-05 |
|    n_updates        | 63564    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14516    |
|    fps              | 39       |
|    time_elapsed     | 7415     |
|    total_timesteps  | 294318   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000363 |
|    n_updates        | 63579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00389  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14520    |
|    fps              | 39       |
|    time_elapsed     | 7416     |
|    total_timesteps  | 294382   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000427 |
|    n_updates        | 63595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00389  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14524    |
|    fps              | 39       |
|    time_elapsed     | 7416     |
|    total_timesteps  | 294446   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0051   |
|    n_updates        | 63611    |
----------------------------------
Eval num_timesteps=294500, episode_reward=-0.02 +/- 0.20
Episode length: 15.96 +/- 0.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.0229  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 294500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00657  |
|    n_updates        | 63624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00651 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14528    |
|    fps              | 39       |
|    time_elapsed     | 7420     |
|    total_timesteps  | 294518   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000571 |
|    n_updates        | 63629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.00655 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14532    |
|    fps              | 39       |
|    time_elapsed     | 7421     |
|    total_timesteps  | 294583   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00122  |
|    n_updates        | 63645    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14536    |
|    fps              | 39       |
|    time_elapsed     | 7421     |
|    total_timesteps  | 294641   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000287 |
|    n_updates        | 63660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0142   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14540    |
|    fps              | 39       |
|    time_elapsed     | 7422     |
|    total_timesteps  | 294707   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000454 |
|    n_updates        | 63676    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14544    |
|    fps              | 39       |
|    time_elapsed     | 7422     |
|    total_timesteps  | 294771   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000515 |
|    n_updates        | 63692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0243   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14548    |
|    fps              | 39       |
|    time_elapsed     | 7423     |
|    total_timesteps  | 294836   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000259 |
|    n_updates        | 63708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0242   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14552    |
|    fps              | 39       |
|    time_elapsed     | 7423     |
|    total_timesteps  | 294906   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00672  |
|    n_updates        | 63726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0238   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14556    |
|    fps              | 39       |
|    time_elapsed     | 7424     |
|    total_timesteps  | 294978   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000827 |
|    n_updates        | 63744    |
----------------------------------
Eval num_timesteps=295000, episode_reward=0.02 +/- 0.28
Episode length: 16.00 +/- 1.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.017    |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 295000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.32e-05 |
|    n_updates        | 63749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0137   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14560    |
|    fps              | 39       |
|    time_elapsed     | 7428     |
|    total_timesteps  | 295042   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000144 |
|    n_updates        | 63760    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0137   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14564    |
|    fps              | 39       |
|    time_elapsed     | 7429     |
|    total_timesteps  | 295106   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000465 |
|    n_updates        | 63776    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0137   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14568    |
|    fps              | 39       |
|    time_elapsed     | 7429     |
|    total_timesteps  | 295168   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000113 |
|    n_updates        | 63791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.00386  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14572    |
|    fps              | 39       |
|    time_elapsed     | 7430     |
|    total_timesteps  | 295232   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.11e-05 |
|    n_updates        | 63807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14576    |
|    fps              | 39       |
|    time_elapsed     | 7430     |
|    total_timesteps  | 295293   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000523 |
|    n_updates        | 63823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14580    |
|    fps              | 39       |
|    time_elapsed     | 7430     |
|    total_timesteps  | 295358   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000554 |
|    n_updates        | 63839    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0143   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14584    |
|    fps              | 39       |
|    time_elapsed     | 7431     |
|    total_timesteps  | 295420   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000272 |
|    n_updates        | 63854    |
----------------------------------
Eval num_timesteps=295500, episode_reward=-0.01 +/- 0.24
Episode length: 17.44 +/- 2.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17.4     |
|    mean_reward      | -0.00866 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 295500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000511 |
|    n_updates        | 63874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0119   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14588    |
|    fps              | 39       |
|    time_elapsed     | 7436     |
|    total_timesteps  | 295541   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000316 |
|    n_updates        | 63885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | 0.0118   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14592    |
|    fps              | 39       |
|    time_elapsed     | 7436     |
|    total_timesteps  | 295607   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000771 |
|    n_updates        | 63901    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14596    |
|    fps              | 39       |
|    time_elapsed     | 7437     |
|    total_timesteps  | 295678   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.92e-05 |
|    n_updates        | 63919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.4     |
|    ep_rew_mean      | 0.0115   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14600    |
|    fps              | 39       |
|    time_elapsed     | 7437     |
|    total_timesteps  | 295742   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.16e-05 |
|    n_updates        | 63935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14604    |
|    fps              | 39       |
|    time_elapsed     | 7438     |
|    total_timesteps  | 295806   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 9.07e-05 |
|    n_updates        | 63951    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14608    |
|    fps              | 39       |
|    time_elapsed     | 7438     |
|    total_timesteps  | 295870   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000498 |
|    n_updates        | 63967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0242   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14612    |
|    fps              | 39       |
|    time_elapsed     | 7439     |
|    total_timesteps  | 295930   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000321 |
|    n_updates        | 63982    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14616    |
|    fps              | 39       |
|    time_elapsed     | 7439     |
|    total_timesteps  | 295994   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000575 |
|    n_updates        | 63998    |
----------------------------------
Eval num_timesteps=296000, episode_reward=0.06 +/- 0.33
Episode length: 15.96 +/- 1.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.0572   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 296000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000123 |
|    n_updates        | 63999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.014    |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14620    |
|    fps              | 39       |
|    time_elapsed     | 7443     |
|    total_timesteps  | 296059   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00297  |
|    n_updates        | 64014    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | 0.0139   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14624    |
|    fps              | 39       |
|    time_elapsed     | 7444     |
|    total_timesteps  | 296124   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000341 |
|    n_updates        | 64030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0142   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14628    |
|    fps              | 39       |
|    time_elapsed     | 7444     |
|    total_timesteps  | 296189   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.95e-05 |
|    n_updates        | 64047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.0142   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14632    |
|    fps              | 39       |
|    time_elapsed     | 7445     |
|    total_timesteps  | 296254   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000771 |
|    n_updates        | 64063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00604 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14636    |
|    fps              | 39       |
|    time_elapsed     | 7445     |
|    total_timesteps  | 296318   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000398 |
|    n_updates        | 64079    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00604 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14640    |
|    fps              | 39       |
|    time_elapsed     | 7446     |
|    total_timesteps  | 296384   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00057  |
|    n_updates        | 64095    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | 0.00407  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14644    |
|    fps              | 39       |
|    time_elapsed     | 7446     |
|    total_timesteps  | 296445   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000272 |
|    n_updates        | 64111    |
----------------------------------
Eval num_timesteps=296500, episode_reward=-0.00 +/- 0.24
Episode length: 16.06 +/- 0.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16.1     |
|    mean_reward      | -0.00322 |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 296500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00605  |
|    n_updates        | 64124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.00598 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14648    |
|    fps              | 39       |
|    time_elapsed     | 7451     |
|    total_timesteps  | 296511   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00753  |
|    n_updates        | 64127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.00574 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14652    |
|    fps              | 39       |
|    time_elapsed     | 7451     |
|    total_timesteps  | 296575   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000224 |
|    n_updates        | 64143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | -0.00542 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14656    |
|    fps              | 39       |
|    time_elapsed     | 7452     |
|    total_timesteps  | 296639   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0077   |
|    n_updates        | 64159    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.6     |
|    ep_rew_mean      | 0.00474  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14660    |
|    fps              | 39       |
|    time_elapsed     | 7452     |
|    total_timesteps  | 296699   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000522 |
|    n_updates        | 64174    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00298  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14664    |
|    fps              | 39       |
|    time_elapsed     | 7453     |
|    total_timesteps  | 296807   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00525  |
|    n_updates        | 64201    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00716 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14668    |
|    fps              | 39       |
|    time_elapsed     | 7453     |
|    total_timesteps  | 296872   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.78e-05 |
|    n_updates        | 64217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00288  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14672    |
|    fps              | 39       |
|    time_elapsed     | 7454     |
|    total_timesteps  | 296935   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00396  |
|    n_updates        | 64233    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00292  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14676    |
|    fps              | 39       |
|    time_elapsed     | 7454     |
|    total_timesteps  | 296995   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000426 |
|    n_updates        | 64248    |
----------------------------------
Eval num_timesteps=297000, episode_reward=-0.02 +/- 0.20
Episode length: 16.02 +/- 0.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.023   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 297000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000395 |
|    n_updates        | 64249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | 0.00292  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14680    |
|    fps              | 39       |
|    time_elapsed     | 7459     |
|    total_timesteps  | 297060   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00777  |
|    n_updates        | 64264    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00716 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14684    |
|    fps              | 39       |
|    time_elapsed     | 7459     |
|    total_timesteps  | 297124   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00398  |
|    n_updates        | 64280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0172  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14688    |
|    fps              | 39       |
|    time_elapsed     | 7460     |
|    total_timesteps  | 297247   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000691 |
|    n_updates        | 64311    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0172  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14692    |
|    fps              | 39       |
|    time_elapsed     | 7460     |
|    total_timesteps  | 297311   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000685 |
|    n_updates        | 64327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0169  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14696    |
|    fps              | 39       |
|    time_elapsed     | 7461     |
|    total_timesteps  | 297376   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000687 |
|    n_updates        | 64343    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0169  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14700    |
|    fps              | 39       |
|    time_elapsed     | 7461     |
|    total_timesteps  | 297440   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000566 |
|    n_updates        | 64359    |
----------------------------------
Eval num_timesteps=297500, episode_reward=-0.00 +/- 0.24
Episode length: 15.96 +/- 1.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | -0.0028  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 297500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000398 |
|    n_updates        | 64374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.017   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14704    |
|    fps              | 39       |
|    time_elapsed     | 7465     |
|    total_timesteps  | 297506   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000316 |
|    n_updates        | 64376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.00696 |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14708    |
|    fps              | 39       |
|    time_elapsed     | 7466     |
|    total_timesteps  | 297569   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000637 |
|    n_updates        | 64392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0172  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14712    |
|    fps              | 39       |
|    time_elapsed     | 7466     |
|    total_timesteps  | 297634   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000148 |
|    n_updates        | 64408    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0172  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14716    |
|    fps              | 39       |
|    time_elapsed     | 7467     |
|    total_timesteps  | 297698   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000805 |
|    n_updates        | 64424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0173  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14720    |
|    fps              | 39       |
|    time_elapsed     | 7467     |
|    total_timesteps  | 297767   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000435 |
|    n_updates        | 64441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0173  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14724    |
|    fps              | 39       |
|    time_elapsed     | 7468     |
|    total_timesteps  | 297832   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000611 |
|    n_updates        | 64457    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0173  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14728    |
|    fps              | 39       |
|    time_elapsed     | 7468     |
|    total_timesteps  | 297896   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00448  |
|    n_updates        | 64473    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0173  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14732    |
|    fps              | 39       |
|    time_elapsed     | 7469     |
|    total_timesteps  | 297962   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.43e-05 |
|    n_updates        | 64490    |
----------------------------------
Eval num_timesteps=298000, episode_reward=0.02 +/- 0.28
Episode length: 15.86 +/- 1.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.9     |
|    mean_reward      | 0.0176   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 298000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 6.14e-05 |
|    n_updates        | 64499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0174  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14736    |
|    fps              | 39       |
|    time_elapsed     | 7473     |
|    total_timesteps  | 298027   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000222 |
|    n_updates        | 64506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0173  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14740    |
|    fps              | 39       |
|    time_elapsed     | 7474     |
|    total_timesteps  | 298092   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000184 |
|    n_updates        | 64522    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.2     |
|    ep_rew_mean      | -0.0276  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14744    |
|    fps              | 39       |
|    time_elapsed     | 7474     |
|    total_timesteps  | 298161   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000493 |
|    n_updates        | 64540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0276  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14748    |
|    fps              | 39       |
|    time_elapsed     | 7475     |
|    total_timesteps  | 298225   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 8.34e-05 |
|    n_updates        | 64556    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0276  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14752    |
|    fps              | 39       |
|    time_elapsed     | 7475     |
|    total_timesteps  | 298289   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000547 |
|    n_updates        | 64572    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.1     |
|    ep_rew_mean      | -0.0276  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14756    |
|    fps              | 39       |
|    time_elapsed     | 7475     |
|    total_timesteps  | 298353   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000304 |
|    n_updates        | 64588    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0282  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14760    |
|    fps              | 39       |
|    time_elapsed     | 7476     |
|    total_timesteps  | 298429   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000514 |
|    n_updates        | 64607    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.9     |
|    ep_rew_mean      | -0.0265  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14764    |
|    fps              | 39       |
|    time_elapsed     | 7476     |
|    total_timesteps  | 298494   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000752 |
|    n_updates        | 64623    |
----------------------------------
Eval num_timesteps=298500, episode_reward=0.06 +/- 0.33
Episode length: 15.98 +/- 1.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 16       |
|    mean_reward      | 0.0572   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 298500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000177 |
|    n_updates        | 64624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0282  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14768    |
|    fps              | 39       |
|    time_elapsed     | 7481     |
|    total_timesteps  | 298603   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00037  |
|    n_updates        | 64650    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0281  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14772    |
|    fps              | 39       |
|    time_elapsed     | 7481     |
|    total_timesteps  | 298664   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000499 |
|    n_updates        | 64665    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0383  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14776    |
|    fps              | 39       |
|    time_elapsed     | 7482     |
|    total_timesteps  | 298729   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000217 |
|    n_updates        | 64682    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0383  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14780    |
|    fps              | 39       |
|    time_elapsed     | 7482     |
|    total_timesteps  | 298793   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00428  |
|    n_updates        | 64698    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17.3     |
|    ep_rew_mean      | -0.0383  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14784    |
|    fps              | 39       |
|    time_elapsed     | 7483     |
|    total_timesteps  | 298857   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00529  |
|    n_updates        | 64714    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14788    |
|    fps              | 39       |
|    time_elapsed     | 7483     |
|    total_timesteps  | 298922   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.41e-05 |
|    n_updates        | 64730    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14792    |
|    fps              | 39       |
|    time_elapsed     | 7484     |
|    total_timesteps  | 298987   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0118   |
|    n_updates        | 64746    |
----------------------------------
Eval num_timesteps=299000, episode_reward=0.02 +/- 0.28
Episode length: 15.80 +/- 1.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 15.8     |
|    mean_reward      | 0.0179   |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 299000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000304 |
|    n_updates        | 64749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14796    |
|    fps              | 39       |
|    time_elapsed     | 7488     |
|    total_timesteps  | 299051   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000723 |
|    n_updates        | 64762    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14800    |
|    fps              | 39       |
|    time_elapsed     | 7488     |
|    total_timesteps  | 299117   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.3e-05  |
|    n_updates        | 64779    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.036   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14804    |
|    fps              | 39       |
|    time_elapsed     | 7489     |
|    total_timesteps  | 299181   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 7.36e-05 |
|    n_updates        | 64795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.046   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14808    |
|    fps              | 39       |
|    time_elapsed     | 7489     |
|    total_timesteps  | 299245   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000297 |
|    n_updates        | 64811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.046   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14812    |
|    fps              | 39       |
|    time_elapsed     | 7490     |
|    total_timesteps  | 299309   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000226 |
|    n_updates        | 64827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0359  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14816    |
|    fps              | 39       |
|    time_elapsed     | 7490     |
|    total_timesteps  | 299371   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000218 |
|    n_updates        | 64842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0357  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14820    |
|    fps              | 39       |
|    time_elapsed     | 7490     |
|    total_timesteps  | 299435   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000286 |
|    n_updates        | 64858    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0357  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14824    |
|    fps              | 39       |
|    time_elapsed     | 7491     |
|    total_timesteps  | 299499   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000194 |
|    n_updates        | 64874    |
----------------------------------
Eval num_timesteps=299500, episode_reward=0.10 +/- 0.37
Episode length: 16.10 +/- 4.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 16.1     |
|    mean_reward     | 0.0967   |
| time/              |          |
|    total_timesteps | 299500   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0357  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14828    |
|    fps              | 39       |
|    time_elapsed     | 7495     |
|    total_timesteps  | 299563   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 5.32e-05 |
|    n_updates        | 64890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0256  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14832    |
|    fps              | 39       |
|    time_elapsed     | 7496     |
|    total_timesteps  | 299628   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000693 |
|    n_updates        | 64906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.7     |
|    ep_rew_mean      | -0.0256  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14836    |
|    fps              | 39       |
|    time_elapsed     | 7496     |
|    total_timesteps  | 299693   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000384 |
|    n_updates        | 64923    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.0271  |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14840    |
|    fps              | 39       |
|    time_elapsed     | 7497     |
|    total_timesteps  | 299796   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000609 |
|    n_updates        | 64948    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14844    |
|    fps              | 39       |
|    time_elapsed     | 7497     |
|    total_timesteps  | 299861   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000227 |
|    n_updates        | 64965    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14848    |
|    fps              | 39       |
|    time_elapsed     | 7498     |
|    total_timesteps  | 299926   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000303 |
|    n_updates        | 64981    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 17       |
|    ep_rew_mean      | -0.027   |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 14852    |
|    fps              | 40       |
|    time_elapsed     | 7498     |
|    total_timesteps  | 299990   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.08e-05 |
|    n_updates        | 64997    |
----------------------------------
Eval num_timesteps=300000, episode_reward=-0.03 +/- 0.20
Episode length: 17.04 +/- 5.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 17       |
|    mean_reward      | -0.0271  |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 300000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000331 |
|    n_updates        | 64999    |
----------------------------------
/mnt/c/Proyecto/.venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'trains/predict-position/dqn-3/saves' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
/mnt/c/Proyecto/.venv/lib/python3.10/site-packages/vizdoom/gymnasium_wrapper/base_gymnasium_env.py:84: UserWarning: Detected screen format CRCGCB. Only RGB24 and GRAY8 are supported in the Gymnasium wrapper. Forcing RGB24.
  warnings.warn(
Parameters: {'batch_size': 64, 'learning_rate': 1e-05, 'buffer_size': 15000, 'gamma': 0.957, 'exploration_fraction': 0.4, 'exploration_final_eps': 0.001, 'learning_starts': 40000.0, 'decay_start_steps': 40000.0, 'decay_end_steps': 200000.0}
Training steps: 300000
Frame skip: 4
Using cuda device
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.8     |
|    ep_rew_mean      | 379      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 4        |
|    fps              | 1213     |
|    time_elapsed     | 0        |
|    total_timesteps  | 379      |
----------------------------------
Eval num_timesteps=500, episode_reward=168.24 +/- 44.38
Episode length: 42.46 +/- 11.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.5     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 500      |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.4     |
|    ep_rew_mean      | 376      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 8        |
|    fps              | 151      |
|    time_elapsed     | 4        |
|    total_timesteps  | 755      |
----------------------------------
Eval num_timesteps=1000, episode_reward=177.78 +/- 45.45
Episode length: 44.76 +/- 11.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 1000     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.8     |
|    ep_rew_mean      | 378      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 12       |
|    fps              | 115      |
|    time_elapsed     | 9        |
|    total_timesteps  | 1138     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.1     |
|    ep_rew_mean      | 339      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 16       |
|    fps              | 134      |
|    time_elapsed     | 10       |
|    total_timesteps  | 1361     |
----------------------------------
Eval num_timesteps=1500, episode_reward=180.46 +/- 48.11
Episode length: 45.52 +/- 12.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.5     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 1500     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.5     |
|    ep_rew_mean      | 337      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 20       |
|    fps              | 111      |
|    time_elapsed     | 15       |
|    total_timesteps  | 1691     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79       |
|    ep_rew_mean      | 315      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 24       |
|    fps              | 123      |
|    time_elapsed     | 15       |
|    total_timesteps  | 1896     |
----------------------------------
Eval num_timesteps=2000, episode_reward=179.14 +/- 39.08
Episode length: 45.20 +/- 9.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 2000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.6     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 28       |
|    fps              | 109      |
|    time_elapsed     | 20       |
|    total_timesteps  | 2229     |
----------------------------------
Eval num_timesteps=2500, episode_reward=169.84 +/- 42.95
Episode length: 42.86 +/- 10.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 2500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.4     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 32       |
|    fps              | 101      |
|    time_elapsed     | 24       |
|    total_timesteps  | 2510     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.6     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 36       |
|    fps              | 110      |
|    time_elapsed     | 25       |
|    total_timesteps  | 2758     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 40       |
|    fps              | 117      |
|    time_elapsed     | 25       |
|    total_timesteps  | 2957     |
----------------------------------
Eval num_timesteps=3000, episode_reward=172.86 +/- 58.39
Episode length: 43.56 +/- 14.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 3000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 44       |
|    fps              | 107      |
|    time_elapsed     | 29       |
|    total_timesteps  | 3194     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.9     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 48       |
|    fps              | 113      |
|    time_elapsed     | 30       |
|    total_timesteps  | 3401     |
----------------------------------
Eval num_timesteps=3500, episode_reward=182.02 +/- 55.45
Episode length: 45.92 +/- 13.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 3500     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.1     |
|    ep_rew_mean      | 275      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 52       |
|    fps              | 103      |
|    time_elapsed     | 34       |
|    total_timesteps  | 3595     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.7     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 56       |
|    fps              | 112      |
|    time_elapsed     | 35       |
|    total_timesteps  | 3960     |
----------------------------------
Eval num_timesteps=4000, episode_reward=164.08 +/- 44.71
Episode length: 41.38 +/- 11.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.4     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 4000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.7     |
|    ep_rew_mean      | 281      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 60       |
|    fps              | 106      |
|    time_elapsed     | 39       |
|    total_timesteps  | 4241     |
----------------------------------
Eval num_timesteps=4500, episode_reward=172.78 +/- 47.40
Episode length: 43.48 +/- 11.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.5     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 4500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 64       |
|    fps              | 102      |
|    time_elapsed     | 44       |
|    total_timesteps  | 4551     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 68       |
|    fps              | 107      |
|    time_elapsed     | 44       |
|    total_timesteps  | 4813     |
----------------------------------
Eval num_timesteps=5000, episode_reward=174.86 +/- 46.51
Episode length: 44.12 +/- 11.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 5000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 72       |
|    fps              | 104      |
|    time_elapsed     | 49       |
|    total_timesteps  | 5154     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | 287      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 76       |
|    fps              | 110      |
|    time_elapsed     | 49       |
|    total_timesteps  | 5473     |
----------------------------------
Eval num_timesteps=5500, episode_reward=166.40 +/- 46.25
Episode length: 42.00 +/- 11.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42       |
|    mean_reward      | 166      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 5500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 287      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 80       |
|    fps              | 106      |
|    time_elapsed     | 54       |
|    total_timesteps  | 5779     |
----------------------------------
Eval num_timesteps=6000, episode_reward=175.40 +/- 45.51
Episode length: 44.24 +/- 11.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 6000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | 286      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 84       |
|    fps              | 100      |
|    time_elapsed     | 59       |
|    total_timesteps  | 6046     |
----------------------------------
Eval num_timesteps=6500, episode_reward=161.14 +/- 39.90
Episode length: 40.60 +/- 9.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.6     |
|    mean_reward      | 161      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 6500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 88       |
|    fps              | 100      |
|    time_elapsed     | 64       |
|    total_timesteps  | 6500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 92       |
|    fps              | 104      |
|    time_elapsed     | 64       |
|    total_timesteps  | 6754     |
----------------------------------
Eval num_timesteps=7000, episode_reward=166.42 +/- 42.64
Episode length: 41.94 +/- 10.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.9     |
|    mean_reward      | 166      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 7000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 96       |
|    fps              | 101      |
|    time_elapsed     | 69       |
|    total_timesteps  | 7067     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 100      |
|    fps              | 106      |
|    time_elapsed     | 69       |
|    total_timesteps  | 7444     |
----------------------------------
Eval num_timesteps=7500, episode_reward=179.62 +/- 54.77
Episode length: 45.30 +/- 13.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 7500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 104      |
|    fps              | 103      |
|    time_elapsed     | 74       |
|    total_timesteps  | 7697     |
----------------------------------
Eval num_timesteps=8000, episode_reward=179.80 +/- 53.75
Episode length: 45.30 +/- 13.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 8000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 108      |
|    fps              | 101      |
|    time_elapsed     | 79       |
|    total_timesteps  | 8083     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 286      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 112      |
|    fps              | 104      |
|    time_elapsed     | 79       |
|    total_timesteps  | 8331     |
----------------------------------
Eval num_timesteps=8500, episode_reward=174.58 +/- 44.83
Episode length: 43.98 +/- 11.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44       |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 8500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 116      |
|    fps              | 102      |
|    time_elapsed     | 84       |
|    total_timesteps  | 8619     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 120      |
|    fps              | 106      |
|    time_elapsed     | 84       |
|    total_timesteps  | 8976     |
----------------------------------
Eval num_timesteps=9000, episode_reward=164.94 +/- 41.24
Episode length: 41.60 +/- 10.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.6     |
|    mean_reward      | 165      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 9000     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 124      |
|    fps              | 103      |
|    time_elapsed     | 88       |
|    total_timesteps  | 9160     |
----------------------------------
Eval num_timesteps=9500, episode_reward=169.10 +/- 38.64
Episode length: 42.60 +/- 9.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 9500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 128      |
|    fps              | 102      |
|    time_elapsed     | 93       |
|    total_timesteps  | 9600     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 132      |
|    fps              | 105      |
|    time_elapsed     | 93       |
|    total_timesteps  | 9843     |
----------------------------------
Eval num_timesteps=10000, episode_reward=162.76 +/- 45.48
Episode length: 41.04 +/- 11.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41       |
|    mean_reward      | 163      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 10000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 136      |
|    fps              | 102      |
|    time_elapsed     | 98       |
|    total_timesteps  | 10048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 140      |
|    fps              | 104      |
|    time_elapsed     | 98       |
|    total_timesteps  | 10240    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 144      |
|    fps              | 106      |
|    time_elapsed     | 98       |
|    total_timesteps  | 10463    |
----------------------------------
Eval num_timesteps=10500, episode_reward=177.78 +/- 49.39
Episode length: 44.78 +/- 12.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 10500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 148      |
|    fps              | 105      |
|    time_elapsed     | 103      |
|    total_timesteps  | 10867    |
----------------------------------
Eval num_timesteps=11000, episode_reward=168.48 +/- 45.96
Episode length: 42.48 +/- 11.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.5     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 11000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.2     |
|    ep_rew_mean      | 299      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 152      |
|    fps              | 103      |
|    time_elapsed     | 107      |
|    total_timesteps  | 11114    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 294      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 156      |
|    fps              | 105      |
|    time_elapsed     | 108      |
|    total_timesteps  | 11356    |
----------------------------------
Eval num_timesteps=11500, episode_reward=184.64 +/- 44.03
Episode length: 46.56 +/- 11.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.6     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 11500    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 160      |
|    fps              | 102      |
|    time_elapsed     | 113      |
|    total_timesteps  | 11617    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 164      |
|    fps              | 105      |
|    time_elapsed     | 113      |
|    total_timesteps  | 11917    |
----------------------------------
Eval num_timesteps=12000, episode_reward=168.78 +/- 41.01
Episode length: 42.64 +/- 10.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 12000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 295      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 168      |
|    fps              | 103      |
|    time_elapsed     | 117      |
|    total_timesteps  | 12218    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 172      |
|    fps              | 105      |
|    time_elapsed     | 118      |
|    total_timesteps  | 12427    |
----------------------------------
Eval num_timesteps=12500, episode_reward=185.90 +/- 50.69
Episode length: 46.84 +/- 12.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.8     |
|    mean_reward      | 186      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 12500    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 176      |
|    fps              | 102      |
|    time_elapsed     | 123      |
|    total_timesteps  | 12704    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 286      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 180      |
|    fps              | 104      |
|    time_elapsed     | 123      |
|    total_timesteps  | 12967    |
----------------------------------
Eval num_timesteps=13000, episode_reward=177.88 +/- 40.53
Episode length: 44.78 +/- 10.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 13000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 184      |
|    fps              | 103      |
|    time_elapsed     | 128      |
|    total_timesteps  | 13312    |
----------------------------------
Eval num_timesteps=13500, episode_reward=166.00 +/- 39.42
Episode length: 41.86 +/- 9.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.9     |
|    mean_reward      | 166      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 13500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 188      |
|    fps              | 102      |
|    time_elapsed     | 133      |
|    total_timesteps  | 13645    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 192      |
|    fps              | 104      |
|    time_elapsed     | 133      |
|    total_timesteps  | 13901    |
----------------------------------
Eval num_timesteps=14000, episode_reward=174.74 +/- 63.85
Episode length: 44.10 +/- 15.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 14000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.4     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 196      |
|    fps              | 102      |
|    time_elapsed     | 138      |
|    total_timesteps  | 14204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.4     |
|    ep_rew_mean      | 280      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 200      |
|    fps              | 104      |
|    time_elapsed     | 138      |
|    total_timesteps  | 14483    |
----------------------------------
Eval num_timesteps=14500, episode_reward=169.70 +/- 41.97
Episode length: 42.78 +/- 10.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 14500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71       |
|    ep_rew_mean      | 282      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 204      |
|    fps              | 103      |
|    time_elapsed     | 143      |
|    total_timesteps  | 14800    |
----------------------------------
Eval num_timesteps=15000, episode_reward=169.68 +/- 38.74
Episode length: 42.84 +/- 9.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 15000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | 275      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 208      |
|    fps              | 101      |
|    time_elapsed     | 148      |
|    total_timesteps  | 15002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.7     |
|    ep_rew_mean      | 277      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 212      |
|    fps              | 103      |
|    time_elapsed     | 148      |
|    total_timesteps  | 15299    |
----------------------------------
Eval num_timesteps=15500, episode_reward=187.98 +/- 52.73
Episode length: 47.42 +/- 13.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.4     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 15500    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 216      |
|    fps              | 101      |
|    time_elapsed     | 153      |
|    total_timesteps  | 15631    |
----------------------------------
Eval num_timesteps=16000, episode_reward=181.34 +/- 48.53
Episode length: 45.74 +/- 12.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.7     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 16000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 220      |
|    fps              | 100      |
|    time_elapsed     | 158      |
|    total_timesteps  | 16001    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 224      |
|    fps              | 102      |
|    time_elapsed     | 158      |
|    total_timesteps  | 16311    |
----------------------------------
Eval num_timesteps=16500, episode_reward=169.36 +/- 41.22
Episode length: 42.76 +/- 10.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 16500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 228      |
|    fps              | 101      |
|    time_elapsed     | 163      |
|    total_timesteps  | 16616    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 232      |
|    fps              | 103      |
|    time_elapsed     | 163      |
|    total_timesteps  | 16958    |
----------------------------------
Eval num_timesteps=17000, episode_reward=169.62 +/- 49.00
Episode length: 42.78 +/- 12.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 17000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 290      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 236      |
|    fps              | 102      |
|    time_elapsed     | 168      |
|    total_timesteps  | 17348    |
----------------------------------
Eval num_timesteps=17500, episode_reward=186.16 +/- 47.51
Episode length: 46.92 +/- 11.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.9     |
|    mean_reward      | 186      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 17500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 240      |
|    fps              | 101      |
|    time_elapsed     | 173      |
|    total_timesteps  | 17566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.9     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 244      |
|    fps              | 103      |
|    time_elapsed     | 173      |
|    total_timesteps  | 17949    |
----------------------------------
Eval num_timesteps=18000, episode_reward=169.88 +/- 44.98
Episode length: 42.88 +/- 11.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 18000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 248      |
|    fps              | 102      |
|    time_elapsed     | 178      |
|    total_timesteps  | 18213    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 252      |
|    fps              | 103      |
|    time_elapsed     | 178      |
|    total_timesteps  | 18456    |
----------------------------------
Eval num_timesteps=18500, episode_reward=163.96 +/- 39.27
Episode length: 41.36 +/- 9.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.4     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 18500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 256      |
|    fps              | 102      |
|    time_elapsed     | 182      |
|    total_timesteps  | 18674    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 260      |
|    fps              | 103      |
|    time_elapsed     | 183      |
|    total_timesteps  | 18975    |
----------------------------------
Eval num_timesteps=19000, episode_reward=171.44 +/- 42.06
Episode length: 43.18 +/- 10.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.2     |
|    mean_reward      | 171      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 19000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 264      |
|    fps              | 101      |
|    time_elapsed     | 187      |
|    total_timesteps  | 19162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 268      |
|    fps              | 103      |
|    time_elapsed     | 188      |
|    total_timesteps  | 19477    |
----------------------------------
Eval num_timesteps=19500, episode_reward=172.18 +/- 43.27
Episode length: 43.50 +/- 10.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.5     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 19500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 272      |
|    fps              | 101      |
|    time_elapsed     | 192      |
|    total_timesteps  | 19676    |
----------------------------------
Eval num_timesteps=20000, episode_reward=179.08 +/- 45.83
Episode length: 45.16 +/- 11.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 20000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 276      |
|    fps              | 101      |
|    time_elapsed     | 197      |
|    total_timesteps  | 20053    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 280      |
|    fps              | 102      |
|    time_elapsed     | 197      |
|    total_timesteps  | 20224    |
----------------------------------
Eval num_timesteps=20500, episode_reward=197.16 +/- 57.15
Episode length: 49.64 +/- 14.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.6     |
|    mean_reward      | 197      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 20500    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.4     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 284      |
|    fps              | 101      |
|    time_elapsed     | 203      |
|    total_timesteps  | 20552    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 288      |
|    fps              | 102      |
|    time_elapsed     | 203      |
|    total_timesteps  | 20757    |
----------------------------------
Eval num_timesteps=21000, episode_reward=179.00 +/- 42.72
Episode length: 45.16 +/- 10.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 21000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.4     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 292      |
|    fps              | 101      |
|    time_elapsed     | 208      |
|    total_timesteps  | 21041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | 280      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 296      |
|    fps              | 101      |
|    time_elapsed     | 208      |
|    total_timesteps  | 21249    |
----------------------------------
Eval num_timesteps=21500, episode_reward=169.96 +/- 38.39
Episode length: 42.84 +/- 9.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 21500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 300      |
|    fps              | 100      |
|    time_elapsed     | 212      |
|    total_timesteps  | 21500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.3     |
|    ep_rew_mean      | 280      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 304      |
|    fps              | 102      |
|    time_elapsed     | 213      |
|    total_timesteps  | 21833    |
----------------------------------
Eval num_timesteps=22000, episode_reward=172.00 +/- 47.26
Episode length: 43.36 +/- 11.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.4     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 22000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 308      |
|    fps              | 101      |
|    time_elapsed     | 217      |
|    total_timesteps  | 22112    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | 278      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 312      |
|    fps              | 102      |
|    time_elapsed     | 217      |
|    total_timesteps  | 22282    |
----------------------------------
Eval num_timesteps=22500, episode_reward=169.10 +/- 43.05
Episode length: 42.60 +/- 10.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 22500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.3     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 316      |
|    fps              | 101      |
|    time_elapsed     | 222      |
|    total_timesteps  | 22657    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | 278      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 320      |
|    fps              | 103      |
|    time_elapsed     | 222      |
|    total_timesteps  | 22997    |
----------------------------------
Eval num_timesteps=23000, episode_reward=178.48 +/- 49.26
Episode length: 45.00 +/- 12.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 23000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | 278      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 324      |
|    fps              | 102      |
|    time_elapsed     | 227      |
|    total_timesteps  | 23296    |
----------------------------------
Eval num_timesteps=23500, episode_reward=169.46 +/- 49.01
Episode length: 42.76 +/- 12.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 23500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.4     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 328      |
|    fps              | 102      |
|    time_elapsed     | 232      |
|    total_timesteps  | 23752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.4     |
|    ep_rew_mean      | 280      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 332      |
|    fps              | 103      |
|    time_elapsed     | 232      |
|    total_timesteps  | 23998    |
----------------------------------
Eval num_timesteps=24000, episode_reward=184.16 +/- 45.95
Episode length: 46.42 +/- 11.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.4     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 24000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | 274      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 336      |
|    fps              | 102      |
|    time_elapsed     | 237      |
|    total_timesteps  | 24231    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69       |
|    ep_rew_mean      | 274      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 340      |
|    fps              | 102      |
|    time_elapsed     | 237      |
|    total_timesteps  | 24469    |
----------------------------------
Eval num_timesteps=24500, episode_reward=163.64 +/- 42.52
Episode length: 41.32 +/- 10.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.3     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 24500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 344      |
|    fps              | 101      |
|    time_elapsed     | 241      |
|    total_timesteps  | 24589    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 348      |
|    fps              | 102      |
|    time_elapsed     | 242      |
|    total_timesteps  | 24845    |
----------------------------------
Eval num_timesteps=25000, episode_reward=163.90 +/- 32.28
Episode length: 41.36 +/- 8.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.4     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 25000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.5     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 352      |
|    fps              | 101      |
|    time_elapsed     | 246      |
|    total_timesteps  | 25103    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.2     |
|    ep_rew_mean      | 267      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 356      |
|    fps              | 102      |
|    time_elapsed     | 246      |
|    total_timesteps  | 25399    |
----------------------------------
Eval num_timesteps=25500, episode_reward=175.64 +/- 47.92
Episode length: 44.26 +/- 11.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.3     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 25500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.5     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 360      |
|    fps              | 102      |
|    time_elapsed     | 251      |
|    total_timesteps  | 25820    |
----------------------------------
Eval num_timesteps=26000, episode_reward=172.04 +/- 34.84
Episode length: 43.44 +/- 8.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.4     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 26000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69       |
|    ep_rew_mean      | 274      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 364      |
|    fps              | 101      |
|    time_elapsed     | 256      |
|    total_timesteps  | 26066    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.3     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 368      |
|    fps              | 102      |
|    time_elapsed     | 256      |
|    total_timesteps  | 26311    |
----------------------------------
Eval num_timesteps=26500, episode_reward=170.18 +/- 41.31
Episode length: 42.88 +/- 10.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 26500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 372      |
|    fps              | 102      |
|    time_elapsed     | 260      |
|    total_timesteps  | 26689    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.5     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 376      |
|    fps              | 103      |
|    time_elapsed     | 261      |
|    total_timesteps  | 26903    |
----------------------------------
Eval num_timesteps=27000, episode_reward=180.50 +/- 41.20
Episode length: 45.46 +/- 10.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.5     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 27000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.7     |
|    ep_rew_mean      | 273      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 380      |
|    fps              | 101      |
|    time_elapsed     | 265      |
|    total_timesteps  | 27097    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | 269      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 384      |
|    fps              | 102      |
|    time_elapsed     | 266      |
|    total_timesteps  | 27331    |
----------------------------------
Eval num_timesteps=27500, episode_reward=170.16 +/- 43.94
Episode length: 42.84 +/- 10.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 27500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.9     |
|    ep_rew_mean      | 274      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 388      |
|    fps              | 102      |
|    time_elapsed     | 270      |
|    total_timesteps  | 27643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.5     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 392      |
|    fps              | 103      |
|    time_elapsed     | 270      |
|    total_timesteps  | 27889    |
----------------------------------
Eval num_timesteps=28000, episode_reward=176.06 +/- 51.28
Episode length: 44.38 +/- 12.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 28000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.4     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 396      |
|    fps              | 101      |
|    time_elapsed     | 275      |
|    total_timesteps  | 28093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.5     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 400      |
|    fps              | 102      |
|    time_elapsed     | 275      |
|    total_timesteps  | 28347    |
----------------------------------
Eval num_timesteps=28500, episode_reward=184.16 +/- 52.79
Episode length: 46.40 +/- 13.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.4     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 28500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 266      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 404      |
|    fps              | 101      |
|    time_elapsed     | 280      |
|    total_timesteps  | 28521    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 408      |
|    fps              | 102      |
|    time_elapsed     | 280      |
|    total_timesteps  | 28679    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | 266      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 412      |
|    fps              | 103      |
|    time_elapsed     | 280      |
|    total_timesteps  | 28983    |
----------------------------------
Eval num_timesteps=29000, episode_reward=177.86 +/- 53.05
Episode length: 44.84 +/- 13.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 29000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.9     |
|    ep_rew_mean      | 258      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 416      |
|    fps              | 102      |
|    time_elapsed     | 285      |
|    total_timesteps  | 29143    |
----------------------------------
Eval num_timesteps=29500, episode_reward=175.38 +/- 49.44
Episode length: 44.24 +/- 12.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 29500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.4     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 420      |
|    fps              | 101      |
|    time_elapsed     | 290      |
|    total_timesteps  | 29540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | 262      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 424      |
|    fps              | 102      |
|    time_elapsed     | 290      |
|    total_timesteps  | 29896    |
----------------------------------
Eval num_timesteps=30000, episode_reward=176.22 +/- 47.42
Episode length: 44.36 +/- 11.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 30000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.2     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 428      |
|    fps              | 102      |
|    time_elapsed     | 294      |
|    total_timesteps  | 30173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.7     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 432      |
|    fps              | 103      |
|    time_elapsed     | 295      |
|    total_timesteps  | 30470    |
----------------------------------
Eval num_timesteps=30500, episode_reward=165.72 +/- 43.95
Episode length: 41.82 +/- 10.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.8     |
|    mean_reward      | 166      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 30500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 436      |
|    fps              | 102      |
|    time_elapsed     | 299      |
|    total_timesteps  | 30783    |
----------------------------------
Eval num_timesteps=31000, episode_reward=175.32 +/- 49.87
Episode length: 44.16 +/- 12.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 31000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 440      |
|    fps              | 102      |
|    time_elapsed     | 304      |
|    total_timesteps  | 31029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.7     |
|    ep_rew_mean      | 269      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 444      |
|    fps              | 103      |
|    time_elapsed     | 304      |
|    total_timesteps  | 31360    |
----------------------------------
Eval num_timesteps=31500, episode_reward=178.70 +/- 46.59
Episode length: 45.04 +/- 11.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 31500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | 270      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 448      |
|    fps              | 102      |
|    time_elapsed     | 309      |
|    total_timesteps  | 31627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 452      |
|    fps              | 102      |
|    time_elapsed     | 309      |
|    total_timesteps  | 31839    |
----------------------------------
Eval num_timesteps=32000, episode_reward=175.92 +/- 47.05
Episode length: 44.38 +/- 11.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 32000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | 265      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 456      |
|    fps              | 102      |
|    time_elapsed     | 313      |
|    total_timesteps  | 32062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 258      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 460      |
|    fps              | 102      |
|    time_elapsed     | 314      |
|    total_timesteps  | 32301    |
----------------------------------
Eval num_timesteps=32500, episode_reward=180.98 +/- 51.75
Episode length: 45.60 +/- 12.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 32500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.9     |
|    ep_rew_mean      | 258      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 464      |
|    fps              | 102      |
|    time_elapsed     | 318      |
|    total_timesteps  | 32552    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.9     |
|    ep_rew_mean      | 258      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 468      |
|    fps              | 102      |
|    time_elapsed     | 318      |
|    total_timesteps  | 32798    |
----------------------------------
Eval num_timesteps=33000, episode_reward=185.30 +/- 47.36
Episode length: 46.60 +/- 11.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.6     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 33000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.4     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 472      |
|    fps              | 102      |
|    time_elapsed     | 323      |
|    total_timesteps  | 33025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.6     |
|    ep_rew_mean      | 253      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 476      |
|    fps              | 102      |
|    time_elapsed     | 323      |
|    total_timesteps  | 33262    |
----------------------------------
Eval num_timesteps=33500, episode_reward=170.16 +/- 41.92
Episode length: 42.94 +/- 10.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 33500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 480      |
|    fps              | 101      |
|    time_elapsed     | 329      |
|    total_timesteps  | 33504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.3     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 484      |
|    fps              | 102      |
|    time_elapsed     | 329      |
|    total_timesteps  | 33866    |
----------------------------------
Eval num_timesteps=34000, episode_reward=168.74 +/- 40.16
Episode length: 42.54 +/- 10.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.5     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 34000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.9     |
|    ep_rew_mean      | 258      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 488      |
|    fps              | 102      |
|    time_elapsed     | 334      |
|    total_timesteps  | 34129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.2     |
|    ep_rew_mean      | 259      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 492      |
|    fps              | 102      |
|    time_elapsed     | 334      |
|    total_timesteps  | 34404    |
----------------------------------
Eval num_timesteps=34500, episode_reward=168.24 +/- 38.57
Episode length: 42.44 +/- 9.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.4     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 34500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | 274      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 496      |
|    fps              | 103      |
|    time_elapsed     | 338      |
|    total_timesteps  | 34969    |
----------------------------------
Eval num_timesteps=35000, episode_reward=172.88 +/- 45.21
Episode length: 43.52 +/- 11.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.5     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 35000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.4     |
|    ep_rew_mean      | 276      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 500      |
|    fps              | 102      |
|    time_elapsed     | 343      |
|    total_timesteps  | 35290    |
----------------------------------
Eval num_timesteps=35500, episode_reward=173.04 +/- 44.61
Episode length: 43.62 +/- 11.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 35500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.7     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 504      |
|    fps              | 102      |
|    time_elapsed     | 347      |
|    total_timesteps  | 35692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.4     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 508      |
|    fps              | 103      |
|    time_elapsed     | 348      |
|    total_timesteps  | 35917    |
----------------------------------
Eval num_timesteps=36000, episode_reward=174.36 +/- 49.97
Episode length: 44.00 +/- 12.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44       |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 36000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 512      |
|    fps              | 102      |
|    time_elapsed     | 352      |
|    total_timesteps  | 36304    |
----------------------------------
Eval num_timesteps=36500, episode_reward=177.30 +/- 49.84
Episode length: 44.70 +/- 12.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.7     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 36500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 516      |
|    fps              | 102      |
|    time_elapsed     | 357      |
|    total_timesteps  | 36579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 520      |
|    fps              | 103      |
|    time_elapsed     | 357      |
|    total_timesteps  | 36903    |
----------------------------------
Eval num_timesteps=37000, episode_reward=193.58 +/- 53.47
Episode length: 48.78 +/- 13.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.8     |
|    mean_reward      | 194      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 37000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 524      |
|    fps              | 102      |
|    time_elapsed     | 362      |
|    total_timesteps  | 37157    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | 286      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 528      |
|    fps              | 102      |
|    time_elapsed     | 362      |
|    total_timesteps  | 37368    |
----------------------------------
Eval num_timesteps=37500, episode_reward=176.60 +/- 35.16
Episode length: 44.52 +/- 8.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.5     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 37500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.4     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 532      |
|    fps              | 102      |
|    time_elapsed     | 367      |
|    total_timesteps  | 37608    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 536      |
|    fps              | 103      |
|    time_elapsed     | 367      |
|    total_timesteps  | 37898    |
----------------------------------
Eval num_timesteps=38000, episode_reward=173.02 +/- 51.50
Episode length: 43.66 +/- 12.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.7     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 38000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.7     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 540      |
|    fps              | 102      |
|    time_elapsed     | 372      |
|    total_timesteps  | 38102    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | 280      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 544      |
|    fps              | 103      |
|    time_elapsed     | 372      |
|    total_timesteps  | 38405    |
----------------------------------
Eval num_timesteps=38500, episode_reward=178.22 +/- 48.64
Episode length: 44.96 +/- 12.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 38500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.4     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 548      |
|    fps              | 102      |
|    time_elapsed     | 377      |
|    total_timesteps  | 38771    |
----------------------------------
Eval num_timesteps=39000, episode_reward=167.22 +/- 44.00
Episode length: 42.16 +/- 10.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.2     |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 39000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | 286      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 552      |
|    fps              | 102      |
|    time_elapsed     | 381      |
|    total_timesteps  | 39037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 556      |
|    fps              | 103      |
|    time_elapsed     | 381      |
|    total_timesteps  | 39443    |
----------------------------------
Eval num_timesteps=39500, episode_reward=180.70 +/- 48.34
Episode length: 45.52 +/- 12.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.5     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 39500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.1     |
|    ep_rew_mean      | 299      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 560      |
|    fps              | 102      |
|    time_elapsed     | 386      |
|    total_timesteps  | 39815    |
----------------------------------
Eval num_timesteps=40000, episode_reward=163.10 +/- 36.40
Episode length: 41.14 +/- 9.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.1     |
|    mean_reward      | 163      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 40000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.9     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 564      |
|    fps              | 102      |
|    time_elapsed     | 391      |
|    total_timesteps  | 40045    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.52     |
|    n_updates        | 11       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 568      |
|    fps              | 103      |
|    time_elapsed     | 392      |
|    total_timesteps  | 40430    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.22     |
|    n_updates        | 107      |
----------------------------------
Eval num_timesteps=40500, episode_reward=159.58 +/- 29.64
Episode length: 40.20 +/- 7.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.2     |
|    mean_reward      | 160      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 40500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.18     |
|    n_updates        | 124      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 1        |
| time/               |          |
|    episodes         | 572      |
|    fps              | 102      |
|    time_elapsed     | 397      |
|    total_timesteps  | 40673    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.47     |
|    n_updates        | 168      |
----------------------------------
Eval num_timesteps=41000, episode_reward=176.70 +/- 44.68
Episode length: 44.52 +/- 11.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.5     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 1        |
| time/               |          |
|    total_timesteps  | 41000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0555   |
|    n_updates        | 249      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.5     |
|    ep_rew_mean      | 308      |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 576      |
|    fps              | 102      |
|    time_elapsed     | 401      |
|    total_timesteps  | 41010    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0679   |
|    n_updates        | 252      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.3     |
|    ep_rew_mean      | 311      |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 580      |
|    fps              | 102      |
|    time_elapsed     | 402      |
|    total_timesteps  | 41330    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00416  |
|    n_updates        | 332      |
----------------------------------
Eval num_timesteps=41500, episode_reward=188.74 +/- 47.56
Episode length: 47.62 +/- 11.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.6     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.999    |
| time/               |          |
|    total_timesteps  | 41500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0416   |
|    n_updates        | 374      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.7     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 584      |
|    fps              | 102      |
|    time_elapsed     | 407      |
|    total_timesteps  | 41634    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00627  |
|    n_updates        | 408      |
----------------------------------
Eval num_timesteps=42000, episode_reward=190.90 +/- 68.18
Episode length: 48.10 +/- 17.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.1     |
|    mean_reward      | 191      |
| rollout/            |          |
|    exploration_rate | 0.999    |
| time/               |          |
|    total_timesteps  | 42000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0772   |
|    n_updates        | 499      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.2     |
|    ep_rew_mean      | 315      |
|    exploration_rate | 0.999    |
| time/               |          |
|    episodes         | 588      |
|    fps              | 102      |
|    time_elapsed     | 412      |
|    total_timesteps  | 42047    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0168   |
|    n_updates        | 511      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.2     |
|    ep_rew_mean      | 315      |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 592      |
|    fps              | 102      |
|    time_elapsed     | 412      |
|    total_timesteps  | 42321    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0829   |
|    n_updates        | 580      |
----------------------------------
Eval num_timesteps=42500, episode_reward=162.78 +/- 54.84
Episode length: 41.02 +/- 13.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41       |
|    mean_reward      | 163      |
| rollout/            |          |
|    exploration_rate | 0.998    |
| time/               |          |
|    total_timesteps  | 42500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00348  |
|    n_updates        | 624      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.4     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 596      |
|    fps              | 102      |
|    time_elapsed     | 416      |
|    total_timesteps  | 42605    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00544  |
|    n_updates        | 651      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.8     |
|    ep_rew_mean      | 306      |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 600      |
|    fps              | 102      |
|    time_elapsed     | 417      |
|    total_timesteps  | 42973    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.085    |
|    n_updates        | 743      |
----------------------------------
Eval num_timesteps=43000, episode_reward=168.24 +/- 60.31
Episode length: 42.40 +/- 15.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.4     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 0.997    |
| time/               |          |
|    total_timesteps  | 43000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0216   |
|    n_updates        | 749      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 604      |
|    fps              | 102      |
|    time_elapsed     | 421      |
|    total_timesteps  | 43327    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0924   |
|    n_updates        | 831      |
----------------------------------
Eval num_timesteps=43500, episode_reward=181.12 +/- 61.31
Episode length: 45.60 +/- 15.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.997    |
| time/               |          |
|    total_timesteps  | 43500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.036    |
|    n_updates        | 874      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 307      |
|    exploration_rate | 0.997    |
| time/               |          |
|    episodes         | 608      |
|    fps              | 102      |
|    time_elapsed     | 426      |
|    total_timesteps  | 43641    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0386   |
|    n_updates        | 910      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 612      |
|    fps              | 102      |
|    time_elapsed     | 426      |
|    total_timesteps  | 43853    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0134   |
|    n_updates        | 963      |
----------------------------------
Eval num_timesteps=44000, episode_reward=180.08 +/- 40.23
Episode length: 45.42 +/- 10.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.996    |
| time/               |          |
|    total_timesteps  | 44000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0205   |
|    n_updates        | 999      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 616      |
|    fps              | 102      |
|    time_elapsed     | 430      |
|    total_timesteps  | 44059    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0284   |
|    n_updates        | 1014     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.996    |
| time/               |          |
|    episodes         | 620      |
|    fps              | 102      |
|    time_elapsed     | 431      |
|    total_timesteps  | 44284    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0142   |
|    n_updates        | 1070     |
----------------------------------
Eval num_timesteps=44500, episode_reward=186.34 +/- 52.36
Episode length: 46.96 +/- 13.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47       |
|    mean_reward      | 186      |
| rollout/            |          |
|    exploration_rate | 0.995    |
| time/               |          |
|    total_timesteps  | 44500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0184   |
|    n_updates        | 1124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 624      |
|    fps              | 102      |
|    time_elapsed     | 435      |
|    total_timesteps  | 44583    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.031    |
|    n_updates        | 1145     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.4     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 628      |
|    fps              | 102      |
|    time_elapsed     | 436      |
|    total_timesteps  | 44906    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0503   |
|    n_updates        | 1226     |
----------------------------------
Eval num_timesteps=45000, episode_reward=174.42 +/- 58.60
Episode length: 43.98 +/- 14.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44       |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.994    |
| time/               |          |
|    total_timesteps  | 45000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00378  |
|    n_updates        | 1249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.9     |
|    ep_rew_mean      | 306      |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 632      |
|    fps              | 102      |
|    time_elapsed     | 440      |
|    total_timesteps  | 45295    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00211  |
|    n_updates        | 1323     |
----------------------------------
Eval num_timesteps=45500, episode_reward=174.78 +/- 48.23
Episode length: 44.04 +/- 12.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44       |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.994    |
| time/               |          |
|    total_timesteps  | 45500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0235   |
|    n_updates        | 1374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.6     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.994    |
| time/               |          |
|    episodes         | 636      |
|    fps              | 102      |
|    time_elapsed     | 444      |
|    total_timesteps  | 45557    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00149  |
|    n_updates        | 1389     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.4     |
|    ep_rew_mean      | 308      |
|    exploration_rate | 0.993    |
| time/               |          |
|    episodes         | 640      |
|    fps              | 102      |
|    time_elapsed     | 445      |
|    total_timesteps  | 45838    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.173    |
|    n_updates        | 1459     |
----------------------------------
Eval num_timesteps=46000, episode_reward=183.02 +/- 68.37
Episode length: 46.16 +/- 17.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.2     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.993    |
| time/               |          |
|    total_timesteps  | 46000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.029    |
|    n_updates        | 1499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.7     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 644      |
|    fps              | 102      |
|    time_elapsed     | 450      |
|    total_timesteps  | 46178    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00137  |
|    n_updates        | 1544     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 648      |
|    fps              | 102      |
|    time_elapsed     | 450      |
|    total_timesteps  | 46396    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.025    |
|    n_updates        | 1598     |
----------------------------------
Eval num_timesteps=46500, episode_reward=188.70 +/- 55.99
Episode length: 47.56 +/- 13.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.6     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.992    |
| time/               |          |
|    total_timesteps  | 46500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0262   |
|    n_updates        | 1624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.7     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 652      |
|    fps              | 102      |
|    time_elapsed     | 455      |
|    total_timesteps  | 46806    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.015    |
|    n_updates        | 1701     |
----------------------------------
Eval num_timesteps=47000, episode_reward=250.30 +/- 87.04
Episode length: 62.90 +/- 21.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.9     |
|    mean_reward      | 250      |
| rollout/            |          |
|    exploration_rate | 0.991    |
| time/               |          |
|    total_timesteps  | 47000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0671   |
|    n_updates        | 1749     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.4     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.991    |
| time/               |          |
|    episodes         | 656      |
|    fps              | 102      |
|    time_elapsed     | 461      |
|    total_timesteps  | 47084    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0422   |
|    n_updates        | 1770     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 660      |
|    fps              | 102      |
|    time_elapsed     | 461      |
|    total_timesteps  | 47363    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00159  |
|    n_updates        | 1840     |
----------------------------------
Eval num_timesteps=47500, episode_reward=257.70 +/- 66.14
Episode length: 64.80 +/- 16.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.8     |
|    mean_reward      | 258      |
| rollout/            |          |
|    exploration_rate | 0.99     |
| time/               |          |
|    total_timesteps  | 47500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00156  |
|    n_updates        | 1874     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.99     |
| time/               |          |
|    episodes         | 664      |
|    fps              | 101      |
|    time_elapsed     | 467      |
|    total_timesteps  | 47618    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0228   |
|    n_updates        | 1904     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 668      |
|    fps              | 102      |
|    time_elapsed     | 468      |
|    total_timesteps  | 47863    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0104   |
|    n_updates        | 1965     |
----------------------------------
Eval num_timesteps=48000, episode_reward=200.34 +/- 69.81
Episode length: 50.46 +/- 17.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.5     |
|    mean_reward      | 200      |
| rollout/            |          |
|    exploration_rate | 0.989    |
| time/               |          |
|    total_timesteps  | 48000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.000912 |
|    n_updates        | 1999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 672      |
|    fps              | 102      |
|    time_elapsed     | 473      |
|    total_timesteps  | 48292    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00132  |
|    n_updates        | 2072     |
----------------------------------
Eval num_timesteps=48500, episode_reward=248.76 +/- 105.71
Episode length: 62.60 +/- 26.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.6     |
|    mean_reward      | 249      |
| rollout/            |          |
|    exploration_rate | 0.988    |
| time/               |          |
|    total_timesteps  | 48500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00198  |
|    n_updates        | 2124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.988    |
| time/               |          |
|    episodes         | 676      |
|    fps              | 101      |
|    time_elapsed     | 478      |
|    total_timesteps  | 48582    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0641   |
|    n_updates        | 2145     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.987    |
| time/               |          |
|    episodes         | 680      |
|    fps              | 102      |
|    time_elapsed     | 479      |
|    total_timesteps  | 48953    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00175  |
|    n_updates        | 2238     |
----------------------------------
Eval num_timesteps=49000, episode_reward=270.42 +/- 91.47
Episode length: 67.98 +/- 22.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68       |
|    mean_reward      | 270      |
| rollout/            |          |
|    exploration_rate | 0.987    |
| time/               |          |
|    total_timesteps  | 49000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00165  |
|    n_updates        | 2249     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 308      |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 684      |
|    fps              | 101      |
|    time_elapsed     | 486      |
|    total_timesteps  | 49364    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0358   |
|    n_updates        | 2340     |
----------------------------------
Eval num_timesteps=49500, episode_reward=174.16 +/- 51.81
Episode length: 43.94 +/- 13.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.986    |
| time/               |          |
|    total_timesteps  | 49500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00112  |
|    n_updates        | 2374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 688      |
|    fps              | 101      |
|    time_elapsed     | 490      |
|    total_timesteps  | 49621    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00214  |
|    n_updates        | 2405     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.6     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.985    |
| time/               |          |
|    episodes         | 692      |
|    fps              | 101      |
|    time_elapsed     | 491      |
|    total_timesteps  | 49879    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00122  |
|    n_updates        | 2469     |
----------------------------------
Eval num_timesteps=50000, episode_reward=183.84 +/- 62.08
Episode length: 46.38 +/- 15.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.4     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.984    |
| time/               |          |
|    total_timesteps  | 50000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0407   |
|    n_updates        | 2499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 696      |
|    fps              | 101      |
|    time_elapsed     | 495      |
|    total_timesteps  | 50069    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.433    |
|    n_updates        | 2517     |
----------------------------------
Eval num_timesteps=50500, episode_reward=191.26 +/- 45.63
Episode length: 48.18 +/- 11.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.2     |
|    mean_reward      | 191      |
| rollout/            |          |
|    exploration_rate | 0.983    |
| time/               |          |
|    total_timesteps  | 50500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.082    |
|    n_updates        | 2624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.4     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.983    |
| time/               |          |
|    episodes         | 700      |
|    fps              | 100      |
|    time_elapsed     | 500      |
|    total_timesteps  | 50513    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0908   |
|    n_updates        | 2628     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.9     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 704      |
|    fps              | 101      |
|    time_elapsed     | 500      |
|    total_timesteps  | 50815    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0536   |
|    n_updates        | 2703     |
----------------------------------
Eval num_timesteps=51000, episode_reward=260.68 +/- 121.40
Episode length: 65.52 +/- 30.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.5     |
|    mean_reward      | 261      |
| rollout/            |          |
|    exploration_rate | 0.982    |
| time/               |          |
|    total_timesteps  | 51000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0605   |
|    n_updates        | 2749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.982    |
| time/               |          |
|    episodes         | 708      |
|    fps              | 100      |
|    time_elapsed     | 506      |
|    total_timesteps  | 51077    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0156   |
|    n_updates        | 2769     |
----------------------------------
Eval num_timesteps=51500, episode_reward=178.42 +/- 46.30
Episode length: 44.98 +/- 11.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.981    |
| time/               |          |
|    total_timesteps  | 51500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00362  |
|    n_updates        | 2874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 712      |
|    fps              | 100      |
|    time_elapsed     | 511      |
|    total_timesteps  | 51524    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.102    |
|    n_updates        | 2880     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.1     |
|    ep_rew_mean      | 307      |
|    exploration_rate | 0.98     |
| time/               |          |
|    episodes         | 716      |
|    fps              | 101      |
|    time_elapsed     | 512      |
|    total_timesteps  | 51770    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0858   |
|    n_updates        | 2942     |
----------------------------------
Eval num_timesteps=52000, episode_reward=250.80 +/- 77.64
Episode length: 63.14 +/- 19.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.1     |
|    mean_reward      | 251      |
| rollout/            |          |
|    exploration_rate | 0.979    |
| time/               |          |
|    total_timesteps  | 52000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0919   |
|    n_updates        | 2999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.7     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.979    |
| time/               |          |
|    episodes         | 720      |
|    fps              | 100      |
|    time_elapsed     | 518      |
|    total_timesteps  | 52153    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.101    |
|    n_updates        | 3038     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79       |
|    ep_rew_mean      | 315      |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 724      |
|    fps              | 101      |
|    time_elapsed     | 519      |
|    total_timesteps  | 52488    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.015    |
|    n_updates        | 3121     |
----------------------------------
Eval num_timesteps=52500, episode_reward=242.74 +/- 55.17
Episode length: 61.14 +/- 13.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.1     |
|    mean_reward      | 243      |
| rollout/            |          |
|    exploration_rate | 0.978    |
| time/               |          |
|    total_timesteps  | 52500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0738   |
|    n_updates        | 3124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 310      |
|    exploration_rate | 0.978    |
| time/               |          |
|    episodes         | 728      |
|    fps              | 100      |
|    time_elapsed     | 524      |
|    total_timesteps  | 52682    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0515   |
|    n_updates        | 3170     |
----------------------------------
Eval num_timesteps=53000, episode_reward=217.66 +/- 70.77
Episode length: 54.80 +/- 17.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.8     |
|    mean_reward      | 218      |
| rollout/            |          |
|    exploration_rate | 0.977    |
| time/               |          |
|    total_timesteps  | 53000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0928   |
|    n_updates        | 3249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 310      |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 732      |
|    fps              | 100      |
|    time_elapsed     | 530      |
|    total_timesteps  | 53082    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.105    |
|    n_updates        | 3270     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 736      |
|    fps              | 100      |
|    time_elapsed     | 530      |
|    total_timesteps  | 53229    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00307  |
|    n_updates        | 3307     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.9     |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.976    |
| time/               |          |
|    episodes         | 740      |
|    fps              | 100      |
|    time_elapsed     | 531      |
|    total_timesteps  | 53431    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00239  |
|    n_updates        | 3357     |
----------------------------------
Eval num_timesteps=53500, episode_reward=185.54 +/- 72.03
Episode length: 46.78 +/- 18.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.8     |
|    mean_reward      | 186      |
| rollout/            |          |
|    exploration_rate | 0.976    |
| time/               |          |
|    total_timesteps  | 53500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00289  |
|    n_updates        | 3374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.975    |
| time/               |          |
|    episodes         | 744      |
|    fps              | 100      |
|    time_elapsed     | 536      |
|    total_timesteps  | 53653    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.009    |
|    n_updates        | 3413     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 299      |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 748      |
|    fps              | 100      |
|    time_elapsed     | 536      |
|    total_timesteps  | 53901    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00256  |
|    n_updates        | 3475     |
----------------------------------
Eval num_timesteps=54000, episode_reward=179.28 +/- 52.79
Episode length: 45.22 +/- 13.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.974    |
| time/               |          |
|    total_timesteps  | 54000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00279  |
|    n_updates        | 3499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.974    |
| time/               |          |
|    episodes         | 752      |
|    fps              | 100      |
|    time_elapsed     | 541      |
|    total_timesteps  | 54134    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0032   |
|    n_updates        | 3533     |
----------------------------------
Eval num_timesteps=54500, episode_reward=184.90 +/- 52.91
Episode length: 46.64 +/- 13.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.6     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.973    |
| time/               |          |
|    total_timesteps  | 54500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00236  |
|    n_updates        | 3624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.973    |
| time/               |          |
|    episodes         | 756      |
|    fps              | 99       |
|    time_elapsed     | 546      |
|    total_timesteps  | 54502    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.247    |
|    n_updates        | 3625     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.4     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 760      |
|    fps              | 100      |
|    time_elapsed     | 547      |
|    total_timesteps  | 54900    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0861   |
|    n_updates        | 3724     |
----------------------------------
Eval num_timesteps=55000, episode_reward=172.10 +/- 42.01
Episode length: 43.36 +/- 10.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.4     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 0.971    |
| time/               |          |
|    total_timesteps  | 55000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00194  |
|    n_updates        | 3749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.971    |
| time/               |          |
|    episodes         | 764      |
|    fps              | 99       |
|    time_elapsed     | 551      |
|    total_timesteps  | 55088    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.219    |
|    n_updates        | 3771     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.9     |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.97     |
| time/               |          |
|    episodes         | 768      |
|    fps              | 100      |
|    time_elapsed     | 552      |
|    total_timesteps  | 55453    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00288  |
|    n_updates        | 3863     |
----------------------------------
Eval num_timesteps=55500, episode_reward=176.32 +/- 39.85
Episode length: 44.42 +/- 9.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.97     |
| time/               |          |
|    total_timesteps  | 55500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.182    |
|    n_updates        | 3874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 772      |
|    fps              | 99       |
|    time_elapsed     | 556      |
|    total_timesteps  | 55659    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00294  |
|    n_updates        | 3914     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 776      |
|    fps              | 100      |
|    time_elapsed     | 557      |
|    total_timesteps  | 55892    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0029   |
|    n_updates        | 3972     |
----------------------------------
Eval num_timesteps=56000, episode_reward=263.12 +/- 55.99
Episode length: 66.14 +/- 13.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.1     |
|    mean_reward      | 263      |
| rollout/            |          |
|    exploration_rate | 0.968    |
| time/               |          |
|    total_timesteps  | 56000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.139    |
|    n_updates        | 3999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 780      |
|    fps              | 99       |
|    time_elapsed     | 563      |
|    total_timesteps  | 56212    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0536   |
|    n_updates        | 4052     |
----------------------------------
Eval num_timesteps=56500, episode_reward=268.80 +/- 54.89
Episode length: 67.52 +/- 13.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.5     |
|    mean_reward      | 269      |
| rollout/            |          |
|    exploration_rate | 0.967    |
| time/               |          |
|    total_timesteps  | 56500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.356    |
|    n_updates        | 4124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 0.967    |
| time/               |          |
|    episodes         | 784      |
|    fps              | 99       |
|    time_elapsed     | 568      |
|    total_timesteps  | 56521    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00315  |
|    n_updates        | 4130     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 286      |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 788      |
|    fps              | 99       |
|    time_elapsed     | 569      |
|    total_timesteps  | 56812    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00242  |
|    n_updates        | 4202     |
----------------------------------
Eval num_timesteps=57000, episode_reward=190.34 +/- 50.98
Episode length: 47.84 +/- 12.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.8     |
|    mean_reward      | 190      |
| rollout/            |          |
|    exploration_rate | 0.965    |
| time/               |          |
|    total_timesteps  | 57000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.16     |
|    n_updates        | 4249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 0.965    |
| time/               |          |
|    episodes         | 792      |
|    fps              | 99       |
|    time_elapsed     | 574      |
|    total_timesteps  | 57042    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00214  |
|    n_updates        | 4260     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 796      |
|    fps              | 99       |
|    time_elapsed     | 574      |
|    total_timesteps  | 57419    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.166    |
|    n_updates        | 4354     |
----------------------------------
Eval num_timesteps=57500, episode_reward=179.72 +/- 41.41
Episode length: 45.32 +/- 10.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.964    |
| time/               |          |
|    total_timesteps  | 57500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.238    |
|    n_updates        | 4374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.9     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 0.964    |
| time/               |          |
|    episodes         | 800      |
|    fps              | 99       |
|    time_elapsed     | 578      |
|    total_timesteps  | 57602    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00388  |
|    n_updates        | 4400     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 804      |
|    fps              | 99       |
|    time_elapsed     | 579      |
|    total_timesteps  | 57966    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00305  |
|    n_updates        | 4491     |
----------------------------------
Eval num_timesteps=58000, episode_reward=191.38 +/- 61.49
Episode length: 48.22 +/- 15.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.2     |
|    mean_reward      | 191      |
| rollout/            |          |
|    exploration_rate | 0.962    |
| time/               |          |
|    total_timesteps  | 58000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00302  |
|    n_updates        | 4499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.3     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 0.962    |
| time/               |          |
|    episodes         | 808      |
|    fps              | 99       |
|    time_elapsed     | 584      |
|    total_timesteps  | 58205    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0707   |
|    n_updates        | 4551     |
----------------------------------
Eval num_timesteps=58500, episode_reward=243.98 +/- 96.05
Episode length: 61.44 +/- 24.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.4     |
|    mean_reward      | 244      |
| rollout/            |          |
|    exploration_rate | 0.961    |
| time/               |          |
|    total_timesteps  | 58500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00164  |
|    n_updates        | 4624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.3     |
|    ep_rew_mean      | 280      |
|    exploration_rate | 0.961    |
| time/               |          |
|    episodes         | 812      |
|    fps              | 99       |
|    time_elapsed     | 590      |
|    total_timesteps  | 58559    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.225    |
|    n_updates        | 4639     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | 281      |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 816      |
|    fps              | 99       |
|    time_elapsed     | 591      |
|    total_timesteps  | 58825    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00232  |
|    n_updates        | 4706     |
----------------------------------
Eval num_timesteps=59000, episode_reward=178.86 +/- 54.72
Episode length: 45.10 +/- 13.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.1     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.959    |
| time/               |          |
|    total_timesteps  | 59000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0519   |
|    n_updates        | 4749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 0.959    |
| time/               |          |
|    episodes         | 820      |
|    fps              | 99       |
|    time_elapsed     | 596      |
|    total_timesteps  | 59163    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00536  |
|    n_updates        | 4790     |
----------------------------------
Eval num_timesteps=59500, episode_reward=234.70 +/- 49.74
Episode length: 59.06 +/- 12.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.1     |
|    mean_reward      | 235      |
| rollout/            |          |
|    exploration_rate | 0.957    |
| time/               |          |
|    total_timesteps  | 59500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.105    |
|    n_updates        | 4874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 824      |
|    fps              | 98       |
|    time_elapsed     | 602      |
|    total_timesteps  | 59563    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.156    |
|    n_updates        | 4890     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | 281      |
|    exploration_rate | 0.957    |
| time/               |          |
|    episodes         | 828      |
|    fps              | 99       |
|    time_elapsed     | 602      |
|    total_timesteps  | 59737    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00158  |
|    n_updates        | 4934     |
----------------------------------
Eval num_timesteps=60000, episode_reward=174.44 +/- 50.71
Episode length: 43.92 +/- 12.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.956    |
| time/               |          |
|    total_timesteps  | 60000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00907  |
|    n_updates        | 4999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 0.956    |
| time/               |          |
|    episodes         | 832      |
|    fps              | 98       |
|    time_elapsed     | 607      |
|    total_timesteps  | 60089    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.301    |
|    n_updates        | 5022     |
----------------------------------
Eval num_timesteps=60500, episode_reward=180.68 +/- 72.93
Episode length: 45.60 +/- 18.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.954    |
| time/               |          |
|    total_timesteps  | 60500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00467  |
|    n_updates        | 5124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.954    |
| time/               |          |
|    episodes         | 836      |
|    fps              | 98       |
|    time_elapsed     | 614      |
|    total_timesteps  | 60527    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.169    |
|    n_updates        | 5131     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 840      |
|    fps              | 98       |
|    time_elapsed     | 614      |
|    total_timesteps  | 60742    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.263    |
|    n_updates        | 5185     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.953    |
| time/               |          |
|    episodes         | 844      |
|    fps              | 99       |
|    time_elapsed     | 615      |
|    total_timesteps  | 60949    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.338    |
|    n_updates        | 5237     |
----------------------------------
Eval num_timesteps=61000, episode_reward=218.96 +/- 81.01
Episode length: 55.16 +/- 20.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.2     |
|    mean_reward      | 219      |
| rollout/            |          |
|    exploration_rate | 0.953    |
| time/               |          |
|    total_timesteps  | 61000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0103   |
|    n_updates        | 5249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 848      |
|    fps              | 98       |
|    time_elapsed     | 623      |
|    total_timesteps  | 61284    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.108    |
|    n_updates        | 5320     |
----------------------------------
Eval num_timesteps=61500, episode_reward=173.06 +/- 40.04
Episode length: 43.66 +/- 10.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.7     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.951    |
| time/               |          |
|    total_timesteps  | 61500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.152    |
|    n_updates        | 5374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.951    |
| time/               |          |
|    episodes         | 852      |
|    fps              | 97       |
|    time_elapsed     | 627      |
|    total_timesteps  | 61507    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0044   |
|    n_updates        | 5376     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.95     |
| time/               |          |
|    episodes         | 856      |
|    fps              | 98       |
|    time_elapsed     | 628      |
|    total_timesteps  | 61799    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.133    |
|    n_updates        | 5449     |
----------------------------------
Eval num_timesteps=62000, episode_reward=205.00 +/- 95.54
Episode length: 51.62 +/- 23.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.6     |
|    mean_reward      | 205      |
| rollout/            |          |
|    exploration_rate | 0.949    |
| time/               |          |
|    total_timesteps  | 62000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0119   |
|    n_updates        | 5499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.4     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 860      |
|    fps              | 97       |
|    time_elapsed     | 634      |
|    total_timesteps  | 62137    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00551  |
|    n_updates        | 5534     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.948    |
| time/               |          |
|    episodes         | 864      |
|    fps              | 98       |
|    time_elapsed     | 635      |
|    total_timesteps  | 62423    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00428  |
|    n_updates        | 5605     |
----------------------------------
Eval num_timesteps=62500, episode_reward=175.12 +/- 48.96
Episode length: 44.20 +/- 12.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.947    |
| time/               |          |
|    total_timesteps  | 62500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.147    |
|    n_updates        | 5624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.946    |
| time/               |          |
|    episodes         | 868      |
|    fps              | 97       |
|    time_elapsed     | 641      |
|    total_timesteps  | 62847    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0153   |
|    n_updates        | 5711     |
----------------------------------
Eval num_timesteps=63000, episode_reward=175.10 +/- 57.93
Episode length: 44.12 +/- 14.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.946    |
| time/               |          |
|    total_timesteps  | 63000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.292    |
|    n_updates        | 5749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 872      |
|    fps              | 97       |
|    time_elapsed     | 648      |
|    total_timesteps  | 63208    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00636  |
|    n_updates        | 5801     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.944    |
| time/               |          |
|    episodes         | 876      |
|    fps              | 97       |
|    time_elapsed     | 648      |
|    total_timesteps  | 63376    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.144    |
|    n_updates        | 5843     |
----------------------------------
Eval num_timesteps=63500, episode_reward=172.10 +/- 58.94
Episode length: 43.32 +/- 14.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.3     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 0.944    |
| time/               |          |
|    total_timesteps  | 63500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00676  |
|    n_updates        | 5874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.4     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.943    |
| time/               |          |
|    episodes         | 880      |
|    fps              | 97       |
|    time_elapsed     | 652      |
|    total_timesteps  | 63753    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.316    |
|    n_updates        | 5938     |
----------------------------------
Eval num_timesteps=64000, episode_reward=179.18 +/- 52.97
Episode length: 45.16 +/- 13.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.942    |
| time/               |          |
|    total_timesteps  | 64000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.111    |
|    n_updates        | 5999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.4     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 884      |
|    fps              | 97       |
|    time_elapsed     | 657      |
|    total_timesteps  | 64057    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00302  |
|    n_updates        | 6014     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.941    |
| time/               |          |
|    episodes         | 888      |
|    fps              | 97       |
|    time_elapsed     | 657      |
|    total_timesteps  | 64382    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.107    |
|    n_updates        | 6095     |
----------------------------------
Eval num_timesteps=64500, episode_reward=193.16 +/- 71.22
Episode length: 48.64 +/- 17.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.6     |
|    mean_reward      | 193      |
| rollout/            |          |
|    exploration_rate | 0.94     |
| time/               |          |
|    total_timesteps  | 64500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.122    |
|    n_updates        | 6124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.94     |
| time/               |          |
|    episodes         | 892      |
|    fps              | 97       |
|    time_elapsed     | 662      |
|    total_timesteps  | 64667    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.108    |
|    n_updates        | 6166     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.1     |
|    ep_rew_mean      | 299      |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 896      |
|    fps              | 97       |
|    time_elapsed     | 663      |
|    total_timesteps  | 64929    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.338    |
|    n_updates        | 6232     |
----------------------------------
Eval num_timesteps=65000, episode_reward=225.48 +/- 53.35
Episode length: 56.76 +/- 13.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.8     |
|    mean_reward      | 225      |
| rollout/            |          |
|    exploration_rate | 0.938    |
| time/               |          |
|    total_timesteps  | 65000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.153    |
|    n_updates        | 6249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.937    |
| time/               |          |
|    episodes         | 900      |
|    fps              | 97       |
|    time_elapsed     | 668      |
|    total_timesteps  | 65255    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.114    |
|    n_updates        | 6313     |
----------------------------------
Eval num_timesteps=65500, episode_reward=174.08 +/- 49.56
Episode length: 43.92 +/- 12.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.936    |
| time/               |          |
|    total_timesteps  | 65500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.109    |
|    n_updates        | 6374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 310      |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 904      |
|    fps              | 97       |
|    time_elapsed     | 672      |
|    total_timesteps  | 65754    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00322  |
|    n_updates        | 6438     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.7     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.935    |
| time/               |          |
|    episodes         | 908      |
|    fps              | 97       |
|    time_elapsed     | 673      |
|    total_timesteps  | 65972    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0067   |
|    n_updates        | 6492     |
----------------------------------
Eval num_timesteps=66000, episode_reward=183.00 +/- 47.90
Episode length: 46.12 +/- 11.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.935    |
| time/               |          |
|    total_timesteps  | 66000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.25     |
|    n_updates        | 6499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.934    |
| time/               |          |
|    episodes         | 912      |
|    fps              | 97       |
|    time_elapsed     | 677      |
|    total_timesteps  | 66224    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.128    |
|    n_updates        | 6555     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 916      |
|    fps              | 97       |
|    time_elapsed     | 678      |
|    total_timesteps  | 66396    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00699  |
|    n_updates        | 6598     |
----------------------------------
Eval num_timesteps=66500, episode_reward=169.62 +/- 62.60
Episode length: 42.80 +/- 15.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.933    |
| time/               |          |
|    total_timesteps  | 66500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.15     |
|    n_updates        | 6624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.3     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.932    |
| time/               |          |
|    episodes         | 920      |
|    fps              | 97       |
|    time_elapsed     | 682      |
|    total_timesteps  | 66690    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.276    |
|    n_updates        | 6672     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 924      |
|    fps              | 98       |
|    time_elapsed     | 682      |
|    total_timesteps  | 66941    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0106   |
|    n_updates        | 6735     |
----------------------------------
Eval num_timesteps=67000, episode_reward=169.42 +/- 35.80
Episode length: 42.74 +/- 8.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.7     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.931    |
| time/               |          |
|    total_timesteps  | 67000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.251    |
|    n_updates        | 6749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.9     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.93     |
| time/               |          |
|    episodes         | 928      |
|    fps              | 97       |
|    time_elapsed     | 686      |
|    total_timesteps  | 67223    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.206    |
|    n_updates        | 6805     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.929    |
| time/               |          |
|    episodes         | 932      |
|    fps              | 98       |
|    time_elapsed     | 687      |
|    total_timesteps  | 67444    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00566  |
|    n_updates        | 6860     |
----------------------------------
Eval num_timesteps=67500, episode_reward=173.16 +/- 51.01
Episode length: 43.68 +/- 12.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.7     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.929    |
| time/               |          |
|    total_timesteps  | 67500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.129    |
|    n_updates        | 6874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 287      |
|    exploration_rate | 0.928    |
| time/               |          |
|    episodes         | 936      |
|    fps              | 97       |
|    time_elapsed     | 691      |
|    total_timesteps  | 67749    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.397    |
|    n_updates        | 6937     |
----------------------------------
Eval num_timesteps=68000, episode_reward=253.72 +/- 133.31
Episode length: 63.74 +/- 33.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.7     |
|    mean_reward      | 254      |
| rollout/            |          |
|    exploration_rate | 0.927    |
| time/               |          |
|    total_timesteps  | 68000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.354    |
|    n_updates        | 6999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 940      |
|    fps              | 97       |
|    time_elapsed     | 697      |
|    total_timesteps  | 68076    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.127    |
|    n_updates        | 7018     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.925    |
| time/               |          |
|    episodes         | 944      |
|    fps              | 97       |
|    time_elapsed     | 698      |
|    total_timesteps  | 68406    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.147    |
|    n_updates        | 7101     |
----------------------------------
Eval num_timesteps=68500, episode_reward=269.68 +/- 118.03
Episode length: 67.80 +/- 29.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.8     |
|    mean_reward      | 270      |
| rollout/            |          |
|    exploration_rate | 0.925    |
| time/               |          |
|    total_timesteps  | 68500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.119    |
|    n_updates        | 7124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 948      |
|    fps              | 97       |
|    time_elapsed     | 704      |
|    total_timesteps  | 68643    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.119    |
|    n_updates        | 7160     |
----------------------------------
Eval num_timesteps=69000, episode_reward=228.00 +/- 125.95
Episode length: 57.42 +/- 31.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.4     |
|    mean_reward      | 228      |
| rollout/            |          |
|    exploration_rate | 0.923    |
| time/               |          |
|    total_timesteps  | 69000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00375  |
|    n_updates        | 7249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.3     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.923    |
| time/               |          |
|    episodes         | 952      |
|    fps              | 97       |
|    time_elapsed     | 710      |
|    total_timesteps  | 69042    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00532  |
|    n_updates        | 7260     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.4     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 956      |
|    fps              | 97       |
|    time_elapsed     | 711      |
|    total_timesteps  | 69338    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.164    |
|    n_updates        | 7334     |
----------------------------------
Eval num_timesteps=69500, episode_reward=181.70 +/- 48.57
Episode length: 45.82 +/- 12.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.8     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.921    |
| time/               |          |
|    total_timesteps  | 69500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.247    |
|    n_updates        | 7374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.92     |
| time/               |          |
|    episodes         | 960      |
|    fps              | 97       |
|    time_elapsed     | 718      |
|    total_timesteps  | 69767    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00601  |
|    n_updates        | 7441     |
----------------------------------
Eval num_timesteps=70000, episode_reward=220.86 +/- 92.96
Episode length: 55.58 +/- 23.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.6     |
|    mean_reward      | 221      |
| rollout/            |          |
|    exploration_rate | 0.919    |
| time/               |          |
|    total_timesteps  | 70000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.128    |
|    n_updates        | 7499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.6     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.918    |
| time/               |          |
|    episodes         | 964      |
|    fps              | 96       |
|    time_elapsed     | 726      |
|    total_timesteps  | 70182    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.224    |
|    n_updates        | 7545     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.4     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.917    |
| time/               |          |
|    episodes         | 968      |
|    fps              | 96       |
|    time_elapsed     | 727      |
|    total_timesteps  | 70483    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0114   |
|    n_updates        | 7620     |
----------------------------------
Eval num_timesteps=70500, episode_reward=297.50 +/- 124.07
Episode length: 74.74 +/- 31.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.7     |
|    mean_reward      | 298      |
| rollout/            |          |
|    exploration_rate | 0.917    |
| time/               |          |
|    total_timesteps  | 70500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0115   |
|    n_updates        | 7624     |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 972      |
|    fps              | 95       |
|    time_elapsed     | 737      |
|    total_timesteps  | 70783    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00934  |
|    n_updates        | 7695     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.1     |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.915    |
| time/               |          |
|    episodes         | 976      |
|    fps              | 96       |
|    time_elapsed     | 738      |
|    total_timesteps  | 70987    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.575    |
|    n_updates        | 7746     |
----------------------------------
Eval num_timesteps=71000, episode_reward=226.38 +/- 71.32
Episode length: 56.96 +/- 17.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57       |
|    mean_reward      | 226      |
| rollout/            |          |
|    exploration_rate | 0.915    |
| time/               |          |
|    total_timesteps  | 71000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0106   |
|    n_updates        | 7749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 980      |
|    fps              | 95       |
|    time_elapsed     | 743      |
|    total_timesteps  | 71168    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.398    |
|    n_updates        | 7791     |
----------------------------------
Eval num_timesteps=71500, episode_reward=220.16 +/- 72.89
Episode length: 55.52 +/- 18.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.5     |
|    mean_reward      | 220      |
| rollout/            |          |
|    exploration_rate | 0.913    |
| time/               |          |
|    total_timesteps  | 71500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.192    |
|    n_updates        | 7874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.913    |
| time/               |          |
|    episodes         | 984      |
|    fps              | 95       |
|    time_elapsed     | 749      |
|    total_timesteps  | 71528    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.335    |
|    n_updates        | 7881     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.912    |
| time/               |          |
|    episodes         | 988      |
|    fps              | 95       |
|    time_elapsed     | 750      |
|    total_timesteps  | 71754    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.217    |
|    n_updates        | 7938     |
----------------------------------
Eval num_timesteps=72000, episode_reward=166.56 +/- 30.71
Episode length: 41.98 +/- 7.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42       |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.911    |
| time/               |          |
|    total_timesteps  | 72000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0109   |
|    n_updates        | 7999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.91     |
| time/               |          |
|    episodes         | 992      |
|    fps              | 95       |
|    time_elapsed     | 755      |
|    total_timesteps  | 72065    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.235    |
|    n_updates        | 8016     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.909    |
| time/               |          |
|    episodes         | 996      |
|    fps              | 95       |
|    time_elapsed     | 756      |
|    total_timesteps  | 72367    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0237   |
|    n_updates        | 8091     |
----------------------------------
Eval num_timesteps=72500, episode_reward=180.28 +/- 45.58
Episode length: 45.46 +/- 11.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.5     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.909    |
| time/               |          |
|    total_timesteps  | 72500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.194    |
|    n_updates        | 8124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 1000     |
|    fps              | 95       |
|    time_elapsed     | 760      |
|    total_timesteps  | 72566    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0082   |
|    n_updates        | 8141     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 0.907    |
| time/               |          |
|    episodes         | 1004     |
|    fps              | 95       |
|    time_elapsed     | 761      |
|    total_timesteps  | 72877    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0168   |
|    n_updates        | 8219     |
----------------------------------
Eval num_timesteps=73000, episode_reward=207.76 +/- 42.21
Episode length: 52.26 +/- 10.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.3     |
|    mean_reward      | 208      |
| rollout/            |          |
|    exploration_rate | 0.906    |
| time/               |          |
|    total_timesteps  | 73000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00721  |
|    n_updates        | 8249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 0.906    |
| time/               |          |
|    episodes         | 1008     |
|    fps              | 95       |
|    time_elapsed     | 765      |
|    total_timesteps  | 73088    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.191    |
|    n_updates        | 8271     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 287      |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 1012     |
|    fps              | 95       |
|    time_elapsed     | 766      |
|    total_timesteps  | 73444    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.351    |
|    n_updates        | 8360     |
----------------------------------
Eval num_timesteps=73500, episode_reward=213.34 +/- 46.16
Episode length: 53.70 +/- 11.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.7     |
|    mean_reward      | 213      |
| rollout/            |          |
|    exploration_rate | 0.904    |
| time/               |          |
|    total_timesteps  | 73500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0107   |
|    n_updates        | 8374     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.903    |
| time/               |          |
|    episodes         | 1016     |
|    fps              | 95       |
|    time_elapsed     | 771      |
|    total_timesteps  | 73785    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0103   |
|    n_updates        | 8446     |
----------------------------------
Eval num_timesteps=74000, episode_reward=272.30 +/- 89.22
Episode length: 68.46 +/- 22.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.5     |
|    mean_reward      | 272      |
| rollout/            |          |
|    exploration_rate | 0.902    |
| time/               |          |
|    total_timesteps  | 74000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00797  |
|    n_updates        | 8499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 1020     |
|    fps              | 95       |
|    time_elapsed     | 778      |
|    total_timesteps  | 74134    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00424  |
|    n_updates        | 8533     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 1024     |
|    fps              | 95       |
|    time_elapsed     | 778      |
|    total_timesteps  | 74388    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0112   |
|    n_updates        | 8596     |
----------------------------------
Eval num_timesteps=74500, episode_reward=177.38 +/- 60.61
Episode length: 44.72 +/- 15.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.7     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 0.9      |
| time/               |          |
|    total_timesteps  | 74500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0112   |
|    n_updates        | 8624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.899    |
| time/               |          |
|    episodes         | 1028     |
|    fps              | 95       |
|    time_elapsed     | 783      |
|    total_timesteps  | 74675    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0096   |
|    n_updates        | 8668     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 1032     |
|    fps              | 95       |
|    time_elapsed     | 783      |
|    total_timesteps  | 74929    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.188    |
|    n_updates        | 8732     |
----------------------------------
Eval num_timesteps=75000, episode_reward=272.20 +/- 104.88
Episode length: 68.38 +/- 26.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.4     |
|    mean_reward      | 272      |
| rollout/            |          |
|    exploration_rate | 0.898    |
| time/               |          |
|    total_timesteps  | 75000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0113   |
|    n_updates        | 8749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.897    |
| time/               |          |
|    episodes         | 1036     |
|    fps              | 95       |
|    time_elapsed     | 789      |
|    total_timesteps  | 75158    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0385   |
|    n_updates        | 8789     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.896    |
| time/               |          |
|    episodes         | 1040     |
|    fps              | 95       |
|    time_elapsed     | 790      |
|    total_timesteps  | 75471    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0196   |
|    n_updates        | 8867     |
----------------------------------
Eval num_timesteps=75500, episode_reward=212.76 +/- 41.98
Episode length: 53.50 +/- 10.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.5     |
|    mean_reward      | 213      |
| rollout/            |          |
|    exploration_rate | 0.896    |
| time/               |          |
|    total_timesteps  | 75500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00894  |
|    n_updates        | 8874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 1044     |
|    fps              | 95       |
|    time_elapsed     | 795      |
|    total_timesteps  | 75707    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.165    |
|    n_updates        | 8926     |
----------------------------------
Eval num_timesteps=76000, episode_reward=225.22 +/- 62.44
Episode length: 56.60 +/- 15.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.6     |
|    mean_reward      | 225      |
| rollout/            |          |
|    exploration_rate | 0.893    |
| time/               |          |
|    total_timesteps  | 76000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0223   |
|    n_updates        | 8999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.893    |
| time/               |          |
|    episodes         | 1048     |
|    fps              | 95       |
|    time_elapsed     | 800      |
|    total_timesteps  | 76074    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.486    |
|    n_updates        | 9018     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.891    |
| time/               |          |
|    episodes         | 1052     |
|    fps              | 95       |
|    time_elapsed     | 801      |
|    total_timesteps  | 76474    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.174    |
|    n_updates        | 9118     |
----------------------------------
Eval num_timesteps=76500, episode_reward=208.50 +/- 51.69
Episode length: 52.54 +/- 12.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.5     |
|    mean_reward      | 208      |
| rollout/            |          |
|    exploration_rate | 0.891    |
| time/               |          |
|    total_timesteps  | 76500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.199    |
|    n_updates        | 9124     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 1056     |
|    fps              | 94       |
|    time_elapsed     | 808      |
|    total_timesteps  | 76802    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.378    |
|    n_updates        | 9200     |
----------------------------------
Eval num_timesteps=77000, episode_reward=176.44 +/- 58.91
Episode length: 44.46 +/- 14.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.5     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.889    |
| time/               |          |
|    total_timesteps  | 77000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.36     |
|    n_updates        | 9249     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 1060     |
|    fps              | 94       |
|    time_elapsed     | 814      |
|    total_timesteps  | 77126    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.397    |
|    n_updates        | 9281     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.887    |
| time/               |          |
|    episodes         | 1064     |
|    fps              | 95       |
|    time_elapsed     | 815      |
|    total_timesteps  | 77498    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.03     |
|    n_updates        | 9374     |
----------------------------------
Eval num_timesteps=77500, episode_reward=217.60 +/- 54.06
Episode length: 54.78 +/- 13.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.8     |
|    mean_reward      | 218      |
| rollout/            |          |
|    exploration_rate | 0.887    |
| time/               |          |
|    total_timesteps  | 77500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 1068     |
|    fps              | 94       |
|    time_elapsed     | 820      |
|    total_timesteps  | 77771    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00696  |
|    n_updates        | 9442     |
----------------------------------
Eval num_timesteps=78000, episode_reward=228.48 +/- 115.01
Episode length: 57.50 +/- 28.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.5     |
|    mean_reward      | 228      |
| rollout/            |          |
|    exploration_rate | 0.884    |
| time/               |          |
|    total_timesteps  | 78000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00447  |
|    n_updates        | 9499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.884    |
| time/               |          |
|    episodes         | 1072     |
|    fps              | 94       |
|    time_elapsed     | 825      |
|    total_timesteps  | 78115    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.188    |
|    n_updates        | 9528     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 1076     |
|    fps              | 94       |
|    time_elapsed     | 826      |
|    total_timesteps  | 78386    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0073   |
|    n_updates        | 9596     |
----------------------------------
Eval num_timesteps=78500, episode_reward=211.82 +/- 92.80
Episode length: 53.28 +/- 23.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.3     |
|    mean_reward      | 212      |
| rollout/            |          |
|    exploration_rate | 0.882    |
| time/               |          |
|    total_timesteps  | 78500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00786  |
|    n_updates        | 9624     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 1080     |
|    fps              | 94       |
|    time_elapsed     | 832      |
|    total_timesteps  | 78742    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0109   |
|    n_updates        | 9685     |
----------------------------------
Eval num_timesteps=79000, episode_reward=168.66 +/- 44.13
Episode length: 42.50 +/- 11.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.5     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.88     |
| time/               |          |
|    total_timesteps  | 79000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.17     |
|    n_updates        | 9749     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.6     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.879    |
| time/               |          |
|    episodes         | 1084     |
|    fps              | 94       |
|    time_elapsed     | 836      |
|    total_timesteps  | 79089    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.187    |
|    n_updates        | 9772     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.6     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 1088     |
|    fps              | 94       |
|    time_elapsed     | 837      |
|    total_timesteps  | 79410    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.211    |
|    n_updates        | 9852     |
----------------------------------
Eval num_timesteps=79500, episode_reward=155.96 +/- 39.03
Episode length: 39.44 +/- 9.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.4     |
|    mean_reward      | 156      |
| rollout/            |          |
|    exploration_rate | 0.877    |
| time/               |          |
|    total_timesteps  | 79500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.352    |
|    n_updates        | 9874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 307      |
|    exploration_rate | 0.876    |
| time/               |          |
|    episodes         | 1092     |
|    fps              | 94       |
|    time_elapsed     | 841      |
|    total_timesteps  | 79765    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0137   |
|    n_updates        | 9941     |
----------------------------------
Eval num_timesteps=80000, episode_reward=196.12 +/- 96.35
Episode length: 49.42 +/- 24.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.4     |
|    mean_reward      | 196      |
| rollout/            |          |
|    exploration_rate | 0.875    |
| time/               |          |
|    total_timesteps  | 80000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.207    |
|    n_updates        | 9999     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.6     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 1096     |
|    fps              | 94       |
|    time_elapsed     | 846      |
|    total_timesteps  | 80024    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.51     |
|    n_updates        | 10005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.9     |
|    ep_rew_mean      | 306      |
|    exploration_rate | 0.874    |
| time/               |          |
|    episodes         | 1100     |
|    fps              | 94       |
|    time_elapsed     | 847      |
|    total_timesteps  | 80258    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0122   |
|    n_updates        | 10064    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 1104     |
|    fps              | 94       |
|    time_elapsed     | 847      |
|    total_timesteps  | 80448    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0158   |
|    n_updates        | 10111    |
----------------------------------
Eval num_timesteps=80500, episode_reward=177.28 +/- 70.91
Episode length: 44.68 +/- 17.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.7     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 0.873    |
| time/               |          |
|    total_timesteps  | 80500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0126   |
|    n_updates        | 10124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 1108     |
|    fps              | 94       |
|    time_elapsed     | 851      |
|    total_timesteps  | 80584    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.437    |
|    n_updates        | 10145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.872    |
| time/               |          |
|    episodes         | 1112     |
|    fps              | 94       |
|    time_elapsed     | 851      |
|    total_timesteps  | 80767    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00827  |
|    n_updates        | 10191    |
----------------------------------
Eval num_timesteps=81000, episode_reward=263.26 +/- 99.88
Episode length: 66.12 +/- 24.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.1     |
|    mean_reward      | 263      |
| rollout/            |          |
|    exploration_rate | 0.87     |
| time/               |          |
|    total_timesteps  | 81000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.448    |
|    n_updates        | 10249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.87     |
| time/               |          |
|    episodes         | 1116     |
|    fps              | 94       |
|    time_elapsed     | 858      |
|    total_timesteps  | 81102    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.211    |
|    n_updates        | 10275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 1120     |
|    fps              | 94       |
|    time_elapsed     | 858      |
|    total_timesteps  | 81428    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.233    |
|    n_updates        | 10356    |
----------------------------------
Eval num_timesteps=81500, episode_reward=228.56 +/- 128.62
Episode length: 57.52 +/- 32.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.5     |
|    mean_reward      | 229      |
| rollout/            |          |
|    exploration_rate | 0.868    |
| time/               |          |
|    total_timesteps  | 81500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0216   |
|    n_updates        | 10374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.867    |
| time/               |          |
|    episodes         | 1124     |
|    fps              | 94       |
|    time_elapsed     | 864      |
|    total_timesteps  | 81717    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0146   |
|    n_updates        | 10429    |
----------------------------------
Eval num_timesteps=82000, episode_reward=255.74 +/- 135.28
Episode length: 64.30 +/- 33.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.3     |
|    mean_reward      | 256      |
| rollout/            |          |
|    exploration_rate | 0.866    |
| time/               |          |
|    total_timesteps  | 82000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.222    |
|    n_updates        | 10499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.865    |
| time/               |          |
|    episodes         | 1128     |
|    fps              | 94       |
|    time_elapsed     | 870      |
|    total_timesteps  | 82081    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0176   |
|    n_updates        | 10520    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.864    |
| time/               |          |
|    episodes         | 1132     |
|    fps              | 94       |
|    time_elapsed     | 871      |
|    total_timesteps  | 82337    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.239    |
|    n_updates        | 10584    |
----------------------------------
Eval num_timesteps=82500, episode_reward=216.50 +/- 94.78
Episode length: 54.50 +/- 23.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.5     |
|    mean_reward      | 216      |
| rollout/            |          |
|    exploration_rate | 0.863    |
| time/               |          |
|    total_timesteps  | 82500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0194   |
|    n_updates        | 10624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.863    |
| time/               |          |
|    episodes         | 1136     |
|    fps              | 94       |
|    time_elapsed     | 876      |
|    total_timesteps  | 82608    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.679    |
|    n_updates        | 10651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 1140     |
|    fps              | 94       |
|    time_elapsed     | 876      |
|    total_timesteps  | 82850    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00809  |
|    n_updates        | 10712    |
----------------------------------
Eval num_timesteps=83000, episode_reward=175.10 +/- 58.90
Episode length: 44.16 +/- 14.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.861    |
| time/               |          |
|    total_timesteps  | 83000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.258    |
|    n_updates        | 10749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.86     |
| time/               |          |
|    episodes         | 1144     |
|    fps              | 94       |
|    time_elapsed     | 881      |
|    total_timesteps  | 83161    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.259    |
|    n_updates        | 10790    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.859    |
| time/               |          |
|    episodes         | 1148     |
|    fps              | 94       |
|    time_elapsed     | 881      |
|    total_timesteps  | 83472    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0351   |
|    n_updates        | 10867    |
----------------------------------
Eval num_timesteps=83500, episode_reward=168.68 +/- 41.56
Episode length: 42.60 +/- 10.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.858    |
| time/               |          |
|    total_timesteps  | 83500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.261    |
|    n_updates        | 10874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 0.857    |
| time/               |          |
|    episodes         | 1152     |
|    fps              | 94       |
|    time_elapsed     | 885      |
|    total_timesteps  | 83732    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.92     |
|    n_updates        | 10932    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 1156     |
|    fps              | 94       |
|    time_elapsed     | 886      |
|    total_timesteps  | 83959    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.967    |
|    n_updates        | 10989    |
----------------------------------
Eval num_timesteps=84000, episode_reward=164.20 +/- 37.27
Episode length: 41.44 +/- 9.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.4     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 0.856    |
| time/               |          |
|    total_timesteps  | 84000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.216    |
|    n_updates        | 10999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.854    |
| time/               |          |
|    episodes         | 1160     |
|    fps              | 94       |
|    time_elapsed     | 890      |
|    total_timesteps  | 84458    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.239    |
|    n_updates        | 11114    |
----------------------------------
Eval num_timesteps=84500, episode_reward=204.62 +/- 50.08
Episode length: 51.50 +/- 12.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.5     |
|    mean_reward      | 205      |
| rollout/            |          |
|    exploration_rate | 0.853    |
| time/               |          |
|    total_timesteps  | 84500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.247    |
|    n_updates        | 11124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.852    |
| time/               |          |
|    episodes         | 1164     |
|    fps              | 94       |
|    time_elapsed     | 896      |
|    total_timesteps  | 84889    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.233    |
|    n_updates        | 11222    |
----------------------------------
Eval num_timesteps=85000, episode_reward=168.90 +/- 49.51
Episode length: 42.56 +/- 12.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.851    |
| time/               |          |
|    total_timesteps  | 85000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.265    |
|    n_updates        | 11249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.85     |
| time/               |          |
|    episodes         | 1168     |
|    fps              | 94       |
|    time_elapsed     | 900      |
|    total_timesteps  | 85128    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00969  |
|    n_updates        | 11281    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 1172     |
|    fps              | 94       |
|    time_elapsed     | 901      |
|    total_timesteps  | 85465    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.24     |
|    n_updates        | 11366    |
----------------------------------
Eval num_timesteps=85500, episode_reward=239.78 +/- 69.65
Episode length: 60.30 +/- 17.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60.3     |
|    mean_reward      | 240      |
| rollout/            |          |
|    exploration_rate | 0.849    |
| time/               |          |
|    total_timesteps  | 85500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.237    |
|    n_updates        | 11374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.847    |
| time/               |          |
|    episodes         | 1176     |
|    fps              | 94       |
|    time_elapsed     | 909      |
|    total_timesteps  | 85721    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.243    |
|    n_updates        | 11430    |
----------------------------------
Eval num_timesteps=86000, episode_reward=168.84 +/- 41.90
Episode length: 42.54 +/- 10.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.5     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.846    |
| time/               |          |
|    total_timesteps  | 86000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.267    |
|    n_updates        | 11499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.846    |
| time/               |          |
|    episodes         | 1180     |
|    fps              | 93       |
|    time_elapsed     | 916      |
|    total_timesteps  | 86069    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.475    |
|    n_updates        | 11517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 0.844    |
| time/               |          |
|    episodes         | 1184     |
|    fps              | 94       |
|    time_elapsed     | 917      |
|    total_timesteps  | 86363    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.013    |
|    n_updates        | 11590    |
----------------------------------
Eval num_timesteps=86500, episode_reward=212.86 +/- 82.77
Episode length: 53.60 +/- 20.68
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.6     |
|    mean_reward      | 213      |
| rollout/            |          |
|    exploration_rate | 0.843    |
| time/               |          |
|    total_timesteps  | 86500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0116   |
|    n_updates        | 11624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.7     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 0.843    |
| time/               |          |
|    episodes         | 1188     |
|    fps              | 93       |
|    time_elapsed     | 924      |
|    total_timesteps  | 86580    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.238    |
|    n_updates        | 11644    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 0.841    |
| time/               |          |
|    episodes         | 1192     |
|    fps              | 93       |
|    time_elapsed     | 925      |
|    total_timesteps  | 86926    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.226    |
|    n_updates        | 11731    |
----------------------------------
Eval num_timesteps=87000, episode_reward=181.62 +/- 48.11
Episode length: 45.82 +/- 11.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.8     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.841    |
| time/               |          |
|    total_timesteps  | 87000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.67     |
|    n_updates        | 11749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 287      |
|    exploration_rate | 0.84     |
| time/               |          |
|    episodes         | 1196     |
|    fps              | 93       |
|    time_elapsed     | 932      |
|    total_timesteps  | 87247    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.515    |
|    n_updates        | 11811    |
----------------------------------
Eval num_timesteps=87500, episode_reward=184.92 +/- 75.42
Episode length: 46.66 +/- 18.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.7     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.838    |
| time/               |          |
|    total_timesteps  | 87500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00992  |
|    n_updates        | 11874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.838    |
| time/               |          |
|    episodes         | 1200     |
|    fps              | 93       |
|    time_elapsed     | 939      |
|    total_timesteps  | 87570    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0278   |
|    n_updates        | 11892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 1204     |
|    fps              | 93       |
|    time_elapsed     | 939      |
|    total_timesteps  | 87887    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.24     |
|    n_updates        | 11971    |
----------------------------------
Eval num_timesteps=88000, episode_reward=195.24 +/- 59.76
Episode length: 49.16 +/- 14.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.2     |
|    mean_reward      | 195      |
| rollout/            |          |
|    exploration_rate | 0.836    |
| time/               |          |
|    total_timesteps  | 88000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.277    |
|    n_updates        | 11999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 1208     |
|    fps              | 93       |
|    time_elapsed     | 945      |
|    total_timesteps  | 88133    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0265   |
|    n_updates        | 12033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.834    |
| time/               |          |
|    episodes         | 1212     |
|    fps              | 93       |
|    time_elapsed     | 946      |
|    total_timesteps  | 88415    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.115    |
|    n_updates        | 12103    |
----------------------------------
Eval num_timesteps=88500, episode_reward=274.10 +/- 98.29
Episode length: 68.90 +/- 24.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.9     |
|    mean_reward      | 274      |
| rollout/            |          |
|    exploration_rate | 0.833    |
| time/               |          |
|    total_timesteps  | 88500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.265    |
|    n_updates        | 12124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.9     |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.832    |
| time/               |          |
|    episodes         | 1216     |
|    fps              | 93       |
|    time_elapsed     | 952      |
|    total_timesteps  | 88694    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.24     |
|    n_updates        | 12173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 1220     |
|    fps              | 93       |
|    time_elapsed     | 953      |
|    total_timesteps  | 88997    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.229    |
|    n_updates        | 12249    |
----------------------------------
Eval num_timesteps=89000, episode_reward=199.36 +/- 93.75
Episode length: 50.14 +/- 23.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.1     |
|    mean_reward      | 199      |
| rollout/            |          |
|    exploration_rate | 0.831    |
| time/               |          |
|    total_timesteps  | 89000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76       |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.829    |
| time/               |          |
|    episodes         | 1224     |
|    fps              | 93       |
|    time_elapsed     | 958      |
|    total_timesteps  | 89314    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.257    |
|    n_updates        | 12328    |
----------------------------------
Eval num_timesteps=89500, episode_reward=296.86 +/- 121.45
Episode length: 74.54 +/- 30.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.5     |
|    mean_reward      | 297      |
| rollout/            |          |
|    exploration_rate | 0.828    |
| time/               |          |
|    total_timesteps  | 89500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.7      |
|    n_updates        | 12374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.6     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.827    |
| time/               |          |
|    episodes         | 1228     |
|    fps              | 92       |
|    time_elapsed     | 965      |
|    total_timesteps  | 89644    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.256    |
|    n_updates        | 12410    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.826    |
| time/               |          |
|    episodes         | 1232     |
|    fps              | 93       |
|    time_elapsed     | 966      |
|    total_timesteps  | 89904    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00871  |
|    n_updates        | 12475    |
----------------------------------
Eval num_timesteps=90000, episode_reward=161.54 +/- 51.17
Episode length: 40.78 +/- 12.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.8     |
|    mean_reward      | 162      |
| rollout/            |          |
|    exploration_rate | 0.825    |
| time/               |          |
|    total_timesteps  | 90000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0297   |
|    n_updates        | 12499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.6     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.825    |
| time/               |          |
|    episodes         | 1236     |
|    fps              | 92       |
|    time_elapsed     | 970      |
|    total_timesteps  | 90166    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0408   |
|    n_updates        | 12541    |
----------------------------------
Eval num_timesteps=90500, episode_reward=279.98 +/- 118.04
Episode length: 70.36 +/- 29.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.4     |
|    mean_reward      | 280      |
| rollout/            |          |
|    exploration_rate | 0.823    |
| time/               |          |
|    total_timesteps  | 90500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0266   |
|    n_updates        | 12624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.4     |
|    ep_rew_mean      | 308      |
|    exploration_rate | 0.822    |
| time/               |          |
|    episodes         | 1240     |
|    fps              | 92       |
|    time_elapsed     | 977      |
|    total_timesteps  | 90590    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.293    |
|    n_updates        | 12647    |
----------------------------------
Eval num_timesteps=91000, episode_reward=223.08 +/- 105.72
Episode length: 56.14 +/- 26.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.1     |
|    mean_reward      | 223      |
| rollout/            |          |
|    exploration_rate | 0.82     |
| time/               |          |
|    total_timesteps  | 91000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0427   |
|    n_updates        | 12749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.5     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.82     |
| time/               |          |
|    episodes         | 1244     |
|    fps              | 92       |
|    time_elapsed     | 983      |
|    total_timesteps  | 91013    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0347   |
|    n_updates        | 12753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 310      |
|    exploration_rate | 0.819    |
| time/               |          |
|    episodes         | 1248     |
|    fps              | 92       |
|    time_elapsed     | 984      |
|    total_timesteps  | 91250    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0175   |
|    n_updates        | 12812    |
----------------------------------
Eval num_timesteps=91500, episode_reward=245.02 +/- 113.07
Episode length: 61.58 +/- 28.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.6     |
|    mean_reward      | 245      |
| rollout/            |          |
|    exploration_rate | 0.818    |
| time/               |          |
|    total_timesteps  | 91500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0159   |
|    n_updates        | 12874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.6     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 1252     |
|    fps              | 92       |
|    time_elapsed     | 990      |
|    total_timesteps  | 91694    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.351    |
|    n_updates        | 12923    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.9     |
|    ep_rew_mean      | 318      |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 1256     |
|    fps              | 92       |
|    time_elapsed     | 991      |
|    total_timesteps  | 91952    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.323    |
|    n_updates        | 12987    |
----------------------------------
Eval num_timesteps=92000, episode_reward=192.38 +/- 77.99
Episode length: 48.46 +/- 19.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.5     |
|    mean_reward      | 192      |
| rollout/            |          |
|    exploration_rate | 0.815    |
| time/               |          |
|    total_timesteps  | 92000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.295    |
|    n_updates        | 12999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 307      |
|    exploration_rate | 0.814    |
| time/               |          |
|    episodes         | 1260     |
|    fps              | 92       |
|    time_elapsed     | 995      |
|    total_timesteps  | 92179    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.561    |
|    n_updates        | 13044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.812    |
| time/               |          |
|    episodes         | 1264     |
|    fps              | 92       |
|    time_elapsed     | 996      |
|    total_timesteps  | 92455    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0253   |
|    n_updates        | 13113    |
----------------------------------
Eval num_timesteps=92500, episode_reward=196.92 +/- 98.07
Episode length: 49.60 +/- 24.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.6     |
|    mean_reward      | 197      |
| rollout/            |          |
|    exploration_rate | 0.812    |
| time/               |          |
|    total_timesteps  | 92500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0158   |
|    n_updates        | 13124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 299      |
|    exploration_rate | 0.812    |
| time/               |          |
|    episodes         | 1268     |
|    fps              | 92       |
|    time_elapsed     | 1000     |
|    total_timesteps  | 92632    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.305    |
|    n_updates        | 13157    |
----------------------------------
Eval num_timesteps=93000, episode_reward=175.86 +/- 43.43
Episode length: 44.32 +/- 10.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.3     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.81     |
| time/               |          |
|    total_timesteps  | 93000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.283    |
|    n_updates        | 13249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 1272     |
|    fps              | 92       |
|    time_elapsed     | 1005     |
|    total_timesteps  | 93017    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.868    |
|    n_updates        | 13254    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.6     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.808    |
| time/               |          |
|    episodes         | 1276     |
|    fps              | 92       |
|    time_elapsed     | 1006     |
|    total_timesteps  | 93277    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.55     |
|    n_updates        | 13319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 1280     |
|    fps              | 92       |
|    time_elapsed     | 1006     |
|    total_timesteps  | 93492    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.286    |
|    n_updates        | 13372    |
----------------------------------
Eval num_timesteps=93500, episode_reward=176.46 +/- 64.36
Episode length: 44.44 +/- 16.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.807    |
| time/               |          |
|    total_timesteps  | 93500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00815  |
|    n_updates        | 13374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 1284     |
|    fps              | 92       |
|    time_elapsed     | 1011     |
|    total_timesteps  | 93779    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0161   |
|    n_updates        | 13444    |
----------------------------------
Eval num_timesteps=94000, episode_reward=227.08 +/- 92.10
Episode length: 57.12 +/- 23.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.1     |
|    mean_reward      | 227      |
| rollout/            |          |
|    exploration_rate | 0.804    |
| time/               |          |
|    total_timesteps  | 94000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0186   |
|    n_updates        | 13499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.803    |
| time/               |          |
|    episodes         | 1288     |
|    fps              | 92       |
|    time_elapsed     | 1016     |
|    total_timesteps  | 94163    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.28     |
|    n_updates        | 13540    |
----------------------------------
Eval num_timesteps=94500, episode_reward=212.38 +/- 92.04
Episode length: 53.46 +/- 23.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.5     |
|    mean_reward      | 212      |
| rollout/            |          |
|    exploration_rate | 0.801    |
| time/               |          |
|    total_timesteps  | 94500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0302   |
|    n_updates        | 13624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.801    |
| time/               |          |
|    episodes         | 1292     |
|    fps              | 92       |
|    time_elapsed     | 1022     |
|    total_timesteps  | 94506    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.317    |
|    n_updates        | 13626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.8      |
| time/               |          |
|    episodes         | 1296     |
|    fps              | 92       |
|    time_elapsed     | 1022     |
|    total_timesteps  | 94699    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.281    |
|    n_updates        | 13674    |
----------------------------------
Eval num_timesteps=95000, episode_reward=199.26 +/- 70.05
Episode length: 50.22 +/- 17.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.2     |
|    mean_reward      | 199      |
| rollout/            |          |
|    exploration_rate | 0.799    |
| time/               |          |
|    total_timesteps  | 95000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.87     |
|    n_updates        | 13749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.798    |
| time/               |          |
|    episodes         | 1300     |
|    fps              | 92       |
|    time_elapsed     | 1027     |
|    total_timesteps  | 95036    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.375    |
|    n_updates        | 13758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.3     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.796    |
| time/               |          |
|    episodes         | 1304     |
|    fps              | 92       |
|    time_elapsed     | 1028     |
|    total_timesteps  | 95422    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.561    |
|    n_updates        | 13855    |
----------------------------------
Eval num_timesteps=95500, episode_reward=236.40 +/- 75.76
Episode length: 59.48 +/- 18.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.5     |
|    mean_reward      | 236      |
| rollout/            |          |
|    exploration_rate | 0.796    |
| time/               |          |
|    total_timesteps  | 95500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.597    |
|    n_updates        | 13874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.795    |
| time/               |          |
|    episodes         | 1308     |
|    fps              | 92       |
|    time_elapsed     | 1036     |
|    total_timesteps  | 95617    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0317   |
|    n_updates        | 13904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.794    |
| time/               |          |
|    episodes         | 1312     |
|    fps              | 92       |
|    time_elapsed     | 1036     |
|    total_timesteps  | 95827    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.274    |
|    n_updates        | 13956    |
----------------------------------
Eval num_timesteps=96000, episode_reward=165.52 +/- 39.76
Episode length: 41.74 +/- 9.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.7     |
|    mean_reward      | 166      |
| rollout/            |          |
|    exploration_rate | 0.793    |
| time/               |          |
|    total_timesteps  | 96000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.589    |
|    n_updates        | 13999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.792    |
| time/               |          |
|    episodes         | 1316     |
|    fps              | 92       |
|    time_elapsed     | 1043     |
|    total_timesteps  | 96139    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0161   |
|    n_updates        | 14034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.791    |
| time/               |          |
|    episodes         | 1320     |
|    fps              | 92       |
|    time_elapsed     | 1043     |
|    total_timesteps  | 96389    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0365   |
|    n_updates        | 14097    |
----------------------------------
Eval num_timesteps=96500, episode_reward=180.60 +/- 37.48
Episode length: 45.56 +/- 9.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.79     |
| time/               |          |
|    total_timesteps  | 96500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0216   |
|    n_updates        | 14124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.79     |
| time/               |          |
|    episodes         | 1324     |
|    fps              | 92       |
|    time_elapsed     | 1048     |
|    total_timesteps  | 96648    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0215   |
|    n_updates        | 14161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.788    |
| time/               |          |
|    episodes         | 1328     |
|    fps              | 92       |
|    time_elapsed     | 1049     |
|    total_timesteps  | 96950    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0266   |
|    n_updates        | 14237    |
----------------------------------
Eval num_timesteps=97000, episode_reward=171.48 +/- 46.67
Episode length: 43.24 +/- 11.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.2     |
|    mean_reward      | 171      |
| rollout/            |          |
|    exploration_rate | 0.788    |
| time/               |          |
|    total_timesteps  | 97000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.292    |
|    n_updates        | 14249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.787    |
| time/               |          |
|    episodes         | 1332     |
|    fps              | 92       |
|    time_elapsed     | 1053     |
|    total_timesteps  | 97187    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.523    |
|    n_updates        | 14296    |
----------------------------------
Eval num_timesteps=97500, episode_reward=182.80 +/- 46.25
Episode length: 46.06 +/- 11.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.785    |
| time/               |          |
|    total_timesteps  | 97500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.039    |
|    n_updates        | 14374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.784    |
| time/               |          |
|    episodes         | 1336     |
|    fps              | 92       |
|    time_elapsed     | 1058     |
|    total_timesteps  | 97570    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.283    |
|    n_updates        | 14392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 0.783    |
| time/               |          |
|    episodes         | 1340     |
|    fps              | 92       |
|    time_elapsed     | 1059     |
|    total_timesteps  | 97836    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.552    |
|    n_updates        | 14458    |
----------------------------------
Eval num_timesteps=98000, episode_reward=165.90 +/- 49.07
Episode length: 41.84 +/- 12.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.8     |
|    mean_reward      | 166      |
| rollout/            |          |
|    exploration_rate | 0.782    |
| time/               |          |
|    total_timesteps  | 98000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.305    |
|    n_updates        | 14499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.9     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 0.781    |
| time/               |          |
|    episodes         | 1344     |
|    fps              | 92       |
|    time_elapsed     | 1063     |
|    total_timesteps  | 98099    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.012    |
|    n_updates        | 14524    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 1348     |
|    fps              | 92       |
|    time_elapsed     | 1064     |
|    total_timesteps  | 98477    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.297    |
|    n_updates        | 14619    |
----------------------------------
Eval num_timesteps=98500, episode_reward=172.78 +/- 37.35
Episode length: 43.60 +/- 9.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.779    |
| time/               |          |
|    total_timesteps  | 98500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.302    |
|    n_updates        | 14624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.3     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 0.777    |
| time/               |          |
|    episodes         | 1352     |
|    fps              | 92       |
|    time_elapsed     | 1070     |
|    total_timesteps  | 98821    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0277   |
|    n_updates        | 14705    |
----------------------------------
Eval num_timesteps=99000, episode_reward=183.70 +/- 49.95
Episode length: 46.34 +/- 12.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.3     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.776    |
| time/               |          |
|    total_timesteps  | 99000    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0315   |
|    n_updates        | 14749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | 287      |
|    exploration_rate | 0.775    |
| time/               |          |
|    episodes         | 1356     |
|    fps              | 92       |
|    time_elapsed     | 1075     |
|    total_timesteps  | 99150    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.554    |
|    n_updates        | 14787    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.774    |
| time/               |          |
|    episodes         | 1360     |
|    fps              | 92       |
|    time_elapsed     | 1076     |
|    total_timesteps  | 99456    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0125   |
|    n_updates        | 14863    |
----------------------------------
Eval num_timesteps=99500, episode_reward=190.32 +/- 51.22
Episode length: 47.92 +/- 12.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.9     |
|    mean_reward      | 190      |
| rollout/            |          |
|    exploration_rate | 0.773    |
| time/               |          |
|    total_timesteps  | 99500    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0122   |
|    n_updates        | 14874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.772    |
| time/               |          |
|    episodes         | 1364     |
|    fps              | 92       |
|    time_elapsed     | 1081     |
|    total_timesteps  | 99738    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0163   |
|    n_updates        | 14934    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 1368     |
|    fps              | 92       |
|    time_elapsed     | 1081     |
|    total_timesteps  | 99971    |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00896  |
|    n_updates        | 14992    |
----------------------------------
Eval num_timesteps=100000, episode_reward=175.08 +/- 45.20
Episode length: 44.12 +/- 11.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.771    |
| time/               |          |
|    total_timesteps  | 100000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0162   |
|    n_updates        | 14999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.769    |
| time/               |          |
|    episodes         | 1372     |
|    fps              | 92       |
|    time_elapsed     | 1086     |
|    total_timesteps  | 100325   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.383    |
|    n_updates        | 15081    |
----------------------------------
Eval num_timesteps=100500, episode_reward=191.14 +/- 50.99
Episode length: 48.24 +/- 12.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.2     |
|    mean_reward      | 191      |
| rollout/            |          |
|    exploration_rate | 0.768    |
| time/               |          |
|    total_timesteps  | 100500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0437   |
|    n_updates        | 15124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.766    |
| time/               |          |
|    episodes         | 1376     |
|    fps              | 92       |
|    time_elapsed     | 1091     |
|    total_timesteps  | 100748   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0361   |
|    n_updates        | 15186    |
----------------------------------
Eval num_timesteps=101000, episode_reward=217.46 +/- 97.35
Episode length: 54.72 +/- 24.29
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.7     |
|    mean_reward      | 217      |
| rollout/            |          |
|    exploration_rate | 0.765    |
| time/               |          |
|    total_timesteps  | 101000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.657    |
|    n_updates        | 15249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.764    |
| time/               |          |
|    episodes         | 1380     |
|    fps              | 92       |
|    time_elapsed     | 1097     |
|    total_timesteps  | 101113   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.322    |
|    n_updates        | 15278    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.3     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.763    |
| time/               |          |
|    episodes         | 1384     |
|    fps              | 92       |
|    time_elapsed     | 1097     |
|    total_timesteps  | 101305   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.345    |
|    n_updates        | 15326    |
----------------------------------
Eval num_timesteps=101500, episode_reward=228.70 +/- 46.58
Episode length: 57.56 +/- 11.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.6     |
|    mean_reward      | 229      |
| rollout/            |          |
|    exploration_rate | 0.762    |
| time/               |          |
|    total_timesteps  | 101500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.397    |
|    n_updates        | 15374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | 295      |
|    exploration_rate | 0.761    |
| time/               |          |
|    episodes         | 1388     |
|    fps              | 92       |
|    time_elapsed     | 1103     |
|    total_timesteps  | 101576   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0303   |
|    n_updates        | 15393    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.76     |
| time/               |          |
|    episodes         | 1392     |
|    fps              | 92       |
|    time_elapsed     | 1103     |
|    total_timesteps  | 101850   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0598   |
|    n_updates        | 15462    |
----------------------------------
Eval num_timesteps=102000, episode_reward=182.92 +/- 48.21
Episode length: 46.12 +/- 12.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.759    |
| time/               |          |
|    total_timesteps  | 102000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.344    |
|    n_updates        | 15499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.759    |
| time/               |          |
|    episodes         | 1396     |
|    fps              | 92       |
|    time_elapsed     | 1108     |
|    total_timesteps  | 102080   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0159   |
|    n_updates        | 15519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.756    |
| time/               |          |
|    episodes         | 1400     |
|    fps              | 92       |
|    time_elapsed     | 1109     |
|    total_timesteps  | 102481   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0172   |
|    n_updates        | 15620    |
----------------------------------
Eval num_timesteps=102500, episode_reward=179.52 +/- 48.60
Episode length: 45.28 +/- 12.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.756    |
| time/               |          |
|    total_timesteps  | 102500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0202   |
|    n_updates        | 15624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.755    |
| time/               |          |
|    episodes         | 1404     |
|    fps              | 92       |
|    time_elapsed     | 1113     |
|    total_timesteps  | 102698   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.00774  |
|    n_updates        | 15674    |
----------------------------------
Eval num_timesteps=103000, episode_reward=246.30 +/- 106.42
Episode length: 62.00 +/- 26.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62       |
|    mean_reward      | 246      |
| rollout/            |          |
|    exploration_rate | 0.753    |
| time/               |          |
|    total_timesteps  | 103000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.632    |
|    n_updates        | 15749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 296      |
|    exploration_rate | 0.753    |
| time/               |          |
|    episodes         | 1408     |
|    fps              | 92       |
|    time_elapsed     | 1119     |
|    total_timesteps  | 103058   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.686    |
|    n_updates        | 15764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.751    |
| time/               |          |
|    episodes         | 1412     |
|    fps              | 92       |
|    time_elapsed     | 1120     |
|    total_timesteps  | 103296   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.363    |
|    n_updates        | 15823    |
----------------------------------
Eval num_timesteps=103500, episode_reward=188.76 +/- 51.67
Episode length: 47.54 +/- 12.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.5     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.75     |
| time/               |          |
|    total_timesteps  | 103500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.06     |
|    n_updates        | 15874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.9     |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.749    |
| time/               |          |
|    episodes         | 1416     |
|    fps              | 92       |
|    time_elapsed     | 1125     |
|    total_timesteps  | 103725   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0171   |
|    n_updates        | 15931    |
----------------------------------
Eval num_timesteps=104000, episode_reward=267.08 +/- 103.61
Episode length: 67.22 +/- 25.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.2     |
|    mean_reward      | 267      |
| rollout/            |          |
|    exploration_rate | 0.747    |
| time/               |          |
|    total_timesteps  | 104000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0152   |
|    n_updates        | 15999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.7     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.746    |
| time/               |          |
|    episodes         | 1420     |
|    fps              | 92       |
|    time_elapsed     | 1131     |
|    total_timesteps  | 104155   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0295   |
|    n_updates        | 16038    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.3     |
|    ep_rew_mean      | 312      |
|    exploration_rate | 0.744    |
| time/               |          |
|    episodes         | 1424     |
|    fps              | 92       |
|    time_elapsed     | 1132     |
|    total_timesteps  | 104478   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.732    |
|    n_updates        | 16119    |
----------------------------------
Eval num_timesteps=104500, episode_reward=172.56 +/- 73.99
Episode length: 43.54 +/- 18.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.5     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.744    |
| time/               |          |
|    total_timesteps  | 104500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.386    |
|    n_updates        | 16124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.1     |
|    ep_rew_mean      | 315      |
|    exploration_rate | 0.742    |
| time/               |          |
|    episodes         | 1428     |
|    fps              | 92       |
|    time_elapsed     | 1137     |
|    total_timesteps  | 104861   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0373   |
|    n_updates        | 16215    |
----------------------------------
Eval num_timesteps=105000, episode_reward=169.30 +/- 48.09
Episode length: 42.66 +/- 12.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.7     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.741    |
| time/               |          |
|    total_timesteps  | 105000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.93     |
|    n_updates        | 16249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.6     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 0.74     |
| time/               |          |
|    episodes         | 1432     |
|    fps              | 92       |
|    time_elapsed     | 1141     |
|    total_timesteps  | 105145   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.7      |
|    n_updates        | 16286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.5     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.739    |
| time/               |          |
|    episodes         | 1436     |
|    fps              | 92       |
|    time_elapsed     | 1142     |
|    total_timesteps  | 105424   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0276   |
|    n_updates        | 16355    |
----------------------------------
Eval num_timesteps=105500, episode_reward=221.70 +/- 54.75
Episode length: 55.80 +/- 13.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.8     |
|    mean_reward      | 222      |
| rollout/            |          |
|    exploration_rate | 0.738    |
| time/               |          |
|    total_timesteps  | 105500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0209   |
|    n_updates        | 16374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 316      |
|    exploration_rate | 0.737    |
| time/               |          |
|    episodes         | 1440     |
|    fps              | 92       |
|    time_elapsed     | 1147     |
|    total_timesteps  | 105784   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0184   |
|    n_updates        | 16445    |
----------------------------------
Eval num_timesteps=106000, episode_reward=185.24 +/- 44.03
Episode length: 46.62 +/- 10.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.6     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.735    |
| time/               |          |
|    total_timesteps  | 106000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.39     |
|    n_updates        | 16499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 319      |
|    exploration_rate | 0.735    |
| time/               |          |
|    episodes         | 1444     |
|    fps              | 92       |
|    time_elapsed     | 1152     |
|    total_timesteps  | 106123   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.364    |
|    n_updates        | 16530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.7     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 0.733    |
| time/               |          |
|    episodes         | 1448     |
|    fps              | 92       |
|    time_elapsed     | 1152     |
|    total_timesteps  | 106443   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.314    |
|    n_updates        | 16610    |
----------------------------------
Eval num_timesteps=106500, episode_reward=188.00 +/- 56.35
Episode length: 47.30 +/- 14.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 0.732    |
| time/               |          |
|    total_timesteps  | 106500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0126   |
|    n_updates        | 16624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.2     |
|    ep_rew_mean      | 315      |
|    exploration_rate | 0.731    |
| time/               |          |
|    episodes         | 1452     |
|    fps              | 92       |
|    time_elapsed     | 1157     |
|    total_timesteps  | 106745   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0346   |
|    n_updates        | 16686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.2     |
|    ep_rew_mean      | 311      |
|    exploration_rate | 0.729    |
| time/               |          |
|    episodes         | 1456     |
|    fps              | 92       |
|    time_elapsed     | 1158     |
|    total_timesteps  | 106968   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0475   |
|    n_updates        | 16741    |
----------------------------------
Eval num_timesteps=107000, episode_reward=196.40 +/- 51.23
Episode length: 49.40 +/- 12.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.4     |
|    mean_reward      | 196      |
| rollout/            |          |
|    exploration_rate | 0.729    |
| time/               |          |
|    total_timesteps  | 107000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.344    |
|    n_updates        | 16749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.8     |
|    ep_rew_mean      | 314      |
|    exploration_rate | 0.727    |
| time/               |          |
|    episodes         | 1460     |
|    fps              | 92       |
|    time_elapsed     | 1163     |
|    total_timesteps  | 107335   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.02     |
|    n_updates        | 16833    |
----------------------------------
Eval num_timesteps=107500, episode_reward=174.94 +/- 55.69
Episode length: 44.08 +/- 13.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.726    |
| time/               |          |
|    total_timesteps  | 107500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.652    |
|    n_updates        | 16874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.7     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.726    |
| time/               |          |
|    episodes         | 1464     |
|    fps              | 92       |
|    time_elapsed     | 1167     |
|    total_timesteps  | 107607   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.329    |
|    n_updates        | 16901    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.5     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.724    |
| time/               |          |
|    episodes         | 1468     |
|    fps              | 92       |
|    time_elapsed     | 1167     |
|    total_timesteps  | 107821   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.71     |
|    n_updates        | 16955    |
----------------------------------
Eval num_timesteps=108000, episode_reward=187.84 +/- 75.82
Episode length: 47.34 +/- 18.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 0.723    |
| time/               |          |
|    total_timesteps  | 108000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0266   |
|    n_updates        | 16999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.6     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.723    |
| time/               |          |
|    episodes         | 1472     |
|    fps              | 92       |
|    time_elapsed     | 1172     |
|    total_timesteps  | 108082   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0134   |
|    n_updates        | 17020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 307      |
|    exploration_rate | 0.72     |
| time/               |          |
|    episodes         | 1476     |
|    fps              | 92       |
|    time_elapsed     | 1173     |
|    total_timesteps  | 108451   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0619   |
|    n_updates        | 17112    |
----------------------------------
Eval num_timesteps=108500, episode_reward=180.70 +/- 51.35
Episode length: 45.66 +/- 12.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.7     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.72     |
| time/               |          |
|    total_timesteps  | 108500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0328   |
|    n_updates        | 17124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.719    |
| time/               |          |
|    episodes         | 1480     |
|    fps              | 92       |
|    time_elapsed     | 1178     |
|    total_timesteps  | 108763   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.115    |
|    n_updates        | 17190    |
----------------------------------
Eval num_timesteps=109000, episode_reward=180.96 +/- 67.46
Episode length: 45.62 +/- 16.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.717    |
| time/               |          |
|    total_timesteps  | 109000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.326    |
|    n_updates        | 17249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.6     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.717    |
| time/               |          |
|    episodes         | 1484     |
|    fps              | 92       |
|    time_elapsed     | 1182     |
|    total_timesteps  | 109064   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.347    |
|    n_updates        | 17265    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.8     |
|    ep_rew_mean      | 314      |
|    exploration_rate | 0.714    |
| time/               |          |
|    episodes         | 1488     |
|    fps              | 92       |
|    time_elapsed     | 1183     |
|    total_timesteps  | 109457   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0209   |
|    n_updates        | 17364    |
----------------------------------
Eval num_timesteps=109500, episode_reward=172.54 +/- 37.78
Episode length: 43.58 +/- 9.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.714    |
| time/               |          |
|    total_timesteps  | 109500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.345    |
|    n_updates        | 17374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.2     |
|    ep_rew_mean      | 311      |
|    exploration_rate | 0.713    |
| time/               |          |
|    episodes         | 1492     |
|    fps              | 92       |
|    time_elapsed     | 1187     |
|    total_timesteps  | 109672   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.661    |
|    n_updates        | 17417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.2     |
|    ep_rew_mean      | 315      |
|    exploration_rate | 0.711    |
| time/               |          |
|    episodes         | 1496     |
|    fps              | 92       |
|    time_elapsed     | 1188     |
|    total_timesteps  | 109996   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0144   |
|    n_updates        | 17498    |
----------------------------------
Eval num_timesteps=110000, episode_reward=212.74 +/- 61.13
Episode length: 53.64 +/- 15.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.6     |
|    mean_reward      | 213      |
| rollout/            |          |
|    exploration_rate | 0.711    |
| time/               |          |
|    total_timesteps  | 110000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.05     |
|    n_updates        | 17499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 308      |
|    exploration_rate | 0.71     |
| time/               |          |
|    episodes         | 1500     |
|    fps              | 92       |
|    time_elapsed     | 1193     |
|    total_timesteps  | 110216   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.83     |
|    n_updates        | 17553    |
----------------------------------
Eval num_timesteps=110500, episode_reward=188.04 +/- 47.39
Episode length: 47.36 +/- 11.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.4     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 0.708    |
| time/               |          |
|    total_timesteps  | 110500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0222   |
|    n_updates        | 17624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.3     |
|    ep_rew_mean      | 316      |
|    exploration_rate | 0.707    |
| time/               |          |
|    episodes         | 1504     |
|    fps              | 92       |
|    time_elapsed     | 1198     |
|    total_timesteps  | 110626   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.236    |
|    n_updates        | 17656    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 310      |
|    exploration_rate | 0.706    |
| time/               |          |
|    episodes         | 1508     |
|    fps              | 92       |
|    time_elapsed     | 1199     |
|    total_timesteps  | 110839   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.403    |
|    n_updates        | 17709    |
----------------------------------
Eval num_timesteps=111000, episode_reward=174.88 +/- 43.26
Episode length: 44.10 +/- 10.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.705    |
| time/               |          |
|    total_timesteps  | 111000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.37     |
|    n_updates        | 17749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 316      |
|    exploration_rate | 0.703    |
| time/               |          |
|    episodes         | 1512     |
|    fps              | 92       |
|    time_elapsed     | 1203     |
|    total_timesteps  | 111243   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.385    |
|    n_updates        | 17810    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.7     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.702    |
| time/               |          |
|    episodes         | 1516     |
|    fps              | 92       |
|    time_elapsed     | 1204     |
|    total_timesteps  | 111490   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.204    |
|    n_updates        | 17872    |
----------------------------------
Eval num_timesteps=111500, episode_reward=176.30 +/- 59.76
Episode length: 44.56 +/- 14.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.6     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.702    |
| time/               |          |
|    total_timesteps  | 111500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.49     |
|    n_updates        | 17874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.4     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.7      |
| time/               |          |
|    episodes         | 1520     |
|    fps              | 92       |
|    time_elapsed     | 1208     |
|    total_timesteps  | 111799   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.395    |
|    n_updates        | 17949    |
----------------------------------
Eval num_timesteps=112000, episode_reward=188.74 +/- 62.41
Episode length: 47.60 +/- 15.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.6     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.698    |
| time/               |          |
|    total_timesteps  | 112000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.861    |
|    n_updates        | 17999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.698    |
| time/               |          |
|    episodes         | 1524     |
|    fps              | 92       |
|    time_elapsed     | 1213     |
|    total_timesteps  | 112032   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0223   |
|    n_updates        | 18007    |
----------------------------------
Eval num_timesteps=112500, episode_reward=179.48 +/- 51.17
Episode length: 45.28 +/- 12.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.695    |
| time/               |          |
|    total_timesteps  | 112500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.773    |
|    n_updates        | 18124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.695    |
| time/               |          |
|    episodes         | 1528     |
|    fps              | 92       |
|    time_elapsed     | 1218     |
|    total_timesteps  | 112510   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0172   |
|    n_updates        | 18127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.5     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.693    |
| time/               |          |
|    episodes         | 1532     |
|    fps              | 92       |
|    time_elapsed     | 1220     |
|    total_timesteps  | 112896   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.38     |
|    n_updates        | 18223    |
----------------------------------
Eval num_timesteps=113000, episode_reward=181.62 +/- 47.33
Episode length: 45.80 +/- 11.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.8     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.692    |
| time/               |          |
|    total_timesteps  | 113000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.404    |
|    n_updates        | 18249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.1     |
|    ep_rew_mean      | 307      |
|    exploration_rate | 0.691    |
| time/               |          |
|    episodes         | 1536     |
|    fps              | 92       |
|    time_elapsed     | 1224     |
|    total_timesteps  | 113136   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0183   |
|    n_updates        | 18283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.689    |
| time/               |          |
|    episodes         | 1540     |
|    fps              | 92       |
|    time_elapsed     | 1225     |
|    total_timesteps  | 113439   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0306   |
|    n_updates        | 18359    |
----------------------------------
Eval num_timesteps=113500, episode_reward=178.64 +/- 45.55
Episode length: 45.02 +/- 11.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.689    |
| time/               |          |
|    total_timesteps  | 113500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0384   |
|    n_updates        | 18374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.687    |
| time/               |          |
|    episodes         | 1544     |
|    fps              | 92       |
|    time_elapsed     | 1230     |
|    total_timesteps  | 113749   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.43     |
|    n_updates        | 18437    |
----------------------------------
Eval num_timesteps=114000, episode_reward=179.94 +/- 41.28
Episode length: 45.40 +/- 10.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.686    |
| time/               |          |
|    total_timesteps  | 114000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.449    |
|    n_updates        | 18499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 306      |
|    exploration_rate | 0.685    |
| time/               |          |
|    episodes         | 1548     |
|    fps              | 92       |
|    time_elapsed     | 1236     |
|    total_timesteps  | 114143   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.416    |
|    n_updates        | 18535    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.9     |
|    ep_rew_mean      | 306      |
|    exploration_rate | 0.683    |
| time/               |          |
|    episodes         | 1552     |
|    fps              | 92       |
|    time_elapsed     | 1237     |
|    total_timesteps  | 114435   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.751    |
|    n_updates        | 18608    |
----------------------------------
Eval num_timesteps=114500, episode_reward=189.36 +/- 52.36
Episode length: 47.70 +/- 13.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.7     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.683    |
| time/               |          |
|    total_timesteps  | 114500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.421    |
|    n_updates        | 18624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78       |
|    ep_rew_mean      | 310      |
|    exploration_rate | 0.681    |
| time/               |          |
|    episodes         | 1556     |
|    fps              | 92       |
|    time_elapsed     | 1242     |
|    total_timesteps  | 114768   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0272   |
|    n_updates        | 18691    |
----------------------------------
Eval num_timesteps=115000, episode_reward=164.52 +/- 55.87
Episode length: 41.48 +/- 13.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.5     |
|    mean_reward      | 165      |
| rollout/            |          |
|    exploration_rate | 0.679    |
| time/               |          |
|    total_timesteps  | 115000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.08     |
|    n_updates        | 18749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.7     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.679    |
| time/               |          |
|    episodes         | 1560     |
|    fps              | 92       |
|    time_elapsed     | 1246     |
|    total_timesteps  | 115109   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0207   |
|    n_updates        | 18777    |
----------------------------------
Eval num_timesteps=115500, episode_reward=181.98 +/- 54.82
Episode length: 45.88 +/- 13.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.676    |
| time/               |          |
|    total_timesteps  | 115500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0255   |
|    n_updates        | 18874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.6     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 0.676    |
| time/               |          |
|    episodes         | 1564     |
|    fps              | 92       |
|    time_elapsed     | 1251     |
|    total_timesteps  | 115571   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.395    |
|    n_updates        | 18892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.5     |
|    ep_rew_mean      | 321      |
|    exploration_rate | 0.674    |
| time/               |          |
|    episodes         | 1568     |
|    fps              | 92       |
|    time_elapsed     | 1252     |
|    total_timesteps  | 115874   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0172   |
|    n_updates        | 18968    |
----------------------------------
Eval num_timesteps=116000, episode_reward=182.46 +/- 58.50
Episode length: 45.94 +/- 14.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.673    |
| time/               |          |
|    total_timesteps  | 116000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.38     |
|    n_updates        | 18999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.4     |
|    ep_rew_mean      | 328      |
|    exploration_rate | 0.671    |
| time/               |          |
|    episodes         | 1572     |
|    fps              | 92       |
|    time_elapsed     | 1257     |
|    total_timesteps  | 116320   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0336   |
|    n_updates        | 19079    |
----------------------------------
Eval num_timesteps=116500, episode_reward=181.02 +/- 54.06
Episode length: 45.62 +/- 13.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.67     |
| time/               |          |
|    total_timesteps  | 116500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0174   |
|    n_updates        | 19124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.2     |
|    ep_rew_mean      | 323      |
|    exploration_rate | 0.669    |
| time/               |          |
|    episodes         | 1576     |
|    fps              | 92       |
|    time_elapsed     | 1261     |
|    total_timesteps  | 116569   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0391   |
|    n_updates        | 19142    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.2     |
|    ep_rew_mean      | 327      |
|    exploration_rate | 0.667    |
| time/               |          |
|    episodes         | 1580     |
|    fps              | 92       |
|    time_elapsed     | 1262     |
|    total_timesteps  | 116987   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0561   |
|    n_updates        | 19246    |
----------------------------------
Eval num_timesteps=117000, episode_reward=178.62 +/- 49.19
Episode length: 45.02 +/- 12.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.666    |
| time/               |          |
|    total_timesteps  | 117000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.714    |
|    n_updates        | 19249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.4     |
|    ep_rew_mean      | 332      |
|    exploration_rate | 0.664    |
| time/               |          |
|    episodes         | 1584     |
|    fps              | 92       |
|    time_elapsed     | 1267     |
|    total_timesteps  | 117402   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.11     |
|    n_updates        | 19350    |
----------------------------------
Eval num_timesteps=117500, episode_reward=156.22 +/- 52.22
Episode length: 39.38 +/- 13.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.4     |
|    mean_reward      | 156      |
| rollout/            |          |
|    exploration_rate | 0.663    |
| time/               |          |
|    total_timesteps  | 117500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.794    |
|    n_updates        | 19374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.4     |
|    ep_rew_mean      | 328      |
|    exploration_rate | 0.662    |
| time/               |          |
|    episodes         | 1588     |
|    fps              | 92       |
|    time_elapsed     | 1271     |
|    total_timesteps  | 117695   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.432    |
|    n_updates        | 19423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.1     |
|    ep_rew_mean      | 331      |
|    exploration_rate | 0.66     |
| time/               |          |
|    episodes         | 1592     |
|    fps              | 92       |
|    time_elapsed     | 1272     |
|    total_timesteps  | 117982   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0195   |
|    n_updates        | 19495    |
----------------------------------
Eval num_timesteps=118000, episode_reward=168.98 +/- 44.89
Episode length: 42.56 +/- 11.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.66     |
| time/               |          |
|    total_timesteps  | 118000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0178   |
|    n_updates        | 19499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.7     |
|    ep_rew_mean      | 329      |
|    exploration_rate | 0.658    |
| time/               |          |
|    episodes         | 1596     |
|    fps              | 92       |
|    time_elapsed     | 1276     |
|    total_timesteps  | 118267   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.383    |
|    n_updates        | 19566    |
----------------------------------
Eval num_timesteps=118500, episode_reward=186.36 +/- 77.16
Episode length: 46.92 +/- 19.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.9     |
|    mean_reward      | 186      |
| rollout/            |          |
|    exploration_rate | 0.657    |
| time/               |          |
|    total_timesteps  | 118500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.774    |
|    n_updates        | 19624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.5     |
|    ep_rew_mean      | 333      |
|    exploration_rate | 0.656    |
| time/               |          |
|    episodes         | 1600     |
|    fps              | 92       |
|    time_elapsed     | 1281     |
|    total_timesteps  | 118570   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0163   |
|    n_updates        | 19642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.8     |
|    ep_rew_mean      | 330      |
|    exploration_rate | 0.654    |
| time/               |          |
|    episodes         | 1604     |
|    fps              | 92       |
|    time_elapsed     | 1282     |
|    total_timesteps  | 118903   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.592    |
|    n_updates        | 19725    |
----------------------------------
Eval num_timesteps=119000, episode_reward=218.96 +/- 94.82
Episode length: 55.10 +/- 23.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.1     |
|    mean_reward      | 219      |
| rollout/            |          |
|    exploration_rate | 0.653    |
| time/               |          |
|    total_timesteps  | 119000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.362    |
|    n_updates        | 19749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.6     |
|    ep_rew_mean      | 329      |
|    exploration_rate | 0.653    |
| time/               |          |
|    episodes         | 1608     |
|    fps              | 92       |
|    time_elapsed     | 1287     |
|    total_timesteps  | 119098   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.397    |
|    n_updates        | 19774    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.2     |
|    ep_rew_mean      | 323      |
|    exploration_rate | 0.651    |
| time/               |          |
|    episodes         | 1612     |
|    fps              | 92       |
|    time_elapsed     | 1288     |
|    total_timesteps  | 119364   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0397   |
|    n_updates        | 19840    |
----------------------------------
Eval num_timesteps=119500, episode_reward=183.80 +/- 42.45
Episode length: 46.32 +/- 10.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.3     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.65     |
| time/               |          |
|    total_timesteps  | 119500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0368   |
|    n_updates        | 19874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.7     |
|    ep_rew_mean      | 321      |
|    exploration_rate | 0.65     |
| time/               |          |
|    episodes         | 1616     |
|    fps              | 92       |
|    time_elapsed     | 1292     |
|    total_timesteps  | 119555   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0614   |
|    n_updates        | 19888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.3     |
|    ep_rew_mean      | 319      |
|    exploration_rate | 0.648    |
| time/               |          |
|    episodes         | 1620     |
|    fps              | 92       |
|    time_elapsed     | 1293     |
|    total_timesteps  | 119825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0193   |
|    n_updates        | 19956    |
----------------------------------
Eval num_timesteps=120000, episode_reward=174.40 +/- 60.48
Episode length: 44.02 +/- 15.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44       |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.647    |
| time/               |          |
|    total_timesteps  | 120000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.769    |
|    n_updates        | 19999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80       |
|    ep_rew_mean      | 318      |
|    exploration_rate | 0.647    |
| time/               |          |
|    episodes         | 1624     |
|    fps              | 92       |
|    time_elapsed     | 1298     |
|    total_timesteps  | 120033   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.21     |
|    n_updates        | 20008    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.7     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.645    |
| time/               |          |
|    episodes         | 1628     |
|    fps              | 92       |
|    time_elapsed     | 1299     |
|    total_timesteps  | 120280   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0272   |
|    n_updates        | 20069    |
----------------------------------
Eval num_timesteps=120500, episode_reward=168.44 +/- 55.63
Episode length: 42.46 +/- 13.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.5     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 0.643    |
| time/               |          |
|    total_timesteps  | 120500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0259   |
|    n_updates        | 20124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.643    |
| time/               |          |
|    episodes         | 1632     |
|    fps              | 92       |
|    time_elapsed     | 1303     |
|    total_timesteps  | 120515   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0226   |
|    n_updates        | 20128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.9     |
|    ep_rew_mean      | 306      |
|    exploration_rate | 0.641    |
| time/               |          |
|    episodes         | 1636     |
|    fps              | 92       |
|    time_elapsed     | 1304     |
|    total_timesteps  | 120828   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.447    |
|    n_updates        | 20206    |
----------------------------------
Eval num_timesteps=121000, episode_reward=168.12 +/- 51.01
Episode length: 42.36 +/- 12.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.4     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 0.64     |
| time/               |          |
|    total_timesteps  | 121000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0504   |
|    n_updates        | 20249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.64     |
| time/               |          |
|    episodes         | 1640     |
|    fps              | 92       |
|    time_elapsed     | 1308     |
|    total_timesteps  | 121067   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.037    |
|    n_updates        | 20266    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.1     |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.638    |
| time/               |          |
|    episodes         | 1644     |
|    fps              | 92       |
|    time_elapsed     | 1309     |
|    total_timesteps  | 121359   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.423    |
|    n_updates        | 20339    |
----------------------------------
Eval num_timesteps=121500, episode_reward=225.90 +/- 78.10
Episode length: 56.86 +/- 19.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.9     |
|    mean_reward      | 226      |
| rollout/            |          |
|    exploration_rate | 0.637    |
| time/               |          |
|    total_timesteps  | 121500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.43     |
|    n_updates        | 20374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.6     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.635    |
| time/               |          |
|    episodes         | 1648     |
|    fps              | 92       |
|    time_elapsed     | 1315     |
|    total_timesteps  | 121801   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0443   |
|    n_updates        | 20450    |
----------------------------------
Eval num_timesteps=122000, episode_reward=233.88 +/- 86.99
Episode length: 58.86 +/- 21.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.9     |
|    mean_reward      | 234      |
| rollout/            |          |
|    exploration_rate | 0.633    |
| time/               |          |
|    total_timesteps  | 122000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.849    |
|    n_updates        | 20499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.4     |
|    ep_rew_mean      | 308      |
|    exploration_rate | 0.632    |
| time/               |          |
|    episodes         | 1652     |
|    fps              | 92       |
|    time_elapsed     | 1321     |
|    total_timesteps  | 122176   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.3      |
|    n_updates        | 20543    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 308      |
|    exploration_rate | 0.63     |
| time/               |          |
|    episodes         | 1656     |
|    fps              | 92       |
|    time_elapsed     | 1322     |
|    total_timesteps  | 122497   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.902    |
|    n_updates        | 20624    |
----------------------------------
Eval num_timesteps=122500, episode_reward=159.94 +/- 44.97
Episode length: 40.36 +/- 11.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.4     |
|    mean_reward      | 160      |
| rollout/            |          |
|    exploration_rate | 0.63     |
| time/               |          |
|    total_timesteps  | 122500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 307      |
|    exploration_rate | 0.628    |
| time/               |          |
|    episodes         | 1660     |
|    fps              | 92       |
|    time_elapsed     | 1327     |
|    total_timesteps  | 122828   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.472    |
|    n_updates        | 20706    |
----------------------------------
Eval num_timesteps=123000, episode_reward=179.42 +/- 53.11
Episode length: 45.28 +/- 13.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.627    |
| time/               |          |
|    total_timesteps  | 123000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.838    |
|    n_updates        | 20749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.627    |
| time/               |          |
|    episodes         | 1664     |
|    fps              | 92       |
|    time_elapsed     | 1331     |
|    total_timesteps  | 123029   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.46     |
|    n_updates        | 20757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.624    |
| time/               |          |
|    episodes         | 1668     |
|    fps              | 92       |
|    time_elapsed     | 1332     |
|    total_timesteps  | 123445   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.511    |
|    n_updates        | 20861    |
----------------------------------
Eval num_timesteps=123500, episode_reward=171.48 +/- 44.86
Episode length: 43.26 +/- 11.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.3     |
|    mean_reward      | 171      |
| rollout/            |          |
|    exploration_rate | 0.623    |
| time/               |          |
|    total_timesteps  | 123500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.611    |
|    n_updates        | 20874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.622    |
| time/               |          |
|    episodes         | 1672     |
|    fps              | 92       |
|    time_elapsed     | 1336     |
|    total_timesteps  | 123632   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.31     |
|    n_updates        | 20907    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.621    |
| time/               |          |
|    episodes         | 1676     |
|    fps              | 92       |
|    time_elapsed     | 1337     |
|    total_timesteps  | 123858   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.481    |
|    n_updates        | 20964    |
----------------------------------
Eval num_timesteps=124000, episode_reward=231.30 +/- 107.66
Episode length: 58.22 +/- 26.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.2     |
|    mean_reward      | 231      |
| rollout/            |          |
|    exploration_rate | 0.62     |
| time/               |          |
|    total_timesteps  | 124000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.429    |
|    n_updates        | 20999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.8     |
|    ep_rew_mean      | 286      |
|    exploration_rate | 0.619    |
| time/               |          |
|    episodes         | 1680     |
|    fps              | 92       |
|    time_elapsed     | 1343     |
|    total_timesteps  | 124164   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.498    |
|    n_updates        | 21040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.7     |
|    ep_rew_mean      | 281      |
|    exploration_rate | 0.617    |
| time/               |          |
|    episodes         | 1684     |
|    fps              | 92       |
|    time_elapsed     | 1344     |
|    total_timesteps  | 124467   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0277   |
|    n_updates        | 21116    |
----------------------------------
Eval num_timesteps=124500, episode_reward=183.46 +/- 44.68
Episode length: 46.24 +/- 11.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.2     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.617    |
| time/               |          |
|    total_timesteps  | 124500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.422    |
|    n_updates        | 21124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 0.614    |
| time/               |          |
|    episodes         | 1688     |
|    fps              | 92       |
|    time_elapsed     | 1349     |
|    total_timesteps  | 124850   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.428    |
|    n_updates        | 21212    |
----------------------------------
Eval num_timesteps=125000, episode_reward=176.16 +/- 48.98
Episode length: 44.40 +/- 12.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.613    |
| time/               |          |
|    total_timesteps  | 125000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.451    |
|    n_updates        | 21249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.7     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 0.612    |
| time/               |          |
|    episodes         | 1692     |
|    fps              | 92       |
|    time_elapsed     | 1353     |
|    total_timesteps  | 125154   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.43     |
|    n_updates        | 21288    |
----------------------------------
Eval num_timesteps=125500, episode_reward=173.16 +/- 69.74
Episode length: 43.70 +/- 17.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.7     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.61     |
| time/               |          |
|    total_timesteps  | 125500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.3      |
|    n_updates        | 21374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 0.609    |
| time/               |          |
|    episodes         | 1696     |
|    fps              | 92       |
|    time_elapsed     | 1358     |
|    total_timesteps  | 125542   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.438    |
|    n_updates        | 21385    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.607    |
| time/               |          |
|    episodes         | 1700     |
|    fps              | 92       |
|    time_elapsed     | 1359     |
|    total_timesteps  | 125853   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.023    |
|    n_updates        | 21463    |
----------------------------------
Eval num_timesteps=126000, episode_reward=199.30 +/- 59.36
Episode length: 50.20 +/- 14.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.2     |
|    mean_reward      | 199      |
| rollout/            |          |
|    exploration_rate | 0.606    |
| time/               |          |
|    total_timesteps  | 126000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.44     |
|    n_updates        | 21499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 0.605    |
| time/               |          |
|    episodes         | 1704     |
|    fps              | 92       |
|    time_elapsed     | 1364     |
|    total_timesteps  | 126152   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.899    |
|    n_updates        | 21537    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.603    |
| time/               |          |
|    episodes         | 1708     |
|    fps              | 92       |
|    time_elapsed     | 1365     |
|    total_timesteps  | 126429   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.484    |
|    n_updates        | 21607    |
----------------------------------
Eval num_timesteps=126500, episode_reward=290.50 +/- 136.80
Episode length: 72.96 +/- 34.24
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73       |
|    mean_reward      | 290      |
| rollout/            |          |
|    exploration_rate | 0.603    |
| time/               |          |
|    total_timesteps  | 126500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0443   |
|    n_updates        | 21624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 0.602    |
| time/               |          |
|    episodes         | 1712     |
|    fps              | 92       |
|    time_elapsed     | 1371     |
|    total_timesteps  | 126626   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.863    |
|    n_updates        | 21656    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.6      |
| time/               |          |
|    episodes         | 1716     |
|    fps              | 92       |
|    time_elapsed     | 1372     |
|    total_timesteps  | 126922   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.827    |
|    n_updates        | 21730    |
----------------------------------
Eval num_timesteps=127000, episode_reward=230.20 +/- 80.43
Episode length: 57.96 +/- 20.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58       |
|    mean_reward      | 230      |
| rollout/            |          |
|    exploration_rate | 0.599    |
| time/               |          |
|    total_timesteps  | 127000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0338   |
|    n_updates        | 21749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.598    |
| time/               |          |
|    episodes         | 1720     |
|    fps              | 92       |
|    time_elapsed     | 1377     |
|    total_timesteps  | 127214   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0304   |
|    n_updates        | 21803    |
----------------------------------
Eval num_timesteps=127500, episode_reward=175.34 +/- 41.09
Episode length: 44.22 +/- 10.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.596    |
| time/               |          |
|    total_timesteps  | 127500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.27     |
|    n_updates        | 21874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.9     |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.595    |
| time/               |          |
|    episodes         | 1724     |
|    fps              | 92       |
|    time_elapsed     | 1382     |
|    total_timesteps  | 127623   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.466    |
|    n_updates        | 21905    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.594    |
| time/               |          |
|    episodes         | 1728     |
|    fps              | 92       |
|    time_elapsed     | 1383     |
|    total_timesteps  | 127825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.055    |
|    n_updates        | 21956    |
----------------------------------
Eval num_timesteps=128000, episode_reward=169.78 +/- 44.30
Episode length: 42.80 +/- 11.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.593    |
| time/               |          |
|    total_timesteps  | 128000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.29     |
|    n_updates        | 21999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76       |
|    ep_rew_mean      | 303      |
|    exploration_rate | 0.592    |
| time/               |          |
|    episodes         | 1732     |
|    fps              | 92       |
|    time_elapsed     | 1387     |
|    total_timesteps  | 128118   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.827    |
|    n_updates        | 22029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 305      |
|    exploration_rate | 0.589    |
| time/               |          |
|    episodes         | 1736     |
|    fps              | 92       |
|    time_elapsed     | 1388     |
|    total_timesteps  | 128494   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.517    |
|    n_updates        | 22123    |
----------------------------------
Eval num_timesteps=128500, episode_reward=282.42 +/- 139.46
Episode length: 71.04 +/- 34.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71       |
|    mean_reward      | 282      |
| rollout/            |          |
|    exploration_rate | 0.589    |
| time/               |          |
|    total_timesteps  | 128500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0155   |
|    n_updates        | 22124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 308      |
|    exploration_rate | 0.587    |
| time/               |          |
|    episodes         | 1740     |
|    fps              | 92       |
|    time_elapsed     | 1395     |
|    total_timesteps  | 128798   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0471   |
|    n_updates        | 22199    |
----------------------------------
Eval num_timesteps=129000, episode_reward=187.98 +/- 55.09
Episode length: 47.34 +/- 13.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 0.586    |
| time/               |          |
|    total_timesteps  | 129000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0479   |
|    n_updates        | 22249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 306      |
|    exploration_rate | 0.585    |
| time/               |          |
|    episodes         | 1744     |
|    fps              | 92       |
|    time_elapsed     | 1399     |
|    total_timesteps  | 129058   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0515   |
|    n_updates        | 22264    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76       |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.583    |
| time/               |          |
|    episodes         | 1748     |
|    fps              | 92       |
|    time_elapsed     | 1400     |
|    total_timesteps  | 129400   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.831    |
|    n_updates        | 22349    |
----------------------------------
Eval num_timesteps=129500, episode_reward=166.98 +/- 38.20
Episode length: 42.12 +/- 9.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.1     |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.582    |
| time/               |          |
|    total_timesteps  | 129500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0564   |
|    n_updates        | 22374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.3     |
|    ep_rew_mean      | 300      |
|    exploration_rate | 0.581    |
| time/               |          |
|    episodes         | 1752     |
|    fps              | 92       |
|    time_elapsed     | 1405     |
|    total_timesteps  | 129707   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.821    |
|    n_updates        | 22426    |
----------------------------------
Eval num_timesteps=130000, episode_reward=177.34 +/- 44.58
Episode length: 44.70 +/- 11.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.7     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 0.579    |
| time/               |          |
|    total_timesteps  | 130000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.892    |
|    n_updates        | 22499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.4     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.578    |
| time/               |          |
|    episodes         | 1756     |
|    fps              | 92       |
|    time_elapsed     | 1410     |
|    total_timesteps  | 130140   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.724    |
|    n_updates        | 22534    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.575    |
| time/               |          |
|    episodes         | 1760     |
|    fps              | 92       |
|    time_elapsed     | 1411     |
|    total_timesteps  | 130459   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0228   |
|    n_updates        | 22614    |
----------------------------------
Eval num_timesteps=130500, episode_reward=243.82 +/- 123.65
Episode length: 61.28 +/- 30.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.3     |
|    mean_reward      | 244      |
| rollout/            |          |
|    exploration_rate | 0.575    |
| time/               |          |
|    total_timesteps  | 130500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1        |
|    n_updates        | 22624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 0.572    |
| time/               |          |
|    episodes         | 1764     |
|    fps              | 92       |
|    time_elapsed     | 1418     |
|    total_timesteps  | 130984   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.49     |
|    n_updates        | 22745    |
----------------------------------
Eval num_timesteps=131000, episode_reward=161.38 +/- 32.93
Episode length: 40.70 +/- 8.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.7     |
|    mean_reward      | 161      |
| rollout/            |          |
|    exploration_rate | 0.572    |
| time/               |          |
|    total_timesteps  | 131000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.714    |
|    n_updates        | 22749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.6     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.569    |
| time/               |          |
|    episodes         | 1768     |
|    fps              | 92       |
|    time_elapsed     | 1422     |
|    total_timesteps  | 131306   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0575   |
|    n_updates        | 22826    |
----------------------------------
Eval num_timesteps=131500, episode_reward=171.14 +/- 57.47
Episode length: 43.18 +/- 14.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.2     |
|    mean_reward      | 171      |
| rollout/            |          |
|    exploration_rate | 0.568    |
| time/               |          |
|    total_timesteps  | 131500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.9      |
|    n_updates        | 22874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.7     |
|    ep_rew_mean      | 325      |
|    exploration_rate | 0.566    |
| time/               |          |
|    episodes         | 1772     |
|    fps              | 92       |
|    time_elapsed     | 1427     |
|    total_timesteps  | 131806   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.4      |
|    n_updates        | 22951    |
----------------------------------
Eval num_timesteps=132000, episode_reward=160.36 +/- 39.72
Episode length: 40.50 +/- 9.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.5     |
|    mean_reward      | 160      |
| rollout/            |          |
|    exploration_rate | 0.564    |
| time/               |          |
|    total_timesteps  | 132000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0254   |
|    n_updates        | 22999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.2     |
|    ep_rew_mean      | 327      |
|    exploration_rate | 0.564    |
| time/               |          |
|    episodes         | 1776     |
|    fps              | 92       |
|    time_elapsed     | 1432     |
|    total_timesteps  | 132081   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.523    |
|    n_updates        | 23020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.7     |
|    ep_rew_mean      | 329      |
|    exploration_rate | 0.561    |
| time/               |          |
|    episodes         | 1780     |
|    fps              | 92       |
|    time_elapsed     | 1432     |
|    total_timesteps  | 132432   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.041    |
|    n_updates        | 23107    |
----------------------------------
Eval num_timesteps=132500, episode_reward=175.32 +/- 44.51
Episode length: 44.18 +/- 11.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.561    |
| time/               |          |
|    total_timesteps  | 132500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.951    |
|    n_updates        | 23124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.5     |
|    ep_rew_mean      | 325      |
|    exploration_rate | 0.56     |
| time/               |          |
|    episodes         | 1784     |
|    fps              | 92       |
|    time_elapsed     | 1437     |
|    total_timesteps  | 132620   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.511    |
|    n_updates        | 23154    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.9     |
|    ep_rew_mean      | 318      |
|    exploration_rate | 0.558    |
| time/               |          |
|    episodes         | 1788     |
|    fps              | 92       |
|    time_elapsed     | 1437     |
|    total_timesteps  | 132838   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.495    |
|    n_updates        | 23209    |
----------------------------------
Eval num_timesteps=133000, episode_reward=174.16 +/- 53.37
Episode length: 43.94 +/- 13.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.557    |
| time/               |          |
|    total_timesteps  | 133000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.474    |
|    n_updates        | 23249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.6     |
|    ep_rew_mean      | 321      |
|    exploration_rate | 0.556    |
| time/               |          |
|    episodes         | 1792     |
|    fps              | 92       |
|    time_elapsed     | 1443     |
|    total_timesteps  | 133210   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0714   |
|    n_updates        | 23302    |
----------------------------------
Eval num_timesteps=133500, episode_reward=174.14 +/- 71.52
Episode length: 43.88 +/- 17.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.554    |
| time/               |          |
|    total_timesteps  | 133500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0211   |
|    n_updates        | 23374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 319      |
|    exploration_rate | 0.553    |
| time/               |          |
|    episodes         | 1796     |
|    fps              | 92       |
|    time_elapsed     | 1448     |
|    total_timesteps  | 133559   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.965    |
|    n_updates        | 23389    |
----------------------------------
Eval num_timesteps=134000, episode_reward=164.00 +/- 36.85
Episode length: 41.38 +/- 9.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.4     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 0.55     |
| time/               |          |
|    total_timesteps  | 134000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.492    |
|    n_updates        | 23499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.9     |
|    ep_rew_mean      | 326      |
|    exploration_rate | 0.55     |
| time/               |          |
|    episodes         | 1800     |
|    fps              | 92       |
|    time_elapsed     | 1453     |
|    total_timesteps  | 134046   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.506    |
|    n_updates        | 23511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.1     |
|    ep_rew_mean      | 331      |
|    exploration_rate | 0.547    |
| time/               |          |
|    episodes         | 1804     |
|    fps              | 92       |
|    time_elapsed     | 1454     |
|    total_timesteps  | 134458   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0265   |
|    n_updates        | 23614    |
----------------------------------
Eval num_timesteps=134500, episode_reward=172.58 +/- 43.29
Episode length: 43.48 +/- 10.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.5     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.547    |
| time/               |          |
|    total_timesteps  | 134500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.023    |
|    n_updates        | 23624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.2     |
|    ep_rew_mean      | 339      |
|    exploration_rate | 0.543    |
| time/               |          |
|    episodes         | 1808     |
|    fps              | 92       |
|    time_elapsed     | 1459     |
|    total_timesteps  | 134944   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.508    |
|    n_updates        | 23735    |
----------------------------------
Eval num_timesteps=135000, episode_reward=184.10 +/- 45.47
Episode length: 46.42 +/- 11.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.4     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.543    |
| time/               |          |
|    total_timesteps  | 135000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.51     |
|    n_updates        | 23749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.5     |
|    ep_rew_mean      | 352      |
|    exploration_rate | 0.54     |
| time/               |          |
|    episodes         | 1812     |
|    fps              | 92       |
|    time_elapsed     | 1464     |
|    total_timesteps  | 135472   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0345   |
|    n_updates        | 23867    |
----------------------------------
Eval num_timesteps=135500, episode_reward=182.68 +/- 51.77
Episode length: 46.04 +/- 12.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46       |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.539    |
| time/               |          |
|    total_timesteps  | 135500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0272   |
|    n_updates        | 23874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.8     |
|    ep_rew_mean      | 354      |
|    exploration_rate | 0.537    |
| time/               |          |
|    episodes         | 1816     |
|    fps              | 92       |
|    time_elapsed     | 1469     |
|    total_timesteps  | 135797   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.522    |
|    n_updates        | 23949    |
----------------------------------
Eval num_timesteps=136000, episode_reward=173.42 +/- 51.97
Episode length: 43.72 +/- 12.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.7     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.536    |
| time/               |          |
|    total_timesteps  | 136000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.508    |
|    n_updates        | 23999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.5     |
|    ep_rew_mean      | 361      |
|    exploration_rate | 0.534    |
| time/               |          |
|    episodes         | 1820     |
|    fps              | 92       |
|    time_elapsed     | 1474     |
|    total_timesteps  | 136265   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.036    |
|    n_updates        | 24066    |
----------------------------------
Eval num_timesteps=136500, episode_reward=193.46 +/- 70.46
Episode length: 48.78 +/- 17.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.8     |
|    mean_reward      | 193      |
| rollout/            |          |
|    exploration_rate | 0.532    |
| time/               |          |
|    total_timesteps  | 136500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.903    |
|    n_updates        | 24124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.3     |
|    ep_rew_mean      | 356      |
|    exploration_rate | 0.532    |
| time/               |          |
|    episodes         | 1824     |
|    fps              | 92       |
|    time_elapsed     | 1478     |
|    total_timesteps  | 136553   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.513    |
|    n_updates        | 24138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90       |
|    ep_rew_mean      | 359      |
|    exploration_rate | 0.53     |
| time/               |          |
|    episodes         | 1828     |
|    fps              | 92       |
|    time_elapsed     | 1479     |
|    total_timesteps  | 136825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.513    |
|    n_updates        | 24206    |
----------------------------------
Eval num_timesteps=137000, episode_reward=181.96 +/- 42.95
Episode length: 45.92 +/- 10.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.528    |
| time/               |          |
|    total_timesteps  | 137000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.529    |
|    n_updates        | 24249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.7     |
|    ep_rew_mean      | 357      |
|    exploration_rate | 0.528    |
| time/               |          |
|    episodes         | 1832     |
|    fps              | 92       |
|    time_elapsed     | 1484     |
|    total_timesteps  | 137084   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.493    |
|    n_updates        | 24270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.8     |
|    ep_rew_mean      | 354      |
|    exploration_rate | 0.526    |
| time/               |          |
|    episodes         | 1836     |
|    fps              | 92       |
|    time_elapsed     | 1484     |
|    total_timesteps  | 137374   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.36     |
|    n_updates        | 24343    |
----------------------------------
Eval num_timesteps=137500, episode_reward=261.18 +/- 133.51
Episode length: 65.64 +/- 33.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.6     |
|    mean_reward      | 261      |
| rollout/            |          |
|    exploration_rate | 0.525    |
| time/               |          |
|    total_timesteps  | 137500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0472   |
|    n_updates        | 24374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.3     |
|    ep_rew_mean      | 356      |
|    exploration_rate | 0.523    |
| time/               |          |
|    episodes         | 1840     |
|    fps              | 92       |
|    time_elapsed     | 1491     |
|    total_timesteps  | 137727   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0169   |
|    n_updates        | 24431    |
----------------------------------
Eval num_timesteps=138000, episode_reward=180.10 +/- 56.06
Episode length: 45.32 +/- 14.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.521    |
| time/               |          |
|    total_timesteps  | 138000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0404   |
|    n_updates        | 24499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.1     |
|    ep_rew_mean      | 367      |
|    exploration_rate | 0.519    |
| time/               |          |
|    episodes         | 1844     |
|    fps              | 92       |
|    time_elapsed     | 1496     |
|    total_timesteps  | 138271   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.479    |
|    n_updates        | 24567    |
----------------------------------
Eval num_timesteps=138500, episode_reward=285.10 +/- 123.06
Episode length: 71.60 +/- 30.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.6     |
|    mean_reward      | 285      |
| rollout/            |          |
|    exploration_rate | 0.517    |
| time/               |          |
|    total_timesteps  | 138500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0133   |
|    n_updates        | 24624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.9     |
|    ep_rew_mean      | 370      |
|    exploration_rate | 0.516    |
| time/               |          |
|    episodes         | 1848     |
|    fps              | 92       |
|    time_elapsed     | 1503     |
|    total_timesteps  | 138690   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.33     |
|    n_updates        | 24672    |
----------------------------------
Eval num_timesteps=139000, episode_reward=188.82 +/- 44.91
Episode length: 47.62 +/- 11.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.6     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.514    |
| time/               |          |
|    total_timesteps  | 139000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0368   |
|    n_updates        | 24749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.5     |
|    ep_rew_mean      | 373      |
|    exploration_rate | 0.513    |
| time/               |          |
|    episodes         | 1852     |
|    fps              | 92       |
|    time_elapsed     | 1508     |
|    total_timesteps  | 139061   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0338   |
|    n_updates        | 24765    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.5     |
|    ep_rew_mean      | 369      |
|    exploration_rate | 0.511    |
| time/               |          |
|    episodes         | 1856     |
|    fps              | 92       |
|    time_elapsed     | 1509     |
|    total_timesteps  | 139392   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.45     |
|    n_updates        | 24847    |
----------------------------------
Eval num_timesteps=139500, episode_reward=175.00 +/- 48.95
Episode length: 44.14 +/- 12.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.51     |
| time/               |          |
|    total_timesteps  | 139500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.518    |
|    n_updates        | 24874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.8     |
|    ep_rew_mean      | 370      |
|    exploration_rate | 0.508    |
| time/               |          |
|    episodes         | 1860     |
|    fps              | 92       |
|    time_elapsed     | 1513     |
|    total_timesteps  | 139743   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0395   |
|    n_updates        | 24935    |
----------------------------------
Eval num_timesteps=140000, episode_reward=182.76 +/- 71.85
Episode length: 46.10 +/- 17.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.506    |
| time/               |          |
|    total_timesteps  | 140000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.469    |
|    n_updates        | 24999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.9     |
|    ep_rew_mean      | 362      |
|    exploration_rate | 0.506    |
| time/               |          |
|    episodes         | 1864     |
|    fps              | 92       |
|    time_elapsed     | 1518     |
|    total_timesteps  | 140072   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.747    |
|    n_updates        | 25017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.1     |
|    ep_rew_mean      | 363      |
|    exploration_rate | 0.503    |
| time/               |          |
|    episodes         | 1868     |
|    fps              | 92       |
|    time_elapsed     | 1519     |
|    total_timesteps  | 140413   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0356   |
|    n_updates        | 25103    |
----------------------------------
Eval num_timesteps=140500, episode_reward=178.76 +/- 49.52
Episode length: 45.02 +/- 12.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.503    |
| time/               |          |
|    total_timesteps  | 140500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0407   |
|    n_updates        | 25124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89       |
|    ep_rew_mean      | 354      |
|    exploration_rate | 0.501    |
| time/               |          |
|    episodes         | 1872     |
|    fps              | 92       |
|    time_elapsed     | 1524     |
|    total_timesteps  | 140703   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0331   |
|    n_updates        | 25175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.4     |
|    ep_rew_mean      | 352      |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 1876     |
|    fps              | 92       |
|    time_elapsed     | 1524     |
|    total_timesteps  | 140920   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.183    |
|    n_updates        | 25229    |
----------------------------------
Eval num_timesteps=141000, episode_reward=278.46 +/- 141.12
Episode length: 69.98 +/- 35.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70       |
|    mean_reward      | 278      |
| rollout/            |          |
|    exploration_rate | 0.499    |
| time/               |          |
|    total_timesteps  | 141000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.041    |
|    n_updates        | 25249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.1     |
|    ep_rew_mean      | 351      |
|    exploration_rate | 0.497    |
| time/               |          |
|    episodes         | 1880     |
|    fps              | 92       |
|    time_elapsed     | 1532     |
|    total_timesteps  | 141244   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.525    |
|    n_updates        | 25310    |
----------------------------------
Eval num_timesteps=141500, episode_reward=277.46 +/- 166.91
Episode length: 69.72 +/- 41.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.7     |
|    mean_reward      | 277      |
| rollout/            |          |
|    exploration_rate | 0.495    |
| time/               |          |
|    total_timesteps  | 141500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0483   |
|    n_updates        | 25374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.5     |
|    ep_rew_mean      | 356      |
|    exploration_rate | 0.495    |
| time/               |          |
|    episodes         | 1884     |
|    fps              | 91       |
|    time_elapsed     | 1538     |
|    total_timesteps  | 141571   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0267   |
|    n_updates        | 25392    |
----------------------------------
Eval num_timesteps=142000, episode_reward=169.72 +/- 46.31
Episode length: 42.84 +/- 11.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.492    |
| time/               |          |
|    total_timesteps  | 142000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0781   |
|    n_updates        | 25499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.4     |
|    ep_rew_mean      | 368      |
|    exploration_rate | 0.491    |
| time/               |          |
|    episodes         | 1888     |
|    fps              | 91       |
|    time_elapsed     | 1544     |
|    total_timesteps  | 142077   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.03     |
|    n_updates        | 25519    |
----------------------------------
Eval num_timesteps=142500, episode_reward=177.72 +/- 50.70
Episode length: 44.76 +/- 12.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.488    |
| time/               |          |
|    total_timesteps  | 142500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0279   |
|    n_updates        | 25624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.1     |
|    ep_rew_mean      | 371      |
|    exploration_rate | 0.488    |
| time/               |          |
|    episodes         | 1892     |
|    fps              | 91       |
|    time_elapsed     | 1549     |
|    total_timesteps  | 142520   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0334   |
|    n_updates        | 25629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.7     |
|    ep_rew_mean      | 373      |
|    exploration_rate | 0.485    |
| time/               |          |
|    episodes         | 1896     |
|    fps              | 92       |
|    time_elapsed     | 1551     |
|    total_timesteps  | 142924   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.544    |
|    n_updates        | 25730    |
----------------------------------
Eval num_timesteps=143000, episode_reward=213.96 +/- 116.00
Episode length: 53.96 +/- 28.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54       |
|    mean_reward      | 214      |
| rollout/            |          |
|    exploration_rate | 0.484    |
| time/               |          |
|    total_timesteps  | 143000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0287   |
|    n_updates        | 25749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.3     |
|    ep_rew_mean      | 364      |
|    exploration_rate | 0.483    |
| time/               |          |
|    episodes         | 1900     |
|    fps              | 91       |
|    time_elapsed     | 1556     |
|    total_timesteps  | 143173   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.57     |
|    n_updates        | 25793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.5     |
|    ep_rew_mean      | 356      |
|    exploration_rate | 0.481    |
| time/               |          |
|    episodes         | 1904     |
|    fps              | 92       |
|    time_elapsed     | 1557     |
|    total_timesteps  | 143405   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.635    |
|    n_updates        | 25851    |
----------------------------------
Eval num_timesteps=143500, episode_reward=206.70 +/- 67.55
Episode length: 52.04 +/- 16.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52       |
|    mean_reward      | 207      |
| rollout/            |          |
|    exploration_rate | 0.48     |
| time/               |          |
|    total_timesteps  | 143500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.052    |
|    n_updates        | 25874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.7     |
|    ep_rew_mean      | 349      |
|    exploration_rate | 0.479    |
| time/               |          |
|    episodes         | 1908     |
|    fps              | 91       |
|    time_elapsed     | 1565     |
|    total_timesteps  | 143715   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.6      |
|    n_updates        | 25928    |
----------------------------------
Eval num_timesteps=144000, episode_reward=255.92 +/- 89.65
Episode length: 64.34 +/- 22.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.3     |
|    mean_reward      | 256      |
| rollout/            |          |
|    exploration_rate | 0.476    |
| time/               |          |
|    total_timesteps  | 144000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0238   |
|    n_updates        | 25999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.3     |
|    ep_rew_mean      | 344      |
|    exploration_rate | 0.476    |
| time/               |          |
|    episodes         | 1912     |
|    fps              | 91       |
|    time_elapsed     | 1574     |
|    total_timesteps  | 144106   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0356   |
|    n_updates        | 26026    |
----------------------------------
Eval num_timesteps=144500, episode_reward=173.82 +/- 40.76
Episode length: 43.84 +/- 10.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.8     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.473    |
| time/               |          |
|    total_timesteps  | 144500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.546    |
|    n_updates        | 26124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.4     |
|    ep_rew_mean      | 348      |
|    exploration_rate | 0.472    |
| time/               |          |
|    episodes         | 1916     |
|    fps              | 91       |
|    time_elapsed     | 1580     |
|    total_timesteps  | 144533   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0215   |
|    n_updates        | 26133    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.3     |
|    ep_rew_mean      | 340      |
|    exploration_rate | 0.47     |
| time/               |          |
|    episodes         | 1920     |
|    fps              | 91       |
|    time_elapsed     | 1581     |
|    total_timesteps  | 144797   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.994    |
|    n_updates        | 26199    |
----------------------------------
Eval num_timesteps=145000, episode_reward=287.00 +/- 117.72
Episode length: 72.12 +/- 29.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.1     |
|    mean_reward      | 287      |
| rollout/            |          |
|    exploration_rate | 0.469    |
| time/               |          |
|    total_timesteps  | 145000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.653    |
|    n_updates        | 26249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.5     |
|    ep_rew_mean      | 341      |
|    exploration_rate | 0.468    |
| time/               |          |
|    episodes         | 1924     |
|    fps              | 91       |
|    time_elapsed     | 1588     |
|    total_timesteps  | 145102   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0432   |
|    n_updates        | 26275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.5     |
|    ep_rew_mean      | 344      |
|    exploration_rate | 0.465    |
| time/               |          |
|    episodes         | 1928     |
|    fps              | 91       |
|    time_elapsed     | 1589     |
|    total_timesteps  | 145472   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.54     |
|    n_updates        | 26367    |
----------------------------------
Eval num_timesteps=145500, episode_reward=267.44 +/- 161.95
Episode length: 67.22 +/- 40.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.2     |
|    mean_reward      | 267      |
| rollout/            |          |
|    exploration_rate | 0.465    |
| time/               |          |
|    total_timesteps  | 145500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.02     |
|    n_updates        | 26374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.7     |
|    ep_rew_mean      | 345      |
|    exploration_rate | 0.463    |
| time/               |          |
|    episodes         | 1932     |
|    fps              | 91       |
|    time_elapsed     | 1595     |
|    total_timesteps  | 145755   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.026    |
|    n_updates        | 26438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.6     |
|    ep_rew_mean      | 341      |
|    exploration_rate | 0.462    |
| time/               |          |
|    episodes         | 1936     |
|    fps              | 91       |
|    time_elapsed     | 1595     |
|    total_timesteps  | 145932   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.018    |
|    n_updates        | 26482    |
----------------------------------
Eval num_timesteps=146000, episode_reward=175.44 +/- 57.42
Episode length: 44.24 +/- 14.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.461    |
| time/               |          |
|    total_timesteps  | 146000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0584   |
|    n_updates        | 26499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.1     |
|    ep_rew_mean      | 339      |
|    exploration_rate | 0.459    |
| time/               |          |
|    episodes         | 1940     |
|    fps              | 91       |
|    time_elapsed     | 1600     |
|    total_timesteps  | 146241   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.07     |
|    n_updates        | 26560    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.2     |
|    ep_rew_mean      | 327      |
|    exploration_rate | 0.458    |
| time/               |          |
|    episodes         | 1944     |
|    fps              | 91       |
|    time_elapsed     | 1601     |
|    total_timesteps  | 146488   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.567    |
|    n_updates        | 26621    |
----------------------------------
Eval num_timesteps=146500, episode_reward=170.42 +/- 49.66
Episode length: 42.98 +/- 12.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43       |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.457    |
| time/               |          |
|    total_timesteps  | 146500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.542    |
|    n_updates        | 26624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82       |
|    ep_rew_mean      | 327      |
|    exploration_rate | 0.454    |
| time/               |          |
|    episodes         | 1948     |
|    fps              | 91       |
|    time_elapsed     | 1605     |
|    total_timesteps  | 146892   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.499    |
|    n_updates        | 26722    |
----------------------------------
Eval num_timesteps=147000, episode_reward=184.52 +/- 47.91
Episode length: 46.52 +/- 12.01
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.5     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.454    |
| time/               |          |
|    total_timesteps  | 147000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0367   |
|    n_updates        | 26749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81       |
|    ep_rew_mean      | 323      |
|    exploration_rate | 0.452    |
| time/               |          |
|    episodes         | 1952     |
|    fps              | 91       |
|    time_elapsed     | 1610     |
|    total_timesteps  | 147160   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0216   |
|    n_updates        | 26789    |
----------------------------------
Eval num_timesteps=147500, episode_reward=193.04 +/- 67.72
Episode length: 48.62 +/- 16.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.6     |
|    mean_reward      | 193      |
| rollout/            |          |
|    exploration_rate | 0.45     |
| time/               |          |
|    total_timesteps  | 147500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.516    |
|    n_updates        | 26874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.3     |
|    ep_rew_mean      | 324      |
|    exploration_rate | 0.45     |
| time/               |          |
|    episodes         | 1956     |
|    fps              | 91       |
|    time_elapsed     | 1615     |
|    total_timesteps  | 147518   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0262   |
|    n_updates        | 26879    |
----------------------------------
Eval num_timesteps=148000, episode_reward=275.48 +/- 154.18
Episode length: 69.26 +/- 38.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.3     |
|    mean_reward      | 275      |
| rollout/            |          |
|    exploration_rate | 0.446    |
| time/               |          |
|    total_timesteps  | 148000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0398   |
|    n_updates        | 26999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.4     |
|    ep_rew_mean      | 332      |
|    exploration_rate | 0.445    |
| time/               |          |
|    episodes         | 1960     |
|    fps              | 91       |
|    time_elapsed     | 1623     |
|    total_timesteps  | 148081   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.48     |
|    n_updates        | 27020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.5     |
|    ep_rew_mean      | 329      |
|    exploration_rate | 0.444    |
| time/               |          |
|    episodes         | 1964     |
|    fps              | 91       |
|    time_elapsed     | 1623     |
|    total_timesteps  | 148322   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0515   |
|    n_updates        | 27080    |
----------------------------------
Eval num_timesteps=148500, episode_reward=173.64 +/- 42.15
Episode length: 43.76 +/- 10.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.8     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.442    |
| time/               |          |
|    total_timesteps  | 148500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0351   |
|    n_updates        | 27124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.7     |
|    ep_rew_mean      | 325      |
|    exploration_rate | 0.441    |
| time/               |          |
|    episodes         | 1968     |
|    fps              | 91       |
|    time_elapsed     | 1629     |
|    total_timesteps  | 148583   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0376   |
|    n_updates        | 27145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81       |
|    ep_rew_mean      | 323      |
|    exploration_rate | 0.44     |
| time/               |          |
|    episodes         | 1972     |
|    fps              | 91       |
|    time_elapsed     | 1629     |
|    total_timesteps  | 148805   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.544    |
|    n_updates        | 27201    |
----------------------------------
Eval num_timesteps=149000, episode_reward=177.08 +/- 51.26
Episode length: 44.64 +/- 12.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.6     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 0.438    |
| time/               |          |
|    total_timesteps  | 149000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.703    |
|    n_updates        | 27249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82       |
|    ep_rew_mean      | 327      |
|    exploration_rate | 0.437    |
| time/               |          |
|    episodes         | 1976     |
|    fps              | 91       |
|    time_elapsed     | 1635     |
|    total_timesteps  | 149119   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.01     |
|    n_updates        | 27279    |
----------------------------------
Eval num_timesteps=149500, episode_reward=161.02 +/- 36.64
Episode length: 40.58 +/- 9.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.6     |
|    mean_reward      | 161      |
| rollout/            |          |
|    exploration_rate | 0.434    |
| time/               |          |
|    total_timesteps  | 149500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.11     |
|    n_updates        | 27374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.5     |
|    ep_rew_mean      | 333      |
|    exploration_rate | 0.434    |
| time/               |          |
|    episodes         | 1980     |
|    fps              | 91       |
|    time_elapsed     | 1639     |
|    total_timesteps  | 149598   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.031    |
|    n_updates        | 27399    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.1     |
|    ep_rew_mean      | 335      |
|    exploration_rate | 0.431    |
| time/               |          |
|    episodes         | 1984     |
|    fps              | 91       |
|    time_elapsed     | 1640     |
|    total_timesteps  | 149985   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.558    |
|    n_updates        | 27496    |
----------------------------------
Eval num_timesteps=150000, episode_reward=170.48 +/- 55.07
Episode length: 43.02 +/- 13.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43       |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.431    |
| time/               |          |
|    total_timesteps  | 150000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.547    |
|    n_updates        | 27499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.8     |
|    ep_rew_mean      | 326      |
|    exploration_rate | 0.429    |
| time/               |          |
|    episodes         | 1988     |
|    fps              | 91       |
|    time_elapsed     | 1645     |
|    total_timesteps  | 150254   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0302   |
|    n_updates        | 27563    |
----------------------------------
Eval num_timesteps=150500, episode_reward=162.66 +/- 39.32
Episode length: 40.94 +/- 9.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.9     |
|    mean_reward      | 163      |
| rollout/            |          |
|    exploration_rate | 0.427    |
| time/               |          |
|    total_timesteps  | 150500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0358   |
|    n_updates        | 27624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.2     |
|    ep_rew_mean      | 323      |
|    exploration_rate | 0.426    |
| time/               |          |
|    episodes         | 1992     |
|    fps              | 91       |
|    time_elapsed     | 1649     |
|    total_timesteps  | 150641   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.03     |
|    n_updates        | 27660    |
----------------------------------
Eval num_timesteps=151000, episode_reward=291.34 +/- 145.39
Episode length: 73.24 +/- 36.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.2     |
|    mean_reward      | 291      |
| rollout/            |          |
|    exploration_rate | 0.423    |
| time/               |          |
|    total_timesteps  | 151000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.556    |
|    n_updates        | 27749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81       |
|    ep_rew_mean      | 322      |
|    exploration_rate | 0.423    |
| time/               |          |
|    episodes         | 1996     |
|    fps              | 91       |
|    time_elapsed     | 1658     |
|    total_timesteps  | 151024   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.538    |
|    n_updates        | 27755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.1     |
|    ep_rew_mean      | 331      |
|    exploration_rate | 0.419    |
| time/               |          |
|    episodes         | 2000     |
|    fps              | 91       |
|    time_elapsed     | 1660     |
|    total_timesteps  | 151483   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0408   |
|    n_updates        | 27870    |
----------------------------------
Eval num_timesteps=151500, episode_reward=260.02 +/- 122.81
Episode length: 65.40 +/- 30.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.4     |
|    mean_reward      | 260      |
| rollout/            |          |
|    exploration_rate | 0.419    |
| time/               |          |
|    total_timesteps  | 151500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0608   |
|    n_updates        | 27874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.8     |
|    ep_rew_mean      | 334      |
|    exploration_rate | 0.417    |
| time/               |          |
|    episodes         | 2004     |
|    fps              | 90       |
|    time_elapsed     | 1670     |
|    total_timesteps  | 151783   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.585    |
|    n_updates        | 27945    |
----------------------------------
Eval num_timesteps=152000, episode_reward=220.92 +/- 64.28
Episode length: 55.62 +/- 16.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.6     |
|    mean_reward      | 221      |
| rollout/            |          |
|    exploration_rate | 0.415    |
| time/               |          |
|    total_timesteps  | 152000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.025    |
|    n_updates        | 27999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.1     |
|    ep_rew_mean      | 339      |
|    exploration_rate | 0.413    |
| time/               |          |
|    episodes         | 2008     |
|    fps              | 90       |
|    time_elapsed     | 1676     |
|    total_timesteps  | 152226   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.613    |
|    n_updates        | 28056    |
----------------------------------
Eval num_timesteps=152500, episode_reward=185.00 +/- 56.10
Episode length: 46.58 +/- 14.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.6     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.411    |
| time/               |          |
|    total_timesteps  | 152500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.675    |
|    n_updates        | 28124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.7     |
|    ep_rew_mean      | 345      |
|    exploration_rate | 0.409    |
| time/               |          |
|    episodes         | 2012     |
|    fps              | 90       |
|    time_elapsed     | 1681     |
|    total_timesteps  | 152778   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0627   |
|    n_updates        | 28194    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.3     |
|    ep_rew_mean      | 336      |
|    exploration_rate | 0.407    |
| time/               |          |
|    episodes         | 2016     |
|    fps              | 90       |
|    time_elapsed     | 1682     |
|    total_timesteps  | 152966   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.559    |
|    n_updates        | 28241    |
----------------------------------
Eval num_timesteps=153000, episode_reward=176.80 +/- 47.01
Episode length: 44.64 +/- 11.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.6     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 0.407    |
| time/               |          |
|    total_timesteps  | 153000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.64     |
|    n_updates        | 28249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.3     |
|    ep_rew_mean      | 340      |
|    exploration_rate | 0.404    |
| time/               |          |
|    episodes         | 2020     |
|    fps              | 90       |
|    time_elapsed     | 1687     |
|    total_timesteps  | 153330   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.544    |
|    n_updates        | 28332    |
----------------------------------
Eval num_timesteps=153500, episode_reward=194.46 +/- 89.18
Episode length: 49.08 +/- 22.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.1     |
|    mean_reward      | 194      |
| rollout/            |          |
|    exploration_rate | 0.403    |
| time/               |          |
|    total_timesteps  | 153500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.537    |
|    n_updates        | 28374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.5     |
|    ep_rew_mean      | 340      |
|    exploration_rate | 0.402    |
| time/               |          |
|    episodes         | 2024     |
|    fps              | 90       |
|    time_elapsed     | 1692     |
|    total_timesteps  | 153653   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0427   |
|    n_updates        | 28413    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.2     |
|    ep_rew_mean      | 339      |
|    exploration_rate | 0.399    |
| time/               |          |
|    episodes         | 2028     |
|    fps              | 90       |
|    time_elapsed     | 1693     |
|    total_timesteps  | 153990   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.672    |
|    n_updates        | 28497    |
----------------------------------
Eval num_timesteps=154000, episode_reward=268.42 +/- 132.78
Episode length: 67.46 +/- 33.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.5     |
|    mean_reward      | 268      |
| rollout/            |          |
|    exploration_rate | 0.399    |
| time/               |          |
|    total_timesteps  | 154000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0477   |
|    n_updates        | 28499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.1     |
|    ep_rew_mean      | 347      |
|    exploration_rate | 0.396    |
| time/               |          |
|    episodes         | 2032     |
|    fps              | 90       |
|    time_elapsed     | 1701     |
|    total_timesteps  | 154465   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.596    |
|    n_updates        | 28616    |
----------------------------------
Eval num_timesteps=154500, episode_reward=181.20 +/- 43.34
Episode length: 45.66 +/- 10.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.7     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.395    |
| time/               |          |
|    total_timesteps  | 154500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.569    |
|    n_updates        | 28624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.2     |
|    ep_rew_mean      | 359      |
|    exploration_rate | 0.392    |
| time/               |          |
|    episodes         | 2036     |
|    fps              | 90       |
|    time_elapsed     | 1708     |
|    total_timesteps  | 154950   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0525   |
|    n_updates        | 28737    |
----------------------------------
Eval num_timesteps=155000, episode_reward=189.22 +/- 69.34
Episode length: 47.68 +/- 17.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.7     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.391    |
| time/               |          |
|    total_timesteps  | 155000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0509   |
|    n_updates        | 28749    |
----------------------------------
Eval num_timesteps=155500, episode_reward=166.74 +/- 33.34
Episode length: 42.08 +/- 8.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.1     |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.387    |
| time/               |          |
|    total_timesteps  | 155500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.027    |
|    n_updates        | 28874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.9     |
|    ep_rew_mean      | 370      |
|    exploration_rate | 0.387    |
| time/               |          |
|    episodes         | 2040     |
|    fps              | 90       |
|    time_elapsed     | 1723     |
|    total_timesteps  | 155531   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.587    |
|    n_updates        | 28882    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.5     |
|    ep_rew_mean      | 373      |
|    exploration_rate | 0.385    |
| time/               |          |
|    episodes         | 2044     |
|    fps              | 90       |
|    time_elapsed     | 1724     |
|    total_timesteps  | 155841   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0381   |
|    n_updates        | 28960    |
----------------------------------
Eval num_timesteps=156000, episode_reward=254.52 +/- 111.94
Episode length: 64.00 +/- 27.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64       |
|    mean_reward      | 255      |
| rollout/            |          |
|    exploration_rate | 0.383    |
| time/               |          |
|    total_timesteps  | 156000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.584    |
|    n_updates        | 28999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 365      |
|    exploration_rate | 0.383    |
| time/               |          |
|    episodes         | 2048     |
|    fps              | 90       |
|    time_elapsed     | 1733     |
|    total_timesteps  | 156055   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.027    |
|    n_updates        | 29013    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.2     |
|    ep_rew_mean      | 363      |
|    exploration_rate | 0.381    |
| time/               |          |
|    episodes         | 2052     |
|    fps              | 90       |
|    time_elapsed     | 1734     |
|    total_timesteps  | 156279   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.598    |
|    n_updates        | 29069    |
----------------------------------
Eval num_timesteps=156500, episode_reward=183.32 +/- 50.11
Episode length: 46.24 +/- 12.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.2     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.379    |
| time/               |          |
|    total_timesteps  | 156500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.584    |
|    n_updates        | 29124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92       |
|    ep_rew_mean      | 367      |
|    exploration_rate | 0.378    |
| time/               |          |
|    episodes         | 2056     |
|    fps              | 90       |
|    time_elapsed     | 1741     |
|    total_timesteps  | 156723   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.025    |
|    n_updates        | 29180    |
----------------------------------
Eval num_timesteps=157000, episode_reward=180.14 +/- 43.28
Episode length: 45.42 +/- 10.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.375    |
| time/               |          |
|    total_timesteps  | 157000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.09     |
|    n_updates        | 29249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.1     |
|    ep_rew_mean      | 359      |
|    exploration_rate | 0.375    |
| time/               |          |
|    episodes         | 2060     |
|    fps              | 89       |
|    time_elapsed     | 1748     |
|    total_timesteps  | 157093   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0277   |
|    n_updates        | 29273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.9     |
|    ep_rew_mean      | 358      |
|    exploration_rate | 0.373    |
| time/               |          |
|    episodes         | 2064     |
|    fps              | 89       |
|    time_elapsed     | 1749     |
|    total_timesteps  | 157311   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.55     |
|    n_updates        | 29327    |
----------------------------------
Eval num_timesteps=157500, episode_reward=178.36 +/- 57.93
Episode length: 44.98 +/- 14.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.371    |
| time/               |          |
|    total_timesteps  | 157500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.609    |
|    n_updates        | 29374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.2     |
|    ep_rew_mean      | 359      |
|    exploration_rate | 0.37     |
| time/               |          |
|    episodes         | 2068     |
|    fps              | 89       |
|    time_elapsed     | 1756     |
|    total_timesteps  | 157601   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.608    |
|    n_updates        | 29400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.8     |
|    ep_rew_mean      | 366      |
|    exploration_rate | 0.367    |
| time/               |          |
|    episodes         | 2072     |
|    fps              | 89       |
|    time_elapsed     | 1758     |
|    total_timesteps  | 157982   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0303   |
|    n_updates        | 29495    |
----------------------------------
Eval num_timesteps=158000, episode_reward=170.12 +/- 57.27
Episode length: 42.88 +/- 14.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.367    |
| time/               |          |
|    total_timesteps  | 158000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.596    |
|    n_updates        | 29499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.8     |
|    ep_rew_mean      | 362      |
|    exploration_rate | 0.366    |
| time/               |          |
|    episodes         | 2076     |
|    fps              | 89       |
|    time_elapsed     | 1765     |
|    total_timesteps  | 158201   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0345   |
|    n_updates        | 29550    |
----------------------------------
Eval num_timesteps=158500, episode_reward=285.82 +/- 151.65
Episode length: 71.82 +/- 37.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.8     |
|    mean_reward      | 286      |
| rollout/            |          |
|    exploration_rate | 0.363    |
| time/               |          |
|    total_timesteps  | 158500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.031    |
|    n_updates        | 29624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.5     |
|    ep_rew_mean      | 357      |
|    exploration_rate | 0.363    |
| time/               |          |
|    episodes         | 2080     |
|    fps              | 89       |
|    time_elapsed     | 1773     |
|    total_timesteps  | 158551   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0352   |
|    n_updates        | 29637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.5     |
|    ep_rew_mean      | 353      |
|    exploration_rate | 0.361    |
| time/               |          |
|    episodes         | 2084     |
|    fps              | 89       |
|    time_elapsed     | 1774     |
|    total_timesteps  | 158834   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.57     |
|    n_updates        | 29708    |
----------------------------------
Eval num_timesteps=159000, episode_reward=179.36 +/- 47.97
Episode length: 45.18 +/- 12.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.359    |
| time/               |          |
|    total_timesteps  | 159000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0648   |
|    n_updates        | 29749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.8     |
|    ep_rew_mean      | 358      |
|    exploration_rate | 0.357    |
| time/               |          |
|    episodes         | 2088     |
|    fps              | 89       |
|    time_elapsed     | 1779     |
|    total_timesteps  | 159233   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.08     |
|    n_updates        | 29808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.1     |
|    ep_rew_mean      | 351      |
|    exploration_rate | 0.356    |
| time/               |          |
|    episodes         | 2092     |
|    fps              | 89       |
|    time_elapsed     | 1779     |
|    total_timesteps  | 159451   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.616    |
|    n_updates        | 29862    |
----------------------------------
Eval num_timesteps=159500, episode_reward=194.34 +/- 51.56
Episode length: 48.98 +/- 12.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49       |
|    mean_reward      | 194      |
| rollout/            |          |
|    exploration_rate | 0.355    |
| time/               |          |
|    total_timesteps  | 159500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0692   |
|    n_updates        | 29874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.6     |
|    ep_rew_mean      | 349      |
|    exploration_rate | 0.353    |
| time/               |          |
|    episodes         | 2096     |
|    fps              | 89       |
|    time_elapsed     | 1785     |
|    total_timesteps  | 159787   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0824   |
|    n_updates        | 29946    |
----------------------------------
Eval num_timesteps=160000, episode_reward=174.08 +/- 54.37
Episode length: 43.84 +/- 13.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.8     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.351    |
| time/               |          |
|    total_timesteps  | 160000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0268   |
|    n_updates        | 29999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.4     |
|    ep_rew_mean      | 340      |
|    exploration_rate | 0.351    |
| time/               |          |
|    episodes         | 2100     |
|    fps              | 89       |
|    time_elapsed     | 1790     |
|    total_timesteps  | 160019   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.84     |
|    n_updates        | 30004    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85       |
|    ep_rew_mean      | 339      |
|    exploration_rate | 0.349    |
| time/               |          |
|    episodes         | 2104     |
|    fps              | 89       |
|    time_elapsed     | 1790     |
|    total_timesteps  | 160281   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.95     |
|    n_updates        | 30070    |
----------------------------------
Eval num_timesteps=160500, episode_reward=260.92 +/- 94.99
Episode length: 65.60 +/- 23.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.6     |
|    mean_reward      | 261      |
| rollout/            |          |
|    exploration_rate | 0.347    |
| time/               |          |
|    total_timesteps  | 160500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.341    |
|    n_updates        | 30124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.6     |
|    ep_rew_mean      | 333      |
|    exploration_rate | 0.346    |
| time/               |          |
|    episodes         | 2108     |
|    fps              | 89       |
|    time_elapsed     | 1797     |
|    total_timesteps  | 160590   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.446    |
|    n_updates        | 30147    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.6     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 0.345    |
| time/               |          |
|    episodes         | 2112     |
|    fps              | 89       |
|    time_elapsed     | 1797     |
|    total_timesteps  | 160742   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.405    |
|    n_updates        | 30185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80       |
|    ep_rew_mean      | 319      |
|    exploration_rate | 0.343    |
| time/               |          |
|    episodes         | 2116     |
|    fps              | 89       |
|    time_elapsed     | 1798     |
|    total_timesteps  | 160968   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0405   |
|    n_updates        | 30241    |
----------------------------------
Eval num_timesteps=161000, episode_reward=184.26 +/- 52.21
Episode length: 46.48 +/- 13.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.5     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.343    |
| time/               |          |
|    total_timesteps  | 161000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.588    |
|    n_updates        | 30249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 0.341    |
| time/               |          |
|    episodes         | 2120     |
|    fps              | 89       |
|    time_elapsed     | 1802     |
|    total_timesteps  | 161282   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.2      |
|    n_updates        | 30320    |
----------------------------------
Eval num_timesteps=161500, episode_reward=179.50 +/- 68.25
Episode length: 45.30 +/- 17.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.339    |
| time/               |          |
|    total_timesteps  | 161500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.71     |
|    n_updates        | 30374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.9     |
|    ep_rew_mean      | 314      |
|    exploration_rate | 0.339    |
| time/               |          |
|    episodes         | 2124     |
|    fps              | 89       |
|    time_elapsed     | 1807     |
|    total_timesteps  | 161542   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0257   |
|    n_updates        | 30385    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.5     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.336    |
| time/               |          |
|    episodes         | 2128     |
|    fps              | 89       |
|    time_elapsed     | 1808     |
|    total_timesteps  | 161842   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0287   |
|    n_updates        | 30460    |
----------------------------------
Eval num_timesteps=162000, episode_reward=179.62 +/- 78.43
Episode length: 45.36 +/- 19.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.335    |
| time/               |          |
|    total_timesteps  | 162000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.592    |
|    n_updates        | 30499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 307      |
|    exploration_rate | 0.333    |
| time/               |          |
|    episodes         | 2132     |
|    fps              | 89       |
|    time_elapsed     | 1813     |
|    total_timesteps  | 162167   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0651   |
|    n_updates        | 30541    |
----------------------------------
Eval num_timesteps=162500, episode_reward=192.96 +/- 49.74
Episode length: 48.64 +/- 12.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.6     |
|    mean_reward      | 193      |
| rollout/            |          |
|    exploration_rate | 0.331    |
| time/               |          |
|    total_timesteps  | 162500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0329   |
|    n_updates        | 30624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.33     |
| time/               |          |
|    episodes         | 2136     |
|    fps              | 89       |
|    time_elapsed     | 1819     |
|    total_timesteps  | 162571   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.576    |
|    n_updates        | 30642    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.328    |
| time/               |          |
|    episodes         | 2140     |
|    fps              | 89       |
|    time_elapsed     | 1819     |
|    total_timesteps  | 162805   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0691   |
|    n_updates        | 30701    |
----------------------------------
Eval num_timesteps=163000, episode_reward=291.56 +/- 120.67
Episode length: 73.24 +/- 30.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.2     |
|    mean_reward      | 292      |
| rollout/            |          |
|    exploration_rate | 0.327    |
| time/               |          |
|    total_timesteps  | 163000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0994   |
|    n_updates        | 30749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | 287      |
|    exploration_rate | 0.326    |
| time/               |          |
|    episodes         | 2144     |
|    fps              | 89       |
|    time_elapsed     | 1826     |
|    total_timesteps  | 163053   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.641    |
|    n_updates        | 30763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.324    |
| time/               |          |
|    episodes         | 2148     |
|    fps              | 89       |
|    time_elapsed     | 1828     |
|    total_timesteps  | 163340   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.63     |
|    n_updates        | 30834    |
----------------------------------
Eval num_timesteps=163500, episode_reward=183.64 +/- 57.31
Episode length: 46.24 +/- 14.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.2     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.323    |
| time/               |          |
|    total_timesteps  | 163500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0247   |
|    n_updates        | 30874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.322    |
| time/               |          |
|    episodes         | 2152     |
|    fps              | 89       |
|    time_elapsed     | 1833     |
|    total_timesteps  | 163616   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0487   |
|    n_updates        | 30903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 286      |
|    exploration_rate | 0.319    |
| time/               |          |
|    episodes         | 2156     |
|    fps              | 89       |
|    time_elapsed     | 1834     |
|    total_timesteps  | 163912   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.62     |
|    n_updates        | 30977    |
----------------------------------
Eval num_timesteps=164000, episode_reward=189.78 +/- 63.95
Episode length: 47.82 +/- 16.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.8     |
|    mean_reward      | 190      |
| rollout/            |          |
|    exploration_rate | 0.318    |
| time/               |          |
|    total_timesteps  | 164000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0216   |
|    n_updates        | 30999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.6     |
|    ep_rew_mean      | 281      |
|    exploration_rate | 0.317    |
| time/               |          |
|    episodes         | 2160     |
|    fps              | 89       |
|    time_elapsed     | 1839     |
|    total_timesteps  | 164156   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.155    |
|    n_updates        | 31038    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 0.315    |
| time/               |          |
|    episodes         | 2164     |
|    fps              | 89       |
|    time_elapsed     | 1839     |
|    total_timesteps  | 164394   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.21     |
|    n_updates        | 31098    |
----------------------------------
Eval num_timesteps=164500, episode_reward=264.96 +/- 146.36
Episode length: 66.54 +/- 36.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.5     |
|    mean_reward      | 265      |
| rollout/            |          |
|    exploration_rate | 0.314    |
| time/               |          |
|    total_timesteps  | 164500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.71     |
|    n_updates        | 31124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 285      |
|    exploration_rate | 0.312    |
| time/               |          |
|    episodes         | 2168     |
|    fps              | 89       |
|    time_elapsed     | 1846     |
|    total_timesteps  | 164753   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.599    |
|    n_updates        | 31188    |
----------------------------------
Eval num_timesteps=165000, episode_reward=171.40 +/- 60.57
Episode length: 43.20 +/- 15.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.2     |
|    mean_reward      | 171      |
| rollout/            |          |
|    exploration_rate | 0.31     |
| time/               |          |
|    total_timesteps  | 165000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.644    |
|    n_updates        | 31249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 0.309    |
| time/               |          |
|    episodes         | 2172     |
|    fps              | 89       |
|    time_elapsed     | 1850     |
|    total_timesteps  | 165104   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.58     |
|    n_updates        | 31275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 0.308    |
| time/               |          |
|    episodes         | 2176     |
|    fps              | 89       |
|    time_elapsed     | 1851     |
|    total_timesteps  | 165279   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0627   |
|    n_updates        | 31319    |
----------------------------------
Eval num_timesteps=165500, episode_reward=170.02 +/- 41.78
Episode length: 42.84 +/- 10.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.306    |
| time/               |          |
|    total_timesteps  | 165500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.603    |
|    n_updates        | 31374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 0.305    |
| time/               |          |
|    episodes         | 2180     |
|    fps              | 89       |
|    time_elapsed     | 1856     |
|    total_timesteps  | 165659   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0215   |
|    n_updates        | 31414    |
----------------------------------
Eval num_timesteps=166000, episode_reward=220.94 +/- 89.23
Episode length: 55.58 +/- 22.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.6     |
|    mean_reward      | 221      |
| rollout/            |          |
|    exploration_rate | 0.302    |
| time/               |          |
|    total_timesteps  | 166000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.2      |
|    n_updates        | 31499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.301    |
| time/               |          |
|    episodes         | 2184     |
|    fps              | 89       |
|    time_elapsed     | 1862     |
|    total_timesteps  | 166157   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.13     |
|    n_updates        | 31539    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 286      |
|    exploration_rate | 0.298    |
| time/               |          |
|    episodes         | 2188     |
|    fps              | 89       |
|    time_elapsed     | 1862     |
|    total_timesteps  | 166424   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.69     |
|    n_updates        | 31605    |
----------------------------------
Eval num_timesteps=166500, episode_reward=183.54 +/- 50.55
Episode length: 46.26 +/- 12.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.3     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.298    |
| time/               |          |
|    total_timesteps  | 166500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.596    |
|    n_updates        | 31624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 291      |
|    exploration_rate | 0.296    |
| time/               |          |
|    episodes         | 2192     |
|    fps              | 89       |
|    time_elapsed     | 1867     |
|    total_timesteps  | 166751   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.73     |
|    n_updates        | 31687    |
----------------------------------
Eval num_timesteps=167000, episode_reward=243.52 +/- 109.57
Episode length: 61.24 +/- 27.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 61.2     |
|    mean_reward      | 244      |
| rollout/            |          |
|    exploration_rate | 0.294    |
| time/               |          |
|    total_timesteps  | 167000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.635    |
|    n_updates        | 31749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 0.293    |
| time/               |          |
|    episodes         | 2196     |
|    fps              | 89       |
|    time_elapsed     | 1873     |
|    total_timesteps  | 167059   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.612    |
|    n_updates        | 31764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.29     |
| time/               |          |
|    episodes         | 2200     |
|    fps              | 89       |
|    time_elapsed     | 1874     |
|    total_timesteps  | 167404   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0427   |
|    n_updates        | 31850    |
----------------------------------
Eval num_timesteps=167500, episode_reward=252.16 +/- 109.31
Episode length: 63.40 +/- 27.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.4     |
|    mean_reward      | 252      |
| rollout/            |          |
|    exploration_rate | 0.289    |
| time/               |          |
|    total_timesteps  | 167500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.69     |
|    n_updates        | 31874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.8     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.287    |
| time/               |          |
|    episodes         | 2204     |
|    fps              | 89       |
|    time_elapsed     | 1881     |
|    total_timesteps  | 167758   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.18     |
|    n_updates        | 31939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 294      |
|    exploration_rate | 0.285    |
| time/               |          |
|    episodes         | 2208     |
|    fps              | 89       |
|    time_elapsed     | 1882     |
|    total_timesteps  | 167989   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.182    |
|    n_updates        | 31997    |
----------------------------------
Eval num_timesteps=168000, episode_reward=195.06 +/- 59.36
Episode length: 49.18 +/- 14.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.2     |
|    mean_reward      | 195      |
| rollout/            |          |
|    exploration_rate | 0.285    |
| time/               |          |
|    total_timesteps  | 168000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0273   |
|    n_updates        | 31999    |
----------------------------------
Eval num_timesteps=168500, episode_reward=238.58 +/- 110.58
Episode length: 60.02 +/- 27.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60       |
|    mean_reward      | 239      |
| rollout/            |          |
|    exploration_rate | 0.281    |
| time/               |          |
|    total_timesteps  | 168500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.575    |
|    n_updates        | 32124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78       |
|    ep_rew_mean      | 310      |
|    exploration_rate | 0.281    |
| time/               |          |
|    episodes         | 2212     |
|    fps              | 88       |
|    time_elapsed     | 1894     |
|    total_timesteps  | 168542   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.576    |
|    n_updates        | 32135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.7     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.278    |
| time/               |          |
|    episodes         | 2216     |
|    fps              | 89       |
|    time_elapsed     | 1895     |
|    total_timesteps  | 168839   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0333   |
|    n_updates        | 32209    |
----------------------------------
Eval num_timesteps=169000, episode_reward=173.20 +/- 47.93
Episode length: 43.68 +/- 12.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.7     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.277    |
| time/               |          |
|    total_timesteps  | 169000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.631    |
|    n_updates        | 32249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.5     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.276    |
| time/               |          |
|    episodes         | 2220     |
|    fps              | 89       |
|    time_elapsed     | 1900     |
|    total_timesteps  | 169137   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.047    |
|    n_updates        | 32284    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.4     |
|    ep_rew_mean      | 312      |
|    exploration_rate | 0.274    |
| time/               |          |
|    episodes         | 2224     |
|    fps              | 89       |
|    time_elapsed     | 1900     |
|    total_timesteps  | 169383   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.603    |
|    n_updates        | 32345    |
----------------------------------
Eval num_timesteps=169500, episode_reward=190.12 +/- 46.19
Episode length: 47.96 +/- 11.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48       |
|    mean_reward      | 190      |
| rollout/            |          |
|    exploration_rate | 0.273    |
| time/               |          |
|    total_timesteps  | 169500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.625    |
|    n_updates        | 32374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 309      |
|    exploration_rate | 0.272    |
| time/               |          |
|    episodes         | 2228     |
|    fps              | 89       |
|    time_elapsed     | 1905     |
|    total_timesteps  | 169620   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.661    |
|    n_updates        | 32404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.1     |
|    ep_rew_mean      | 311      |
|    exploration_rate | 0.269    |
| time/               |          |
|    episodes         | 2232     |
|    fps              | 89       |
|    time_elapsed     | 1906     |
|    total_timesteps  | 169981   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.611    |
|    n_updates        | 32495    |
----------------------------------
Eval num_timesteps=170000, episode_reward=191.34 +/- 45.34
Episode length: 48.26 +/- 11.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.3     |
|    mean_reward      | 191      |
| rollout/            |          |
|    exploration_rate | 0.268    |
| time/               |          |
|    total_timesteps  | 170000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.601    |
|    n_updates        | 32499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 304      |
|    exploration_rate | 0.266    |
| time/               |          |
|    episodes         | 2236     |
|    fps              | 89       |
|    time_elapsed     | 1911     |
|    total_timesteps  | 170220   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0459   |
|    n_updates        | 32554    |
----------------------------------
Eval num_timesteps=170500, episode_reward=166.94 +/- 41.10
Episode length: 42.12 +/- 10.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.1     |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.264    |
| time/               |          |
|    total_timesteps  | 170500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0509   |
|    n_updates        | 32624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 310      |
|    exploration_rate | 0.263    |
| time/               |          |
|    episodes         | 2240     |
|    fps              | 89       |
|    time_elapsed     | 1915     |
|    total_timesteps  | 170596   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.29     |
|    n_updates        | 32648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.5     |
|    ep_rew_mean      | 312      |
|    exploration_rate | 0.261    |
| time/               |          |
|    episodes         | 2244     |
|    fps              | 89       |
|    time_elapsed     | 1916     |
|    total_timesteps  | 170899   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.25     |
|    n_updates        | 32724    |
----------------------------------
Eval num_timesteps=171000, episode_reward=188.92 +/- 58.45
Episode length: 47.60 +/- 14.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.6     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.26     |
| time/               |          |
|    total_timesteps  | 171000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0895   |
|    n_updates        | 32749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.7     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.258    |
| time/               |          |
|    episodes         | 2248     |
|    fps              | 89       |
|    time_elapsed     | 1921     |
|    total_timesteps  | 171213   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0252   |
|    n_updates        | 32803    |
----------------------------------
Eval num_timesteps=171500, episode_reward=230.24 +/- 74.10
Episode length: 57.88 +/- 18.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.9     |
|    mean_reward      | 230      |
| rollout/            |          |
|    exploration_rate | 0.256    |
| time/               |          |
|    total_timesteps  | 171500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.16     |
|    n_updates        | 32874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.7     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 0.255    |
| time/               |          |
|    episodes         | 2252     |
|    fps              | 89       |
|    time_elapsed     | 1926     |
|    total_timesteps  | 171587   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.675    |
|    n_updates        | 32896    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79       |
|    ep_rew_mean      | 314      |
|    exploration_rate | 0.253    |
| time/               |          |
|    episodes         | 2256     |
|    fps              | 89       |
|    time_elapsed     | 1927     |
|    total_timesteps  | 171814   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.54     |
|    n_updates        | 32953    |
----------------------------------
Eval num_timesteps=172000, episode_reward=182.82 +/- 37.93
Episode length: 46.08 +/- 9.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.251    |
| time/               |          |
|    total_timesteps  | 172000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0392   |
|    n_updates        | 32999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.4     |
|    ep_rew_mean      | 316      |
|    exploration_rate | 0.251    |
| time/               |          |
|    episodes         | 2260     |
|    fps              | 89       |
|    time_elapsed     | 1932     |
|    total_timesteps  | 172096   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0333   |
|    n_updates        | 33023    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.8     |
|    ep_rew_mean      | 317      |
|    exploration_rate | 0.248    |
| time/               |          |
|    episodes         | 2264     |
|    fps              | 89       |
|    time_elapsed     | 1933     |
|    total_timesteps  | 172370   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.48     |
|    n_updates        | 33092    |
----------------------------------
Eval num_timesteps=172500, episode_reward=179.22 +/- 44.21
Episode length: 45.24 +/- 11.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.247    |
| time/               |          |
|    total_timesteps  | 172500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0423   |
|    n_updates        | 33124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 319      |
|    exploration_rate | 0.245    |
| time/               |          |
|    episodes         | 2268     |
|    fps              | 89       |
|    time_elapsed     | 1937     |
|    total_timesteps  | 172769   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.689    |
|    n_updates        | 33192    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.8     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.243    |
| time/               |          |
|    episodes         | 2272     |
|    fps              | 89       |
|    time_elapsed     | 1938     |
|    total_timesteps  | 172979   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.62     |
|    n_updates        | 33244    |
----------------------------------
Eval num_timesteps=173000, episode_reward=262.72 +/- 154.94
Episode length: 66.06 +/- 38.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.1     |
|    mean_reward      | 263      |
| rollout/            |          |
|    exploration_rate | 0.243    |
| time/               |          |
|    total_timesteps  | 173000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.891    |
|    n_updates        | 33249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.3     |
|    ep_rew_mean      | 319      |
|    exploration_rate | 0.24     |
| time/               |          |
|    episodes         | 2276     |
|    fps              | 89       |
|    time_elapsed     | 1944     |
|    total_timesteps  | 173307   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0489   |
|    n_updates        | 33326    |
----------------------------------
Eval num_timesteps=173500, episode_reward=173.70 +/- 42.10
Episode length: 43.82 +/- 10.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.8     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.239    |
| time/               |          |
|    total_timesteps  | 173500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.686    |
|    n_updates        | 33374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.7     |
|    ep_rew_mean      | 313      |
|    exploration_rate | 0.238    |
| time/               |          |
|    episodes         | 2280     |
|    fps              | 89       |
|    time_elapsed     | 1949     |
|    total_timesteps  | 173530   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.653    |
|    n_updates        | 33382    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 301      |
|    exploration_rate | 0.237    |
| time/               |          |
|    episodes         | 2284     |
|    fps              | 89       |
|    time_elapsed     | 1949     |
|    total_timesteps  | 173735   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.93     |
|    n_updates        | 33433    |
----------------------------------
Eval num_timesteps=174000, episode_reward=177.76 +/- 52.37
Episode length: 44.78 +/- 13.12
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.234    |
| time/               |          |
|    total_timesteps  | 174000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0464   |
|    n_updates        | 33499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.9     |
|    ep_rew_mean      | 302      |
|    exploration_rate | 0.234    |
| time/               |          |
|    episodes         | 2288     |
|    fps              | 89       |
|    time_elapsed     | 1954     |
|    total_timesteps  | 174018   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.598    |
|    n_updates        | 33504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.1     |
|    ep_rew_mean      | 298      |
|    exploration_rate | 0.232    |
| time/               |          |
|    episodes         | 2292     |
|    fps              | 89       |
|    time_elapsed     | 1955     |
|    total_timesteps  | 174258   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0201   |
|    n_updates        | 33564    |
----------------------------------
Eval num_timesteps=174500, episode_reward=177.50 +/- 48.53
Episode length: 44.74 +/- 12.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.7     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.23     |
| time/               |          |
|    total_timesteps  | 174500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.671    |
|    n_updates        | 33624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 297      |
|    exploration_rate | 0.23     |
| time/               |          |
|    episodes         | 2296     |
|    fps              | 89       |
|    time_elapsed     | 1959     |
|    total_timesteps  | 174517   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0274   |
|    n_updates        | 33629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | 292      |
|    exploration_rate | 0.228    |
| time/               |          |
|    episodes         | 2300     |
|    fps              | 89       |
|    time_elapsed     | 1960     |
|    total_timesteps  | 174745   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.88     |
|    n_updates        | 33686    |
----------------------------------
Eval num_timesteps=175000, episode_reward=182.78 +/- 44.75
Episode length: 46.16 +/- 11.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.2     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.226    |
| time/               |          |
|    total_timesteps  | 175000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.033    |
|    n_updates        | 33749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 0.226    |
| time/               |          |
|    episodes         | 2304     |
|    fps              | 89       |
|    time_elapsed     | 1965     |
|    total_timesteps  | 175015   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0236   |
|    n_updates        | 33753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 290      |
|    exploration_rate | 0.223    |
| time/               |          |
|    episodes         | 2308     |
|    fps              | 89       |
|    time_elapsed     | 1966     |
|    total_timesteps  | 175285   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0616   |
|    n_updates        | 33821    |
----------------------------------
Eval num_timesteps=175500, episode_reward=178.34 +/- 53.41
Episode length: 44.96 +/- 13.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.221    |
| time/               |          |
|    total_timesteps  | 175500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0631   |
|    n_updates        | 33874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.4     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 0.22     |
| time/               |          |
|    episodes         | 2312     |
|    fps              | 89       |
|    time_elapsed     | 1970     |
|    total_timesteps  | 175679   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.676    |
|    n_updates        | 33919    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.6     |
|    ep_rew_mean      | 281      |
|    exploration_rate | 0.218    |
| time/               |          |
|    episodes         | 2316     |
|    fps              | 89       |
|    time_elapsed     | 1971     |
|    total_timesteps  | 175897   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.94     |
|    n_updates        | 33974    |
----------------------------------
Eval num_timesteps=176000, episode_reward=174.00 +/- 44.17
Episode length: 43.86 +/- 11.05
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.217    |
| time/               |          |
|    total_timesteps  | 176000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.669    |
|    n_updates        | 33999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.4     |
|    ep_rew_mean      | 280      |
|    exploration_rate | 0.216    |
| time/               |          |
|    episodes         | 2320     |
|    fps              | 89       |
|    time_elapsed     | 1975     |
|    total_timesteps  | 176181   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.678    |
|    n_updates        | 34045    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.3     |
|    ep_rew_mean      | 280      |
|    exploration_rate | 0.214    |
| time/               |          |
|    episodes         | 2324     |
|    fps              | 89       |
|    time_elapsed     | 1976     |
|    total_timesteps  | 176417   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.572    |
|    n_updates        | 34104    |
----------------------------------
Eval num_timesteps=176500, episode_reward=169.36 +/- 51.59
Episode length: 42.70 +/- 12.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.7     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.213    |
| time/               |          |
|    total_timesteps  | 176500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.638    |
|    n_updates        | 34124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 0.212    |
| time/               |          |
|    episodes         | 2328     |
|    fps              | 89       |
|    time_elapsed     | 1980     |
|    total_timesteps  | 176632   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0497   |
|    n_updates        | 34157    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.3     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 0.21     |
| time/               |          |
|    episodes         | 2332     |
|    fps              | 89       |
|    time_elapsed     | 1981     |
|    total_timesteps  | 176812   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0507   |
|    n_updates        | 34202    |
----------------------------------
Eval num_timesteps=177000, episode_reward=171.78 +/- 42.98
Episode length: 43.30 +/- 10.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.3     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 0.208    |
| time/               |          |
|    total_timesteps  | 177000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.67     |
|    n_updates        | 34249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.2     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 0.208    |
| time/               |          |
|    episodes         | 2336     |
|    fps              | 89       |
|    time_elapsed     | 1985     |
|    total_timesteps  | 177045   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.727    |
|    n_updates        | 34261    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.1     |
|    ep_rew_mean      | 267      |
|    exploration_rate | 0.206    |
| time/               |          |
|    episodes         | 2340     |
|    fps              | 89       |
|    time_elapsed     | 1986     |
|    total_timesteps  | 177309   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.607    |
|    n_updates        | 34327    |
----------------------------------
Eval num_timesteps=177500, episode_reward=204.28 +/- 97.38
Episode length: 51.46 +/- 24.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.5     |
|    mean_reward      | 204      |
| rollout/            |          |
|    exploration_rate | 0.204    |
| time/               |          |
|    total_timesteps  | 177500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.686    |
|    n_updates        | 34374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.204    |
| time/               |          |
|    episodes         | 2344     |
|    fps              | 89       |
|    time_elapsed     | 1991     |
|    total_timesteps  | 177534   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.672    |
|    n_updates        | 34383    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.202    |
| time/               |          |
|    episodes         | 2348     |
|    fps              | 89       |
|    time_elapsed     | 1992     |
|    total_timesteps  | 177775   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.682    |
|    n_updates        | 34443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 254      |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 2352     |
|    fps              | 89       |
|    time_elapsed     | 1992     |
|    total_timesteps  | 177966   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.24     |
|    n_updates        | 34491    |
----------------------------------
Eval num_timesteps=178000, episode_reward=170.70 +/- 48.93
Episode length: 43.08 +/- 12.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.1     |
|    mean_reward      | 171      |
| rollout/            |          |
|    exploration_rate | 0.2      |
| time/               |          |
|    total_timesteps  | 178000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.658    |
|    n_updates        | 34499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.1     |
|    ep_rew_mean      | 259      |
|    exploration_rate | 0.197    |
| time/               |          |
|    episodes         | 2356     |
|    fps              | 89       |
|    time_elapsed     | 1998     |
|    total_timesteps  | 178327   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.26     |
|    n_updates        | 34581    |
----------------------------------
Eval num_timesteps=178500, episode_reward=165.60 +/- 41.45
Episode length: 41.76 +/- 10.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.8     |
|    mean_reward      | 166      |
| rollout/            |          |
|    exploration_rate | 0.195    |
| time/               |          |
|    total_timesteps  | 178500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.685    |
|    n_updates        | 34624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.194    |
| time/               |          |
|    episodes         | 2360     |
|    fps              | 89       |
|    time_elapsed     | 2005     |
|    total_timesteps  | 178670   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.27     |
|    n_updates        | 34667    |
----------------------------------
Eval num_timesteps=179000, episode_reward=211.38 +/- 53.47
Episode length: 53.22 +/- 13.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.2     |
|    mean_reward      | 211      |
| rollout/            |          |
|    exploration_rate | 0.191    |
| time/               |          |
|    total_timesteps  | 179000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0514   |
|    n_updates        | 34749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.6     |
|    ep_rew_mean      | 269      |
|    exploration_rate | 0.19     |
| time/               |          |
|    episodes         | 2364     |
|    fps              | 89       |
|    time_elapsed     | 2011     |
|    total_timesteps  | 179127   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0772   |
|    n_updates        | 34781    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.7     |
|    ep_rew_mean      | 265      |
|    exploration_rate | 0.187    |
| time/               |          |
|    episodes         | 2368     |
|    fps              | 89       |
|    time_elapsed     | 2012     |
|    total_timesteps  | 179441   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0482   |
|    n_updates        | 34860    |
----------------------------------
Eval num_timesteps=179500, episode_reward=175.38 +/- 51.78
Episode length: 44.24 +/- 13.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.187    |
| time/               |          |
|    total_timesteps  | 179500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.036    |
|    n_updates        | 34874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.185    |
| time/               |          |
|    episodes         | 2372     |
|    fps              | 89       |
|    time_elapsed     | 2017     |
|    total_timesteps  | 179709   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.82     |
|    n_updates        | 34927    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | 262      |
|    exploration_rate | 0.183    |
| time/               |          |
|    episodes         | 2376     |
|    fps              | 89       |
|    time_elapsed     | 2018     |
|    total_timesteps  | 179907   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0342   |
|    n_updates        | 34976    |
----------------------------------
Eval num_timesteps=180000, episode_reward=188.38 +/- 59.07
Episode length: 47.44 +/- 14.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.4     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 0.182    |
| time/               |          |
|    total_timesteps  | 180000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.606    |
|    n_updates        | 34999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.5     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.181    |
| time/               |          |
|    episodes         | 2380     |
|    fps              | 89       |
|    time_elapsed     | 2023     |
|    total_timesteps  | 180178   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.03     |
|    n_updates        | 35044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | 267      |
|    exploration_rate | 0.179    |
| time/               |          |
|    episodes         | 2384     |
|    fps              | 89       |
|    time_elapsed     | 2023     |
|    total_timesteps  | 180435   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0549   |
|    n_updates        | 35108    |
----------------------------------
Eval num_timesteps=180500, episode_reward=206.42 +/- 95.51
Episode length: 52.00 +/- 23.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52       |
|    mean_reward      | 206      |
| rollout/            |          |
|    exploration_rate | 0.178    |
| time/               |          |
|    total_timesteps  | 180500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.098    |
|    n_updates        | 35124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.7     |
|    ep_rew_mean      | 265      |
|    exploration_rate | 0.176    |
| time/               |          |
|    episodes         | 2388     |
|    fps              | 89       |
|    time_elapsed     | 2029     |
|    total_timesteps  | 180687   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0268   |
|    n_updates        | 35171    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | 267      |
|    exploration_rate | 0.174    |
| time/               |          |
|    episodes         | 2392     |
|    fps              | 89       |
|    time_elapsed     | 2029     |
|    total_timesteps  | 180962   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.676    |
|    n_updates        | 35240    |
----------------------------------
Eval num_timesteps=181000, episode_reward=233.96 +/- 119.96
Episode length: 58.88 +/- 29.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.9     |
|    mean_reward      | 234      |
| rollout/            |          |
|    exploration_rate | 0.174    |
| time/               |          |
|    total_timesteps  | 181000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.689    |
|    n_updates        | 35249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.9     |
|    ep_rew_mean      | 262      |
|    exploration_rate | 0.173    |
| time/               |          |
|    episodes         | 2396     |
|    fps              | 88       |
|    time_elapsed     | 2035     |
|    total_timesteps  | 181110   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0611   |
|    n_updates        | 35277    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.5     |
|    ep_rew_mean      | 265      |
|    exploration_rate | 0.17     |
| time/               |          |
|    episodes         | 2400     |
|    fps              | 89       |
|    time_elapsed     | 2036     |
|    total_timesteps  | 181399   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.46     |
|    n_updates        | 35349    |
----------------------------------
Eval num_timesteps=181500, episode_reward=174.96 +/- 41.27
Episode length: 44.14 +/- 10.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.169    |
| time/               |          |
|    total_timesteps  | 181500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0417   |
|    n_updates        | 35374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.1     |
|    ep_rew_mean      | 267      |
|    exploration_rate | 0.167    |
| time/               |          |
|    episodes         | 2404     |
|    fps              | 89       |
|    time_elapsed     | 2040     |
|    total_timesteps  | 181729   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.29     |
|    n_updates        | 35432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 266      |
|    exploration_rate | 0.165    |
| time/               |          |
|    episodes         | 2408     |
|    fps              | 89       |
|    time_elapsed     | 2041     |
|    total_timesteps  | 181973   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.7      |
|    n_updates        | 35493    |
----------------------------------
Eval num_timesteps=182000, episode_reward=279.74 +/- 112.39
Episode length: 70.34 +/- 28.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.3     |
|    mean_reward      | 280      |
| rollout/            |          |
|    exploration_rate | 0.165    |
| time/               |          |
|    total_timesteps  | 182000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.698    |
|    n_updates        | 35499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | 263      |
|    exploration_rate | 0.162    |
| time/               |          |
|    episodes         | 2412     |
|    fps              | 88       |
|    time_elapsed     | 2048     |
|    total_timesteps  | 182296   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0768   |
|    n_updates        | 35573    |
----------------------------------
Eval num_timesteps=182500, episode_reward=179.02 +/- 49.94
Episode length: 45.14 +/- 12.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.1     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.16     |
| time/               |          |
|    total_timesteps  | 182500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.049    |
|    n_updates        | 35624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 266      |
|    exploration_rate | 0.16     |
| time/               |          |
|    episodes         | 2416     |
|    fps              | 88       |
|    time_elapsed     | 2053     |
|    total_timesteps  | 182587   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.102    |
|    n_updates        | 35646    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.158    |
| time/               |          |
|    episodes         | 2420     |
|    fps              | 89       |
|    time_elapsed     | 2054     |
|    total_timesteps  | 182818   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0467   |
|    n_updates        | 35704    |
----------------------------------
Eval num_timesteps=183000, episode_reward=171.68 +/- 42.99
Episode length: 43.28 +/- 10.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.3     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 0.156    |
| time/               |          |
|    total_timesteps  | 183000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.36     |
|    n_updates        | 35749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.155    |
| time/               |          |
|    episodes         | 2424     |
|    fps              | 88       |
|    time_elapsed     | 2058     |
|    total_timesteps  | 183058   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.808    |
|    n_updates        | 35764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | 265      |
|    exploration_rate | 0.153    |
| time/               |          |
|    episodes         | 2428     |
|    fps              | 89       |
|    time_elapsed     | 2059     |
|    total_timesteps  | 183295   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0799   |
|    n_updates        | 35823    |
----------------------------------
Eval num_timesteps=183500, episode_reward=208.34 +/- 122.96
Episode length: 52.40 +/- 30.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.4     |
|    mean_reward      | 208      |
| rollout/            |          |
|    exploration_rate | 0.151    |
| time/               |          |
|    total_timesteps  | 183500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.687    |
|    n_updates        | 35874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | 266      |
|    exploration_rate | 0.151    |
| time/               |          |
|    episodes         | 2432     |
|    fps              | 88       |
|    time_elapsed     | 2064     |
|    total_timesteps  | 183510   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0602   |
|    n_updates        | 35877    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 266      |
|    exploration_rate | 0.149    |
| time/               |          |
|    episodes         | 2436     |
|    fps              | 88       |
|    time_elapsed     | 2064     |
|    total_timesteps  | 183736   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.28     |
|    n_updates        | 35933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 266      |
|    exploration_rate | 0.147    |
| time/               |          |
|    episodes         | 2440     |
|    fps              | 89       |
|    time_elapsed     | 2065     |
|    total_timesteps  | 183995   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0453   |
|    n_updates        | 35998    |
----------------------------------
Eval num_timesteps=184000, episode_reward=282.64 +/- 136.60
Episode length: 71.06 +/- 34.18
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.1     |
|    mean_reward      | 283      |
| rollout/            |          |
|    exploration_rate | 0.147    |
| time/               |          |
|    total_timesteps  | 184000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0606   |
|    n_updates        | 35999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | 267      |
|    exploration_rate | 0.145    |
| time/               |          |
|    episodes         | 2444     |
|    fps              | 88       |
|    time_elapsed     | 2072     |
|    total_timesteps  | 184233   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.693    |
|    n_updates        | 36058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | 265      |
|    exploration_rate | 0.143    |
| time/               |          |
|    episodes         | 2448     |
|    fps              | 88       |
|    time_elapsed     | 2072     |
|    total_timesteps  | 184438   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0223   |
|    n_updates        | 36109    |
----------------------------------
Eval num_timesteps=184500, episode_reward=201.96 +/- 54.27
Episode length: 50.90 +/- 13.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.9     |
|    mean_reward      | 202      |
| rollout/            |          |
|    exploration_rate | 0.143    |
| time/               |          |
|    total_timesteps  | 184500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.649    |
|    n_updates        | 36124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | 265      |
|    exploration_rate | 0.141    |
| time/               |          |
|    episodes         | 2452     |
|    fps              | 88       |
|    time_elapsed     | 2077     |
|    total_timesteps  | 184628   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.34     |
|    n_updates        | 36156    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.139    |
| time/               |          |
|    episodes         | 2456     |
|    fps              | 88       |
|    time_elapsed     | 2078     |
|    total_timesteps  | 184957   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0649   |
|    n_updates        | 36239    |
----------------------------------
Eval num_timesteps=185000, episode_reward=209.08 +/- 117.23
Episode length: 52.56 +/- 29.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.6     |
|    mean_reward      | 209      |
| rollout/            |          |
|    exploration_rate | 0.138    |
| time/               |          |
|    total_timesteps  | 185000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.36     |
|    n_updates        | 36249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | 263      |
|    exploration_rate | 0.136    |
| time/               |          |
|    episodes         | 2460     |
|    fps              | 88       |
|    time_elapsed     | 2084     |
|    total_timesteps  | 185290   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.26     |
|    n_updates        | 36322    |
----------------------------------
Eval num_timesteps=185500, episode_reward=166.34 +/- 48.30
Episode length: 41.86 +/- 12.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.9     |
|    mean_reward      | 166      |
| rollout/            |          |
|    exploration_rate | 0.134    |
| time/               |          |
|    total_timesteps  | 185500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.694    |
|    n_updates        | 36374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64       |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.133    |
| time/               |          |
|    episodes         | 2464     |
|    fps              | 88       |
|    time_elapsed     | 2089     |
|    total_timesteps  | 185528   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0187   |
|    n_updates        | 36381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.9     |
|    ep_rew_mean      | 250      |
|    exploration_rate | 0.132    |
| time/               |          |
|    episodes         | 2468     |
|    fps              | 88       |
|    time_elapsed     | 2089     |
|    total_timesteps  | 185728   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.657    |
|    n_updates        | 36431    |
----------------------------------
Eval num_timesteps=186000, episode_reward=313.02 +/- 143.64
Episode length: 78.56 +/- 35.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 78.6     |
|    mean_reward      | 313      |
| rollout/            |          |
|    exploration_rate | 0.129    |
| time/               |          |
|    total_timesteps  | 186000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.703    |
|    n_updates        | 36499    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.7     |
|    ep_rew_mean      | 253      |
|    exploration_rate | 0.129    |
| time/               |          |
|    episodes         | 2472     |
|    fps              | 88       |
|    time_elapsed     | 2097     |
|    total_timesteps  | 186075   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.632    |
|    n_updates        | 36518    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.3     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 0.125    |
| time/               |          |
|    episodes         | 2476     |
|    fps              | 88       |
|    time_elapsed     | 2098     |
|    total_timesteps  | 186436   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.027    |
|    n_updates        | 36608    |
----------------------------------
Eval num_timesteps=186500, episode_reward=233.54 +/- 76.90
Episode length: 58.74 +/- 19.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.7     |
|    mean_reward      | 234      |
| rollout/            |          |
|    exploration_rate | 0.125    |
| time/               |          |
|    total_timesteps  | 186500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.31     |
|    n_updates        | 36624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | 265      |
|    exploration_rate | 0.122    |
| time/               |          |
|    episodes         | 2480     |
|    fps              | 88       |
|    time_elapsed     | 2104     |
|    total_timesteps  | 186836   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0962   |
|    n_updates        | 36708    |
----------------------------------
Eval num_timesteps=187000, episode_reward=184.60 +/- 47.29
Episode length: 46.56 +/- 11.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.6     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.12     |
| time/               |          |
|    total_timesteps  | 187000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.058    |
|    n_updates        | 36749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 263      |
|    exploration_rate | 0.12     |
| time/               |          |
|    episodes         | 2484     |
|    fps              | 88       |
|    time_elapsed     | 2109     |
|    total_timesteps  | 187045   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0349   |
|    n_updates        | 36761    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 266      |
|    exploration_rate | 0.117    |
| time/               |          |
|    episodes         | 2488     |
|    fps              | 88       |
|    time_elapsed     | 2110     |
|    total_timesteps  | 187373   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0342   |
|    n_updates        | 36843    |
----------------------------------
Eval num_timesteps=187500, episode_reward=206.94 +/- 103.45
Episode length: 52.12 +/- 25.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.1     |
|    mean_reward      | 207      |
| rollout/            |          |
|    exploration_rate | 0.116    |
| time/               |          |
|    total_timesteps  | 187500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.043    |
|    n_updates        | 36874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 263      |
|    exploration_rate | 0.115    |
| time/               |          |
|    episodes         | 2492     |
|    fps              | 88       |
|    time_elapsed     | 2115     |
|    total_timesteps  | 187575   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.99     |
|    n_updates        | 36893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.7     |
|    ep_rew_mean      | 265      |
|    exploration_rate | 0.113    |
| time/               |          |
|    episodes         | 2496     |
|    fps              | 88       |
|    time_elapsed     | 2116     |
|    total_timesteps  | 187781   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.705    |
|    n_updates        | 36945    |
----------------------------------
Eval num_timesteps=188000, episode_reward=185.36 +/- 47.82
Episode length: 46.74 +/- 11.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.7     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.111    |
| time/               |          |
|    total_timesteps  | 188000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.686    |
|    n_updates        | 36999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.11     |
| time/               |          |
|    episodes         | 2500     |
|    fps              | 88       |
|    time_elapsed     | 2121     |
|    total_timesteps  | 188140   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.301    |
|    n_updates        | 37034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | 262      |
|    exploration_rate | 0.108    |
| time/               |          |
|    episodes         | 2504     |
|    fps              | 88       |
|    time_elapsed     | 2121     |
|    total_timesteps  | 188313   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.032    |
|    n_updates        | 37078    |
----------------------------------
Eval num_timesteps=188500, episode_reward=280.20 +/- 122.09
Episode length: 70.48 +/- 30.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.5     |
|    mean_reward      | 280      |
| rollout/            |          |
|    exploration_rate | 0.107    |
| time/               |          |
|    total_timesteps  | 188500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.72     |
|    n_updates        | 37124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | 262      |
|    exploration_rate | 0.106    |
| time/               |          |
|    episodes         | 2508     |
|    fps              | 88       |
|    time_elapsed     | 2128     |
|    total_timesteps  | 188568   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.34     |
|    n_updates        | 37141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 0.104    |
| time/               |          |
|    episodes         | 2512     |
|    fps              | 88       |
|    time_elapsed     | 2128     |
|    total_timesteps  | 188842   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0653   |
|    n_updates        | 37210    |
----------------------------------
Eval num_timesteps=189000, episode_reward=249.12 +/- 113.46
Episode length: 62.64 +/- 28.37
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62.6     |
|    mean_reward      | 249      |
| rollout/            |          |
|    exploration_rate | 0.102    |
| time/               |          |
|    total_timesteps  | 189000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.38     |
|    n_updates        | 37249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.6     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 0.102    |
| time/               |          |
|    episodes         | 2516     |
|    fps              | 88       |
|    time_elapsed     | 2134     |
|    total_timesteps  | 189043   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.806    |
|    n_updates        | 37260    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.2     |
|    ep_rew_mean      | 259      |
|    exploration_rate | 0.0992   |
| time/               |          |
|    episodes         | 2520     |
|    fps              | 88       |
|    time_elapsed     | 2135     |
|    total_timesteps  | 189340   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.765    |
|    n_updates        | 37334    |
----------------------------------
Eval num_timesteps=189500, episode_reward=264.16 +/- 102.59
Episode length: 66.40 +/- 25.69
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.4     |
|    mean_reward      | 264      |
| rollout/            |          |
|    exploration_rate | 0.0977   |
| time/               |          |
|    total_timesteps  | 189500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0652   |
|    n_updates        | 37374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 263      |
|    exploration_rate | 0.0962   |
| time/               |          |
|    episodes         | 2524     |
|    fps              | 88       |
|    time_elapsed     | 2141     |
|    total_timesteps  | 189665   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.725    |
|    n_updates        | 37416    |
----------------------------------
Eval num_timesteps=190000, episode_reward=183.32 +/- 50.30
Episode length: 46.24 +/- 12.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.2     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.0932   |
| time/               |          |
|    total_timesteps  | 190000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0516   |
|    n_updates        | 37499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.093    |
| time/               |          |
|    episodes         | 2528     |
|    fps              | 88       |
|    time_elapsed     | 2146     |
|    total_timesteps  | 190025   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.53     |
|    n_updates        | 37506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.2     |
|    ep_rew_mean      | 271      |
|    exploration_rate | 0.0902   |
| time/               |          |
|    episodes         | 2532     |
|    fps              | 88       |
|    time_elapsed     | 2147     |
|    total_timesteps  | 190331   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.029    |
|    n_updates        | 37582    |
----------------------------------
Eval num_timesteps=190500, episode_reward=254.56 +/- 65.10
Episode length: 64.00 +/- 16.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64       |
|    mean_reward      | 255      |
| rollout/            |          |
|    exploration_rate | 0.0886   |
| time/               |          |
|    total_timesteps  | 190500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0572   |
|    n_updates        | 37624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.6     |
|    ep_rew_mean      | 277      |
|    exploration_rate | 0.0869   |
| time/               |          |
|    episodes         | 2536     |
|    fps              | 88       |
|    time_elapsed     | 2154     |
|    total_timesteps  | 190693   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0675   |
|    n_updates        | 37673    |
----------------------------------
Eval num_timesteps=191000, episode_reward=186.88 +/- 53.04
Episode length: 47.16 +/- 13.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.2     |
|    mean_reward      | 187      |
| rollout/            |          |
|    exploration_rate | 0.0841   |
| time/               |          |
|    total_timesteps  | 191000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.46     |
|    n_updates        | 37749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 0.0839   |
| time/               |          |
|    episodes         | 2540     |
|    fps              | 88       |
|    time_elapsed     | 2159     |
|    total_timesteps  | 191019   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.742    |
|    n_updates        | 37754    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.7     |
|    ep_rew_mean      | 281      |
|    exploration_rate | 0.0814   |
| time/               |          |
|    episodes         | 2544     |
|    fps              | 88       |
|    time_elapsed     | 2160     |
|    total_timesteps  | 191301   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0602   |
|    n_updates        | 37825    |
----------------------------------
Eval num_timesteps=191500, episode_reward=175.96 +/- 39.02
Episode length: 44.34 +/- 9.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.3     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.0796   |
| time/               |          |
|    total_timesteps  | 191500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.107    |
|    n_updates        | 37874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.3     |
|    ep_rew_mean      | 284      |
|    exploration_rate | 0.079    |
| time/               |          |
|    episodes         | 2548     |
|    fps              | 88       |
|    time_elapsed     | 2165     |
|    total_timesteps  | 191564   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.832    |
|    n_updates        | 37890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | 287      |
|    exploration_rate | 0.0764   |
| time/               |          |
|    episodes         | 2552     |
|    fps              | 88       |
|    time_elapsed     | 2166     |
|    total_timesteps  | 191842   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.767    |
|    n_updates        | 37960    |
----------------------------------
Eval num_timesteps=192000, episode_reward=197.26 +/- 66.96
Episode length: 49.74 +/- 16.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.7     |
|    mean_reward      | 197      |
| rollout/            |          |
|    exploration_rate | 0.075    |
| time/               |          |
|    total_timesteps  | 192000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0351   |
|    n_updates        | 37999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | 286      |
|    exploration_rate | 0.0736   |
| time/               |          |
|    episodes         | 2556     |
|    fps              | 88       |
|    time_elapsed     | 2171     |
|    total_timesteps  | 192153   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.727    |
|    n_updates        | 38038    |
----------------------------------
Eval num_timesteps=192500, episode_reward=179.90 +/- 50.76
Episode length: 45.28 +/- 12.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.0704   |
| time/               |          |
|    total_timesteps  | 192500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0828   |
|    n_updates        | 38124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.4     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 0.0701   |
| time/               |          |
|    episodes         | 2560     |
|    fps              | 88       |
|    time_elapsed     | 2176     |
|    total_timesteps  | 192531   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.706    |
|    n_updates        | 38132    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.0669   |
| time/               |          |
|    episodes         | 2564     |
|    fps              | 88       |
|    time_elapsed     | 2177     |
|    total_timesteps  | 192885   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.4      |
|    n_updates        | 38221    |
----------------------------------
Eval num_timesteps=193000, episode_reward=180.96 +/- 33.82
Episode length: 45.68 +/- 8.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.7     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.0658   |
| time/               |          |
|    total_timesteps  | 193000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.748    |
|    n_updates        | 38249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | 293      |
|    exploration_rate | 0.065    |
| time/               |          |
|    episodes         | 2568     |
|    fps              | 88       |
|    time_elapsed     | 2182     |
|    total_timesteps  | 193090   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.4      |
|    n_updates        | 38272    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | 289      |
|    exploration_rate | 0.0628   |
| time/               |          |
|    episodes         | 2572     |
|    fps              | 88       |
|    time_elapsed     | 2182     |
|    total_timesteps  | 193328   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.706    |
|    n_updates        | 38331    |
----------------------------------
Eval num_timesteps=193500, episode_reward=271.18 +/- 138.10
Episode length: 68.14 +/- 34.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.1     |
|    mean_reward      | 271      |
| rollout/            |          |
|    exploration_rate | 0.0613   |
| time/               |          |
|    total_timesteps  | 193500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.684    |
|    n_updates        | 38374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.4     |
|    ep_rew_mean      | 288      |
|    exploration_rate | 0.0597   |
| time/               |          |
|    episodes         | 2576     |
|    fps              | 88       |
|    time_elapsed     | 2189     |
|    total_timesteps  | 193673   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.711    |
|    n_updates        | 38418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | 282      |
|    exploration_rate | 0.0575   |
| time/               |          |
|    episodes         | 2580     |
|    fps              | 88       |
|    time_elapsed     | 2190     |
|    total_timesteps  | 193912   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0421   |
|    n_updates        | 38477    |
----------------------------------
Eval num_timesteps=194000, episode_reward=196.68 +/- 53.97
Episode length: 49.56 +/- 13.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.6     |
|    mean_reward      | 197      |
| rollout/            |          |
|    exploration_rate | 0.0567   |
| time/               |          |
|    total_timesteps  | 194000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.688    |
|    n_updates        | 38499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 0.0552   |
| time/               |          |
|    episodes         | 2584     |
|    fps              | 88       |
|    time_elapsed     | 2195     |
|    total_timesteps  | 194154   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.128    |
|    n_updates        | 38538    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 0.0532   |
| time/               |          |
|    episodes         | 2588     |
|    fps              | 88       |
|    time_elapsed     | 2196     |
|    total_timesteps  | 194379   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.711    |
|    n_updates        | 38594    |
----------------------------------
Eval num_timesteps=194500, episode_reward=303.46 +/- 166.50
Episode length: 76.26 +/- 41.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 76.3     |
|    mean_reward      | 303      |
| rollout/            |          |
|    exploration_rate | 0.0521   |
| time/               |          |
|    total_timesteps  | 194500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.106    |
|    n_updates        | 38624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.7     |
|    ep_rew_mean      | 281      |
|    exploration_rate | 0.0508   |
| time/               |          |
|    episodes         | 2592     |
|    fps              | 88       |
|    time_elapsed     | 2203     |
|    total_timesteps  | 194642   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0598   |
|    n_updates        | 38660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.4     |
|    ep_rew_mean      | 280      |
|    exploration_rate | 0.0491   |
| time/               |          |
|    episodes         | 2596     |
|    fps              | 88       |
|    time_elapsed     | 2204     |
|    total_timesteps  | 194817   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.92     |
|    n_updates        | 38704    |
----------------------------------
Eval num_timesteps=195000, episode_reward=203.80 +/- 94.62
Episode length: 51.32 +/- 23.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51.3     |
|    mean_reward      | 204      |
| rollout/            |          |
|    exploration_rate | 0.0475   |
| time/               |          |
|    total_timesteps  | 195000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.744    |
|    n_updates        | 38749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69       |
|    ep_rew_mean      | 275      |
|    exploration_rate | 0.0471   |
| time/               |          |
|    episodes         | 2600     |
|    fps              | 88       |
|    time_elapsed     | 2209     |
|    total_timesteps  | 195042   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0559   |
|    n_updates        | 38760    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.9     |
|    ep_rew_mean      | 278      |
|    exploration_rate | 0.0446   |
| time/               |          |
|    episodes         | 2604     |
|    fps              | 88       |
|    time_elapsed     | 2210     |
|    total_timesteps  | 195305   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.99     |
|    n_updates        | 38826    |
----------------------------------
Eval num_timesteps=195500, episode_reward=175.84 +/- 46.71
Episode length: 44.40 +/- 11.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.0429   |
| time/               |          |
|    total_timesteps  | 195500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.42     |
|    n_updates        | 38874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.6     |
|    ep_rew_mean      | 277      |
|    exploration_rate | 0.0426   |
| time/               |          |
|    episodes         | 2608     |
|    fps              | 88       |
|    time_elapsed     | 2215     |
|    total_timesteps  | 195525   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.703    |
|    n_updates        | 38881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.3     |
|    ep_rew_mean      | 276      |
|    exploration_rate | 0.0403   |
| time/               |          |
|    episodes         | 2612     |
|    fps              | 88       |
|    time_elapsed     | 2215     |
|    total_timesteps  | 195772   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.712    |
|    n_updates        | 38942    |
----------------------------------
Eval num_timesteps=196000, episode_reward=179.42 +/- 82.67
Episode length: 45.22 +/- 20.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.0382   |
| time/               |          |
|    total_timesteps  | 196000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0802   |
|    n_updates        | 38999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.6     |
|    ep_rew_mean      | 277      |
|    exploration_rate | 0.0382   |
| time/               |          |
|    episodes         | 2616     |
|    fps              | 88       |
|    time_elapsed     | 2220     |
|    total_timesteps  | 196003   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.02     |
|    n_updates        | 39000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | 283      |
|    exploration_rate | 0.0341   |
| time/               |          |
|    episodes         | 2620     |
|    fps              | 88       |
|    time_elapsed     | 2221     |
|    total_timesteps  | 196448   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0948   |
|    n_updates        | 39111    |
----------------------------------
Eval num_timesteps=196500, episode_reward=169.92 +/- 44.03
Episode length: 42.76 +/- 10.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.0336   |
| time/               |          |
|    total_timesteps  | 196500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.08     |
|    n_updates        | 39124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.9     |
|    ep_rew_mean      | 278      |
|    exploration_rate | 0.0322   |
| time/               |          |
|    episodes         | 2624     |
|    fps              | 88       |
|    time_elapsed     | 2226     |
|    total_timesteps  | 196654   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0969   |
|    n_updates        | 39163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.4     |
|    ep_rew_mean      | 276      |
|    exploration_rate | 0.0293   |
| time/               |          |
|    episodes         | 2628     |
|    fps              | 88       |
|    time_elapsed     | 2226     |
|    total_timesteps  | 196962   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0521   |
|    n_updates        | 39240    |
----------------------------------
Eval num_timesteps=197000, episode_reward=183.02 +/- 52.98
Episode length: 46.12 +/- 13.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.029    |
| time/               |          |
|    total_timesteps  | 197000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.94     |
|    n_updates        | 39249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.4     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 0.0273   |
| time/               |          |
|    episodes         | 2632     |
|    fps              | 88       |
|    time_elapsed     | 2231     |
|    total_timesteps  | 197175   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0401   |
|    n_updates        | 39293    |
----------------------------------
Eval num_timesteps=197500, episode_reward=170.28 +/- 39.38
Episode length: 42.98 +/- 9.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43       |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.0243   |
| time/               |          |
|    total_timesteps  | 197500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.756    |
|    n_updates        | 39374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | 279      |
|    exploration_rate | 0.0225   |
| time/               |          |
|    episodes         | 2636     |
|    fps              | 88       |
|    time_elapsed     | 2236     |
|    total_timesteps  | 197699   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.709    |
|    n_updates        | 39424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | 276      |
|    exploration_rate | 0.0202   |
| time/               |          |
|    episodes         | 2640     |
|    fps              | 88       |
|    time_elapsed     | 2237     |
|    total_timesteps  | 197941   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.37     |
|    n_updates        | 39485    |
----------------------------------
Eval num_timesteps=198000, episode_reward=291.34 +/- 148.69
Episode length: 73.20 +/- 37.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 73.2     |
|    mean_reward      | 291      |
| rollout/            |          |
|    exploration_rate | 0.0197   |
| time/               |          |
|    total_timesteps  | 198000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.792    |
|    n_updates        | 39499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68       |
|    ep_rew_mean      | 271      |
|    exploration_rate | 0.0187   |
| time/               |          |
|    episodes         | 2644     |
|    fps              | 88       |
|    time_elapsed     | 2243     |
|    total_timesteps  | 198104   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0702   |
|    n_updates        | 39525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.1     |
|    ep_rew_mean      | 267      |
|    exploration_rate | 0.0171   |
| time/               |          |
|    episodes         | 2648     |
|    fps              | 88       |
|    time_elapsed     | 2244     |
|    total_timesteps  | 198274   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0539   |
|    n_updates        | 39568    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.0153   |
| time/               |          |
|    episodes         | 2652     |
|    fps              | 88       |
|    time_elapsed     | 2244     |
|    total_timesteps  | 198470   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0438   |
|    n_updates        | 39617    |
----------------------------------
Eval num_timesteps=198500, episode_reward=316.44 +/- 215.17
Episode length: 79.46 +/- 53.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 79.5     |
|    mean_reward      | 316      |
| rollout/            |          |
|    exploration_rate | 0.015    |
| time/               |          |
|    total_timesteps  | 198500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0497   |
|    n_updates        | 39624    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.0124   |
| time/               |          |
|    episodes         | 2656     |
|    fps              | 88       |
|    time_elapsed     | 2252     |
|    total_timesteps  | 198778   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.687    |
|    n_updates        | 39694    |
----------------------------------
Eval num_timesteps=199000, episode_reward=190.06 +/- 59.54
Episode length: 47.90 +/- 14.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.9     |
|    mean_reward      | 190      |
| rollout/            |          |
|    exploration_rate | 0.0104   |
| time/               |          |
|    total_timesteps  | 199000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.38     |
|    n_updates        | 39749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.00955  |
| time/               |          |
|    episodes         | 2660     |
|    fps              | 88       |
|    time_elapsed     | 2257     |
|    total_timesteps  | 199086   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.706    |
|    n_updates        | 39771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 258      |
|    exploration_rate | 0.00689  |
| time/               |          |
|    episodes         | 2664     |
|    fps              | 88       |
|    time_elapsed     | 2258     |
|    total_timesteps  | 199370   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.037    |
|    n_updates        | 39842    |
----------------------------------
Eval num_timesteps=199500, episode_reward=180.12 +/- 49.05
Episode length: 45.36 +/- 12.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.00569  |
| time/               |          |
|    total_timesteps  | 199500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.69     |
|    n_updates        | 39874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.9     |
|    ep_rew_mean      | 258      |
|    exploration_rate | 0.00497  |
| time/               |          |
|    episodes         | 2668     |
|    fps              | 88       |
|    time_elapsed     | 2262     |
|    total_timesteps  | 199576   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.686    |
|    n_updates        | 39893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.00215  |
| time/               |          |
|    episodes         | 2672     |
|    fps              | 88       |
|    time_elapsed     | 2263     |
|    total_timesteps  | 199877   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.29     |
|    n_updates        | 39969    |
----------------------------------
Eval num_timesteps=200000, episode_reward=182.82 +/- 45.65
Episode length: 46.00 +/- 11.40
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46       |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.00101  |
| time/               |          |
|    total_timesteps  | 200000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.01     |
|    n_updates        | 39999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 256      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2676     |
|    fps              | 88       |
|    time_elapsed     | 2269     |
|    total_timesteps  | 200101   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.181    |
|    n_updates        | 40025    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.7     |
|    ep_rew_mean      | 253      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2680     |
|    fps              | 88       |
|    time_elapsed     | 2270     |
|    total_timesteps  | 200279   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.708    |
|    n_updates        | 40069    |
----------------------------------
Eval num_timesteps=200500, episode_reward=183.12 +/- 48.93
Episode length: 46.10 +/- 12.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 200500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.752    |
|    n_updates        | 40124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.6     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2684     |
|    fps              | 88       |
|    time_elapsed     | 2276     |
|    total_timesteps  | 200611   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0867   |
|    n_updates        | 40152    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2688     |
|    fps              | 88       |
|    time_elapsed     | 2277     |
|    total_timesteps  | 200935   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.223    |
|    n_updates        | 40233    |
----------------------------------
Eval num_timesteps=201000, episode_reward=183.90 +/- 51.50
Episode length: 46.38 +/- 12.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.4     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 201000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.47     |
|    n_updates        | 40249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.1     |
|    ep_rew_mean      | 259      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2692     |
|    fps              | 88       |
|    time_elapsed     | 2282     |
|    total_timesteps  | 201155   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.776    |
|    n_updates        | 40288    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2696     |
|    fps              | 88       |
|    time_elapsed     | 2282     |
|    total_timesteps  | 201446   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0642   |
|    n_updates        | 40361    |
----------------------------------
Eval num_timesteps=201500, episode_reward=216.06 +/- 44.64
Episode length: 54.40 +/- 11.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.4     |
|    mean_reward      | 216      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 201500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.11     |
|    n_updates        | 40374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | 267      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2700     |
|    fps              | 88       |
|    time_elapsed     | 2288     |
|    total_timesteps  | 201741   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.176    |
|    n_updates        | 40435    |
----------------------------------
Eval num_timesteps=202000, episode_reward=192.52 +/- 37.57
Episode length: 48.56 +/- 9.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.6     |
|    mean_reward      | 193      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 202000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.52     |
|    n_updates        | 40499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.2     |
|    ep_rew_mean      | 267      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2704     |
|    fps              | 88       |
|    time_elapsed     | 2294     |
|    total_timesteps  | 202025   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.193    |
|    n_updates        | 40506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2708     |
|    fps              | 88       |
|    time_elapsed     | 2295     |
|    total_timesteps  | 202266   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.75     |
|    n_updates        | 40566    |
----------------------------------
Eval num_timesteps=202500, episode_reward=194.18 +/- 58.64
Episode length: 48.96 +/- 14.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49       |
|    mean_reward      | 194      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 202500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0662   |
|    n_updates        | 40624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.7     |
|    ep_rew_mean      | 273      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2712     |
|    fps              | 88       |
|    time_elapsed     | 2300     |
|    total_timesteps  | 202642   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0643   |
|    n_updates        | 40660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | 276      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2716     |
|    fps              | 88       |
|    time_elapsed     | 2301     |
|    total_timesteps  | 202948   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.04     |
|    n_updates        | 40736    |
----------------------------------
Eval num_timesteps=203000, episode_reward=183.14 +/- 48.91
Episode length: 46.10 +/- 12.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 203000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.48     |
|    n_updates        | 40749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 266      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2720     |
|    fps              | 88       |
|    time_elapsed     | 2306     |
|    total_timesteps  | 203142   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.12     |
|    n_updates        | 40785    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | 269      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2724     |
|    fps              | 88       |
|    time_elapsed     | 2307     |
|    total_timesteps  | 203409   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0457   |
|    n_updates        | 40852    |
----------------------------------
Eval num_timesteps=203500, episode_reward=218.14 +/- 109.04
Episode length: 54.96 +/- 27.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55       |
|    mean_reward      | 218      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 203500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.754    |
|    n_updates        | 40874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2728     |
|    fps              | 87       |
|    time_elapsed     | 2316     |
|    total_timesteps  | 203702   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0534   |
|    n_updates        | 40925    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | 270      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2732     |
|    fps              | 88       |
|    time_elapsed     | 2317     |
|    total_timesteps  | 203958   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0279   |
|    n_updates        | 40989    |
----------------------------------
Eval num_timesteps=204000, episode_reward=178.92 +/- 46.98
Episode length: 45.14 +/- 11.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.1     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 204000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.061    |
|    n_updates        | 40999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.9     |
|    ep_rew_mean      | 258      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2736     |
|    fps              | 87       |
|    time_elapsed     | 2322     |
|    total_timesteps  | 204186   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.131    |
|    n_updates        | 41046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.6     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2740     |
|    fps              | 87       |
|    time_elapsed     | 2323     |
|    total_timesteps  | 204398   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.151    |
|    n_updates        | 41099    |
----------------------------------
Eval num_timesteps=204500, episode_reward=170.92 +/- 43.00
Episode length: 43.06 +/- 10.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.1     |
|    mean_reward      | 171      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 204500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.79     |
|    n_updates        | 41124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.7     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2744     |
|    fps              | 87       |
|    time_elapsed     | 2327     |
|    total_timesteps  | 204573   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.46     |
|    n_updates        | 41143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | 263      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2748     |
|    fps              | 87       |
|    time_elapsed     | 2329     |
|    total_timesteps  | 204879   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.907    |
|    n_updates        | 41219    |
----------------------------------
Eval num_timesteps=205000, episode_reward=194.70 +/- 52.51
Episode length: 48.96 +/- 13.13
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49       |
|    mean_reward      | 195      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 205000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.72     |
|    n_updates        | 41249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.5     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2752     |
|    fps              | 87       |
|    time_elapsed     | 2334     |
|    total_timesteps  | 205121   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.56     |
|    n_updates        | 41280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2756     |
|    fps              | 87       |
|    time_elapsed     | 2335     |
|    total_timesteps  | 205339   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.838    |
|    n_updates        | 41334    |
----------------------------------
Eval num_timesteps=205500, episode_reward=187.82 +/- 56.19
Episode length: 47.30 +/- 14.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 205500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.45     |
|    n_updates        | 41374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.5     |
|    ep_rew_mean      | 256      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2760     |
|    fps              | 87       |
|    time_elapsed     | 2342     |
|    total_timesteps  | 205538   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.715    |
|    n_updates        | 41384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.5     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2764     |
|    fps              | 87       |
|    time_elapsed     | 2343     |
|    total_timesteps  | 205721   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0472   |
|    n_updates        | 41430    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 254      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2768     |
|    fps              | 87       |
|    time_elapsed     | 2344     |
|    total_timesteps  | 205982   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.43     |
|    n_updates        | 41495    |
----------------------------------
Eval num_timesteps=206000, episode_reward=182.14 +/- 49.56
Episode length: 45.92 +/- 12.41
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 206000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.123    |
|    n_updates        | 41499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 253      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2772     |
|    fps              | 87       |
|    time_elapsed     | 2352     |
|    total_timesteps  | 206259   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.739    |
|    n_updates        | 41564    |
----------------------------------
Eval num_timesteps=206500, episode_reward=180.14 +/- 45.89
Episode length: 45.36 +/- 11.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 206500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.066    |
|    n_updates        | 41624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2776     |
|    fps              | 87       |
|    time_elapsed     | 2358     |
|    total_timesteps  | 206507   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0376   |
|    n_updates        | 41626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.7     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2780     |
|    fps              | 87       |
|    time_elapsed     | 2359     |
|    total_timesteps  | 206745   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.61     |
|    n_updates        | 41686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.4     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2784     |
|    fps              | 87       |
|    time_elapsed     | 2360     |
|    total_timesteps  | 206953   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0338   |
|    n_updates        | 41738    |
----------------------------------
Eval num_timesteps=207000, episode_reward=189.58 +/- 49.16
Episode length: 47.76 +/- 12.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.8     |
|    mean_reward      | 190      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 207000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.114    |
|    n_updates        | 41749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62       |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2788     |
|    fps              | 87       |
|    time_elapsed     | 2366     |
|    total_timesteps  | 207130   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.44     |
|    n_updates        | 41782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.6     |
|    ep_rew_mean      | 249      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2792     |
|    fps              | 87       |
|    time_elapsed     | 2368     |
|    total_timesteps  | 207415   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0588   |
|    n_updates        | 41853    |
----------------------------------
Eval num_timesteps=207500, episode_reward=184.08 +/- 41.91
Episode length: 46.38 +/- 10.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.4     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 207500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.47     |
|    n_updates        | 41874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.9     |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2796     |
|    fps              | 87       |
|    time_elapsed     | 2375     |
|    total_timesteps  | 207632   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.41     |
|    n_updates        | 41907    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.9     |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2800     |
|    fps              | 87       |
|    time_elapsed     | 2376     |
|    total_timesteps  | 207930   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.843    |
|    n_updates        | 41982    |
----------------------------------
Eval num_timesteps=208000, episode_reward=180.98 +/- 42.65
Episode length: 45.58 +/- 10.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 208000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.735    |
|    n_updates        | 41999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.9     |
|    ep_rew_mean      | 242      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2804     |
|    fps              | 87       |
|    time_elapsed     | 2381     |
|    total_timesteps  | 208110   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0572   |
|    n_updates        | 42027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.8     |
|    ep_rew_mean      | 242      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2808     |
|    fps              | 87       |
|    time_elapsed     | 2382     |
|    total_timesteps  | 208348   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.762    |
|    n_updates        | 42086    |
----------------------------------
Eval num_timesteps=208500, episode_reward=176.08 +/- 39.70
Episode length: 44.46 +/- 9.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.5     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 208500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.825    |
|    n_updates        | 42124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.8     |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2812     |
|    fps              | 87       |
|    time_elapsed     | 2387     |
|    total_timesteps  | 208623   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.058    |
|    n_updates        | 42155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.1     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2816     |
|    fps              | 87       |
|    time_elapsed     | 2387     |
|    total_timesteps  | 208858   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.41     |
|    n_updates        | 42214    |
----------------------------------
Eval num_timesteps=209000, episode_reward=171.76 +/- 69.61
Episode length: 43.32 +/- 17.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.3     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 209000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.2      |
|    n_updates        | 42249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59       |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2820     |
|    fps              | 87       |
|    time_elapsed     | 2392     |
|    total_timesteps  | 209043   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.47     |
|    n_updates        | 42260    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58       |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2824     |
|    fps              | 87       |
|    time_elapsed     | 2393     |
|    total_timesteps  | 209206   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.754    |
|    n_updates        | 42301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.8     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2828     |
|    fps              | 87       |
|    time_elapsed     | 2393     |
|    total_timesteps  | 209377   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.683    |
|    n_updates        | 42344    |
----------------------------------
Eval num_timesteps=209500, episode_reward=186.94 +/- 96.82
Episode length: 47.12 +/- 24.22
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.1     |
|    mean_reward      | 187      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 209500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0472   |
|    n_updates        | 42374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.9     |
|    ep_rew_mean      | 226      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2832     |
|    fps              | 87       |
|    time_elapsed     | 2399     |
|    total_timesteps  | 209651   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0482   |
|    n_updates        | 42412    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.2     |
|    ep_rew_mean      | 227      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2836     |
|    fps              | 87       |
|    time_elapsed     | 2400     |
|    total_timesteps  | 209905   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.111    |
|    n_updates        | 42476    |
----------------------------------
Eval num_timesteps=210000, episode_reward=173.20 +/- 40.57
Episode length: 43.64 +/- 10.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 210000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0481   |
|    n_updates        | 42499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57       |
|    ep_rew_mean      | 227      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2840     |
|    fps              | 87       |
|    time_elapsed     | 2404     |
|    total_timesteps  | 210103   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.153    |
|    n_updates        | 42525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.9     |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2844     |
|    fps              | 87       |
|    time_elapsed     | 2405     |
|    total_timesteps  | 210362   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.162    |
|    n_updates        | 42590    |
----------------------------------
Eval num_timesteps=210500, episode_reward=169.84 +/- 37.58
Episode length: 42.90 +/- 9.43
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 210500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.781    |
|    n_updates        | 42624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2848     |
|    fps              | 87       |
|    time_elapsed     | 2409     |
|    total_timesteps  | 210644   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.05     |
|    n_updates        | 42660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.9     |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2852     |
|    fps              | 87       |
|    time_elapsed     | 2410     |
|    total_timesteps  | 210911   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.031    |
|    n_updates        | 42727    |
----------------------------------
Eval num_timesteps=211000, episode_reward=177.68 +/- 50.12
Episode length: 44.78 +/- 12.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 211000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.92     |
|    n_updates        | 42749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.7     |
|    ep_rew_mean      | 233      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2856     |
|    fps              | 87       |
|    time_elapsed     | 2415     |
|    total_timesteps  | 211206   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.87     |
|    n_updates        | 42801    |
----------------------------------
Eval num_timesteps=211500, episode_reward=179.12 +/- 41.95
Episode length: 45.18 +/- 10.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 211500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.26     |
|    n_updates        | 42874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60       |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2860     |
|    fps              | 87       |
|    time_elapsed     | 2420     |
|    total_timesteps  | 211541   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.2      |
|    n_updates        | 42885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.3     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2864     |
|    fps              | 87       |
|    time_elapsed     | 2420     |
|    total_timesteps  | 211748   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.122    |
|    n_updates        | 42936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.9     |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2868     |
|    fps              | 87       |
|    time_elapsed     | 2421     |
|    total_timesteps  | 211974   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.831    |
|    n_updates        | 42993    |
----------------------------------
Eval num_timesteps=212000, episode_reward=183.64 +/- 37.59
Episode length: 46.28 +/- 9.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.3     |
|    mean_reward      | 184      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 212000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.56     |
|    n_updates        | 42999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.7     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2872     |
|    fps              | 87       |
|    time_elapsed     | 2426     |
|    total_timesteps  | 212231   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.31     |
|    n_updates        | 43057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.4     |
|    ep_rew_mean      | 236      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2876     |
|    fps              | 87       |
|    time_elapsed     | 2426     |
|    total_timesteps  | 212445   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.48     |
|    n_updates        | 43111    |
----------------------------------
Eval num_timesteps=212500, episode_reward=186.54 +/- 49.25
Episode length: 47.06 +/- 12.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.1     |
|    mean_reward      | 187      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 212500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.805    |
|    n_updates        | 43124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.8     |
|    ep_rew_mean      | 233      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2880     |
|    fps              | 87       |
|    time_elapsed     | 2431     |
|    total_timesteps  | 212621   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0698   |
|    n_updates        | 43155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.3     |
|    ep_rew_mean      | 232      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2884     |
|    fps              | 87       |
|    time_elapsed     | 2431     |
|    total_timesteps  | 212783   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.24     |
|    n_updates        | 43195    |
----------------------------------
Eval num_timesteps=213000, episode_reward=172.66 +/- 45.46
Episode length: 43.58 +/- 11.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 213000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0778   |
|    n_updates        | 43249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.7     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2888     |
|    fps              | 87       |
|    time_elapsed     | 2436     |
|    total_timesteps  | 213096   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.47     |
|    n_updates        | 43273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60       |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2892     |
|    fps              | 87       |
|    time_elapsed     | 2437     |
|    total_timesteps  | 213412   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.5      |
|    n_updates        | 43352    |
----------------------------------
Eval num_timesteps=213500, episode_reward=172.20 +/- 46.47
Episode length: 43.40 +/- 11.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.4     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 213500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.727    |
|    n_updates        | 43374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.2     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2896     |
|    fps              | 87       |
|    time_elapsed     | 2441     |
|    total_timesteps  | 213555   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.796    |
|    n_updates        | 43388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58       |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2900     |
|    fps              | 87       |
|    time_elapsed     | 2441     |
|    total_timesteps  | 213731   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0308   |
|    n_updates        | 43432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.5     |
|    ep_rew_mean      | 232      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2904     |
|    fps              | 87       |
|    time_elapsed     | 2442     |
|    total_timesteps  | 213961   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0545   |
|    n_updates        | 43490    |
----------------------------------
Eval num_timesteps=214000, episode_reward=180.24 +/- 41.88
Episode length: 45.38 +/- 10.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 214000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.49     |
|    n_updates        | 43499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.7     |
|    ep_rew_mean      | 233      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2908     |
|    fps              | 87       |
|    time_elapsed     | 2447     |
|    total_timesteps  | 214218   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0919   |
|    n_updates        | 43554    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2912     |
|    fps              | 87       |
|    time_elapsed     | 2447     |
|    total_timesteps  | 214386   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0993   |
|    n_updates        | 43596    |
----------------------------------
Eval num_timesteps=214500, episode_reward=222.04 +/- 119.85
Episode length: 55.88 +/- 29.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.9     |
|    mean_reward      | 222      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 214500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.104    |
|    n_updates        | 43624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.1     |
|    ep_rew_mean      | 231      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2916     |
|    fps              | 87       |
|    time_elapsed     | 2453     |
|    total_timesteps  | 214672   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.66     |
|    n_updates        | 43667    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.1     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2920     |
|    fps              | 87       |
|    time_elapsed     | 2455     |
|    total_timesteps  | 214958   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.804    |
|    n_updates        | 43739    |
----------------------------------
Eval num_timesteps=215000, episode_reward=174.74 +/- 49.92
Episode length: 44.04 +/- 12.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44       |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 215000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.48     |
|    n_updates        | 43749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.5     |
|    ep_rew_mean      | 236      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2924     |
|    fps              | 87       |
|    time_elapsed     | 2460     |
|    total_timesteps  | 215154   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0896   |
|    n_updates        | 43788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.9     |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2928     |
|    fps              | 87       |
|    time_elapsed     | 2461     |
|    total_timesteps  | 215271   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.821    |
|    n_updates        | 43817    |
----------------------------------
Eval num_timesteps=215500, episode_reward=179.66 +/- 39.41
Episode length: 45.30 +/- 9.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.3     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 215500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0937   |
|    n_updates        | 43874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.1     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2932     |
|    fps              | 87       |
|    time_elapsed     | 2465     |
|    total_timesteps  | 215560   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.23     |
|    n_updates        | 43889    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.1     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2936     |
|    fps              | 87       |
|    time_elapsed     | 2466     |
|    total_timesteps  | 215817   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.896    |
|    n_updates        | 43954    |
----------------------------------
Eval num_timesteps=216000, episode_reward=163.58 +/- 42.76
Episode length: 41.20 +/- 10.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.2     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 216000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.781    |
|    n_updates        | 43999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.1     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2940     |
|    fps              | 87       |
|    time_elapsed     | 2470     |
|    total_timesteps  | 216009   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.16     |
|    n_updates        | 44002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59       |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2944     |
|    fps              | 87       |
|    time_elapsed     | 2471     |
|    total_timesteps  | 216263   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.82     |
|    n_updates        | 44065    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.3     |
|    ep_rew_mean      | 231      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2948     |
|    fps              | 87       |
|    time_elapsed     | 2472     |
|    total_timesteps  | 216471   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0519   |
|    n_updates        | 44117    |
----------------------------------
Eval num_timesteps=216500, episode_reward=167.36 +/- 53.77
Episode length: 42.18 +/- 13.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.2     |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 216500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.759    |
|    n_updates        | 44124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.5     |
|    ep_rew_mean      | 228      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2952     |
|    fps              | 87       |
|    time_elapsed     | 2476     |
|    total_timesteps  | 216663   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.813    |
|    n_updates        | 44165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.7     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2956     |
|    fps              | 87       |
|    time_elapsed     | 2477     |
|    total_timesteps  | 216878   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0678   |
|    n_updates        | 44219    |
----------------------------------
Eval num_timesteps=217000, episode_reward=167.38 +/- 46.07
Episode length: 42.18 +/- 11.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.2     |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 217000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.785    |
|    n_updates        | 44249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.1     |
|    ep_rew_mean      | 227      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2960     |
|    fps              | 87       |
|    time_elapsed     | 2482     |
|    total_timesteps  | 217247   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.897    |
|    n_updates        | 44311    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.1     |
|    ep_rew_mean      | 227      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2964     |
|    fps              | 87       |
|    time_elapsed     | 2482     |
|    total_timesteps  | 217457   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.846    |
|    n_updates        | 44364    |
----------------------------------
Eval num_timesteps=217500, episode_reward=166.74 +/- 42.90
Episode length: 42.02 +/- 10.70
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42       |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 217500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.57     |
|    n_updates        | 44374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57       |
|    ep_rew_mean      | 226      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2968     |
|    fps              | 87       |
|    time_elapsed     | 2487     |
|    total_timesteps  | 217670   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.684    |
|    n_updates        | 44417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.6     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2972     |
|    fps              | 87       |
|    time_elapsed     | 2487     |
|    total_timesteps  | 217890   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.47     |
|    n_updates        | 44472    |
----------------------------------
Eval num_timesteps=218000, episode_reward=177.22 +/- 55.39
Episode length: 44.68 +/- 13.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.7     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 218000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0858   |
|    n_updates        | 44499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.2     |
|    ep_rew_mean      | 227      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2976     |
|    fps              | 87       |
|    time_elapsed     | 2492     |
|    total_timesteps  | 218166   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.92     |
|    n_updates        | 44541    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2980     |
|    fps              | 87       |
|    time_elapsed     | 2493     |
|    total_timesteps  | 218385   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0527   |
|    n_updates        | 44596    |
----------------------------------
Eval num_timesteps=218500, episode_reward=185.08 +/- 42.07
Episode length: 46.58 +/- 10.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.6     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 218500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.9      |
|    n_updates        | 44624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.4     |
|    ep_rew_mean      | 232      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2984     |
|    fps              | 87       |
|    time_elapsed     | 2497     |
|    total_timesteps  | 218623   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.814    |
|    n_updates        | 44655    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.3     |
|    ep_rew_mean      | 228      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2988     |
|    fps              | 87       |
|    time_elapsed     | 2498     |
|    total_timesteps  | 218825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.42     |
|    n_updates        | 44706    |
----------------------------------
Eval num_timesteps=219000, episode_reward=186.42 +/- 46.86
Episode length: 46.94 +/- 11.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.9     |
|    mean_reward      | 186      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 219000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.888    |
|    n_updates        | 44749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.7     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2992     |
|    fps              | 87       |
|    time_elapsed     | 2503     |
|    total_timesteps  | 219079   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0912   |
|    n_updates        | 44769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.9     |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 2996     |
|    fps              | 87       |
|    time_elapsed     | 2504     |
|    total_timesteps  | 219445   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.833    |
|    n_updates        | 44861    |
----------------------------------
Eval num_timesteps=219500, episode_reward=177.70 +/- 53.08
Episode length: 44.76 +/- 13.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 219500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.937    |
|    n_updates        | 44874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.5     |
|    ep_rew_mean      | 236      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3000     |
|    fps              | 87       |
|    time_elapsed     | 2508     |
|    total_timesteps  | 219676   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.143    |
|    n_updates        | 44918    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.1     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3004     |
|    fps              | 87       |
|    time_elapsed     | 2509     |
|    total_timesteps  | 219976   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.717    |
|    n_updates        | 44993    |
----------------------------------
Eval num_timesteps=220000, episode_reward=167.62 +/- 36.43
Episode length: 42.36 +/- 9.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.4     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 220000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.072    |
|    n_updates        | 44999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3008     |
|    fps              | 87       |
|    time_elapsed     | 2513     |
|    total_timesteps  | 220234   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0946   |
|    n_updates        | 45058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.3     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3012     |
|    fps              | 87       |
|    time_elapsed     | 2514     |
|    total_timesteps  | 220419   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.897    |
|    n_updates        | 45104    |
----------------------------------
Eval num_timesteps=220500, episode_reward=177.10 +/- 55.91
Episode length: 44.64 +/- 13.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.6     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 220500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.887    |
|    n_updates        | 45124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.2     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3016     |
|    fps              | 87       |
|    time_elapsed     | 2518     |
|    total_timesteps  | 220593   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.097    |
|    n_updates        | 45148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.9     |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3020     |
|    fps              | 87       |
|    time_elapsed     | 2519     |
|    total_timesteps  | 220847   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0908   |
|    n_updates        | 45211    |
----------------------------------
Eval num_timesteps=221000, episode_reward=173.46 +/- 39.89
Episode length: 43.76 +/- 9.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.8     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 221000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.905    |
|    n_updates        | 45249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.8     |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3024     |
|    fps              | 87       |
|    time_elapsed     | 2524     |
|    total_timesteps  | 221133   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.806    |
|    n_updates        | 45283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.5     |
|    ep_rew_mean      | 245      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3028     |
|    fps              | 87       |
|    time_elapsed     | 2525     |
|    total_timesteps  | 221422   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.14     |
|    n_updates        | 45355    |
----------------------------------
Eval num_timesteps=221500, episode_reward=184.84 +/- 46.88
Episode length: 46.58 +/- 11.77
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.6     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 221500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.848    |
|    n_updates        | 45374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3032     |
|    fps              | 87       |
|    time_elapsed     | 2529     |
|    total_timesteps  | 221609   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.862    |
|    n_updates        | 45402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.1     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3036     |
|    fps              | 87       |
|    time_elapsed     | 2530     |
|    total_timesteps  | 221830   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.154    |
|    n_updates        | 45457    |
----------------------------------
Eval num_timesteps=222000, episode_reward=180.32 +/- 47.88
Episode length: 45.36 +/- 12.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 222000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.841    |
|    n_updates        | 45499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3040     |
|    fps              | 87       |
|    time_elapsed     | 2534     |
|    total_timesteps  | 222031   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0572   |
|    n_updates        | 45507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.2     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3044     |
|    fps              | 87       |
|    time_elapsed     | 2535     |
|    total_timesteps  | 222379   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.15     |
|    n_updates        | 45594    |
----------------------------------
Eval num_timesteps=222500, episode_reward=172.92 +/- 51.18
Episode length: 43.62 +/- 12.81
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 222500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0745   |
|    n_updates        | 45624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.8     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3048     |
|    fps              | 87       |
|    time_elapsed     | 2540     |
|    total_timesteps  | 222546   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.25     |
|    n_updates        | 45636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62       |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3052     |
|    fps              | 87       |
|    time_elapsed     | 2541     |
|    total_timesteps  | 222858   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.54     |
|    n_updates        | 45714    |
----------------------------------
Eval num_timesteps=223000, episode_reward=181.90 +/- 50.05
Episode length: 45.84 +/- 12.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.8     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 223000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.762    |
|    n_updates        | 45749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62       |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3056     |
|    fps              | 87       |
|    time_elapsed     | 2547     |
|    total_timesteps  | 223077   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.175    |
|    n_updates        | 45769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.7     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3060     |
|    fps              | 87       |
|    time_elapsed     | 2548     |
|    total_timesteps  | 223316   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0794   |
|    n_updates        | 45828    |
----------------------------------
Eval num_timesteps=223500, episode_reward=169.22 +/- 47.13
Episode length: 42.64 +/- 11.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 223500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.52     |
|    n_updates        | 45874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.6     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3064     |
|    fps              | 87       |
|    time_elapsed     | 2552     |
|    total_timesteps  | 223519   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.181    |
|    n_updates        | 45879    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3068     |
|    fps              | 87       |
|    time_elapsed     | 2553     |
|    total_timesteps  | 223716   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.93     |
|    n_updates        | 45928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60       |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3072     |
|    fps              | 87       |
|    time_elapsed     | 2554     |
|    total_timesteps  | 223887   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.36     |
|    n_updates        | 45971    |
----------------------------------
Eval num_timesteps=224000, episode_reward=311.94 +/- 167.34
Episode length: 78.36 +/- 41.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 78.4     |
|    mean_reward      | 312      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 224000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.26     |
|    n_updates        | 45999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60       |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3076     |
|    fps              | 87       |
|    time_elapsed     | 2561     |
|    total_timesteps  | 224162   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.58     |
|    n_updates        | 46040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60       |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3080     |
|    fps              | 87       |
|    time_elapsed     | 2562     |
|    total_timesteps  | 224382   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.824    |
|    n_updates        | 46095    |
----------------------------------
Eval num_timesteps=224500, episode_reward=168.94 +/- 52.20
Episode length: 42.62 +/- 13.06
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 224500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.92     |
|    n_updates        | 46124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.6     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3084     |
|    fps              | 87       |
|    time_elapsed     | 2566     |
|    total_timesteps  | 224580   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.32     |
|    n_updates        | 46144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.4     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3088     |
|    fps              | 87       |
|    time_elapsed     | 2567     |
|    total_timesteps  | 224866   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.897    |
|    n_updates        | 46216    |
----------------------------------
Eval num_timesteps=225000, episode_reward=187.38 +/- 51.69
Episode length: 47.28 +/- 12.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | 187      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 225000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.803    |
|    n_updates        | 46249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61       |
|    ep_rew_mean      | 242      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3092     |
|    fps              | 87       |
|    time_elapsed     | 2572     |
|    total_timesteps  | 225175   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.102    |
|    n_updates        | 46293    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59       |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3096     |
|    fps              | 87       |
|    time_elapsed     | 2572     |
|    total_timesteps  | 225347   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.37     |
|    n_updates        | 46336    |
----------------------------------
Eval num_timesteps=225500, episode_reward=181.94 +/- 47.68
Episode length: 45.86 +/- 11.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 225500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.793    |
|    n_updates        | 46374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.5     |
|    ep_rew_mean      | 232      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3100     |
|    fps              | 87       |
|    time_elapsed     | 2577     |
|    total_timesteps  | 225522   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.169    |
|    n_updates        | 46380    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.2     |
|    ep_rew_mean      | 231      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3104     |
|    fps              | 87       |
|    time_elapsed     | 2578     |
|    total_timesteps  | 225799   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0947   |
|    n_updates        | 46449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.4     |
|    ep_rew_mean      | 228      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3108     |
|    fps              | 87       |
|    time_elapsed     | 2578     |
|    total_timesteps  | 225978   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.131    |
|    n_updates        | 46494    |
----------------------------------
Eval num_timesteps=226000, episode_reward=175.40 +/- 53.29
Episode length: 44.14 +/- 13.31
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 226000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0769   |
|    n_updates        | 46499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.5     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3112     |
|    fps              | 87       |
|    time_elapsed     | 2584     |
|    total_timesteps  | 226373   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.56     |
|    n_updates        | 46593    |
----------------------------------
Eval num_timesteps=226500, episode_reward=177.30 +/- 51.00
Episode length: 44.76 +/- 12.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 226500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.9      |
|    n_updates        | 46624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3116     |
|    fps              | 87       |
|    time_elapsed     | 2589     |
|    total_timesteps  | 226733   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0613   |
|    n_updates        | 46683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.4     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3120     |
|    fps              | 87       |
|    time_elapsed     | 2590     |
|    total_timesteps  | 226889   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.868    |
|    n_updates        | 46722    |
----------------------------------
Eval num_timesteps=227000, episode_reward=167.36 +/- 34.30
Episode length: 42.18 +/- 8.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.2     |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 227000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.747    |
|    n_updates        | 46749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.1     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3124     |
|    fps              | 87       |
|    time_elapsed     | 2596     |
|    total_timesteps  | 227140   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0757   |
|    n_updates        | 46784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.9     |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3128     |
|    fps              | 87       |
|    time_elapsed     | 2596     |
|    total_timesteps  | 227310   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.901    |
|    n_updates        | 46827    |
----------------------------------
Eval num_timesteps=227500, episode_reward=285.20 +/- 110.55
Episode length: 71.68 +/- 27.62
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.7     |
|    mean_reward      | 285      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 227500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.859    |
|    n_updates        | 46874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.6     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3132     |
|    fps              | 87       |
|    time_elapsed     | 2603     |
|    total_timesteps  | 227569   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.793    |
|    n_updates        | 46892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.5     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3136     |
|    fps              | 87       |
|    time_elapsed     | 2604     |
|    total_timesteps  | 227778   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0344   |
|    n_updates        | 46944    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.4     |
|    ep_rew_mean      | 236      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3140     |
|    fps              | 87       |
|    time_elapsed     | 2604     |
|    total_timesteps  | 227968   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.61     |
|    n_updates        | 46991    |
----------------------------------
Eval num_timesteps=228000, episode_reward=197.04 +/- 48.22
Episode length: 49.66 +/- 12.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 49.7     |
|    mean_reward      | 197      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 228000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.33     |
|    n_updates        | 46999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.5     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3144     |
|    fps              | 87       |
|    time_elapsed     | 2609     |
|    total_timesteps  | 228130   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.62     |
|    n_updates        | 47032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.1     |
|    ep_rew_mean      | 231      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3148     |
|    fps              | 87       |
|    time_elapsed     | 2610     |
|    total_timesteps  | 228353   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.47     |
|    n_updates        | 47088    |
----------------------------------
Eval num_timesteps=228500, episode_reward=176.02 +/- 51.84
Episode length: 44.36 +/- 12.98
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 228500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.834    |
|    n_updates        | 47124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.7     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3152     |
|    fps              | 87       |
|    time_elapsed     | 2615     |
|    total_timesteps  | 228624   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0549   |
|    n_updates        | 47155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3156     |
|    fps              | 87       |
|    time_elapsed     | 2615     |
|    total_timesteps  | 228837   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.796    |
|    n_updates        | 47209    |
----------------------------------
Eval num_timesteps=229000, episode_reward=262.20 +/- 77.85
Episode length: 65.96 +/- 19.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66       |
|    mean_reward      | 262      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 229000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0456   |
|    n_updates        | 47249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.1     |
|    ep_rew_mean      | 231      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3160     |
|    fps              | 87       |
|    time_elapsed     | 2623     |
|    total_timesteps  | 229130   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.49     |
|    n_updates        | 47282    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.7     |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3164     |
|    fps              | 87       |
|    time_elapsed     | 2624     |
|    total_timesteps  | 229392   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.837    |
|    n_updates        | 47347    |
----------------------------------
Eval num_timesteps=229500, episode_reward=169.12 +/- 40.20
Episode length: 42.62 +/- 10.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 229500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.13     |
|    n_updates        | 47374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.8     |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3168     |
|    fps              | 87       |
|    time_elapsed     | 2628     |
|    total_timesteps  | 229591   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.132    |
|    n_updates        | 47397    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3172     |
|    fps              | 87       |
|    time_elapsed     | 2629     |
|    total_timesteps  | 229904   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.52     |
|    n_updates        | 47475    |
----------------------------------
Eval num_timesteps=230000, episode_reward=389.84 +/- 243.21
Episode length: 97.82 +/- 60.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 97.8     |
|    mean_reward      | 390      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 230000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.52     |
|    n_updates        | 47499    |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3176     |
|    fps              | 87       |
|    time_elapsed     | 2638     |
|    total_timesteps  | 230179   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.265    |
|    n_updates        | 47544    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.8     |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3180     |
|    fps              | 87       |
|    time_elapsed     | 2638     |
|    total_timesteps  | 230358   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.146    |
|    n_updates        | 47589    |
----------------------------------
Eval num_timesteps=230500, episode_reward=166.32 +/- 41.24
Episode length: 41.86 +/- 10.26
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.9     |
|    mean_reward      | 166      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 230500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.57     |
|    n_updates        | 47624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.6     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3184     |
|    fps              | 87       |
|    time_elapsed     | 2643     |
|    total_timesteps  | 230545   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.64     |
|    n_updates        | 47636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.7     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3188     |
|    fps              | 87       |
|    time_elapsed     | 2644     |
|    total_timesteps  | 230833   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.835    |
|    n_updates        | 47708    |
----------------------------------
Eval num_timesteps=231000, episode_reward=374.56 +/- 156.35
Episode length: 94.02 +/- 39.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 94       |
|    mean_reward      | 375      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 231000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.28     |
|    n_updates        | 47749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.6     |
|    ep_rew_mean      | 233      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3192     |
|    fps              | 87       |
|    time_elapsed     | 2652     |
|    total_timesteps  | 231033   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.836    |
|    n_updates        | 47758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.4     |
|    ep_rew_mean      | 236      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3196     |
|    fps              | 87       |
|    time_elapsed     | 2653     |
|    total_timesteps  | 231286   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.69     |
|    n_updates        | 47821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.7     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3200     |
|    fps              | 87       |
|    time_elapsed     | 2653     |
|    total_timesteps  | 231491   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.869    |
|    n_updates        | 47872    |
----------------------------------
Eval num_timesteps=231500, episode_reward=326.38 +/- 142.31
Episode length: 81.92 +/- 35.56
----------------------------------
| eval/               |          |
|    mean_ep_length   | 81.9     |
|    mean_reward      | 326      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 231500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.119    |
|    n_updates        | 47874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.2     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3204     |
|    fps              | 87       |
|    time_elapsed     | 2661     |
|    total_timesteps  | 231721   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.133    |
|    n_updates        | 47930    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.6     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3208     |
|    fps              | 87       |
|    time_elapsed     | 2662     |
|    total_timesteps  | 231935   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.785    |
|    n_updates        | 47983    |
----------------------------------
Eval num_timesteps=232000, episode_reward=173.14 +/- 49.15
Episode length: 43.68 +/- 12.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.7     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 232000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.844    |
|    n_updates        | 47999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.9     |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3212     |
|    fps              | 87       |
|    time_elapsed     | 2666     |
|    total_timesteps  | 232158   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.988    |
|    n_updates        | 48039    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.1     |
|    ep_rew_mean      | 223      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3216     |
|    fps              | 87       |
|    time_elapsed     | 2667     |
|    total_timesteps  | 232342   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.181    |
|    n_updates        | 48085    |
----------------------------------
Eval num_timesteps=232500, episode_reward=289.46 +/- 165.17
Episode length: 72.76 +/- 41.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.8     |
|    mean_reward      | 289      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 232500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.964    |
|    n_updates        | 48124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.6     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3220     |
|    fps              | 86       |
|    time_elapsed     | 2673     |
|    total_timesteps  | 232551   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0941   |
|    n_updates        | 48137    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.4     |
|    ep_rew_mean      | 224      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3224     |
|    fps              | 87       |
|    time_elapsed     | 2674     |
|    total_timesteps  | 232783   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.72     |
|    n_updates        | 48195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.4     |
|    ep_rew_mean      | 224      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3228     |
|    fps              | 87       |
|    time_elapsed     | 2675     |
|    total_timesteps  | 232948   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.03     |
|    n_updates        | 48236    |
----------------------------------
Eval num_timesteps=233000, episode_reward=181.38 +/- 50.48
Episode length: 45.76 +/- 12.66
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.8     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 233000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.121    |
|    n_updates        | 48249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.3     |
|    ep_rew_mean      | 228      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3232     |
|    fps              | 87       |
|    time_elapsed     | 2680     |
|    total_timesteps  | 233296   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.298    |
|    n_updates        | 48323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.9     |
|    ep_rew_mean      | 226      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3236     |
|    fps              | 87       |
|    time_elapsed     | 2680     |
|    total_timesteps  | 233468   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.919    |
|    n_updates        | 48366    |
----------------------------------
Eval num_timesteps=233500, episode_reward=178.26 +/- 47.14
Episode length: 44.98 +/- 11.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 233500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.32     |
|    n_updates        | 48374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.8     |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3240     |
|    fps              | 87       |
|    time_elapsed     | 2685     |
|    total_timesteps  | 233746   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.132    |
|    n_updates        | 48436    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.1     |
|    ep_rew_mean      | 231      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3244     |
|    fps              | 87       |
|    time_elapsed     | 2685     |
|    total_timesteps  | 233944   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.142    |
|    n_updates        | 48485    |
----------------------------------
Eval num_timesteps=234000, episode_reward=175.80 +/- 53.52
Episode length: 44.30 +/- 13.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.3     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 234000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0665   |
|    n_updates        | 48499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.7     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3248     |
|    fps              | 87       |
|    time_elapsed     | 2690     |
|    total_timesteps  | 234127   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.943    |
|    n_updates        | 48531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.7     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3252     |
|    fps              | 87       |
|    time_elapsed     | 2690     |
|    total_timesteps  | 234296   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.839    |
|    n_updates        | 48573    |
----------------------------------
Eval num_timesteps=234500, episode_reward=181.58 +/- 45.83
Episode length: 45.78 +/- 11.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.8     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 234500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.176    |
|    n_updates        | 48624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.7     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3256     |
|    fps              | 87       |
|    time_elapsed     | 2696     |
|    total_timesteps  | 234603   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.853    |
|    n_updates        | 48650    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.5     |
|    ep_rew_mean      | 224      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3260     |
|    fps              | 87       |
|    time_elapsed     | 2697     |
|    total_timesteps  | 234781   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.16     |
|    n_updates        | 48695    |
----------------------------------
Eval num_timesteps=235000, episode_reward=185.46 +/- 54.17
Episode length: 46.72 +/- 13.51
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.7     |
|    mean_reward      | 185      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 235000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.08     |
|    n_updates        | 48749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.5     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3264     |
|    fps              | 86       |
|    time_elapsed     | 2704     |
|    total_timesteps  | 235046   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0951   |
|    n_updates        | 48761    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.3     |
|    ep_rew_mean      | 224      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3268     |
|    fps              | 86       |
|    time_elapsed     | 2705     |
|    total_timesteps  | 235224   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.48     |
|    n_updates        | 48805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.3     |
|    ep_rew_mean      | 220      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3272     |
|    fps              | 87       |
|    time_elapsed     | 2706     |
|    total_timesteps  | 235434   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.18     |
|    n_updates        | 48858    |
----------------------------------
Eval num_timesteps=235500, episode_reward=169.96 +/- 49.09
Episode length: 42.82 +/- 12.27
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 235500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0809   |
|    n_updates        | 48874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.3     |
|    ep_rew_mean      | 215      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3276     |
|    fps              | 86       |
|    time_elapsed     | 2710     |
|    total_timesteps  | 235606   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0767   |
|    n_updates        | 48901    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.5     |
|    ep_rew_mean      | 216      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3280     |
|    fps              | 86       |
|    time_elapsed     | 2711     |
|    total_timesteps  | 235808   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.868    |
|    n_updates        | 48951    |
----------------------------------
Eval num_timesteps=236000, episode_reward=163.56 +/- 42.27
Episode length: 41.28 +/- 10.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.3     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 236000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.906    |
|    n_updates        | 48999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55       |
|    ep_rew_mean      | 218      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3284     |
|    fps              | 86       |
|    time_elapsed     | 2716     |
|    total_timesteps  | 236040   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.104    |
|    n_updates        | 49009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.7     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3288     |
|    fps              | 86       |
|    time_elapsed     | 2717     |
|    total_timesteps  | 236400   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.5      |
|    n_updates        | 49099    |
----------------------------------
Eval num_timesteps=236500, episode_reward=320.22 +/- 157.54
Episode length: 80.44 +/- 39.38
----------------------------------
| eval/               |          |
|    mean_ep_length   | 80.4     |
|    mean_reward      | 320      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 236500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.868    |
|    n_updates        | 49124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.9     |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3292     |
|    fps              | 86       |
|    time_elapsed     | 2725     |
|    total_timesteps  | 236618   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.831    |
|    n_updates        | 49154    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.4     |
|    ep_rew_mean      | 220      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3296     |
|    fps              | 86       |
|    time_elapsed     | 2726     |
|    total_timesteps  | 236830   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.865    |
|    n_updates        | 49207    |
----------------------------------
Eval num_timesteps=237000, episode_reward=167.24 +/- 39.03
Episode length: 42.20 +/- 9.78
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.2     |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 237000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.76     |
|    n_updates        | 49249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.1     |
|    ep_rew_mean      | 223      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3300     |
|    fps              | 86       |
|    time_elapsed     | 2730     |
|    total_timesteps  | 237098   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.798    |
|    n_updates        | 49274    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.3     |
|    ep_rew_mean      | 224      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3304     |
|    fps              | 86       |
|    time_elapsed     | 2731     |
|    total_timesteps  | 237354   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.03     |
|    n_updates        | 49338    |
----------------------------------
Eval num_timesteps=237500, episode_reward=168.12 +/- 43.62
Episode length: 42.40 +/- 10.91
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.4     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 237500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.79     |
|    n_updates        | 49374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.2     |
|    ep_rew_mean      | 223      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3308     |
|    fps              | 86       |
|    time_elapsed     | 2735     |
|    total_timesteps  | 237553   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.876    |
|    n_updates        | 49388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.6     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3312     |
|    fps              | 86       |
|    time_elapsed     | 2736     |
|    total_timesteps  | 237823   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.49     |
|    n_updates        | 49455    |
----------------------------------
Eval num_timesteps=238000, episode_reward=162.82 +/- 36.22
Episode length: 41.12 +/- 9.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.1     |
|    mean_reward      | 163      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 238000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.02     |
|    n_updates        | 49499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.9     |
|    ep_rew_mean      | 226      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3316     |
|    fps              | 86       |
|    time_elapsed     | 2740     |
|    total_timesteps  | 238029   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.52     |
|    n_updates        | 49507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.8     |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3320     |
|    fps              | 86       |
|    time_elapsed     | 2741     |
|    total_timesteps  | 238327   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.804    |
|    n_updates        | 49581    |
----------------------------------
Eval num_timesteps=238500, episode_reward=275.34 +/- 138.61
Episode length: 69.16 +/- 34.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.2     |
|    mean_reward      | 275      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 238500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.59     |
|    n_updates        | 49624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.8     |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3324     |
|    fps              | 86       |
|    time_elapsed     | 2748     |
|    total_timesteps  | 238566   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0872   |
|    n_updates        | 49641    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.8     |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3328     |
|    fps              | 86       |
|    time_elapsed     | 2748     |
|    total_timesteps  | 238730   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.6      |
|    n_updates        | 49682    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.7     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3332     |
|    fps              | 86       |
|    time_elapsed     | 2749     |
|    total_timesteps  | 238868   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.55     |
|    n_updates        | 49716    |
----------------------------------
Eval num_timesteps=239000, episode_reward=171.50 +/- 38.44
Episode length: 43.30 +/- 9.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.3     |
|    mean_reward      | 172      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 239000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.47     |
|    n_updates        | 49749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.9     |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3336     |
|    fps              | 86       |
|    time_elapsed     | 2753     |
|    total_timesteps  | 239055   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.5      |
|    n_updates        | 49763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56       |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3340     |
|    fps              | 86       |
|    time_elapsed     | 2754     |
|    total_timesteps  | 239342   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.39     |
|    n_updates        | 49835    |
----------------------------------
Eval num_timesteps=239500, episode_reward=175.24 +/- 41.89
Episode length: 44.20 +/- 10.42
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.2     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 239500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.888    |
|    n_updates        | 49874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.9     |
|    ep_rew_mean      | 226      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3344     |
|    fps              | 86       |
|    time_elapsed     | 2758     |
|    total_timesteps  | 239634   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.762    |
|    n_updates        | 49908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.5     |
|    ep_rew_mean      | 228      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3348     |
|    fps              | 86       |
|    time_elapsed     | 2759     |
|    total_timesteps  | 239876   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.916    |
|    n_updates        | 49968    |
----------------------------------
Eval num_timesteps=240000, episode_reward=186.68 +/- 52.42
Episode length: 47.08 +/- 13.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.1     |
|    mean_reward      | 187      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 240000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.834    |
|    n_updates        | 49999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3352     |
|    fps              | 86       |
|    time_elapsed     | 2764     |
|    total_timesteps  | 240058   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.198    |
|    n_updates        | 50014    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.4     |
|    ep_rew_mean      | 228      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3356     |
|    fps              | 86       |
|    time_elapsed     | 2765     |
|    total_timesteps  | 240344   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.6      |
|    n_updates        | 50085    |
----------------------------------
Eval num_timesteps=240500, episode_reward=279.32 +/- 111.71
Episode length: 70.22 +/- 27.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.2     |
|    mean_reward      | 279      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 240500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.9      |
|    n_updates        | 50124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.7     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3360     |
|    fps              | 86       |
|    time_elapsed     | 2771     |
|    total_timesteps  | 240552   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.875    |
|    n_updates        | 50137    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.7     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3364     |
|    fps              | 86       |
|    time_elapsed     | 2772     |
|    total_timesteps  | 240713   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.49     |
|    n_updates        | 50178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.7     |
|    ep_rew_mean      | 230      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3368     |
|    fps              | 86       |
|    time_elapsed     | 2773     |
|    total_timesteps  | 240998   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0903   |
|    n_updates        | 50249    |
----------------------------------
Eval num_timesteps=241000, episode_reward=220.94 +/- 99.40
Episode length: 55.58 +/- 24.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.6     |
|    mean_reward      | 221      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 241000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3372     |
|    fps              | 86       |
|    time_elapsed     | 2778     |
|    total_timesteps  | 241193   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0372   |
|    n_updates        | 50298    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.4     |
|    ep_rew_mean      | 228      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3376     |
|    fps              | 86       |
|    time_elapsed     | 2778     |
|    total_timesteps  | 241343   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.876    |
|    n_updates        | 50335    |
----------------------------------
Eval num_timesteps=241500, episode_reward=189.22 +/- 60.90
Episode length: 47.72 +/- 15.25
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.7     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 241500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.143    |
|    n_updates        | 50374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.2     |
|    ep_rew_mean      | 227      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3380     |
|    fps              | 86       |
|    time_elapsed     | 2783     |
|    total_timesteps  | 241524   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.65     |
|    n_updates        | 50380    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.5     |
|    ep_rew_mean      | 225      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3384     |
|    fps              | 86       |
|    time_elapsed     | 2783     |
|    total_timesteps  | 241694   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.145    |
|    n_updates        | 50423    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.6     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3388     |
|    fps              | 86       |
|    time_elapsed     | 2784     |
|    total_timesteps  | 241956   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.191    |
|    n_updates        | 50488    |
----------------------------------
Eval num_timesteps=242000, episode_reward=255.04 +/- 98.95
Episode length: 64.16 +/- 24.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 64.2     |
|    mean_reward      | 255      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 242000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.1      |
|    n_updates        | 50499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.5     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3392     |
|    fps              | 86       |
|    time_elapsed     | 2790     |
|    total_timesteps  | 242166   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.128    |
|    n_updates        | 50541    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.6     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3396     |
|    fps              | 86       |
|    time_elapsed     | 2791     |
|    total_timesteps  | 242392   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.57     |
|    n_updates        | 50597    |
----------------------------------
Eval num_timesteps=242500, episode_reward=178.04 +/- 52.74
Episode length: 44.90 +/- 13.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 242500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.952    |
|    n_updates        | 50624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.2     |
|    ep_rew_mean      | 223      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3400     |
|    fps              | 86       |
|    time_elapsed     | 2796     |
|    total_timesteps  | 242714   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.923    |
|    n_updates        | 50678    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.9     |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3404     |
|    fps              | 86       |
|    time_elapsed     | 2797     |
|    total_timesteps  | 242944   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.986    |
|    n_updates        | 50735    |
----------------------------------
Eval num_timesteps=243000, episode_reward=166.78 +/- 44.13
Episode length: 42.12 +/- 11.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.1     |
|    mean_reward      | 167      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 243000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 4.09     |
|    n_updates        | 50749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.9     |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3408     |
|    fps              | 86       |
|    time_elapsed     | 2801     |
|    total_timesteps  | 243145   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.865    |
|    n_updates        | 50786    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.5     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3412     |
|    fps              | 86       |
|    time_elapsed     | 2802     |
|    total_timesteps  | 243375   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0935   |
|    n_updates        | 50843    |
----------------------------------
Eval num_timesteps=243500, episode_reward=251.62 +/- 109.19
Episode length: 63.26 +/- 27.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 63.3     |
|    mean_reward      | 252      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 243500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.131    |
|    n_updates        | 50874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.7     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3416     |
|    fps              | 86       |
|    time_elapsed     | 2808     |
|    total_timesteps  | 243602   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.41     |
|    n_updates        | 50900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.8     |
|    ep_rew_mean      | 218      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3420     |
|    fps              | 86       |
|    time_elapsed     | 2808     |
|    total_timesteps  | 243811   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.831    |
|    n_updates        | 50952    |
----------------------------------
Eval num_timesteps=244000, episode_reward=178.02 +/- 49.95
Episode length: 44.88 +/- 12.47
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 244000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.976    |
|    n_updates        | 50999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.6     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3424     |
|    fps              | 86       |
|    time_elapsed     | 2813     |
|    total_timesteps  | 244125   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0982   |
|    n_updates        | 51031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56       |
|    ep_rew_mean      | 223      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3428     |
|    fps              | 86       |
|    time_elapsed     | 2814     |
|    total_timesteps  | 244329   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.64     |
|    n_updates        | 51082    |
----------------------------------
Eval num_timesteps=244500, episode_reward=224.84 +/- 88.54
Episode length: 56.58 +/- 22.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.6     |
|    mean_reward      | 225      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 244500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.119    |
|    n_updates        | 51124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.8     |
|    ep_rew_mean      | 226      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3432     |
|    fps              | 86       |
|    time_elapsed     | 2819     |
|    total_timesteps  | 244545   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.824    |
|    n_updates        | 51136    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.4     |
|    ep_rew_mean      | 224      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3436     |
|    fps              | 86       |
|    time_elapsed     | 2819     |
|    total_timesteps  | 244693   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.75     |
|    n_updates        | 51173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.2     |
|    ep_rew_mean      | 223      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3440     |
|    fps              | 86       |
|    time_elapsed     | 2820     |
|    total_timesteps  | 244960   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.65     |
|    n_updates        | 51239    |
----------------------------------
Eval num_timesteps=245000, episode_reward=172.64 +/- 42.74
Episode length: 43.58 +/- 10.72
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 245000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.258    |
|    n_updates        | 51249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.2     |
|    ep_rew_mean      | 219      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3444     |
|    fps              | 86       |
|    time_elapsed     | 2824     |
|    total_timesteps  | 245152   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.812    |
|    n_updates        | 51287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.5     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3448     |
|    fps              | 86       |
|    time_elapsed     | 2825     |
|    total_timesteps  | 245425   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.09     |
|    n_updates        | 51356    |
----------------------------------
Eval num_timesteps=245500, episode_reward=177.54 +/- 43.00
Episode length: 44.76 +/- 10.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 245500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.783    |
|    n_updates        | 51374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.7     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3452     |
|    fps              | 86       |
|    time_elapsed     | 2830     |
|    total_timesteps  | 245626   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.04     |
|    n_updates        | 51406    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.7     |
|    ep_rew_mean      | 217      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3456     |
|    fps              | 86       |
|    time_elapsed     | 2830     |
|    total_timesteps  | 245814   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.59     |
|    n_updates        | 51453    |
----------------------------------
Eval num_timesteps=246000, episode_reward=177.86 +/- 44.66
Episode length: 44.86 +/- 11.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 246000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0848   |
|    n_updates        | 51499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.4     |
|    ep_rew_mean      | 220      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3460     |
|    fps              | 86       |
|    time_elapsed     | 2835     |
|    total_timesteps  | 246089   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.39     |
|    n_updates        | 51522    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.8     |
|    ep_rew_mean      | 226      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3464     |
|    fps              | 86       |
|    time_elapsed     | 2836     |
|    total_timesteps  | 246393   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.111    |
|    n_updates        | 51598    |
----------------------------------
Eval num_timesteps=246500, episode_reward=178.56 +/- 38.02
Episode length: 45.04 +/- 9.54
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 246500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.133    |
|    n_updates        | 51624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.9     |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3468     |
|    fps              | 86       |
|    time_elapsed     | 2840     |
|    total_timesteps  | 246590   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.894    |
|    n_updates        | 51647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.6     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3472     |
|    fps              | 86       |
|    time_elapsed     | 2841     |
|    total_timesteps  | 246750   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.118    |
|    n_updates        | 51687    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.2     |
|    ep_rew_mean      | 223      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3476     |
|    fps              | 86       |
|    time_elapsed     | 2842     |
|    total_timesteps  | 246963   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.76     |
|    n_updates        | 51740    |
----------------------------------
Eval num_timesteps=247000, episode_reward=174.54 +/- 45.28
Episode length: 43.94 +/- 11.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 247000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.74     |
|    n_updates        | 51749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.8     |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3480     |
|    fps              | 86       |
|    time_elapsed     | 2846     |
|    total_timesteps  | 247103   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0616   |
|    n_updates        | 51775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.8     |
|    ep_rew_mean      | 226      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3484     |
|    fps              | 86       |
|    time_elapsed     | 2847     |
|    total_timesteps  | 247372   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0448   |
|    n_updates        | 51842    |
----------------------------------
Eval num_timesteps=247500, episode_reward=170.48 +/- 38.76
Episode length: 43.04 +/- 9.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43       |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 247500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.854    |
|    n_updates        | 51874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.2     |
|    ep_rew_mean      | 223      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3488     |
|    fps              | 86       |
|    time_elapsed     | 2852     |
|    total_timesteps  | 247580   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.859    |
|    n_updates        | 51894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56       |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3492     |
|    fps              | 86       |
|    time_elapsed     | 2853     |
|    total_timesteps  | 247765   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.9      |
|    n_updates        | 51941    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.6     |
|    ep_rew_mean      | 221      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3496     |
|    fps              | 86       |
|    time_elapsed     | 2854     |
|    total_timesteps  | 247955   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.851    |
|    n_updates        | 51988    |
----------------------------------
Eval num_timesteps=248000, episode_reward=221.60 +/- 66.54
Episode length: 55.78 +/- 16.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 55.8     |
|    mean_reward      | 222      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 248000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0777   |
|    n_updates        | 51999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.6     |
|    ep_rew_mean      | 217      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3500     |
|    fps              | 86       |
|    time_elapsed     | 2859     |
|    total_timesteps  | 248179   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.224    |
|    n_updates        | 52044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.1     |
|    ep_rew_mean      | 215      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3504     |
|    fps              | 86       |
|    time_elapsed     | 2860     |
|    total_timesteps  | 248351   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.73     |
|    n_updates        | 52087    |
----------------------------------
Eval num_timesteps=248500, episode_reward=178.10 +/- 54.03
Episode length: 44.86 +/- 13.49
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 248500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.129    |
|    n_updates        | 52124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.7     |
|    ep_rew_mean      | 217      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3508     |
|    fps              | 86       |
|    time_elapsed     | 2865     |
|    total_timesteps  | 248615   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.09     |
|    n_updates        | 52153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.7     |
|    ep_rew_mean      | 217      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3512     |
|    fps              | 86       |
|    time_elapsed     | 2866     |
|    total_timesteps  | 248841   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.907    |
|    n_updates        | 52210    |
----------------------------------
Eval num_timesteps=249000, episode_reward=176.40 +/- 43.60
Episode length: 44.42 +/- 10.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 249000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.81     |
|    n_updates        | 52249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.9     |
|    ep_rew_mean      | 218      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3516     |
|    fps              | 86       |
|    time_elapsed     | 2870     |
|    total_timesteps  | 249090   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0776   |
|    n_updates        | 52272    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.8     |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3520     |
|    fps              | 86       |
|    time_elapsed     | 2871     |
|    total_timesteps  | 249389   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.956    |
|    n_updates        | 52347    |
----------------------------------
Eval num_timesteps=249500, episode_reward=180.56 +/- 45.03
Episode length: 45.54 +/- 11.30
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.5     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 249500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.18     |
|    n_updates        | 52374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.5     |
|    ep_rew_mean      | 216      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3524     |
|    fps              | 86       |
|    time_elapsed     | 2876     |
|    total_timesteps  | 249573   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.843    |
|    n_updates        | 52393    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.7     |
|    ep_rew_mean      | 217      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3528     |
|    fps              | 86       |
|    time_elapsed     | 2877     |
|    total_timesteps  | 249797   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.01     |
|    n_updates        | 52449    |
----------------------------------
Eval num_timesteps=250000, episode_reward=175.08 +/- 47.04
Episode length: 44.10 +/- 11.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 250000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.42     |
|    n_updates        | 52499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.8     |
|    ep_rew_mean      | 218      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3532     |
|    fps              | 86       |
|    time_elapsed     | 2881     |
|    total_timesteps  | 250026   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.05     |
|    n_updates        | 52506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.4     |
|    ep_rew_mean      | 220      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3536     |
|    fps              | 86       |
|    time_elapsed     | 2882     |
|    total_timesteps  | 250234   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.136    |
|    n_updates        | 52558    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55       |
|    ep_rew_mean      | 219      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3540     |
|    fps              | 86       |
|    time_elapsed     | 2883     |
|    total_timesteps  | 250465   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.236    |
|    n_updates        | 52616    |
----------------------------------
Eval num_timesteps=250500, episode_reward=187.52 +/- 48.74
Episode length: 47.26 +/- 12.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 250500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.108    |
|    n_updates        | 52624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.2     |
|    ep_rew_mean      | 219      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3544     |
|    fps              | 86       |
|    time_elapsed     | 2888     |
|    total_timesteps  | 250677   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.112    |
|    n_updates        | 52669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.6     |
|    ep_rew_mean      | 217      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3548     |
|    fps              | 86       |
|    time_elapsed     | 2888     |
|    total_timesteps  | 250883   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.83     |
|    n_updates        | 52720    |
----------------------------------
Eval num_timesteps=251000, episode_reward=228.56 +/- 103.87
Episode length: 57.54 +/- 25.97
----------------------------------
| eval/               |          |
|    mean_ep_length   | 57.5     |
|    mean_reward      | 229      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 251000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.179    |
|    n_updates        | 52749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.1     |
|    ep_rew_mean      | 215      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3552     |
|    fps              | 86       |
|    time_elapsed     | 2894     |
|    total_timesteps  | 251035   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.892    |
|    n_updates        | 52758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.4     |
|    ep_rew_mean      | 220      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3556     |
|    fps              | 86       |
|    time_elapsed     | 2895     |
|    total_timesteps  | 251351   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.77     |
|    n_updates        | 52837    |
----------------------------------
Eval num_timesteps=251500, episode_reward=236.76 +/- 116.51
Episode length: 59.50 +/- 29.20
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59.5     |
|    mean_reward      | 237      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 251500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.216    |
|    n_updates        | 52874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.5     |
|    ep_rew_mean      | 217      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3560     |
|    fps              | 86       |
|    time_elapsed     | 2902     |
|    total_timesteps  | 251543   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.896    |
|    n_updates        | 52885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55       |
|    ep_rew_mean      | 218      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3564     |
|    fps              | 86       |
|    time_elapsed     | 2904     |
|    total_timesteps  | 251890   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.949    |
|    n_updates        | 52972    |
----------------------------------
Eval num_timesteps=252000, episode_reward=180.90 +/- 48.31
Episode length: 45.60 +/- 12.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 252000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.17     |
|    n_updates        | 52999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.3     |
|    ep_rew_mean      | 220      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3568     |
|    fps              | 86       |
|    time_elapsed     | 2909     |
|    total_timesteps  | 252120   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.66     |
|    n_updates        | 53029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.9     |
|    ep_rew_mean      | 222      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3572     |
|    fps              | 86       |
|    time_elapsed     | 2910     |
|    total_timesteps  | 252339   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.67     |
|    n_updates        | 53084    |
----------------------------------
Eval num_timesteps=252500, episode_reward=169.56 +/- 45.16
Episode length: 42.70 +/- 11.33
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.7     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 252500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.06     |
|    n_updates        | 53124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.1     |
|    ep_rew_mean      | 223      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3576     |
|    fps              | 86       |
|    time_elapsed     | 2917     |
|    total_timesteps  | 252575   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.285    |
|    n_updates        | 53143    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3580     |
|    fps              | 86       |
|    time_elapsed     | 2918     |
|    total_timesteps  | 252862   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.873    |
|    n_updates        | 53215    |
----------------------------------
Eval num_timesteps=253000, episode_reward=173.68 +/- 46.46
Episode length: 43.80 +/- 11.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.8     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 253000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0911   |
|    n_updates        | 53249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 229      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3584     |
|    fps              | 86       |
|    time_elapsed     | 2925     |
|    total_timesteps  | 253134   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.192    |
|    n_updates        | 53283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.2     |
|    ep_rew_mean      | 231      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3588     |
|    fps              | 86       |
|    time_elapsed     | 2925     |
|    total_timesteps  | 253396   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.915    |
|    n_updates        | 53348    |
----------------------------------
Eval num_timesteps=253500, episode_reward=211.40 +/- 62.22
Episode length: 53.20 +/- 15.59
----------------------------------
| eval/               |          |
|    mean_ep_length   | 53.2     |
|    mean_reward      | 211      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 253500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.155    |
|    n_updates        | 53374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.5     |
|    ep_rew_mean      | 232      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3592     |
|    fps              | 86       |
|    time_elapsed     | 2933     |
|    total_timesteps  | 253611   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.18     |
|    n_updates        | 53402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.6     |
|    ep_rew_mean      | 233      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3596     |
|    fps              | 86       |
|    time_elapsed     | 2934     |
|    total_timesteps  | 253820   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.839    |
|    n_updates        | 53454    |
----------------------------------
Eval num_timesteps=254000, episode_reward=173.24 +/- 47.04
Episode length: 43.66 +/- 11.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.7     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 254000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.203    |
|    n_updates        | 53499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.6     |
|    ep_rew_mean      | 233      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3600     |
|    fps              | 86       |
|    time_elapsed     | 2940     |
|    total_timesteps  | 254035   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0919   |
|    n_updates        | 53508    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.6     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3604     |
|    fps              | 86       |
|    time_elapsed     | 2942     |
|    total_timesteps  | 254309   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.38     |
|    n_updates        | 53577    |
----------------------------------
Eval num_timesteps=254500, episode_reward=179.40 +/- 48.37
Episode length: 45.20 +/- 12.07
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 254500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.216    |
|    n_updates        | 53624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.7     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3608     |
|    fps              | 86       |
|    time_elapsed     | 2947     |
|    total_timesteps  | 254681   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0563   |
|    n_updates        | 53670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.7     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3612     |
|    fps              | 86       |
|    time_elapsed     | 2949     |
|    total_timesteps  | 254910   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.41     |
|    n_updates        | 53727    |
----------------------------------
Eval num_timesteps=255000, episode_reward=168.00 +/- 51.75
Episode length: 42.40 +/- 12.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.4     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 255000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.35     |
|    n_updates        | 53749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3616     |
|    fps              | 86       |
|    time_elapsed     | 2956     |
|    total_timesteps  | 255225   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.102    |
|    n_updates        | 53806    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3620     |
|    fps              | 86       |
|    time_elapsed     | 2957     |
|    total_timesteps  | 255414   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.185    |
|    n_updates        | 53853    |
----------------------------------
Eval num_timesteps=255500, episode_reward=234.50 +/- 89.23
Episode length: 59.02 +/- 22.32
----------------------------------
| eval/               |          |
|    mean_ep_length   | 59       |
|    mean_reward      | 234      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 255500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.72     |
|    n_updates        | 53874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3624     |
|    fps              | 86       |
|    time_elapsed     | 2965     |
|    total_timesteps  | 255714   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.888    |
|    n_updates        | 53928    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.5     |
|    ep_rew_mean      | 245      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3628     |
|    fps              | 86       |
|    time_elapsed     | 2966     |
|    total_timesteps  | 255950   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.65     |
|    n_updates        | 53987    |
----------------------------------
Eval num_timesteps=256000, episode_reward=173.82 +/- 45.49
Episode length: 43.80 +/- 11.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.8     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 256000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.947    |
|    n_updates        | 53999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.6     |
|    ep_rew_mean      | 245      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3632     |
|    fps              | 86       |
|    time_elapsed     | 2971     |
|    total_timesteps  | 256182   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.245    |
|    n_updates        | 54045    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.6     |
|    ep_rew_mean      | 245      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3636     |
|    fps              | 86       |
|    time_elapsed     | 2972     |
|    total_timesteps  | 256392   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.38     |
|    n_updates        | 54097    |
----------------------------------
Eval num_timesteps=256500, episode_reward=180.24 +/- 56.40
Episode length: 45.44 +/- 14.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 256500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.65     |
|    n_updates        | 54124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62       |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3640     |
|    fps              | 86       |
|    time_elapsed     | 2979     |
|    total_timesteps  | 256661   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.139    |
|    n_updates        | 54165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.5     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3644     |
|    fps              | 86       |
|    time_elapsed     | 2980     |
|    total_timesteps  | 256825   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.247    |
|    n_updates        | 54206    |
----------------------------------
Eval num_timesteps=257000, episode_reward=174.34 +/- 43.62
Episode length: 43.96 +/- 10.89
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44       |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 257000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.75     |
|    n_updates        | 54249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 247      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3648     |
|    fps              | 86       |
|    time_elapsed     | 2986     |
|    total_timesteps  | 257092   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.949    |
|    n_updates        | 54272    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3652     |
|    fps              | 86       |
|    time_elapsed     | 2987     |
|    total_timesteps  | 257443   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.951    |
|    n_updates        | 54360    |
----------------------------------
Eval num_timesteps=257500, episode_reward=246.50 +/- 62.27
Episode length: 62.04 +/- 15.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 62       |
|    mean_reward      | 246      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 257500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.72     |
|    n_updates        | 54374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.4     |
|    ep_rew_mean      | 248      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3656     |
|    fps              | 86       |
|    time_elapsed     | 2993     |
|    total_timesteps  | 257595   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.237    |
|    n_updates        | 54398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.3     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3660     |
|    fps              | 86       |
|    time_elapsed     | 2994     |
|    total_timesteps  | 257877   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.55     |
|    n_updates        | 54469    |
----------------------------------
Eval num_timesteps=258000, episode_reward=261.36 +/- 117.00
Episode length: 65.72 +/- 29.28
----------------------------------
| eval/               |          |
|    mean_ep_length   | 65.7     |
|    mean_reward      | 261      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 258000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.12     |
|    n_updates        | 54499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.9     |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3664     |
|    fps              | 85       |
|    time_elapsed     | 3004     |
|    total_timesteps  | 258083   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.74     |
|    n_updates        | 54520    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.2     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3668     |
|    fps              | 85       |
|    time_elapsed     | 3005     |
|    total_timesteps  | 258444   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.949    |
|    n_updates        | 54610    |
----------------------------------
Eval num_timesteps=258500, episode_reward=174.14 +/- 44.66
Episode length: 43.92 +/- 11.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 258500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.139    |
|    n_updates        | 54624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.2     |
|    ep_rew_mean      | 251      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3672     |
|    fps              | 85       |
|    time_elapsed     | 3011     |
|    total_timesteps  | 258658   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.266    |
|    n_updates        | 54664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3676     |
|    fps              | 85       |
|    time_elapsed     | 3012     |
|    total_timesteps  | 258987   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.17     |
|    n_updates        | 54746    |
----------------------------------
Eval num_timesteps=259000, episode_reward=179.56 +/- 43.84
Episode length: 45.24 +/- 10.96
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.2     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 259000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.157    |
|    n_updates        | 54749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.9     |
|    ep_rew_mean      | 254      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3680     |
|    fps              | 85       |
|    time_elapsed     | 3017     |
|    total_timesteps  | 259253   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.14     |
|    n_updates        | 54813    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.4     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3684     |
|    fps              | 85       |
|    time_elapsed     | 3018     |
|    total_timesteps  | 259477   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.112    |
|    n_updates        | 54869    |
----------------------------------
Eval num_timesteps=259500, episode_reward=178.04 +/- 39.73
Episode length: 44.88 +/- 10.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 259500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.228    |
|    n_updates        | 54874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.9     |
|    ep_rew_mean      | 250      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3688     |
|    fps              | 85       |
|    time_elapsed     | 3025     |
|    total_timesteps  | 259682   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.546    |
|    n_updates        | 54920    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.6     |
|    ep_rew_mean      | 249      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3692     |
|    fps              | 85       |
|    time_elapsed     | 3025     |
|    total_timesteps  | 259875   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.51     |
|    n_updates        | 54968    |
----------------------------------
Eval num_timesteps=260000, episode_reward=181.12 +/- 45.22
Episode length: 45.62 +/- 11.21
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 260000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.63     |
|    n_updates        | 54999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | 251      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3696     |
|    fps              | 85       |
|    time_elapsed     | 3030     |
|    total_timesteps  | 260123   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.983    |
|    n_updates        | 55030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.6     |
|    ep_rew_mean      | 253      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3700     |
|    fps              | 85       |
|    time_elapsed     | 3031     |
|    total_timesteps  | 260393   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.66     |
|    n_updates        | 55098    |
----------------------------------
Eval num_timesteps=260500, episode_reward=182.82 +/- 55.58
Episode length: 46.08 +/- 13.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.1     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 260500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.989    |
|    n_updates        | 55124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.7     |
|    ep_rew_mean      | 249      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3704     |
|    fps              | 85       |
|    time_elapsed     | 3036     |
|    total_timesteps  | 260580   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.896    |
|    n_updates        | 55144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61       |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3708     |
|    fps              | 85       |
|    time_elapsed     | 3037     |
|    total_timesteps  | 260785   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.01     |
|    n_updates        | 55196    |
----------------------------------
Eval num_timesteps=261000, episode_reward=175.98 +/- 39.15
Episode length: 44.38 +/- 9.74
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 261000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.81     |
|    n_updates        | 55249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61       |
|    ep_rew_mean      | 242      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3712     |
|    fps              | 85       |
|    time_elapsed     | 3041     |
|    total_timesteps  | 261009   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.297    |
|    n_updates        | 55252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.4     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3716     |
|    fps              | 85       |
|    time_elapsed     | 3042     |
|    total_timesteps  | 261265   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.12     |
|    n_updates        | 55316    |
----------------------------------
Eval num_timesteps=261500, episode_reward=173.46 +/- 48.36
Episode length: 43.80 +/- 12.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.8     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 261500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.971    |
|    n_updates        | 55374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3720     |
|    fps              | 85       |
|    time_elapsed     | 3048     |
|    total_timesteps  | 261526   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.18     |
|    n_updates        | 55381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3724     |
|    fps              | 85       |
|    time_elapsed     | 3050     |
|    total_timesteps  | 261765   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0786   |
|    n_updates        | 55441    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3728     |
|    fps              | 85       |
|    time_elapsed     | 3050     |
|    total_timesteps  | 261970   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.18     |
|    n_updates        | 55492    |
----------------------------------
Eval num_timesteps=262000, episode_reward=167.90 +/- 45.75
Episode length: 42.36 +/- 11.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.4     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 262000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.07     |
|    n_updates        | 55499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60       |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3732     |
|    fps              | 85       |
|    time_elapsed     | 3055     |
|    total_timesteps  | 262179   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.09     |
|    n_updates        | 55544    |
----------------------------------
Eval num_timesteps=262500, episode_reward=181.08 +/- 47.82
Episode length: 45.60 +/- 11.92
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.6     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 262500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.12     |
|    n_updates        | 55624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3736     |
|    fps              | 85       |
|    time_elapsed     | 3060     |
|    total_timesteps  | 262502   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.81     |
|    n_updates        | 55625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.2     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3740     |
|    fps              | 85       |
|    time_elapsed     | 3061     |
|    total_timesteps  | 262784   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0446   |
|    n_updates        | 55695    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.5     |
|    ep_rew_mean      | 245      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3744     |
|    fps              | 85       |
|    time_elapsed     | 3062     |
|    total_timesteps  | 262980   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.94     |
|    n_updates        | 55744    |
----------------------------------
Eval num_timesteps=263000, episode_reward=174.16 +/- 30.02
Episode length: 43.92 +/- 7.46
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 263000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.779    |
|    n_updates        | 55749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3748     |
|    fps              | 85       |
|    time_elapsed     | 3068     |
|    total_timesteps  | 263206   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.231    |
|    n_updates        | 55801    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3752     |
|    fps              | 85       |
|    time_elapsed     | 3069     |
|    total_timesteps  | 263466   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.17     |
|    n_updates        | 55866    |
----------------------------------
Eval num_timesteps=263500, episode_reward=164.48 +/- 43.26
Episode length: 41.50 +/- 10.90
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.5     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 263500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.398    |
|    n_updates        | 55874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.2     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3756     |
|    fps              | 85       |
|    time_elapsed     | 3074     |
|    total_timesteps  | 263715   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.896    |
|    n_updates        | 55928    |
----------------------------------
Eval num_timesteps=264000, episode_reward=194.28 +/- 59.40
Episode length: 48.94 +/- 14.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.9     |
|    mean_reward      | 194      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 264000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.07     |
|    n_updates        | 55999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3760     |
|    fps              | 85       |
|    time_elapsed     | 3081     |
|    total_timesteps  | 264013   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.242    |
|    n_updates        | 56003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62       |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3764     |
|    fps              | 85       |
|    time_elapsed     | 3083     |
|    total_timesteps  | 264281   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.03     |
|    n_updates        | 56070    |
----------------------------------
Eval num_timesteps=264500, episode_reward=191.26 +/- 63.39
Episode length: 48.20 +/- 15.85
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48.2     |
|    mean_reward      | 191      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 264500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.868    |
|    n_updates        | 56124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.8     |
|    ep_rew_mean      | 242      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3768     |
|    fps              | 85       |
|    time_elapsed     | 3088     |
|    total_timesteps  | 264523   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.226    |
|    n_updates        | 56130    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.3     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3772     |
|    fps              | 85       |
|    time_elapsed     | 3089     |
|    total_timesteps  | 264784   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.74     |
|    n_updates        | 56195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.7     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3776     |
|    fps              | 85       |
|    time_elapsed     | 3090     |
|    total_timesteps  | 264961   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.149    |
|    n_updates        | 56240    |
----------------------------------
Eval num_timesteps=265000, episode_reward=174.44 +/- 38.33
Episode length: 44.04 +/- 9.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44       |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 265000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.04     |
|    n_updates        | 56249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.4     |
|    ep_rew_mean      | 236      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3780     |
|    fps              | 85       |
|    time_elapsed     | 3094     |
|    total_timesteps  | 265188   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.01     |
|    n_updates        | 56296    |
----------------------------------
Eval num_timesteps=265500, episode_reward=156.88 +/- 35.49
Episode length: 39.56 +/- 8.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 39.6     |
|    mean_reward      | 157      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 265500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1        |
|    n_updates        | 56374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.6     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3784     |
|    fps              | 85       |
|    time_elapsed     | 3098     |
|    total_timesteps  | 265539   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.909    |
|    n_updates        | 56384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3788     |
|    fps              | 85       |
|    time_elapsed     | 3099     |
|    total_timesteps  | 265793   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.885    |
|    n_updates        | 56448    |
----------------------------------
Eval num_timesteps=266000, episode_reward=170.54 +/- 45.81
Episode length: 42.98 +/- 11.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43       |
|    mean_reward      | 171      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 266000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.251    |
|    n_updates        | 56499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.8     |
|    ep_rew_mean      | 245      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3792     |
|    fps              | 85       |
|    time_elapsed     | 3104     |
|    total_timesteps  | 266051   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.264    |
|    n_updates        | 56512    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | 251      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3796     |
|    fps              | 85       |
|    time_elapsed     | 3105     |
|    total_timesteps  | 266425   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.263    |
|    n_updates        | 56606    |
----------------------------------
Eval num_timesteps=266500, episode_reward=241.58 +/- 105.27
Episode length: 60.78 +/- 26.35
----------------------------------
| eval/               |          |
|    mean_ep_length   | 60.8     |
|    mean_reward      | 242      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 266500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.322    |
|    n_updates        | 56624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.4     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3800     |
|    fps              | 85       |
|    time_elapsed     | 3111     |
|    total_timesteps  | 266728   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.947    |
|    n_updates        | 56681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.3     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3804     |
|    fps              | 85       |
|    time_elapsed     | 3112     |
|    total_timesteps  | 266912   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.157    |
|    n_updates        | 56727    |
----------------------------------
Eval num_timesteps=267000, episode_reward=181.80 +/- 51.83
Episode length: 45.88 +/- 13.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 267000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.04     |
|    n_updates        | 56749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3808     |
|    fps              | 85       |
|    time_elapsed     | 3116     |
|    total_timesteps  | 267196   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.15     |
|    n_updates        | 56798    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.2     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3812     |
|    fps              | 85       |
|    time_elapsed     | 3117     |
|    total_timesteps  | 267424   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.87     |
|    n_updates        | 56855    |
----------------------------------
Eval num_timesteps=267500, episode_reward=265.86 +/- 120.03
Episode length: 66.90 +/- 29.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.9     |
|    mean_reward      | 266      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 267500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.196    |
|    n_updates        | 56874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.2     |
|    ep_rew_mean      | 251      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3816     |
|    fps              | 85       |
|    time_elapsed     | 3123     |
|    total_timesteps  | 267583   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.109    |
|    n_updates        | 56895    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.4     |
|    ep_rew_mean      | 248      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3820     |
|    fps              | 85       |
|    time_elapsed     | 3124     |
|    total_timesteps  | 267769   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.75     |
|    n_updates        | 56942    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.8     |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3824     |
|    fps              | 85       |
|    time_elapsed     | 3124     |
|    total_timesteps  | 267946   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.93     |
|    n_updates        | 56986    |
----------------------------------
Eval num_timesteps=268000, episode_reward=188.44 +/- 43.67
Episode length: 47.44 +/- 10.93
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.4     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 268000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.77     |
|    n_updates        | 56999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.9     |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3828     |
|    fps              | 85       |
|    time_elapsed     | 3129     |
|    total_timesteps  | 268163   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.929    |
|    n_updates        | 57040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62       |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3832     |
|    fps              | 85       |
|    time_elapsed     | 3130     |
|    total_timesteps  | 268376   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.06     |
|    n_updates        | 57093    |
----------------------------------
Eval num_timesteps=268500, episode_reward=161.08 +/- 34.12
Episode length: 40.62 +/- 8.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.6     |
|    mean_reward      | 161      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 268500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.974    |
|    n_updates        | 57124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.5     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3836     |
|    fps              | 85       |
|    time_elapsed     | 3134     |
|    total_timesteps  | 268656   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.881    |
|    n_updates        | 57163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62       |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3840     |
|    fps              | 85       |
|    time_elapsed     | 3135     |
|    total_timesteps  | 268983   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.77     |
|    n_updates        | 57245    |
----------------------------------
Eval num_timesteps=269000, episode_reward=182.50 +/- 46.64
Episode length: 46.00 +/- 11.63
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46       |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 269000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.986    |
|    n_updates        | 57249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 247      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3844     |
|    fps              | 85       |
|    time_elapsed     | 3139     |
|    total_timesteps  | 269189   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.079    |
|    n_updates        | 57297    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.3     |
|    ep_rew_mean      | 248      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3848     |
|    fps              | 85       |
|    time_elapsed     | 3140     |
|    total_timesteps  | 269440   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.107    |
|    n_updates        | 57359    |
----------------------------------
Eval num_timesteps=269500, episode_reward=275.12 +/- 110.93
Episode length: 69.14 +/- 27.71
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.1     |
|    mean_reward      | 275      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 269500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.173    |
|    n_updates        | 57374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.1     |
|    ep_rew_mean      | 251      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3852     |
|    fps              | 85       |
|    time_elapsed     | 3147     |
|    total_timesteps  | 269781   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.88     |
|    n_updates        | 57445    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.8     |
|    ep_rew_mean      | 249      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3856     |
|    fps              | 85       |
|    time_elapsed     | 3147     |
|    total_timesteps  | 269991   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.39     |
|    n_updates        | 57497    |
----------------------------------
Eval num_timesteps=270000, episode_reward=169.78 +/- 43.02
Episode length: 42.92 +/- 10.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 270000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0562   |
|    n_updates        | 57499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.4     |
|    ep_rew_mean      | 248      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3860     |
|    fps              | 85       |
|    time_elapsed     | 3152     |
|    total_timesteps  | 270255   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.32     |
|    n_updates        | 57563    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.8     |
|    ep_rew_mean      | 245      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3864     |
|    fps              | 85       |
|    time_elapsed     | 3153     |
|    total_timesteps  | 270459   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.09     |
|    n_updates        | 57614    |
----------------------------------
Eval num_timesteps=270500, episode_reward=168.92 +/- 44.67
Episode length: 42.60 +/- 11.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 270500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.14     |
|    n_updates        | 57624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.2     |
|    ep_rew_mean      | 247      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3868     |
|    fps              | 85       |
|    time_elapsed     | 3157     |
|    total_timesteps  | 270739   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.123    |
|    n_updates        | 57684    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.5     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3872     |
|    fps              | 85       |
|    time_elapsed     | 3158     |
|    total_timesteps  | 270939   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.91     |
|    n_updates        | 57734    |
----------------------------------
Eval num_timesteps=271000, episode_reward=178.22 +/- 47.93
Episode length: 44.92 +/- 12.00
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 271000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.887    |
|    n_updates        | 57749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 247      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3876     |
|    fps              | 85       |
|    time_elapsed     | 3162     |
|    total_timesteps  | 271173   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.7      |
|    n_updates        | 57793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.4     |
|    ep_rew_mean      | 248      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3880     |
|    fps              | 85       |
|    time_elapsed     | 3163     |
|    total_timesteps  | 271425   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.07     |
|    n_updates        | 57856    |
----------------------------------
Eval num_timesteps=271500, episode_reward=233.74 +/- 56.30
Episode length: 58.84 +/- 14.08
----------------------------------
| eval/               |          |
|    mean_ep_length   | 58.8     |
|    mean_reward      | 234      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 271500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.07     |
|    n_updates        | 57874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3884     |
|    fps              | 85       |
|    time_elapsed     | 3169     |
|    total_timesteps  | 271654   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.03     |
|    n_updates        | 57913    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.3     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3888     |
|    fps              | 85       |
|    time_elapsed     | 3170     |
|    total_timesteps  | 271921   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.13     |
|    n_updates        | 57980    |
----------------------------------
Eval num_timesteps=272000, episode_reward=169.70 +/- 42.83
Episode length: 42.78 +/- 10.73
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 272000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.01     |
|    n_updates        | 57999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.6     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3892     |
|    fps              | 85       |
|    time_elapsed     | 3174     |
|    total_timesteps  | 272116   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.467    |
|    n_updates        | 58028    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.1     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3896     |
|    fps              | 85       |
|    time_elapsed     | 3175     |
|    total_timesteps  | 272332   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.125    |
|    n_updates        | 58082    |
----------------------------------
Eval num_timesteps=272500, episode_reward=174.88 +/- 41.34
Episode length: 44.08 +/- 10.39
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.1     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 272500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.13     |
|    n_updates        | 58124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.1     |
|    ep_rew_mean      | 235      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3900     |
|    fps              | 85       |
|    time_elapsed     | 3179     |
|    total_timesteps  | 272642   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.238    |
|    n_updates        | 58160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.5     |
|    ep_rew_mean      | 236      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3904     |
|    fps              | 85       |
|    time_elapsed     | 3180     |
|    total_timesteps  | 272864   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.14     |
|    n_updates        | 58215    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58       |
|    ep_rew_mean      | 231      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3908     |
|    fps              | 85       |
|    time_elapsed     | 3180     |
|    total_timesteps  | 272999   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.71     |
|    n_updates        | 58249    |
----------------------------------
Eval num_timesteps=273000, episode_reward=173.36 +/- 38.57
Episode length: 43.74 +/- 9.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 43.7     |
|    mean_reward     | 173      |
| time/              |          |
|    total_timesteps | 273000   |
---------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.5     |
|    ep_rew_mean      | 233      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3912     |
|    fps              | 85       |
|    time_elapsed     | 3185     |
|    total_timesteps  | 273277   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.181    |
|    n_updates        | 58319    |
----------------------------------
Eval num_timesteps=273500, episode_reward=173.04 +/- 55.63
Episode length: 43.62 +/- 13.95
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.6     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 273500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.72     |
|    n_updates        | 58374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60       |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3916     |
|    fps              | 85       |
|    time_elapsed     | 3190     |
|    total_timesteps  | 273578   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.859    |
|    n_updates        | 58394    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.2     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3920     |
|    fps              | 85       |
|    time_elapsed     | 3191     |
|    total_timesteps  | 273889   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.93     |
|    n_updates        | 58472    |
----------------------------------
Eval num_timesteps=274000, episode_reward=180.82 +/- 47.58
Episode length: 45.50 +/- 11.83
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.5     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 274000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.9      |
|    n_updates        | 58499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3924     |
|    fps              | 85       |
|    time_elapsed     | 3195     |
|    total_timesteps  | 274082   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.232    |
|    n_updates        | 58520    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.8     |
|    ep_rew_mean      | 242      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3928     |
|    fps              | 85       |
|    time_elapsed     | 3195     |
|    total_timesteps  | 274247   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.998    |
|    n_updates        | 58561    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61       |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3932     |
|    fps              | 85       |
|    time_elapsed     | 3196     |
|    total_timesteps  | 274478   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.236    |
|    n_updates        | 58619    |
----------------------------------
Eval num_timesteps=274500, episode_reward=315.06 +/- 163.97
Episode length: 79.14 +/- 41.04
----------------------------------
| eval/               |          |
|    mean_ep_length   | 79.1     |
|    mean_reward      | 315      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 274500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.06     |
|    n_updates        | 58624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3936     |
|    fps              | 85       |
|    time_elapsed     | 3203     |
|    total_timesteps  | 274711   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.19     |
|    n_updates        | 58677    |
----------------------------------
Eval num_timesteps=275000, episode_reward=178.52 +/- 44.64
Episode length: 44.98 +/- 11.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45       |
|    mean_reward      | 179      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 275000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.7      |
|    n_updates        | 58749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3940     |
|    fps              | 85       |
|    time_elapsed     | 3208     |
|    total_timesteps  | 275002   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.54     |
|    n_updates        | 58750    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3944     |
|    fps              | 85       |
|    time_elapsed     | 3209     |
|    total_timesteps  | 275208   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.115    |
|    n_updates        | 58801    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.1     |
|    ep_rew_mean      | 239      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3948     |
|    fps              | 85       |
|    time_elapsed     | 3209     |
|    total_timesteps  | 275452   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.4      |
|    n_updates        | 58862    |
----------------------------------
Eval num_timesteps=275500, episode_reward=170.42 +/- 36.51
Episode length: 43.02 +/- 9.10
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43       |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 275500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.9      |
|    n_updates        | 58874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.9     |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3952     |
|    fps              | 85       |
|    time_elapsed     | 3215     |
|    total_timesteps  | 275666   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.302    |
|    n_updates        | 58916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.9     |
|    ep_rew_mean      | 234      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3956     |
|    fps              | 85       |
|    time_elapsed     | 3216     |
|    total_timesteps  | 275880   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.08     |
|    n_updates        | 58969    |
----------------------------------
Eval num_timesteps=276000, episode_reward=170.16 +/- 39.36
Episode length: 42.92 +/- 9.84
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.9     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 276000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.17     |
|    n_updates        | 58999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.8     |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3960     |
|    fps              | 85       |
|    time_elapsed     | 3222     |
|    total_timesteps  | 276236   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.04     |
|    n_updates        | 59058    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.8     |
|    ep_rew_mean      | 238      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3964     |
|    fps              | 85       |
|    time_elapsed     | 3222     |
|    total_timesteps  | 276436   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.168    |
|    n_updates        | 59108    |
----------------------------------
Eval num_timesteps=276500, episode_reward=175.56 +/- 44.62
Episode length: 44.28 +/- 11.11
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.3     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 276500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.265    |
|    n_updates        | 59124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.6     |
|    ep_rew_mean      | 237      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3968     |
|    fps              | 85       |
|    time_elapsed     | 3227     |
|    total_timesteps  | 276704   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.19     |
|    n_updates        | 59175    |
----------------------------------
Eval num_timesteps=277000, episode_reward=187.58 +/- 50.17
Episode length: 47.26 +/- 12.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.3     |
|    mean_reward      | 188      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 277000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.11     |
|    n_updates        | 59249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.7     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3972     |
|    fps              | 85       |
|    time_elapsed     | 3232     |
|    total_timesteps  | 277007   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.78     |
|    n_updates        | 59251    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.9     |
|    ep_rew_mean      | 242      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3976     |
|    fps              | 85       |
|    time_elapsed     | 3233     |
|    total_timesteps  | 277261   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.03     |
|    n_updates        | 59315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3980     |
|    fps              | 85       |
|    time_elapsed     | 3234     |
|    total_timesteps  | 277475   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.297    |
|    n_updates        | 59368    |
----------------------------------
Eval num_timesteps=277500, episode_reward=183.10 +/- 47.15
Episode length: 46.18 +/- 11.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 46.2     |
|    mean_reward      | 183      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 277500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.543    |
|    n_updates        | 59374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.3     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3984     |
|    fps              | 85       |
|    time_elapsed     | 3239     |
|    total_timesteps  | 277786   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.37     |
|    n_updates        | 59446    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.7     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3988     |
|    fps              | 85       |
|    time_elapsed     | 3240     |
|    total_timesteps  | 277991   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.108    |
|    n_updates        | 59497    |
----------------------------------
Eval num_timesteps=278000, episode_reward=215.34 +/- 73.82
Episode length: 54.22 +/- 18.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 54.2     |
|    mean_reward      | 215      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 278000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.89     |
|    n_updates        | 59499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.8     |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3992     |
|    fps              | 85       |
|    time_elapsed     | 3246     |
|    total_timesteps  | 278291   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.04     |
|    n_updates        | 59572    |
----------------------------------
Eval num_timesteps=278500, episode_reward=178.16 +/- 50.40
Episode length: 44.94 +/- 12.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.9     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 278500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.236    |
|    n_updates        | 59624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.7     |
|    ep_rew_mean      | 249      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 3996     |
|    fps              | 85       |
|    time_elapsed     | 3251     |
|    total_timesteps  | 278599   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.98     |
|    n_updates        | 59649    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 247      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4000     |
|    fps              | 85       |
|    time_elapsed     | 3252     |
|    total_timesteps  | 278850   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.12     |
|    n_updates        | 59712    |
----------------------------------
Eval num_timesteps=279000, episode_reward=180.18 +/- 54.40
Episode length: 45.44 +/- 13.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.4     |
|    mean_reward      | 180      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 279000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.918    |
|    n_updates        | 59749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.7     |
|    ep_rew_mean      | 253      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4004     |
|    fps              | 85       |
|    time_elapsed     | 3257     |
|    total_timesteps  | 279230   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.27     |
|    n_updates        | 59807    |
----------------------------------
Eval num_timesteps=279500, episode_reward=264.12 +/- 116.26
Episode length: 66.40 +/- 29.02
----------------------------------
| eval/               |          |
|    mean_ep_length   | 66.4     |
|    mean_reward      | 264      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 279500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.178    |
|    n_updates        | 59874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | 263      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4008     |
|    fps              | 85       |
|    time_elapsed     | 3264     |
|    total_timesteps  | 279599   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.62     |
|    n_updates        | 59899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4012     |
|    fps              | 85       |
|    time_elapsed     | 3265     |
|    total_timesteps  | 279903   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.257    |
|    n_updates        | 59975    |
----------------------------------
Eval num_timesteps=280000, episode_reward=295.22 +/- 141.53
Episode length: 74.24 +/- 35.44
----------------------------------
| eval/               |          |
|    mean_ep_length   | 74.2     |
|    mean_reward      | 295      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 280000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.03     |
|    n_updates        | 59999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4016     |
|    fps              | 85       |
|    time_elapsed     | 3272     |
|    total_timesteps  | 280130   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.265    |
|    n_updates        | 60032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.6     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4020     |
|    fps              | 85       |
|    time_elapsed     | 3273     |
|    total_timesteps  | 280353   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.279    |
|    n_updates        | 60088    |
----------------------------------
Eval num_timesteps=280500, episode_reward=168.66 +/- 38.75
Episode length: 42.54 +/- 9.75
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.5     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 280500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.08     |
|    n_updates        | 60124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.2     |
|    ep_rew_mean      | 259      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4024     |
|    fps              | 85       |
|    time_elapsed     | 3277     |
|    total_timesteps  | 280605   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.87     |
|    n_updates        | 60151    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.4     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4028     |
|    fps              | 85       |
|    time_elapsed     | 3278     |
|    total_timesteps  | 280783   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.2      |
|    n_updates        | 60195    |
----------------------------------
Eval num_timesteps=281000, episode_reward=169.84 +/- 48.56
Episode length: 42.80 +/- 12.14
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 281000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.681    |
|    n_updates        | 60249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.4     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4032     |
|    fps              | 85       |
|    time_elapsed     | 3284     |
|    total_timesteps  | 281022   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.89     |
|    n_updates        | 60255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4036     |
|    fps              | 85       |
|    time_elapsed     | 3285     |
|    total_timesteps  | 281266   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.14     |
|    n_updates        | 60316    |
----------------------------------
Eval num_timesteps=281500, episode_reward=304.46 +/- 138.97
Episode length: 76.46 +/- 34.80
----------------------------------
| eval/               |          |
|    mean_ep_length   | 76.5     |
|    mean_reward      | 304      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 281500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.62     |
|    n_updates        | 60374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4040     |
|    fps              | 85       |
|    time_elapsed     | 3296     |
|    total_timesteps  | 281547   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.19     |
|    n_updates        | 60386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4044     |
|    fps              | 85       |
|    time_elapsed     | 3298     |
|    total_timesteps  | 281843   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.93     |
|    n_updates        | 60460    |
----------------------------------
Eval num_timesteps=282000, episode_reward=354.26 +/- 170.63
Episode length: 88.84 +/- 42.65
----------------------------------
| eval/               |          |
|    mean_ep_length   | 88.8     |
|    mean_reward      | 354      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 282000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.06     |
|    n_updates        | 60499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4048     |
|    fps              | 85       |
|    time_elapsed     | 3306     |
|    total_timesteps  | 282188   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.41     |
|    n_updates        | 60546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | 269      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4052     |
|    fps              | 85       |
|    time_elapsed     | 3307     |
|    total_timesteps  | 282421   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.288    |
|    n_updates        | 60605    |
----------------------------------
Eval num_timesteps=282500, episode_reward=174.56 +/- 46.58
Episode length: 43.92 +/- 11.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 175      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 282500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.02     |
|    n_updates        | 60624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.2     |
|    ep_rew_mean      | 271      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4056     |
|    fps              | 85       |
|    time_elapsed     | 3312     |
|    total_timesteps  | 282703   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.29     |
|    n_updates        | 60675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4060     |
|    fps              | 85       |
|    time_elapsed     | 3312     |
|    total_timesteps  | 282978   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.213    |
|    n_updates        | 60744    |
----------------------------------
Eval num_timesteps=283000, episode_reward=176.92 +/- 47.04
Episode length: 44.54 +/- 11.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.5     |
|    mean_reward      | 177      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 283000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.01     |
|    n_updates        | 60749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.6     |
|    ep_rew_mean      | 269      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4064     |
|    fps              | 85       |
|    time_elapsed     | 3317     |
|    total_timesteps  | 283192   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.258    |
|    n_updates        | 60797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4068     |
|    fps              | 85       |
|    time_elapsed     | 3318     |
|    total_timesteps  | 283438   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.07     |
|    n_updates        | 60859    |
----------------------------------
Eval num_timesteps=283500, episode_reward=328.62 +/- 169.20
Episode length: 82.52 +/- 42.34
----------------------------------
| eval/               |          |
|    mean_ep_length   | 82.5     |
|    mean_reward      | 329      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 283500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2        |
|    n_updates        | 60874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | 264      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4072     |
|    fps              | 85       |
|    time_elapsed     | 3326     |
|    total_timesteps  | 283640   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.99     |
|    n_updates        | 60909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4076     |
|    fps              | 85       |
|    time_elapsed     | 3327     |
|    total_timesteps  | 283998   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.04     |
|    n_updates        | 60999    |
----------------------------------
Eval num_timesteps=284000, episode_reward=168.40 +/- 44.92
Episode length: 42.54 +/- 11.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.5     |
|    mean_reward      | 168      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 284000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.7     |
|    ep_rew_mean      | 269      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4080     |
|    fps              | 85       |
|    time_elapsed     | 3332     |
|    total_timesteps  | 284244   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.28     |
|    n_updates        | 61060    |
----------------------------------
Eval num_timesteps=284500, episode_reward=224.48 +/- 63.05
Episode length: 56.50 +/- 15.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 56.5     |
|    mean_reward      | 224      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 284500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.143    |
|    n_updates        | 61124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | 268      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4084     |
|    fps              | 85       |
|    time_elapsed     | 3339     |
|    total_timesteps  | 284513   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.86     |
|    n_updates        | 61128    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.4     |
|    ep_rew_mean      | 272      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4088     |
|    fps              | 85       |
|    time_elapsed     | 3340     |
|    total_timesteps  | 284833   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.336    |
|    n_updates        | 61208    |
----------------------------------
Eval num_timesteps=285000, episode_reward=270.06 +/- 96.59
Episode length: 67.88 +/- 24.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67.9     |
|    mean_reward      | 270      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 285000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.97     |
|    n_updates        | 61249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.6     |
|    ep_rew_mean      | 269      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4092     |
|    fps              | 85       |
|    time_elapsed     | 3347     |
|    total_timesteps  | 285049   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.291    |
|    n_updates        | 61262    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.8     |
|    ep_rew_mean      | 266      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4096     |
|    fps              | 85       |
|    time_elapsed     | 3348     |
|    total_timesteps  | 285279   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.15     |
|    n_updates        | 61319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | 262      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4100     |
|    fps              | 85       |
|    time_elapsed     | 3349     |
|    total_timesteps  | 285450   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.237    |
|    n_updates        | 61362    |
----------------------------------
Eval num_timesteps=285500, episode_reward=180.56 +/- 54.06
Episode length: 45.54 +/- 13.57
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.5     |
|    mean_reward      | 181      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 285500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.61     |
|    n_updates        | 61374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4104     |
|    fps              | 85       |
|    time_elapsed     | 3353     |
|    total_timesteps  | 285637   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.993    |
|    n_updates        | 61409    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62       |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4108     |
|    fps              | 85       |
|    time_elapsed     | 3354     |
|    total_timesteps  | 285803   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.223    |
|    n_updates        | 61450    |
----------------------------------
Eval num_timesteps=286000, episode_reward=266.10 +/- 112.90
Episode length: 66.96 +/- 28.23
----------------------------------
| eval/               |          |
|    mean_ep_length   | 67       |
|    mean_reward      | 266      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 286000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.2      |
|    n_updates        | 61499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4112     |
|    fps              | 85       |
|    time_elapsed     | 3363     |
|    total_timesteps  | 286043   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.427    |
|    n_updates        | 61510    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.2     |
|    ep_rew_mean      | 243      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4116     |
|    fps              | 85       |
|    time_elapsed     | 3364     |
|    total_timesteps  | 286252   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.1      |
|    n_updates        | 61562    |
----------------------------------
Eval num_timesteps=286500, episode_reward=190.30 +/- 50.25
Episode length: 47.96 +/- 12.53
----------------------------------
| eval/               |          |
|    mean_ep_length   | 48       |
|    mean_reward      | 190      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 286500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.92     |
|    n_updates        | 61624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.9     |
|    ep_rew_mean      | 250      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4120     |
|    fps              | 85       |
|    time_elapsed     | 3369     |
|    total_timesteps  | 286641   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.188    |
|    n_updates        | 61660    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 254      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4124     |
|    fps              | 85       |
|    time_elapsed     | 3370     |
|    total_timesteps  | 286988   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.41     |
|    n_updates        | 61746    |
----------------------------------
Eval num_timesteps=287000, episode_reward=160.14 +/- 39.04
Episode length: 40.44 +/- 9.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.4     |
|    mean_reward      | 160      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 287000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.0813   |
|    n_updates        | 61749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.7     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4128     |
|    fps              | 85       |
|    time_elapsed     | 3375     |
|    total_timesteps  | 287252   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.287    |
|    n_updates        | 61812    |
----------------------------------
Eval num_timesteps=287500, episode_reward=207.94 +/- 40.72
Episode length: 52.36 +/- 10.19
----------------------------------
| eval/               |          |
|    mean_ep_length   | 52.4     |
|    mean_reward      | 208      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 287500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.2      |
|    n_updates        | 61874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4132     |
|    fps              | 85       |
|    time_elapsed     | 3380     |
|    total_timesteps  | 287585   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.188    |
|    n_updates        | 61896    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4136     |
|    fps              | 85       |
|    time_elapsed     | 3381     |
|    total_timesteps  | 287823   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.119    |
|    n_updates        | 61955    |
----------------------------------
Eval num_timesteps=288000, episode_reward=275.32 +/- 112.76
Episode length: 69.18 +/- 28.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 69.2     |
|    mean_reward      | 275      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 288000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.23     |
|    n_updates        | 61999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4140     |
|    fps              | 85       |
|    time_elapsed     | 3387     |
|    total_timesteps  | 288124   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.448    |
|    n_updates        | 62030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.1     |
|    ep_rew_mean      | 259      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4144     |
|    fps              | 85       |
|    time_elapsed     | 3388     |
|    total_timesteps  | 288350   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.873    |
|    n_updates        | 62087    |
----------------------------------
Eval num_timesteps=288500, episode_reward=189.12 +/- 40.52
Episode length: 47.62 +/- 10.17
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47.6     |
|    mean_reward      | 189      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 288500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.7      |
|    n_updates        | 62124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4148     |
|    fps              | 85       |
|    time_elapsed     | 3393     |
|    total_timesteps  | 288602   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.73     |
|    n_updates        | 62150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.1     |
|    ep_rew_mean      | 259      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4152     |
|    fps              | 85       |
|    time_elapsed     | 3394     |
|    total_timesteps  | 288928   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.371    |
|    n_updates        | 62231    |
----------------------------------
Eval num_timesteps=289000, episode_reward=173.84 +/- 45.91
Episode length: 43.88 +/- 11.50
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.9     |
|    mean_reward      | 174      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 289000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.73     |
|    n_updates        | 62249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65       |
|    ep_rew_mean      | 258      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4156     |
|    fps              | 85       |
|    time_elapsed     | 3399     |
|    total_timesteps  | 289202   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.43     |
|    n_updates        | 62300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 256      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4160     |
|    fps              | 85       |
|    time_elapsed     | 3399     |
|    total_timesteps  | 289412   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.14     |
|    n_updates        | 62352    |
----------------------------------
Eval num_timesteps=289500, episode_reward=164.16 +/- 36.65
Episode length: 41.46 +/- 9.16
----------------------------------
| eval/               |          |
|    mean_ep_length   | 41.5     |
|    mean_reward      | 164      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 289500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.193    |
|    n_updates        | 62374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4164     |
|    fps              | 85       |
|    time_elapsed     | 3404     |
|    total_timesteps  | 289618   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.02     |
|    n_updates        | 62404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4168     |
|    fps              | 85       |
|    time_elapsed     | 3405     |
|    total_timesteps  | 289913   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.457    |
|    n_updates        | 62478    |
----------------------------------
Eval num_timesteps=290000, episode_reward=172.62 +/- 47.47
Episode length: 43.52 +/- 11.86
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.5     |
|    mean_reward      | 173      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 290000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.945    |
|    n_updates        | 62499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 257      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4172     |
|    fps              | 85       |
|    time_elapsed     | 3410     |
|    total_timesteps  | 290117   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.04     |
|    n_updates        | 62529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.5     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4176     |
|    fps              | 85       |
|    time_elapsed     | 3410     |
|    total_timesteps  | 290352   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.84     |
|    n_updates        | 62587    |
----------------------------------
Eval num_timesteps=290500, episode_reward=181.80 +/- 55.49
Episode length: 45.86 +/- 13.87
----------------------------------
| eval/               |          |
|    mean_ep_length   | 45.9     |
|    mean_reward      | 182      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 290500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.143    |
|    n_updates        | 62624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4180     |
|    fps              | 85       |
|    time_elapsed     | 3415     |
|    total_timesteps  | 290656   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.415    |
|    n_updates        | 62663    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.2     |
|    ep_rew_mean      | 251      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4184     |
|    fps              | 85       |
|    time_elapsed     | 3416     |
|    total_timesteps  | 290832   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.34     |
|    n_updates        | 62707    |
----------------------------------
Eval num_timesteps=291000, episode_reward=201.06 +/- 65.87
Episode length: 50.54 +/- 16.48
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.5     |
|    mean_reward      | 201      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 291000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.01     |
|    n_updates        | 62749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.1     |
|    ep_rew_mean      | 250      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4188     |
|    fps              | 85       |
|    time_elapsed     | 3421     |
|    total_timesteps  | 291140   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.18     |
|    n_updates        | 62784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.4     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4192     |
|    fps              | 85       |
|    time_elapsed     | 3422     |
|    total_timesteps  | 291384   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.02     |
|    n_updates        | 62845    |
----------------------------------
Eval num_timesteps=291500, episode_reward=186.42 +/- 49.91
Episode length: 47.00 +/- 12.45
----------------------------------
| eval/               |          |
|    mean_ep_length   | 47       |
|    mean_reward      | 186      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 291500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.76     |
|    n_updates        | 62874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | 250      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4196     |
|    fps              | 85       |
|    time_elapsed     | 3427     |
|    total_timesteps  | 291579   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.49     |
|    n_updates        | 62894    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.2     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4200     |
|    fps              | 85       |
|    time_elapsed     | 3428     |
|    total_timesteps  | 291866   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.44     |
|    n_updates        | 62966    |
----------------------------------
Eval num_timesteps=292000, episode_reward=280.12 +/- 127.67
Episode length: 70.42 +/- 31.94
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.4     |
|    mean_reward      | 280      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 292000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.3      |
|    n_updates        | 62999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4204     |
|    fps              | 85       |
|    time_elapsed     | 3434     |
|    total_timesteps  | 292189   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.34     |
|    n_updates        | 63047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 261      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4208     |
|    fps              | 85       |
|    time_elapsed     | 3435     |
|    total_timesteps  | 292367   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.218    |
|    n_updates        | 63091    |
----------------------------------
Eval num_timesteps=292500, episode_reward=288.92 +/- 84.77
Episode length: 72.60 +/- 21.15
----------------------------------
| eval/               |          |
|    mean_ep_length   | 72.6     |
|    mean_reward      | 289      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 292500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.09     |
|    n_updates        | 63124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 260      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4212     |
|    fps              | 84       |
|    time_elapsed     | 3444     |
|    total_timesteps  | 292598   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.735    |
|    n_updates        | 63149    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | 262      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4216     |
|    fps              | 84       |
|    time_elapsed     | 3445     |
|    total_timesteps  | 292832   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.265    |
|    n_updates        | 63207    |
----------------------------------
Eval num_timesteps=293000, episode_reward=169.58 +/- 46.25
Episode length: 42.76 +/- 11.55
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.8     |
|    mean_reward      | 170      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 293000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.88     |
|    n_updates        | 63249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4220     |
|    fps              | 84       |
|    time_elapsed     | 3451     |
|    total_timesteps  | 293053   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.19     |
|    n_updates        | 63263    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.7     |
|    ep_rew_mean      | 249      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4224     |
|    fps              | 84       |
|    time_elapsed     | 3452     |
|    total_timesteps  | 293262   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.04     |
|    n_updates        | 63315    |
----------------------------------
Eval num_timesteps=293500, episode_reward=279.34 +/- 134.67
Episode length: 70.22 +/- 33.60
----------------------------------
| eval/               |          |
|    mean_ep_length   | 70.2     |
|    mean_reward      | 279      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 293500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.355    |
|    n_updates        | 63374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.7     |
|    ep_rew_mean      | 249      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4228     |
|    fps              | 84       |
|    time_elapsed     | 3460     |
|    total_timesteps  | 293526   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.14     |
|    n_updates        | 63381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.3     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4232     |
|    fps              | 84       |
|    time_elapsed     | 3461     |
|    total_timesteps  | 293714   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.33     |
|    n_updates        | 63428    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4236     |
|    fps              | 84       |
|    time_elapsed     | 3462     |
|    total_timesteps  | 293959   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.1      |
|    n_updates        | 63489    |
----------------------------------
Eval num_timesteps=294000, episode_reward=200.50 +/- 63.92
Episode length: 50.46 +/- 16.03
----------------------------------
| eval/               |          |
|    mean_ep_length   | 50.5     |
|    mean_reward      | 200      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 294000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.22     |
|    n_updates        | 63499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.6     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4240     |
|    fps              | 84       |
|    time_elapsed     | 3468     |
|    total_timesteps  | 294188   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.77     |
|    n_updates        | 63546    |
----------------------------------
Eval num_timesteps=294500, episode_reward=284.34 +/- 66.82
Episode length: 71.44 +/- 16.67
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.4     |
|    mean_reward      | 284      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 294500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.137    |
|    n_updates        | 63624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.9     |
|    ep_rew_mean      | 246      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4244     |
|    fps              | 84       |
|    time_elapsed     | 3475     |
|    total_timesteps  | 294541   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.278    |
|    n_updates        | 63635    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 244      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4248     |
|    fps              | 84       |
|    time_elapsed     | 3475     |
|    total_timesteps  | 294740   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.14     |
|    n_updates        | 63684    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 241      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4252     |
|    fps              | 84       |
|    time_elapsed     | 3476     |
|    total_timesteps  | 294983   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.63     |
|    n_updates        | 63745    |
----------------------------------
Eval num_timesteps=295000, episode_reward=272.56 +/- 103.13
Episode length: 68.58 +/- 25.79
----------------------------------
| eval/               |          |
|    mean_ep_length   | 68.6     |
|    mean_reward      | 273      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 295000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.92     |
|    n_updates        | 63749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.3     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4256     |
|    fps              | 84       |
|    time_elapsed     | 3483     |
|    total_timesteps  | 295231   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.1      |
|    n_updates        | 63807    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.3     |
|    ep_rew_mean      | 240      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4260     |
|    fps              | 84       |
|    time_elapsed     | 3484     |
|    total_timesteps  | 295439   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.27     |
|    n_updates        | 63859    |
----------------------------------
Eval num_timesteps=295500, episode_reward=178.04 +/- 43.99
Episode length: 44.84 +/- 10.99
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.8     |
|    mean_reward      | 178      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 295500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1        |
|    n_updates        | 63874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 247      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4264     |
|    fps              | 84       |
|    time_elapsed     | 3489     |
|    total_timesteps  | 295831   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.19     |
|    n_updates        | 63957    |
----------------------------------
Eval num_timesteps=296000, episode_reward=202.46 +/- 66.50
Episode length: 50.96 +/- 16.64
----------------------------------
| eval/               |          |
|    mean_ep_length   | 51       |
|    mean_reward      | 202      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 296000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 3.04     |
|    n_updates        | 63999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.6     |
|    ep_rew_mean      | 249      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4268     |
|    fps              | 84       |
|    time_elapsed     | 3494     |
|    total_timesteps  | 296177   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.247    |
|    n_updates        | 64044    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.2     |
|    ep_rew_mean      | 252      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4272     |
|    fps              | 84       |
|    time_elapsed     | 3495     |
|    total_timesteps  | 296442   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.18     |
|    n_updates        | 64110    |
----------------------------------
Eval num_timesteps=296500, episode_reward=318.20 +/- 127.35
Episode length: 79.98 +/- 31.88
----------------------------------
| eval/               |          |
|    mean_ep_length   | 80       |
|    mean_reward      | 318      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 296500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.03     |
|    n_updates        | 64124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | 251      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4276     |
|    fps              | 84       |
|    time_elapsed     | 3502     |
|    total_timesteps  | 296657   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.03     |
|    n_updates        | 64164    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.6     |
|    ep_rew_mean      | 249      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4280     |
|    fps              | 84       |
|    time_elapsed     | 3503     |
|    total_timesteps  | 296916   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.16     |
|    n_updates        | 64228    |
----------------------------------
Eval num_timesteps=297000, episode_reward=286.32 +/- 152.32
Episode length: 71.94 +/- 38.09
----------------------------------
| eval/               |          |
|    mean_ep_length   | 71.9     |
|    mean_reward      | 286      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 297000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.2      |
|    n_updates        | 64249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 256      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4284     |
|    fps              | 84       |
|    time_elapsed     | 3510     |
|    total_timesteps  | 297262   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.372    |
|    n_updates        | 64315    |
----------------------------------
Eval num_timesteps=297500, episode_reward=309.96 +/- 143.36
Episode length: 77.86 +/- 35.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 77.9     |
|    mean_reward      | 310      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 297500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.09     |
|    n_updates        | 64374    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 254      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4288     |
|    fps              | 84       |
|    time_elapsed     | 3517     |
|    total_timesteps  | 297520   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.68     |
|    n_updates        | 64379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.5     |
|    ep_rew_mean      | 253      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4292     |
|    fps              | 84       |
|    time_elapsed     | 3518     |
|    total_timesteps  | 297736   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.82     |
|    n_updates        | 64433    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.2     |
|    ep_rew_mean      | 255      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4296     |
|    fps              | 84       |
|    time_elapsed     | 3519     |
|    total_timesteps  | 297995   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.963    |
|    n_updates        | 64498    |
----------------------------------
Eval num_timesteps=298000, episode_reward=342.16 +/- 162.39
Episode length: 85.88 +/- 40.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 85.9     |
|    mean_reward      | 342      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 298000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.355    |
|    n_updates        | 64499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 256      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4300     |
|    fps              | 84       |
|    time_elapsed     | 3527     |
|    total_timesteps  | 298293   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.09     |
|    n_updates        | 64573    |
----------------------------------
Eval num_timesteps=298500, episode_reward=171.26 +/- 45.24
Episode length: 43.20 +/- 11.36
----------------------------------
| eval/               |          |
|    mean_ep_length   | 43.2     |
|    mean_reward      | 171      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 298500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.505    |
|    n_updates        | 64624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.2     |
|    ep_rew_mean      | 251      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4304     |
|    fps              | 84       |
|    time_elapsed     | 3531     |
|    total_timesteps  | 298509   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.183    |
|    n_updates        | 64627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.6     |
|    ep_rew_mean      | 253      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4308     |
|    fps              | 84       |
|    time_elapsed     | 3532     |
|    total_timesteps  | 298726   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.12     |
|    n_updates        | 64681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 254      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4312     |
|    fps              | 84       |
|    time_elapsed     | 3533     |
|    total_timesteps  | 298979   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.94     |
|    n_updates        | 64744    |
----------------------------------
Eval num_timesteps=299000, episode_reward=161.70 +/- 42.18
Episode length: 40.82 +/- 10.52
----------------------------------
| eval/               |          |
|    mean_ep_length   | 40.8     |
|    mean_reward      | 162      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 299000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.922    |
|    n_updates        | 64749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 254      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4316     |
|    fps              | 84       |
|    time_elapsed     | 3537     |
|    total_timesteps  | 299209   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.83     |
|    n_updates        | 64802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 254      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4320     |
|    fps              | 84       |
|    time_elapsed     | 3538     |
|    total_timesteps  | 299436   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 2.12     |
|    n_updates        | 64858    |
----------------------------------
Eval num_timesteps=299500, episode_reward=176.10 +/- 50.55
Episode length: 44.40 +/- 12.61
----------------------------------
| eval/               |          |
|    mean_ep_length   | 44.4     |
|    mean_reward      | 176      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 299500   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.11     |
|    n_updates        | 64874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.9     |
|    ep_rew_mean      | 254      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4324     |
|    fps              | 84       |
|    time_elapsed     | 3542     |
|    total_timesteps  | 299647   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.96     |
|    n_updates        | 64911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 256      |
|    exploration_rate | 0.001    |
| time/               |          |
|    episodes         | 4328     |
|    fps              | 84       |
|    time_elapsed     | 3543     |
|    total_timesteps  | 299961   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 1.85     |
|    n_updates        | 64990    |
----------------------------------
Eval num_timesteps=300000, episode_reward=169.02 +/- 39.45
Episode length: 42.60 +/- 9.82
----------------------------------
| eval/               |          |
|    mean_ep_length   | 42.6     |
|    mean_reward      | 169      |
| rollout/            |          |
|    exploration_rate | 0.001    |
| time/               |          |
|    total_timesteps  | 300000   |
| train/              |          |
|    learning_rate    | 1e-05    |
|    loss             | 0.221    |
|    n_updates        | 64999    |
----------------------------------
/mnt/c/Proyecto/.venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'trains/take-cover/dqn-3/saves' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
Parameters: {'batch_size': 64, 'learning_rate': 1e-05, 'buffer_size': 15000, 'gamma': 0.957, 'exploration_fraction': 0.4, 'exploration_final_eps': 0.001, 'learning_starts': 40000.0, 'decay_start_steps': 40000.0, 'decay_end_steps': 200000.0}
Training steps: 300000
Frame skip: 4
